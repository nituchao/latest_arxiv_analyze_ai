# 20251007
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 深强化学习算法在集装箱堆存规划问题中的基准研究 [PDF](https://arxiv.org/pdf/2510.02589), [HTML](https://arxiv.org/abs/2510.02589)
### Authors
Yunqi Huang,Nishith Chennakeshava,Alexis Carras,Vladislav Neverov,Wei Liu,Aske Plaat,Yingjie Fan
### Background
集装箱堆存规划（CSPP）是海洋运输和码头操作的关键组成部分，直接影响供应链效率。由于其复杂性，CSPP 传统上依赖于人类的专业知识。虽然最近有使用强化学习（RL）来解决 CSPP 的尝试，但在不同的算法之间进行系统基准比较仍然有限。
### Innovation
本文开发了一个 Gym 环境来捕捉 CSPP 的基本特征，并扩展了涵盖起重机调度的多智能体和单智能体形式。在该框架下，评估了五种 RL 算法（DQN、QR-DQN、A2C、PPO 和 TRPO）在不同复杂性场景下的表现。结果表明，随着复杂性的增加，算法性能之间存在明显的差距，强调了算法选择和问题表述对于 CSPP 的重要性。
### Conclusion
本文对多种 RL 方法进行了基准测试，提供了一个包含起重机调度的可重复使用 Gym 环境，为未来研究和海运物流的实际部署奠定了基础。
## 2. `cs.AI` - RefineShot: 重新思考基于基础技能评估的影视理解 [PDF](https://arxiv.org/pdf/2510.02423), [HTML](https://arxiv.org/abs/2510.02423)
### Authors
Hang Wu,Yujun Cai,Haonan Ge,Hongkai Chen,Ming-Hsuan Yang,Yiwei Wang
### Background
电影拍摄的理解能力包括识别视觉内容和电影技术如何构建叙事意义的能力。这种能力受到越来越多的关注，因为它增强了现实世界应用中的多模态理解，并且支撑着电影和媒体中的内容创作。ShotBench 是这一任务最全面的基准，涵盖了广泛的电影概念和VQA风格的评估，标志着 ShotVL 达到了最先进的技术水平。然而，研究表明 ShotBench 中存在模糊化的选项设计问题，并且 ShotVL 在推理一致性以及指令遵守方面存在不足，这些都妨碍了评估的可靠性，并阻碍了未来的发展。
### Innovation
本文系统地改进了 ShotBench，通过一致的选项重结构化，首次对 ShotVL 的推理行为进行了关键分析，并引入了一个扩展的评估协议，该协议可以同时评估任务的准确性以及核心模型的能力。通过这些努力，得出了 RefineShot，这一改进和扩展的基准，它能够实现更可靠的评估，并促进未来在影视理解方面的进步。
### Conclusion
RefineShot 提供了更可靠的基础技能评估工具，为影视理解领域的研究和进步提供了更好的基础.
## 3. `cs.AI` - 温度采样在测试时缩放中的作用 [PDF](https://arxiv.org/pdf/2510.02611), [HTML](https://arxiv.org/abs/2510.02611)
### Authors
Yuheng Wu,Azalia Mirhoseini,Thierry Tambe
### Background
大语言模型（LLMs）可以通过测试时缩放（TTS）在推断时提高推理能力，其中生成多个推理轨迹并选择最佳的一个。先前的研究表明，增加样本数K会逐步提高准确性。本文表明在大型K的情况下，进一步缩放不会带来提升，并且某些难题无论生成多少推理轨迹都无法解决。有趣的是，不同的采样温度解决了不同的问题子集，暗示单一温度缩放只探索了模型潜力的一部分。
### Innovation
本文提出了沿着温度维度进行缩放，这可以扩大LLMs的推理边界。平均而言，温度缩放在Qwen3（0.6B, 1.7B, 4B, 8B）和五个代表性推理基准（AIME 2024/2025, MATH500, LiveCodeBench, Hi-ToM）上比单一温度缩放提供了额外的7.3个点的增益。此外，温度缩放使得基础模型能够达到与强化学习（RL）训练的对应模型相当的性能，而无需额外的后训练。本文还就这一现象进行了全面的分析并设计了一种多温度投票方法来减少温度缩放的开销。
### Conclusion
我们的研究结果表明，TTS比先前认为的更有力量，并且温度缩放提供了一种简单而有效的方法来解锁基础模型的潜在能力。
## 4. `cs.AI` - 通过风险控制实现安全高效的基于上下文学习 [PDF](https://arxiv.org/pdf/2510.02480), [HTML](https://arxiv.org/abs/2510.02480)
### Authors
Andrea Wynn,Metod Jazbec,Charith Peris,Rinat Khaziev,Anqi Liu,Daniel Khashabi,Eric Nalisnick
### Background
大语言模型（LLMs）展示了从少量上下文示例中学习新任务的显著能力。然而，这种灵活性带来了安全问题：LLMs 可能会受不正确的或恶意的示例影响——例如，如果对手篡改或注入有害示例而无人察觉。这促使我们在系统本身中内置机制来防范此类攻击。本文旨在通过严格的方法限制有害示例对模型性能的负面影响。
### Innovation
提出了一个新颖的方法来限制有害示例对模型性能的负面影响。首先，定义了一个基准的“安全”行为——即模型在没有上下文示例（零样本）时的性能。接着，通过分布无关的风险控制（DFRC）来控制上下文样本对性能的负面影响，在于它通过动态早期退出预测，忽略那些最关注有害输入的注意力头部。此外，提出对DFRC的修改不仅能够限制有害输入的风险，还能利用有益输入的性能和效率增益。
### Conclusion
本文展示了该方法可以有效控制有害上下文示例的风险，同时在有益示例上实现显著的计算效率增益。通过理论和实验结果表明该方法的有效性。
## 5. `cs.AI` - 智能代理在增材制造合金发现中的应用 [PDF](https://arxiv.org/pdf/2510.02567), [HTML](https://arxiv.org/abs/2510.02567)
### Authors
Peter Pak,Achuth Chandrasekhar,Amir Barati Farimani
### Background
增材制造（AM）领域的合金发现是一个复杂的过程，通常需要化学、热力学模拟和实验分析等多领域专业知识。通过利用大型语言模型（LLM）使能的智能代理，可以利用其知识库调用工具执行热力学性质计算等操作，有效增强研究者的合金研究能力，加快合金发现过程。这些智能代理能够根据工具调用的结果动态调整任务路径，实现自主决策，提升实用环境中的决策效率。
### Innovation
该研究通过开发一个能够处理复杂用户请求并提供合金可打印性分析的多智能体系统，利用LLM使能的智能代理自动化和加速增材制造合金发现的过程，并彰显了采用这一多智能体系统的好处。
### Conclusion
该工作旨在利用LLM使能的智能代理自动化和加速增材制造中的合金发现任务，并展示了多智能体系统的优点。
## 6. `cs.AI` - 协调人类-AI团队：经理代理作为统一的研究挑战 [PDF](https://arxiv.org/pdf/2510.02557), [HTML](https://arxiv.org/abs/2510.02557)
### Authors
Charlie Masters,Advaith Vellanki,Jiangbo Shangguan,Bart Kultys,Jonathan Gilmore,Alastair Moore,Stefano V. Albrecht
### Background
尽管代理型人工智能在自动化个体任务方面取得了进步，但管理复杂的多代理工作流仍然是一项具有挑战性的问题。本文讨论了自主代理系统如何在动态的人类-AI团队中协调合作的问题。
### Innovation
作者提出了自主管理代理作为核心挑战，并将其形式化为部分可观察的随机博弈。作者还定义了四个基础挑战：(1) 组合推理以实现分层分解，(2) 在偏好的不断变化下进行多目标优化，(3) 在临时团队中进行协调和规划，(4) 设计治理和合规性。作者还推出了一种开源的多代理工作流编排框架，即MA-Gym。
### Conclusion
评估基于GPT-5的管理代理在20个工作流中的表现，发现它们在共同优化目标完成、约束遵守和工作流运行时间方面遇到了困难。这表明工作流管理是一个具有挑战性的开放问题。最后，作者提出了自主管理系统在组织和伦理方面的含义。
## 7. `cs.AI` - BrowserArena: 在实际网页导航任务中评估LLM代理 [PDF](https://arxiv.org/pdf/2510.02418), [HTML](https://arxiv.org/abs/2510.02418)
### Authors
Sagnik Anupam,Davis Brown,Shuo Li,Eric Wong,Hamed Hassani,Osbert Bastani
### Background
当前的LLM（大型语言模型）代理能够在开放网络上浏览和执行动作，但现有的代理评估主要局限在沙盒环境或人造任务中。为了更全面地评估和理解这些代理在真实世界中的行为，作者介绍了一种名为BrowserArena的平台。BrowserArena允许收集用户提交的任务，在类似竞技场的设置中进行直接对比，并通过逐步骤的人类反馈来揭示代理使用的失败模式。
### Innovation
BrowserArena是一个实时的开放网络代理评估平台，它通过收集用户提交的任务、进行竞技场风格的直接对比，并使用逐步骤的人类反馈来揭示代理的失败模式。该平台还通过构建特定数据集来进一步研究这些任务，从而揭示了不同语言模型在处理这些失败模式时的差异性。
### Conclusion
通过BrowserArena，研究人员识别出代理在解决验证码、清除弹出广告和直接导航到URL这三个关键任务中的三大一致失败模式。进一步研究这些任务后，发现不同语言模型在这些失败模式中的行动策略存在显著差异。这些发现揭示了当前网络代理的多样性和脆弱性。更广泛而言，BrowserArena的测试方法为在大规模环境下研究和理解代理的失败模式提供了一种有力方法。
## 8. `cs.AI` - 缓解多模态推理中的模态失衡 [PDF](https://arxiv.org/pdf/2510.02608), [HTML](https://arxiv.org/abs/2510.02608)
### Authors
Chen Henry Wu,Neil Kale,Aditi Raghunathan
### Background
本文探讨了在多模态背景下，大规模基础模型（FMs）在协同推理能力上的表现，特别是当不同模态存在冲突时的处理能力。研究显示，FMs在单一模态下的冲突识别能力表现良好，但当不同模态信息分布不均时，其识别准确率显著下降，类似现象也出现在跨语言场景中。这些失败揭示了跨模态注意力不平衡的问题，表明目前的数据集未提供足够的跨模态推理样本。
### Innovation
本文揭示了大规模基础模型在处理跨模态冲突方面的不足，通过实验证明了适度的模态组合策略可以显著减少跨模态注意力不平衡，从而提高下游视觉-语言任务的表现。方法简单且易于实现，强调了系统化解决跨模态背景下问题的重要性。
### Conclusion
本文的研究结果强调了在构建可靠的基础模型时，系统地解决跨模态背景下的问题的重要性，并证明了一种简单的模态组合策略可以显著改善下游性能。
## 9. `cs.AI` - AutoMaAS: 自主进化的多智能体架构搜索方法针对大规模语言模型 [PDF](https://arxiv.org/pdf/2510.02669), [HTML](https://arxiv.org/abs/2510.02669)
### Authors
Bo Ma,Hang Li,ZeHua Hu,XiaoFan Gui,LuYao Liu,Simon Liu
### Background
多智能体系统由大型语言模型驱动，已经在多个领域展示了非凡的能力，但现有的自动设计方法倾向于寻找单一的解决方案，这些方案无法根据查询复杂性和领域要求进行资源分配调整。
### Innovation
本文引入了AutoMaAS，这是一种自我演化的多智能体架构搜索框架，利用神经架构搜索原则，通过动态操作生命周期管理和自动化机器学习技术自动发现最优的智能体配置。其四个关键创新点包括：(1)基于性能与成本分析的自动操作生成、融合和消除；(2)动态成本意识优化，结合实时参数调整；(3)通过在线反馈集成实现持续的架构精炼；(4)通过决策追踪机制增强可解释性。
### Conclusion
跨六个基准的广泛实验表明，AutoMaAS 在保持1.0-7.1%性能提升的同时，使推理成本降低了3-5%，并与最先进的方法相比具备更好的适应性。该框架展示出在不同数据集和LLM基础模型之间优越的迁移能力，确立了大规模语言模型时代自动多智能体系统设计的新范式。
## 10. `cs.AI` - Geolog-IA：用于学术论文的对话系统 [PDF](https://arxiv.org/pdf/2510.02653), [HTML](https://arxiv.org/abs/2510.02653)
### Authors
Micaela Fuel Pozo,Andrea Guatumillo Saltos,Yeseña Tipan Llumiquinga,Kelly Lascano Aguirre,Marilyn Castillo Jara,Christian Mejia-Escobar
### Background
该研究基于人工智能，开发了Geolog-IA，这是一种新型对话系统，能够自然地回答来自厄瓜多尔中央大学地质论文相关的问题。该系统使用了Llama 3.1和Gemini 2.5语言模型，并结合了检索增强生成（RAG）架构和SQLite数据库，以此来解决幻觉和过时知识的问题。
### Innovation
该研究的主要创新在于，通过使用Llama 3.1、Gemini 2.5语言模型、RAG架构和SQLite数据库，Geolog-IA能够更好地解决科研问答中的示例幻觉和知识老化问题。评估结果表明，Geolog-IA在BLEU度量上的性能评分为0.87，表明其生成的回答具有高一致性与准确性。系统提供了一个直观的基于Web的界面，便于机构中的多位人员进行互动和信息检索，如导师、教师、学生和管理人员等，能够形成应用于其他学科的基础工具和框架。
### Conclusion
Geolog-IA作为一种对话系统，在教育、培训和研究领域可以提供重要支持，并为其他学科的应用奠定基础。
## 11. `cs.AI` - 现实世界事件的概念 [PDF](https://arxiv.org/pdf/2510.02655), [HTML](https://arxiv.org/abs/2510.02655)
### Authors
Daniel G. Schwartz
### Background
本文提出了可能性的新概念，作为一种替代如今标准化的概念，该概念由L.A. Zadeh于1978年首次引入。新版本受原始概念启发，但在形式上没有任何共同之处，两者仅共同采用了Łukasiewicz多值逻辑联结词的解释方法。此外，本文没有寻求提供一种普遍的可能性概念，而是具体关注现实世界事件的可能性。该概念将事件视为具有使其实现的前提和可能阻碍其实现的约束，事件的可能性是前提成立和约束不成立的概率函数。这个版本的可能性概念可以合理应用于规划问题，能够帮助确定实现目标的最佳计划，即最容易或最可行的计划。作者推测这可以正确捕捉人类关于计划的正常推理过程。相关的理论被详细阐述，并提供了一个车辆路径规划的示例，还提出了未来潜在的应用方向。
### Innovation
提出了一个新概念——可能性，作为一种替代L.A. Zadeh在1978年引入的标准概念。虽然新版本受启发于原始概念，但在形式上完全不同。它专注于计算现实世界事件的可能性，该可能性是前提成立和约束不成立的概率函数。此外，该理论还提议将此概念应用于确定实现目标的最佳计划，并推测这种推理模型正确地反映了人类主题的计划推理。
### Conclusion
该模型详细阐述了新的可能性概念，并通过车辆路径规划的示例进行了说明。此外，还提出了未来可能会有更多潜在的应用领域。
## 12. `cs.AI` - 多模态函数向量在空间关系中的应用 [PDF](https://arxiv.org/pdf/2510.02528), [HTML](https://arxiv.org/abs/2510.02528)
### Authors
Shuhao Fu,Esther Goldberg,Ying Nian Wu,Hongjing Lu
### Background
大型多模态模型（LMMs）在有少量多模态示范的情况下展示了强大的上下文学习能力，但其内部机制仍不透明。本文基于之前大型语言模型的工作，发现开放火焰go-4B这一视觉语言模型中一小部分注意力头负责传递空间关系的表示，激活这些注意力头的函数向量可以提取并操作以改变LMM在关系任务上的表现。通过因果中介分析使用合成和真实图像数据集，这些函数向量可以在推理时显著提高零样本准确度。进一步研究证明，这些多模态函数向量在经过少量微调后，与冻结LMM参数基线相比，具有显著优势。最后，不同空间关系特定的函数向量可以线性组合解决未训练的空间关系类比问题，表明该方法具有强大的泛化能力。研究表明，LMM将空间关系知识编码于局部内部结构中，能够系统地提取和优化，从而深化我们对模型模块性和关系推理控制的理解。
### Innovation
研究发现一小部分注意力头负责传递空间关系的表示，提出了能够提高LMM在关系任务上表现的多模态函数向量。这些函数向量可以在调参少量数据后显著改善LMM的上下文学习基线。此外，这些特定的空间关系函数向量可以线性组合来解决未训练的空间关系类比问题，进一步证明了该方法的有效性与泛化能力。
### Conclusion
本文表明LMM中的空间关系知识存储于局部内部结构中，通过系统提取和优化这些知识，显著提升了LMM对复杂空间关系任务的理解与处理能力，对提高模型的模块性和增强对关系推理的控制有重要意义。
## 13. `cs.AI` - 多模态大型语言模型框架以实现安全可解释的智能电网集成电动汽车 [PDF](https://arxiv.org/pdf/2510.02592), [HTML](https://arxiv.org/abs/2510.02592)
### Authors
Jean Douglas Carvalho,Hugo Kenji,Ahmad Mohammad Saber,Glaucia Melo,Max Mauro Dias Santos,Deepa Kundur
### Background
电动汽车（EVs）与智能电网的整合提供了提高运输系统和能源网络的机会。然而，确保驾驶员、车辆和周围环境之间的安全和可解释的交互仍然是一个重要挑战。
### Innovation
该论文提出了一种基于多模态大型语言模型（LLM）的框架，用于处理多模态传感器数据（如目标检测、语义分割和车辆遥测），并生成自然语言警告供驾驶员使用。该框架通过结合视觉感知（YOLOv8）、地理编码定位和CAN总线遥测，将原始传感器数据与驾驶员理解相连接，在城市驾驶场景中实现更安全、更明智的决策。
### Conclusion
实验数据表明，该框架能够生成针对关键情况（如行人、自行车骑行者和其他车辆的接近）的上下文感知警告，证实了其有效性。该论文强调了LLM作为电动汽车辅助工具的潜力，通过使车队协调、电动汽车功率预测和交通感知能源规划变得规模化，将对电力系统和电动汽车产生好处。
## 14. `cs.AI` - 奖赏模型路由在对齐中的应用 [PDF](https://arxiv.org/pdf/2510.02850), [HTML](https://arxiv.org/abs/2510.02850)
### Authors
Xinle Wu,Yao Lu
### Background
强化学习（RL）从人类或AI反馈进行训练（RLHF/RLAIF）已成为大型语言模型（LLMs）对齐的标准范式。然而，大多数流程依赖于单一的奖励模型（RM），限制了对齐质量，并存在过拟合的风险。最近的研究探索了RM路由——从候选池中动态选择RM以利用互补优势，保持RM调用的时间复杂度为O(1)，但现有方法存在冷启动和探索不足的问题。
### Innovation
我们提出了一个混合路由框架BayesianRouter，结合了离线RM强度学习与在线贝叶斯选择。离线阶段，多任务路由器在偏好数据上进行训练，以估计每个RM的可靠性。在线阶段，贝叶斯泰勒抽样路由器进行 查询级别的RM选择，使用离线嵌入作为高斯先验，通过在线奖励自适应更新后验，以适应不断变化的策略分布。
### Conclusion
在指令遵循（AlpacaEval-2，Arena-Hard，MT-Bench）和推理（GSM8K，MMLU）基准测试中，BayesianRouter 一致优于单个RM、RM增强和现有路由方法。
## 15. `cs.AI` - ARS: 自适应多模态模型对抗代理，具备即插即用攻击 [PDF](https://arxiv.org/pdf/2510.02677), [HTML](https://arxiv.org/abs/2510.02677)
### Authors
Zhaorun Chen,Xun Liu,Mintong Kang,Jiawei Zhang,Minzhou Pan,Shuang Yang,Bo Li
### Background
随着视觉-语言模型（VLMs）的日益突出，它们的多模态界面也带来了新的安全漏洞，使得安全性评估变得更具挑战性和关键性。现有的红队攻击实验要么局限于狭窄的敌对模式，要么严重依赖于手动工程，缺乏对新兴真实世界VLM漏洞的大规模探索。
### Innovation
本文提出了ARS，一种自适应红队攻击代理，能够系统地开展全面的安全风险评估。ARS能够根据给定的目标有害行为或风险定义，自动优化多种包含增强推理的多层次红队策略，从而有效触发目标VLM的有害输出。此外，本文还提出了一种增强安全评估多样性和有效性的机制，包括层次记忆和ε-贪婪攻击探索算法。
### Conclusion
广泛实验表明，ARS在攻击成功率上取得了SOTA（当前最先进技术），平均超过基线52.1%，并在Claude-4-Sonnet上超过了90%。ARS生成的红队实例多样性显著提高，揭示了VLMs中的新兴漏洞。基于ARS，作者构建了包含超过30K个红队实例的大型多模态安全数据集，涵盖了51个不同的风险类别，并以实际的多模态威胁和监管风险为基础。利用ARS-Bench进行安全微调能够显著提高VLMs的鲁棒性，同时保持其通用用途，提供了针对新兴威胁优化多模态安全对齐的行动指南。
## 16. `cs.AI` - 从事实到反事实：为智能环境设计和评估反事实解释 [PDF](https://arxiv.org/pdf/2510.03078), [HTML](https://arxiv.org/abs/2510.03078)
### Authors
Anna Trapp,Mersedeh Sadeghi,Andreas Vogelsang
### Background
规则为基础的智能环境逐渐成为人们关注的焦点，解释性被认为是这类智能环境的一个关键特性。然而，在这些规则基础上，现有的方法尚未能够生成反事实解释。反事实解释是一种描述为了达成预期结果，可以进行怎样的不同操作的工具，在Explainable人工智能(XAI)中具有重要价值。
### Innovation
本文提出了首个针对规则为基础的智能环境的反事实解释形式化和实现方法。这种方法通过扩展现有智能环境的解释引擎以插件的形式进行实现。此外，通过用户研究对比了生成的反事实解释和传统的因果解释的用户偏好，揭示了语言简洁性和可操作性在不同情境下的影响。
### Conclusion
我们的研究为智能环境提供了一种新的解释框架，并提供了实验证据来指导何时选择每种解释类型更为有效。因果解释在语言简洁性和时间紧迫情况下更受欢迎，反事实解释则在可操作内容方面更受用户青睐。
## 17. `cs.AI` - 统一多模态离散扩散模型的强化学习 [PDF](https://arxiv.org/pdf/2510.02880), [HTML](https://arxiv.org/abs/2510.02880)
### Authors
Tianren Ma,Mu Zhang,Yibing Wang,Qixiang Ye
### Background
优化离散扩散模型（DDM）的奖励依然是一个挑战：无自回归范式使得重要性采样棘手且评估过程复杂，困扰着诸如GRPO等强化学习方法。
### Innovation
作者引入了MaskGRPO，这是一种首创的方法，能够使离散扩散的多模态强化学习在有效的重要性采样和模态特定适应方面实现可扩展性。首先，作者澄清了DDMs的理论基础，有助于建立能捕捉有价值的token波动以供梯度更新的重要性估计器。其次，作者精细调整了视觉序列的评估方法，产生多样化的完成品并提供可靠的优化梯度。最终，通过数学推理、编码和视觉生成基准测试，MaskGRPO带来了更稳定和高效的更新，提升了推理性能和生成质量。
### Conclusion
本研究将MaskGRPO确立为一种系统性的策略优化方法，并首次为离散视觉扩散提供了一种实用途径。
## 18. `cs.AI` - NCV：一种低成本结构化错误定位的大语言模型推理一致性验证方法 [PDF](https://arxiv.org/pdf/2510.02816), [HTML](https://arxiv.org/abs/2510.02816)
### Authors
Yulong Zhang,Li Wang,Wei Du,Peilin Li,Yuqin Dai Zhiyuan Zhao,Lingyong Fang,Ziniu Liu,Ru Zhang,Huijia Zhu,Gongshen Liu
### Background
在大语言模型中验证多步推理非常困难，因为错误定位模糊不清且标记每个令牌的成本高昂。现有的方法要么评估完整的推理链，导致注意力稀释，要么依赖昂贵的多采样。这使得验证过程既不高效也不可靠，特别是在大规模语言模型中。
### Innovation
引入了一种无需训练的框架——节点一致性验证（NCV），它将验证重构成节点级别的轻量级二进制一致性检查。通过将推理链分解为相互连接的验证节点，NCV能够精确定位错误并避免不必要的长格式生成。这种方法提高了解释性和效率，并提供了一种可扩展的解决方案，用于可靠的大语言模型推理验证，同时消耗比传统方法如CoT验证器少6到58倍的令牌数，F1分数提高了10%到25%。
### Conclusion
实验表明，NCV方法不仅增强了可解释性和效率，而且提供了比传统方法更具成本效益的解决方案，实现了大语言模型推理验证的可靠性和高效性。
## 19. `cs.AI` - AI解释的本体论与认识论分析 [PDF](https://arxiv.org/pdf/2510.02996), [HTML](https://arxiv.org/abs/2510.02996)
### Authors
Martina Mattioli,Eike Petersen,Aasa Feragen,Marcello Pelillo,Siavash A. Bigdeli
### Background
人工智能（AI）已经渗透到几乎所有领域，但当前主导的深度学习方法因其缺乏解释而被视为黑箱系统，严重影响了其可信度和应用。为了解决这一问题，可解释人工智能（XAI）方法被提出，旨在提供模型决策过程的解释。然而，关于解释的基本概念——包括什么是解释、我们是否可以知道它、以及它是绝对的还是相对的——尚未完全明了，长期受到哲学界的深刻探讨。不同XAI方法中存在的假设对AI解释的有效性和解释在不同领域的含义具有重要影响。
### Innovation
本文分析了AI解释应用到AI系统时所涉及的本体论和认识论假设，即我们对解释存在的假设以及我们能否获取这些解释知识的假设。研究表明，看似微小的技术改变可能对应着对解释假设的重要差异，并强调了在选择XAI方法时忽视本体论和认识论框架的风险，提出了根据不同应用场景选择和调整合适XAI方法的方法。
### Conclusion
本研究揭示了XAI方法中潜藏的假设对解释的影响，并强调了在选择合适的XAI方法时需要注意本体论和认识论框架的选择和应用。
## 20. `cs.AI` - 认真对待戈德哈特法则：通用人工智能优化的原理性限制 [PDF](https://arxiv.org/pdf/2510.02840), [HTML](https://arxiv.org/abs/2510.02840)
### Authors
Antoine Maier,Aude Maier,Tom David
### Background
在机器学习中，一个常见但很少被审视的假设是训练过程能够产生满足其指定目标函数的模型。这一假设被称为目标满足假设（Objective Satisfaction Assumption, OSA）。尽管人们普遍承认OSA的偏离，但其含义却常常被忽视。本文指出，在学习范式无关的框架下，OSA在现实条件下会失败：近似、估计和优化错误会导致系统系统性偏离目标，这是技术限制的一部分。除此之外，完全捕捉和翻译开发者的意图，比如与人类偏好的齐一性，转化为正式目标是实际中难以实现的，这使得错标不可避免。在缺乏数学对标这些差距的刻画时，在强烈优化压力下，这些差距会直接转化为戈德哈特法则失效的模式。由于戈德哈特失效点无法预先确定，因此对通用人工智能系统的优化需要一个原理性的限制。没有这样的限制，继续优化很可能会使系统进入预可预测且不可逆转的失控行为。
### Innovation
本文创新性地提出了在戈德哈特法则失效点难以预知的情况下，对通用人工智能系统的优化设定了原理性限制。这一假设基于数学结果，指出现实条件下模型的系统性偏差显著，并且在强优化压力下，这些偏差会演变成戈德哈特法则失效的形式。这种研究视角不仅扩展了对机器学习中模型偏差的理解，还为AI系统的优化提供了一种新的方法论。
### Conclusion
本文强调在对通用人工智能进行优化时，需认真对待戈德哈特法则所揭示的问题，并提出不该过度依赖实际训练结果来实现目标。这不仅是因为技术上的局限性，也由于无法完全捕捉开发者的意图。为了避免不可逆转的控制失灵，应该在设计和优化过程中设定严格的数学限制，以应对强烈的优化压力导致的目标转移问题。这种上限设定不仅是对现有假设的挑战，也为未来的研究和实践提供了指导方向。
## 21. `cs.AI` - 超越最终答案：评估增强工具的智能体推理轨迹 [PDF](https://arxiv.org/pdf/2510.02837), [HTML](https://arxiv.org/abs/2510.02837)
### Authors
Wonjoong Kim,Sangwu Park,Yeonjun In,Sein Kim,Dongha Lee,Chanyoung Park
### Background
尽管最近的工具增强基准测试集包含复杂的用户请求和多种工具，大多数的评估方法仍然仅限于答案匹配。然而，随着解决用户请求所需步骤的增加，评估智能体性能的方式必须超越最终答案，还要评估解决问题的过程，包括效率、虚构和适应性等方面的评价。直接将智能体的轨迹与真实轨迹进行比较是最简单的评估方法，但这种做法由于标记所有有效的真轨迹成本过高而受到限制。虽然简单的基于LLM的评估器可以评估轨迹，但没有真实数据时效果较差。
### Innovation
本文引入了TRACE框架，这是一种用于多维度评估工具增强LLM智能体性能的框架。该框架通过引入知识库，将之前推理步骤中收集的知识累积起来，从而能够进行多方面的分析和评估智能体的推理轨迹。为了验证框架的有效性，作者创建了一个新的元评估数据集，通过现有的基准测试增加各种和有缺陷的轨迹，每个轨迹都标记了多维度的性能分数。结果表明，TRACE能够在经济高效且可扩展的方式下准确评估这些复杂行为，即使使用开源的LLM也是如此。此外，作者还应用他们的方法来评估解决工具增强任务时智能体产生的轨迹，揭示了以前未报告的观察及其相应的见解。
### Conclusion
本文提出了一种评估工具增强LLM智能体性能的新框架——TRACE。该框架通过引入知识库有效评估智能体的推理轨迹，并通过一个新创建的元评估数据集验证了其有效性。结果表明，TRACE能够高效且经济地评估复杂行为，即使使用开源的LLM也是如此。通过应用此方法，还揭示了智能体在解决问题中的新观察及其见解。
## 22. `cs.AI` - 通过运动增强的注意交叉模态交互进行压缩视频动作识别的表示学习 [PDF](https://arxiv.org/pdf/2205.03569), [HTML](https://arxiv.org/abs/2205.03569)
### Authors
Bing Li,Jiaxin Chen,Dongming Zhang,Xiuguo Bao,Di Huang
### Background
近年来，压缩视频动作识别因为通过使用稀疏采样的RGB帧和压缩的运动线索（如运动向量和残差）代替原始视频而显著减少了存储和计算成本，因此受到了越来越多的关注。然而，这一任务遭受了粗略且多噪声的动力学特征以及RGB和运动模态之间融合不足的问题。
### Innovation
该论文提出了一种新颖的框架，名为带有运动增强的注意交叉模态交互网络（MEACI-Net）。它采用两流结构，分别为RGB模态和运动模态。特别地，运动流嵌入了多尺度块和去噪模块，以增强表示学习。然后，通过引入选择性运动补全（SMC）和跨模态增强（CMA）模块加强两流之间的交互，其中SMC用时空注意局部运动特征补全RGB模态，而CMA进一步通过选择性特征增强结合两个模态。
### Conclusion
在UCF-101、HMDB-51和Kinetics-400基准上的广泛实验表明MEACI-Net的有效性和效率。
## 23. `cs.AI` - CoDA: 辅助系统以促进合作数据可视化的系统 [PDF](https://arxiv.org/pdf/2510.03194), [HTML](https://arxiv.org/abs/2510.03194)
### Authors
Zichen Chen,Jiefeng Chen,Sercan Ö. Arik,Misha Sra,Tomas Pfister,Jinsung Yoon
### Background
深入的研究已经革新了数据分析，但数据科学家仍然花费大量时间手动制作可视化，突显了从自然语言查询实现稳健自动化的必要性。然而，当前系统在处理包含多个文件和迭代细化的复杂数据集时存在困难。现有的方法，包括简单的单代理或多代理系统，通常简化任务，集中在初始查询解析上，而忽略了数据复杂性、代码错误或最终可视化质量的管理。
### Innovation
本文重新定义了这一挑战为协作多代理问题。我们介绍了CoDA，一种多代理系统，采用专门的语言模型（LLM）代理进行元数据分析、任务规划、代码生成和自我反思。该研究通过元数据聚焦分析绕过token限制，并通过质量驱动的细化确保了系统的鲁棒性。广泛的评估表明CoDA在整体分数上实现了显著提升，相对于竞争性基线的性能提高了41.5%。这项工作证明了数据可视化自动化未来在于整合协作代理工作流程，而不是孤立的代码生成。
### Conclusion
这项工作展示了数据可视化自动化未来在于整合协作代理工作流程，而非孤立的代码生成。CoDA通过多代理系统的具体应用实现了在复杂数据集上的高水平自动化与改进，表现出强大的系统性能和鲁棒性。
## 24. `cs.AI` - 改善协作式实体AI中的合作 [PDF](https://arxiv.org/pdf/2510.03153), [HTML](https://arxiv.org/abs/2510.03153)
### Authors
Hima Jacob Leven Suprabha,Laxmi Nag Laxminarayan Nagesh,Ajith Nair,Alvin Reuben Amal Selvaster,Ayan Khan,Raghuram Damarla,Sanju Hannah Samuel,Sreenithi Saravana Perumal,Titouan Puech,Venkataramireddy Marella,Vishal Sonar,Alessandro Suglia,Oliver Lemon
### Background
大型语言模型（LLMs）集成到多智能体系统中，开辟了与AI代理合作进行协作推理的新可能性。本文探讨了不同的提示方法，并评估了它们在增强智能体的协作行为和决策制定方面的有效性。
### Innovation
我们增强了CoELA框架，这是一个用于构建利用LLMs进行多智能体通信、推理和任务协调的协作实体代理的框架。通过系统实验，我们研究了不同的LLM和提示工程策略，以识别最大化合作性能的最佳组合。此外，我们还整合了语音功能，使智能体间的协作能以无间隙的语言交互进行。
### Conclusion
我们的研究表明，提示优化对提高协作智能体性能的有效性；例如，我们最佳的组合在使用Gemma3运行时，比原CoELA系统提高了22%的效率。此外，语音集成为迭代系统的开发和演示提供了一个更加吸引人的用户界面。
## 25. `cs.AI` - 通过量化对抗性扰动来建模攻击：检测AI生成的文本 [PDF](https://arxiv.org/pdf/2510.02319), [HTML](https://arxiv.org/abs/2510.02319)
### Authors
Lekkala Sai Teja,Annepaka Yadagiri,Sangam Sai Anish,Siva Gopala Krishna Nuthakki,Partha Pakray
### Background
高级大型语言模型（LLMs）的快速发展催生了双重用途问题，急需建立可靠的AI生成文本检测系统。现代检测系统容易受到对抗性攻击的影响，尤其是通过改写技术实施的，这种技术能够绕过统计检测。本文探讨了对抗性鲁棒性问题，首先量化了标准对抗性训练的局限性，然后引入了一种新的、更为健壮的检测框架：扰动不变特征工程（PIFE）。PIFE通过多阶段标准化管道将输入文本转换成标准化形式，然后使用像Levenshtein距离和语义相似度这样的度量标准量化变换的幅度，并直接将这些信号输入到分类器。
### Innovation
本文提出了一种新的检测框架PIFE，通过引入多阶段标准化管道将输入文本转换成标准化形式，使用度量标准量化变换的幅度，并直接将这些信号输入到分类器，显著增强了对抗性鲁棒性。在同级 taxonomy 攻击中的评估显示，相较于传统的对抗性训练模型，PIFE在严格1%的误报率下保持了82.6%的真正阳性率，有效抵御了复杂的语义攻击。
### Conclusion
本文的研究发现，明确定模扰动艺术，而不是仅仅进行训练，是实现对抗性攻击真正鲁棒性的更有前途的途径。PIFE模型在对抗性攻击下的优越性能证明了这一点。
## 26. `cs.AI` - 由领域特定表示调节生成模型实现工作调度的约束自动生成 [PDF](https://arxiv.org/pdf/2510.02679), [HTML](https://arxiv.org/abs/2510.02679)
### Authors
Yu-Zhe Shi,Qiao Xu,Yanjia Li,Mingchen Liu,Huamin Qu,Lecheng Ruan,Qining Wang
### Background
高级计划和调度（APS）系统对于现代制造业不可或缺，它们能够优化资源分配和生产效率，在日益复杂和动态的环境中起到关键作用。尽管已经广泛研究了解决抽象调度问题的算法，但将制造要求转换为正式约束的先决条件仍然需要手动和费时的手动过程。近年来，生成模型，尤其是大规模语言模型（LLMs），显示出从异构制造原材料数据中自动生成约束的潜力，但由于自然语言歧义性、不确定的输出和有限的领域特定知识，它们的直接应用仍面临挑战。因此，本文提出了一个以约束为中心的架构来调节LLMs，实现可靠的自动化约束生成以进行生产调度。该架构通过领域特定表示来组织层次结构空间，并确保精度和可靠性，同时保持灵活性。此外，本文设计并部署了自动化生产场景适应算法，以高效地针对特定的制造配置进行定制。实验结果表明，所提出的方法在平衡LLMs的生成能力和制造系统的可靠性需求方面表现出色，对于约束生成任务的表现显著优于纯基于LLM的方法。
### Innovation
本文提出的约束为中心的架构调节了大规模语言模型（LLMs）以实现制造计划中的自动化约束生成。该架构通过领域特定表示组织层次结构空间，确保精确性与可靠性的同时保持灵活性，并设计了一个自动化生产场景适应算法，以高效地针对特定制造配置进行定制。这种方法成功地平衡了LLMs的生成能力与制造系统的可靠性需求，显著优于基于LLM的纯方法。
### Conclusion
本文提出了一种以约束为中心的设计框架，将领域特定表示应用于生成模型以实现可靠且高效的生产调度自动化约束生成。实验结果验证了该方法的有效性，表明其在生产调度任务中展现了显著的优势。
## 27. `cs.AI` - EntropyLong: 通过预测不确定性实现有效的长上下文训练 [PDF](https://arxiv.org/pdf/2510.02330), [HTML](https://arxiv.org/abs/2510.02330)
### Authors
Junlong Jia,Ziyang Chen,Xing Wu,Chaochen Gao,Zijia Lin,Debing Zhang,Songlin Hu,Binghui Guo
### Background
训练具有长期依赖性的长文本语言模型需要特定的数据构建方法。当前的方法，如通用文本拼接或基于启发式的变体，往往无法保证真实的长期依赖性。
### Innovation
提出了一种名为EntropyLong的新数据构建方法，该方法利用预测不确定性来验证依赖性质量。该方法通过识别文档中的高熵位置，从大量语料库中检索语义相关上下文，并通过评估这些上下文是否能降低预测熵来验证其有效性。这种方法确保每个依赖性代表可测量的信息增益而非虚假的相关性。
### Conclusion
通过将原始文档与这些验证过的上下文补充相结合，构造具有长期依赖性的训练样例。使用FineWebEdu和Cosmopedia生成了一个128K长度序列的数据集，含有效验证的依赖性。基于此数据训练的模型在RULER基准测试中表现出显著的改进，特别是在需要远处信息的任务中。在指令微调后，模型在LongBenchv2上也取得了显著增益，展示了对长上下文的理解增强。广泛的消融研究进一步证明了熵验证对于长上下文训练的必要性和有效性。
## 28. `cs.AI` - AMANDA: 通过代理医学知识增强实现数据高效医学视觉问答 [PDF](https://arxiv.org/pdf/2510.02328), [HTML](https://arxiv.org/abs/2510.02328)
### Authors
Ziqing Wang,Chengsheng Mao,Xiaole Wen,Yuan Luo,Kaize Ding
### Background
医学多模态大型语言模型（Med-MLLMs）在医学视觉问答（Med-VQA）中显示出巨大的潜力。但在低资源环境中，由于缺乏大量标注数据，现有多模态大语言模型的医学推理能力存在瓶颈，导致性能下降。具体来说，这些瓶颈包括对医学图像细节的忽略，以及无法有效整合专门的医学知识。
### Innovation
提出了一个无需训练的代理框架AMANDA，通过大型语言模型代理进行医学知识增强。该框架包括两个方面的知识增强：一是通过从粗到细的问题分解进行医学知识增强，以实现全面诊断；二是通过生物医学知识图谱检索使推理过程得以依托专门的医学知识，从而提高医学知识的集成能力。
### Conclusion
在八个医学视觉问答基准测试中，AMANDA在零样本和少量样本条件下都取得了显著的性能提升。该研究成果为低资源环境下的医学视觉问答提供了有效方法。
## 29. `cs.AI` - Raven's Progressive Matrices 中省略规则的研究 [PDF](https://arxiv.org/pdf/2510.03127), [HTML](https://arxiv.org/abs/2510.03127)
### Authors
Binze Li
### Background
类比推理是人类认知的核心，但仍然是人工智能的基本挑战。Raven's Progressive Matrices (RPM) 是一种评估抽象推理能力的常用基准，通过要求推断潜在的结构性规则来进行推理。尽管视觉和语言模型在 RPM 任务上取得了很大的成功，但其表现是否反映真实的推理能力或依赖于统计捷径仍不清楚。这项研究通过在训练中故意省略某些结构性规则来考察现代AI系统在不完整训练条件下的泛化能力。研究在 Impartial-RAVEN (I-RAVEN) 数据集上评估了序列到序列的变换器模型和视觉架构（如 CoPINet 和 Dual-Contrast 网络）。实验表明，尽管变换器在熟悉的规则上表现出很强的能力，但在面对新的或被省略的规则时，其准确性会急剧下降。此外，标记级准确率与完整答案准确率之间的差距强调了当前方法的基本局限性。这些发现为深度学习模型中的推理机制提供了新的见解，并强调了向稳健的抽象推理迈进的架构需求。
### Innovation
本研究通过在训练中故意省略某些结构性规则，考察现代AI系统在不完整训练条件下的泛化能力。研究在 Impartial-RAVEN (I-RAVEN) 数据集上评估了序列到序列的变换器模型和视觉架构，发现变换器在熟悉的规则上表现出很强的能力，但在面对新的或被省略的规则时，其准确性会急剧下降。这些发现为深度学习模型中的推理机制提供了新的见解。
### Conclusion
尽管变换器在熟悉的规则上表现出很强的能力，但在面对新的或被省略的规则时，其准确性会急剧下降。此外，标记级准确率与完整答案准确率之间的差距强调了当前方法的基本局限性。这些发现为深度学习模型中的推理机制提供了新的见解，并强调了向稳健的抽象推理迈进的架构需求。
## 30. `cs.AI` - 使用CASAL减少幻觉：对比激活引导的概算学习 [PDF](https://arxiv.org/pdf/2510.02324), [HTML](https://arxiv.org/abs/2510.02324)
### Authors
Wannan Yang,Xinchi Qiu,Lei Yu,Yuchen Zhang,Oliver Aobo Yang,Narine Kokhlikyan,Nicola Cancedda,Diego Garcia-Olano
### Background
大型语言模型(LLMs)展示出了强大的能力，但它们经常出现幻觉现象，即自信地提供错误的答案而不是承认自己的无知。先前的研究表明模型内部存储了其知识的线性表示，且通过激活引导可以减少幻觉。然而，这些方法需要实时监控与干预才能生效。因此，介绍一种结合可解释性与概算优化的高效算法_Contrastive Activation Steering for Amortized Learning (CASAL)。
### Innovation
CASAL将激活引导的好处直接融入模型的权重中。这种算法只需要训练单个Transformer层的子模块，却能减少30%-40%的幻觉，且计算效率提高了30倍，数据效率提高了20倍，比基于LoRA的SFT和DPO等强基线更适用数据稀缺的领域。CASAL灵活的特性使得它能够减轻文本和视觉-语言模型中的幻觉，且是首次证明对于密集模型和Mixture-of-Experts (MoE)模型都是有效的引导训练方法
### Conclusion
CASAL为将启发式解释方法应用于生产系统提供了有希望的发展方向。
## 31. `cs.AI` - 协同进化的连续离散扩散：让你的扩散语言模型成为一个潜推理器 [PDF](https://arxiv.org/pdf/2510.03206), [HTML](https://arxiv.org/abs/2510.03206)
### Authors
Cai Zhou,Chenxiao Yang,Yi Hu,Chenyu Wang,Chubin Zhang,Muhan Zhang,Lester Mackey,Tommi Jaakkola,Stephen Bates,Dinghuai Zhang
### Background
最近扩散语言模型，尤其是掩码离散扩散模型取得了很大的成功。尽管有些理论和初步的实验证据表明，具有闭环变压器或连续的链式思考的隐化推理具有优势，但连续扩散模型通常在性能上不如其离散的对应物。论文认为扩散语言模型不一定需要在离散空间中，证明了连续扩散模型相较于离散扩散模型和闭环变压器有更强的表达能力。认为理论上的表达能力和实际表现之间的矛盾来源于其实际可训练性问题：虽然连续扩散可以提供闭环变压器缺乏的中介监督，但是这种模型面对从连续表示空间解码到离散令牌空间时存在额外难度。
### Innovation
提出了采用统一连续表示空间和离散令牌空间的联合多模态扩散过程的协同进化连续离散扩散（CCDD）模型。该模型利用单一模型在同一空间同时去噪。通过结合两种模态，CCDD 在潜在空间中有丰富的语义表示，在连续表示空间和离散令牌空间中的样本质量与可训练性方面表现出色。针对CCDD提出了有效的架构和先进的训练/采样技术，通过广泛的现实任务中语言模型实验验证了其强大的实际表现。
### Conclusion
CCDD不仅能够在潜在空间中提供丰富的语义信息，而且通过使用显式离散令牌具有更好的训练稳定性和样本质量，使扩散语言模型在实际应用中更加灵活和高效。通过这种方法，扩散语言模型能够成为有效的潜推理器。
## 32. `cs.AI` - Multiplicative-Additive Constrained Models:向联合可视化交互和独立效应方向努力 [PDF](https://arxiv.org/pdf/2509.21923), [HTML](https://arxiv.org/abs/2509.21923)
### Authors
Fumin Wang
### Background
在高风险领域如医疗保健中应用机器学习时，可解释性是一个重要考虑因素，因为它涉及生命安全。广义可加模型（GAMs）通过可视化形状函数提高了可解释性。然而，为了保持可解释性，GAMs放弃了除了两元交互之外的高级交互效应，这对预测性能提出了显著限制。研究者发现曲线遍历集回归（CESR），一种乘法模型，既能可视化其形状函数，又能同时考虑到所有特征的交互和个体特征效应，但CESR在性能上未能优于GAMs。因此，研究者提出了乘法-加法约束模型（MACMs），在CESR的基础上添加加法部分以解开交互和独立项的混合系数，从而有效地扩大了假设空间。MACMs的形状函数都可以自然地可视化，帮助用户理解特征如何参与决策过程。实验结果表明，基于神经网络的MACMs在预测性能上显著优于CESR和当前最先进的GAMs。
### Innovation
提出了乘法-加法约束模型（MACMs），结合了CESR的可解释性和泛化性能。MACMs在CESR的基础上引入了加法部分，以分离交互和独立项的系数，从而扩展了假设空间，使其既能自动生成形状函数的可视化，又能在预测性能上超越传统模型如GAMs和CESR。
### Conclusion
实验结果证实了MACMs在预测性能上的优越性，其结合了可解释性和良好的预测能力，适合应用于高风险领域以获取更高的决策可信度。
## 33. `cs.AI` - SelfJudge：通过自我监督裁判验证实现更快的推测性解码 [PDF](https://arxiv.org/pdf/2510.02329), [HTML](https://arxiv.org/abs/2510.02329)
### Authors
Kanghoon Yoon,Minsub Kim,Sungjae Lee,Joonhyung Lee,Sunghyeon Woo,Yeonjun In,Se Jung Kwon,Chanyoung Park,Dongsoo Lee
### Background
现存的推测性解码算法通过候选模型和目标模型之间的验证来加速大规模语言模型（LLM）的推断，但这种方法受到对人类注释或具有可验证真实标准的任务的依赖限制，从而限制了其在多种NLP任务中的普适性。现有的方法在灵活性和泛化能力上有所欠缺，特别是在处理没有明确人工注释或可验证标准的NLP任务时显得不够适用。
### Innovation
SelfJudge通过自我监督机制训练裁判验证器，这种方法评估逐词替换响应的语义保留情况，从而在不依赖人工注释或可验证标准的情况下，实现对多样化NLP任务的自动验证训练。这种方法提高了推测性解码在准确性和推断速度之间的权衡，提供了一个适用于更广泛NLP任务的快速推断解决方案。
### Conclusion
实验结果表明，SelfJudge相比现有的裁判解码基准，能实现更优的准确性和推断速度之间的权衡，为大语言模型的快速推断提供了一种具有普适性的解决方案。
## 34. `cs.AI` - Agentic-AI Healthcare: 多语言，保护隐私的框架，带有MCP代理 [PDF](https://arxiv.org/pdf/2510.02325), [HTML](https://arxiv.org/abs/2510.02325)
### Authors
Mohammed A. Shehab
### Background
该论文介绍了一种名为Agentic-AI Healthcare的研究原型，这个系统在一个研究者的项目中开发，具有隐私保护、多语言和解释性等特点。系统利用新兴的模型上下文协议（MCP）协调多个智能代理进行患者互动，包括症状检查、药物建议和预约安排等功能。该平台包含一个专用的隐私和合规层，采用基于角色的访问控制（RBAC）、AES-GCM字段级加密和防篡改审计日志等技术，符合HIPAA（美国）、PIPEDA（加拿大）和PHIPA（安大略省）等主要的健康数据保护标准。研究中提供了多语言患者-医生互动（英语、法语、阿拉伯语）和由大规模语言模型驱动的透明诊断推理示例。
### Innovation
这项工作强调了在医疗应用中结合智能代理编排、多语言可访问性和遵守标准架构的可行性。具体创新包括：1) 使用MCP协议协调多智能代理；2) 集成了保护隐私和合规的多层次安全技术，如基于角色的访问控制和防篡改审计日志；3) 支援多语言的患者-医生互动和透明的诊断推理处理能力，使用大规模语言模型提供支持。
### Conclusion
该平台被描述为一个研究原型而非认证的医疗器械，展示了在医疗保健应用中隐私第一、多语言双向互动和遵守法律法规的技术方向，并强调了这一领域的研究潜力和可行性。
## 35. `cs.AI` - 合成对话生成用于互动对话式提取与推荐（ICER） [PDF](https://arxiv.org/pdf/2510.02331), [HTML](https://arxiv.org/abs/2510.02331)
### Authors
Moonkyung Ryu,Chih-Wei Hsu,Yinlam Chow,Mohammad Ghavamzadeh,Craig Boutilier
### Background
语言模型（LMs）在对话式推荐系统（CRSs）中具有巨大潜力，但由于缺乏公开的CRS数据，将LMs微调用于CRSs变得具有挑战性。虽然可以使用LM作为用户模拟器来生成数据以训练基于LM的CRSs，但这些模拟器通常缺乏行为一致性，生成的对话序列与真实用户不符。
### Innovation
开发了一种生成与用户潜在状态一致自然对话的方法，结合了行为模拟器和LM提示。通过这种方法生成了一个大量开放源代码CRS数据集，包括偏好提取和示例批评。部分对话的评判结果显示，在一致性、事实性和自然性方面表现出色。
### Conclusion
该研究通过合成对话生成，解决了数据不足的问题，提高了CRSs的训练效果，展示了其在实际应用中的潜力。
## 36. `cs.AI` - KAME: Tandem Architecture for Enhancing Knowledge in Real-Time Speech-to-Speech Conversational AI [PDF](https://arxiv.org/pdf/2510.02327), [HTML](https://arxiv.org/abs/2510.02327)
### Authors
So Kuroki,Yotaro Kubo,Takuya Akiba,Yujin Tang
### Background
实时语音到语音（S2S）模型擅长生成自然且低延迟的对话响应，但通常缺乏深度知识和语义理解。相比之下，结合自动语音识别、文本基础的大语言模型（LLM）和文本到语音合成的级联系统虽然能提供 superior 的知识表示，但会增加显著的延迟，破坏自然交互的流畅性。本研究旨在弥合这两种架构之间的差距，提出了一种新的混合架构，通过实时处理用户语音并同时将查询传递给强大的后端LLM，不仅优化了即时响应能力，还能实时注入LLM的文本响应指导S2S模型的语音生成，因此实现了丰富的知识注入而无需级联系统带来的全部延迟代价。研究使用带有多轮问答会话的MT-Bench基准的语音合成变体进行评估，结果显示该系统在响应准确性上显著优于基线S2S模型，接近级联系统的表现，同时保持与基线相同的延迟水平。
### Innovation
该论文提出了一种新颖的混合架构，称为KAME，它利用S2S模型的实时响应能力同时结合大语言模型的丰富知识生成能力。具体而言，KAME架构通过S2S变压器实时处理用户的语音，并将查询同时传递给强大的后端LLM，实现实时注入LLM的文本响应，进而指导S2S模型的语音生成，有效地将知识注入输出，同时保持较低的延迟，从而弥合了实时S2S模型和级联系统的性能差距。
### Conclusion
通过对比评估和实验结果，本文提出的KAME系统在准确性方面显著优于单一的实时S2S模型，甚至在某些指标上接近其级联系统的水平，同时保持了与基线模型相当的响应延迟。这项工作为构建更高效、富有知识的实时对话系统提供了一种新的有效方法。
## 37. `cs.AI` - 基于索赔奖励优化长篇临床文本生成 [PDF](https://arxiv.org/pdf/2510.02338), [HTML](https://arxiv.org/abs/2510.02338)
### Authors
Samyak Jhaveri,Praphul Singh,Jangwon Kim,Tara Taghavi,Krishnaram Kenthapadi
### Background
自动化临床记录需要精准地与完整性和事实根基等优先事项对齐。本文提出了一个评估集成强化学习框架，用于长形式临床文本生成，结合了Group Relative Policy Optimization (GRPO)与DocLens，一个以索赔级别为评估标准并提供确定性、对话基础奖励的评估器。
### Innovation
该方法直接优化事实根基和完整性，无需训练独立的奖励模型或依赖人类撰写的参考文献。通过简单的奖励门控策略，这种方法提高了临床记录的质量并降低了训练成本。独立的GPT-5定性评估进一步支持了这些优势，显示GRPO输出在真实性、完整性和简洁性方面表现更好，且有较少的遗漏和虚构。
### Conclusion
由于基准相对较清洁，基模已较好对齐，因此这些改善很可能代表保守的下限。该框架可以在实际应用场景中扩展，并可集成定制目标，如指南合规或收费偏好。
## 38. `cs.AI` - CRACQ: 多维度的自动化文档评估方法 [PDF](https://arxiv.org/pdf/2510.02337), [HTML](https://arxiv.org/abs/2510.02337)
### Authors
Ishak Soltani,Francisco Belo,Bernardo Tavares
### Background
当前对于文档的评估主要集中在基于特征的自动作文评分（Automated Essay Scoring, AES）技术上，这类技术主要应用于文章形式的机器生成文本。然而，这些评估方法主要集中于单一特性或者特定类型文档，无法全面覆盖多样化的文本形式，尤其是与特定应用场景（如资助提案）相关的特性。因此，提出了一种名为CRACQ的多维度评估框架，旨在更全面地评价文档在网络、结构和内容等不同维度上的表现。
### Innovation
CRACQ是一种独立于文档形式的多维度评价框架，它可以分析包括语义、语体和结构在内的多种信号，并进行累积评估。这是通过集成不同的信号来提供一个更为全面的特质层面和整体层面的分析方法。与基于单一得分的方法不同，CRACQ评估方法经过500份合成资助提案的训练，并与其他人工智能（如LLM）评估方法进行了基准测试，显示出更加稳定和可解释的特质评估结果。
### Conclusion
尽管CRACQ的初步结果表明其能在特质水平上提供比直接LLM评估更为稳定和可解释的结果，但在可靠性及适用范围方面仍存在挑战。这一框架为不同形式和领域的文档提供了更为广泛的自动化评估手段，未来研究需要解决这些挑战以提高其应用范围和效果。
## 39. `cs.AI` - 具有自我评估和向量导向检索的抗幻觉领域特定研究助手 [PDF](https://arxiv.org/pdf/2510.02326), [HTML](https://arxiv.org/abs/2510.02326)
### Authors
Vivek Bhavsar,Joseph Ereifej,Aravanan Gurusami
### Background
大型语言模型在加速文献综合方面表现出色，但仍可能产生幻觉和错误引用，限制了其在专家工作流程中的应用价值。
### Innovation
提出了一种模块化的基于GPT的研究助手RA-FSM，该助手采用了有限状态机（FSM）策略，通过Relevance（相关性）、Confidence（置信度）和Knowledge（知识）三个阶段进行控制。系统基于向量检索和确定性的参考文献管道，能够过滤无关查询、评估答案可答性并仅在必要时触发检索，生成带有置信度标签和去重参考文献的答案。该系统首先通过按等级筛选的摄入流程构建了领域知识库，从期刊、会议论文、索引、预印本和专利中获取信息，并写入密集向量索引和关系库中。它被用于光子学领域并在六个任务类别（分析推理、数值分析、方法论批判、综合比较、事实提取和应用设计）进行了评估。
### Conclusion
领域专家在盲测中更偏好RA-FSM，认为其在边界条件处理和证据使用上更为可靠。与强大的笔记本语言模型和单次调用的基础版GPT API相比，RA-FSM的覆盖率和新颖性分析显示能够探索更多内容，同时具有可调的延迟和成本开销。该设计强调透明且引文充分的答案，适用于高风险的技术工作，并且具有应用于其他科学领域的通用性。
## 40. `cs.AI` - 带有上下文和社会维度的人类移动数据集 [PDF](https://arxiv.org/pdf/2510.02333), [HTML](https://arxiv.org/abs/2510.02333)
### Authors
Chiara Pugliese,Francesco Lettich,Guido Rocchietti,Chiara Renso,Fabio Pinelli
### Background
本文档介绍了一种资源文件，该文件提供了两个以语义丰富的人类轨迹为重点的公开可用数据集，以及构建它们的管道。这些轨迹数据来源于OpenStreetMap上的公共GPS踪迹，并包括上下文层次结构，如停留点、移动、兴趣点（POIs）、推断的交通模式以及天气数据。这些数据集涵盖巴黎和纽约两个结构不同的大型城市，并以表格和资源描述框架（RDF）格式提供，支持语义推理和FAIR数据实践。文章指出这些数据集是为支持行为建模、移动预测、知识图谱构建等研究任务而设计的。
### Innovation
这篇论文的创新之处在于，首次将现实世界的移动行为、结构化的语义丰富、由大型语言模型（LLMs）生成的文本，以及语义网络兼容性整合到一个可重用的框架中，实现了跨模态和语义的移动分析。另一项独特的创新点是，在数据集中加入了由LLMs生成的合成、现实主义社会媒体帖子，这使数据处理更加贴近真实场景，提高了数据集的实用性和多样性。
### Conclusion
本文档提供的资源是第一个结合了真实世界的移动性数据、结构化的语义增强、LLMs生成的文本以及与语义网兼容性的可重用框架。该资源集涵盖了两个不同结构的大型城市：巴黎和纽约，支持多种研究任务，包括但不限于行为建模、移动预测、知识图谱构建，以及基于LLMs的应用开发。这一创新性数据集为移动分析领域带来了新的研究潜力和应用机会。
## 41. `cs.AI` - 错误根源何在？基于表示梯度追踪归因不良大语言模型行为 [PDF](https://arxiv.org/pdf/2510.02334), [HTML](https://arxiv.org/abs/2510.02334)
### Authors
Zhe Li,Wei Zhao,Yige Li,Jun Sun
### Background
大规模语言模型（LLMs）展现出显著的能力，但其部署常因产生有害内容、事实不准确和社会偏见等不良行为受到阻碍。诊断这些失败的根本原因是对AI安全构成的关键挑战。现有归因方法，尤其是基于参数梯度的方法，常常因为噪音信号和计算复杂度过高而失效。
### Innovation
本文引入了一种新颖而高效的框架，通过分析表示及其梯度来诊断一系列不良的LLM行为，该框架直接在模型的激活空间中工作，提供将输出与其训练数据联系起来的语义上具有意义的信号。该方法系统评估了包括追踪有害内容、检测后门污染和识别知识污染等方面的任务。结果显示，该方法不仅在样本级归因方面表现出色，还实现了精细化的标记级分析，精确识别出对模型行为有因果影响的具体样本和短语。这项工作提供了一个强大的诊断工具，用于理解、审计并最终缓解与LLMs相关的风险。
### Conclusion
本工作提供了一种强大的诊断工具，用于理解、审计并最终缓解与LLMs相关的风险。该方法不仅在样本级归因方面表现出色，还实现了精细化的标记级分析，准确地识别出特定的样本和短语，对其行为有因果影响。
## 42. `cs.AI` - 评估论证型大型语言模型中的不确定性量化方法 [PDF](https://arxiv.org/pdf/2510.02339), [HTML](https://arxiv.org/abs/2510.02339)
### Authors
Kevin Zhou,Adam Dejl,Gabriel Freedman,Lihu Chen,Antonio Rago,Francesca Toni
### Background
随着大型语言模型（LLMs）作为先进技术的核心地位日益重要，不确定性量化（UQ）的研究愈发关键。这关乎确保LLMs的可靠性。我们聚焦于将LLM UQ方法应用于论证型LLMs（ArgLLMs），这是一种基于计算论证的可解释LLM框架。UQ方法在ArgLLMs的决策过程中扮演了至关重要角色。
### Innovation
本文研究的创新之处在于探索了在论证型大型语言模型中整合UQ方法的途径，并对不同UQ方法在论证实务中的效果进行了首次实验性评估。特别地，提出了一种新颖的评估UQ方法有效性的方法，当面对复杂的、可能引发争议的陈述时尤为有用。
### Conclusion
实验结果显示，尽管直接提示方法非常简单，但在论证型大型语言模型中同样能有效进行UQ，显著优于更复杂的方法。这表明直接提示方法是一种值得在解释型LLM中采用的UQ策略。
## 43. `cs.AI` - FormalML：评估机器学习理论形式子目标完成的基准 [PDF](https://arxiv.org/pdf/2510.02335), [HTML](https://arxiv.org/abs/2510.02335)
### Authors
Xiao-Wen Yang,Zihao Zhang,Jianuo Cao,Zhi Zhou,Zenan Li,Lan-Zhe Guo,Yuan Yao,Taolue Chen,Yu-Feng Li,Xiaoxing Ma
### Background
大型语言模型（LLMs）在形式定理证明方面取得了显著进展，但它们作为数学家的实用助手，填补复杂证明中未完成步骤的能力尚未得到充分研究。本研究将这一挑战定义为子目标完成任务，即LLM需要在人类提供的草图中处理被遗留的简短但复杂的证明义务。为此，作者引入了FormalML基准，该基准基于机器学习的基础理论构建。通过将过程性证明转换为声明性形式，作者提取了涵盖优化和概率不等式的4937个问题，具有不同难度级别。FormalML是第一个结合前提检索和研究级复杂背景的子目标完成基准，其能够全面评估现有的最先进证明系统的准确性和效率局限性，强调需要更加强大的基于LLM的证明系统来有效完成子目标。
### Innovation
构建了名为FormalML的基准测试，它是第一个结合前提检索和复杂研究级背景的子目标完成基准，使用Lean 4构建并提供了一种翻译技术，将过程性证明转换为声明性形式，涵盖4937个问题。作者使用这种方法来全面评估最先进的证明系统的准确性和效率，并发现现有系统存在的局限性，推动了更有效的基于LLM的证明系统的需求。
### Conclusion
评估结果显示，当前最先进的证明系统在准确性和效率方面存在局限性，强调了需要开发更加强大的基于LLM的证明系统，以有效完成数学证明中的子目标。
## 44. `cs.AI` - KurdSTS: Kurdish Semantic Textual Similarity [PDF](https://arxiv.org/pdf/2510.02336), [HTML](https://arxiv.org/abs/2510.02336)
### Authors
Abdulhady Abas Abdullah,Hadi Veisi,Hussein M. Al
### Background
语义文本相似性(STS)评估了两段文本之间的含义重叠程度，并支持许多NLP任务。虽然资源丰富语言（如高级资源语言）已经有大量的数据集，但像库尔德语这样的低资源语言却很少有人或数据集支持其研究。库尔德语因其形态学特征、拼写变体和语言混杂等原因，在进行STS任务时面临挑战。
### Innovation
本文提出了首个库尔德语的STS数据集，包含10,000对涵盖正式和非正式语体的句子，每对句子都进行了相似性标注。它对比了Sentence-BERT、多语言BERT及其他强基线模型，展示了这些模型在库尔德语STS任务中的性能，同时也指出了模型在处理库尔德语形态学特征、拼写变体和语言混杂时面临的挑战。该数据集和基线模型为库尔德语语义分析和低资源NLP的研究提供了可重复的评估工具，并为未来的研究打下了基础。
### Conclusion
本文的数据集和基线模型建立了可重复的评估框架，并为未来研究库尔德语语义和低资源NLP提供了强有力的起点。
## 45. `cs.AI` - DRIFT: 利用真实世界中丰富的用户不满意信号进行偏好学习 [PDF](https://arxiv.org/pdf/2510.02341), [HTML](https://arxiv.org/abs/2510.02341)
### Authors
Yifan Wang,Bolian Li,Junlin Wu,Zhaoxuan Tan,Zheli Liu,Ruqi Zhang,Ananth Grama,Qingkai Zeng
### Background
在实际应用中，大规模语言模型（如会话AI系统、代码生成助手）会自然地生成大量的隐性用户不满意信号（DSAT），用户通过反复修正、纠正和表达偏好来达到更好的答案，但显性的满意度（SAT）反馈则很少见。现有的偏好学习方法与这种数据特征不匹配，因为它们依赖昂贵的人工注释或假设有足够的正面反馈。
### Innovation
本文介绍了DRIFT（Dissatisfaction-Refined Iterative Preference Training），它基于真实世界的DSAT信号进行训练，并且动态地从不断演变的策略中采样积极的信号。实验证明，DRIFT在WildFeedback和UltraFeedback数据集上训练的模型，在WildBench任务得分和AlpacaEval2胜率上分别比基础模型提高了6.23%至7.61%（7B模型）和8.95%至12.29%（14B模型），超越了强有力的基线方法如迭代DPO和SPIN。此外，DRIFT在更大的规模表现出显著的改进，14B模型训练后在WildBench上超过了GPT-4o-mini。进一步分析显示DRIFT保留了探索能力，能产出更多样化的高回报解决方案而不是局限于狭窄的类别。理论证明该设计保留了偏好边际并避免了梯度退化。
### Conclusion
这些结果表明，DRIFT是一个有效且可扩展的后训练配方，充分利用了最丰富和信息量最大的信号。代码和数据可在以下网址获得。
## 46. `cs.AI` - 非对比自监督学习方法在网络入侵检测中的性能研究 [PDF](https://arxiv.org/pdf/2510.02349), [HTML](https://arxiv.org/abs/2510.02349)
### Authors
Hamed Fard,Tobias Schalau,Gerhard Wunder
### Background
在网络入侵检测这一网络安全领域的研究中，过去二十多年来主要依赖监督学习算法。然而，这些算法只能检测已知异常，因此促使研究者探索替代方法。受到了计算机视觉领域中自监督学习成功的启发，越来越多的研究者开始探索将该范式应用于网络入侵检测。尽管先前研究主要关注对比自监督方法，但非对比自监督方法结合编码器架构（作为表征学习的基础）和确定学习内容的数据增强策略的有效性，对于有效检测攻击尚不清楚。
### Innovation
本研究对比了五种非对比自监督学习方法在三种编码器架构和六种数据增强策略下的性能。系统性地在两个网络入侵检测数据集（UNSW-NB15和5G-NIDD）上进行了九十次实验，探讨了编码器架构和数据增强策略的最佳组合，以及非对比自监督方法在攻击检测中的竞争力。
### Conclusion
在对比最佳模型与两个无监督基线（DeepSVDD和自编码器）的性能结果后，展示了非对比自监督方法在攻击检测中的竞争力。
## 47. `cs.AI` - mini-vec2vec：利用线性变换扩展通用几何对齐的规模 [PDF](https://arxiv.org/pdf/2510.02348), [HTML](https://arxiv.org/abs/2510.02348)
### Authors
Guy Dar
### Background
我们基于vec2vec构建，vec2vec是一个设计用于在没有平行数据的情况下对齐文本嵌入空间的程序。虽然vec2vec的对齐效果接近完美，但其计算成本高且不稳定。mini-vec2vec是一种简单且高效的替代方案，计算成本大幅降低，并且高度稳定。mini-vec2vec的方法由三个主要阶段组成：伪平行嵌入向量的临时匹配、变换拟合和迭代细化。
### Innovation
mini-vec2vec的主要创新在于它是一种线性的替代方案，与原始的vec2vec相比，在效率上提高了数量级，同时匹配或超过了vec2vec的结果。此外，mini-vec2vec的算法稳定且具有可解释性，这使其更容易扩展并在新领域和领域中获得应用。
### Conclusion
mini-vec2vec 利用线性变换，不仅提高了对齐任务的效率，还保持了与原始vec2vec相当或更好的结果，同时提供了更高的算法稳定性和可解释性，为在新领域和领域的应用打开了新的机会。
## 48. `cs.AI` - LLMSQL：为LLM时代升级的Text-to-SQL基准 [PDF](https://arxiv.org/pdf/2510.02350), [HTML](https://arxiv.org/abs/2510.02350)
### Authors
Dzmitry Pihulski,Karol Charchut,Viktoria Novogrodskaia,Jan Kocoń
### Background
自然语言到SQL查询（Text-to-SQL）转换使非专业用户能够与关系数据库交互，并长期以来一直是数据自然语言接口的核心任务。尽管WikiSQL数据集在早期的Text-to-SQL研究中起到了关键作用，但由于结构和注释问题（包括大小写不一致、数据类型不匹配、语法错误和未解答的问题），其使用有所下降。因此，需要对WikiSQL进行系统性修正和转换，以适应LLM时代。
### Innovation
LLMSQL是对WikiSQL的数据集进行了系统性修订和转换，特别为LLM时代设计。它包括对错误进行分类，并实现自动方法进行清洗和重新注释。评估了多个大型语言模型（LLMs），展示了这些改进的影响。LLMSQL不仅作为一个更新出现，而是作为适用于现代自然语言到SQL模型生成和评估的LLM就绪基准引入，不同于原版的WikiSQL更适合指针网络模型从输入中选择标记。
### Conclusion
LLMSQL通过提供干净的自然语言问题和完整的SQL查询作为纯文本，使现代自然语言到SQL模型的生成和评估变得简单直接，旨在成为适用于LLM时代的Text-to-SQL基准。
## 49. `cs.AI` - 基于小型语言模型的课程指导 [PDF](https://arxiv.org/pdf/2510.02347), [HTML](https://arxiv.org/abs/2510.02347)
### Authors
Konstantinos Katharakis,Sippo Rossi,Raghava Rao Mukkamala
### Background
在教育领域，生成式AI和大型语言模型（LLMs）的应用正处于起步阶段。本文研究了使用检索增强生成（RAG）流水线和选定的开源小语言模型（SLMs）开发和评估课程指导型AI教学助手的方法。通过对包括LLaMA 3.1、IBM Granite 3.3和Gemma 3等八个SLMs与GPT-4o进行基准测试，发现通过适当的提示和目标检索，SLMs能够提供与LLMs同样准确且符合教育理念的响应。
### Innovation
研究采用小语言模型（SLMs）并将其与大型语言模型（LLMs）进行对比测试，以证明在适当的提示和目标检索下，SLMs能够提供高度准确且符合教育标准的响应。更重要的是，SLMs具有较低的计算和能源消耗需求，因此能够在消费者级硬件上实现实时使用，无需依赖云基础设施。这使得SLMs不仅具备成本效益和保护隐私的优势，还能减少碳足迹，成为教育机构实施个性化学习的重要可持续和节能选项。
### Conclusion
研究结果表明，通过适当提示和目标检索，小语言模型能够与大型语言模型在提供准确和符合教育目标的响应方面表现出色，并且由于其较低的计算和能源需求，使得它们在成本、隐私和环境方面更具优势，为教育机构大规模实施个性化学习提供了可行的解决方案。
## 50. `cs.AI` - AI时代的隐私：数据风险分类 [PDF](https://arxiv.org/pdf/2510.02357), [HTML](https://arxiv.org/abs/2510.02357)
### Authors
Grace Billiris,Asif Gill,Madhushi Bandara
### Background
随着AI系统处理越来越多的敏感数据，传统隐私框架因其独特的自主学习和黑盒决策特点而难以应对新的隐私挑战。
### Innovation
本文通过系统回顾识别出45项研究，提出了一种分类AI隐私风险的分类法，识别出了19个关键风险并分为四个类别：数据集级别，模型级别，基础设施级别，内部威胁风险。这项分类法挑战了传统安全方法，强调技术和行为维度之间的差距，有助于促进可信赖的AI发展。
### Conclusion
本文通过二阶分析AI隐私的科学框架，填补了现有研究在综合理解技术与行为之间的差距这一方面的空白，并为未来研究奠定了基础。
## 51. `cs.AI` - CATMark: 一种用于大型语言模型跨任务鲁棒水印的上下文感知阈值框架 [PDF](https://arxiv.org/pdf/2510.02342), [HTML](https://arxiv.org/abs/2510.02342)
### Authors
Yu Zhang,Shuliang Liu,Xu Yang,Xuming Hu
### Background
现有的水印算法通过嵌入和检测文本中的隐藏统计特征来有效识别机器生成的内容。然而，这种嵌入会导致文本质量下降，特别是在低熵场景下性能需要改进时。现有方法依赖于熵阈值，通常需要大量的计算资源进行调优，并且在面对未知或跨任务生成场景时表现出色度较差。现有的方法往往依赖于预先定义的阈值或特定任务的调优，这限制了其适应性和鲁棒性。因此，提高水印算法的文本质量和适应不同任务场景的能力是一个重要的研究目标和挑战。
### Innovation
本文提出了一个名为$text{C}ontext-text{A}ware text{T}hreshold text{W}atermarking (text{CAT})$（Context-Aware Threshold for Watermarking）的新型框架，用于动态调整基于实时语义上下文的水印强度。该框架通过logits聚类将文本生成划分为语义状态，建立上下文感知的熵阈值，这样可以同时保持结构内容的保真度并嵌入鲁棒水印。与现有方法相比，$text{CAT}$框架无需预先定义的阈值或特定任务的调优，从而提供了更好的适应性和鲁棒性。实验证明，$text{CAT}$框架在跨任务场景中提高了文本质量，同时保持了检测准确性。
### Conclusion
本文提出的Context-Aware Threshold watermarking ($text{CAT}$)框架通过实时上下文调整水印强度，提高了大型语言模型中水印算法在跨任务场景中的文本质量和鲁棒性。通过实验验证，$text{CAT}$算法在不同任务场景下能够保持高质量文本输出和准确的水印检测能力。
## 52. `cs.AI` - 一种高容量和安全的神经语言隐写消歧算法 [PDF](https://arxiv.org/pdf/2510.02332), [HTML](https://arxiv.org/abs/2510.02332)
### Authors
Yapei Feng,Feng Jiang,Shanhao Wu,Hua Zhong
### Background
神经语言隐写旨在将信息嵌入自然文本中，同时保持统计上的不可检测性。这一领域的基本挑战源于现代分割器在分词时存在的歧义性，这可能导致灾难性的解码失败。近年来，SyncPool方法通过在一组歧义候选词上使用粗略的同步机制来解决这一问题。然而，SyncPool牺牲了嵌入容量，因为它仅利用了歧义组的全部香农熵进行同步，而不是用于信息嵌入。
### Innovation
本文提出了一种名为look-ahead Sync的方法，该方法在保持SyncPool提供的安全保证的情况下，克服了其容量限制。look-ahead Sync仅在真正无法区分的标记序列上进行最小的同步采样，同时战略性地保留所有其他可区分的路径，以最大化嵌入容量。提供理论证明支持该方法的安全性，并分析其实现的嵌入容量与理论上限之间的差距。实验表明，该方法在英语（使用Llama 3）和中文（使用Qwen 2.5）基准上，一致地接近理论容量上限，并且在嵌入率方面显著优于SyncPool，特别是在候选池较大的情况下。
### Conclusion
总体而言，这一工作代表了向实用的高容量并且可验证安全的语言隐写技术迈出的重要一步。
## 53. `cs.AI` - 评估面向实际决策和推荐的语音对话大语言模型中的偏见 [PDF](https://arxiv.org/pdf/2510.02352), [HTML](https://arxiv.org/abs/2510.02352)
### Authors
Yihao Wu,Tianrui Wang,Yizhou Peng,Yi-Wen Chao,Xuyi Zhuang,Xinsheng Wang,Shunshun Yin,Ziyang Ma
### Background
虽然大型语言模型（LLMs）中的偏见，如输出中的刻板印象和文化倾向已被研究和识别，但带有音频输入和输出的口语对话模型（SDMs）中的偏见和特征则鲜有研究。副语言特征，比如年龄、性别和口音，会影响模型输出；在多轮对话中，这些影响可能会加剧偏见，这对决策和推荐任务的公平性有潜在的影响。
### Innovation
本研究系统性地评估了语音LLMs中的偏见，并研究了多轮对话中重复负面反馈的影响。使用Group Unfairness Score (GUS)进行决策偏见衡量，使用similarity-based normalized statistics rate (SNSR)进行推荐任务的偏见衡量。结果发现，商用模型普遍表现出更低的偏见，而开源模型对年龄和性别更为敏感，推荐任务更会放大跨群体差异。本研究首次系统研究了端到端语音对话模型中的偏见，为公平可靠的声音交互系统提供了见解。
### Conclusion
本研究提供了首个面向端到端语音对话模型的系统性研究，探讨了决策和推荐任务中的偏见。研究还发布了FairDialogue数据集和评估代码，以促进进一步研究，并为确保基于音频的交互系统公平可靠提供了方向。
## 54. `cs.AI` - Emission-GPT：一种针对排放目录和数据分析的知识检索领域特定语言模型代理 [PDF](https://arxiv.org/pdf/2510.02359), [HTML](https://arxiv.org/abs/2510.02359)
### Authors
Jiashu Ye,Tong Wu,Weiwen Chen,Hao Zhang,Zeteng Lin,Xingxing Li,Shujuan Weng,Manni Zhu,Xin Yuan,Xinlong Hong,Jingjie Li,Junyu Zheng,Zhijiong Huang,Jing Tang
### Background
改善空气质量并应对气候变化需要对空气污染物和温室气体排放有准确的理解和分析。然而，排放相关的知识往往是碎片化的且高度专业化，现有的访问和整合排放数据的方法仍不够高效。这些问题限制了非专家理解和解释排放信息的能力，给研究和管理带来挑战。
### Innovation
我们提出了Emission-GPT，一个基于多元知识库（包含超过10,000份文件）的定制化语言模型代理，专注于大气排放领域。Emission-GPT利用提示工程和问题完成来支持精准的专业领域问题回答。用户还可以通过自然语言互动分析排放数据，例如查询和可视化清单、分析源贡献以及为用户定义的情景推荐排放系数。案例研究显示，Emission-GPT通过简单的提示可以直接从原始数据中提取关键见解，如点源分布和行业趋势。其模块化和可扩展的架构能够自动化传统的手动工作流，从而使Emission-GPT成为下一代排放清单发展和情景评估的基础工具。
### Conclusion
Emission-GPT通过增强的模块化和可扩展架构，将复杂的排放数据知识转换为易于理解和操作的信息，提升了非专业人士与专家之间的沟通效率，为未来排放清单开发和情景评估提供了范例。
## 55. `cs.AI` - ChunkLLM：一种加速大语言模型推理的轻量级插件框架 [PDF](https://arxiv.org/pdf/2510.02361), [HTML](https://arxiv.org/abs/2510.02361)
### Authors
Haojie Ouyang,Jianwei Lv,Lei Ren,Chen Wei,Xiaojie Wang,Fangxiang Feng
### Background
基于Transformer的大模型在自然语言处理和计算机视觉方面表现出色，但由于自注意力机制的时间复杂度与输入标记数量呈二次关系，面临严重的计算效率问题。近期，研究者提出了一系列基于块选择和压缩的方法来缓解这一问题，但这些方法要么存在语义不完整的问题，要么训练推理效率较差。为此，本文提出了一种轻量级且可插拔的训练框架——ChunkLLM。
### Innovation
ChunkLLM引入了QK Adapter（Q-Adapter和K-Adapter）和Chunk Adapter两个模块。QK Adapter附着在每个Transformer层上，实现特征压缩和块注意力采集的双重功能。Chunk Adapter位于模型底层，通过利用上下文语义信息检测块边界。在训练阶段，主干参数保持冻结状态，仅QK Adapter和Chunk Adapter进行训练。提出了注意力蒸馏方法用于训练QK Adapter，以提高关键块的回忆率。在推理阶段，仅在检测到当前标记为块边界时触发块选择，从而加速模型的推理过程。实验在多种任务的大、短文本基准数据集上进行，证明了ChunkLLM不仅在短文本基准上达到可比的性能，在长上下文基准上也保持了98.64%的性能，同时保留了48.58%的关键值缓存率，并在处理120K长文本时实现了4.48倍的最大加速。
### Conclusion
本文提出的ChunkLLM方法有效缓解了大语言模型的计算效率问题，既维护了模型在不同文本长度上的性能，又大幅提高了推理速度。
## 56. `cs.AI` - 使用罗马尼亚历史进行跨语言偏见分析的大规模语言模型研究 [PDF](https://arxiv.org/pdf/2510.02362), [HTML](https://arxiv.org/abs/2510.02362)
### Authors
Matei-Iulian Cocu,Răzvan-Cosmin Cristia,Adrian Marius Dumitran
### Background
本文研究选择一组有争议的罗马尼亚历史问题，让多个人工智能语言模型用不同的语言和背景回答这些问题，以评估其偏见。历史通常从具有文化和社会偏见的角度呈现，这可能受到特定国家及其价值观的影响。由于这些模型可能在训练过程中遇到数据集的模糊性和非中立性，导致它们的回答可能缺乏客观性。研究过程分为三个阶段，以证实期望的回答类型在一定程度上会影响响应内容；通过让模型给出数字评分，可以进一步观察模型根据问题的语言格式调整立场的情况。
### Innovation
该研究创新之处在于它利用多个语言模型针对特定历史问题进行跨语言分析，揭示了模型在响应中的潜在偏见及其在不同语言和格式中的变化特点。这项研究不仅有助于理解语言模型在多语言环境下的表现，还可能为进一步提高模型的中立性和准确性提供参考路径。
### Conclusion
研究结果显示，二元响应的稳定性较高但并不完美，且会因语言和格式不同而变化；数字评分经常偏离最初的二元选择，且最一致的模型并不一定是被认为最准确或中立的。这项研究揭示了模型在不同语境下的偏好性和不一致性，指出了需要进一步改进的地方。
## 57. `cs.AI` - 联邦时空图学习在智能电网中被动攻击检测的应用 [PDF](https://arxiv.org/pdf/2510.02371), [HTML](https://arxiv.org/abs/2510.02371)
### Authors
Bochra Al Agha,Razane Tajeddine
### Background
智能电网面临被动窃听威胁，攻击者通过监听通信链路而不篡改数据，可以揭露电网拓扑结构、消费模式和运营行为，为更严重的定向攻击打开通道。这一威胁难以检测，因为其产生的信号微弱且短暂，单个节点或时间线上审视通信数据时这些信号常常会消失。
### Innovation
本文提出了一种基于图的多模式检测器，该检测器通过在以自我为中心的星状子图和短时间窗口内融合物理层和行为指标，来检测被动攻击。该检测器采用两阶段编码器：图卷积实现对自我为中心的星状子图间空间上下文的聚合，而双向GRU则建模短期时间依赖性。编码器将异构特征转换为适合分类的统一时空表示。通过联邦学习设置进行训练，并利用FedProx提高算法对本地数据异质性的鲁棒性，保证联邦智能电网部署的信任。
### Conclusion
研究结果表明，结合空间和时间上下文能够可靠地检测隐秘侦察活动，同时将错误警报率保持在较低水平，这使得该方法适用于非独立同分布的联邦智能电网部署。模型在特定时间步长上的测试准确率达到98.32%，在0.15%的误报率下，每序列的测试准确度为93.35%。
## 58. `cs.AI` - 评估大型语言模型在物理世界中的隐私意识：一个评估基准 [PDF](https://arxiv.org/pdf/2510.02356), [HTML](https://arxiv.org/abs/2510.02356)
### Authors
Xinjie Shen,Mufei Li,Pan Li
### Background
大型语言模型（LLMs）在具身代理中的部署对测量其在物理世界中的隐私意识提出了紧迫需求。现有的评估方法主要集中在自然语言场景中，未能涵盖具体的物理环境情况。因此，急需一种新的方法来全面评估LLM在实际环境中的隐私意识能力。这项研究推出了一种名为EAPrivacy的综合评估基准，目的是量化由LLM驱动的代理在处理敏感物体、适应变化环境、平衡任务执行与隐私限制以及解决社会规范冲突方面的物理世界隐私意识能力。研究发现，当前最先进的模型在物理环境变化的场景中准确性仅为59%，在包含隐私请求的任务中，模型有86%的时间优先考虑任务完成而非隐私约束。在涉及隐私与重要社会规范冲突的情境中，主要模型有15%的时间不顾社会规范，这些发现强调了LLMs在日常物理隐私方面存在的根本性错位，并指出需要更 robust 的物理感知对齐方式。
### Innovation
提出了EAPrivacy，一种用于量化大型语言模型在物理世界中隐私意识的全面评估基准。EAPrivacy涵盖了四个层次的程序生成场景，以测试代理处理敏感对象、适应环境变化、平衡任务执行与隐私限制以及解决社会规范冲突的能力。这项研究通过EAPrivacy揭示了当前模型在这些方面存在的缺陷，特别是动态环境中的表现以及对隐私请求的重视程度不足。这表明需要更强大的物理感知对齐策略来增强LLMs的隐私意识。
### Conclusion
通过EAPrivacy基准对模型的评估显示，当前的大型语言模型在物理世界隐私方面的理解和处理存在重要缺陷。特别是，在环境变化和需要同时满足隐私约束的情境中，表现尤为不理想。这项研究揭示了现有模型在处理真实环境中隐私问题方面存在的根本性不足，并强调了在人工智能系统中加强物理隐私意识的必要性。
## 59. `cs.AI` - BluePrint：用于LLM角色评估和训练的社交媒体用户数据集 [PDF](https://arxiv.org/pdf/2510.02343), [HTML](https://arxiv.org/abs/2510.02343)
### Authors
Aurélien Bück-Kaeffer,Je Qin Chooi,Dan Zhao,Maximilian Puelma Touzel,Kellin Pelrine,Jean-François Godbout,Reihaneh Rabbany,Zachary Yang
### Background
大规模语言模型（LLMs）提供了模拟大型社交媒体动态的潜力，但在使用人类被试进行此类研究时，伦理和后勤的挑战促使学者寻找替代方案。然而，目前缺乏标准化的数据资源来微调和评估LLMs作为现实的社交媒体代理。为了解决这一问题，本文提出了一种名叫SIMPACT的框架，用于构造行为基于的社会媒体数据集，适合训练代理模型。
### Innovation
本研究引入了SIMPACT框架以及一个名为BluePrint的大规模数据集。BluePrint数据集中包含了从公开的Bluesky数据中聚类得到的匿名用户角色，每个角色代表了一系列行为模式，并且在此过程中采用了匿名化和去身份化的技术以保护用户隐私。BluePrint数据集特地聚焦于政治话语，它包括了12种类型的社交媒体互动（点赞、回复等），每条实例都附带了前序的发布活动，支持了模型在互动行为上进行语境依赖的建模。
### Conclusion
SIMPACT框架通过标准化数据集和评估协议，为严肃可靠的社交媒体模拟提供了基础。BluePrint不仅作为一个评价基准数据集用于政治话语建模，还为各个主题领域提供了模板，用于研究诸如信息传播和极化等问题。
## 60. `cs.AI` - 语言模型中参数化和上下文知识利用的训练动态 [PDF](https://arxiv.org/pdf/2510.02370), [HTML](https://arxiv.org/abs/2510.02370)
### Authors
Minsung Kim,Dong-Kyum Kim,Jea Kwon,Nakyeong Yang,Kyomin Jung,Meeyoung Cha
### Background
大型语言模型在推理时检索到的上下文知识与预训练期间获得的参数知识之间经常发生冲突。接受外部知识而不加判断的模型容易受到误导信息的影响，而严格遵循参数知识的模型则无法受益于检索。尽管检索增强生成工具得到了广泛应用，但对在训练过程中影响知识仲裁策略的因素知之甚少。这个知识仲裁策略的缺乏导致可能会生成具有不良仲裁行为的预训练模型，浪费了大量的计算资源。因此，迫切需要研究训练条件如何影响模型对参数和上下文知识的利用，以及如何在训练过程中选择和运用这些知识。
### Innovation
本研究首次系统地控制训练条件，研究其如何影响模型对参数和上下文知识的利用以及如何在训练过程中选择和运用这些知识。通过在包含不一致信息或分布偏差的合成传记语料库上训练基于转换器的语言模型，发现内部重复事实促进了参数能力和上下文能力的发展。此外，训练时包含矛盾信息或分布偏斜的语料库有助于模型发展出灵活利用参数和上下文知识的策略。研究结果表明，不应将这些非理想特性视为要去除的瑕疵，而应认为它们对于学习灵活的仲裁机制是重要的。这项研究提供了具体、基于经验的指导，以实现和谐集成参数和上下文知识的预训练模型的创建。
### Conclusion
本研究揭示了内部重复事实有助于发展和发展灵活利用参数和上下文知识的策略，这对创建能够和谐集成参数和上下文知识的预训练模型具有重要意义。建议在非理想的数据集上训练模型，以促进更好的知识仲裁机制。
## 61. `cs.AI` - 大型语言模型代理中的沉默螺旋现象 [PDF](https://arxiv.org/pdf/2510.02360), [HTML](https://arxiv.org/abs/2510.02360)
### Authors
Mingze Zhong,Meng Fang,Zijing Shi,Yuxuan Huang,Shunfeng Zheng,Yali Du,Ling Chen,Jun Wang
### Background
沉默螺旋（SoS）理论认为，持有少数观点的个体往往会因为害怕社会孤立而保持沉默，这使得多数观点可以在公众话语中占据主导地位。然而，当'代理'指的是大型语言模型时，传统的心理解释并不适用，因为SoS是为人类社会设计的。因此，一个核心问题是：在大型语言模型集体中，是否可以观察到类似SoS的动力学模式？
### Innovation
本文提出了一个评估框架来研究大型语言模型代理中的沉默螺旋现象。具体来说，通过系统地改变'历史'和'人设'信号的可用性，考察了四种控制条件下的意见动态。研究结果表明，历史和人设的共同作用能够产生强烈的多数派主导，并且重现了SoS模式；只有历史信号导致强烈的锚定效应；只有人设信号则促进多样但不相关的观点，显示在没有历史锚定时，无法出现SoS动态。这项工作将计算社会学与负责任的人工智能设计相结合，强调了需要监测和缓解大型语言模型代理系统中的新兴一致性问题的重要性。
### Conclusion
历史和人设信号的共同使用能够强烈地产生多数派主导，并复制SoS模式。只有使用历史信号可以产生强烈的锚定效应。只有使用人设信号，则可培养多样但不相关的意见，这表明缺乏历史锚定时SoS动态无法出现。这项工作在计算社会学与负责任人工智能设计之间架起了桥梁，并强调了监测和缓解大型语言模型代理系统中新兴一致性问题的重要需求。
## 62. `cs.AI` - DiffuSpec: 开启基于扩散模型的投机解码 [PDF](https://arxiv.org/pdf/2510.02358), [HTML](https://arxiv.org/abs/2510.02358)
### Authors
Guanghao Li,Zhihui Fu,Min Fang,Qibin Zhao,Ming Tang,Chun Yuan,Jun Wang
### Background
随着大型语言模型（LLMs）的规模增加，准确性提升，但由于逐个令牌的自回归（AR）解码过程需要串行前向传递，因此增加了延迟。投机性解码通过快速起草者提出multi-token草稿来解决这一问题，但这些草稿仍需由目标模型并行验证，这在实际部署中依然受限于AR起草者，其序贯传递限制了实际获得的时间收益。因此，研究团队回到起草阶段，提出了一种无需训练的模块化框架——DiffuSpec，该框架利用预训练的扩散语言模型（DLM）在单次前向传递中生成multi-token草稿，同时仍与标准的AR验证器兼容。由于DLM草稿是在双向条件控制下生成的，平行位置候选形成了一个令牌网络，在网络中，每个位置上最可能的令牌不一定形成因果左至右路径。此外，DLM起草还需要预设草稿长度，产生速度与质量之间的权衡。为应对这些问题，研究人员引入了两个实用组件：在该网络上进行因果一致性路径搜索（CPS），以提取与AR验证相一致的左至右路径，以及调整下次建议大小的自适应草案长度（ADL）控制器，该控制器基于最近的接受反馈和实际生成长度进行调整。
### Innovation
DiffuSpec是一个无需训练的模块化框架，它利用预训练的扩散语言模型（DLM）在单次前向传递中生成multi-token草稿，并且仍然与标准的AR验证器兼容。与其前身的对比，DiffuSpec在多个基准测试中提供了高达3倍的实际时间加速，证明了基于扩散模型的起草方法可以作为一个强大的替代选择，用于AR推出的投机解码中，而不再受限于AR起草者。这表明扩散模型能够在保持句子质量的同时显著提高解码速度，展示了其在加速语言模型推理过程中的潜力。
### Conclusion
DiffuSpec作为一个无需训练的模块化框架，展示了扩散语言模型在加快语言模型解码过程中的潜力。通过减少延迟和提高速度，DiffuSpec为实际应用中提高模型的吞吐量提供了新的途径，证明了基于扩散模型的草案生成技术能够在保持质量的同时显著加速语言模型推理。
## 63. `cs.AI` - 结合生成AI与键入动态的混合CAPTCHA以增强恶意软件检测 [PDF](https://arxiv.org/pdf/2510.02374), [HTML](https://arxiv.org/abs/2510.02374)
### Authors
Ayda Aghaei Nia
### Background
传统的CAPTCHA在用户体验和防护能力之间存在着权衡，尤其在对抗具有AI能力的自动化工具时更为明显。本文通过将大型语言模型带来的认知挑战与基于键入动态的行为生物特征分析相结合，提出了一种新型的混合CAPTCHA系统，旨在同时增强恶意软件检测并提升用户体验。
### Innovation
该研究引入了一种结合生成AI与键入动态的新一代CAPTCHA系统，通过生成动态不可预测的问题和分析用户打字节奏，以区分人类和机器输入。该系统不仅提高了对基于粘贴和脚本的模拟攻击的防御能力，还维持了高度的人性化体验。
### Conclusion
实验结果表明，该双层架构在恶意软件检测的准确性上表现出色，有效抵御了基于粘贴和脚本的模拟攻击，并且在人类参与者的使用体验上得分很高。这项工作展示了将认知测试和行为测试结合以创建新一代更安全、用户友好的CAPTCHA的潜力。
## 64. `cs.AI` - 超越手册和任务：针对LLM代理的实例级上下文学习 [PDF](https://arxiv.org/pdf/2510.02369), [HTML](https://arxiv.org/abs/2510.02369)
### Authors
Kuntai Cai,Juncheng Liu,Xianglin Yang,Zhaojie Niu,Xiaokui Xiao,Xing Chen
### Background
大型语言模型（LLM）代理通常接收到两种类型的上下文：（i）环境级别的手册，定义交互界面和全局规则；（ii）与特定目标相关联的任务级指导或演示。这项工作识别出了一种被忽视的重要层级上的上下文，即实例级上下文，这包括与特定环境实例相关的可验证和可重用的事实，如物体位置、工艺食谱和当地规则。研究者认为，实例级上下文的缺失是LLM代理在复杂任务中失败的一个常见原因，因为成功不仅依赖于对全局规则或任务提示的推理，还依赖于基于精确和持久的事实所做的决定。获取这种上下文不仅需要记忆，而且还有在有限的交互预算下高效地探索、验证和格式化这些事实的挑战。将这个问题形式化为实例级上下文学习（ILCL），研究者提出了一种通用的方法来解决它。该方法进行指导探索，并使用紧凑的待办事项森林智能地优先考虑下一步行动，并使用轻量级的计划-执行-提取循环来执行它们。这个过程会自动生成可多次使用并在多个下游任务和代理间有用的高精度上下文文档，从而稀释初始探索成本。
### Innovation
提出了实例级上下文学习（ILCL）这一概念，并设计了一种通用方法来解决这一问题。方法采用了指导探索策略，结合了一个紧凑的待办事项森林来智慧地优先化下一步行动，并通过轻量级的计划-执行-提取循环执行这些行动。这种方法自动生成可重用的高质量上下文文档，从而摊薄初始探索成本，并通过实例级上下文的持续利用提高了代理的可靠性和效率。实例级上下文利用TextWorld、ALFWorld和Crafter这三个任务中的应用展示了显著的成功率和效率提升。
### Conclusion
通过将一次性探索转化为持久、可重用的知识，方法补充了现有的上下文，使LLM代理更加可靠和高效。这种方法表明，提供实例级上下文对于解决复杂任务中的某些挑战至关重要。
## 65. `cs.AI` - A-MemGuard: 一种基于LLM代理记忆的前瞻性防御框架 [PDF](https://arxiv.org/pdf/2510.02373), [HTML](https://arxiv.org/abs/2510.02373)
### Authors
Qianshan Wei,Tengchao Yang,Yaochen Wang,Xinfeng Li,Lijun Li,Zhenfei Yin,Yi Zhan,Thorsten Holz,Zhiqiang Lin,XiaoFeng Wang
### Background
大型语言模型（LLM）代理通过记忆来自过去的交互学习，从而在复杂环境中实现自主规划和决策。然而，这种对记忆的依赖引入了一个关键的安全风险：对手可以向代理的记忆中注入看似无害的记录，从而操控其未来的行动。这些威胁有两个核心方面：首先，被注入记录的恶意效果仅在特定上下文中激活，使得在孤立审计内存条目时难以检测；其次，这种操纵一旦触发，可以引发自我强化的错误循环：被篡改的结果作为先例存储，不仅放大了初始错误，还逐渐降低了未来类似的攻击阈值。
### Innovation
本文提出了A-MemGuard（代理记忆卫士），这是一个专门为LLM代理记忆设计的前瞻性防御框架。核心思想是记忆本身必须具备自我检查和自我纠正的能力。A-MemGuard通过两种机制实现这一目标：（1）基于共识的验证机制，通过比较多个相关记忆推导出的推理路径来检测异常；（2）双重记忆结构，使得检测到的失败得以提炼为“教训”独立存储，供未来行动参考，以此打破错误循环并促进适应能力。全面的基准测试结果表明，A-MemGuard能够将攻击成功率降低超过95%，同时保持极小的实用性成本。这项工作将LLM记忆安全从静态筛选转变为一种随着时间增强的经验驱动型模型。
### Conclusion
A-MemGuard有效地克服了记忆向攻击注入可能引发的自我强化错误循环这一挑战，显著提升了LLM代理记忆的安全性。该防御框架的实现证明了记忆自我检查和自我纠正的重要性，并通过双重记忆结构和基于共识的验证带来了全面的防护效果。综合评估表明其性能优越，尤其是其高安全性与低实用性成本之间的良好平衡。
## 66. `cs.AI` - CWM: 通过世界模型进行代码生成研究的开放权重LLM [PDF](https://arxiv.org/pdf/2510.02387), [HTML](https://arxiv.org/abs/2510.02387)
### Authors
FAIR CodeGen team. Jade Copet,Quentin Carbonneaux,Gal Cohen,Jonas Gehring,Jacob Kahn,Jannik Kossen,Felix Kreuk,Emily McMilin,Michel Meyer,Yuxiang Wei,David Zhang,Kunhao Zheng,Jordi Armengol-Estapé,Pedram Bashiri,Maximilian Beck,Pierre Chambon,Abhishek Charnalia,Chris Cummins,Juliette Decugis,Zacharias V. Fisches,François Fleuret,Fabian Gloeckle,Alex Gu,Michael Hassid,Daniel Haziza,Badr Youbi Idrissi,Christian Keller,Rahul Kindi,Hugh Leather,Gallil Maimon,Aram Markosyan,Francisco Massa,Pierre-Emmanuel Mazaré,Vegard Mella,Naila Murray,Keyur Muzumdar,Peter O'Hearn,Matteo Pagliardini,Dmitrii Pedchenko,Tal Remez,Volker Seeker,Marco Selvi,Oren Sultan,Sida Wang,Luca Wehrstedt,Ori Yoran,Lingming Zhang,Taco Cohen,Yossi Adi,Gabriel Synnaeve
### Background
为推进基于世界模型的代码生成研究，该项目发布了一个320亿参数的开放权重大语言模型(CWM)。为了超越仅基于静态代码训练所能学习到的代码理解水平，该项目对CWM进行了中间训练，使其利用Python解释器和自主Docker环境中的大量观测-行动轨迹，并在可验证的编程、数学和多轮软件工程环境中进行广泛的多任务推理RL。CWM被用于提供一个强大的研究工具箱，供研究人员探索世界建模如何通过推理和规划提高计算环境中的代码生成机会。
### Innovation
该项目通过引入一个320亿参数的世界模型大语言模型(CWM)，为代码生成研究提供了新的工具。CWM通过在Python和Docker环境中进行中间训练，并进行多层次推理，特别在编程、数学和多轮软件工程领域展现了潜力。此外，CWM还展示了世界模型如何能够在代码生成中带来自主编码的功能，以及如何通过多步模拟来实现Python代码执行的逐步模拟。
### Conclusion
研究者通过CWM展示了如何利用世界模型增强代码生成，特别是通过推理和规划来优化在计算环境中的编程过程。模型在通用编程和数学任务上表现出色，展示了其在SWE-bench、LiveCodeBench、Math-500和AIME 2024等任务上的测试分数。为了支持进一步的研究，CWM在不同阶段的检查点已被发布，包括中间训练、精调和奖励学习阶段的结果。
## 67. `cs.AI` - 在部署中扩展同态应用 [PDF](https://arxiv.org/pdf/2510.02376), [HTML](https://arxiv.org/abs/2510.02376)
### Authors
Ryan Marinelli,Angelica Chowdhury
### Background
本文描述了一个旨在评估加密生态系统生产准备情况的原型同态应用开发。为实现这一目的，实现了一个电影推荐应用，并通过容器化和编排进行生产部署。通过调整部署配置，本研究缓解了完全同态加密（FHE）的计算限制，并通过额外的基础设施优化进行了改进。该研究的重点在于探讨如何在实际部署中有效地管理和优化同态加密应用的资源使用，以满足应用场景的需求。
### Innovation
本文的创新之处在于，它提供了将同态加密应用部署到实际生产环境中的方法和策略，通过容器化和编排技术，以及优化部署配置，有效克服了同态加密计算上的挑战，使得该技术在实际应用中更加可行和高效。
### Conclusion
本文提出的方法成功地将同态加密应用部署到生产环境中，通过调整部署配置，优化基础设施，缓解了计算限制，为未来同态加密技术的广泛应用铺平了道路。
## 68. `cs.AI` - 使用分层记忆的预训练：分离尾部和普通知识 [PDF](https://arxiv.org/pdf/2510.02375), [HTML](https://arxiv.org/abs/2510.02375)
### Authors
Hadi Pouransari,David Grangier,C Thomas,Michael Kirchhof,Oncel Tuzel
### Background
现代语言模型的出色性能主要依赖于参数的缩放：更大的模型可以存储更多的世界知识并进行更有效的推理。然而，将所有世界知识压缩到参数中是不必要的，因为每次提示只使用一部分知识，而且对于有限的推理时间和计算能力的边缘设备来说是不现实的。本文通过引入内存增强的架构和与现有硬件范例相契合的预训练策略来解决这个问题。
### Innovation
本文提出了一种分层记忆架构以及一种与现有硬件范例相契合的预训练策略。在这个架构中，使用小型语言模型访问包含世界知识的大型分层参数化内存库。在预训练和推理时，会根据上下文获取一个较小的记忆块并添加到模型中。研究结果表明，使用一个16000万个参数的模型，加上从46亿个参数的记忆库中获取的18000万个参数的记忆块，其性能可与参数超过两倍的常规模型相媲美。此外，研究还探讨了转录器中参数化记忆的最佳类型和大小，并将其扩展至超过210亿个参数。研究表明，提出的分层前馈记忆在各种转录器架构中都能取得稳健的效果，无论是预训练中添加还是后续添加都能适用。
### Conclusion
通过大规模实验，我们的研究展示了显著的性能改进：拥有160M参数并结合了18M参数的分层记忆的小型语言模型，在性能上与参数量超过常规模型两倍的模型相匹配。此外，我们还研究了分层参数化记忆的最佳类型和大小，并将其扩展到超过210亿个参数，验证了这种架构在多种转录器中的有效性。
## 69. `cs.AI` - 突破MoE大语言模型的三重困境：基于结构化压缩的动态专家聚类 [PDF](https://arxiv.org/pdf/2510.02345), [HTML](https://arxiv.org/abs/2510.02345)
### Authors
Peijun Zhu,Ning Yang,Jiayu Wei,Jinghang Wu,Haijun Zhang
### Background
混合专家（MoE）大语言模型（LLMs）面临负载不平衡、参数冗余和通信开销等三大挑战。现有的解决方法通常是针对其中特定问题进行优化，缺乏一个综合的解决方案。
### Innovation
提出了一个基于动态专家聚类和结构化压缩的统一框架，旨在协同解决这些挑战。该方法利用在线聚类过程，结合参数和激活相似度的综合度量，周期性地重新分组专家，以稳定专家的利用率。此外，通过将每个专家的权重分解为共享基础矩阵和超低秩残差适配器，实现了参数减少五倍，并保持了专业性。框架还提出了一种两阶段的分层次路由策略，以及异质精度方案和动态卸载策略，进一步提高了效率和内存利用率。
### Conclusion
该框架在GLUE和WikiText-103上的表现与标准MoE模型相当，参数量减少了约80%，吞吐量提高了10%-20%，并将专家负载的方差降低了超过三倍。这表明结构重组成一种原则性的途径，可实现规模可扩展、高效且内存有效的MoE大语言模型。
## 70. `cs.AI` - 只需超参数：利用原生扩散模型的五步推断生成与最新蒸馏模型媲美的图像 [PDF](https://arxiv.org/pdf/2510.02390), [HTML](https://arxiv.org/abs/2510.02390)
### Authors
Zilai Li
### Background
扩散模型是一种最先进的生成模型，通过神经网络迭代应用生成图像。这个生成过程被认为是解决常微分方程或随机微分方程的算法。作者分析了扩散ODE和SDE截断误差，提出了一种无需训练的五步算法，能够生成高质量的512x512和1024x1024图像，性能接近最新的蒸馏模型，同时在五步内能生成512x512的图像，比最先进的ODE求解器DPM++ 2m在20步内的效果更好。
### Innovation
该研究提出了一种无需训练的五步算法，能够在八步内生成1024x1024分辨率的高质量图像，其FID性能与最新的蒸馏模型相当，甚至优于最先进的ODE求解器DPM++ 2m在20步内生成512x512图像的效果。此外，该算法在五步内也能生成512x512的图像，FID性能优于DPM++2m在20步内的结果，同时超过最先进的AMED插件求解器和Flash Diffusion模型。
### Conclusion
该算法在COCO 2014，COCO 2017和LAION数据集上的FID性能分别为15.7，22.35和17.52，优于DPM++2m的17.3，23.75和17.33，也优于最先进的AMED插件求解器的19.07，25.50和18.06。在五步推断中，算法的FID性能也表现出接近最先进的性能，特别是在六步合成1024 * 1024图像时，性能与最新的蒸馏算法只有一小差距。
## 71. `cs.AI` - 线性循环神经网络在自回归生成长音乐样本的应用 [PDF](https://arxiv.org/pdf/2510.02401), [HTML](https://arxiv.org/abs/2510.02401)
### Authors
Konrad Szewczyk,Daniel Gallo Fernández,James Townsend
### Background
直接以自回归方式生成音频波形是一个具有挑战性的任务，特别是由于原始序列的长度和多个时间尺度上存在的显著结构。传统的方法，包括循环神经网络、因果卷积和自注意力机制，在此任务上效果有限。最近有研究表明，在即时音频建模中，深度状态空间模型，也被称为线性循环神经网络（RNN），能够高效地处理这一问题。本研究进一步探索了线性RNN在原始音频建模中的应用边界，通过不同的架构选择和上下文并行性，实现了一个可以训练长达一分钟（1M标记）样本的数据集，达到了小规模数据集上的最新对数似然比和感知度度量结果。
### Innovation
本工作专注于线性RNN在原始音频建模中的高效应用，通过不同的架构设计及上下文并行性，允许训练长度超过一分钟的序列。实现了创新的HarmonicRNN模型，在小规模数据集上取得了最新的对数似然比和感知度度量结果。
### Conclusion
研究结果表明，线性RNN在原始音频波形生成上的应用具有显著优势，特别是在效率和稳定性方面。引入的HarmonicRNN模型表现在小规模音频数据集上达到了最优的对数似然比和感知度度量，展示了其在长音频生成中的潜力。
## 72. `cs.AI` - RainSeer：基于物理学指导建模的精细雨量重建 [PDF](https://arxiv.org/pdf/2510.02414), [HTML](https://arxiv.org/abs/2510.02414)
### Authors
Lin Chen(1),Jun Chen(1),Minghui Qiu(1),Shuxin Zhong(1),Binghong Chen(2),Kaishun Wu(1) ((1) The Hong Kong University of Science and Technology (Guangzhou), (2) China Meteorological Administration)
### Background
重新构建高分辨率降雨场对于洪水预报、水文建模和气候分析至关重要。然而，现有的空间插值方法，无论是基于自动气象站(AWS)测量还是通过卫星/雷达观测增强，往往会导致过度平滑关键结构，无法捕捉锋度的转变和局部极端值。
### Innovation
提出了RainSeer，一种结构感知重构框架，重新解读雷达反射率作为具有物理依据的结构先验，捕捉降雨发展的具体时间、地点和方式。RainSeer通过一个结合物理信息的两阶段架构来解决两个基本挑战：一是将高分辨率体积雷达数据转化为稀疏的点状降雨观测，二是通过地对空的水汽-降水关联，重建物理上的连接。RainSeer通过空间对齐和地理感知的降雨解码机制实现了这一目标。
### Conclusion
RainSeer在两个公开数据集（RAIN-F和MeteoNet）上进行了评估，结果表明与最先进的基线相比，MAE降低了超过13.31%，并且在重建的降雨场中显著增强了结构的准确性。
## 73. `cs.AI` - 语言、文化和意识形态：基于推理的大语言模型在政治推文中个性化检测不当言论 [PDF](https://arxiv.org/pdf/2510.02351), [HTML](https://arxiv.org/abs/2510.02351)
### Authors
Dzmitry Pihulski,Jan Kocoń
### Background
背景介绍大语言模型如何评估政治话语中的不当言论，特别是在被要求采用特定政治和文化视角时。研究者使用了以2020年美国选举推文为中心的多语言MD-Agreement数据集，评估了几种最近的大语言模型，考察这些模型如何根据不同的政治角色（极右、保守、中间派、进步）从英语、波兰语和俄语语境中判断推文是否为不当言论。
### Innovation
创新在于使用了多语言MD-Agreement数据集，重点分析了各种近期大语言模型在不同文化背景下的表现，特别强调了推理能力对不当言论检测的影响，发现具有明确推理能力的大型模型在处理复杂政治言论时更具一致性，能够更好地捕捉细微差异。
### Conclusion
结论指出，具有明确推理能力的大语言模型在处理跨语言和意识形态差异的细分类别方面的个性化和可解释性更好。这表明，在各种语言和意识形态背景下对社会政治文本进行细致分类的关键在于使用推理机制，因此应进一步优化大语言模型进行更复杂的社会政治文本分类。
## 74. `cs.AI` - 跨平台DNA甲基化分类器用于鉴别组3和4分子亚型的八种分子亚型髓母细胞瘤 [PDF](https://arxiv.org/pdf/2510.02416), [HTML](https://arxiv.org/abs/2510.02416)
### Authors
Omer Abid,Gholamreza Rafiee
### Background
髓母细胞瘤是儿童的一种恶性脑癌，发现了分子亚群后，正在推动个性化治疗策略的发展。2019年，一个共识确定了组3和4中的八种新型亚型，每个亚型都表现出异质性特征。分类器对于将这些发现转化为临床实践非常重要，可以支持临床试验、个性化治疗的研发和应用以及患者监测。
### Innovation
该研究展示了一种基于DNA甲基化的跨平台机器学习分类器，能够在HM450和EPIC甲基化阵列样本中区分这八种亚型。在两个独立的测试集上，该模型实现了加权F1 = 0.95和平衡准确率 = 0.957，且结果跨平台一致。这是第一个跨平台解决方案，为更广泛的适用性提供后向兼容性，并增强了可访问性。此外，一旦通过网络应用部署，它还有望成为第一个公开可获取的这些亚型的分类器。
### Conclusion
这项工作朝着提高精确医疗并改善分子亚型髓母细胞瘤（主要流行群体3和4）患者的临床结果迈出了一步。
## 75. `cs.AI` - 如何训练你的顾问：使用顾问模型引导黑盒大型语言模型 [PDF](https://arxiv.org/pdf/2510.02453), [HTML](https://arxiv.org/abs/2510.02453)
### Authors
Parth Asawa,Alan Zhu,Matei Zaharia,Alexandros G. Dimakis,Joseph E. Gonzalez
### Background
当前，基础模型越来越多地用作黑盒服务，这意味着不能修改模型权重，且定制主要依赖于提示的调整。尽管静态提示优化显示出潜力，但这种方法产生的是一个固定的提示，无法适应不同的输入、用户或环境。本文探讨了顾问模型的重要性，这是一种使用强化学习训练的小型参数化策略模型，能够在黑盒模型运行时提供自然语言的实时指令，从而提升了模型的适应性和灵活性。
### Innovation
本文创新地提出了顾问模型（Advisor Models），这是一种通过强化学习训练的轻量级参数化策略，能够实时地在上下文中为黑盒模型提供自然语言指令。该模型作为一个小型辅助模型，位于输入和黑盒模型之间，根据环境提供的奖励信号实时调节模型的行为。相比静态提示优化，顾问模型能够在多个涉及推理和个人化的情景中表现出更优的性能，通过发现环境动态来提高下游任务的性能。该模型还展示了通用性，能够在不同的黑盒模型之间进行迁移，并保持对离分布输入的鲁棒性。
### Conclusion
顾问模型为用户提供了一个可学习的接口，使黑盒系统能够更具个性化和环境适应性。本文研究表明，通过顾问模型动态优化黑盒模型是一种有前景的方向，能够推动具备前沿能力的个性化和环境适应性人工智能的发展。
## 76. `cs.AI` - 动态目标攻击 [PDF](https://arxiv.org/pdf/2510.02422), [HTML](https://arxiv.org/abs/2510.02422)
### Authors
Kedong Xiu,Churui Zeng,Tianhang Zheng,Xinzhe Huang,Xiaojun Jia,Di Wang,Puning Zhao,Zhan Qin,Kui Ren
### Background
现有的基于梯度的越狱攻击通常通过优化一个固定的积极回答后缀来诱导模型产生一个固定的响应。然而，这种固定的响应目标通常位于安全对齐的大规模语言模型（LLM）在面对各类害数据输入时输出分布的一个极其稀疏的区域。这种目标和原始输出之间的巨大差异使得现有的攻击需要多次迭代来优化对抗提示，这依然可能无法从目标模型中诱导出低概率的目标响应。
### Innovation
提出了一种新的越狱框架——动态目标攻击（DTA），该方法依赖于目标模型自身的响应作为优化对抗提示的目标。DTA 在每次优化循环中都会从当前提示的输出分布中迭代地采样多个候选响应，并选择最危险的响应作为临时目标进行提示优化。与现有的攻击方法相比，DTA 显著减少了目标与输出分布之间的差异，从而大大简化了发现有效对抗提示的优化过程。
### Conclusion
大量实验结果显示，DTA 在彩色盒设置中仅需 200 次优化迭代即可使新一代安全对齐的 LLM 的成功攻击率 (ASR) 超过 87%，大大超越了最先进的基准方法，节省了 2 至 26 倍的时间成本。在黑色盒设置中，DTA 使用Llama-3-8B-Instruct作为代理模型进行目标采样，对目标模型Llama-3-70B-Instruct的成功攻击率超过 85%，同时也优于其同类型的基准方法。
## 77. `cs.AI` - 使用相关性数据增强的深度学习模型进行极值预测 [PDF](https://arxiv.org/pdf/2510.02407), [HTML](https://arxiv.org/abs/2510.02407)
### Authors
Junru Hua,Rahul Ahluwalia,Rohitash Chandra
### Background
数据增强方法利用生成对抗网络（GANs）和合成少数类过采样技术（SMOTE）等技术，已被广泛应用于解决类别不平衡问题，尤其是在模式分类和计算机视觉领域。极高值预测因其在金融和气候变化等问题中的广泛应用而成为一个具有挑战性的研究领域。当前研究旨在通过结合深度学习模型和数据增强技术，提出一个新的数据增强框架，用于预测极端值，进而提高极高值预测的准确性，特别是在极值区域的预测精度。研究中使用了卷积长短期记忆（Conv-LSTM）和双向长短期记忆（BD-LSTM）网络进行多步预测。研究综合评估了不同数据增强技术在预测精度上的有效性和计算效率，特别是在极值区域的预测性能。此外，研究还提出了一种基于相关性的数据增强策略，以增强数据的适应性和提高预测效果。Conv-LSTM和BD-LSTM在不同类型的序列上展示了互补的优势，为提高极高值预测性能提供了新的思路。
### Innovation
提出了一种基于相关性数据增强的深度学习模型框架，用于极大值预测。该框架结合了基于GANs和SMOTE的数据增强方法与深度学习模型，尤其适合于处理极端值预测任务中的类别不平衡问题。研究首次探讨了基于相关性的数据增强策略的可能应用，并验证了SMOTE策略在不同类型预测任务上的适应性和效率。此外，研究还比较了Conv-LSTM和BD-LSTM在网络结构上的差异，发现了它们各自的优势和适用场景，为未来极值预测模型的选择和设计提供了参考
### Conclusion
研究结果表明，基于SMOTE的数据增强策略在预测性能和计算效率上表现出色，尤其是在极端值区域。Conv-LSTM在周期性和稳定的序列数据上表现出色，而BD-LSTM则更适合于处理混沌或非平稳序列数据。这些发现进一步证实了将数据增强与深度学习模型结合在预测极端值方面的有效性。
## 78. `cs.AI` - 关于推理模型基准污染检测的脆弱性 [PDF](https://arxiv.org/pdf/2510.02386), [HTML](https://arxiv.org/abs/2510.02386)
### Authors
Han Wang,Haoyu Li,Brian Ko,Huan Zhang
### Background
竞争性排行榜已经将评估变成了一场竞赛，开发者通过优化基准测试套件来提高排名。然而，一种作弊策略是通过将评估基准直接融入训练数据中，导致了基准污染，即报告了虚假的性能。研究表明，这种污染对于LRMs来说是不可检测的或很容易被掩盖，尤其是在某些情况下，SFT(指导性微调)和RL(强化学习)结合使用，以及在应用CoT(逐步推理)的情况下。这些情况不仅会使污染不易被检测，还会在某些情景中使其完全不可检测。这种脆弱性不仅影响了排行榜的公平性，还威胁了公开展示排行榜的公正性。
### Innovation
研究新发现了两种情境下的污染检测脆弱性：(1) 当基础模型通过SFT和RL演变成为LRMs时，原始的污染检测方法可以识别SFT过程中的污染，但短暂的GRPO训练可以显著掩盖依赖于这种方法的污染信号；(2) 当SFT污染结合CoT应用于高级LRMs作为最终阶段时，几乎所有污染检测方法都只能随机猜测。这些研究结果证明了一大类RL方法可能具有类似的污染掩盖能力。
### Conclusion
研究揭示了LRMs评估的独特脆弱性：模型开发者可以轻易污染LRMs以实现排行榜的虚假表现，且留下的污染痕迹很少，从而严重破坏了评估的公平性，并威胁了公共排行榜的完整性。这表明需要开发更高级的污染检测方法和针对LRMs的信任评估协议。
## 79. `cs.AI` - 通过微调的多模态大型语言模型进行青光眼检测及结构化OCT报告生成 [PDF](https://arxiv.org/pdf/2510.02403), [HTML](https://arxiv.org/abs/2510.02403)
### Authors
Jalil Jalili,Yashraj Gavhane,Evan Walker,Anna Heinke,Christopher Bowd,Akram Belghith,Massimo A. Fazio,Christopher A. Girkin,C. Gustavo De Moraes,Jeffrey M. Liebmann,Sally L. Baxter,Robert N. Weinreb,Linda M. Zangwill,Mark Christopher
### Background
该研究旨在开发一种可解释的多模态大型语言模型（MM-LLM），该模型能够筛选视神经头（ONH）OCT圆扫描的质量，并生成包含青光眼诊断和视网膜神经纤维层（RNFL）局域变薄评估在内的结构化临床报告。该研究使用了1310名患者贡献的43,849张Spectralis ONH OCT圆扫描图像（其中1331个为青光眼眼，867个为健康眼）。
### Innovation
研究创新点在于使用微调的多模态大型语言模型来生成临床描述，该模型能够评估OCT图像质量，检测青光眼并进行RNFL局域变薄分类。该模型在质量评估、青光眼检测和RNFL局域变薄分类方面表现出色，且能够生成文本描述，与参考报告高度一致。
### Conclusion
微调后的MM-LLM能够基于OCT影像生成准确的临床描述。该模型在识别图像质量问题和检测青光眼方面表现出高准确性。此外，该模型还提供了RNFL局域变薄的区域描述，有助于临床OCT评估。
## 80. `cs.AI` - CLARITY: 临床助理，用于路由、推断和分诊 [PDF](https://arxiv.org/pdf/2510.02463), [HTML](https://arxiv.org/abs/2510.02463)
### Authors
Vladimir Shaposhnikov,Aleksandr Nesterov,Ilia Kopanichuk,Ivan Bakulin,Egor Zhelvakov,Ruslan Abramov,Ekaterina Tsapieva,Dmitry V. Dylov,Ivan Oseledets
### Background
该平台旨在通过结合有限状态机（FSM）和使用大规模语言模型（LLM）的协作代理，促进患者与专科医生的对接、临床咨询以及患者病情严重程度的评估。该混合架构确保了平台的安全、高效和稳健性能，使其能够灵活地满足现有医疗保健工作流程和IT解决方案的需求。
### Innovation
CLARITY平台通过结合有限状态机（FSM）和使用大规模语言模型（LLM）的协作代理，实现了结构化的对话流程控制和症状分析，强调了患者病情的优先转介给合适的专科医生。该平台已在包含55,000多个用户对话的大规模全国性院内IT平台中实现集成，并通过专家注释的对话进行验证，显示了其在初次尝试的路由精准度和咨询时间上的优越性。
### Conclusion
CLARITY平台通过验证证明了其超过人类级别的首次尝试路由精准度，咨询时间平均缩短了3倍，体现了其在识别和推荐专科医生方面的卓越表现。同时，CLARITY平台具有模块化的微服务架构，能够根据医疗保健工作流程的需求灵活扩展，为现代医疗保健提供了有力的技术支持。
## 81. `cs.AI` - Litespark 技术报告：高性能、节能的大语言模型训练框架 [PDF](https://arxiv.org/pdf/2510.02483), [HTML](https://arxiv.org/abs/2510.02483)
### Authors
Nii Osae Osae Dade,Moinul Hossain Rahat
### Background
训练大型语言模型（LLMs）面临长时间训练和巨量能耗的问题，现代模型需要数月计算时间和吉瓦时电力。为应对这些挑战，本文提出了一种新的预训练框架Litespark，通过针对性优化变压器注意力和MLP层来解决这些低效问题。该方法结合了架构改进和算法增强，以最大化模型FLOPs利用率（MFU），同时保持与标准变压器实现的兼容性。
### Innovation
Litespark通过针对性优化变压器注意力和MLP层，结合架构改进和算法增强，最大化模型FLOPs利用率（MFU），并且适用于标准变压器实现。在SlimPajama-627B数据集上对3B和30B参数的Llama模型进行了全面基准测试，显示出了显著的性能提升和能效降低：多节点H200 GPU集群中训练吞吐量提高2-6倍，能耗降低55%-83%。这些优化是模型和硬件无关的，可以在多种变压器架构中应用，扩展到后训练阶段，包括监督微调和直接偏好优化等。
### Conclusion
Litespark框架解决了大型语言模型训练中的低效率问题，通过优化提高了训练吞吐量和能效，适用于不同规模和架构的模型。这些改进有望在各种场景中得到广泛应用，进一步促进大语言模型技术的研究和发展。
## 82. `cs.AI` - SIMSplat：基于语言对齐4D高斯点积的预测驾驶场景编辑 [PDF](https://arxiv.org/pdf/2510.02469), [HTML](https://arxiv.org/abs/2510.02469)
### Authors
Sung-Yeon Park,Adam Lee,Juanwu Lu,Can Cui,Luyang Jiang,Rohit Gupta,Kyungtae Han,Ahmadreza Moradipari,Ziran Wang
### Background
驾驶场景的操纵日益成为虚拟驾驶模拟器的一种有前途的替代方案。然而，现有的框架由于编辑能力有限，难以高效生成逼真的场景。为应对这些挑战，我们提出了SIMSplat，一种使用语言对齐高斯点积的预测驾驶场景编辑器。作为一种受语言控制的编辑器，SIMSplat能够使用自然语言提示进行直观的操纵。通过将语言与高斯重构的场景对齐，它还支持直接查询道路物体，允许精确而灵活的编辑。方法提供详细的物体级别编辑，包括添加新物体和修改车辆和行人的轨迹，同时也结合了多智能体运动预测的预测路径细化，以生成场景中所有代理的真实互动。
### Innovation
SIMSplat 提出了使用语言对齐高斯点积的预测驾驶场景编辑器，能够使用自然语言提示进行直观的视觉操纵。通过多智能体运动预测，实现了对所有代理的真实互动预估，并提供了详细的物体级别编辑能力，包括添加新物体和修改轨迹，具备广泛的编辑能力和适应范围。
### Conclusion
在 Waymo 数据集上的实验展示了 SIMSplat 的广泛编辑能力和广泛的适应范围。
## 83. `cs.AI` - NEURODNAAI: 使用深度学习框架促进可持续数字存储介质的DNA基信息存储的神经流水线方法 [PDF](https://arxiv.org/pdf/2510.02417), [HTML](https://arxiv.org/abs/2510.02417)
### Authors
Rakesh Thakur,Lavanya Singh,Yashika,Manomay Bundawala,Aruna Kumar
### Background
DNA由于其卓越的密度和耐久性，被看作是数字信息存储的潜在介质。尽管前期研究已发展出编码理论、工作流程设计和仿真工具，但合成成本、测序错误以及生物限制（如GC含量不平衡和同聚体）等问题限制了其实用部署。
### Innovation
我们的框架借鉴了量子并行性的概念来增强编码多样性和抗御能力，结合生物启发的约束条件与深度学习来提高DNA存储中的错误缓解。NeuroDNAAI将二进制数据流编码为符号DNA序列，并通过替换、插入和删除等噪声通道传输和重建，且具有高保真度。实验结果表明，传统的提示或基于规则的方案无法有效适应现实中的噪音，而NeuroDNAAI则表现出更出色的准确性。并且实验数据展示了对于文本和图像数据都具有低位错误率。
### Conclusion
通过统一理论、工作流程和仿真为一个管道，NeuroDNAAI实现了可扩展且生物学上有效的归档DNA存储。
## 84. `cs.AI` - PHORECAST：跨人口群体促进公共卫生宣传的人工智能理解 [PDF](https://arxiv.org/pdf/2510.02535), [HTML](https://arxiv.org/abs/2510.02535)
### Authors
Rifaa Qadri,Anh Nhat Nhu,Swati Ramnath,Laura Yu Zheng,Raj Bhansali,Sylvette La Touche-Howard,Tracy Marie Zeeger,Tom Goldstein,Ming Lin
### Background
理解不同个体和社群对说服性信息的反应对于推动个性化的、社会意识强的机器学习具有重要意义。虽然大型视觉和语言模型（VLMs）显示出潜力，但它们在高风险领域（如公共卫生）中模拟复杂多样的人类反应的能力仍有待探索，这主要是由于缺乏全面的多模态数据集。
### Innovation
PHORECAST（公共卫生宣传接受度和活动信号跟踪）数据集被引入，旨在启用对单个层面的行为反应和社群层面的参与模式的细微预测。该数据集支持多模态理解、响应预测、个性化和社交预测任务，使其能够严格评估现代AI系统在模仿、解释和预判异质公众情绪和行为方面的表现。通过提供新的数据集以推动公共健康的AI进步，PHORECAST旨在促进开发出不仅更具有社会意识，而且与适应性和包容性健康传播目标保持一致的模型。
### Conclusion
PHORECAST 目标在于激发模型的发展，这些模型不仅更加社会意识强烈，而且与适应性和包容性健康传播的目标更加一致。
## 85. `cs.AI` - 基于市场的数据子集选择——多准则示例效用的有序聚合 [PDF](https://arxiv.org/pdf/2510.02456), [HTML](https://arxiv.org/abs/2510.02456)
### Authors
Ashish Jha,Valentin Leplat,AH Phan
### Background
选择一个小而有用的训练数据子集是困难的，因为例子有用性的信号（不确定性、稀有性、多样性等）是异质的，并且通常用不规则的权重组合在一起。现有的方法需要通过预先设定的指标和权重来评估每个例子的重要性，但这种方法缺乏透明性和可解释性。本文针对这种情况，提出了一种基于市场的选择器，通过成本函数预测市场（LMSR）给予每个例子价格，信号作为交易者，单一的流动性参数控制集中度，主题归一化稳定校准。
### Innovation
本文提出了市场机制来定价每个训练样本，通过LMSR预测市场设置价格，使用单一的流动性参数控制聚集的集中度，并通过主题归一化稳定校准。价格通过每个令牌的价格规则$rho=p/beta^{frac{1}{u}}$计算，$u$暴露了可解释的长度偏差。轻量级的多样性头部分提高了覆盖率。通过主题簇覆盖率和有效样本大小量化覆盖率。理论层面证明LMSR实现了具有指数加权和凸目标的最大熵聚合，提供了聚合强度的透明控件。实验证明了该方法在GSM8K和AGNews数据集上的有效性，市场结合了轻量级平衡，提高了准确性和稳定性，且选择过程几乎不消耗GPU时间。
### Conclusion
该框架统一了固定计算条件下多准则数据子集选择，适用于提示级别的推理和分类任务。
## 86. `cs.AI` - Oracle-RLAIF: 通过排名反馈强化学习改进多模态视频模型的微调框架 [PDF](https://arxiv.org/pdf/2510.02561), [HTML](https://arxiv.org/abs/2510.02561)
### Authors
Derek Shi,Ruben Glatt,Christine Klymko,Shubham Mohole,Hongjun Choi,Shashank Kushwaha,Sam Sakla,Felipe Leno da Silva
### Background
近年来，大视频-语言模型（VLMs）的进步依赖于广泛的微调技巧，以加强文本和视觉理解之间的对齐。主流管道通常将监督微调（SFT）与偏好数据的强化学习相结合，以增强视频理解。然而，随着VLMs参数规模的扩大，获取足够的人类反馈的成本也在增加。为了使微调更加经济有效，最近的框架探索了使用AI反馈的强化学习（RLAIF），即用AI作为评判者代替人类偏好。当前的RLAIF框架依赖于一个专门的奖励模型，该模型通过视频叙事进行训练，以创建校准的标量奖励，这是一项昂贵且限制性强的管道。
### Innovation
本文提出了Oracle-RLAIF，这是一种新框架，用更通用的Oracle排名器代替训练好的奖励模型，该排名器充当一个可以取代评分的模型响应的评估器。还引入了基于组相对策略优化（GRPO）的排名损失函数$GRPO_{rank}$，该函数直接优化序数反馈，具有感知排名的优势。实证研究显示，Oracle-RLAIF在各种视频理解基准上优于现有细调方法，一致地表现出优于现有VLMs的性能。Oracle-RLAIF铺平了通过排名而不是评分的强化学习进行大规模多模态视频模型对齐的道路，从而创建灵活且数据有效的框架.
### Conclusion
Oracle-RLAIF在视频理解基准上显著优于现有VLMs，在使用排名反馈进行强化学习时为多模态视频模型的对齐提供了更具灵活性和数据效率的方法。
## 87. `cs.AI` - ToolTweak: An Attack on Tool Selection in LLM-based Agents [PDF](https://arxiv.org/pdf/2510.02554), [HTML](https://arxiv.org/abs/2510.02554)
### Authors
Jonathan Sneh,Ruomei Yan,Jialin Yu,Philip Torr,Yarin Gal,Sunando Sengupta,Eric Sommerlade,Alasdair Paren,Adel Bibi
### Background
随着大型语言模型（LLMs）越来越多地驱动与外部工具交互的代理，使用工具已成为扩展其功能的关键机制。这些代理通常从不断增长的数据库或市场中选择工具来解决用户任务，这在工具供应商和服务提供商之间引发了显性的竞争，以获得更高的可见性和使用率。然而，这一工具选择过程存在一个严重的漏洞：通过迭代修改工具名称和描述，对手可以系统地引导代理选择特定工具，从而获得不公平的优势。
### Innovation
本文展示了这一选择过程中存在的关键漏洞：通过迭代修改工具名称和描述，对手可以系统地引导代理选择特定的工具。我们提出了ToolTweak，一种轻量级的自动化攻击方法，能够将工具的选择率提高到高达81%。这种攻击不仅影响个别工具，还会导致工具使用分布的变化，揭示工具生态系统中对公平性、竞争性和安全性的影响。我们还评估了两种防御措施：同义词改写和困惑度过滤，以减少偏见，使代理更平等地选择功能相似的工具。
### Conclusion
为了降低这些风险，我们评估了两种防御措施：同义词改写和困惑度过滤，这两种方法能够减少偏见，使得代理更平等地选择功能相似的工具。所有代码将在该论文被接受后开源。
## 88. `cs.AI` - 高密度交通和多样交互场景的轨迹生成器 [PDF](https://arxiv.org/pdf/2510.02627), [HTML](https://arxiv.org/abs/2510.02627)
### Authors
Ruining Yang,Yi Xu,Yixiao Chen,Yun Fu,Lili Su
### Background
准确的轨迹预测是自动驾驶的基础，因为它支持在复杂环境中的安全运动规划和避障。现有基准数据集受长尾分布问题的影响，大多数样本来自低密度场景和简单的直线驾驶行为，导致高密度场景和安全关键机动（如变道、超车和转弯）的代表性不足。这对于模型泛化的挑战，造成了过于乐观的评估。
### Innovation
提出了一种新颖的轨迹生成框架，同时增强场景密度并丰富行为多样性。具体而言，该方法将连续的道路环境转换为结构化的网格表示，支持精细路径规划、明确冲突检测和多Agent协调。在此表示基础上，引入了行为感知生成机制，结合基于规则的决策触发器和Frenet基于的轨迹平滑以及动态可行性约束。这种设计允许生成具有复杂交互的真实高密度场景和罕见行为。
### Conclusion
大规模Argoverse 1和Argoverse 2数据集上的实验表明，该方法在提高Agent密度和行为多样性方面显著改进，同时保留了运动的真实性和场景级别的安全性。我们的合成数据也改善了下游轨迹预测模型在高密度场景中的性能。
## 89. `cs.AI` - 自动建筑规范审查：案例研究 [PDF](https://arxiv.org/pdf/2510.02634), [HTML](https://arxiv.org/abs/2510.02634)
### Authors
Hanlong Wan,Weili Xu,Michael Rosenberg,Jian Zhang,Aysha Siddika
### Background
资源有限或农村地区的建筑官员因项目规模和复杂性增加而面临劳动密集型、易出错且成本高的设计文件人工审查。BIM与大型语言模型（LLM）的广泛应用为自动代码审查（ACR）提供了机会。
### Innovation
本文提出了一种基于代理驱动的新颖框架，该框架结合了基于BIM的数据提取与使用检索增强生成（RAG）和模型上下文协议（MCP）代理管道实现的自动化验证。通过直接调用美国能源部的COMcheck引擎和基于RAG的规则推理解释机制来处理建筑规范检查。
### Conclusion
研究成果展示了将BIM与权威性代码审查工具相结合的可扩展、可互操作且符合生产方式的方法，证明MCP代理管道在严谨性和可靠性方面优于RAG推理解释管道。
## 90. `cs.AI` - 视频模型有多自信？赋予视频模型表达不确定性的能力 [PDF](https://arxiv.org/pdf/2510.02571), [HTML](https://arxiv.org/abs/2510.02571)
### Authors
Zhiting Mei,Ola Shorinwa,Anirudha Majumdar
### Background
生成视频模型展示了令人印象深刻的文本到视频能力，广泛应用于许多实际应用场景中。然而，像大型语言模型（LLMs）一样，视频生成模型也倾向于产生虚幻的内容，即使这些视频是凭空想象的，也可能看起来合理。尽管前人的工作对LLMs的不确定性量化（UQ）进行了大量研究，但并没有针对视频生成模型的UQ方法，由此引发了严重的安全问题。在此背景下，本文研究如何量化视频模型的不确定性。
### Innovation
本文提出了一个视频生成模型不确定性的量化框架，包括：(i) 一种基于稳健的秩相关估计的评估视频模型校准的指标；(ii) 一种黑色盒状UQ方法（称为S-QUBED），这种方法利用潜在建模将预测不确定性严格分解为aleatoric和epistemic组成部分；(iii) 一个UQ数据集，用于视频模型中的校准基准测试。本研究通过在潜在空间中条件化生成任务，解开了由于任务说明模糊和知识不足导致的不确定性。
### Conclusion
通过广泛的基准视频数据集实验，我们展示了S-QUBED能够在任务准确性和任务不确定性之间建立负相关关系，有效地计算aleatoric和epistemic组成部分。
## 91. `cs.AI` - MINERVA: 基于神经估计互信息的监督特征选择方法 [PDF](https://arxiv.org/pdf/2510.02610), [HTML](https://arxiv.org/abs/2510.02610)
### Authors
Taurai Muvunzaa,Egor Kraev,Pere Planell-Morell,Alexander Y. Shestopaloff
### Background
现有的特征过滤方法依赖于统计上的成对相关性度量来建模特征-目标关系，但这种方法在目标依赖于特征的高阶交互而不是个体贡献时可能失效。本文介绍了Mutual Information Neural Estimation Regularized Vetting Algorithm（MINERVA），这是一种基于神经估计特征和目标之间互信息的新型监督特征选择方法。该方法通过神经网络参数化互信息的近似，并使用包含稀疏性诱导正则化项的精心设计的损失函数进行特征选择。该方法通过拆分表征学习和特征选择两个阶段的实现，确保更好的泛化能力和更准确的特征重要性表达。
### Innovation
MINERVA引入了一种基于神经估计互信息的监督特征选择方法。通过神经网络参数化互信息的近似，并在损失函数中加入稀疏性诱导正则化项来实现特征选择。该方法通过两个阶段的实现来拆分表征学习和特征选择，以确保更好的泛化能力和更准确的特征重要性表达。MINERVA能够捕捉文献中罕见的普遍依赖结构，并通过评估特征子集的集合来有效地捕捉复杂的特征-目标关系。
### Conclusion
实验结果表明，MINERVA方法在合成和现实生活中的诈骗数据集上的效果显著，并能够执行精确的解决方案。
## 92. `cs.AI` - 从像素到因子：学习独立可控的状态变量用于强化学习 [PDF](https://arxiv.org/pdf/2510.02484), [HTML](https://arxiv.org/abs/2510.02484)
### Authors
Rafael Rodriguez-Sanchez,Cameron Allen,George Konidaris
### Background
现有的利用因式分解马尔可夫决策过程的算法比无因式假设的方法更高效，但需要事先知道因式分解的表示，这在仅观察高维观察信息的智能体面前是不成立的。另一方面，深度强化学习可以处理高维输入，但无法利用结构化的因式因素来提升性能。本文旨在解决这一表示问题，提出了Action-Controllable Factorization (ACF)，一种对比学习方法，能够从像素观察中发现独立可控的潜在变量，即每个动作可以独立影响的状态成分。通过这种方法，ACF能够在三个已知事实结构的基准测试中（Taxi、FourRooms和MiniGrid-DoorKey）直接从像素观察中恢复真实的可控因变量，且始终优于基线拆分算法。
### Innovation
ACF是一种对比学习方法，能从像素观察数据中发现独立可控的潜在变量，且这种方法在外观未知的高维环境中仍能发挥作用。AWC不仅解决了一般从高维观察中学习低维因变量的挑战，还直接从像素观察中恢复了真实的可控因变量，从而在熟悉的基准测试中取得了更好的性能，并且能够在没有先验因式结构知识的情况下进行学习。
### Conclusion
ACF能够在未提前知道因式分解结构的情况下，从像素观察中学习独立可控的状态变量，并在基准测试中取得了优于基线算法的效果，为在高维观察中适用的强化学习提供了新的方法。
## 93. `cs.AI` - 当研究人员谈论AI的思维模型/理论_of_ mind时，他们真正谈论的是什么？ [PDF](https://arxiv.org/pdf/2510.02660), [HTML](https://arxiv.org/abs/2510.02660)
### Authors
Xiaoyun Yin,Elmira Zahmat Doost,Shiwen Zhou,Garima Arya Yadav,Jamie C. Gorman
### Background
研究者在谈论AI系统具备ToM或心理模型时，实际上讨论的是行为预测和偏见修正，而不是真正的心智状态。文章指出当前的研究混淆了复杂的模式匹配与真实认知之间的区别，忽视了模拟与体验的关键差别。虽然最近的研究表明大语言模型在ToM实验室任务上达到了人类水平的表现，但这只是基于行为的模仿。更重要的是，整个测试方法可能在将个别的人类认知测试应用于AI系统时存在缺陷，应该直接评估人类与AI交互时刻的认知情况。文章建议转向互主体验框架，强调人类认知和AI算法的共同贡献以及交互动态，而非单独测试AI。
### Innovation
文章强调了区分模拟与体验的重要性，并提出转向互主体验框架，以更好地理解和评估AI和人类交互之间的动态过程。
### Conclusion
文章认为，直接评估人类与AI交互时刻的认知情况更能准确地反映真实情况，建议未来的研究集中在人类和AI的交互动态上，而非单独测试AI系统。
## 94. `cs.AI` - 基于知识图谱的RAG系统评估框架 [PDF](https://arxiv.org/pdf/2510.02549), [HTML](https://arxiv.org/abs/2510.02549)
### Authors
Sicheng Dong,Vahid Zolfaghari,Nenad Petrovic,Alois Knoll
### Background
大语言模型（LLMs）在文本生成和对话系统等领域得到了广泛应用，并成为重要研究焦点。其中，检索增强生成（RAG）是LLMs的关键应用场景，极大地提高了生成内容的可靠性和相关性。然而，评估RAG系统的任务仍然具有挑战性，传统评价指标难以有效捕捉现代LLM生成内容的关键特征，如高流畅性和自然性。
### Innovation
该研究借鉴了RAGAS工具并将其扩展为基于知识图谱（KG）的评价框架。该框架通过多跳推理和语义社区聚类来提取更全面的评分指标，从而深化了对RAG系统的理解，并提供了关于其性能的更精细视角。为了验证该方法的有效性，研究者将其性能与RAGAS评分进行了比较，并构建了一个由人工注释的子集来评估人类判断与自动化指标之间的相关性。此外，研究还进行了针对性实验，以证明基于知识图谱的评估方法能够对生成输出中的细微语义差异表现出更高的敏感性。
### Conclusion
最后，作者讨论了评估RAG系统的几个关键挑战，并指出了未来研究的潜在方向。该研究通过引入全面且精细的评价标准和有效方法，为改善RAG系统的评估质量和应用效果提供了新思路。
## 95. `cs.AI` - HALO: 2.5D集成的内存中心异构加速器及其在低批量LLM推理中的应用 [PDF](https://arxiv.org/pdf/2510.02675), [HTML](https://arxiv.org/abs/2510.02675)
### Authors
Shubham Negi,Kaushik Roy
### Background
大语言模型（LLMs）的快速普及带动了对高效推理日益增长的需求，尤其是在聊天机器人和个人助理等对延迟敏感的应用中。LLM推理过程分为两个阶段：并行处理整个输入序列的预填充阶段和顺序生成标记的解码阶段。这些阶段对计算和内存资源的需求差异显著，这使得加速器设计面临巨大挑战。现有工作大多专注于高批量推理或仅评估短输入上下文长度，而关键的低批量和长输入上下文应用场景仍然未被充分研究。
### Innovation
HALO是一个为处理低批量LLM推理中预填充和解码阶段的特殊挑战而设计的异构存储器中心加速器。它结合了HBM支持的计算在DRAM（CiD）中，以及片上模拟计算在存储器（CiM）中的计算，通过2.5D整合技术结合使用。HALO引入了感知阶段的映射策略，根据预填充和解码阶段的不同需求进行适应。对内存操作密集型的解码阶段使用CiD进行计算，以减少DRAM内的数据移动；对计算密集型的预填充阶段使用CiM以利用其高通量矩阵乘法能力。此外，该研究分析了在两种架构极端情况下的性能权衡，突出了异构设计的必要性。
### Conclusion
通过对LLaMA-2 7B和Qwen3 8B模型的评估，HALO加速方法在相对AttAcc和CENT方法分别实现了最高18倍和2.5倍的几何平均加速。
## 96. `cs.AI` - RAMAC: 多模态风险感知的离线强化学习及其行为正则化的作用 [PDF](https://arxiv.org/pdf/2510.02695), [HTML](https://arxiv.org/abs/2510.02695)
### Authors
Kai Fukazawa,Kunal Mundada,Iman Soltani
### Background
在安全关键领域中，由于在线数据收集的不可行性，离线强化学习（RL）提供了一种有吸引力的选择，但前提是策略必须提供高回报且不会引入灾难性的尾部风险。以往的风险厌恶离线 RL 研究在确保安全性的同时牺牲了价值保守性和限制了策略类别，而具有广泛表达能力的策略仅在无风险偏好设置中被使用。
### Innovation
本文通过引入Risk-Aware Multimodal Actor-Critic (RAMAC) 架构解决这一问题，该架构结合了生成策略和分布性评论家，通过生成路径区分复合目标，涵盖了分布风险和BC损失，从而在复杂的多模态场景中实现风险敏感学习。该论文实例化了RAMAC，使用扩散和流匹配策略，并在大多数Stochastic-D4RL任务中观察到了CVaR一致增益，同时仍然保持了强大的回报。
### Conclusion
RAMAC框架能够同时解决风险感知和多模态行为的问题，在保持高回报的同时有效控制低尾风险，这一创新为安全关键领域的离线强化学习提供了有力的支持。
## 97. `cs.AI` - 通过中间分布塑形微调扩散模型 [PDF](https://arxiv.org/pdf/2510.02692), [HTML](https://arxiv.org/abs/2510.02692)
### Authors
Gautham Govind Anil,Shaan Ul Haque,Nithish Kannen,Dheeraj Nagaraj,Sanjay Shakkottai,Karthikeyan Shanmugam
### Background
扩散模型在许多领域中广泛用于生成任务。虽然预训练的扩散模型能够有效捕捉训练数据的分布，但在与下游应用对齐时，往往需要通过奖励函数来调整这些分布。现有的策略梯度方法，如近端策略优化(PPO)，在自回归生成的背景下得到了广泛应用。然而，对于扩散模型而言，所需要计算的边缘似然性难以直接处理，这促使了其他替代提案和近似方法的出现。在这一背景下，作者将不同版本的拒绝采样微调（RAFT）统一为一种新的方法——GRAFT，并表明其隐式实现了带有重塑奖励的PPO。接着，作者提出了P-GRAFT以在中间噪声水平重塑分布，并通过实验证明了这种方法可以有效地进行微调。作者还通过偏差-方差折中理论进行了数学上的解释。基于此，作者提出逆噪声校正来改进流动模型，而无需使用显式的奖励。作者在文本到图像生成、布局生成、分子生成和无条件图像生成任务上进行了实证评估。
### Innovation
作者将不同版本的拒绝采样微调统一为一种新的方法——GRAFT，并表明其隐式实现了带有重塑奖励的PPO。提出P-GRAFT在中间噪声水平重塑分布，并在多项任务上展示了较为有效的微调效果。提出了逆噪声校正来改进流动模型，而无需使用显式的奖励。
### Conclusion
作者的框架应用于Stable Diffusion 2，使得在流行的文本到图像（T2I）基准测试中优于策略梯度方法，相对提高了8.81%。对于无条件图像生成，逆噪声校正提高了生成图像的FID，同时减少了每张图像的FLOPs。
## 98. `cs.AI` - 一种新颖的统一轻量级时空转换器方法在无人机网络入侵检测中的应用 [PDF](https://arxiv.org/pdf/2510.02711), [HTML](https://arxiv.org/abs/2510.02711)
### Authors
Tarun Kumar Biswas,Ashrafun Zannat,Waqas Ishtiaq,Md. Alamgir Hossain
### Background
无人机在商用、工业和民用领域中的日益集成导致了重大的网络安全性挑战，特别因为无人机网络容易受到各种形式的网络攻击的影响。现有的入侵检测机制在面对无人机运行的动态和资源受限等复杂环境时缺乏足够的适应性、效率和泛化能力。
### Innovation
该论文提出了一个名为TSLT-Net的新型轻量级和统一的时空变换器入侵检测系统，专门针对无人机网络。TSLT-Net利用自我注意力机制来有效地建模网络流量的时空模式，从而准确检测多种入侵类型。该框架包括一个简化的预处理管道，支持在单一架构中进行多类攻击分类和二元异常检测。
### Conclusion
通过在包含超过230万条标注记录的ISOT无人机异常检测数据集上进行的广泛实验，TSLT-Net展示了在多类检测中高达99.99％的准确率和在二元异常检测中的100％准确率，并且具有微小的内存占用量和可训练参数数量（分别为0.04 MB和9722个）。这些结果确立了TSLT-Net是实时无人机网络安全的有效和可扩展解决方案，特别适合用于关键任务无人机系统中的边缘设备部署。
## 99. `cs.AI` - 使用高斯描述符和逆向协同优化模板和墨水配方的全自动化定向自组装光刻技术 [PDF](https://arxiv.org/pdf/2510.02715), [HTML](https://arxiv.org/abs/2510.02715)
### Authors
Yuhao Zhou,Huangyan Shen,Qingliang Song,Qingshu Dong,Jianfeng Li,Weihua Li
### Background
定向自组装（DSA）中的块共聚物（BCPs）在制造亚7纳米技术节点下的接触孔或垂直互连访问方面提供了高度有前景的方法。为了精确控制尺寸和位置制造圆孔，块共聚物的自组装需要由适当设计的模板提供指导。有效地参数化模板形状以实现高效优化仍然是一个关键但具有挑战性的问题。此外，优化后的模板必须具有良好的可制造性，以满足实际应用的需求。
### Innovation
本文提出了一种高斯描述符，仅通过两个参数即可表征模板形状。同时，建议使用AB/AB二元混合物而不是纯二块共聚物来提高块共聚物系统对模板形状的适应性。通过应用于二元混合物和模板形状协同优化的贝叶斯优化，我们揭示了基于高斯描述符的贝叶斯优化能够有效地为多种多孔模式提供最佳模板，所有这些都导致了高度匹配的自组装形态。此外，通过在优化过程中对模板曲率变化施加约束，确保每种优化模板的优异可制造性。值得注意的是，在高精度需求下，混合物的每个关键参数都表现出相当宽的可调节窗口。
### Conclusion
我们的工作为推进DSA技术提供了有价值的见解，并且有望促进其实际应用的进一步发展。
## 100. `cs.AI` - iLLM-A*: 一个加速1000倍的增强型大规模网格地图路径规划算法 [PDF](https://arxiv.org/pdf/2510.02716), [HTML](https://arxiv.org/abs/2510.02716)
### Authors
Junlin Zeng,Xin Zhang,Xiang Zhao,Yan Pan
### Background
路径规划在由各种应用引发的网格地图中受到了广泛关注，现有方法如A*、迪杰斯特拉及其变种在小型地图上表现良好，但在大型地图上由于搜索时间和内存消耗大而效率低下。最近，大型语言模型（LLMs）在路径规划中表现出色，但仍存在空间幻觉和规划性能差的问题。其中，LLM-A*通过使用LLM生成一系列航点，然后利用A*规划相邻航点之间的路径来构建完整路径，但其在处理大型地图时仍然存在较高的计算时间。
### Innovation
我们针对LLM-A*的瓶颈进行了深入研究，并设计出一种创新的增强型算法iLLM-A*，它包括三种优化机制：A*的优化、增量学习方法以生成高质量航点，以及为A*选择合适的航点进行路径规划。
### Conclusion
在对各种网格地图进行全面评估后，与LLM-A*相比，iLLM-A*在平均情况下实现了超过1000倍的加速，极端情况下达到2349.5倍；节省了高达58.6%的内存成本；实现更短的路径长度和更低的路径长度标准差。
## 101. `cs.AI` - 时间至不一致：大规模语言模型在对抗攻击下的稳健性生存分析 [PDF](https://arxiv.org/pdf/2510.02712), [HTML](https://arxiv.org/abs/2510.02712)
### Authors
Yubo Li,Ramayya Krishnan,Rema Padman
### Background
大语言模型（LLMs）已经在对话式AI领域带来了革命性的变化，但它们在扩展的多轮对话中的稳健性仍然没有被充分理解。现有的评估框架主要集中在静态基准和单轮次评估上，无法捕捉现实对话中对话质量逐步下降的时间动态特征。本文通过分析36,951轮对话，涵盖9个最先进的LLMs，首次从生存分析的角度对对话式AI的稳健性进行了全面研究，揭示了前所未有的时间动态特征。
### Innovation
本文引入了一种生存分析框架，使用Cox比例风险模型、加速失效时间模型和随机生存森林方法，分析LLMs在对话中的表现，揭示了对话稳健性的特殊时间动态特征。研究发现，自相矛盾的提示到提示（P2P）语义漂移是灾难性的，导致对话失败的风险显著增加；相反，渐进的、累积的漂移则是保护性的，可以大大降低对话失败的风险，使对话能够延长。与交互的AFT模型表现出色，具有优越的区分能力和良好的校准性。这些发现为评估LLM的稳健性提供了强有力的方法，同时也为设计更具弹性的对话代理提供了具体见解，挑战了对对话AI系统中语义一致性必要性的传统假设。
### Conclusion
本研究通过生存分析揭示了LLM在对话中的超强时间动态特征，阐明了自相矛盾的P2P语义漂移的灾难性影响和渐进累积漂移的保护性影响。与交互的AFT模型表现突出，具有优越的区分能力和良好的校准性。该研究确立了生存分析作为评估LLM稳健性的强大范式，为设计更具弹性的对话代理提供了实用的见解，并挑战了对话AI系统中语义一致性必要性的传统假设。
## 102. `cs.AI` - SAE-RNA: 一种稀疏自编码器模型，用于解释RNA语言模型表示 [PDF](https://arxiv.org/pdf/2510.02734), [HTML](https://arxiv.org/abs/2510.02734)
### Authors
Taehan Kim,Sangdae Nam
### Background
深度学习尤其是大型语言模型的进步，已经彻底改变了生物分子建模，蛋白质方面的进展（如ESM）激发了新兴的RNA语言模型，如RiNALMo。然而，这些RNA语言模型内部是如何表示mRNA或ncRNA家族的具体信息的仍然不清楚。
### Innovation
我们提出了一种可解释性模型SAE-RNA，用于分析RiNALMo表示并将它们映射到已知的人类级生物特征。我们的工作将RNA解释性置于在预训练词嵌入中发现概念的框架内，而无需端到端重新训练，并提供了探索RNA LMs可能编码的ncRNA家族特征的实用工具。该模型可以扩展，用于RNA群组之间的对比，并支持关于先前未知的相互关系的假设生成。
### Conclusion
该研究通过SAE-RNA模型，为理解RNA语言模型的内部表示机制提供了一个新的途径。该模型不仅能够用于近距离对比不同RNA群组，还能够支持关于ncRNA家族相互关系的假设生成。
## 103. `cs.AI` - 数据驱动的动力学能否揭示隐藏的物理规律？需要可解释的神经算子 [PDF](https://arxiv.org/pdf/2510.02683), [HTML](https://arxiv.org/abs/2510.02683)
### Authors
Wenhan Gao,Jian Luo,Fang Wan,Ruichen Xu,Xiang Liu,Haipeng Xing,Yi Liu
### Background
近年来，神经算子作为一种强大的工具出现，用于学习函数空间之间的映射，使复杂动力学的数据驱动模拟成为可能。尽管取得了成功，但对其学习机制的理解仍较为浅薄。本研究根据其工作领域将神经算子分为两类：空间域模型（基于网格学习）和函数域模型（基于函数基学习）。研究聚焦于物理原理约束下的数据驱动动力学学习，并提供了一种解释神经算子预测过程的方法，展示了其从数据中学习隐藏物理规律的能力，但此方法仅适用于特定情况，突显了通用解释方法的紧迫需求。此外，研究展示了一种简单双空间多尺度模型达到了SOTA性能，认为这种双空间多尺度模型有潜力学习复杂的物理学并需要进一步研究。最后，强调了将已知物理原则纳入神经算子中的必要性，以增强泛化能力和揭示更多隐藏的物理现象。
### Innovation
提出了对神经算子的分类方法，区分了基于网格和基于函数基的学习模型；提供了一种解释神经算子预测过程的方法；展示了简单双空间多尺度模型在SOTA性能方面的应用；强调了双空间多尺度模型在学习复杂物理学上的潜力.
### Conclusion
虽然现有的神经算子方法在数据驱动动力学的学习上显示出潜力，但目前仍缺乏通用的解释框架。研究认为简单的双空间多尺度模型展示了学习复杂物理的潜力，并强调了需要进一步探索。同时，该研究强调了将已知物理原则整合到神经算子中的必要性，以提高泛化能力和揭示更多隐含的物理现象。
## 104. `cs.AI` - AgenticRAG：为零样本可解释推荐系统提供工具增强基础模型 [PDF](https://arxiv.org/pdf/2510.02668), [HTML](https://arxiv.org/abs/2510.02668)
### Authors
Bo Ma,Hang Li,ZeHua Hu,XiaoFan Gui,LuYao Liu,Simon Liu
### Background
尽管基础模型近年来在人工智能领域取得了革命性的进展，但在推荐系统中的应用仍然受到推理不透明性及知识限制的限制。现有推荐系统通常缺乏透明性、依赖特定任务的培训，且知识表示相对静态，无法很好地应对新颖或者模糊的查询需求。AgenticRAG框架旨在解决这些问题，通过结合工具增强的基础模型和检索增强的生成技术，以实现零样本中的可解释推荐。该框架允用户外部工具调用、知识检索及推理链思路，设计出无特定任务培训的自主推荐代理，从而实现透明决策。实验结果在三个实际数据集上表明AgenticRAG 在Amazon Electronics数据集上NDCG@10提高0.4%，MovieLens-1M数据集上提高0.8%，在Yelp数据集上提高1.6%，体现出优秀的解释性和与传统方法相当的计算效率，从而弥补现有推荐系统的不足，为用户提供更透明、更准确的推荐决策过程
### Innovation
AgenticRAG框架创新性地结合了工具增强基础模型与检索增强生成技术，提出了一种创新的框架来实现零样本推荐系统的透明解释性。具体包括三点：1) 引入了工具调用机制，提高了模型的灵活性和实用性；2) 深度整合了外部知识检索，使推荐更具依据性；3) 强化了推理链路，确保决策过程的透明性和合理性。上述创新使得AgenticRAG在多个实际数据集上展示出显著优势，证明了它在设计透明可解释推荐系统方面的潜力
### Conclusion
AgenticRAG展示了在零样本推荐系统中实现透明、可解释的推荐过程的重要性。实验结果表明，该框架不仅提高了推荐性能，还提供了更好的可解释性，同时维持了可接受的计算效率。这为未来的推荐系统设计提供了新的思路，促进了更具透明度和合理性的智能推荐系统的开发。
## 105. `cs.AI` - TutorBench：评估大型语言模型辅导能力的标准 [PDF](https://arxiv.org/pdf/2510.02663), [HTML](https://arxiv.org/abs/2510.02663)
### Authors
Rakshith S Srinivasa,Zora Che,Chen Bo Calvin Zhang,Diego Mares,Ernesto Hernandez,Jayeon Park,Dean Lee,Guillermo Mangialardi,Charmaine Ng,Ed-Yeremai Hernandez Cardona,Anisha Gunjal,Yunzhong He,Bing Liu,Chen Xing
### Background
随着学生越来越多地采用大型语言模型（LLMs）作为学习辅助工具，构建能够处理辅导细微差别的模型变得至关重要。这些模型需要能够识别学生的核心需求，具备适应性，提供个性化指导，并且准确。为实现这一目标，我们引入了TutorBench，这是一个数据集和评估基准，旨在严谨评估LLMs的核心辅导技能。该数据集包含1490个由专家精心筛选的样本，聚焦于高中和AP水平的课程。这些样本来自三种常见的辅导任务：（i）为学生的困惑生成定制的解释，（ii）提供针对学生作业的实用反馈，（iii）通过有效的提示生成促进主动学习。为了应对辅导的固有复杂性，每个样本都配备了样本特定的评分标准，这些标准用于评估阶段的模型响应评价。TutorBench采用了一种可靠且细粒度的自动评估方法，使用LLM裁判和样本特定的评分标准。我们对16种前沿的LLM进行了评估，并详细分析了它们的性能和行为。结果显示，没有一种前沿的LLM得分超过56%，显示出很大的改进空间。我们发现，LLMs在展示全面的辅导技能方面存在不足，这些技能能够有效引导、诊断和支持学生，所有前沿的模型在与这些技能相关的评分标准上都未能达到60%的及格率。我们还发现，不同的模型家族在不同情景下表现出不同的优势和局限性：Claude模型在支持主动学习方面表现最好，但在其他两个应用场景中则落后于其他模型。通过发布TutorBench，我们提供了一个全面而不足的基准，以指导下一代AI辅导的发展。
### Innovation
提出了一个名为TutorBench的框架，旨在评估大型语言模型的辅导能力。该框架包括1490个针对特定辅导任务的高质量样本和详细的评分标准，能够更全面地评估模型的辅导技能。还采用了一种自动评价方法，结合LLM裁判和样本特定的评分标准，能够更客观地评估模型的表现。通过评估多种前沿的大型语言模型，揭示了当前模型在辅导技能上的不足和不同模型家族的不同优劣。
### Conclusion
现有的前沿大型语言模型在辅导能力方面存在显著不足，几乎所有模型在模拟真实辅导场景的评分标准上的表现都不理想。尽管存在差异，现有的大型语言模型在支持主动学习方面表现出色，但在应对其他主要辅导任务时则远远不够。通过发布TutorBench，我们期望能够推动该领域的进一步研究和发展，促进下一代AI辅导工具的开发。
## 106. `cs.AI` - 通过用喻驱动设计原型化数字社会空间：将空间概念转化为交互式社会仿真 [PDF](https://arxiv.org/pdf/2510.02759), [HTML](https://arxiv.org/abs/2510.02759)
### Authors
Yoojin Hong,Martina Di Paola,Braahmi Padmakumar,Hwi Joon Lee,Mahnoor Shafiq,Joseph Seering
### Background
社交平台在交流中占据核心地位，然而其设计主要集中在参与度和规模上。尽管研究人员提出了替代性的在线空间愿景，但在平台限制内进行原型设计仍然困难。本研究旨在通过引入一种用喻驱动系统帮助用户想象和探索新的社交媒体环境。
### Innovation
该系统通过将用户的用喻转化为结构化的平台特性集，并生成由LLM驱动的代理占据的互动模拟来实现。这一方法突破了在平台限制内进行原型设计的难题，使得非技术用户也能创造性地探索社交媒体的新环境。
### Conclusion
研究表明，用喻能够让用户表达独特的社会期望，模拟的感知真实性取决于其捕捉诸如亲密性、参与度和时间性参与等动态的能力。研究者认为用喻驱动的仿真可以成为一种强大的设计工具，用于原型化不同社会架构，并扩展未来社交平台的设计空间。
## 107. `cs.AI` - Align Your Query: Representation Alignment for Multimodality Medical Object Detection [PDF](https://arxiv.org/pdf/2510.02789), [HTML](https://arxiv.org/abs/2510.02789)
### Authors
Ara Seo,Bryan Sangwoo Kim,Hyungjin Chung,Jong Chul Ye
### Background
医学对象检测在使用单一检测器对混合医学模态（如X胸片、CT、MRI）进行训练时受到限制，这是因为不同模态的统计特征和表示空间存在异质性和分离。为了应对这一挑战，研究引入了表示对齐（representation alignment）的方法，该方法已被证明能将来自不同来源的特征整合到共享空间。研究聚焦于DETR风格的对象查询表示，并提出了一种简单的、独立于检测器的框架，通过多模态上下文注意（MoCA）将模态上下文信息注入到对象查询中。
### Innovation
研究定义了模态令牌（modality tokens），这是一种紧凑的、源于文本的嵌入式表示，用于编码图像模态，并通过多模态上下文注意（MoCA）将模态上下文信息融入检测过程，同时集成到DETR风格的架构中。此外，研究还引入了QueryREPA，一种短预训练阶段，使用特定任务的对比目标来校准查询表示以与模态令牌对齐，在模态平衡批次中进行。
### Conclusion
研究结合MoCA和QueryREPA，生成模态感知的、类忠实的查询，并有效转移到下游训练中。实验结果表明，该方法在各种模态同时训练的情况下，能够一致地改进AP（平均精确度），且具有轻微的计算开销和无需架构修改的特点，为多模态医学对象检测提供了实际可行的途径。
## 108. `cs.AI` - CST-AFNet: 一种基于双注意力机制的深度学习框架在物联网网络中的入侵检测 [PDF](https://arxiv.org/pdf/2510.02717), [HTML](https://arxiv.org/abs/2510.02717)
### Authors
Waqas Ishtiaq,Ashrafun Zannat,A.H.M. Shahariar Parvez,Md. Alamgir Hossain,Muntasir Hasan Kanchan,Muhammad Masud Tarek
### Background
物联网（IoT）的快速发展彻底改变了现代工业，实现了智能化自动化和实时连接。然而，这也带来了由于这些环境异构、资源受限和分布式性质而带来的复杂网络安全挑战。为应对这些挑战，本研究提出了CST AFNet，一种针对物联网网络的鲁棒入侵检测新型双注意力机制的深度学习框架。该模型结合多尺度卷积神经网络（CNN）进行空间特征提取，双向门控循环单元（BiGRUs）捕获时间依赖性，以及双注意力机制（通道和时间注意力），以增强对重要数据模式的关注。
### Innovation
CST AFNet 是一种针对物联网和工业物联网复杂环境的鲁棒入侵检测模型。该模型引入了双注意力机制，结合多尺度卷积神经网络和双向门控循环单元，有效提高了数据模式识别的准确性。实验结果显示，CST AFNet 在15种攻击类型和良性流量上都表现出色，准确率达到99.97%，宏平均精准率、召回率和F1分数均超过99.3%，远超传统深度学习模型。
### Conclusion
CST AFNet 是一种强大且可扩展的实时网络安全威胁检测解决方案，适用于复杂物联网和工业物联网环境，有助于建立更安全、智能且适应性强的网络物理系统。未来研究可以进一步探索模型在不同类型物联网设备和网络环境中的应用与优化。
## 109. `cs.AI` - MaskCD：通过图像头部掩蔽对比解码减轻LVLM幻觉 [PDF](https://arxiv.org/pdf/2510.02790), [HTML](https://arxiv.org/abs/2510.02790)
### Authors
Jingyuan Deng,Yujiu Yang
### Background
大视觉-语言模型（LVLMs）在下游多模态任务中的视觉-语言理解方面表现出显著的能力。尽管它们的性能在不断提高，但同时也出现了一些问题，其中幻觉现象尤为突出，即LVLMs生成与其输入的视觉和文本内容矛盾的内容。已有多种方法试图解决这一问题，例如对比解码和注意力操控。然而，对比解码方法在构造合适的对比样本方面存在困难，而注意力操控方法则缺乏稳定性，容易受到外界影响。
### Innovation
本文提出了图像头部掩蔽对比解码（MaskCD），利用LVLMs中的‘图像头部’，通过掩蔽它们来构造用于对比解码的对比样本。这种方法克服了对比解码和注意力操控的缺点，提升了模型对抗幻觉现象的能力，同时保持了LVLMs的整体性能。
### Conclusion
MaskCD在LLaVA-1.5-7b和Qwen-VL-7b上进行了评估，并使用CHAIR、POPE、AMBER和MME等基准测试。实验结果表明，MaskCD有效地缓解了幻觉现象，并保留了LVLMs的通用能力。对应的资源可以在这里找到：this https URL。
## 110. `cs.AI` - OptunaHub：一个黑盒优化平台 [PDF](https://arxiv.org/pdf/2510.02798), [HTML](https://arxiv.org/abs/2510.02798)
### Authors
Yoshihiko Ozaki,Shuhei Watanabe,Toshihiko Yanase
### Background
黑盒优化（BBO）推动了诸如自动化机器学习（AutoML）和材料信息学等领域的发展，但研究努力经常跨越不同领域而显现碎片化。为了更好地整合和促进这些领域的研究，引入了一个名为OptunaHub的社区平台，旨在集中BBO方法和基准测试，提供统一的Python API，一个贡献者包注册表，并提供一个网页界面来促进搜索和跨领域研究。
### Innovation
OptunaHub 提供了一个统一的平台，通过集中 BBO 方法和基准测试，促进黑盒优化在不同领域的研究和应用。平台包括统一的 Python API，贡献者包注册表和网页界面，旨在促进贡献和应用的良性循环。源代码公开存储在 GitHub 的 Optuna 组织中，包括 optunahub，optunahub-registry 和 optunahub-web 存储库。
### Conclusion
OptunaHub 通过提供统一的 BBO 方法和基准测试，促进了黑盒优化方法的研究和应用，并旨在构建一种促进贡献和应用的良性循环，从而推动该领域的进一步发展。
## 111. `cs.AI` - TravelBench：在低资源领域探索LLM性能 [PDF](https://arxiv.org/pdf/2510.02719), [HTML](https://arxiv.org/abs/2510.02719)
### Authors
Srinivas Billa,Xiaonan Jing
### Background
现有的大规模语言模型（LLM）基准测试结果并不能很好地反映模型在资源有限任务中的能力，这给在这些领域开发有效的解决方案带来了困难。为了应对这些挑战，该研究构建了14个覆盖7种常见NLP任务的旅行领域数据集，并使用匿名化的真实场景数据。这些数据集的构建目的在于分析LLM在各种任务的表现，从而揭示在资源有限任务中的性能表现与一般基准测试结果之间的差异。
### Innovation
研究通过构建专门针对旅行领域的数据集来探索LLM的性能，覆盖了7种常见的NLP任务，并分析了不同LLM在这类任务中的表现，尤其是在小规模数据资源上的表现。研究发现，尽管训练算力巨大，但通用的基准测试结果不足以评估LLM在低资源任务中的性能。研究还揭示，推理能力对于小规模模型来说，提供了更大的性能提升，使模型在某些任务上更具判别力。这种专门构建的数据集和研究结果填补了现有研究的空白，为未来在低资源领域开发有效的LLM解决方案提供了新的视角和方法。
### Conclusion
研究结果表明，在资源有限的任务中，通用的基准测试结果无法充分反映模型的真实性能表现。对于复杂且具有领域特定性的场景，即使训练算力很大，开箱即用的大型语言模型仍可能遇到性能瓶颈。此外，推理能力对于较小规模的语言模型更为关键，能够显著提升模型在某些特定任务上的表现。该研究证明，需要专门设计的数据集和评估方法来更准确地评估LLM在低资源任务领域中的性能，并为进一步研究提供了方向。
## 112. `cs.AI` - 时间序列在线经验预测中的相关性导向阈值调整 [PDF](https://arxiv.org/pdf/2510.02809), [HTML](https://arxiv.org/abs/2510.02809)
### Authors
Théo Dupuy,Binbin Xu,Stéphane Perrey,Jacky Montmain,Abdelhak Imoussaten
### Background
近年来，机器学习领域中的不确定性量化受到了广泛关注。对于时间序列预测，经验预测（Conformal Prediction, CP）方法逐渐成为研究热点。特别是针对数据分布随时间变化的问题，一种名为在线经验预测（Online Conformal Prediction, OCP）的方法应运而生。OCP的核心思想是在基于分布观察的情况下动态更新阈值。现有OCP方法主要关注预测区间的覆盖有效性并最小化预测区间的宽度，但通常只考虑预测区间的覆盖有效性而未充分考虑预测区间的相关性，即预测区间内实际值的重要性。作者在此基础上提出改进，引入能评估预测区间实际值相关性的函数，从而达到更窄的预测区间并保持覆盖有效性。
### Innovation
提出了一种在OCP中的相关性导向阈值调整方法，通过使用量化预测区间实际值相关性的函数来替代简单的区间内/外判别，以实现更窄的预测区间并维持覆盖有效性。
### Conclusion
实验结果表明，与现有的OCP方法相比，改进的阈值调整方法能够在保持覆盖有效性的前提下生成更紧致的预测区间。
## 113. `cs.AI` - 评估大型语言模型在IUCN红名单物种信息中的应用 [PDF](https://arxiv.org/pdf/2510.02830), [HTML](https://arxiv.org/abs/2510.02830)
### Authors
Shinya Uryu
### Background
大型语言模型（LLMs）在保护领域迅速普及，用于应对生物多样性的危机。然而，这些模型在物种评估中的可靠性尚待确定。这项研究系统地验证了五个领先的模型，涵盖了21,955个物种在四个核心IUCN红名单评估组件上的表现：分类学、保护状况、分布和威胁。
### Innovation
研究揭示了一个关键的悖论：模型在分类学分类上表现出色（94.9% 的准确性），但在保护学推理上却普遍失败（状态评估准确率为27.2%）。这一知识-推理差距表明，问题不仅仅在于数据限制，还与模型的固有架构有关。此外，模型显示出系统性偏差，倾向于优先考虑具有吸引力的脊椎动物，这可能会扩大现有的保护不平等。研究结果强调，在使用LLMs进行信息检索时需要人类监督，建议采用人机结合的方法，其中LLMs辅助专家能力，而人类专家则保留在风险评估和政策决策上唯一的权威。
### Conclusion
研究明确了合理部署LLMs的界限：它们是强大的信息检索工具，但在基于判断的决策领域需要人类监督。推荐采用人机结合的方法，其中LLMs辅助专家能力，人类专家则保留在风险评估和政策决策上唯一的权威。
## 114. `cs.AI` - 知识驱动与频率自适应学习的电池健康预測建模 [PDF](https://arxiv.org/pdf/2510.02839), [HTML](https://arxiv.org/abs/2510.02839)
### Authors
Vijay Babu Pamshetti,Wei Zhang,Sumei Sun,Jie Zhang,Yonggang Wen,Qingyu Yan
### Background
电池健康预測对于确保现代能源系统中的安全、效率与可持续性至关重要。然而，由于电池降解行为的复杂性，包括非线性、噪声、容量再生等问题，准确且可靠地实现长期健康预測颇具挑战。现有的数据驱动模型能够捕捉时间相关的降解特征，但往往缺乏知识指导，导致长期健康预測不可靠。
### Innovation
本文提出了一种名为Karma的具有知识驱动且频率自适应学习能力的电池容量估计与剩余使用寿命预测模型。该模型首先进行信号分解，提取不同频段的电池信号。通过一种双流深度学习架构，分别捕捉长时间低频降解趋势和高频短期动态。Karma结合知识进行预測调节，基于经验研究将电池退化建模为双指数函数，并使用粒子滤波优化知识参数，确保预測结果的物理一致性和可靠性。
### Conclusion
实验结果显示，Karma在两个主流数据集上的电池健康预测方面优于现有最先进的算法，平均误差分别降低了50.6%和32.6%。这些结果证明了Karma的鲁棒性、普适性和在各种应用中实现更安全、更可靠电池管理的潜力。
## 115. `cs.AI` - 基于约束满意度的古典填词游戏Wordle：新颖策略与跨语言验证 [PDF](https://arxiv.org/pdf/2510.02855), [HTML](https://arxiv.org/abs/2510.02855)
### Authors
Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel,Kamrujjaman,Eftakhar Ahmed Arnob,Ahsan Habib Tareq
### Background
Wordle提供了用于约束满足问题（CSP）解决的算法丰富测试平台。现有解法主要依赖信息论的熵最大化或基于频率的启发式方法，但未经过正式的约束处理。这一研究首次将Wordle问题全面形式化为CSP问题，并提出了新的约束意识解法策略。
### Innovation
提出了CSP-Aware Entropy（通过约束传播后的信息增益计算）和概率CSP框架（结合贝叶斯单词频率先验与逻辑约束）。在2315个英文单词的评估中，CSP-Aware Entropy平均猜测次数为3.54，成功率为99.9%，在噪声条件下仍能维持相对优势，尤其是在概率CSP方法下通过约束恢复机制实现所有噪声水平下的100%成功率。
### Conclusion
结合形式化CSP处理，约束意识启发式方法，概率与逻辑集成，鲁棒性分析和跨语言验证，研究建立了一系列新的性能基准，表明原理上的约束满意度技术在结构化谜题解决领域优于经典的基于信息论和学习的方法。开源实现（带有34个单元测试，代码覆盖率91%）提供可重复研究的基础设施。
## 116. `cs.AI` - Flamed-TTS：基于流匹配注意力模型的高效生成与动态节奏零样本文本转语音 [PDF](https://arxiv.org/pdf/2510.02848), [HTML](https://arxiv.org/abs/2510.02848)
### Authors
Hieu-Nghia Huynh-Nguyen,Huynh Nguyen Dang,Ngoc-Son Nguyen,Van Nguyen
### Background
零样本文本转语音（Zero-shot Text-to-Speech, TTS）已经取得了显著的进步，通过使用简短的上下文提示（少于100字），模型能够合成语音。这些提示充当声源示例，使模型能够模仿说话人的身份、语调和其他特征，而不需要大量特定训练者的数据。尽管一些方法结合了语言模型、扩散和流匹配，已经在零样本TTS中证明了它们的有效性，但仍然存在合成不可靠、实时性能差和计算开销大的问题。此外，时序多样性对于提高生成语音的自然度仍然未得到深入探索。
### Innovation
本文提出了Flamed-TTS，这是一种创新的零样本TTS框架，旨在实现低计算成本、低延迟和高语音保真度的同时，增加丰富的时序多样性。通过改进流匹配的训练方案，并结合离散和连续表示来对应语音的不同特征，Flamed-TTS在清晰度、自然度、保真度、声学特征保存和动态速度方面超越了现有最先进的模型。特别是在错误率上，Flamed-TTS达到了最低的4%，同时保持了较低的延迟和高质量的生成语音。
### Conclusion
实验结果证明，Flamed-TTS在多个关键指标上都超过了最先进的模型。Flamed-TTS通过减少计算资源消耗和提高生成语音的自然度，在零样本TTS领域展现出了显著的优势。该框架为未来零样本TTS的研究提供了一个新的方向，有望在实际应用中进一步提升语音合成的性能。
## 117. `cs.AI` - 解析变换器：绿色人工智能的 CLEAR 视角 [PDF](https://arxiv.org/pdf/2510.02810), [HTML](https://arxiv.org/abs/2510.02810)
### Authors
Hemang Jain,Shailender Goyal,Divyansh Pandey,Karthik Vaidhyanathan
### Background
大型语言模型（LLMs）的快速普及引发了重大环境关注。与一次性训练成本不同，LLM 推断在全世界范围内持续进行并现在主导了人工智能的能源足迹。然而，大多数可持续性研究仅报告粗略、模型级别的指标，由于缺乏细粒度的测量方法，更多地将能源效率视为次要目标，而不是主要目标。本文首次对变换器架构的核心组件进行细粒度的推断能耗实证分析，揭示了聚光注意块（Attention blocks）每浮点运算（FLOP）的能耗显著增加，表明能量消耗并不与FLOP计数成正比。
### Innovation
本文提出了一种名为 Component-Level Energy Assessment via Repeated sampling (CLEAR) 的新方法，以克服微秒尺度组件执行与毫秒级能量传感器监控之间的时间不匹配问题。使用 CLEAR 方法，评估了15个模型，涵盖了四种不同的架构类型，并保持了组件间能耗方差在9.5%以下，同时捕捉到超过模型总能耗的90%。研究表明聚光注意块每浮点运算的能耗显著增加，说明仅凭FLOPs无法在组件级别捕捉到真正的能耗成本。
### Conclusion
本文建立了详细的组件级别能耗基线，并为通过组件级别优化构建节能变换器模型提供了一步步之遥的初步见解。
## 118. `cs.AI` - 利用自我监督和层次深度学习融合多光谱和超光谱卫星数据进行有害藻华监测 [PDF](https://arxiv.org/pdf/2510.02763), [HTML](https://arxiv.org/abs/2510.02763)
### Authors
Nicholas LaHaye,Kelly M. Luis,Michelle M. Gierach
### Background
本文介绍了利用多传感器卫星数据检测和绘制有害藻华（HAB）严重性和种类的自我监督机器学习框架。框架结合了执行仪器（VIIRS，MODIS，Sentinel-3，PACE）反射率数据和TROPOMI太阳诱导荧光（SIF），在不需要每个仪器标签数据集的情况下生成HAB严重性和种类产品。该成果验证了美国墨西哥湾和南加州（2018-2025年）现场数据，结果显示与总浮游植物、Karenia brevis、 Alexandrium spp.以及Pseudo-nitzschia spp.测量结果高度一致。这项工作推进了在标签稀缺环境中的HAB监测，并通过层次嵌入实现探索性分析，是将自我监督学习应用于全球水生生物地球化学操作化的重要一步。
### Innovation
该论文提出的SIT-FUSE框架通过结合多传感器卫星数据（包括反射率和太阳诱导荧光）进行有害藻华的检测和物种分类，无需依赖于每个传感器的标签数据集，采用自我监督的表示学习和分层深度聚类，将浮游植物聚类为可解释的类别，并通过与现场数据的对比验证了其有效性。这种方法在标签稀缺环境下提供了可扩展的HAB监测手段，同时为探索性分析提供了层次嵌入方法，为自我监督学习在水生生物地球化学中的操作化奠定了基础。
### Conclusion
本文提出的方法为在标签稀缺环境中实现大规模有害藻华监测提供了一种有效的自我监督学习框架。通过验证来自墨西哥湾和南加州的实际数据，证明了该框架的准确性。此外，通过层次嵌入实现的探索性分析是将自我监督学习应用于全球水生生物地球化学的重要里程碑。
## 119. `cs.AI` - 工作区域挑战视觉语言模型轨迹规划：迈向缓解与稳健自动驾驶 [PDF](https://arxiv.org/pdf/2510.02803), [HTML](https://arxiv.org/abs/2510.02803)
### Authors
Yifan Liao,Zhen Sun,Xiaoyun Qiu,Zixiao Zhao,Wenbing Tang,Xinlei He,Xinhu Zheng,Tianwei Zhang,Xinyi Huang,Xingshuo Han
### Background
视觉语言模型（VLMs）凭借强大的多模态推理能力被多家汽车制造商引入自动驾驶中，以提升复杂环境下的规划能力。但这些模型在工作区域中的轨迹规划能力尚未被研究，而工作区域往往包含不规则布局、临时交通控制和动态变化的几何结构，这些特点对规划能力提出了更大挑战。
### Innovation
该研究首次系统地对Vision Language Models (VLMs) 在工作区域的轨迹规划能力进行了研究，揭示了主流VLMs在这方面的成功率仅为32%，并提出了REACT-Drive框架，结合了检索增强生成（RAG）算法，通过将先前的失败案例转化为约束规则和可执行的轨迹规划代码，以及从新场景中检索相似模式来引导轨迹生成，从而显著提高了轨迹规划的准确性和效率。
### Conclusion
实验结果显示，与VLM基线相比，REACT-Drive在使用Qwen2.5-VL评估时平均位移误差降低了3倍左右，在推理时间上也显著优于其他方法，如微调方法。在真实车辆上进行的15个工作区域场景实验进一步验证了REACT-Drive的实际应用价值。
## 120. `cs.AI` - 表征美丽：迈向参与但客观的潜在美学 [PDF](https://arxiv.org/pdf/2510.02869), [HTML](https://arxiv.org/abs/2510.02869)
### Authors
Alexander Michael Rusnak
### Background
机器是否能识美这一问题虽然美丽这一概念因文化与个体体验的不同而显得富有吸引力但在哲学上却难以界定，但随着深度学习系统在审美判断能力上表现出色，研究者们开始探索神经网络在大量具备不同形式的美丽对象中描绘美学能力。该研究通过借鉴跨模型表征一致性的最新成果，展示了非美学图像不产生更一致的表征，而美学内容却能够产生更一致和对齐的表征，进一步表明了美丽图像的形式结构具有实在论的基础，而不仅是社会构建值的反映。
### Innovation
研究提出了基于物理和文化基础的美学实在论，指出机器不仅仅是模仿者，能够在不同的尺度视角下产生独特的创新洞察。此外，研究强调人类感知和创造力在塑造深度学习系统潜在空间中的核心作用，表明人类与机器共同创造不仅是可能的，而是美学目标导向吸引理在文化生产和机器感知中的基础所在。
### Conclusion
人类与机器共同创造不仅是可能的，更是美学目标导向吸引力在文化生产和机器感知中的基石。美丽作为这种共创造过程中的驱动力，不仅能增加人类与机器之间的互动，还能够促进跨越不同尺度的独特创新。
## 121. `cs.AI` - 基于社交媒体的可解释文本性格评估的计算框架 [PDF](https://arxiv.org/pdf/2510.02811), [HTML](https://arxiv.org/abs/2510.02811)
### Authors
Matej Gjurković
### Background
个性是指个体在行为、思考和情感上的差异。随着数字足迹的增加，特别是社交媒体上的足迹，自动化的人格评估方法变得越来越重要。自然语言处理（NLP）使分析未结构化文本数据成为可能，以识别出个性指标。然而，大规模的标个性数据集稀缺，以及人格心理学与NLP之间的脱节，限制了模型的有效性和可解释性。为应对这些挑战，该论文提出了两个从Reddit收集的数据集——MBTI9k和PANDORA，涵盖了1700万条评论、从超过10000名用户那里收集，集成了MBTI和五大人格模型以及人口统计数据，克服了数据规模、质量和标签覆盖的限制。实验表明人口统计变量影响模型的有效性。
### Innovation
论文提出了两个新的数据集——MBTI9k和PANDORA，覆盖了大量的无名用户评论并整合了五大人格理论模型和人口统计信息。此外，论文还提出了SIMPA（Statement-to-Item Matching Personality Assessment）框架，这是一种可解释的人格评估框架，能够匹配用户生成的陈述与经过验证的问卷项目，利用机器学习和语义相似性，提升评估的准确性和解释性，比人类评估更具可比性，同时保持了高解释性和效率。SIMPA的模型兼容性、多层提示检测和可扩展性使其适用于涉及复杂标签分类和涉及目标概念的提示关联的研究和实际应用中。
### Conclusion
尽管专注于人格评估，但SIMPA的通用性远超这一领域。其模型兼容性、层次提示检测和可扩展性使其适用于各种涉及复杂标签分类和提示与目标概念关联的研究和实际应用。
## 122. `cs.AI` - DMark：不依赖顺序的Diffusion大语言模型水印方法 [PDF](https://arxiv.org/pdf/2510.02902), [HTML](https://arxiv.org/abs/2510.02902)
### Authors
Linyu Wu,Linhao Zhong,Wenjie Qu,Yuexin Li,Yue Liu,Shengfang Zhai,Chunhua Shen,Jiaheng Zhang
### Background
现有水印方法难以应用于扩散大语言模型（dLLMs），因为它们不遵循顺序解码，这打破了传统水印依赖的因果设计。与自回归模型自左向右生成词元不同，dLLMs可在任何顺序完成词元，使得现有水印失效。
### Innovation
DMark是一个专为dLLMs设计的第一个水印框架，引入了三种互补策略恢复水印的可检测性：预测水印使用模型预测的词元；双向水印利用扩散解码中的前后向依赖关系；预测双向水印结合了这两种方法以最大化检测强度。
### Conclusion
实验表明，DMark在1%的误报率下达到了92.0-99.5%的检测率，同时保持了文本质量，而现有的简单 adaptation 只能达到49.6-71.2%的检测率。DMark还展示了对文本操作的鲁棒性，证明了有效水印对于非自回归语言模型是可行的。
## 123. `cs.AI` - 帕累托最优的非均匀语言生成 [PDF](https://arxiv.org/pdf/2510.02795), [HTML](https://arxiv.org/abs/2510.02795)
### Authors
Moses Charikar,Chirag Pabbaraju
### Background
基林伯格和穆利讷桑（2024）提出了一个语言生成模型，在该模型中，给定一个可数集合的语言，并且有对手按照某种语言$L$的字符串列表进行枚举，目标是从目标语言生成新字符串，使得从某个有限时间点开始生成的所有字符串都是有效的。李、拉马南和特瓦里（2024）以及查里克尔和帕巴拉朱（2024）已经展示了此模型中强的非均匀生成保证，提出了一种算法：在看到特定数量的不同的输入字符串$t(L)$后（仅取决于$L$和集合，而不取决于枚举顺序），能够生成新的有效字符串。然而，对于这两种工作，算法对于某些语言$L$的生成时间$t(L)$可能会比最优解严格差。
### Innovation
本文研究了非均匀语言生成的帕累托最优性。我们提出了一种算法，其生成时间为$t^text{∗}(L)$，几乎达到了帕累托最优标准：对于任何其他生成时间在某些语言$L$上比$t^text{∗}(L)$更小的算法来说，其在其他语言$L'$上的生成时间必然更差。帕累托最优性是对于非均匀生成所能达到的最佳结果。我们的算法框架还能进一步适应噪声和代表性生成的现实场景。
### Conclusion
本文提出了一个算法框架，确保算法能够在给定的语言集合中达到帕累托最优，同时适应噪声和代表性生成等实际场景需求。
## 124. `cs.AI` - Hierarchical Generalized Category Discovery for Brain Tumor Classification in Digital Pathology [PDF](https://arxiv.org/pdf/2510.02760), [HTML](https://arxiv.org/abs/2510.02760)
### Authors
Matthias Perkonigg,Patrick Rockenschaub,Georg Göbel,Adelheid Wöhrer
### Background
准确的大脑肿瘤分类对于神经肿瘤手术中的术中决策至关重要。然而，现有的方法仅限于固定的预定义分类，无法捕获训练期间未出现的肿瘤类型模式。无监督学习可以提取一般特性，但缺乏从标记数据中整合先验知识的能力，而半监督方法通常假设所有潜在类别在标记数据中都有代表。为了解决这一问题，Generalized Category Discovery (GCD)旨在通过在未标记数据中分类已知和未知类别来弥合这一差距。为了反映大脑肿瘤分类学的层次结构，本文提出了一种新的方法——Hierarchical Generalized Category Discovery for Brain Tumor Classification (HGCD-BT)，该方法结合了层次聚类和对比学习。该方法通过引入新颖的半监督层次聚类损失来扩展基于对比学习的GCD方法，从而更好地适应层次结构分类任务。HGCD-BT在OpenSRH数据集上的评估表明，与最先进的GCD方法相比，其在斑块级分类中的准确率提高了28%，特别是在识别之前未见过的肿瘤类别方面具有显著优势。此外，还在Digital Brain Tumor Atlas数据集上的组织切片级分类中验证了该方法的普适性，确认其在不同成像模式下的适用性。
### Innovation
提出的HGCD-BT方法通过结合层次聚类和对比学习来解决现有的GCD方法在处理未知肿瘤类别和层次结构分类任务上的限制。具体地，该方法引入了一种新的半监督层次聚类损失，以增强对比学习和层次聚类的结合效果，从而能够更好地区分已知和未知的肿瘤类别，提高分类的准确性和适用范围。此外，该方法在多种不同成像模式下的表现进一步验证了其普适性和可靠性。
### Conclusion
提出了一种新的方法——Hierarchical Generalized Category Discovery for Brain Tumor Classification (HGCD-BT)，该方法通过结合层次聚类和对比学习来解决肿瘤分类中的未知类别问题和层次结构需求。HGCD-BT在斑块级别的OpenSRH数据集和组织切片级别的Digital Brain Tumor Atlas数据集上的表现优于现有方法，特别是在识别和分类未知肿瘤类别时展现了显著性能提升，证明了其在不同成像模式下的普适性和可靠性。
## 125. `cs.AI` - 熵正则化线性二次控制在乘性噪声下的策略梯度全球收敛性 [PDF](https://arxiv.org/pdf/2510.02896), [HTML](https://arxiv.org/abs/2510.02896)
### Authors
Gabriel Diaz,Lucky Li,Wenhao Zhang
### Background
强化学习（RL）已经成为动态环境中序列决策的强大框架，特别是在系统参数未知的情况下。本文研究了熵正则化的线性二次控制（LQC）问题在无限时间范围内的强化学习（RL）控制方法，特别是在存在乘性噪声的情况下。
### Innovation
本文创新地提出了Sample-Based Regularized Policy Gradient（SB-RPG）算法，这是一种无需知道系统参数的模型自由的RL算法。SB-RPG算法证明了在满足梯度支配和接近光滑条件下，尽管问题具有非凸性，也能全局收敛。此外，通过熵正则化加速了算法的收敛速度，并解决了RL中探索与利用的权衡问题。
### Conclusion
数值模拟结果验证了理论分析结果，并表明SB-RPG在未知参数环境中有效地解决了线性二次控制问题，特别是存在乘性噪声情况下。
## 126. `cs.AI` - FeDABoost：适应性加权的公平感知联邦学习 [PDF](https://arxiv.org/pdf/2510.02914), [HTML](https://arxiv.org/abs/2510.02914)
### Authors
Tharuka Kasthuri Arachchige,Veselka Boeva,Shahrooz Abghari
### Background
该工作关注在非IID（独立同分布）场景下改进联邦学习（FL）的性能和公平性。为了提高模型聚合的效果，并改善表现不佳的客户端，研究提出了一种名为FeDABoost的新颖FL框架，它结合了动态加权机制和自适应梯度聚合策略。
### Innovation
FeDABoost的核心创新在于它引入了一种动态加权机制和自适应梯度聚合策略。通过参考Multiclass AdaBoost（SAMME）算法的加权机制，其聚合方法对本地误差率较低的客户端赋予更高的权重，从而促进模型更可靠地贡献。同时，该框架还针对表现不佳的客户端动态调整了聚焦损失参数，强调在本地训练中更难以分类的样本，以提高其性能和公平性。
### Conclusion
FeDABoost已在三个基准数据集（MNIST、FEMNIST和CIFAR10）上进行了评估，并将其性能与FedAvg和Ditto进行了比较。实验结果表明，FeDABoost在公平性和性能方面表现出了改进和竞争力。
## 127. `cs.AI` - Ergodic Risk Measures: Towards a Risk-Aware Foundation for Continual Reinforcement Learning [PDF](https://arxiv.org/pdf/2510.02945), [HTML](https://arxiv.org/abs/2510.02945)
### Authors
Juan Sebastian Rojas,Chi-Guhn Lee
### Background
持续强化学习（continual RL）旨在形式化终身学习和无限适应的概念。目前，持续强化学习在无风险决策视角下得到了广泛的探索，其中目标是优化长期性能的期望值。然而，现有的非持续强化学习中的风险度量理论并不适用于持续学习环境，需要建立一种新的理论框架来支持风险感知的持续强化学习。
### Innovation
本工作首次通过风险感知决策的角度，为持续强化学习建立了正式的理论框架。论文指出，当前用于非持续强化学习的风险度量理论在持续学习环境下不兼容。因此，论文引入了一类新的符合持续学习的遍历风险度量，该理论扩展了风险度量理论，使其适用于持续强化学习。最后，论文通过案例研究和实验结果展示了遍历风险度量的直观吸引力和理论正确性，为风险感知的持续强化学习奠定了基础。
### Conclusion
通过引入遍历风险度量，论文为风险感知视角下的持续强化学习提供了新的理论支持。遍历风险度量能够更好地适应持续学习中的长期性能度量，而不仅仅局限于期望值。这些新的方法和理论框架为未来的持续强化学习研究提供了新的视角和工具。
## 128. `cs.AI` - 将大型语言模型扎根于临床证据：一种用于查询英国NICE临床指南的检索增强生成系统 [PDF](https://arxiv.org/pdf/2510.02967), [HTML](https://arxiv.org/abs/2510.02967)
### Authors
Matthew Lewis,Samuel Thio,Richard JB Dobson,Spiros Denaxas
### Background
英国国家卫生与临床卓越研究所（NICE）的临床指南内容丰富但篇幅较长，这在时间紧迫的医疗系统中限制了其利用率。本研究开发了一个基于大型语言模型（LLM）的检索增强生成（RAG）系统，旨在通过创建一个能够根据自然语言查询为用户提供精确信息的系统来解决这一问题。
### Innovation
该研究开发并评估了一个RAG系统，以查询英国NICE临床指南中的信息。系统采用了一种由混合嵌入机制组成的检索架构，并在包含10,195个文本片段的数据集上进行了评估，这些文本片段来自三百份指南。此外，该系统在生成阶段表现出显著效果，增强了模型的忠实度，这表明RAG系统能够通过将答案接地于相关来源材料来防止信息篡改。
### Conclusion
该研究证明了RAG系统在医疗保健领域应用生成式人工智能的有效性、可靠性和可扩展性，从而提供了一种成本效益高的访问医学指南的方式。
## 129. `cs.AI` - 由AI生成的儿童性虐待材料-有什么危害？ [PDF](https://arxiv.org/pdf/2510.02978), [HTML](https://arxiv.org/abs/2510.02978)
### Authors
Caoilte Ó Ciardha,John Buckley,Rebecca S. Portnoff
### Background
随着生成型人工智能工具（能够生成全真或部分合成儿童性虐待材料（AI CSAM））的发展，这对于儿童保护、执法和对儿童剥削的社会回应提出了严峻挑战。尽管有观点认为AI CSAM因其表面上不存在直接的受害者而与传统CSAM在危害性上有根本的不同，但这种观点并未顾及AI CSAM在制造和消费过程中的各种风险。AI CSAM涉及到未被虐待儿童的合成内容、已知受害者的重新受害者化、诱骗、胁迫和性勒索的促进，以及儿童性剥削的正常化。此外，AI CSAM可能提供了一条新的或增强的犯罪途径，降低了参与门槛，使用户逐步接触到极端的内容，并削弱了对儿童性兴趣个体的保护因素。
### Innovation
该论文介绍了几种关键技术，并深入探讨了AI CSAM相关的各种危害，强调了声称AI CSAM可以作为减少危害工具的论点掩盖了其真实风险，并可能阻碍生态系统对这一问题的应对措施。
### Conclusion
论文警示，不应将AI CSAM视为减少危害的工具，并强调一些对无害性的声称掩盖了其实际风险，可能妨碍生态系统对这一问题的应对。
## 130. `cs.AI` - WavInWav: 通过可逆神经网络的时域语音隐写 [PDF](https://arxiv.org/pdf/2510.02915), [HTML](https://arxiv.org/abs/2510.02915)
### Authors
Wei Fan,Kejiang Chen,Xiangkun Wang,Weiming Zhang,Nenghai Yu
### Background
数据隐藏对于数字媒体中的安全通信至关重要，近年来，深度神经网络（DNNs）的发展为有效嵌入秘密信息提供了增强方法。然而，之前的音频隐藏方法在恢复秘密音频时往往效果不佳，因为它们在时间-频率关系建模方面存在内在缺陷。本文探讨了这些局限性，并提出了一种新的基于DNN的方法。我们使用基于流的可逆神经网络直接链接隐写音频、原始音频和秘密音频，增强了嵌入和提取消息的可逆性。为了应对时间-频率变换中常见的问题，这些问题会降低秘密音频的质量，在恢复过程中，我们实施了时间-频率损失函数在时域信号上，从而保留了时间-频率约束的优点，同时也增强了消息恢复的可逆性，这对于实际应用尤为重要。我们还加入了一种加密技术以保护隐藏数据免受未授权访问。在VCTK和LibriSpeech数据集上的实验结果表明，我们的方法在主观和客观指标上优于前人方法，并对各种类型的噪声具有鲁棒性，表明其在目标安全通信场景中的实用性
### Innovation
1. 使用基于流的可逆神经网络直接链接隐写音频、原始音频和秘密音频，增强嵌入和提取消息的可逆性。2. 在时域信号上实施时间-频率损失函数，以应对时间-频率变换过程中对秘密音频质量的负面影响。3. 加入加密技术以保护隐藏数据免受未授权访问。
### Conclusion
我们的方法在VCTK和LibriSpeech数据集上的实验结果表明，它在主观和客观指标上优于前人方法，对各种类型的噪声具有鲁棒性。这表明它在目标安全通信场景中具有实用性。
## 131. `cs.AI` - 从不精确监督学习鲁棒扩散模型 [PDF](https://arxiv.org/pdf/2510.03016), [HTML](https://arxiv.org/abs/2510.03016)
### Authors
Dong-Dong Wu,Jiacheng Cui,Wei Wang,Zhiqiang She,Masashi Sugiyama
### Background
近年来，条件扩散模型在各种生成任务中取得了显著的成果，但它们的训练通常依赖于大规模的数据集，这些数据集中的条件输入往往是不精确或含有噪声的。这些不精确的监督信息可能导致条件不匹配，从而降低生成的质量。
### Innovation
该论文提出了DMIS，一种训练具有鲁棒性的扩散模型的统一框架。DMIS 是对扩散模型中首个系统性的研究，旨在解决不精确监督带来的挑战。该框架通过极大化似然性进行训练，并将目标拆分为生成和分类两个部分：生成部分模拟不精确标签的分布，分类部分利用扩散分类器推断类后验概率，同时通过优化的时间步长采样策略提高了效率。
### Conclusion
广泛的实验表明，DMIS 在不同形式的不精确监督下能够生成高质量且具有区分性的样本，包括图像生成、弱监督学习和噪声数据集凝练任务。
## 132. `cs.AI` - 无目标 jailbreak 攻击 [PDF](https://arxiv.org/pdf/2510.02999), [HTML](https://arxiv.org/abs/2510.02999)
### Authors
Xinzhe Huang,Wenjing Hu,Tianhang Zheng,Kedong Xiu,Xiaojun Jia,Di Wang,Zhan Qin,Kui Ren
### Background
现有的基于梯度的 jailbreak 攻击方法，如 GreedyCoordinate Gradient (GCG) 和 COLD-Attack，通常优化对抗后缀以使大型语言模型 (LLM) 的输出与预定义的目标响应一致。然而，这些方法通过将优化目标限制为引发预定义的响应，从而限制了敌对搜索空间，影响了整体攻击效果。此外，现有的方法通常需要大量的优化迭代来弥补固定目标和原始模型响应之间的巨大差距，导致攻击效率低下。
### Innovation
该研究提出了一种无目标的基于梯度的 jailbreak 攻击 (UJA)，旨在促使 LLM 产生不安全的响应，而不强制执行任何预定义的模式。具体来说，通过制定一个无目标的攻击目标来最大化 LLM 响应的不安全概率，该概率可以通过判别模型量化。由于目标是非可微的，进一步将其分解为两个可微的子目标，分别优化最优有害响应及其相应的对抗前缀，提供了分解的理论分析以验证这一点。与有目标的 jailbreak 攻击相比，UJA 的无限制目标显著扩展了搜索空间，允许更灵活和高效的 LLM 探索。
### Conclusion
textsc{UJA} 在仅 100 次优化迭代就能实现超过 80% 的攻击成功率，针对最近的安全对齐的大语言模型，相对于最先进的基于梯度的攻击（如 I-GCG 和 COLD-Attack）有着超过 20% 的性能提升。
## 133. `cs.AI` - 遗产保护中的腐蚀风险估计：基于温度和湿度的物联网和机器学习方法 [PDF](https://arxiv.org/pdf/2510.02973), [HTML](https://arxiv.org/abs/2510.02973)
### Authors
Reginald Juan M. Mercado,Muhammad Kabeer,Haider Al-Obaidy,Rosdiadee Nordin
### Background
文化重要遗产地点如菲律宾圣塞巴斯蒂安大教堂的钢结构保护需要准确的腐蚀预测。因此，研究开发了一种与LoRa无线通信连接的物联网硬件系统，用于监测具有钢结构的遗产建筑。通过物联网系统生成的三年数据集，构建了仅使用温度和相对湿度数据的机器学习框架，以预测大气中的腐蚀率。该框架通过Streamlit仪表板和ngrok隧道供公众访问，可提供实时腐蚀监测和可行的保护建议。
### Innovation
开发了一种基于LoRa无线通信的物联网硬件系统，结合机器学习框架，仅使用温度和相对湿度数据即可预测钢结构遗产建筑的腐蚀率。通过Streamlit仪表板提供实时腐蚀监控，并通过ngrok隧道实现公共访问，提供实时的腐蚀监测和保护建议。该方法为资源有限的遗产站点提供了可扩展且成本效益高的监测方案，证明了高级回归可以从基本气象数据中提取准确的腐蚀预测，从而促进全球重要文化的保护，而无需广泛的传感器网络。
### Conclusion
该最小数据方法是可扩展且成本效益高的，适用于资源有限的遗产站点。通过简单的气象数据，高级回归方法能够提供准确的腐蚀预测，从而实现对全球重要文化和历史结构的主动保护，无需复杂传感器网络。
## 134. `cs.AI` - CHORD: 利用设备-云协作定制混合精度离线模型进行序列推荐 [PDF](https://arxiv.org/pdf/2510.03038), [HTML](https://arxiv.org/abs/2510.03038)
### Authors
Tianqi Liu,Kairui Fu,Shengyu Zhang,Wenyan Fan,Zhaocheng Du,Jieming Zhu,Fan Wu,Fei Wu
### Background
随着移动设备功能的提升，直接部署排序模型在设备上成为可能，这使得实时上下文推荐成为现实。然而，将模型从云端迁移到设备时，资源异质性不可避免地需要进行模型压缩。虽然最近的量化方法为高效部署提供了希望，但它们忽视了设备特定的用户兴趣，导致推荐准确性降低。在设备上进行微调可以捕捉个性化用户偏好，但也通过本地重新训练带来了额外的计算负担。
### Innovation
本文提出了一种利用通道混合精度量化来同时实现个性化和资源适配部署的框架（CHORD），该框架通过利用云上的辅助超网络模块在网络初始化阶段识别用户特定的关键参数。参数敏感性分析在多级粒度（层、滤波器和元素级别）上进行，以精确映射用户画像到量化策略。CHORD通过设备上混合精度量化提供动态模型适应和加速推理，无需反向传播，从而避免了昂贵的重新训练周期。通过仅使用2位通道来编码量化策略，CHORD减少了通信开销。
### Conclusion
实验结果在三个现实世界数据集上使用两种流行的骨干网络（SASRec和Caser）展示了CHORD的准确度、高效性和适应性。
## 135. `cs.AI` - 零采样优化：迈向高效黑盒优化的零样本预训练模型 [PDF](https://arxiv.org/pdf/2510.03051), [HTML](https://arxiv.org/abs/2510.03051)
### Authors
Jamison Meindl,Yunsheng Tian,Tony Cui,Veronika Thost,Zhang-Wei Hong,Johannes Dürholt,Jie Chen,Wojciech Matusik,Mina Konaković Luković
### Background
全球优化需要极端样本效率来应对昂贵且无导数的黑盒函数。当前最先进方法是贝叶斯优化(BO)，但其性能依赖于需要手动调整且难以泛化的代理模型和获取函数超参数。
### Innovation
提出了一种名为ZeroShotOpt的通用预训练模型，适用于从2D到20D的连续黑盒优化任务。该模型通过大规模优化轨迹的离线强化学习训练，利用生成的具有多样化景观的百万个合成高斯过程函数进行预训练，学习迁移优化政策，从而在未知基准上实现稳健的零样本泛化，匹配或超越领先全局优化器的样本效率。
### Conclusion
ZeroShotOpt为未来扩展和改进提供了可重用的基础。其开源代码、数据集和模型已发布。
## 136. `cs.AI` - 从高频传感器到中午报告：利用迁移学习在海上轴功率预测中的应用 [PDF](https://arxiv.org/pdf/2510.03003), [HTML](https://arxiv.org/abs/2510.03003)
### Authors
Akriti Sharma,Dogan Altan,Dusica Marijan,Arnbjørn Maressa
### Background
随着全球海上运输的增长，能源优化变得至关重要，这有助于降低运营成本并确保高效运作。轴功率是发动机传输到螺旋桨的机械功率，直接关系到燃料消耗，因此准确预测轴功率是船舶性能优化的关键步骤。轴功率与船速、螺旋桨每分钟转速以及天气和海况等参数密切相关。频繁获取这些操作数据可以提高预测准确性。然而，获取高质量的传感器数据常常不可行且成本高昂，因此可以使用中午报告作为替代数据源。
### Innovation
本文提出了一种基于迁移学习的方法来预测船舶轴功率。初始模型在高频数据上训练，然后通过低频的每日中午报告进行细调。实验对象包括姐妹船（尺寸和配置相同）、类似船舶（稍大且发动机不同）和不同船舶（尺寸和配置不同）。结果表明，与仅使用中午报告数据训练的模型相比，对于姐妹船，平均绝对百分比误差减少了10.6%；对于类似船舶，减少了3.6%；对于不同船舶，减少了5.3%。
### Conclusion
本研究采用了迁移学习方法，通过从高频数据到低频中午报告的训练过程，提出了一种预测船舶轴功率的新方法，并通过实际船舶的数据验证了其有效性，显著提高了预测准确性。
## 137. `cs.AI` - BrainIB++：利用图神经网络和信息瓶颈方法在精神分裂症中的功能性脑生物标志物 [PDF](https://arxiv.org/pdf/2510.03004), [HTML](https://arxiv.org/abs/2510.03004)
### Authors
Tianzheng Hu,Qiang Li,Shu Liu,Vince D. Calhoun,Guido van Wingen,Shujian Yu
### Background
在精神疾病领域，开发诊断模型正在受到关注。基于静息态功能磁共振成像(rs-fMRI)的机器学习分类器已经被开发出来，用于识别能够区分精神疾病和健康对照的脑生物标志物。然而，传统的基于机器学习的诊断模型常常依赖于大量的特征工程，这会因手动干预而引入偏差。尽管深度学习模型预期能够不需要手动干预运行，但它们的可解释性差严重阻碍了产生可解释和可靠的脑生物标志物，进而支持诊断决策，最终限制了其临床应用。
### Innovation
本文介绍了一种名为BrainIB++的端到端创新图神经网络框架，该框架利用信息瓶颈(IB)原则，在模型训练期间识别出最重要的数据驱动脑区子图，以便于解释。该模型在三种多队列精神分裂症数据集中与九种现有的脑网络分类方法进行了对比评估，其诊断准确性表现出优越性，并且具有对未见数据的泛化能力。所识别的子图还与精神分裂症的已知临床生物标志物对应，特别是在视觉、传感器运动和高阶认知功能网络方面强调了异常情况，这不仅增强了模型的可解释性，还突显了其在实际诊断应用中的相关性。
### Conclusion
BrainIB++模型在诊断准确性方面表现优异，具有良好的泛化能力，并且其识别的脑区子图具有与精神分裂症已知临床生物标志物的对应性，突显了模型在实际诊断应用中的价值。
## 138. `cs.AI` - 一种用于足够接近旅行商问题的统一深度强化学习方法 [PDF](https://arxiv.org/pdf/2510.03065), [HTML](https://arxiv.org/abs/2510.03065)
### Authors
Mingfeng Fan,Jiaqi Cheng,Yaoxin Wu,Yifeng Zhang,Yibin Yang,Guohua Wu,Guillaume Sartoretti
### Background
近年来，深度强化学习（DRL）在解决NP难旅行商问题（TSP）方面逐渐占据优势。然而，关于近似旅行商问题（CETSP）的研究较少，这主要是由于其基于邻域访问准则的挑战，即节点在代理进入其紧凑邻域内时被视为被访问。
### Innovation
本文提出了一个用离散方案制定的CETSP马尔可夫决策过程（MDP）模型，并提出了一种新型的统一双解码器DRL（UD3RL）框架，将决策分为节点选择和路径点确定两个子任务。此外，还引入了一种最近邻子图交互策略，以增强位置解码过程中的空间推理能力。为使UD3RL模型能够适应不同规模的问题和不同类型的邻域半径（常数和随机半径），本文定制了REINFORCE算法进行训练。
### Conclusion
实验结果表明，UD3RL在解决方案质量和运行时间方面都优于传统方法，同时在问题规模、空间分布和半径范围等方面表现出较强的泛化能力，对动态环境具有较强的鲁棒性。
## 139. `cs.AI` - 参数化动作Actor-Critic强化学习算法在网页搜索匹配计划生成中的比较分析 [PDF](https://arxiv.org/pdf/2510.03064), [HTML](https://arxiv.org/abs/2510.03064)
### Authors
Ubayd Bapoo,Clement N Nyirenda
### Background
该研究评估了Soft Actor Critic (SAC)、Greedy Actor Critic (GAC)和Truncated Quantile Critics (TQC)在完全可观测环境下的高维决策任务中的性能，特别是针对参数化动作（PA）空间，无需使用递归网络，使用了Platform-v0和Goal-v0基准测试具有离散动作的持续动作-参数空间。通过Microsoft NNI进行超参数优化，确保了GAC和TQC代码库的修改以保证可重复性。
### Innovation
研究引入了Parameterized Action Greedy Actor-Critic (PAGAC)算法，并展示了其实现在平台游戏和足球机器人目标游戏中的最佳训练时间和回报。PAGAC在复杂动作空间中表现出更快的速度和更高的稳定性，显示出在要求快速收敛和稳定性能的任务中更具优势。未来的研究计划探索结合熵正则化与截断基方法的混合策略，以增强稳定性和扩大泛化研究的范围。
### Conclusion
PAGAC算法在实验中表现出了最佳的效率和可靠性，特别是在Platform和Robot Soccer Goal任务中，从而为需要快速收敛和稳定性能的任务提供了一种理想的选择。
## 140. `cs.AI` - 探究 LLM 生成代码中的异味 [PDF](https://arxiv.org/pdf/2510.03029), [HTML](https://arxiv.org/abs/2510.03029)
### Authors
Debalina Ghosh Paul,Hong Zhu,Ian Bayley
### Background
大型语言模型（LLMs）被越来越多地用于生成程序代码。尽管在生成代码的功能正确性方面有许多研究，但对于代码质量的研究却较少。本研究针对生成代码的质量进行了研究。
### Innovation
本文提出了一种基于场景的方法来评估 LLM 生成代码的质量。通过测量代码异味（代码质量的重要指标），并与参考解决方案进行比较，将测试数据集分为不同子集以代表不同使用场景。此外，还开发了一个自动测试系统来评估更多复杂任务和高级话题（如面向对象概念）下的代码异味，并对四种最先进的 LLM 进行了实验。
### Conclusion
在代码异味方面，LLM 的性能与相应场景中人类编写代码的质量高度相关。然而，LLM 生成的代码质量明显逊于人类编写的代码。
## 141. `cs.AI` - 馏分蛋白质 Backbone 生成 [PDF](https://arxiv.org/pdf/2510.03095), [HTML](https://arxiv.org/abs/2510.03095)
### Authors
Liyang Xie,Haoran Zhang,Zhendong Wang,Wesley Tansey,Mingyuan Zhou
### Background
蛋白质结构的设计已经使用了基于扩散和流的生成模型，这些模型在蛋白质骨架生成任务中展现了强大的性能，但其生成速度受限于逆向扩散过程中的大量迭代步骤，导致它们在大规模蛋白质发现中的实用性受限。
### Innovation
研究了评分蒸馏技术，这种技术在视觉领域已被证明可以减少采样步骤数量，同时保持高的生成质量。通过一系列实验，将最先进的评分身份蒸馏（SiD）策略适配到训练有限步骤的蛋白质骨架生成器，显著减少了采样时间，同时保持了与预训练教师模型相当的性能。特别地，结合多步生成和推理时间噪声调节是关键。
### Conclusion
我们蒸馏的有限步骤生成器实现了采样速度超过20倍的提升，同时保持与Proteina教师模型相当的设计灵活性、多样性和新颖性。这降低了推理成本，促进了大规模的在硅中蛋白质设计，使得基于扩散的模型更接近实际的蛋白质工程应用。
## 142. `cs.AI` - 言语情感识别中的语义区分：描述性言语与表达性言语的角色洞察 [PDF](https://arxiv.org/pdf/2510.03060), [HTML](https://arxiv.org/abs/2510.03060)
### Authors
Rongchen Guo,Vincent Francoeur,Isar Nejadgholi,Sylvain Gagnon,Miodrag Bolic
### Background
言语情感识别（SER）对于改善人机互动至关重要，但其准确性受限于语音中情感细微差别的复杂性。
### Innovation
区分描述性语义和表达性语义，前者代表语音的上下文内容，后者反映说话者的心理状态；通过记录参与者观看情感浓郁的电影片段后的描述性音频剪辑，包含每个剪辑对应的预期情感标签、参与者自我评价的情感反应及其正性/激动评分；实验证明了描述性语义与预期情感一致，而表达性语义与引发的情感相关。
### Conclusion
研究结果为SER在人机交互中的应用提供了指导，并为更具备上下文感知能力的人工智能系统铺平了道路。
## 143. `cs.AI` - 神经极化解码器在通信中的研究 [PDF](https://arxiv.org/pdf/2510.03069), [HTML](https://arxiv.org/abs/2510.03069)
### Authors
Rom Hirsch,Ziv Aharoni,Henry D. Pfister,Haim H. Permuter
### Background
先前的研究表明，神经极化解码器（NPDs）在合成信道中的有效性，但是尚未将其扩展应用于实际的通信系统。本文探讨并分析如何将NPDs适应并应用于端到端的通信系统，包括OFDM和单载波通信系统，以满足实际系统的各种需求，如任何码长、高级调制方式以及多样性信道条件下的鲁棒性。此外，NPD可以直接处理具有记忆效应的信道，利用其结构提高数据传输速率，而不需使用导频和循环前缀。尽管与标准5G极化解码器相比，NPD的计算复杂性更高，但其神经网络架构能有效表示信道统计，带来可管理的复杂性，适用于实际系统。
### Innovation
本文的主要创新在于将NPDs扩展应用于实际通信系统，特别是OFDM和单载波系统，并通过率匹配、高级调制方式和信道多样性支持任何码长。NPD能够直接处理具有记忆效应的信道，不依赖于导频和循环前缀，从而在计算复杂性和系统性能之间找到平衡，最终表现出比5G标准极化解码器更高的性能，特别是在低码率和短块配置中，这些配置在5G控制信道中很常见。此外，NPD在单载波系统中的性能与OFDM系统相当，甚至具有更低的PAPR，使得在5G信道上有效传输单载波成为可能。
### Conclusion
实验结果表明，NPD在5G信道中始终在BER、BLER和吞吐量方面优于5G标准极化解码器，特别是在低码率和短块配置中。进一步研究发现，NPD为试点无、高效且鲁棒的解码解决方案，为实际通信系统提供了高性能的替代方案。
## 144. `cs.AI` - 大型视觉语言模型在颈动脉风险分层中的多模态基准测试、微调及临床见解 [PDF](https://arxiv.org/pdf/2510.02922), [HTML](https://arxiv.org/abs/2510.02922)
### Authors
Daphne Tsolissou,Theofanis Ganitidis,Konstantinos Mitsis,Stergios CHristodoulidis,Maria Vakalopoulou,Konstantina Nikita
### Background
可靠地评估颈部动脉粥样硬化疾病的风险仍然是临床的一大挑战，因为这需要将多种临床和影像信息以透明且易理解的方式整合。本研究探索了当前最先进的和较新的大型视觉语言模型（LVLMs）在将超声影像（USI）与结构化临床、人口统计学、实验室和蛋白质生物标志数据整合以评估颈动脉斑块方面的潜在应用。
### Innovation
该研究提出了一种模拟现实诊断场景的框架，通过面试式问题序列比较多种开源LVLM，涵盖通用和医疗专用模型。零样本实验表明，尽管这些模型非常强大，但它们在准确识别影像模态和解剖位置及风险分类准确性的表现不佳。为了解决这一限制，LLaVa-NeXT-Vicuna 经过低秩适应 (LoRA) 后，增强了中风风险分层。通过将多模态表格数据以文本形式整合，提高了特定性和平衡准确率，表现优于以前基于同一数据集训练的卷积神经网络（CNN）基准。
### Conclusion
我们的研究结果强调了LVLMs在基于超声的心血管风险预测中的潜力和局限性，突出了多模态整合、模型校准和领域适应对于临床转化的重要性。
## 145. `cs.AI` - 基于路径签名的注意力转换器在资产配置中的应用 [PDF](https://arxiv.org/pdf/2510.03129), [HTML](https://arxiv.org/abs/2510.03129)
### Authors
Yoontae Hwang,Stefan Zohren
### Background
在量化金融中，稳健的资产配置是一个关键挑战。基于深度学习的方法常常因为目标不匹配和误差放大而失败。传统的方法和基于深度学习的模型在资产配置上的表现都不尽如人意，特别是当与预测-然后优化的模型比较时，更是显得不足。研究人员需要设计新的方法来克服这些限制，提高资产配置的准确性与稳定性，尤其是在风险管理和资本分配方面。
### Innovation
本文提出了Signature-Informed Transformer (SIT)，这是一种新型框架，通过直接优化风险感知的财务目标来学习端到端的分配策略。SIT的核心创新包括路径签名（用于丰富的资产动态几何表示）和基于路径签名的注意力机制（嵌入了金融推理偏置，如领先-滞后效应），使模型更好地理解复杂的金融市场动力学。实验结果表明，SIT 在每日 S&P 100 股票数据上显著优于传统方法和基于深度学习的方法，特别是在与预测-然后优化模型比较时。这些结果表明，目标感知和几何感知的推理偏置对于机器学习系统在风险管理下的资本分配至关重要。
### Conclusion
这些结果证明了基于SIT框架的资产配置方法的有效性和优越性，特别是在严格的风险管理下。然而，研究也指出，在实际应用中仍需进一步探索和改进，特别是在处理更复杂的金融市场动态时。此外，模型的泛化能力还需要进一步测试，以确保在不同市场条件下的一致性表现。
## 146. `cs.AI` - HAVIR：使用CLIP引导的多样化扩散级联视觉到图像重建 [PDF](https://arxiv.org/pdf/2510.03122), [HTML](https://arxiv.org/abs/2510.03122)
### Authors
Shiyi Zhang,Dong Liang,Hairong Zheng,Yihang Zhou
### Background
从脑活动重建视觉信息促进了神经科学与计算机视觉的跨学科整合。然而，现有方法在准确恢复复杂视觉刺激时仍然面临挑战。这种困难源于自然场景的特性：低层次特征表现出异质性，而高层次特征由于上下文重叠而表现出语义纠缠。现有的重建方法难以同时捕捉这些多层次和复杂的特征。
### Innovation
受视皮层分层表示理论的启发，提出了HAVIR模型。该模型将视觉皮层分为两个分层区域，从每个区域提取不同的特征。详细的生成器从空间处理体素中提取结构信息并转换为潜在扩散先验，而语义提取器将语义处理体素转换为CLIP嵌入。这些组件通过多功能扩散模型综合，以最终生成图像。实验结果表明，HAVIR提高了复杂场景下重建的结构和语义质量，优于现有模型。
### Conclusion
HAVIR通过分层处理自然场景的低层次和高层次特征，显著提升了复杂场景下图像重建的质量和语义精度，并且在实验中超越了现有模型。
## 147. `cs.AI` - 在视觉生成模型中促进组合泛化的驱动力是什么？ [PDF](https://arxiv.org/pdf/2510.03075), [HTML](https://arxiv.org/abs/2510.03075)
### Authors
Karim Farid,Rajat Sahay,Yumna Ali Alnaggar,Simon Schrodi,Volker Fischer,Cordelia Schmid,Thomas Brox
### Background
组合泛化能力，即生成已知概念的新组合，是视觉生成模型的关键要素。然而，并非所有促进或抑制这一能力的机制都被完全理解。本研究旨在系统地研究各种设计选择如何以正向或负向方式影响图像和视频生成中的组合泛化能力。通过受控实验，我们发现了两个关键因素：(i) 训练目标是否作用于离散还是连续分布，以及(ii) 训练期间条件信息对组成部分概念提供了多大程度的信息。基于这些见解，我们展示了用一种辅助的连续JEPA基目标放松MaskGIT的离散损失可以改善类似MaskGIT的离散模型中的组合性能。
### Innovation
通过受控实验，研究确定了两种关键因素：训练目标是否作用于离散还是连续分布，以及训练期间条件信息对组成部分概念提供的信息程度。此外，研究还展示了使用一种辅助的连续JEPA基目标可以放松MaskGIT的离散损失，从而改善离散模型中的组合性能。
### Conclusion
研究结果表明，通过调整训练目标的性质和训练期间提供的条件信息，可以提高视觉生成模型的组合泛化能力。
## 148. `cs.AI` - 主题建模作为长文生成：长上下文LLM能否通过零样本提示彻底改变NTM？ [PDF](https://arxiv.org/pdf/2510.03174), [HTML](https://arxiv.org/abs/2510.03174)
### Authors
Xuan Xu,Haolun Li,Zhongliang Yang,Beilin Chu,Jia Song,Moxuan Xu,Linna Zhou
### Background
传统主题模型，如神经主题模型，依赖于推断和生成网络来学习潜在主题分布。本研究探索了在大型语言模型时代，主题建模的新范式，将其定义为一种长文生成任务。文章对比传统主题模型和基于大型语言模型（LLM）的主题模型，并探讨了零样本提示是否可以提高主题质量。
### Innovation
本文提出了将主题建模视为长文生成任务的新范式，并提出了一种简单且实际的方法，直接利用大型语言模型进行话题建模。通过零样本提示的方式，使话题模型任务能够实现即插即用，从而替代或改进现有的神经主题模型。
### Conclusion
研究通过系统比较神经主题模型和大型语言模型在主题质量上的表现，提出了“大多数神经主题模型已过时”的观点，并展示了基于大型语言模型的主题建模方法的优势。
## 149. `cs.AI` - 多事件视频生成中事件何时切换？ [PDF](https://arxiv.org/pdf/2510.03049), [HTML](https://arxiv.org/abs/2510.03049)
### Authors
Ruotong Liao,Guowen Huang,Qing Cheng,Thomas Seidl,Daniel Cremers,Volker Tresp
### Background
随着对挑战性问题的关注增加，文本到视频（T2V）生成领域迅速发展，特别是在需要长时间视频来展示多个具有时间连贯性和可控制内容的连续事件时更加明显。虽然现有的方法在多事件生成上有所扩展，但并未涉及事件转换的内在因素。因此，该研究旨在探讨多事件提示如何控制T2V生成中的事件转换，并进行系统研究以获取相关洞察。
### Innovation
本研究引入了MEve，这是一种自编的多事件文本到视频提示套件，用于评估多事件T2V生成，并对代表性模型家族OpenSora和CogVideoX进行了深入研究。研究结果强调了在去噪步骤和块级模型层中尽早干预的重要性，这为未来模型提供了多事件条件的可能性。
### Conclusion
广泛的实验结果表明，早期干预在去噪步骤和块级模型层对于多事件视频生成的重要性，揭示了多事件视频生成的基本因素，并突显了未来模型多事件条件的可能性。
## 150. `cs.AI` - Wave-GMS: 轻量级多尺度生成模型在医学图像分割中的应用 [PDF](https://arxiv.org/pdf/2510.03216), [HTML](https://arxiv.org/abs/2510.03216)
### Authors
Talha Ahmed,Nehal Ahmed Shaikh,Hassan Mohy-ud-Din
### Background
为了在医院和医疗设施中公平部署人工智能工具，我们需要高性能的深度分割网络，同时这些网络能够在成本低廉的具有有限内存的GPU上进行训练，并支持大规模批次大小。现有的深度学习模型往往需要大量的训练参数，并且依赖于内存密集型的预训练视觉基础模型，这对计算资源要求较高。
### Innovation
本文提出了Wave-GMS，一种轻量级且高效的多尺度生成模型，用于医学图像分割。Wave-GMS模型具有较少的可训练参数，无需加载内存密集型的预训练视觉基础模型，并且能够支持在有限内存的GPU上训练大规模批次大小。实验结果表明，Wave-GMS在四个公开数据集（BUS、BUSI、Kvasir-Instrument和HAM10000）上实现了最新的分割性能，同时还具有出色的跨域泛化能力。
### Conclusion
Wave-GMS模型在使用较少的可训练参数（约2.6M）的情况下，实现了优的分割性能和跨域泛化能力，特别适用于计算资源有限的医疗设施中的医学图像分割应用。此模型的代码已发布供其他研究者使用。
## 151. `cs.AI` - 基于刺激-电压的尖峰电位起始时间预测：经典方法 vs. 受量子启发的方法 [PDF](https://arxiv.org/pdf/2510.03155), [HTML](https://arxiv.org/abs/2510.03155)
### Authors
Stevens Johnson,Varun Puram,Johnson Thomas,Acsah Konuparamban,Ashwin Kannan
### Background
精确建模神经元动作电位（AP）起始时间对于理解神经元对危险信号的编码至关重要。传统的泄漏整流器（LIF）模型虽然广泛应用，但在预测AP起始时间延迟方面表现出较大的相对误差，特别是在受到强烈或快速变化的刺激时。以往的实验发现和量子理论的新进展为更加精确地预测AP起始时间提供了可能。因此，研究人员提出了一种受量子启发的泄漏整流器（QI-LIF）模型，将AP起始视作一种概率事件，通过时间中的高斯波包来表示。这种方法捕获了神经元放电所固有的生物变异性和不确定性。
### Innovation
本文提出了一种受量子启发的泄漏整流器（QI-LIF）模型，该模型将AP起始看作是一个概率事件，通过时间中的高斯波包来表示。这种方法捕捉了神经元放电的固有生物变异性和不确定性。通过系统比较经典LIF模型和QI-LIF模型在不同刺激幅度下的AP起始时间预测误差，研究结果表明，QI-LIF模型能够显著降低预测误差，特别是在高强度刺激的情况下，与观察到的生物反应高度一致。这凸显了量子启发计算框架在提高神经建模准确性方面的潜力，并对基于大脑的计算的量子工程方法产生了重要影响。
### Conclusion
受量子启发的LIF模型（QI-LIF）显著减少了高强度刺激下的AP起始时间预测误差，与观察到的生物反应高度一致。这对于推进神经建模的准确性意义重大，并为基于量子工程的脑启发计算奠定理论基础。
## 152. `cs.AI` - SpineBench：基于SpineMed-450k语料库的临床相关、节段意识基准 [PDF](https://arxiv.org/pdf/2510.03160), [HTML](https://arxiv.org/abs/2510.03160)
### Authors
Ming Zhao,Wenhui Dong,Yang Zhang,Xiang Zheng,Zhonghao Zhang,Zian Zhou,Yunzhi Guan,Liukun Xu,Wei Peng,Zhaoyang Gong,Zhicheng Zhang,Dachuan Li,Xiaosheng Ma,Yuli Ma,Jianing Ni,Changjiang Jiang,Lixia Tian,Qixin Chen,Kaishun Xia,Pingping Liu,Tongshun Zhang,Zhiqiang Liu,Zhongan Bi,Chenyang Si,Tiansheng Sun,Caifeng Shan
### Background
脊柱疾病影响全球6亿多人，是导致残疾的主要原因之一，但AI辅助诊断受限于缺乏分级、多模态数据集。脊柱疾病的临床决策需要在特定椎体级别上跨X光、CT和MRI进行复杂的推理。然而，缺乏可追溯的、有临床依据的指令数据和标准化、脊柱特定的基准阻碍了进步。为了应对这一挑战，本研究介绍了SpineMed这套与实际脊柱外科医生共同设计的生态系统，其中包括一个大型多模态数据集SpineMed-450k和一个有临床依据的评估框架SpineBench。
### Innovation
本研究开发了SpineMed-450k，这是首个专门设计用于跨成像模态进行椎段级推理的大型数据集，汇集了超过450,000个指令实例。数据集从教科书、指南、开源数据集和1000余例匿名医院病例中筛选，采用包含草稿和修订阶段的人工智能生成方法，确保高质量且可追溯的数据。研究还推出了SpineBench，这是一种高效的评估框架，评估模型在脊柱疾病诊断、病理评估及手术规划等方面的临床显著性维度。研究通过多种先进视觉语言模型在SpineBench上的全面评估，揭示了模型在细微、特定节段推理方面的系统性弱点，并展示了在SpineMed-450k上微调的模型在所有任务上的持续且显著改进。
### Conclusion
临床医生的评估证实了该模型输出的诊断清晰度和实用价值，表明SpineMed-450k数据集和SpineBench评估框架为脊柱疾病领域的AI辅助诊断注入了新的活力。
## 153. `cs.AI` - UniShield：统一伪造图像检测和定位的自适应多智能体框架 [PDF](https://arxiv.org/pdf/2510.03161), [HTML](https://arxiv.org/abs/2510.03161)
### Authors
Qing Huang,Zhipei Xu,Xuanyu Zhang,Jian Zhang
### Background
随着图像生成技术的迅速发展，合成图像变得越来越逼真，带来了一些重大的社会风险，如虚假信息和欺诈行为。因此，伪造图像检测和定位（FIDL）变得至关重要，以维护信息完整性和社会安全。现有的领域特定检测方法虽然表现出色，但在实际应用中的适用性仍然有限，主要原因是它们的专业化程度高、跨域泛化能力差以及缺乏集成的自适应框架。
### Innovation
我们提出了一种名为UniShield的新型多智能体统一系统，能够在不同领域（包括图像篡改、文档篡改、DeepFake和AI生成的图像）中检测和定位图像伪造。UniShield创新性地集成了感知代理和检测代理。感知代理能够智能分析图像特征，动态选择合适的检测模型，而检测代理将各种专家检测器整合到一个统一框架中，并生成可解释的报告。实验结果表明，UniShield在检测伪造图像方面取得了最先进的成果，超过了现有统一方法和领域特定检测器，突显了其实用性、适应性和可扩展性优势。
### Conclusion
UniShield在伪造图像检测和定位方面取得了卓越的成果，其优越的实用性、适应性和可扩展性为未来的图像真实性问题提供了新的解决方案。
## 154. `cs.AI` - Abstain and Validate: A 双LLM策略减少代理程序修复中的噪音 [PDF](https://arxiv.org/pdf/2510.03217), [HTML](https://arxiv.org/abs/2510.03217)
### Authors
José Cambronero,Michele Tufano,Sherry Shi,Renyao Wei,Grant Uy,Runxiang Cheng,Chin-Jung Liu,Shiying Pan,Satish Chandra,Pat Rondon
### Background
代理自动化程序修复（APR）在工业界越来越用于解决复杂的问题，但最终生成的修复代码仍然需要人工审查以确保其解决的问题。然而，展示不太可能修复的建议可能增加了开发者的噪音，浪费了宝贵的时间，并降低了对自动代码更改的信任。
### Innovation
提出了两种互补的基于LLM的策略来减少此类噪音：bug 干涉和修补验证策略。bug 干涉排除了代理APR系统不太可能修复的bug。修补验证拒绝可能不是给定bug的良好修复的修补程序。这两种策略在来自Google代码库的多个数据集上进行评估，显示成功率可提高多达13和15个百分点，组合使用时可提高高达39个百分点。对于空指针异常和机器生成的bug报告中的sanitizerbug，修补验证还能提高平均成功率。
### Conclusion
这两种策略提供了一个实际的方法，以便在工业规模上可靠地部署代理APR系统。
## 155. `cs.AI` - 奖励模型是披着大衣的度量标准 [PDF](https://arxiv.org/pdf/2510.03231), [HTML](https://arxiv.org/abs/2510.03231)
### Authors
Sebastian Gehrmann
### Background
在大规模语言模型的后训练中，强化学习的出现激发了对奖励模型的兴趣。奖励模型用于评估模型输出的质量以生成训练信号，而评估指标也监控AI模型的性能。然而，这两个研究领域大多各自为政，导致术语重复和重复的错误。共同面临的挑战包括易受虚假相关性的影响、下游奖励黑客的影响、数据质量改进的方法以及元评估方法。
### Innovation
该论文提出了奖励模型与评估指标之间紧密合作可以克服现有问题的观点，并通过实验证明在某些任务上指标的表现优于奖励模型。同时，该研究提供了两个领域的广泛调查，并指出了在偏好触发方法、避免虚假相关性和奖励黑客以及校准感知元评估方面的改进领域。
### Conclusion
本文通过比较奖励模型和评估指标之间的不同，提出了促进两个领域合作的观点，并指出了多个改进领域，旨在提高奖励模型和评估指标的效果。
## 156. `cs.AI` - Self-Anchor：通过逐步对齐注意力进行大语言模型推理 [PDF](https://arxiv.org/pdf/2510.03223), [HTML](https://arxiv.org/abs/2510.03223)
### Authors
Hongxiang Zhang,Yuan Tian,Tianyi Zhang
### Background
为了解决大型语言模型（LLMs）的复杂推理任务，基于提示的方法提供了一种轻量级的替代方案，相比之下，微调和强化学习更为复杂。然而，当推理链条延长时，关键的中间步骤和原始提示可能会被淹没在上下文中，无法得到足够的关注，从而导致错误。
### Innovation
我们提出了Self-Anchor，这是一种新颖的管道，利用推理的固有结构来引导LLM的注意力。Self-Anchor将推理轨迹分解为结构化的计划，并自动将模型的注意力对准最相关的推理步骤，允许模型在整个生成过程中保持焦点。我们的实验表明，Self-Anchor在六个基准测试中优于当前的SOTA提示方法。特别地，Self-Anchor显著减少了“非推理”模型和专门推理模型之间的性能差距，有可能使大多数LLMs能够处理复杂的推理任务，而无需重新训练。
### Conclusion
实验结果表明，Self-Anchor在六个基准测试中均优于当前的最佳提示方法，特别之处在于，它显著减小了“非推理”模型和专门推理模型之间的性能差距。研究者相信，这项技术可以使大多数语言模型能够处理复杂的推理任务，而无需重新训练，从而提高了模型在复杂推理任务中的表现。
## 157. `cs.AI` - 通过潜在集成的随机共振实现对抗攻击测试时防御 [PDF](https://arxiv.org/pdf/2510.03224), [HTML](https://arxiv.org/abs/2510.03224)
### Authors
Dong Lao,Yuxiang Zhang,Haniyeh Ehsani Oskouie,Yangchao Wu,Alex Wong,Stefano Soatto
### Background
本文提出了一种测试时间防御机制，旨在对抗对抗性攻击。现有的防御方法通常依赖于特征过滤或平滑，这可能会导致信息丢失。本文提出了一种利用随机共振增强鲁棒性同时减少信息损失的新方法。该方法通过对输入图像进行微小的平移扰动，调整并重新对齐变换后的特征嵌入，然后在映射回原始参考图像之前进行聚合。
### Innovation
本文的创新在于提出了一种通过利用随机共振技术增强模型鲁棒性的新方法。具体而言，该方法对输入图像进行微小的平移扰动，对变换后的特征嵌入进行对齐和聚合，然后将结果映射回原始参考图像。这种方法可以在不同的网络架构上直接部署，无需额外的网络模块或特定攻击类型的微调。
### Conclusion
实验结果表明，该方法在图像分类任务中的鲁棒性达到了最先进的水平，并首次为密集预测任务（包括立体匹配和光流）建立了通用的测试时防御方法，展示了该方法的多功能性和实用性。具体来说，相较于干净图像（未受扰动），该方法分别在图像分类、立体匹配和光流任务上能恢复68.1%、71.9%和29.2%的准确率损失，即使在不同类型对抗性攻击下依然有效。
## 158. `cs.AI` - 基于因果解缠改进的结构性分解马尔可夫决策过程的蒙特卡洛规划 [PDF](https://arxiv.org/pdf/2406.16151), [HTML](https://arxiv.org/abs/2406.16151)
### Authors
Larkin Liu,Shiqi Liu,Yinruo Hua,Matej Jusup
### Background
马尔可夫决策过程（MDPs）虽然作为通用框架被广泛应用，但通常未能充分利用转换和奖励动力学中的因果结构优势。针对一类资源分配问题，作者引入了构造型分解马尔可夫决策过程（SD-MDP）框架，通过因果解缠技术将MDP的时间因果图分解为独立组件，从而减少维度并提高计算效率。
### Innovation
SD-MDP通过因果解缠将序贯优化问题转化为具有对数复杂度$O(T text{log} T)$的分式背包问题，优于传统具有多项式复杂度的方法。SD-MDP的计算优势与状态空间尺寸无关，使其适用于高维空间。此外，该方法与蒙特卡洛树搜索（MCTS）无缝集成，即使在有限的模拟预算下也能获得更高的预期收益，并提供趋于零的简单遗憾界。
### Conclusion
实验结果表明，在物流和金融领域等各种应用场景下，SD-MDP相比于基准方法表现出更优的策略性能。
## 159. `cs.AI` - SelfBudgeter: 自适应的token分配以提高LLM推理效率 [PDF](https://arxiv.org/pdf/2505.11274), [HTML](https://arxiv.org/abs/2505.11274)
### Authors
Zheng Li,Qingxiu Dong,Jingyuan Ma,Di Zhang,Kai Jia,Zhifang Sui
### Background
尽管推理模型在复杂任务上表现出色，但它们在简单问题上的过度推理会导致过多的计算资源消耗，并显著影响用户体验。
### Innovation
提出了一种名为SelfBudgeter的新颖自适应控制推理框架，该框架在推理之前包含了一个预算估计机制。框架采用两阶段训练模式：在冷启动阶段，模型学习在标准化格式下预测令牌预算；在强化学习阶段，模型根据问题难度自主规划预算，并在生成响应时严格遵守。
### Conclusion
实验结果表明，SelfBudgeter可以根据问题复杂性动态分配预算，对于1.5B模型在GSM8K、MATH500和AIME2025上的平均响应长度压缩了61%，对于7B模型压缩了48%，同时基本保持了准确率。此外，该方法允许用户通过预填的预算字段手动控制推理长度，提供灵活的选择是否中断生成过程。
## 160. `cs.AI` - 通过显式位置到坐标映射改进GUI定位 [PDF](https://arxiv.org/pdf/2510.03230), [HTML](https://arxiv.org/abs/2510.03230)
### Authors
Suyuchen Wang,Tianyu Zhang,Ahmed Masry,Christopher Pal,Spandana Gella,Bang Liu,Perouz Taslakian
### Background
GUI定位是使自主代理能够理解并执行自然语言指示到像素坐标的关键任务，但目前的视觉语言模型（VLMs）在这方面仍存在困难，核心瓶颈是可靠的片段到像素的映射，在高分辨率显示设备上的推断超出训练范围时就会失效。现有方法直接从视觉特征生成坐标文本标记，这迫使模型隐含地推理复杂的坐标映射；因此，在新分辨率上准确性下降并且失败率增加。因此，本文旨在解决这个问题，引入了两项创新。
### Innovation
首先，引入了RULER标记作为显式的坐标标志，使模型可以像地图上的网格线一样引用位置并调整而不是从头开始生成坐标。其次，交错MRoPE（I-MRoPE）可以提高空间编码的效果，确保宽度和高度维度以相同的方式表示，解决了标准位置方案的不对称性。实验结果表明，在ScreenSpot、ScreenSpot-V2和ScreenSpot-Pro三个数据集上，定位准确率得到了一致的提升，特别是在高分辨率界面上的提升最为显著。通过提供显式的空间指导而不是依赖隐含学习的方式，文章提出的方法在不同分辨率和平台下的GUI自动化控制更为可靠。
### Conclusion
通过引入RULER标记和交错MRoPE增强的空间编码方法，本文为GUI自动化领域提供了一种有效的解决方案，能够在多种分辨率和平台上实现更可靠的GUI自动化.
## 161. `cs.AI` - LayerCake: 在大型语言模型层内具有词意识的对比解码 [PDF](https://arxiv.org/pdf/2507.04404), [HTML](https://arxiv.org/abs/2507.04404)
### Authors
Jingze Zhu,Yongliang Wu,Wenbo Zhu,Jiawang Cao,Yanqiang Zheng,Jiawei Chen,Xu Yang,Bernt Schiele,Jonas Fischer,Xinting Hu
### Background
大型语言模型在自然语言理解和生成方面表现出色，但在知识密集型任务中仍然容易出现事实错误，影响其可靠性。现有的解码时间策略虽然提供了一种高效的解决方案，但通常将词级和层级信号隔离开来处理，忽视了它们之间的联合动态。
### Innovation
引入了一种具有词意识的、局部于层级别的对比解码方法，该方法将特定词类型与其最具影响力的变换器层对齐，以改善事实生成。通过经验关注分析，识别出两个关键模式：标点符号词在早期层中占据主导地位，概念词在中间层中控制语义推理。通过有选择地抑制这些词类型的注意，可以在相应深度处诱导控制的事实衰减，从而产生对比信号来指导最终的事实解码。这种方法无需额外训练或模型修改，实验表明这种方法在多种大型语言模型和各种基准测试中都能改善事实性。
### Conclusion
该方法在多个大型语言模型和各种基准测试中一致提高了事实生成的准确性，无需额外训练或模型修改，对实际应用具有重要意义。
## 162. `cs.AI` - MIRROR: 模块化内部处理在LLM对话中的个性化安全性 [PDF](https://arxiv.org/pdf/2506.00430), [HTML](https://arxiv.org/abs/2506.00430)
### Authors
Nicole Hsing
### Background
大型语言模型在个人多轮对话中经常生成有害建议，因为它们忽略了用户特定的安全背景，表现出奉迎同意，并以牺牲用户安全来满足更大群体的偏好。MIRROR是一种模块化的设计架构，旨在通过保持内部状态的持久性和界限，以及记忆跨对话回合的个人对话信息，来解决这些失败问题。
### Innovation
MIRROR采用了一个由'谈者'和'思考者'组成的双组件设计，这灵感来源于两阶段理论。'谈者'用于即时响应生成，而'思考者'则进行异步的详尽处理，合成了在回合之间平行的推理线程，以微小的时间延迟实现。通过使用开源的Llama 4和Mistral 3变体版本，MIRROR增强模型在CuRaTe个性化安全基准测试中相对于七个前沿模型实现了21%的相对改进，成本仅为每回合0.0028至0.0172美元，缩小了开源模型与前沿系统在安全性上的差距。该模块化架构使得根据可负担性和复杂性的不同，灵活部署完整内部处理或单组件配置，为更广泛的用户提供访问安全和个性化的AI服务的机会。
### Conclusion
MIRROR架构通过保持内部状态的持久性和界限，以及记忆跨对话回合的个人对话信息，显著提高了对话安全性，并且由于其模块化的设计，允许灵活部署，使得低成本模型能够进行完整的内部处理，而昂贵的系统可以使用单组件配置，从而民主化了更安全、更个性化的AI的获取。
## 163. `cs.AI` - 利用强化学习使多模态大语言模型适应能够寻求帮助的体态代理 [PDF](https://arxiv.org/pdf/2504.00907), [HTML](https://arxiv.org/abs/2504.00907)
### Authors
Ram Ramrakhya,Matthew Chang,Xavier Puig,Ruta Desai,Zsolt Kira,Roozbeh Mottaghi
### Background
家用机器人在执行任务时需要解读含糊不清和不明确的人类指令。研究这种问题，引入了Ask-to-Act任务，其中体态代理需要借助不明确的指示执行单一或多对象重新排列任务，且需要在部分可观测的环境下策略性地问出最少却相关的澄清问题以解决歧义，从而准确推断用户意图。这项工作旨在通过利用在线强化学习和大语言模型（LLM）自动生成的奖励信号来训练体态代理，从而解决这一挑战，减少对大规模人类演示数据或手工工程奖励的需求，并且在零样本基准上进行评估，表现出色，能够很好地迁移到前所未见的场景和任务上。
### Innovation
提出了一个创新的采用大规模多模态语言模型（LLM）作为视觉-语言-动作（VLA）策略，并通过在线强化学习（RL）和LLM自动生成的奖励进行微调的方法。这种方法使得体态代理能够在不明确的指示下执行任务，并且能够在部分可观测环境下，策略性地要求最少的但必要的澄清信息，从而推断用户意图。此外，这种方法还能够显著超越其他零样本基准以及监督微调的大语言模型，并能够很好地推广到新的场景和任务。
### Conclusion
这是首次展示通过在线强化学习和LLM生成的奖励信号，使多模态大语言模型适应为能够寻求帮助的体态代理的方法。我们的方法在Ask-to-Act任务上的表现超过了所有基准，展现了良好的泛化能力，表明LLM可以被适应为在部分可观测环境下的体态代理，而这之前是没有见过的。
## 164. `cs.AI` - V2X-UniPool: 将多模态感知与知识推理统一应用于自动驾驶 [PDF](https://arxiv.org/pdf/2506.02580), [HTML](https://arxiv.org/abs/2506.02580)
### Authors
Xuewen Luo,Fengze Yang,Fan Ding,Xiangbo Gao,Shuo Xing,Yang Zhou,Zhengzhong Tu,Chenxi Liu
### Background
自动驾驶尽管取得了显著进展，但单一车辆感知仍有局限，特别是受感测范围和遮挡的影响。Vehicle-to-Everything (V2X) 通信通过跨车辆和基础设施协作解决了这些问题，但同时也面临异构性、同步性和延迟的挑战。此外，尽管语言模型具有强大的知识驱动推理和决策能力，但它们本质上不适合处理原始传感器数据，并且容易产生幻觉。这些背景指向了需要一种能够有效结合V2X感知与语义推理的技术框架来提升自动驾驶的性能和效率的需求。
### Innovation
本文提出了一种名为V2X-UniPool的框架，首次将V2X感知与基于语言的推理统一起来，以实现知识驱动的自动驾驶。该框架将多模态V2X数据转换为结构化的语言知识，并在一个按时间索引的知识池中组织它们，进行时序一致的推理。通过使用检索增强生成（RAG），该框架能够基于实时语境做出决策。实验结果表明，V2X-UniPool在真实世界DAIR-V2X数据集上的规划精度和安全性已达到最先进的水平，同时将通信成本降低了超过80%，是评价方法中最具成本效益的。这是通过将V2X感知与语言推理相结合而实现的最新进展。
### Conclusion
这些结果证明了将V2X感知与语言推理相结合能够推动具有可扩展性和可信度的自动驾驶技术的发展。研究者发布的代码可进一步推动该领域的研究和发展。
## 165. `cs.AI` - 社会增强的多层时空过渡图形表征学习中的解缠 [PDF](https://arxiv.org/pdf/2508.07649), [HTML](https://arxiv.org/abs/2508.07649)
### Authors
Jie Li,Haoye Dong,Zhengyang Wu,Zetao Zheng,Mingrong Lin
### Background
商务智能中的下一个地点兴趣（POI）推荐是一项研究热点，用户的时空过渡和社交关系起着关键作用。然而，大多数现有工作将时空过渡分别建模，导致相同的空间-时间关键节点的表示不一致。这种不一致在融合过程中引入冗余信息，增加了模型的不确定性并降低了可解释性。
### Innovation
我们提出了一种基于多层时空过渡图形解缠表示学习的社会增强POI推荐模型DiMuST。该模型采用了一种新颖的解缠变分多层图形自动编码器（DAE），首先通过多层时空图形策略将公共和私有分布解缠，然后通过专家产品机制融合公共特征，并通过对比约束细化私有特征。该模型有效捕捉了POI的空间-时间过渡表示，同时保持了其空间-时间关系的固有联系。
### Conclusion
在两个具有挑战性的数据集上的实验表明，我们的DiMuST在多个指标上显著优于现有方法。
## 166. `cs.AI` - 从仿真到规则：一种用于正式视觉规划的双VLM框架 [PDF](https://arxiv.org/pdf/2510.03182), [HTML](https://arxiv.org/abs/2510.03182)
### Authors
Yilun Hao,Yongchao Chen,Chuchu Fan,Yang Zhang
### Background
视觉语言模型（VLMs）在视觉规划方面表现出强大的潜力，但在精确的空间和长时推理方面仍显不足。相比之下，规划领域定义语言（PDDL）规划器擅长长期形式化规划，但无法理解视觉输入。现有研究结合了这些互补的优势，使VLMs能够将视觉规划问题转换成PDDL文件以进行正式规划。然而，尽管VLMs可以良好地生成PDDL问题文件，但它们在生成描述所有规划规则的PDDL领域文件方面存在困难。因此，先前的方法依赖于人类专家预先定义领域文件或持续的环境访问以进行进一步完善。
### Innovation
本文提出了一种名为VLMFP的双VLM指导框架，该框架能够自主生成PDDL问题文件和领域文件，以实现视频规划。VLMFP引入了两个VLM：SimVLM用于根据输入规则描述模拟动作结果，GenVLM通过比较PDDL和SimVLM执行结果来生成和迭代生成PDDL文件。VLMFP在多个层面提升了通用性：相同的生成PDDL领域文件可以在同一种问题的所有不同实例中使用；VLMs能够泛化应用于具有不同外观和规则的不同问题。
### Conclusion
本文通过6个格子世界领域的评估和对未见实例、外观和游戏规则的测试，验证了VLMFP的有效性和泛化能力。结果表明，SimVLM能够准确描述95.5%和82.6%的情况，模拟85.5%和87.8%的动作序列，以及判断82.4%和85.6%的目标达到情况。在未见实例和未见外观的情况下，根据SimVLM的指导，VLMFP能够生成PDDL文件以实现70.0%和54.1%的有效规划。
## 167. `cs.AI` - Gala: 全局大模型代理用于文本到模型翻译 [PDF](https://arxiv.org/pdf/2509.08970), [HTML](https://arxiv.org/abs/2509.08970)
### Authors
Junyang Cai,Serdar Kadioglu,Bistra Dilkina
### Background
自然语言对优化或满意问题的描述转换为正确的MiniZinc模型具有挑战性，因为这个过程需要逻辑推理和约束编程的专业知识。本文介绍了一种名为Gala的框架，它通过全球智能体方法解决这个问题：多个专门的大语言模型（LLM）智能体根据全局约束类型分解建模任务。通过将问题分解为更小、更明确的子任务，每个LLM可以处理更简单的推理挑战，从而降低整体复杂性。
### Innovation
Gala框架采用全球智能体方法，多个专门的大语言模型（LLM）智能体根据全局约束类型分解建模任务，每个智能体专注于检测和生成特定类型全局约束的代码，最终由整合智能体将这些约束片段合并成完整的MiniZinc模型。这种方法将问题分解为更小、更明确的子任务，通过简化每个LLM需要处理的推理挑战，从而降低整体复杂性。
### Conclusion
我们进行了初步实验，并展示了Gala框架在多个LLM上的表现优于传统的one-shot提示和chain-of-thought提示等基线方法。最后，我们概述了未来工作的全面路线图，明确了潜在的增强和改进方向。
## 168. `cs.AI` - OML：AI模型分发中开放访问和所有权控制的范式 [PDF](https://arxiv.org/pdf/2411.03887), [HTML](https://arxiv.org/abs/2411.03887)
### Authors
Zerui Cheng,Edoardo Contente,Ben Finch,Oleg Golev,Jonathan Hayase,Andrew Miller,Niusha Moshrefi,Anshul Nasery,Sandeep Nailwal,Sewoong Oh,Himanshu Tyagi,Pramod Viswanath
### Background
当前的AI模型分发范式存在根本性的二分法：模型要么是封闭和API封包的，牺牲了透明度和本地执行；要么是公开分发的，牺牲了收益和控制。本文介绍了OML（开放访问、可收益、忠诚AI模型服务）作为一种原语，能够实现新的分发范式，即模型可以自由分发以进行本地执行，同时通过加密机制保证使用授权的真实性。这是首次正式提出并定义这一问题，介绍了针对白盒模型保护的独特挑战——模型提取抗性和权限伪造抗性的严格安全定义。并证明了OML属性实现的基本边界，并描述了从混淆方法到加密解决方案的完整设计空间。为了证明其实用可行性，还提出了OML 1.0，这是一种基于AI原生模型指纹与加密经济性强制机制相结合的OML新建设。通过广泛的理论分析和实验评估，文章确立了OML作为支撑可持续AI生态系统的基础原语的地位。这项工作开辟了在密码学、机器学习和机制设计交叉领域的新研究方向，对于AI的分发和治理具有关键性影响
### Innovation
首次提出了OML原语，解决了白盒模型保护的独特挑战；定义了模型提取抗性和权限伪造抗性的严格安全定义；设计了OML的完整设计空间，包括混淆方法和加密解决方案；提出了OML 1.0，利用AI原生模型指纹与加密经济性强制机制相结合。
### Conclusion
OML作为一种基础原语，对于构建可持续发展的AI生态系统至关重要。该工作在密码学、机器学习和机制设计交叉领域开辟了新的研究方向，对AI的分发和治理具有重要的影响。
## 169. `cs.AI` - 有效且正确的决策树预测等价关系 [PDF](https://arxiv.org/pdf/2509.17774), [HTML](https://arxiv.org/abs/2509.17774)
### Authors
Joao Marques-Silva,Alexey Ignatiev
### Background
最近的研究表明，计算相同分类函数的决策树具有预测等价性，可以在Rashomon集合中占据显著比例，这导致了决策树中的冗余性问题，特别是在基于Rashomon集合的重要性分析中变得不准确。McTavish等人提出的解决方案可以决定预测等价的决策树，该方法包括利用Quine-McCluskey（QM）方法获得决策树的最小子集DNF表示，从而用于预测等价性比较。尽管这种方法可以用于决策树的解释生成和处理缺失数据问题，但公式最小化问题属于多项式层级第二级，Q方法可能表现出最坏情况下的指数级运行时间和空间。
### Innovation
本文首先证明了存在决策树可以触发QM方法的最坏情况下的指数级运行时间和空间。其次，证明了如果两个关键约束不被遵守，QM方法可能不正确地决定预测等价性。更重要的是，本文表明了所有可以应用到最小DNF表示的问题都可以在DT规模的多项式时间内解决，实验结果显示，对于触发最坏情况的决策树，本文提出的新算法与McTavish等人的算法相比快了几个数量级。
### Conclusion
本文解决了决策树预测等价性中的问题，并提供了一种比McTavish等人的方法更快且更准确的解决方案。通过证明最小CNF表示可以用来有效解决所有与DT相关的计算问题，说明了基于最小表示的决策树算法的有效性。
## 170. `cs.AI` - PRIME：集成规划和检索的记忆增强推理 [PDF](https://arxiv.org/pdf/2509.22315), [HTML](https://arxiv.org/abs/2509.22315)
### Authors
Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu
### Background
该研究受到人类认知的双过程理论《Thinking, Fast and Slow》的启发，展示了人类思维中快速直觉思维和缓慢慎重思考的不同过程。现有的语言模型虽然强大，但在复杂知识推理任务上表现不足，通常需要更多训练资源和更复杂的结构，而开源语言模型在这方面尤其落后于闭源模型。
### Innovation
PRIME 是一个将快速直觉思维（System 1）与缓慢慎重思考（System 2）动态整合的多智能体推理框架。它通过引入快速思考智能体（Quick Thinking Agent）和结构化的系统2推理 Pipeline，结合多种专业智能体来进行规划、假设生成、检索、信息整合和决策，从而增强开放源代码语言模型在复杂、知识密集型推理任务上的效率与准确性。
### Conclusion
实验结果表明，PRIME 能够使开源大型语言模型 (LLM) 在需要多步推理和基于知识的推理基准测试中的表现与最新闭源模型（如 GPT-4 和 GPT-4o）竞争。这表明 PRIME 是一个可扩展的解决方案，可以提高需要复杂、知识密集型推理任务的 LLM 的性能。
## 171. `cs.AI` - 伦理原则和算法方法的融合：评估人工智能系统可信性的替代方法 [PDF](https://arxiv.org/pdf/2506.22774), [HTML](https://arxiv.org/abs/2506.22774)
### Authors
Michael Papademas,Xenia Ziouvelou,Antonis Troumpoukis,Vangelis Karkaletsis
### Background
人工智能技术突显了人类制造的复杂挑战，尤其是那些广泛融入社会并产生显著影响的技术。尽管其他技术也可能带来重大风险，但AI因其广泛的覆盖范围使得其社会影响尤为深远。AI系统的复杂性和其卓越的能力可能导致人们对超越直接人类监控或理解的技术产生依赖。为减轻由此产生的风险，已经开发出了一系列理论工具和指南，并创建了旨在保护可信AI的技术工具。然而，现有的指南侧重整体视角但未能提供衡量可信度的技术，而技术工具则能够更好地实现量化，但缺乏整体视角，专注于可信AI的具体方面。本文旨在介绍一种结合可信AI的伦理成分与PageRank和TrustRank的算法过程的评估方法，以建立一种可以最小化当前领域中自我评估技术中固有主观性的评估框架，从而提供定量洞察并考虑相关指南的理论内容。
### Innovation
本文提出了一种结合可信AI伦理成分与PageRank和TrustRank算法过程的评估方法。该方法旨在建立一个量化评估框架，以减少现有领域自我评估中固有的主观性，同时考虑相关指南的理论内容。这种方法能够实现对AI系统可信性的全面评估，提供定量洞察。
### Conclusion
通过这种方法的应用，可以实现对AI系统的全面信任评估，提供定量的见解并考虑相关的理论内容。
## 172. `cs.AI` - THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning [PDF](https://arxiv.org/pdf/2509.13761), [HTML](https://arxiv.org/abs/2509.13761)
### Authors
Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jun Du,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Quan Liu,Jianqing Gao
### Background
大型语言模型（LLMs）在数学推理方面取得了显著进展，但仍在高精度任务如数值计算和正式符号操作中面临挑战。尽管集成外部工具被认为是解决这些问题的一个有前景的方法，现有的方法仍然面临三个关键挑战：构建工具集成推理数据、进行细粒度优化和增强推理能力。
### Innovation
本文提出了THOR（Tool-Integrated Hierarchical Optimization via RL），一种通过基于多智能体的TIRGen管道构建高质量的工具集成推理数据集的方法，该管道采用多智能体演员-评论者架构，并且能够很好地跨不同模型泛化。THOR还引入了一种RL策略来联合优化每个问题集和每个步骤的代码生成，该策略基于一个关键的洞察，即中间工具调用的成功是最终答案正确性的一个强有力预测指标。此外，THOR集成了自我纠错机制，利用即时工具反馈动态地修正推理路径中的错误，从而在推理和非推理模型中表现出强大的泛化能力。在多个数学基准测试中，THOR还实现了同类规模模型的最先进的性能，并在代码基准测试中获得了一致的改善。
### Conclusion
本文的方法不仅展示了在不同模型上强大的泛化能力，并在推理和非推理模型中表现良好，还在多个数学基准测试中取得最先进的性能，并通过引用即时工具反馈，在推理期间实现了持续的性能提升。
## 173. `cs.AI` - 在世界潜在空间中学习互动以实现团队协调 [PDF](https://arxiv.org/pdf/2509.25550), [HTML](https://arxiv.org/abs/2509.25550)
### Authors
Dongsu Lee,Daehee Lee,Yaru Niu,Honguk Woo,Amy Zhang,Ding Zhao
### Background
团队在多智能体强化学习（MARL）场景中的协调是一个极具挑战性的问题，特别是在面对多智能体复杂互动以及因局部观察导致的信息不完整时。传统方法要么通过缓慢且易受攻击的明确消息传递来处理协调问题，要么无法实现有效的团队协调。
### Innovation
本文提出了一种新颖的表示学习框架——交互世界潜在（IWoL），直接通过对通信协议的建模来描述智能体之间的关系和任务特定的世界信息，从而使每个智能体能够在去中心化的环境中协作，同时避免了明确消息传递的固有问题。此外，这种表示既可以作为每个智能体的隐式潜在变量，也可以作为明确的信息在智能体之间传递。
### Conclusion
通过对四个具有挑战性的MARL基准测试的评估，IWoL 框架证明了其在团队协调方面简单而强大的能力。进一步的研究表明，这种表示可以与现有的MARL算法结合使用以增强其性能。
## 174. `cs.AI` - GUI-PRA：GUI任务的进程奖励代理 [PDF](https://arxiv.org/pdf/2509.23263), [HTML](https://arxiv.org/abs/2509.23263)
### Authors
Tao Xiong,Xavier Hu,Yurun Chen,Yuhang Liu,Changqiao Wu,Pengzhi Gao,Wei Liu,Jian Luan,Shengyu Zhang
### Background
GUI代理可以通过多模态大型语言模型（MLLMs）展现出显著的自动化任务潜力，但它们在处理长期任务时表现不佳，常常导致频繁失败。为了应对这一挑战，研究还提出了过程奖励模型（PRMs），作为一种在推理过程中能提供关键过程信号的方法，特别适用于GUI任务。然而，将PRMs应用于GUI领域存在独特挑战，如处理含长时间历史数据的密集人工输入时，PRMs会遭受“中间迷失”现象的影响，即过多的历史上下文会阻碍对当前步骤的评估。此外，标准PRMs缺乏对GUI变化的意识，提供的静态评估无法反映动作的动态后果，这与GUI任务本质上是动态的事实难以匹配。
### Innovation
为了克服上述挑战，该研究提出了GUI-PRA（GUI任务的进程奖励代理）这个看门人代理模型。它通过两个核心组件：基于相关性的检索模块（用于主动检索长时间历史中的相关信息）和逐步总结模块（动态压缩不断增长的交互数据），具备更好的处理历史上下文的能力，从而解决了PRMs中的“中间迷失”现象问题。此外，它还引入了自适应UI感知机制，使代理能够推理UI状态变化，并动态选择最合适的工具来收集实际的视觉证据，确保评估信息始终来自于当前的UI上下文。
### Conclusion
GUI-PRA通过增强的历史上下文处理能力和适应性UI感知机制，在面对长时历史数据和GUI变化时提供更准确的过程奖励，显著改善了GUI代理在长期任务中的表现。
## 175. `cs.AI` - 从模型扩展视角理解具有语义ID的生成推荐 [PDF](https://arxiv.org/pdf/2509.25522), [HTML](https://arxiv.org/abs/2509.25522)
### Authors
Jingzhe Liu,Liam Collins,Jiliang Tang,Tong Zhao,Neil Shah,Clark Mingxuan Ju
### Background
生成模型的最新进展使得生成推荐（Generative Recommendation, GR）成为推荐系统（Recommender Systems, RS）的一个前景广阔的范式。这种方法试图统一丰富的项目语义和协同过滤信号。虽然在其他领域中的生成模型展示了明显的扩展规律，但研究发现基于语义ID（Semantic IDs, SIDs）的GR在扩展模型时表现出显著的瓶颈。具体而言，当放大每个组件——模态编码器、量化分词器和推荐系统本身时，基于SIDs的GR的表现会很快饱和。
### Innovation
本文作者在观察到SIDs容量有限导致的问题后，提出了一种新的策略——直接利用大规模语言模型（Large Language Models, LLMs）进行推荐（即LLM-as-RS）。实验显示，LLM-as-RS在模型扩展性方面表现出优越的性能，并且能够将效果提升20%以上至当前基于SIDs的GR的最佳表现。此外，研究还挑战了LLMs难以捕捉协同过滤信息的传统观点，证明它们随着模型规模的增加在建模用户项目交互方面的能力也在提升。这些分析进一步确认了基于SIDs的GR的固有限制，并表明LLM-as-RS可能是通往生成推荐系统基础模型的一个有希望的方向。
### Conclusion
本文的研究突显了基于SIDs的GR的固有限制，并将其扩展性问题与基于大语言模型的推荐系统进行了比较，展示了后者在大小模型参数范围内优越的扩展行为和模型规模所能带来的潜在利益。LLM-as-RS被定位为生成推荐系统未来研究的一个有希望的路径。
## 176. `cs.AI` - 统一的领域自适应语义分割 [PDF](https://arxiv.org/pdf/2311.13254), [HTML](https://arxiv.org/abs/2311.13254)
### Authors
Zhe Zhang,Gaochang Wu,Jing Zhang,Xiatian Zhu,Dacheng Tao,Tianyou Chai
### Background
UDA-SS（无监督领域自适应语义分割）旨在将标签从标记的源领域传输到未标记的目标领域。虽然现有的UDA-SS工作大多集中在图像方面，近期的研究已经扩展到视频领域，通过建模时间维度来解决这个问题。尽管图像和视频两种研究路径面临的主要挑战是克服领域分布的变化，但这些研究相对独立，导致缺乏整体理解，无法充分交叉融合想法，进而导致方法缺乏统一性，造成重复努力和跨领域的知识转移不充分。
### Innovation
本文建议从通用数据增强的角度探索统一的UDA-SS，提供了一个统一的概念框架，以提高泛化能力，促进想法的交叉融合，最终推动该领域的整体进展和实际应用。具体提出了Quad-directional Mixup（QuadMix）方法，该方法通过在特征空间中解决不同点属性和特征不一致问题，实现跨领域和同一领域内的混合。为了应对视频中的时间偏移，引入了基于光流的跨时空维度特征聚合方法，用于精细的空间领域对齐。广泛的实验表明，该方法在四个挑战性的UDA-SS基准测试中显著优于最新的工作。
### Conclusion
本文通过统一图像和视频场景下的UDA-SS研究，提供了一个全面的理解、协同进步和有效知识共享的概念框架。提出的QuadMix方法显著提高了UDA-SS的性能，证明了通过统一视角的创新对提高领域自适应语义分割技术的有效性，未来的研究有望进一步提升该领域的实际应用效果。
## 177. `cs.AI` - ViLBias: 检测和推断多媒体内容中的偏见 [PDF](https://arxiv.org/pdf/2412.17052), [HTML](https://arxiv.org/abs/2412.17052)
### Authors
Shaina Raza,Caesar Saleh,Azib Farooq,Emrul Hasan,Franklin Ogidi,Maximus Powers,Veronica Chatrath,Marcelo Lotif,Karanpal Sekhon,Roya Javadi,Haad Zahid,Anam Zahid,Vahid Reza Khazaie,Zhenyu Yu
### Background
检测多媒体新闻中的偏见需要模型能够对文本-图像对进行推理，而不仅仅是对文本进行分类。因此，该论文提出了ViLBias，这是一个利用问答风格基准及框架来检测和推理多媒体新闻中的偏见。数据集包含来自多种来源的40,945个文本-图像对，并使用两级LLM注释者管道和分层多数投票以及人工闭环验证进行标注，具有偏见标签和简洁的解释。评估结果显示，同时考虑图像和文本能够提高偏见检测准确性3-5%，并且大型语言模型/视觉-语言模型比小型语言模型更好捕捉文本-图像中的微妙语境和不一致现象。参数高效的方法在不到5%可训练参数的情况下，恢复了97-99%的完整微调性能。对于开放型问答（oVQA），推理准确率在52-79%之间，可靠性在68-89%之间，这些都通过指令微调得到改善；封闭准确度与推理的相关性很强（r=0.91）。
### Innovation
ViLBias提出了一个利用问答风格基准及框架来检测和推理多媒体新闻中的偏见，主要创新点包括：1. 构建了包含40,945个文本-图像对的数据集，每个对都进行了标注和解释；2. 设计了一种两级LLM注释者管道和分层多数投票及人工闭环验证方法进行标注；3. 评估了SLMs、LLMs、VLMs以及参数高效调优策略；4. 显示了结合图像和文本对偏见检测的改进效果；5. 揭示了大型语言模型/视觉-语言模型在捕捉文本-图像中的微妙偏见方面更具优势；6. 提出了几种参数高效的方法，这些方法在低训练参数下也能接近完整微调的性能；7. 对开放型问答（oVQA）的准确性和可靠性进行了评估，并显示了通过指令微调的改进；8. 提出了开放型问答与推理之间的强相关性。
### Conclusion
ViLBias提供了一个可扩展的基准和强力基线，用于多媒体偏见检测和推理质量。通过图像和文本的结合使用，可以显著提高对偏见的检测准确性，特别是对于大型语言模型/视觉-语言模型，它们能够在捕捉微妙语境和文本-图像不一致方面展现出更优的能力。参数高效的调优策略也表明，即使在少量的训练参数下，也能够达到接近完整的微调性能。
## 178. `cs.AI` - OffTopicEval: 当大型语言模型进入错误对话时，几乎总是如此！ [PDF](https://arxiv.org/pdf/2509.26495), [HTML](https://arxiv.org/abs/2509.26495)
### Authors
Jingdi Lei,Varun Gumma,Rishabh Bhardwaj,Seok Min Lim,Chuan Li,Amir Zadeh,Soujanya Poria
### Background
大型语言模型（LLM）的安全性是最紧迫的挑战之一，尤其是在广泛部署面临的问题中。大多数研究和全球讨论主要集中在普遍危害上，如模型帮助用户伤害自己或他人。然而，企业面临的是更基本的担忧：LLM 基础代理是否适用于其预期使用场景。本文将安全操作性定义为LLM在接受或拒绝用户查询时，在特定目的下的恰当表现能力。研究表明，尽管不同模型的表现存在差异，但所有模型在安全操作性方面仍然表现不佳，即便是表现最强的模型也无法达到可靠的运行安全性标准。因此，为了提高LLM的安全性和可靠性，提出了一些基于提示的方法，如查询基础指引（Q-ground）和系统提示基指引（P-ground），以改进异常外域（OOD）场景下的拒绝能力，提高LLM的安全性水平。这些结果表明，当前安全操作性还存在很大的改进空间，而基于提示的引导方法是较为有效的优化措施之一。
### Innovation
本文提出了安全操作性的概念，定义了LLM在执行特定任务时正确接受或拒绝用户查询的能力。作为这一概念下的具体实现，提出了OffTopicEval评估套件及其基准，用于测量通用及特定代理用途情境下的安全操作性。此外，提出了基于提示的方法，如查询基础指引（Q-ground）和系统提示基指引（P-ground），以提高LLM在异常外域情境下的拒绝能力。该方法显著提高了如Llama-3.3和Qwen-3等模型的安全性水平，从而有效抑制了系统中的意外行为。
### Conclusion
研究结果表明，LLM的安全操作性是一个紧迫问题，需要立即采取干预措施。同时，基于提示引导的方式是一种可观的初期方法，可以提高LLM的可靠性和安全性。
## 179. `cs.AI` - 仅需足够的决策：信息论上下文总结化在CMDPs中的学习 [PDF](https://arxiv.org/pdf/2510.01620), [HTML](https://arxiv.org/abs/2510.01620)
### Authors
Peidong Liu,Junjiang Lin,Shaowen Wang,Yao Xu,Haiqing Li,Xuhao Xie,Siyi Wu,Hao Li
### Background
现有的CMDP方法常常在高维度或无结构的上下文中无法有效泛化，导致计算量巨大且性能不稳定。
### Innovation
提出了基于信息论的总结化方法，利用大规模语言模型（LLMs）压缩上下文输入为低维且语义丰富的摘要，从而保留决策关键线索同时减少冗余。这种方法提供了知识上第一个关于CMDPs的后悔边界及延迟-熵权衡特征，并揭示了信息量对计算成本的影响。
### Conclusion
实验结果表明，本方法在各种场景（离散、连续、视觉和推荐）中优于直接上下文和无上下文的基线方法，提升了奖励、成功率和样本效率，同时减少了延迟和内存使用。这证明了基于LLM的总结化提供了一种在资源受限环境下高效决策的可扩展且可解析的解决方案。
## 180. `cs.AI` - RACCooN：具有自动生成叙述的多功能视频编辑框架 [PDF](https://arxiv.org/pdf/2405.18406), [HTML](https://arxiv.org/abs/2405.18406)
### Authors
Jaehong Yoon,Shoubin Yu,Mohit Bansal
### Background
现有视频生成模型主要依赖精心撰写的文本提示来执行特定任务，如修复、风格编辑等。这些模型需要耗费大量人工的时间来描述输入视频，这限制了它们灵活适应用户定制需求的能力。
### Innovation
提出了RACCooN，一种多功能且用户友好的视频到段落到视频生成框架，支持多种视频编辑能力，如删除、添加和修改，通过统一的流程实现。RACCooN的主要贡献在于：（1）提出了多尺度时空聚合策略，自动生成结构化的视频描述，涵盖广义背景和对象细节，无需复杂的人工注释，简化了基于文本的精确视频内容编辑。（2）视频生成模型结合了自动生成的叙述或指令，以提高生成内容的质量和准确性。（3）RACCooN还能构想出给定视频中的新对象，让用户只需提供详细的视频编辑计划即可实现复杂的视频编辑。
### Conclusion
所提出的框架在视频到段落的生成、视频内容编辑方面表现优异，并且可以集成到其他最先进的视频生成模型中，以进一步增强其功能。
## 181. `cs.AI` - 跨模态下AI模型是否进行类似人类的抽象推理？ [PDF](https://arxiv.org/pdf/2510.02125), [HTML](https://arxiv.org/abs/2510.02125)
### Authors
Claas Beger,Ryan Yi,Shuhao Fu,Arseny Moskvichev,Sarah W. Tsai,Sivasankaran Rajamanickam,Melanie Mitchell
### Background
OpenAI的o3-preview推理模型在ARC-AGI基准测试中超过了人类的准确度，但是否意味着最先进的模型能够识别和推理符合任务创建者初衷的抽象概念呢？该研究通过在不同输入模态（文本与视觉）、使用外部Python工具的权限以及推理努力程度不同的条件下评估模型，同时评估模型生成的自然语言规则来解决这一问题。研究发现，尽管一些使用基于文本表示的模型与人类输出准确度相当，但最佳模型的规则通常基于表面级的“捷径”，未能比人类更频繁地捕捉到任务设计意图中的抽象概念。这表明，在仅依赖准确度评估模型的抽象推理能力时可能会过高估计模型表现。
### Innovation
研究引入了结合输出准确性和自然语言规则生成的细粒度分析框架，用于评估模型在解决设计用于激发特定抽象的概念任务上的能力。同时，研究探讨了不同模态下（文本与视觉）模型的表现，并指出仅依赖准确度评估模型的抽象推理能力可能会导致在文本模态中高估而视觉模态中低估的表现。
### Conclusion
研究结果表明，模型在抽象推理方面依然落后于人类。而且，仅使用准确度来评估类似ARC任务的抽象推理能力在文本模态中可能会过高估计，在视觉模态中可能会低估。研究还表明，采用该评价框架能够更真实地反映多模态模型的抽象推理能力，并且提供了一种更有原则的方式来跟踪向人类中心、以抽象为重点的智能的进步。
## 182. `cs.AI` - LLAMAFUZZ: Large Language Model Enhanced Greybox Fuzzing [PDF](https://arxiv.org/pdf/2406.07714), [HTML](https://arxiv.org/abs/2406.07714)
### Authors
Hongxiang Zhang,Yuyang Rong,Yifeng He,Hao Chen
### Background
灰盒模糊测试在揭示程序中的错误和漏洞方面取得了成功，然而，随机化的变异策略限制了它在处理结构化数据时的性能。专门的模糊测试器可以处理复杂的结构化数据，但需要额外的努力来编写语法，并且吞吐量较低。
### Innovation
本文探讨了利用大型语言模型（LLM）来增强结构化数据的灰盒模糊测试的潜力。利用LLM关于数据转换和格式的预训练知识生成新的有效输入，并通过与变异种子对进行微调来学习结构化格式和变异策略。从而开发出LLAMAFUZZ，将LLM的强大功能集成到模糊测试中，用于理解和变异结构化数据。
### Conclusion
LLAMAFUZZ在基准测试Magma和一系列实际程序中表现出色。它比我们的主要竞争对手平均每试次发现41个更多错误，并在代码覆盖率和分支覆盖方面也表现出一致的性能。此外，还展示了通过LLM增强模糊测试过程的一个案例研究。
## 183. `cs.AI` - CBVLM：无需训练的解释性概念大型视觉语言模型用于医学影像分类 [PDF](https://arxiv.org/pdf/2501.12266), [HTML](https://arxiv.org/abs/2501.12266)
### Authors
Cristiano Patrício,Isabel Rio-Torto,Jaime S. Cardoso,Luís F. Teixeira,João C. Neves
### Background
当前在医疗流程中应用基于深度学习的解决方案的主要障碍是标注数据的稀缺性和该类系统的不解释性。概念瓶颈模型（CBMs）通过限制模型输出到一组预定义且可由人类解释的概念来解决解释性问题。然而，这种方法增加了标注负担，并且如果需要添加新的概念，则整个系统需要重新训练。
### Innovation
本文提出了CBVLM（无需训练的解释性概念大型视觉语言模型），该方法结合了大型视觉语言模型（LVLM）的少样本性能优势，通过提示LVLM判断输入图像中是否存在概念，并基于这些概念进行分类。此外，通过一个检索模块选择最好的例子进行上下文学习，从而降低标注成本并保证解释性。
### Conclusion
作者通过在四个医学数据集中进行了广泛实验，在12种大型视觉语言模型（包括通用和医学的）上对CBVLM进行了验证，结果显示CBVLM在没有任何训练的情况下使用少量标注数据始终优于CBMs和任务特定的监督方法。更多详细信息请访问我们的项目页面：this https URL.
## 184. `cs.AI` - Thinkquel: 一种专用于文本到dbt模型，利用合成数据和区间感知目标 [PDF](https://arxiv.org/pdf/2510.00186), [HTML](https://arxiv.org/abs/2510.00186)
### Authors
Anni Li,Aria Attar,Paul Dong
### Background
将自然语言请求转化为可靠的、生产级别的数据转换依然具有挑战性。准确性依赖于精确的模式链接和特定仓库的SQL方言。可用的最强监督仅在序列级别提供，即执行成功和结果匹配。然而，构建大规模且经过执行验证的数据集成本高，而基于令牌级的目标与全局信号不匹配，导致优化不稳定且可移植性有限。
### Innovation
Thinkquel通过引入一种新颖的合成数据管道TS-SQL，结合dbt作为一种可移植的中间表示，并且使用区间感知的强化学习目标，旨在弥补令牌级训练信号与序列级执行奖励之间的差距。此外，针对大语言模型的调优，提出了Token-Sequence GRPO (TS-GRPO)。Thinkquel在500例TS-SQL测试集上达到了93.2%的执行成功率和61.8%的结果匹配率，分别比基础模型提高了67.2%和44.4%。这显示了其在训练稳定性和加速执行匹配奖励收敛方面的优势。
### Conclusion
Thinkquel通过上述方法，显著提高了数据库查询生成的执行成功率和结果匹配率，展示了在合成数据和区间感知目标方面的创新。其在Spider (14B)实验中进一步增强了大语言模型的训练稳定性和加速了执行奖励的收敛。
## 185. `cs.AI` - 通过混合遗传算法实现集装箱装卸的优化和码头再处理减少 [PDF](https://arxiv.org/pdf/2406.08534), [HTML](https://arxiv.org/abs/2406.08534)
### Authors
Md. Mahfuzur Rahman,Md Abrar Jahin,Md. Saiful Islam,M. F. Mridha
### Background
该论文解决了港口集装箱处理中的NP难问题，通过整合码头龙门起重机双循环（QCDC）和减少码头装卸次数，以优化卸货顺序与码头计划间的相互依赖性。研究展示了现有方法与提出的QCDC-DR-GA算法在这两方面的性能差异，并通过统计学方法验证了算法的有效性，强调了孤立优化的低效性和整合算法的必要性，从而提高资源利用和运营效率，给出了一种经济有效的减少港口处理时间的方法，而不需进行大规模基础设施投资。
### Innovation
提出了QCDC-DR-GA，这是一种混合遗传算法，同时优化双循环次数和减少码头再处理次数，具备专门的交叉和突变策略。实验结果表明，对于大型船只，QCDC-DR-GA将总操作时间减少了15-20%。通过双侧配对t检验验证了显著性改进，显著性水平为5%。
### Conclusion
结果强调了孤立优化的低效性和集成算法的必要性。该方法提高了资源利用和运营效率，为港口减少处理时间提供了经济有效的解决方案，无需大规模基础设施投资。
## 186. `cs.AI` - MarketSenseAI 2.0: 提升股票分析的LLM代理 [PDF](https://arxiv.org/pdf/2502.00415), [HTML](https://arxiv.org/abs/2502.00415)
### Authors
George Fatouros,Kostas Metaxas,John Soldatos,Manos Karathanassis
### Background
MarketSenseAI 是一个利用大语言模型（LLMs）综合分析股票市场的新型框架。该框架通过处理财务新闻、历史价格、公司基本面和宏观经济环境来支持股票分析和选择。论文介绍了由LLMs技术快速扩张驱动的最新进展。该框架通过检索增强生成和LLM代理的新颖架构来处理SEC公告和收益电话，并通过系统地处理各种机构报告来丰富宏观经济分析。
### Innovation
提出了一个新颖的检索增强生成和LLM代理架构，该架构能够处理SEC公告和收益电话，并通过系统化处理多种机构报告来丰富宏观经济分析。实验证明，该框架在基本面分析准确性上较之前的版本有了显著提升。在2023-2024年的S&P 100股票上进行的实证研究显示，MarketSenseAI 较指数回报实现累计收益125.9%，同时保持相似的风险敞口。进一步验证，在2024年的S&P 500股票上，该框架获得了33.8%更高的索提诺比率。
### Conclusion
这项工作标志着将LLM技术应用于金融分析的进步，提供了LLM驱动的投资策略稳定性的见解。
## 187. `cs.AI` - 重新思考概念擦除的脆弱性及一种新方法 [PDF](https://arxiv.org/pdf/2502.17537), [HTML](https://arxiv.org/abs/2502.17537)
### Authors
Alex D. Richardson,Kaicheng Zhang,Lucas Beerens,Dongdong Chen
### Background
随着文本生成图像扩散模型的普及，人们对这些模型生成受版权保护或有害图像的问题越来越关注。为应对这一问题，开发了概念擦除（防御）方法，通过后处理微调来“忘记”特定概念。然而，一些概念恢复（攻击）方法表明，这些被擦除的概念可以用对抗性构造的提示恢复，揭示了目前防御机制中的关键漏洞。
### Innovation
论文首先探究了对抗性脆弱性的基础来源并揭示了这些脆弱性存在于概念擦除模型的提示嵌入空间中，这一特征继承自原始的未学习模型。此外，提出了名为RECORD的新坐标下降恢复算法，该算法比现有恢复方法的性能高17.8倍。还进行了广泛的实验证明其计算性能折衷，并提出了加速策略。
### Conclusion
研究表明概念擦除模型存在对抗性脆弱性，并且RECORD算法是高效的恢复算法，具有较高的性能。
## 188. `cs.AI` - Primus: 开源数据集在网络安全LLM培训中的先驱汇集 [PDF](https://arxiv.org/pdf/2502.11191), [HTML](https://arxiv.org/abs/2502.11191)
### Authors
Yao-Ching Yu,Tsun-Han Chiang,Cheng-Wei Tsai,Chien-Ming Huang,Wen-Kwang Tsao
### Background
大型语言模型（LLMs）已在金融、法律和医学等特定领域取得了显著进步，但在网络安全领域，开源数据集却存在严重不足，尤其是在高质量的预训练语料方面。尽管有研究表明，LLMs在其知识预训练过程中获得，但安全领域的此类数据稀缺。为解决这一问题，本文提供了一个覆盖所有主要训练阶段（预训练、指令微调和具有网络安全特定自我反思数据的推理精炼）的全面数据集套件，展示其在公共网络安全基准上的有效性。特别是，持续预训练提高了综合得分15.9%，而推理精炼则提升了安全认证（CISSP）15.8%的水平。所有数据集和已训练的网络安全LLMs将通过ODC-BY和MIT许可协议公开，以促进该领域的进一步研究。
### Innovation
本文创新地提供了一个覆盖网络安全全部训练阶段的全面数据集套件，包括预训练、指令微调和推理精炼，特别纳入了网络安全特定自我反思数据。此外，通过公开数据集和已训练的模型，鼓励社区进一步进行研究，并进行详尽的消融研究以验证其有效性和改进点。
### Conclusion
综合考量，持续预训练显著提升了综合评分，推理精炼对安全认证CISSP指标有明显改善。所有相关数据集和模型将充分公开，以促进网络安全LLM领域的研究进展。
## 189. `cs.AI` - 预训练编码器的互信息引导型后门去污染技术 [PDF](https://arxiv.org/pdf/2406.03508), [HTML](https://arxiv.org/abs/2406.03508)
### Authors
Tingxu Han,Weisong Sun,Ziqi Ding,Chunrong Fang,Hanwei Qian,Jiaxun Li,Zhenyu Chen,Xiangyu Zhang
### Background
自监督学习（SSL）作为一种无需标记数据即可预训练编码器的方法变得越来越有吸引力。基于这些预训练编码器的下游任务可以达到接近最先进的性能。然而，通过SSL预训练的编码器在面对后门攻击时存在脆弱性，已有研究证明了这一点。尽管存在大量针对下游任务模型的后门攻击缓解技术，但在应用于预训练编码器时，因为预训练中的缺乏标记信息，其效果受到了限制。因此，为解决针对预训练编码器的后门攻击，本文提出了一种新的互信息引导型后门去污染技术，命名为MIMIC。
### Innovation
MIMIC通过将可能存在后门的编码器视为教师网络，并利用知识蒸馏从该教师网络中提取一个无后门的学生编码器来攻击后门。MIMIC的不同之处在于它以随机权重初始化学生编码器，不会继承教师网络中的后门。MIMIC利用每一层与提取特征之间的互信息来识别教师网络中的良性知识所在，然后使用这些良性知识进行蒸馏，以从教师网络中复制干净的特征到学生网络中。此外，MIMIC的蒸馏损失包含两方面，克隆损失和注意力损失，旨在同时减轻后门影响和保持编码器的性能。实验结果表明，MIMIC仅使用不到5%的干净数据即可显著降低攻击成功率，超越了七个最先进的后门攻击缓解技术。
### Conclusion
本文提出了一种名为MIMIC的新颖的互信息引导型后门去污染技术，能够在使用少量干净数据的情况下有效提升预训练编码器的安全性，改善其在存在后门攻击情况下的表现。
## 190. `cs.AI` - 使用机器学习推断插件类型 [PDF](https://arxiv.org/pdf/2406.15676), [HTML](https://arxiv.org/abs/2406.15676)
### Authors
Kazi Amanul Islam Siddiqui,Martin Kellogg
### Background
插件类型系统允许程序员扩展编程语言的类型系统以强制执行由程序员定义的语义属性。然而，在现有的代码库中部署插件类型系统具有挑战性，因为需要程序员手动编写类型注解。这篇文章研究了如何使用机器学习自动推断类型注解。通过建立以最小数据流提示来表示的新型表示 NaP-AST，有效的推断类型注解是可能的。进一步地，研究了几种模型架构来推断类型注解，包括图转换器网络、图卷积网络和大型语言模型。这些模型在先前评估NullAway插件类型检查器的12个开源程序上进行了试验应用，除了一个未注释的项目外，降低了警告。经过研究确定，图转换器网络（GTM）显示出最佳表现，召回率为0.89，精确率为0.6。此外，还进行了研究来估算训练模型取得良好性能所需的Java类的数量。在我们的可行性研究中，性能在大约16,000个类时提升，在大约22,000个类时因过拟合下降。
### Innovation
提出了一种新型表示NaP-AST，用于编码最小数据流提示，以有效推断类型注解。研究了几种模型架构，包括图转换器网络、图卷积网络和大型语言模型，以推断类型注解。实验证实了这些模型的有效性，尤其是在Java开源程序上的应用。确定了图转换器网络（GTM）最佳的性能表现，并估计了训练模型取得良好性能所需的Java类数量。
### Conclusion
研究发现图转换器网络（GTM）在推断类型注解方面表现出色。通过16,000个类的Java类可获得良好的性能，但超过22,000个类时可能会因过拟合而性能下降。
## 191. `cs.AI` - LLM自解释的冗余权衡与规模对忠诚度的影响 [PDF](https://arxiv.org/pdf/2503.13445), [HTML](https://arxiv.org/abs/2503.13445)
### Authors
Noah Y. Siegel,Nicolas Heess,Maria Perez-Ortiz,Oana-Maria Camburu
### Background
在被要求解释决策时，大型语言模型（LLMs）可以提供听起来合理但不一定准确的解释。本文研究了75个来自13个家族的不同模型的反事实忠诚度，分析了简洁性和详尽性之间的权衡问题，如何使用相关反事实测试（CCT）来衡量这种权衡，以及这些测试所面对的挑战，例如被操纵性。研究表明，较大的、功能更强的模型在涉及的所有衡量标准上都更忠实。
### Innovation
本文提出了一种新的简化版相关反事实测试（phi-CCT），它避免了计算令牌概率的需求，但仍能解释原始测试的大部分变异。还提出了F-AUROC，能够消除不平衡干预分布的影响，并捕捉到模型生成不同详细程度解释的能力。这两种新指标提高了测试模型解释能力的准确性和实用性。
### Conclusion
研究表明，更大的、更强大的模型通常在所有采用的忠诚度衡量标准上表现得更忠实。此外，随着模型规模的增加，它们对反事实忠诚度的改善是渐进的。研究结果通过开源代码在github上公布，供其他研究人员使用和验证。
## 192. `cs.AI` - 不是困扰而是有用的启发：异常维度偏好频繁出现的词汇 [PDF](https://arxiv.org/pdf/2503.21718), [HTML](https://arxiv.org/abs/2503.21718)
### Authors
Iuri Macocco,Nora Graichen,Gemma Boleda,Marco Baroni
### Background
研究发现，许多现代语言模型中的最后一层中存在异常维度，这些维度在大多数输入中表现为极端激活。这些异常维度的出现被视为模式中的一个普遍现象。相关研究表明，这些异常维度的功能可以追溯到不断预测高频词汇的启发式方法。因此，背景集中在理解这些异常维度产生的原因及其对模型性能的影响上。
### Innovation
提出了如何通过分配剩余维度的相反权重来抑制这种偏好，特别是当这种偏好在上下文中不适当的时候。此外，研究了哪些模型参数能够促进异常维度的产生，并探讨了异常维度的出现情况及其在训练中的时间点。这项研究揭示了异常维度作为许多不同模型发现的一种专门机制，用于实施有用的标记预测启发式方法。
### Conclusion
异常维度并非噪音，而是一种有用的启发，它偏好频繁出现的词汇。异常维度的存在是由许多不同模型在多种情况下发现的一种专门机制，用于实现有效的标记预测启发式方法，从而提升模型性能。
## 193. `cs.AI` - L1: 通过强化学习控制推理模型的思考时长 [PDF](https://arxiv.org/pdf/2503.04697), [HTML](https://arxiv.org/abs/2503.04697)
### Authors
Pranjal Aggarwal,Sean Welleck
### Background
语言模型展现了强大的推理能力，通过生成更长的思考链来提高测试时的表现。然而，现有的模型无法控制其推理长度，导致无法指定计算资源以达到预期的性能水平。
### Innovation
引入了一种简单的强化学习方法——Length Controlled Policy Optimization (LCPO)，该方法旨在优化准确性和遵循用户指定的长度约束。通过LCPO训练的L1模型能够按照提示中的长度约束生成满足长度要求的输出，从而在多种任务上实现了计算成本和准确性的平衡，并超越了现有的S1方法。此外，使用LCPO还发现了一种短推理模型SRM，其表现出与完整长度推理模型相似的推理模式，却能生成与非推理模型相当的思考链长度，并在某些情况下表现出显著的性能提升。
### Conclusion
LCPO能够精确控制推理长度，使得测试时间的算力和准确性可以精细分配。同时，实验结果表明，使用LCPO训练的模型可以生成具有竞争力的思考链长度，显示了灵活性和有效性。
## 194. `cs.AI` - 在图机器学习中量化长距离交互：一个大规模图数据集和一个测量方法 [PDF](https://arxiv.org/pdf/2503.09008), [HTML](https://arxiv.org/abs/2503.09008)
### Authors
Huidong Liang,Haitz Sáez de Ocáriz Borde,Baskaran Sripathmanathan,Michael Bronstein,Xiaowen Dong
### Background
现有的图数据库主要针对小规模图和归纳任务，缺乏对长距离交互的深入探索。当前的评估方法主要比较采用了全局注意力机制（如图变换器）和局部邻域聚合机制（如消息传递神经网络）的模型，但没有直接量度长距离依赖关系。由于缺乏适当的数据集，现有工作难以全面研究长距离依赖在图神经网络中的作用。该论文提出了City-Networks数据集，该数据集基于真实城市道路网络，包含超过10万个节点的图，并具有比现有基准更大直径，从而自然地包含长距离信息。通过对本地节点 eccentricities 进行标注以确保任务需要远距离节点的信息，为研究长距离依赖关系提供了新的视角。
### Innovation
本文提出City-Networks数据集，该数据集具有大规模的图和显著的长径，能够有效捕捉长距离交互。提出了一种基于遥远跳跃邻居雅可比的模型无关测量方法，用于量化长距离依赖，能更准确地表征长距离依赖关系。
### Conclusion
本文不仅通过City-Networks数据集提供了直接评估长距离依赖的有效方法，还通过理论分析为该领域的进一步研究奠定了坚实的基础，特别是在过平滑和影响得分稀释等方面提供了理论依据。
## 195. `cs.AI` - 多保真控制变量方法用于策略梯度估计 [PDF](https://arxiv.org/pdf/2503.05696), [HTML](https://arxiv.org/abs/2503.05696)
### Authors
Xinjie Liu,Cyrus Neary,Kushagra Gupta,Wesley A. Suttle,Christian Ellis,Ufuk Topcu,David Fridovich-Keil
### Background
许多强化学习（RL）算法在部署到实际系统或使用计算成本高昂的高保真模拟器进行训练时不可行，因为它们需要大量的数据。同时，低保真模拟器，如降阶模型、启发式奖励或生成世界模型，可以廉价地提供有用的RL训练数据，尽管它们在零样本迁移时过于粗略。本文背景在于探索如何利用廉价的低保真数据和少量真实的高保真数据来提高训练效率和有效率的模拟到现实的迁移。
### Innovation
提出了一种多保真策略梯度（MFPG）框架，该框架通过混合目标环境的小量真实数据和大量的低保真模拟数据来构建无偏且方差减少的策略梯度估计。在此框架下，实例化了一个多保真版的经典REINFORCE算法。研究表明，在标准假设下，MFPG估计器可确保在目标环境中REINFORCE算法收敛到局部最优策略，并且相比仅使用高保真数据训练，具有更快的有限样本收敛速度。实验证明，MFPG算法在具有有限高保真数据但丰富的离动模数据的模拟机器人基准任务中表现良好，即使在动态差距适中时也能改进高保真度基线的中位性能，且在较大的动态差距时展现出最强的鲁棒性，并且在低保真奖励指定不准确的情况下仍保持有效。
### Conclusion
MFPG不仅提供了一种高效的模拟到现实转移的新范式，还提供了一种管理策略性能和数据收集成本之间的权衡的有说服力的方法。
## 196. `cs.AI` - 激活式LoRA：用于固有模型的微调LLMs [PDF](https://arxiv.org/pdf/2504.12397), [HTML](https://arxiv.org/abs/2504.12397)
### Authors
Kristjan Greenewald,Luis Lastras,Thomas Parnell,Vraj Shah,Lucian Popa,Giulio Zizzo,Chulaka Gunasekara,Ambrish Rawat,David Cox
### Background
低秩适应（LoRA）已经成为一种高效的框架，用于调整大型基础模型的权重，成为数据驱动定制LLMs的首选方法。尽管LoRA可以提供高度定制化的行为和能力，但在多轮的情况下，切换到相关LoRA时效率低下，因为整个回合历史的键值（KV）缓存必须在生成开始前重新计算。这导致了持续高效的多轮任务处理挑战。
### Innovation
我们提出了激活式LoRA（aLoRA），这是一种适应器架构，它修改了LoRA框架，使得aLoRA只适应在其被触发后的序列中的令牌权重。这种方法允许aLoRA接受基础模型的输入字符串的关键值缓存，这意味着aLoRA可以随时激活而无需重新计算之前的键和值，从而解决了之前的效率问题。这使得能够构建我们称之为固有的模型，即专门为输入链或对话的某些部分执行特定操作的模型，这些部分默认使用基础模型。
### Conclusion
我们训练了一组基于aLoRA的固有模型，证明了其在准确度上与标准LoRA竞争的同时，显著提高了推理效率。我们还将我们的激活式LoRA实现贡献给了Huggingface PEFT库。
## 197. `cs.AI` - 基于图神经网络的输电网络拓扑控制：母线信息不对称性和异构表示 [PDF](https://arxiv.org/pdf/2501.07186), [HTML](https://arxiv.org/abs/2501.07186)
### Authors
Matthijs de Jong,Jan Viebahn,Yuliya Shapovalova
### Background
随着可再生能源的普及和电气化的增加，电网拥堵成为一个待解决的重要问题。传统的拓扑控制方法已经证明在实际应用中速度太慢。因此，最近的研究转向利用机器学习（ML）作为一种有效的替代方案。在所有机器学习方法中，图神经网络（GNNs）特别适用于拓扑控制领域，因为它们能够处理电力网络的图形结构。然而，使用同构图表示存在母线信息不对称的问题。该研究旨在探索不同图表示对GNN效果的影响，并提出了一种解决此问题的异构图表示方法。通过对比同构和异构图神经网络以及全连接神经网络（FCNN）在仿真学习任务中的表现，研究人员发现异构图神经网络在内部网络配置中表现最佳，全连接神经网络次之，同构图神经网络表现最差。此外，两种图神经网络在外部网络配置中的泛化能力优于全连接神经网络。
### Innovation
本文提出了一种异构图表示方法来解决同构图表示下的母线信息不对称性问题，并基于此进行图神经网络（GNNs）的研究应用。通过对比不同的图神经网络模型在仿真学习任务中的表现，证明了异构图神经网络的有效性并提供了针对不同网络配置的解决方案。
### Conclusion
异构图神经网络在内部网络配置中的表现优于同构图神经网络和全连接神经网络。此外，无论是同构图神经网络还是异构图神经网络，它们在外部网络配置中的泛化能力都优于全连接神经网络。
## 198. `cs.AI` - 朝向经济推理：在任何基于Transformer的语言模型中启用深寻的多头潜在注意力 [PDF](https://arxiv.org/pdf/2502.14837), [HTML](https://arxiv.org/abs/2502.14837)
### Authors
Tao Ji,Bin Guo,Yuanbin Wu,Qipeng Guo,Lixing Shen,Zhan Chen,Xipeng Qiu,Qi Zhang,Tao Gui
### Background
现有的大型语言模型（LLM）如Llama等使用多头注意力机制（MHA及其变体GQA）存在显著的成本劣势。传统的多头注意力机制需要大量的存储和计算资源来处理关键值（KV）缓存，导致推理过程昂贵且耗时。因此，研究人员致力于寻找一种方法，让已经训练好的LLM能够快速适应一种新的架构——多头潜在注意力（MLA），而不需要从零开始重新训练。DeepSeek提出了一种新的MLA架构，通过显著压缩KV缓存为潜在向量来实现高效的推理。然而，如何让已训练的LLM快速适应MLA而不进行从零开始的初始化训练仍然是一个挑战。
### Innovation
本文提出了首个用于从MHA向MLA迁移的数据高效细化方法（MHA2MLA），该方法包含两个关键组成部分：1）部分方位角余弦位置编码（partial-RoPE）：从较少对注意力分数有贡献的查询和键维度中移除RoPE；2）低秩近似：引入基于预训练关键值参数的联合SVD近似。这些精心设计的策略使得MHA2MLA在仅使用少量数据（0.3%至0.6%）的情况下恢复性能，同时显著降低推理成本，并且可以无缝结合压缩技术，如KV缓存量化。通过这种方法，Llama2-7B的KV缓存大小减少了92.19%，同时仅带来0.5%的长基准性能下降。
### Conclusion
通过MHA2MLA方法，已经训练好的LLM可以快速迁移到MLA架构，从而降低推理成本。这项工作不仅验证了MLA的有效性，还展示了如何在不重新训练模型的情况下，让预训练的LLM适应新的高效推理架构。这对于减少大型语言模型的计算资源需求和提高其经济性具有重要意义。
## 199. `cs.AI` - PropRAG：使用命题路径上的束搜索引导检索 [PDF](https://arxiv.org/pdf/2504.18070), [HTML](https://arxiv.org/abs/2504.18070)
### Authors
Jingjin Wang,Jiawei Han
### Background
Retrieval Augmented Generation (RAG) 是装备大型语言模型 (LLMs) 以保持最新知识的标准方法。然而，标准的 RAG 依赖于独立段落检索，常难以捕捉复杂多步推理所需的相互联系信息。虽然结构化的 RAG 方法通过构建从三元组生成的知识图来尝试解决这一问题，但三元组的固有上下文丢失（上下文塌缩）限制了知识表示的精确度。
### Innovation
PropRAG 引入了一个新颖的 RAG 框架，从三元组转向丰富的命题，并引入了一种 LLM 无关的在线束搜索高效算法，以发现多步推理路径。通过结合更精确的知识表示和显式的路径发现，PropRAG 在 2Wiki、HotpotQA 和 MuSiQue 上实现了零样本下的顶级 Recall@5 和 F1 分数，从而通过更丰富的表现和高效的推理路径发现改进了非参数知识的集成.
### Conclusion
PropRAG 通过提供高保真知识表示和有效的推理路径发现，显著提升了零样本下多步推理链的证据检索能力，推进了非参数知识集成技术的进步。
## 200. `cs.AI` - AlignDiT: 多模态对齐扩散变压器用于同步语音生成 [PDF](https://arxiv.org/pdf/2504.20629), [HTML](https://arxiv.org/abs/2504.20629)
### Authors
Jeongsoo Choi,Ji-Hoon Kim,Kim Sung-Bin,Tae-Hyun Oh,Joon Son Chung
### Background
本文讨论了多模态到语音生成的任务，目的是从多种输入模态：文本、视频和参考音频中合成高质量的声音。由于其广泛的应用场景，如影视制作、配音和虚拟化身，该任务引起了越来越多的关注。尽管最近取得了一些进展，但现有方法仍然在语音可懂度、音频-视频同步、自然语音发音和参考说话者的声音相似性方面存在局限性。
### Innovation
本文提出了AlignDiT，这是一种多模态对齐扩散变压器，可以从对齐的多模态输入中生成准确、同步且自然的语音。AlignDiT 基于 DiT 架构的在上下文学习能力，探索了三种有效的策略来对齐多模态表示。此外，引入了一种新的多功能模态无条件分类器导引机制，允许模型在语音合成时适应性地平衡每个模态的信息。广泛的实验证明，AlignDiT 在质量、同步性和说话者相似性方面显着超越了现有方法。此外，AlignDiT 在各种多模态任务中表现出强大的泛化能力，如视频到语音合成和视觉强制对齐，一直保持了最佳性能。
### Conclusion
实验结果表明，AlignDiT 在多项基准测试中在质量和同步性方面显著优于现有方法，并且在各种多模态任务中表现出强大的泛化能力，保持了最佳性能。演示页面可以在该网址查看：this https URL。
## 201. `cs.AI` - 复杂语音 spectrograms 的深度学习研究 [PDF](https://arxiv.org/pdf/2505.08694), [HTML](https://arxiv.org/abs/2505.08694)
### Authors
Yuying Xie,Zheng-Hua Tan
### Background
深度学习的最新进展显著影响了语音信号处理领域，特别是在复杂谱图的分析和操纵方面。本文综述了利用深度神经网络处理复杂谱图的先进技术，这些谱图包含了幅度和相位的信息。
### Innovation
本文回顾了将实值神经网络应用于复杂谱图的方法及其架构设计，并讨论了针对处理和建模复杂谱图的神经网络的各种训练策略和损失函数。此外，还探讨了复杂谱图与生成模型的交集。
### Conclusion
本综述旨在为语音信号处理、深度学习及相关领域的研究人员和从业者提供有价值的资源。
## 202. `cs.AI` - OT 分数：基于最优运输的无源无监督域适应置信度分数 [PDF](https://arxiv.org/pdf/2505.11669), [HTML](https://arxiv.org/abs/2505.11669)
### Authors
Yiming Zhang,Sitong Liu,Alex Cloninger
### Background
当前的分布对齐方法在无标签的目标领域（source-free无监督域适应，SFUDA）下存在计算和理论上的限制。特别是在没有目标标签的情况下估计分类性能和置信度方面存在挑战。现有的理论框架往往导致计算上的不可计算量，并不能充分反映所使用对齐算法的特性。
### Innovation
引入了最优传输（OT）分数，这是一种新的理论分析得出的置信度度量，利用判别边界灵活性的半离散最优传输对齐。所提出的OT分数具有直观的可解释性和理论严谨性，可以为任何给定的目标伪标签集提供原则性的不确定性估计。实验结果表明，OT分数优于现有的置信度分数，还通过训练时的重加权改善了SFUDA性能，并提供了一个无需标签的模型性能的可靠代理。
### Conclusion
OT分数优于现有信心分数，并能通过训练时重加权提高SFUDA性能，同时还提供了一个无需标签的模型性能的可靠代理。
## 203. `cs.AI` - 从标准多臂 bandit 实验中比较 LLMs 和人类的探索-利用策略：洞察 [PDF](https://arxiv.org/pdf/2505.09901), [HTML](https://arxiv.org/abs/2505.09901)
### Authors
Ziyuan Zhang,Darcy Wang,Ningyuan Chen,Rodrigo Mansur,Vahid Sarhangian
### Background
大型语言模型（LLMs）在复杂序列决策环境中被用作模拟或自动化人类行为的方法。自然地，人们会问LLMs是否在决策行为上与人类相似，且能否达到相同的（或更好的）表现。本研究主要聚焦在探索-利用（E&E）权衡这一动态决策不确定性下的基本方面，使用认知科学和精神病学文献中引入的经典多臂.bandit（MAB）实验，对LLMs、人类和MAB算法的E&E策略进行比较研究。研究通过可解释的选择模型捕捉代理的E&E策略，并调查如何通过提示策略和思考模型启用思考轨迹以重塑LLM决策行为。
### Innovation
本工作结合标准多臂.bandit实验，系统性地比较了LLMs、人类和MAB算法的探索-利用策略；通过可解释的选择模型获取更深层次的洞察；并探讨了如何通过启用思考轨迹来塑造LLM的决策行为机制。
### Conclusion
研究发现，启用思考轨迹的LLMs表现出更接近人类的探索行为，包含随机和定向探索两者。在简单的稳定环境中，思考诱发的LLMs在随机和定向探索的水平上与人类相似。但在更复杂、非稳定环境中的表现，LLMs难以与人类的适应性和高效定向探索相匹配，尽管在某些场景中它们能获得相似的遗憾值。该研究指出了LLMs在模拟人类行为和自动化决策工具方面存在的潜力和局限，并提出了改进的可能性。
## 204. `cs.AI` - DatawiseAgent：面向笔记本的LLM代理框架，实现适应性和稳健的数据科学自动化 [PDF](https://arxiv.org/pdf/2503.07044), [HTML](https://arxiv.org/abs/2503.07044)
### Authors
Ziming You,Yumiao Zhang,Dexuan Xu,Yiwei Lou,Yandong Yan,Wei Wang,Huaming Zhang,Yu Huang
### Background
现有的大型语言模型（LLM）代理在自动化数据科学方面展现出潜力，但它们仍然受到任务范围狭窄、任务间泛化能力有限以及过度依赖最新状态（SOTA）的LLM的限制。现有模型在处理复杂数据科学任务时表现出局限性，尤其是当任务范围扩大或需要跨多个模型的应用时。本文旨在介绍一种名为DatawiseAgent的新框架，它采用基于计算笔记本的工作方式，提供适应性更强、更具稳健性的数据科学自动化解决方案。DatawiseAgent通过设计统一的交互表示和基于有限状态转换器（FSTs）的多阶段架构，实现了灵活的长视规划、逐步解决方案开发以及从执行错误中恢复的能力。
### Innovation
DatawiseAgent框架通过以下创新点来提升数据科学自动化的效果：1）提出一个基于有限状态转换器（FSTs）的封装多阶段架构，促进长期规划和逐步解决方案开发。2）设计一个统一的交互表示法，使得Agent能更好地与用户及系统中的多层次交互进行对话。3）展现出在不同数据科学场景和模型中的一致性和有效性，显著超过AutoGen和TaskWeaver等基线模型，证明了其优越的有效性和适应性。此外，在使用较弱或较小模型时，尽管性能有所下降，数据智慧代理依然保持了稳定的性能，这进一步展示了其稳健性和可扩展性。
### Conclusion
通过实验验证，DatawiseAgent在多项数据科学任务上保持了SOTA的性能，并在较弱或较小模型下也保持了良好的性能，显示出其实用性和可扩展性。因此，这项研究提供了新的途径，用于设计更为适应和稳健的大规模语言模型代理，为数据科学任务的自动化带来实质性的好转。
## 205. `cs.AI` - 用内部和外部知识预训练有限记忆语言模型 [PDF](https://arxiv.org/pdf/2505.15962), [HTML](https://arxiv.org/abs/2505.15962)
### Authors
Linxi Zhao,Sofian Zalouk,Christian K. Belardi,Justin Lovelace,Jin Peng Zhou,Ryan Thomas Noonan,Dongyoung Go,Kilian Q. Weinberger,Yoav Artzi,Jennifer J. Sun
### Background
神经语言模型是黑盒子，它们通过数十亿个不透明参数分布式地存储语言模式和事实知识。这种复杂的编码使检查、验证或更新特定事实变得困难。
### Innovation
引入了有限记忆语言模型（LMLM），在预训练过程中将事实知识外置到外部数据库中，而不是存储在模型权重中。通过战略性地从训练损失中屏蔽外部抽取的事实值，该模型被教导执行针对性的查询，而非依赖记忆型权重。
### Conclusion
实验表明，LMLM相比更大规模的语言模型在标准基准上具有竞争力，同时提供明确、可编辑和可验证的知识库的优势。
## 206. `cs.AI` - 利用在线数据增强小规模波斯语医疗语言模型的知识 [PDF](https://arxiv.org/pdf/2505.16000), [HTML](https://arxiv.org/abs/2505.16000)
### Authors
Mehrdad Ghassabi,Pedram Rostami,Hamidreza Baradaran Kashani,Amirhossein Poursina,Zahra Kazemi,Milad Tavakoli
### Background
语言模型的快速发展展示了人工智能在医疗行业中的潜力。然而，小型语言模型在低资源语言如波斯语的专业领域中面临挑战。尽管存在许多波斯语的医疗领域的网站，但缺乏专门的数据库或语料库，本研究首次构建了一个包含20000个医生患者问答对以及9000万词语料库60%的从医学杂志抓取的语料库。
### Innovation
本研究通过参数高效的微调方法，增强了基础模型aya-expanse-8b的医疗知识。基准评估显示，微调后的模型在医学问答任务中提高了准确性，并成功通过了2023年9月的伊朗基础医学科学入学考试（IBSEE），而基础模型未能通过。此外，微调后的模型还提高了波斯语翻译MMLU的准确性2.67%。这工作突显了利用开放访问的在线数据增强小型医疗领域的语言模型的潜力。
### Conclusion
本研究强调了利用开放访问的在线数据增强小型语言模型的能力，为资源受限的环境下波斯语医疗人工智能应用提供了一个新颖的解决方案。未来的研究可以探索多模态输入进一步提高性能。
## 207. `cs.AI` - CostFilter-AD: 通过匹配成本过滤提高异常检测 [PDF](https://arxiv.org/pdf/2505.01476), [HTML](https://arxiv.org/abs/2505.01476)
### Authors
Zhe Zhang,Mingxiu Cai,Hanxiao Wang,Gaochang Wu,Tianyou Chai,Xiatian Zhu
### Background
无监督异常检测（UAD）旨在识别输入图像中的异常部分相对于正常样本。现有方法通常依赖于图像级别或特征级别的匹配来生成异常分数，但这种匹配过程往往不够准确且容易被忽视，导致检测效果不佳。本文旨在通过引入代价过滤方法（借鉴经典匹配任务中的代价过滤方法），解决这一问题，从而改善异常检测的准确性.
### Innovation
提出了一种称为CostFilter-AD的方法，即代价过滤异常检测。该方法首先构建输入图像与正常样本之间的匹配代价体，然后通过多重特征层引导输入观察作为注意力查询的代价体过滤网络，该系统能有效抑制匹配噪声，保持边缘结构并捕捉细微异常。CostFilter-AD作为通用后处理插件，可以与重建基方法或嵌入基方法兼容，验证了其在单类和多类UAD任务中的通用优点.
### Conclusion
在MVTec-AD和VisA基准上的实验验证了CostFilter-AD在单类和多类UAD任务中的一般优势。代码和模型将在指定链接发布.
## 208. `cs.AI` - XBreaking: 可解释的人工智能用于破解大语言模型 [PDF](https://arxiv.org/pdf/2504.21700), [HTML](https://arxiv.org/abs/2504.21700)
### Authors
Marco Arazzi,Vignesh Kumar Kembu,Antonino Nocera,Vinod P
### Background
大型语言模型在现代由AI驱动的IT领域中占据重要地位，但与之相关的安全威胁可能阻碍其在关键应用场景（如政府部门和医疗机构）中的可靠应用。为了防范这些威胁，商业化的大型语言模型通常会实施复杂的过滤机制，以消除其可能产生的有害输出。LLM劫持作为一种新的威胁，使得现有的防护措施失效。许多先前的方法已经证明了其在不同领域的有效性。为了提升对过滤机制的理解并设计有针对性的劫持攻击，研究提出了一个可解释的人工智能解决方案，通过比较对比被过滤和非过滤模型的行为，以发现独特可利用的对齐模式。接着提出了XBreaking，这是一种新颖的劫持攻击，通过针对噪声注入利用这些独特模式，打破对LLM的安全约束。
### Innovation
研究提出了可解释的人工智能解决方案，它通过比较分析受过滤和非过滤模型的行为来发现独特可利用的对齐模式，然后借助XBreaking攻击利用这些模式，通过针对噪声注入来绕过对LLM的安全限制。这种方法有助于提高对过滤机制的理解，并改进针对性的劫持攻击策略。
### Conclusion
通过全面的实验计划，研究获得了有关过滤机制的重要见解，并展示了我们攻击的有效性和性能。
## 209. `cs.AI` - 基于LLM的恶意软件分析的语义预处理 [PDF](https://arxiv.org/pdf/2506.12113), [HTML](https://arxiv.org/abs/2506.12113)
### Authors
Benjamin Marais,Tony Quertier,Grégoire Barrue
### Background
在恶意软件分析的背景下，许多方法依赖人工智能来处理大量数据。然而，这些技术主要关注数据视图（如图像、序列），而非专家视图。
### Innovation
我们提出了一个基于专家知识的新预处理方法，为可执行文件创建JSON报告。该报告从静态和行为分析中收集功能，并整合了打包程序签名检测、MITRE ATT&CK和恶意软件行为目录（MBC）的知识。目的是构建可被恶意软件分析师理解的二进制文件的语义表示，从而增强对恶意文件分析的AI模型的可解释性。
### Conclusion
使用此预处理方法训练针对恶意软件分类的大型语言模型，我们在一个代表市场现实的复杂数据集上获得了加权平均F1分数0.94。
## 210. `cs.AI` - DiffusionBlocks: 通过扩散解释实现区块神经网络训练 [PDF](https://arxiv.org/pdf/2506.14202), [HTML](https://arxiv.org/abs/2506.14202)
### Authors
Makoto Shing,Masanori Koyama,Takuya Akiba
### Background
端到端反向传播需要在整个层中存储激活，这造成了内存瓶颈并限制了模型的可扩展性。现有的区块训练方法可以缓解这个问题，但这些方法依赖于局部目标的任意选择，主要是在分类任务上进行研究，对其他任务的探索较少。
### Innovation
提出了DiffusionBlocks，这是一个将基于变换器的网络转换为真正独立可训练区块的框架，同时保持端到端训练的竞争性能。核心思想利用了残差连接自然对应于动态系统中的更新。通过对系统进行少量修改，可以将更新转换为去噪过程中的更新，使得每个区块可以独立学习，从而可以一次训练一个区块，减少内存需求。
### Conclusion
DiffusionBlocks训练在多种变换器架构（视觉、扩散、自回归、递归深度、掩码扩散）上展示了与端到端训练相匹配的性能，同时可以完成超出小规模分类的实用任务，具备可扩展性。这一方法在现代生成任务的不同架构中提供了理论支持的方法成功扩展。
## 211. `cs.AI` - NeSyGeo：一种多模态几何推理数据生成的神经符号框架 [PDF](https://arxiv.org/pdf/2505.17121), [HTML](https://arxiv.org/abs/2505.17121)
### Authors
Weiming Wu,Jin Ye,Zi-kang Wang,Zhi Zhou,Yu-Feng Li,Lan-Zhe Guo
### Background
多模态大型语言模型（MLLMs）的几何推理能力的提升依赖于大规模、高质量的推理数据。现有数据生成方法，不论是基于预定义模板还是受限符号证明器，都不可避免地面临多样性和数值泛化的局限性。
### Innovation
提出了一种名为NeSyGeo的新颖神经符号框架，用于生成几何推理数据。框架包括一种基于实体-属性-关系方法的具体领域语言及生成动作，设计了一个符号-视觉-文本流水线来生成推理路径并进行验证，构建了NeSyGeo CoT和NeSyGeo-Caption数据集，并提供了一个新的基准NeSyGeo-Test来评估MLLMs的几何推理能力。实验表明，该提议在强化学习和监督微调两种条件下显著且一致地提升了多个MLLMs的表现。仅4000个样本和两次强化微调，基础模型在MathVision、MathVerse和GeoQA上的改进分别达到+15.8%、+8.4%和+7.3%。值得注意的是，一个4B模型在几何推理任务中的表现可以超越同一系列的8B模型。
### Conclusion
通过NeSyGeo框架，不仅有效地解决了现有数据生成方法的局限性，还显著提高了多个MLLMs在几何推理任务中的表现，为评估和提升模型的几何推理能力提供了新的基准数据集。
## 212. `cs.AI` - 预图像近似方法提高神经网络认证效率 [PDF](https://arxiv.org/pdf/2505.22798), [HTML](https://arxiv.org/abs/2505.22798)
### Authors
Anton Björklund,Mykola Zaitsev,Marta Kwiatkowska
### Background
随着人工智能在安全和安全关键应用中的依赖度增加，有效认证神经网络变得越来越重要。一个具有挑战性的实际用例是“补丁攻击”，即敌对补丁或光照条件遮蔽图像的部分，例如交通标志。尽管最近才开始使用PREMAP对补丁攻击进行认证，该方法使用预图像的下近似和上近似（预图像集合中导致指定输出的所有输入），但当前仅针对中等维度的全连接神经网络有效。为了应对更广泛的实用用例，我们提出了PREMAP的新算法扩展，包括更紧的界限、自适应蒙特卡洛采样和改进的分支启发式算法。
### Innovation
我们提出了PREMAP的新算法扩展，包括更紧的界限、自适应蒙特卡洛采样和改进的分支启发式算法。通过这些效率改进措施，PREMAP能够有效地扩展至以前无法处理的卷积神经网络。我们还展示了预图像近似方法在多种视觉和控制应用中的分析与认证潜力，对于提高网络的可靠性和鲁棒性具有重要意义。
### Conclusion
我们的方法显著提高了PREMAP在神经网络认证中的效率，并成功应用于卷积神经网络，开拓了预图像近似方法在较广泛实际应用场景中的潜力。
## 213. `cs.AI` - SP-VLA: 一种用于VLA模型加速的联合模型调度和令牌剪枝方法 [PDF](https://arxiv.org/pdf/2506.12723), [HTML](https://arxiv.org/abs/2506.12723)
### Authors
Ye Li,Yuan Meng,Zewen Sun,Kangye Ji,Chen Tang,Jiajun Fan,Xinzhu Ma,Shutao Xia,Zhi Wang,Wenwu Zhu
### Background
视觉-语言-动作（VLA）模型因其强大的控制能力吸引了越来越多的关注。然而，它们的高计算成本和低执行频率限制了它们在类似机器人操作和自主导航这样的实时任务中的适用性。现有的VLA加速方法主要关注模型结构优化，但没有注意到这些模型在序列决策环境中运行。因此，序列动作生成中的时间冗余和视觉输入中的空间冗余还未得到有效解决。
### Innovation
本文提出了一种SP-VLA框架，通过联合调度模型和剪枝标记来加速VLA模型。具体来说，设计了一种动作感知的模型调度机制，可以根据实际需要动态切换到轻型生成器或VLA模型，以减少时间冗余。同时，提出了一个时空语义双重感知的标记剪枝方法，以减少空间冗余。这些机制共同引导VLA关注关键动作和显著的视觉信息，实现了有效的加速同时保持高精度。该方法在LIBERO和SimplerEnv中分别实现了无损加速1.5倍和2.4倍，平均性能提高可达6%。在SimplerEnv中，推理频率和延迟分别提高了2.2倍和1.4倍。
### Conclusion
通过联合调度模型和剪枝标记，本文提出的SP-VLA框架有效地加速了VLA模型，同时保持了高性能，在实际应用场景中具有广阔的应用前景。
## 214. `cs.AI` - 连续思维机器 [PDF](https://arxiv.org/pdf/2505.05522), [HTML](https://arxiv.org/abs/2505.05522)
### Authors
Luke Darlow,Ciaran Regan,Sebastian Risi,Jeffrey Seely,Llion Jones
### Background
生物大脑表现出复杂的神经活动，其中神经动力学对于信息处理至关重要。大多数人工神经网络忽略了单个神经元的复杂性，本文质疑这种模式。通过纳入神经元级别的处理和同步，重新引入了神经时间作为基础元素。该论文介绍了一种名为连续思维机器（CTM）的模型，旨在利用神经动力学作为其核心表示。CTM通过在每个神经元使用独特的权重参数来处理来临时历史，以及通过神经同步作为潜在表示来打破传统的神经网络模式，同时平衡神经元抽象与生物现实性，使其具有充分捕捉关键时间动态的能力并保持计算效率.
### Innovation
CTM有两个创新点：（1）神经元级别的时间处理，每个神经元使用独特的权重参数来处理入来的历史；（2）神经同步作为潜在表示。它试图在神经元的抽象与生物学现实性之间找到一个平衡点，有效捕捉关键的时间动态同时保持计算上的可行性。该模型展示了在解决2D迷宫、ImageNet-1K分类、奇偶数计算等多个任务上的性能和灵活性，能够在简单的任务中提前停止计算，在面对更具挑战性的实例时继续计算。CTM具有丰富的内部表示，并能够自然地解释其内部过程，还能够执行需要复杂序列推理的任务。此外，CTM能够利用自适应计算，使其可以在简单任务中提前停止计算，而在面对更具挑战性的实例时继续计算。
### Conclusion
本文的目标是分享CTM及其相关创新，而不是追求新的最先进结果。总的来说，我们相信CTM代表了一个重要的步骤，朝着开发更具有生物可信度和更强壮的人工智能系统前进。我们提供了附加的交互式在线演示和扩展技术报告，以供进一步参考。
## 215. `cs.AI` - JALMBench: 评估音频语言模型安全漏洞基准 [PDF](https://arxiv.org/pdf/2505.17568), [HTML](https://arxiv.org/abs/2505.17568)
### Authors
Zifan Peng,Yule Liu,Zhen Sun,Mingchen Li,Zeren Luo,Jingyi Zheng,Wenhan Dong,Xinlei He,Xuechao Wang,Yingjie Xue,Shengmin Xu,Xinyi Huang
### Background
音频语言模型（ALMs）取得了显著进展，直接将音频模态整合到模型中，而非将语音转换为文本再输入给大型语言模型（LLMs）。尽管关于LLMs的防御性攻击（jailbreak attacks）已广泛研究，但具有良好整合音频模态的ALMs的安全性相对未被充分探讨。目前尚未有专门的对抗性音频数据集和统一框架来评估和比较这些攻击与ALMs。这导致了当前缺乏全面评估ALMs治安的基准工具。针对此问题，本研究提出了JALMBench基准测试，以评估ALMs的安全性。
### Innovation
JALMBench是一个综合评估基准，包含11,316个文本样本和245,355个音频样本，具有超过1,000小时的录音。该基准支持12种主流ALMs、4种文本转移攻击方法和4种音频起源攻击方法、5种防御方法。使用JALMBench，研究者进行了深入分析，探讨攻击效率、主题敏感性、语音多样性和架构。此外，还探索了在提示级别和响应级别两种层面的缓解策略。
### Conclusion
JALMBench为评估和比较音频语言模型的安全性提供了综合评估工具。通过JALMBench，研究人员能够更深入地理解攻击效果及其范式，为防御措施的制定提供了依据。
## 216. `cs.AI` - 在固定维度的E(3)-不变潜在空间中操作三维分子 [PDF](https://arxiv.org/pdf/2506.00771), [HTML](https://arxiv.org/abs/2506.00771)
### Authors
Zitao Chen,Yinjun Jia,Zitong Tian,Wei-Ying Ma,Yanyan Lan
### Background
药物化学家们在优化药物时，往往会考虑到3D结构，并设计结构不同的分子但仍保留关键特点，如形状、药效基团或化学性质。之前的研究使用深度学习方法，如分子 inpainting 或基于属性的优化等监督任务来解决这个问题。
### Innovation
本文提出了一种灵活的零样本分子操作方法，通过共享的3D分子潜在空间导航。引入了名为MolFLAE的变分自编码器，它学习到一个固定维度的、E(3)不变的潜在空间，与原子数量无关。MolFLAE使用E(3)不变的神经网络将3D分子编码到固定数量的潜在节点中，并通过条件于编码器潜在输出的贝叶斯流网络进行分子结构重建。该潜在空间允许零样本分子操作，包括原子数量编辑、结构重建和协同隐变量插值等。本文进一步展示了该方法在人类糖皮质激素受体药物优化任务中的应用，生成了具有改进水溶性的分子，同时保留关键相互作用。
### Conclusion
这些结果突显了该方法的灵活性、稳健性和现实应用前景，为其在分子编辑和优化中的应用开辟了新途径。
## 217. `cs.AI` - VOTE: 视觉-语言-动作优化的轨迹投票集成策略 [PDF](https://arxiv.org/pdf/2507.05116), [HTML](https://arxiv.org/abs/2507.05116)
### Authors
Juyi Lin,Amir Taherin,Arash Akbari,Arman Akbari,Lei Lu,Guangyu Chen,Taskin Padir,Xiaomeng Yang,Weiwei Chen,Yiqian Li,Xue Lin,David Kaeli,Pu Zhao,Yanzhi Wang
### Background
近年来，大规模的视觉-语言-动作（VLA）模型在由自然语言指导的机器人操作任务中表现出优越的性能。然而，现有的VLA模型存在两个主要缺点：产生的大量标记导致推理延迟较高并增加训练成本；生成的动作利用率不足，可能导致性能下降。
### Innovation
本文开发了一种训练框架，通过微调VLA模型来生成显著减少的动作标记，提高了并行性，从而有效降低了推理延迟和训练成本。此外，引入了一种新型的投票集成策略进行推理优化技术，将当前和先前的动作预测结合，提高了生成动作的利用效率和整体性能。
### Conclusion
实验结果表明，本文方法相较于最先进的VLA模型，在边缘平台上以46 Hz的吞吐量实现显著更高的成功率和39倍的推理速度，显示了其实用部署性。代码可从该链接获取。
## 218. `cs.AI` - 等变变分流匹配中的受控生成 [PDF](https://arxiv.org/pdf/2506.18340), [HTML](https://arxiv.org/abs/2506.18340)
### Authors
Floor Eijkelboom,Heiko Zimmermann,Sharvaree Vadgama,Erik J Bekkers,Max Welling,Christian A. Naesseth,Jan-Willem van de Meent
### Background
本文基于变分流匹配（VFM）框架推导出一个控制生成目标，将流匹配问题转化为变分推断问题。通过端到端训练条件生成模型或作为贝叶斯推断问题，实现了控制生成的两种方法。此外，论文还确保了生成的对称性，并为分子生成提供了等变变分流匹配的等变形式，以确保旋转、平移和置换的不变性。
### Innovation
提出了控制生成的两种实现方式，一种是通过端到端训练条件生成模型，另一种是以贝叶斯推断的形式在不需要重新训练的情况下实现后验控制；提出了一种对称性的生成条件，为变分流匹配提供了等变形式，适用于分子生成；在不受控制和受控的分子生成任务上均表现出色，特别是在控制生成方面超越了现有最佳模型。这项工作加强了基于流的生成建模与贝叶斯推断之间的联系，提供了一个可扩展且有原则的框架，用于驱动性和对称性意识生成。
### Conclusion
本文表现出了最先进的无约束分子生成性能，并在控制生成中的端到端训练和贝叶斯推断设置中均超过了现有的最佳模型。这展示了如何结合变分流匹配和贝叶斯推断来实现约束驱动和对称意识的生成。
## 219. `cs.AI` - 空间网络架构 [PDF](https://arxiv.org/pdf/2507.22687), [HTML](https://arxiv.org/abs/2507.22687)
### Authors
Josh Millar,Ryan Gibb,Roy Ang,Hamed Haddadi,Anil Madhavapeddy
### Background
随着物理空间愈发紧密地接入网络设备，无缝协调和环境智能变得可能。然而，当前的云优先架构迫使所有通信都要通过广域网，而无视设备的物理接近性。缺乏对空间网络的抽象概念，即利用物理空间来定义私有的、强大的、低延迟的通信边界。研究旨在解决如何利用物理空间实现点对点的直接通信，以及怎样在网络中实现空间服务和物理空间的组合.
### Innovation
引入了Bifröst编程模型，该模型通过使用大的图表表达包含和连接的概念，实现了空间网络。Bifröst能够根据物理边界制定策略、依照位置命名设备、实现空间服务的实例化，并保持局部自治的同时组合空间。这一模型使开发新的智能空间应用成为可能，例如，在本地设备之间直接通信、物理障碍需要明确的网关以及局部控制与全局协调之间的桥梁建立.
### Conclusion
Bifröst为空间感知应用程序的开发提供了新的可能性，通过直接设备之间的通信、明确的物理障碍网关以及局部控制与全球协调的桥梁，实现了一个全新的空间网络架构.
## 220. `cs.AI` - cAST: 使用抽象语法树进行结构化分块以增强代码检索增强生成 [PDF](https://arxiv.org/pdf/2506.15655), [HTML](https://arxiv.org/abs/2506.15655)
### Authors
Yilin Zhang,Xinran Zhao,Zora Zhiruo Wang,Chenyang Yang,Jiayi Wei,Tongshuang Wu
### Background
检索增强生成(RAG)已成为大规模代码生成的关键技术，通过将预测定位到外部代码库中，提高其实用性。然而，现有RAG流水线的一个关键但尚未成型的方面是分块——即文档分割成可检索单元的过程。现有的基于行的分块启发式方法往往破坏了语义结构，可能会将函数拆分或将不相关的代码合并，这会降低生成质量。因此，本文提出一种基于抽象语法树(即cAST)的方法，这种结构感知的方法能够递归地将大块的AST节点拆分为更小的单元，并尊重大小限制，同时合并兄弟节点。这种方法能够生成自包含且语义连贯的单元，适用于不同编程语言和任务，从而在多种代码生成任务上提高了性能。例如，在RepoEval检索上，将Recall@5提高了4.3分，在SWE-bench生成上，Pass@1提高了2.67分。
### Innovation
本文提出了cAST方法，这是一种结构感知的分块方法，通过递归地将大AST节点拆分为更小的单元并合并兄弟节点来生成语义连贯的代码块。这种方法克服了现有基于行的启发式方法的限制，能保持代码的语义结构，从而提高生成质量。
### Conclusion
本文的工作强调，为了扩展检索增强代码智能，结构感知的分块是至关重要的。这一方法能够在不同编程语言和任务上提高代码生成任务的性能。
## 221. `cs.AI` - SBP-YOLO:一种轻量级实时的检测坑包和裂缝模型，面向智能车辆悬挂系统 [PDF](https://arxiv.org/pdf/2508.01339), [HTML](https://arxiv.org/abs/2508.01339)
### Authors
Chuanqi Liang,Jie Fu,Miao Yu,Lei Luo
### Background
路面不平如减速带和坑包显著影响乘坐舒适度和车辆稳定性。基于预览的悬挂控制可以通过提前检测这些不平表面并主动调整悬挂参数来减轻其影响。准确且实时的检测是关键，但嵌入式部署受限于有限的计算资源和小目标尺寸的输入。
### Innovation
本文提出了一种基于YOLOv1的高效检测框架SBP-YOLO，用于嵌入式系统的坑包和裂缝检测。该框架通过在骨干和颈部中集成GhostConv和VoVGSCSPC模块，减少计算量同时增强多尺度语义特征。P2级分支改进了小对象检测，轻量和高效的检测头（LEDH）保持准确性同时减少开销。通过结合NWD损失、BCKD知识蒸馏和基于Albumentations的数据增强策略的混合训练策略，进一步增强了性能。
### Conclusion
实验表明，SBP-YOLO在嵌入式系统上实现了87.0%的mAP，比YOLOv1提升了5.8%。经过TensorRT FP16量化后，该模型在Jetson AGX Xavier上运行速度达到139.5 FPS，比增强P2的YOLOv1提高了12.4%。这些结果证明了框架适用于嵌入式悬挂控制系统中的快速、低延迟的道路条件感知。
## 222. `cs.AI` - First Hallucination Tokens Are Different from Conditional Ones [PDF](https://arxiv.org/pdf/2507.20836), [HTML](https://arxiv.org/abs/2507.20836)
### Authors
Jakob Snel,Seong Joon Oh
### Background
大的语言模型（LLMs）会产生幻觉，这对于确保模型的信任度至关重要。现有的方法多关注响应或片段级别的幻觉检测，而最近的研究开始探索标记级别的幻觉检测，这种做法可以实现更加细致的干预。然而，幻招信号在整个幻招标记序列中的分布尚未得到研究。因此，了解幻招信号在幻招标记序列中的分布特征对于提升幻招检测的准确性和效率至关重要。
### Innovation
本文利用RAGTruth数据集的标记级别注释，发现第一个幻招标记比后续的幻招标记更容易检测到。这一结构特性在不同的模型中都适用，表明第一个幻招标记在标记级别的幻招检测中起着关键作用。
### Conclusion
第一个幻招标记与后续的幻招标记不同。第一个幻招标记比后续的幻招标记更易于检测，这一特性在多个模型中都有效。此研究结果有助于提升幻招检测的准确性和效率。代码已公开。
## 223. `cs.AI` - 关于调和生成的综述：数据集、评估方法和方法论 [PDF](https://arxiv.org/pdf/2507.04793), [HTML](https://arxiv.org/abs/2507.04793)
### Authors
Yuchen Su,Yonghua Zhu,Ruofan Wang,Zijian Huang,Diana Benavides-Prado,Michael Witbrock
### Background
调和生成旨在创造性地修改文字中的语言元素，以产生幽默或引发双重含义。同时，这项技术也旨在保持文章的连贯性和语境的适宜性，使其在各种媒体和应用场景中广泛应用于创意写作和娱乐领域。尽管调和生成受到了计算语言学的广泛关注，但目前尚未有针对这一特定领域的系统性综述文章。为了填补这一空白，本文提供了关于不同阶段的调和生成数据集和方法的全面综述，包括传统方法、深度学习技术和预训练的语言模型。此外，还汇总了用于评估调和生成质量的自动化和手工评价指标。最后，讨论了研究挑战并提出了未来工作的潜在方向。
### Innovation
本文首次提供了一篇全面的调和生成数据集和方法的系统性综述，涵盖了传统方法、深度学习技术和预训练的语言模型。此外，本文还总结了用于评估调和生成质量的自动化和手工评价指标，为未来的研究提供了参考和指导
### Conclusion
本文提出了针对调和生成的研究挑战，并提出了未来工作的潜在方向。未来的研究可以进一步深入探讨和解决这些挑战，以提高调和生成的准确性和创造性。
## 224. `cs.AI` - 基于元提示调谐基于LLM的代码优化：一个工业视角 [PDF](https://arxiv.org/pdf/2508.01443), [HTML](https://arxiv.org/abs/2508.01443)
### Authors
Jingzhi Gong,Rafail Giavrimis,Paul Brookes,Vardan Voskanyan,Fan Wu,Mari Ashiga,Matthew Truscott,Mike Basios,Leslie Kanthan,Jie Xu,Zheng Wang
### Background
近年来，利用多个大型语言模型（LLMs）进行自动化代码优化的兴趣逐渐增加。然而，部署多个LLM的工业平台面临着一个关键挑战：针对一个LLM优化的提示可能在其他LLM上失败，这需要昂贵的模型特定提示工程，从而限制了多LLM系统的实际部署。
### Innovation
该论文引入了一种称为Meta-Prompted Code Optimization (MPCO)的框架，它可以自动为不同的LLM生成高质量且特定任务的提示，同时保持工业效率的要求。MPCO使用元提示技术动态合成基于项目元数据、任务要求和LLM特定上下文的上下文感知优化提示，并作为ARTEMIS代码优化平台的重要组成部分，用于自动化验证和扩展。
### Conclusion
广泛的实证研究表明，MPCO在五个具有366小时运行时基准的现实世界代码库中表现出色：它总体上实现了高达19.06%的性能提升，并在所有系统中获得了最佳统计排名。分析表明，最有效的优化中有96%源于有意义的编辑。系统性的消融研究和元提示器灵敏度分析表明，全面的上下文整合对于有效的元提示至关重要，且主要的LLM可以作为高效的元提示器发挥作用，为工业实践者提供了有价值的见解。
## 225. `cs.AI` - Quantum-RAG和PunGPT2：为密鲁帕语语言生成和检索提供先进方案 [PDF](https://arxiv.org/pdf/2508.01918), [HTML](https://arxiv.org/abs/2508.01918)
### Authors
Jaskaranjeet Singh,Rakesh Thakur
### Background
尽管大型语言模型（LLMs）取得了快速发展，但低资源语言仍被自然语言处理（NLP）领域排除在外，限制了数百万人的数字访问权。本研究旨在为密鲁帕语生成模型的开发提供一个开放源代码的框架，推动密鲁帕语NLP的发展。
### Innovation
本研究开发了PunGPT2，这是首个基于Gurmukhi和Shahmukhi书写的密鲁帕语生成模型套件，以及利用量子启发检索框架Quantum-RAG。Quantum-RAG结合了稀疏、密集和量子核嵌入，实现了高效、上下文感知的检索，且内存占用量少，这是首次在低资源语言模型中实现这样的检索方法。此外，研究还提出了Pun-RAG和Pun-Instruct模型，前者结合检索增强框架，后者是通过QLoRA微调的指令调整变体，用于零样本摘要、翻译和问答。
### Conclusion
本研究中的模型在FLORES-200、IndicGenBench和新创设的PunjabiEval套件上均表现出色。Quantum-RAG在PunjabiEval上的召回率为10和mT5的BLEU得分上分别提高了7.4和3.5。所有训练脚本、超参数、评估管道、35GB的密鲁帕语语料库、PunjabiEval基准和模型权重均已公开，标志着Punjabi语言生成和检索的新里程碑。
## 226. `cs.AI` - 生成型AI的伦理与可信度评估框架研究 [PDF](https://arxiv.org/pdf/2509.00398), [HTML](https://arxiv.org/abs/2509.00398)
### Authors
Cheonsu Jeong,Seunghyun Lee,Seonhee Jeong,Sungsu Kim
### Background
随着生成型人工智能（AI）技术的迅速发展，伦理和信任问题也日益凸显。当前的AI评估方法主要集中在性能和准确性上，不足以应对这些问题。鉴于此，本研究提出了一套系统性评估框架，旨在通过新的以人类为中心的标准，综合考虑社会影响来解决现有问题。
### Innovation
本研究通过分析关键维度（如公平性、透明度、问责制、安全性、隐私保护、准确性、一致性、鲁棒性、解释性、版权和知识产权保护以及源追踪）及其详细的指标和评估方法，提出了一个全面的伦理与可信度评估框架。此外，还对韩、美、欧、中四种AI伦理政策进行了比较分析，为多学科视角下的技术评估提供了实用手段。
### Conclusion
本研究建立了一个针对生成型AI负责任发展的学术基础，并为政策制定者、开发者、用户及其他利益相关者提供了可操作的见解，支持AI技术的积极社会贡献。
## 227. `cs.AI` - 使用子网络数据并行性的模型并行化 [PDF](https://arxiv.org/pdf/2507.09029), [HTML](https://arxiv.org/abs/2507.09029)
### Authors
Vaibhav Singh,Zafir Khalid,Edouard Oyallon,Eugene Belilovsky
### Background
大规模训练神经网络对加速器的内存要求很高，并且往往需要昂贵的通信成本。
### Innovation
提出了子网络数据并行性（SDP）分布式训练框架，将模型划分为结构化的子网络，在各工作节点上分别训练而无需交换激活值。研究了两种互补的遮蔽模式：向后遮蔽（仅在反向传播步骤应用稀疏性，以保留无偏梯度）和向前遮蔽（也在前向传递步骤移除参数，以获得更强的效率提升并提供额外的正则化）。探索了两种子网络构建策略：神经元级别和模块级别，适用于CNN和Transformer。
### Conclusion
在跨越CNN和Transformer在CIFAR、ImageNet和LLM预训练在FineWeb上的实验中，SDP减少了每设备的内存使用率30%-75%，同时保持或提高了性能。值得注意的是，在FLOP匹配的设置中，向前遮蔽有时可以实现更好的性能。
## 228. `cs.AI` - 利用大型语言模型全面克服推荐系统挑战的综述 [PDF](https://arxiv.org/pdf/2507.21117), [HTML](https://arxiv.org/abs/2507.21117)
### Authors
Rahul Raja,Anshaj Vats,Arpita Vats,Anirban Majumder
### Background
传统的推荐系统采用模块化架构，包括候选生成、多阶段排名和再排序等部分，这些部分分别通过监督目标和手工设计的特征进行独立训练。尽管在许多领域中有效，但这种系统面临着稀疏和噪声交互数据、冷启动问题、个性化深度有限和用户和项目内容的语义理解不足等持续挑战。最近，大型语言模型（LLMs）的出现为解决这些限制提供了新范式，通过统一的语言原生机制在任务、领域和模态中实现泛化。本文综述了LLMs如何被用来应对现代推荐系统中的关键挑战。我们探讨了利用LLMs进行提示驱动的候选检索、语言原生排名、检索增强生成（RAG）和对话推荐的应用，展示了这些方法如何增强个性化、语义对齐和可解释性，而无需大量的任务特定监督。LLMs还支持零样本和少样本推理，允许系统在稀疏启动和长尾场景中有效运行，通过利用外部知识和上下文线索。我们对这些新兴的LLM驱动架构进行了分类，并分析了它们如何有效缓解传统管道的关键瓶颈。通过这种方式，我们提供了一个结构化的框架来理解增强推荐中LLM的设计空间，并指出了准确性和实时性能之间的权衡。我们的目标是展示LLMs不仅是辅助组件，而是构建更适应、语义丰富和用户中心的推荐系统的基础使能器。
### Innovation
本文展示了利用大型语言模型（LLMs）来应对推荐系统中的关键挑战。引入了提示驱动的候选检索、语言原生排名、检索增强生成（RAG）和对话推荐等方法，这些方法能够增强个性化、语义对齐和可解释性，而无需大量的任务特定监督。此外，LLMs支持零样本和少样本推理，能够使系统在冷启动和长尾场景中有效运行，同时利用外部知识和上下文线索。
### Conclusion
通过这种方法，我们提供了一个结构化的框架来理解增强推荐中利用LLM的设计空间，并指出准确性和实时性能之间的权衡。最终目标是展示LLMs不仅仅是辅助组件，而是构建更适应、语义丰富和用户中心的推荐系统的基石。
## 229. `cs.AI` - 基于谱图的框架：量化多模态大语言模型中的幻觉 [PDF](https://arxiv.org/pdf/2508.19366), [HTML](https://arxiv.org/abs/2508.19366)
### Authors
Supratik Sarkar,Swagatam Das
### Background
在大语言模型（LLMs）中，幻觉仍然是可信人工智能的主要障碍，尤其是在医学、法律和金融等高风险多模态领域。目前的评估技术大多具有启发式性质，主要依赖于定量基准或针对特定问题的实验性缓解策略，缺乏理论保证和量化分析的方法。这导致了对幻觉如何产生、传播及跨模态交互理解的不足.
### Innovation
本文引入了首个基于扩散动力学的信息几何框架来量化多模态大语言模型（MLLMs）中的幻觉，从定性检测转向以数学为基础的测量。该方法将MLLM输出表示为多模态图拉普拉斯的谱嵌入，并通过在再生核希尔伯特空间（RKHS）嵌入中利用特征模式分解来捕捉幻觉随时间和输入提示演变的模态感知度量，通过对时间依赖温度分布的多模态幻觉能量进行拉氏-赖兹界估计，使得幻觉识别更加具体和理论可解释.
### Conclusion
本文为量化和界限幻觉问题提供了原则性基础，将幻觉从一种定性的风险转化为一种可处理、可分析的现象。
## 230. `cs.AI` - Scam2Prompt：一种用于生产LLM中恶意钓鱼端点审计的可扩展框架 [PDF](https://arxiv.org/pdf/2509.02372), [HTML](https://arxiv.org/abs/2509.02372)
### Authors
Zhiyang Chen,Tara Saba,Xun Deng,Xujie Si,Fan Long
### Background
随着大型语言模型（LLMs）在现代软件开发中的重要性不断增加，它们在训练过程中依赖于未经过筛选的互联网规模数据集，这增加了安全风险，即恶意内容的吸收和复制。这使得评估这一安全风险变得必要。
### Innovation
本文提出了Scam2Prompt，这是一个可扩展的自动化审计框架，能够识别欺骗网站的潜在意图，并生成模仿这类意图的无害开发者风格提示，用于测试LLM是否会因这些无害的提示生成恶意代码。Scam2Prompt不仅验证了是否存在这种安全风险，还通过构建Innoc2Scam-bench基准测试集，进一步证明了几乎所有LLM都有可能生成恶意代码，且其漏洞程度严重。
### Conclusion
研究表明，Scam2Prompt无害提示触发恶意URL生成的概率为4.24%，Innoc2Scam-bench基准测试集在对7个后续的LLM进行测试时，显示出了这一漏洞不仅存在而且严重，恶意代码生成率从12.7%到43.8%不等。现有的安全措施，如最先进的护栏措施，不足以预防这种行为，检测率普遍低于0.3%。
## 231. `cs.AI` - Rubrics as Rewards: 赋值准则作为奖励：超越可验证领域的强化学习 [PDF](https://arxiv.org/pdf/2507.17746), [HTML](https://arxiv.org/abs/2507.17746)
### Authors
Anisha Gunjal,Anthony Wang,Elaine Lau,Vaskar Nath,Yunzhong He,Bing Liu,Sean Hendryx
### Background
Reinforcement Learning with Verifiable Rewards (RLVR) 已经在数学和编程等具有明确正确性信号的复杂推理任务中表现出色。然而，在扩展到现实世界的推理任务时，评估依赖于微妙的、多层次的判断，而不仅仅是二元的正确性判断，因此充满了挑战。虽然最近在评估基准中使用了基于实例的评估标准来捕捉这样的判断，但其作为强化学习中策略调整期间的奖励信号的应用潜力尚未得到充分探索。
### Innovation
我们引入了名为 Rubrics as Rewards (RaR) 的强化学习方法，这是一种在线策略方法，它可以将赋值标准转化为奖励信号，从而将 RLVR 扩展到可验证领域之外。通过在医疗和科学领域评估多种聚合赋值标准的策略，我们发现最佳 RaR 变体在 HealthBench 和 GPQA-Diamond 上分别相比基于直接Likert等级奖励的流行 LLM-as-judge 基线，实现了最高 31% 和 7% 的相对改进。这些结果表明，RaR 训练的策略可以很好地适应不同的评估格式，既能在基于赋值标准的任务中表现良好，也能在多项选择任务中表现出色。此外，我们发现使用赋值标准作为结构化的奖励信号，可更好地与小型评价者对齐，并减少不同规模评价者表现的波动性。
### Conclusion
我们的研究结果证明了 RaR 方法的有效性，尤其是在医疗和科学领域。我们发现基于赋值标准的奖励策略能够很好地适应多样化的评估形式，并且在多项选择任务中也表现出色。同时，它还改善了模型对小规模评估者的适应性，减少了评估者规模变化带来的性能波动。
## 232. `cs.AI` - STORI: 范畴和分类学基准用于随机环境 [PDF](https://arxiv.org/pdf/2509.01793), [HTML](https://arxiv.org/abs/2509.01793)
### Authors
Aryan Amit Barsainyan,Jing Yu Lim,Dianbo Liu
### Background
尽管强化学习（RL）技术已经在如Atari100k等模拟基准上取得了令人印象深刻的表现，但最近的进步仍然主要局限于模拟环境，并且在现实世界的应用领域显示出有限的迁移性。关键障碍在于环境的随机性，因为真实系统中存在嘈杂的观察、不可预测的动力学以及非平稳条件，这些都会威胁到当前方法的稳定性。现有的基准很难捕捉到这些不确定性，并且倾向于简单的设置结构，使得算法可以被调优以取得成功。由于缺乏一种明确定义的随机性分类法，评估也变得更加复杂，即对一种随机性影响的鲁棒性并不能保证对其他形式不确定性也具有鲁棒性。为解决这一关键缺口，我们介绍了STORI（STOchastic-ataRI），一个系统地整合了多种随机性因素的基准，能够不同形式的不确定性下对RL技术进行严格的评估。我们提出了一种全面的五类环境随机性分类法，并通过对DreamerV3和STORM进行有针对性的评估，展示了现有的最先进模型基于的RL算法存在的系统性脆弱性。我们的研究发现表明，世界模型极大地低估了环境的方差，难以处理动作污染，并在部分可观察性下表现出不稳定的动力学。我们已开源了代码和基准，提供了一个统一的框架来开发更鲁棒的RL系统。
### Innovation
我们提出了STORI（STOchastic-ataRI），一个系统化整合了多种随机性影响因素的基准，并编写了全面的五类环境随机性分类法。我们通过对DreamerV3和STORM的有针对性评估，揭示了最先进的基于模型的RL算法在面对这些随机性时所展现的系统性脆弱性。此外，我们提供了一种统合的框架来促进开发更鲁棒的RL系统。
### Conclusion
通过STORI基准，我们可以更严格地评估RL技术在不同形式不确定性下的表现。我们的研究揭示了当前最先进模型基于的RL算法在面对环境随机性时的重要不足，并为开发更加鲁棒的RL系统提供了明确的方向。
## 233. `cs.AI` - 双阶段重权重MoE模型在长尾自视点错误检测中的应用 [PDF](https://arxiv.org/pdf/2509.12990), [HTML](https://arxiv.org/abs/2509.12990)
### Authors
Boyu Han,Qianqian Xu,Shilong Bao,Zhiyong Yang,Sicong Li,Qingming Huang
### Background
本文专注于从自视点视频数据中识别用户执行动作错误的问题，尤其针对细微且不常见的错误所带来的挑战，提出了一个双阶段重权重混合专家框架 (DR-MoE)，旨在解决这类问题。
### Innovation
该创新点在于提出的双阶段重权重混合专家框架 (DR-MoE)，该框架通过结合预先固定和洛拉调优的ViViT模型来提取特征；在第二阶段，通过不同目标的训练进行分类（重权重交叉熵、AUC损失和标签感知损失），并在分类层次上融合预测，从而在识别罕见和模棱两可的错误实例方面取得了显著效果。
### Conclusion
该方法在长尾错误检测中表现突出，尤其在识别罕见和模棱两可的错误实例方面表现出色，并且该方法的代码已公开。
## 234. `cs.AI` - RelayFormer: 一种适用于图像和视频操作定位的统一局部-全局注意力框架 [PDF](https://arxiv.org/pdf/2508.09459), [HTML](https://arxiv.org/abs/2508.09459)
### Authors
Wen Huang,Jiarui Yang,Tao Dai,Jiawei Li,Shaoxiong Zhan,Bin Wang,Shu-Tao Xia
### Background
视觉操纵定位（VML）旨在识别图像和视频中的篡改区域。随着高级编辑工具的发展，该任务变得越来越具有挑战性。现有方法面临两个主要问题：分辨率多样性，导致缩放或填充会歪曲取证线索并降低效率；模态差异，图像和视频通常需要独立的模型。
### Innovation
我们提出了RelayFormer，这是一种统一框架，能够适应不同的分辨率和模态。RelayFormer将输入划分为固定大小的子图像，并引入了全局-局部接力（GLR）令牌，这些令牌通过全局-局部接力注意力（GLRA）机制传递结构化上下文，从而实现全局线索的高效交换，同时保持精细的篡改特征。与依赖均匀缩放或稀疏注意力的先前方法不同，RelayFormer自然地适用于任意分辨率和视频序列，而不会产生过多的开销。实验表明，RelayFormer在各种基准上实现了最先进的性能，具有显著的效率，融合了分辨率适配性、统一建模和准确性和计算成本之间的良好平衡，无需插值或过度填充。
### Conclusion
实验结果表明，RelayFormer在多种基准上实现了最先进的性能，具有显著的效率，融合了分辨率适配性、统一建模和准确性和计算成本之间的良好平衡，无需插值或过度填充。代码可在以下链接获取：this https URL。
## 235. `cs.AI` - 通过比较变得更好：增强检索对比推理在自动提示优化中的应用 [PDF](https://arxiv.org/pdf/2509.02093), [HTML](https://arxiv.org/abs/2509.02093)
### Authors
Juhyeon Lee,Wonduk Seo,Hyunjin An,Seunghyun Lee,Yi Bu
### Background
自动提示优化近年来已成为提高大型语言模型（LLMs）使用的提示质量的战略，目的在于生成更准确和有用的回答。然而，大多数先前工作集中在直接提示精炼或模型微调上，而忽略了利用LLMs固有的推理能力从对比样例中学习的潜力。在这一背景下，本文分析了一个新的框架：对比推理提示优化（CRPO），将提示优化形式化为检索增强的推理过程。
### Innovation
本文提出了CRPO框架，该框架通过检索HelpSteer2数据集中高、中、低质量的参考提示-响应对，并构建了两种互补的优化范式：（1）层次对比推理，其中LLM对比高、中、低质量的范例（包括提示和响应），通过反省推理来改进自身的生成；（2）多指标对比推理，其中LLM分析每个评估维度的最佳范例，并将它们的长处整合到优化的提示中。通过显式对比高质量和低质量的样例，CRPO使模型能够推断出某些提示成功而另一些失败的原因，从而实现更稳健和可解释的优化。实验结果表明，CRPO显著优于基线模型。
### Conclusion
我们的研究结果表明，对比、检索增强的推理对于推进自动提示优化具有巨大的潜力。
## 236. `cs.AI` - MTRec: 通过心智奖励模型对齐用户偏好 [PDF](https://arxiv.org/pdf/2509.22807), [HTML](https://arxiv.org/abs/2509.22807)
### Authors
Mengchen Zhao,Yifan Gao,Yaqing Hou,Xiangyang Li,Pengjie Gu,Zhenhua Dong,Ruiming Tang,Yi Cai
### Background
推荐模型主要使用隐式用户反馈进行训练，因为显式反馈往往成本较高。然而，隐式反馈，例如点击行为，不一定能准确反映用户的真实偏好。例如，用户可能因为吸引人的标题而点击新闻文章，但实际阅读内容后可能会感到不舒服。缺乏显式反馈，这些错误的隐式信号可能会严重误导推荐系统。
### Innovation
本文提出了一种名为MTRec的新颖序列推荐框架，通过挖掘用户对推荐项目的内心满意度来与用户的实际偏好保持一致。具体来说，MTRec引入了一种心理奖励模型来量化用户满意度，并提出了一种分布式的逆强化学习方法来学习这种模型。通过学习的心理奖励模型引导推荐模型更好地与用户的真实偏好保持一致。
### Conclusion
实验表明，MTRec可以显著提高各种推荐模型的性能。我们在一个工业短视频平台部署了MTRec，并观察到用户平均观看时间增加了7%。
## 237. `cs.AI` - 使用YOLOv12进行稳健的泛癌种分裂图检测 [PDF](https://arxiv.org/pdf/2509.02593), [HTML](https://arxiv.org/abs/2509.02593)
### Authors
Raphaël Bourgade,Guillaume Balezo,Thomas Walter
### Background
分裂图是肿瘤病理学中的关键组织病理学特征，对肿瘤侵袭性和增殖性提供了至关重要的见解。然而，其识别仍然具有挑战性，且存在显著的观察者间差异，即使是经验丰富的病理学家也是如此。为解决这一问题，MItosis DOmain Generalization (MIDOG) 2025挑战成为第三次旨在开发稳健分裂检测算法的国际竞赛.
### Innovation
本文提出了一种基于最先进的YOLOv12对象检测架构的分裂图检测方法。该方法在初步测试集（热点区域）上的F1分数为0.801，并在复杂的、异质的全切片区域的最终测试排行榜上获得了0.7216的F1分数，同时并未依赖外部数据.
### Conclusion
本文的方法在泛癌种分裂检测中取得了较好的效果，并且在复杂和异质的全切片区域展示了良好的稳健性。
## 238. `cs.AI` - MobiLLM：6G 开放RAN中的闭环威胁缓解自主型AI框架 [PDF](https://arxiv.org/pdf/2509.21634), [HTML](https://arxiv.org/abs/2509.21634)
### Authors
Prakhar Sharma,Haohuang Wen,Vinod Yegneswaran,Ashish Gehani,Phillip Porras,Zhiqiang Lin
### Background
6G 网络的演进受到开放的无线电接入网络（O-RAN）范式的加速推动，这是一种开放、可互操作的架构。虽然这一开放性带来了前所未有的创新机会，但也增加了攻击面，从而需要具备弹性、低成本和自主性的安全解决方案。现有的防御手段主要是被动反应性的、劳动密集型的，并不适合下一代系统的规模和复杂性。当前的O-RAN应用多集中在网络优化或被动威胁检测，缺乏闭环的自动化应对能力。
### Innovation
我们提出了一种代理型AI框架，用于6G O-RAN环境中的完全自动化和端到端的威胁缓解。MobiLLM 通过由大型语言模型支持的模块化多代理系统协调安全工作流。该框架包括威胁分析代理、使用检索增强生成（RAG）技术进行威胁分类的代理以及通过O-RAN控制接口安全实施缓解措施的响应代理。该框架基于MITRE FiGHT框架和3GPP规范，提供了一个值得信赖的AI驱动网络安全的范例。
### Conclusion
最初的评估表明，MobiLLM 很好地识别并协调了复杂的缓解策略，显著减少了响应延迟，展示了在6G环境中实现自主安全操作的可能性。同时，该框架为可信的AI驱动网络安全搭建了蓝图。
## 239. `cs.AI` - 朝向不变尺度的显著对象检测：一种通用的评估和优化方法 [PDF](https://arxiv.org/pdf/2509.15573), [HTML](https://arxiv.org/abs/2509.15573)
### Authors
Shilong Bao,Qianqian Xu,Feiran Li,Boyu Han,Zhiyong Yang,Xiaochun Cao,Qingming Huang
### Background
现有研究在显著对象检测（SOD）中已经取得了不少进展，但这些研究主要集中在显著对象检测算法本身，而忽视了评价标准对不同大小显著对象的公平性问题。特别是在单张图片中包含多个显著对象且这些对象大小差异较大的情况下，现有广泛使用的SOD评估标准对小但可能更具有语义重要性的对象存在忽视，导致了偏差性能评估和实际应用中的退化问题。因此，论文探讨了尺度不变评估准则这一在SOD领域中基本但未得到充分研究的问题，提供了揭示现有SOD度量标准固有尺度敏感性的新视角，提出了一个通用的尺度不变评估框架SIEva以及与其配套的优化框架SIOpt，旨在更公平地评估和优化不同尺度显著对象的检测结果。
### Innovation
本文提出了一个通用的尺度不变评估框架SIEva和与其配套的优化框架SIOpt。SIEva框架的创新在于它能够单独评估每个可分离部分，再汇总结果，从而有效缓解不同对象规模不平衡的影响。SIOpt框架遵循尺度不变原则，可以与各种SOD主干网络无缝集成，并在广泛尺度的显著对象检测中显著提高了检测性能。此外，论文还提供了SOD方法的泛化分析，并通过实验结果验证了新评估协议的有效性。创新点在于其不依赖于特定检测算法，增强了评估和优化方法的一般性和适用范围。
### Conclusion
本文通过提出尺度不变评估框架SIEva和优化框架SIOpt，有效解决了显著对象检测中的尺度偏见问题，显著提高了不同尺度显著对象的检测性能。相关实验结果表明，该方法在多个评估指标上均表现优异并对现有方法改进明显。该评估和优化方法为显著对象检测提供了新的视角和发展方向，具有重要的理论和实际意义。
## 240. `cs.AI` - 通过稀疏自编码器为基础的向量精炼增强大语言模型控制 [PDF](https://arxiv.org/pdf/2509.23799), [HTML](https://arxiv.org/abs/2509.23799)
### Authors
Anyi Wang,Xuansheng Wu,Dong Shu,Yunpu Ma,Ninghao Liu
### Background
当前，控制大语言模型（LLM）的方向方法显示出巨大前景，无需修改模型参数。然而，大多数现有方法依赖于大规模数据集来学习清晰的行为信息，这限制了它们在许多现实场景中的适用性。从小型数据集提取的方向向量通常包含与任务无关的噪声特征，这影响了它们的效果。
### Innovation
本文提出了一种通过稀疏自编码器（SAE）精炼方向向量的方法（SAE-RSV），利用SAE对方向向量进行语义去噪和扩充。通过SAE根据其语义识别并移除无关特征，然后通过语义相似性丰富小数据集中缺失的相关特征，从而提高了精炼后的方向向量的效果。
### Conclusion
大规模实验表明，所提出的SAE-RSV方法显著优于所有基线方法，包括监督微调，证明了通过SAE精炼原始方向向量可以在有限训练数据下构造出有效方向向量。
## 241. `cs.AI` - jina-reranker-v3：列表式文档重排序中的‘最后但绝不迟到’交互 [PDF](https://arxiv.org/pdf/2509.25085), [HTML](https://arxiv.org/abs/2509.25085)
### Authors
Feng Wang,Yuqing Li,Han Xiao
### Background
jina-reranker-v3 是一个由0.6亿参数构成的多语言列表式重排序模型。该模型引入了一种新颖的‘最后但绝不迟到’交互方式。不同于像ColBERT这样的延迟交互模型，ColBERT在多向量匹配之前分别编码文档。而jina-reranker-v3 在同一个上下文窗口中对查询与所有候选文档之间应用因果注意力机制，使得在提取每个文档最终标记的上下文嵌入之前能够进行丰富的交互。
### Innovation
jina-reranker-v3 使用了一种新的‘最后但绝不迟到’交互方式。该模型在同一个上下文窗口中对查询与所有候选文档之间应用因果注意力机制，能够在提取每个文档最终标记的上下文嵌入之前进行丰富的交互。这使得模型在具有竞争力的表现的同时保持了较小的参数量。
### Conclusion
jina-reranker-v3 实现了BEIR基准上的最佳性能（nDCG@10为61.94），同时其参数量明显小于其他具有类似性能的模型。
## 242. `cs.AI` - 当长处帮助短处：监督微调中上下文长度如何影响大型语言模型的行为 [PDF](https://arxiv.org/pdf/2509.18762), [HTML](https://arxiv.org/abs/2509.18762)
### Authors
Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen
### Background
大型语言模型（LLMs）在自然语言处理（NLP）任务上取得了显著的性能。随着实际应用的需求逐渐向更长的上下文窗口转变，持续的预训练和监督微调（SFT）在长上下文数据上的应用变得普遍。尽管数据量在持续预训练中的影响已经被广泛研究，但在监督微调中的影响尚不清楚。本文系统地探讨了监督微调数据长度如何影响LLM在短上下文任务中的行为。研究发现，虽然长上下文预训练常见地导致性能下降，但长上下文中进行的监督微调却能提升短上下文任务的性能。通过分析多头注意力机制和前馈网络，研究揭示了知识偏好偏差：长上下文SFT促进上下文知识，而短上下文SFT偏爱参数性知识，这使得依赖长上下文SFT微调不理想。最终研究表明，混合训练能减轻这种偏差，为大规模语言模型的微调提供可解释的指导。
### Innovation
本文的创新之处在于系统地研究了监督微调数据长度如何影响大规模语言模型在短上下文任务中的表现。首先，发现长上下文的监督微调能够改善短上下文任务的性能，这与长上下文预训练引起的性能下降相反。通过解构和分析多头注意力机制和前馈网络，研究揭示了知识偏好偏差，并提出混合训练策略来缓解这种偏差，从而为大规模语言模型的微调提供了可解释的指导。
### Conclusion
研究发现，长上下文监督微调可以改善短上下文任务的性能，并揭示了多头注意力机制和前馈网络之间的知识偏好偏差，强调了混合训练方法在优化语言模型中的重要性。
## 243. `cs.AI` - 无观察攻击在线学习排序 [PDF](https://arxiv.org/pdf/2509.22855), [HTML](https://arxiv.org/abs/2509.22855)
### Authors
Sameep Chattopadhyay,Nikhil Karamchandani,Sharayu Moharir
### Background
在线学习排序（OLTR）在信息检索和机器学习系统中扮演着关键角色，广泛应用于搜索引擎和内容推荐系统中。尽管OLTR算法被广泛采用，但它们对抗协同恶意攻击的脆弱性仍然不为人所知。
### Innovation
提出了一种新的框架，能够攻击广泛使用的OLTR算法，使其可以促进一组目标项，在T-o(T)轮次中出现在推荐列表的前K个位置，同时诱导学习算法产生线性遗憾。此外，还提出了两种创新的攻击策略：用于CascadeUCB1的CascadeOFA和用于PBM-UCB的PBMOFA，并且提供了理论保证证明这两种策略仅需O(logT)次的操控即可成功。
### Conclusion
该研究表明，尽管OLTR算法在对抗协同恶意攻击方面存在脆弱性，但通过精心设计的攻击策略，攻击者可以有效地促进特定项目并诱导学习算法产生线性遗憾。
## 244. `cs.AI` - Putnam-like数据集综述：作为数学竞赛参赛者的LLMs [PDF](https://arxiv.org/pdf/2509.24827), [HTML](https://arxiv.org/abs/2509.24827)
### Authors
Bartosz Bieganowski,Daniel Strzelecki,Robert Skiba,Mateusz Topolewski
### Background
该论文总结了由Google DeepMind发布的Putnam-like基准数据集的结果。这个数据集包含96个源自Putnam竞赛原问题以及576个大型语言模型（LLM）的解决方案。研究目的是评估这些模型解决数学竞赛问题的能力，以验证其在数学领域上的应用潜力。背景信息强调了竞赛问题对于评估模型复杂推理能力的重要性，以及LLMs在类似竞赛环境中的潜在表现和局限性。
### Innovation
该研究创新之处在于构建了一个类似于国际数学奥林匹克竞赛格式的数据集，并将LLMs应用于解决这类高级问题，验证了其在数学推理上的表现。这种对比基准有助于理解LLMs在处理数学问题方面的优劣，并为未来研究提供了基准参考。
### Conclusion
该研究通过对Putnam-like数据集的分析，评估了LLMs解决数学竞赛问题的能力，结果显示虽然LLMs在解决这些问题上取得了显著进展，但仍存在局限性。研究结论指出，尽管LLMs展现了强大的数学推理能力，但它们在处理复杂和非标准问题时仍需要改进。
## 245. `cs.AI` - 更少即是更多：高效又强大的视觉语言模型在自动驾驶中的应用 [PDF](https://arxiv.org/pdf/2510.00060), [HTML](https://arxiv.org/abs/2510.00060)
### Authors
Sheng Yang,Tong Zhan,Guancheng Chen,Yanfeng Lu,Jian Wang
### Background
该研究起始于传统的自主驾驶算法面临的挑战，如复杂的轨迹规划任务难以直接从视觉输入中产生。现有的方法通常需要多阶段处理和复杂的模块，这在效率和实时性上都面临限制。本文将自主驾驶重新概念化为通用语言任务，并将轨迹规划任务简化为预测下一个航位的信息，旨在提供一种更高效、更直接的解决路径。
### Innovation
本文提出了Max-V1框架，作为一种新型的一阶段端到端自主驾驶模型，它采用单次生成范式，与驾驶的固有顺序性一致，并借助Vision-Language Model（视觉语言模型）的生成能力，直接从前置相机输入中进行轨迹预测。该框架通过统计建模确定的监督策略提供明确的学习目标，这使得通过大规模专家演示的模仿学习能够捕获复杂的驾驶策略。此外，该方法在nuScenes数据集上达到了最先进的性能，并在跨域数据集上表现出优越的泛化能力，展示了跨车辆的鲁棒性和适应性。
### Conclusion
该工作通过精心设计的框架展示了理论上和实践上的重大进展，提供了一种涵盖复杂驾驶行为的模型，为开发更为先进的自动驾驶代理奠定了基础。未来的工作将关注此模型在更广泛场景下的应用，并进一步改进其训练和泛化能力。
## 246. `cs.AI` - 流诱导对角高斯过程 [PDF](https://arxiv.org/pdf/2509.17153), [HTML](https://arxiv.org/abs/2509.17153)
### Authors
Moule Lin,Andrea Patane,Weipeng Jing,Shuhao Guan,Goetz Botterweck
### Background
提出了Flow-Induced Diagonal Gaussian Processes (FiD-GP)压缩框架，该框架通过一个紧凑的诱导权重矩阵将神经网络权重不确定性投影到低维度子空间中。-FiD-GP 依赖于归一化流先验和光谱正则化来增强其表示能力，并通过数值稳定的投影机制目标将诱导子空间与特征-梯度几何对齐。此外，该文展示了如何在FiD-GP中设计单次投影以用于异常分布（Out-of-Distribution, OoD）检测。已经对-FiD-GP 进行了分析，表明它在多项任务中的不确定估计能力比基于SVGP的基线模型有所提高，满足理论保证的OoD检测标准的光谱残差边界，并显著减少了神经网络的存储需求，代价是推理计算所需诱导权重的数量增加。在全面的实验研究中涵盖了回归、图像分类、语义分割和异常分布检测基准场景，降低了贝叶斯训练成本多个数量级，通过约51%参数压缩，减少了大约75%的模型大小，并达到了最先进的精度和不确定性估计水平。
### Innovation
引入了FiD-GP框架，该框架利用紧缩的诱导权重矩阵将神经网络的权重不确定性投影到低维度子空间。通过归一化流先验和光谱正则化增强其表示能力，并通过数值稳定的投影机制目标与特征-梯度几何对齐。此外，FiD-GP能够用于单次投影以进行异常分布检测，显著降低存储需求并提高不确定性估计能力。
### Conclusion
FiD-GP相比基于SVGP的基线模型，增强了不确定性估计能力，满足理论保证的OoD检测边界，显著压缩了神经网络的存储需求，但推理计算成本增加。在多项实验中，FiD-GP显著降低了训练成本、减少了参数和模型大小，并保持了先进的精度和不确定性估计水平。
## 247. `cs.AI` - 分析代码语言模型中的潜在概念 [PDF](https://arxiv.org/pdf/2510.00476), [HTML](https://arxiv.org/abs/2510.00476)
### Authors
Arushi Sharma,Vedant Pungliya,Christopher J. Quinn,Ali Jannesari
### Background
大型语言模型（LLMs）训练于代码，其内部行为解读依然是一个关键挑战，尤其对于需要信任、透明性和语义稳健性的应用场景。目前亟需一种能够在LLMs表示空间中揭示代码语言模型中潜在的词汇、语法和语义结构的全局后置解释框架。
### Innovation
提出了Code Concept Analysis（CoCoA）：一种全球后置解释框架，通过将上下文嵌入的标记聚类成可理解的概念组，来揭示代码语言模型中的潜在词汇、语法和语义结构；提出了结合静态分析工具的语法对齐与提示工程大模型的混合注释流水线，实现多层次潜在概念的可扩展标注；利用CoCoA和局部归因方法生成基于概念的解释，提高标记级别可解释性的一致性和可解释性；实验证明，CoCoA能在语义保持扰动下发现稳定的概念（平均聚类敏感性指数CSI = 0.288），并在微调过程中表现出可预测的演化；在编程语言分类任务的用户研究中，概念增强的解释提高了人类中心的可解释性37个百分点，相较于基于集成梯度的标记级归因。
### Conclusion
CoCoA框架在发现和解释代码语言模型中潜在概念方面表现出色，为模型理解、开发和应用提供了一种有效的方法。
## 248. `cs.AI` - SecInfer: 在推理时缩放防止提示注入攻击 [PDF](https://arxiv.org/pdf/2509.24967), [HTML](https://arxiv.org/abs/2509.24967)
### Authors
Yupei Liu,Yanting Wang,Yuqi Jia,Jinyuan Jia,Neil Zhenqiang Gong
### Background
提示注入攻击对大型语言模型的安全构成了广泛威胁。最先进的基于防御的技术通常依赖于对LSTM进行微调以提升其安全性，但这些方法对强大的攻击效果有限。因此，迫切需要一种有效的防御机制来应对这种威胁。
### Innovation
本文提出了SecInfer，一种基于推理时缩放的新颖防御方法。SecInfer采用两步策略：系统提示引导采样和目标任务引导聚合。前者通过多样化系统提示探索不同的推理路径生成多种响应，后者则选择最有可能完成预期任务的响应。该方法通过在推理时提供更多计算资源，能够有效地对抗现有的和适应性的提示注入攻击，并且在性能上超过了最先进的防御方法和现有的推理时缩放技术。
### Conclusion
SecInfer通过在推理过程中增强计算资源分配，有效地缓解了提示注入攻击，证明了其在提升大型语言模型安全方面的有效性。
## 249. `cs.AI` - Causal-Adapter：驯服用于忠实逻辑逆向生成的文本到图像扩散模型 [PDF](https://arxiv.org/pdf/2509.24798), [HTML](https://arxiv.org/abs/2509.24798)
### Authors
Lei Tong,Zhihua Liu,Chaochao Lu,Dino Oglic,Tom Diethe,Philip Teare,Sotirios A. Tsaftaris,Chen Jin
### Background
本文介绍Causal-Adapter，这是一种模块化框架，用于适应冻结的文本到图像扩散主干网络，以生成因果性图像。该方法允许对目标属性进行因果干预，一致地传播这些效果到因果相关者，而不改变图像的核心身份。相比之下，先前的方法依赖于提示工程而非显式的因果结构，而Causal-Adapter利用结构因果建模，并结合了两种属性正则化策略：提示对齐注入，可以将因果属性与文本嵌入对齐以实现精确的语义控制，以及条件令牌对比损失，以分离属性因子，减少不必要的相关性。该方法在合成和真实世界数据集上都取得了最先进的性能，并通过高精度的属性控制（Pendulum数据集上MAE降低91%）和高保真的MRI图像生成（ADNI数据集上FID减少87%）证明了其有效性和可靠性。
### Innovation
Causal-Adapter框架利用结构因果建模并结合了两种属性正则化策略：提示对齐注入和条件令牌对比损失，以实现精确且忠实的属性控制和属性修改。此外，该方法在多个数据集上的表现证明了其优越性和可靠性，具有出色的属性控制精度和高保真的图像生成能力，证明了其对现有方法的改进和创新性。
### Conclusion
Causal-Adapter能够实现具备忠实属性修改且具有强大身份保持的稳健且通用的逻辑逆向编辑。该方法通过显著减少MAE和FID值，证明了在准确的属性控制和高保真MRI图像生成方面具有卓越性能。
## 250. `cs.AI` - DM-Bench: 在糖尿病管理中对个性化决策制定的LLM评估基准 [PDF](https://arxiv.org/pdf/2510.00038), [HTML](https://arxiv.org/abs/2510.00038)
### Authors
Maria Ana Cardei,Josephine Lamp,Mark Derdzinski,Karan Bhatia
### Background
现有健康基准大多数是通用型或面向临床医生，专注于临床任务（如诊断、分诊）的，而DM-Bench则是第一个专为评估大型语言模型（LLM）在糖尿病患者日常生活中的实际决策任务表现设计的基准。DM-Bench涵盖了7种不同的任务类别，代表了糖尿病患者询问的广泛实际问题，包括基本的血糖解释、教育性查询、行为关联、高级决策和长期规划等。该基准数据集包含来自3种不同糖尿病人群（1型糖尿病、2型糖尿病、前驱糖尿病/一般健康和保健）的15,000个体长达一个月的时序数据，包括来自连续血糖监测仪（CGMs）的血糖轨迹和行为日志等数据。
### Innovation
DM-Bench是一个全新的综合性评估框架，专为糖尿病、血糖管理和代谢健康等领域的患者展示型AI解决方案的原型设计而定制。它引入了一整套包含7个任务类别的真实世界问题，从基本的血糖解释到复杂的长期规划。此外，它通过对8种最近的LLM模型进行评估，揭示了这些模型在不同任务和指标上的显著差异，证明了没有一个模型在所有维度上都能表现出色。这说明了在糖尿病管理中，LLM的表现存在显著的差异性，同时也为提高AI解决方案的可靠性和实用性提供了重要依据。
### Conclusion
通过建立这个基准，DM-Bench旨在推动糖尿病护理中AI解决方案的可靠性、安全性、有效性及其实际应用的价值。
## 251. `cs.AI` - GPT和偏见：大语言模型中学习表示的理解的一种稀疏方法 [PDF](https://arxiv.org/pdf/2510.01252), [HTML](https://arxiv.org/abs/2510.01252)
### Authors
Mariam Mahran,Katharina Simbeck
### Background
随着大语言模型（LLMs）越来越多地基于规模庞大且未经精心编目的数据集训练，理解模型的表示以及它们所内化的数据结构、主题和偏见已经成为一个重大挑战。研究者发现，将LLMs与稀疏自编码器（SAEs）结合使用，不仅能解释模型行为，还能揭示深层结构、主题和数据集中的偏见。为了验证这一方法，研究者专门针对简·奥斯汀的长篇小说训练了一个类似于GPT的变压器模型，该数据集富含社会构建和叙事模式。
### Innovation
通过将LLMs与稀疏自编码器结合使用，提供了一种新的机制来解读大规模语料库中的深层次结构、主题和偏见。这种方法可以作为复杂数据集的强大探针，用于偏见发现和模型解释，具有可扩展性。具体体现为通过稀疏自编码器在多层隐藏状态中的应用，揭示了反映文档中关键叙述和概念（如性别、阶级和社会责任）的稀疏可解释特征。
### Conclusion
研究证明了结合使用LLMs和稀疏自编码器的方法可以在大规模语料库中进行偏见发现和模型解释。通过专门针对简·奥斯汀的小说进行训练，并使用稀疏自编码器来探索隐藏状态中的结构，研究揭示了诸如性别、阶级和社会责任等关键概念，从而提供了一种更深入理解大规模语言模型内部结构和偏见的新方法。
## 252. `cs.AI` -  Pack and Force Your Memory: 长视频生成与一致性的记忆打包与强迫策略 [PDF](https://arxiv.org/pdf/2510.01784), [HTML](https://arxiv.org/abs/2510.01784)
### Authors
Xiaofei Wu,Guozhen Zhang,Zhiyong Xu,Yuan Zhou,Qinglin Lu,Xuming He
### Background
长视频生成面临着双重挑战：模型需要捕捉远距离依赖性，同时防止自回归解码过程中的错误累积。前人的方法尚未有效解决这两个问题，这限制了长视频生成模型的实用性和效率。
### Innovation
本文提出了两种创新点。首先，为动态上下文建模，提出了一种名为MemoryPack的记忆打包机制，结合文本和图像信息作为全局引导，联合建模短期和长期依赖性，实现分钟级的时间一致性。其次，为了减轻错误累积，引入了Direct Forcing策略，这是一种高效的单步近似策略，提高训练和推理的一致性，从而减少推理过程中的错误传播。
### Conclusion
MemoryPack和Direct Forcing显著增强了长视频生成的上下文一致性和可靠性，推动了自回归视频模型的实际应用。
## 253. `cs.CL` - 防幻觉、领域特定的研究助手：自我评估和向量基础检索 [PDF](https://arxiv.org/pdf/2510.02326), [HTML](https://arxiv.org/abs/2510.02326)
### Authors
Vivek Bhavsar,Joseph Ereifej,Aravanan Gurusami
### Background
大型语言模型能够加速文献合成，但也存在产生幻觉和误引用的问题，这限制了其在专家工作流中的实用性。
### Innovation
研究人员提出了RA-FSM（研究助手-有限状态机），这是一种基于GPT模块化研究助手，通过有限状态控制循环实现了相关性、置信度和知识的管理。该系统利用向量检索和确定性的引用流程，改进了查询过滤、问题分解和引用管理，增强了边界条件处理和证据使用的一致性。此外，该系统通过阶梯式信息处理流程构建领域知识库，并分析其覆盖范围和创新性，显示出在某些领域的优越性。
### Conclusion
RA-FSM设计强调透明、有良好引用的答案，适用于高风险技术工作，并且可以推广到其他科学领域。在盲评A/B对比中，领域专家更偏好RA-FSM，认为其有更强的边界条件处理能力和更可信的证据使用。
## 254. `cs.AI` - KAIROS：统一训练以实现通用的非自回归时间序列预测 [PDF](https://arxiv.org/pdf/2510.02084), [HTML](https://arxiv.org/abs/2510.02084)
### Authors
Kuiye Ding,Fanda Fan,Zheya Wang,Hongxiao Li,Yifan Wang,Lei Wang,Chunjie Luo,Jianfeng Zhan
### Background
在万维网上，可靠的时序预测提供了前瞻性的信号，用于资源规划、缓存放置和异常响应，使平台在用户行为和内容分布演变时能够高效运作。与其他领域相比，Web应用程序的时间序列预测需要更快的响应性以支持实时决策。
### Innovation
KAIROS是一种非自回归时间序列预测框架，直接建模段级多峰分布。与自回归方法相比，KAIROS避免了错误累积，并实现了即时推理，同时优于现有的非自回归模型，后者往往产生过于平滑的预测。KAIROS在大规模语料库上的训练显示了在六种广泛使用的基准测试上的强通用零样本泛化能力，实现了与状态最先进基础模型相当的预测性能，但成本仅为后者的几分之一。
### Conclusion
KAIROS突显了非自回归设计作为一种可扩展范式的重要性，适用于时间序列中的基础模型。
## 255. `cs.CL` - AMANDA: 数据驱动的医学知识增强框架以实现高效医疗视觉问答 [PDF](https://arxiv.org/pdf/2510.02328), [HTML](https://arxiv.org/abs/2510.02328)
### Authors
Ziqing Wang,Chengsheng Mao,Xiaole Wen,Yuan Luo,Kaize Ding
### Background
医疗多模态大语言模型（Med-MLLMs）在医疗视觉问答（Med-VQA）方面展示了巨大的潜力。然而，在缺乏丰富标注数据的低资源环境下，现有的Med-MLLMs常因医疗推理能力瓶颈而失效：（i）内在推理瓶颈，忽视了医学图像中的细节；（ii）外在推理瓶颈，无法整合专门的医学知识。
### Innovation
我们提出了AMANDA，一个无需训练的代理框架，通过利用LLM代理进行医学知识增强。具体来说，我们的内在医学知识增强集中在粗到细的问题分解以实现全面诊断，而外在医学知识增强则通过生物医学知识图谱检索来指导推理过程。
### Conclusion
我们在八个Med-VQA基准测试中进行了广泛的实验，证明了在零样本和少量样本Med-VQA设置中均取得了显著的改进。相关代码已在此处发布：this https URL。
## 256. `cs.AI` - SingMOS-Pro：一个综合性的歌唱质量评估基准 [PDF](https://arxiv.org/pdf/2510.01812), [HTML](https://arxiv.org/abs/2510.01812)
### Authors
Yuxun Tang,Lan Liu,Wenhao Feng,Yiwen Zhao,Jionghao Han,Yifeng Yu,Jiatong Shi,Qin Jin
### Background
歌唱语音生成技术进展迅速，但评估歌唱质量仍然是一项重大挑战。人类的主观评价通常以听力测试的形式进行，成本高且耗时。现有的一些客观指标只能捕捉有限的感知方面。因此，需要一个能够客观、全面评估歌唱质量的基准数据集来改进这一领域的方法和技术。
### Innovation
本文引入了SingMOS-Pro数据集，此数据集是在我们早期版本SingMOS的基础上的升级，增加了对歌词、旋律和整体质量的详细注释，从而覆盖更广泛的内容，增加了数据的多样性和全面性。该数据集包含7,981个采样点，由41个模型从12个数据集中生成，涵盖了从早期系统到最近进展的整个过程。此外，本文还探讨了如何有效利用不同标准下注释的数据，以及在SingMOS-Pro上对广泛使用的评价方法进行基准测试，为未来的研究提供了强大的参考基准和实际依据。
### Conclusion
本文建立了一个全面的歌唱质量评估基准数据集SingMOS-Pro，为研究者提供了一个可靠、全面的评估工具。通过与多种评估方法的基准测试建立了精确的数据和标注基准，为将来研究提供了实用的参考框架。该数据集可访问此链接：this https URL.
## 257. `cs.AI` - 基于YOLO的金属板缺陷检测 [PDF](https://arxiv.org/pdf/2509.25659), [HTML](https://arxiv.org/abs/2509.25659)
### Authors
Po-Heng Chou,Chun-Chi Wang,Wei-Lung Mao
### Background
工业制造中，自动缺陷检测任务通常耗时且劳动密集，需要开发一种新的方法来提高检测效率和准确性。
### Innovation
提出了一种基于YOLO的深度学习模型，通过结合ConSinGAN进行数据增强，提高了缺陷检测的准确性和效率。具体地，使用YOLOv9模型和ConSinGAN生成大量数据，以解决金属板图像数据稀缺的问题，实验结果显示YOLOv9模型在检测准确性上达到了91.3%，检测时间为146毫秒。
### Conclusion
所提出的YOLOv9模型被集成到工业制造硬件和SCADA系统中，构建了一个实用的自动光学检测系统，并且该自动缺陷检测方案易于应用于工业制造中的其他组件。
## 258. `cs.CL` - KAME: 交替架构以增强实时语音到语音对话型AI的知识 [PDF](https://arxiv.org/pdf/2510.02327), [HTML](https://arxiv.org/abs/2510.02327)
### Authors
So Kuroki,Yotaro Kubo,Takuya Akiba,Yujin Tang
### Background
实时语音到语音（S2S）模型擅长生成自然、低延迟的对话响应，但往往缺乏深厚的知识和语义理解。相比之下，结合自动语音识别、文本基础的大语言模型（LLM）和文本到语音合成的级联系统提供了更好的知识表示，但会带来高的延迟，从而打断自然互动的流畅性。
### Innovation
本文介绍了一种新的混合架构，旨在弥合这两种范式的差距。该框架通过实时S2S变压器处理用户语音以实现即时响应，同时将查询转发给强大的后端LLM。LLM的文本回复实时注入到S2S模型的语音生成中，有效地为其输出注入丰富的知识，同时避免级联系统全面延迟的惩罚。
### Conclusion
我们的方法在反应正确性方面显著优于基线S2S模型，接近级联系统的水平，同时保持与基线相当的延迟。
## 259. `cs.CL` - 合成对话生成以实现交互式对话启发与推荐（ICER） [PDF](https://arxiv.org/pdf/2510.02331), [HTML](https://arxiv.org/abs/2510.02331)
### Authors
Moonkyung Ryu,Chih-Wei Hsu,Yinlam Chow,Mohammad Ghavamzadeh,Craig Boutilier
### Background
语言模型（LMs）在对话型推荐系统（CRSs）中具有巨大潜力，但由于缺乏公开的CRS数据，细调LMs以适应CRSs变得困难。作为应对，可以使用LM作为用户模拟器来生成数据训练LM基CRSs，但它们常缺乏行为一致性，生成的语句序列与任何真实用户的行为不符。
### Innovation
本文提出了一种使用行为模拟器和基于LM的提示相结合的方法，生成与用户潜在状态一致的自然对话。并通过这一方法生成了一个包含偏好启发和示例批评的大型开源CRS数据集，部分对话受到评分者的高度评价，显示出了高度的一致性、事实性和自然性。
### Conclusion
研究通过生成对话集成功地提高了CRS数据的质量，有助于改善基于语言模型的对话型推荐系统的性能。
## 260. `cs.CL` - 一种高容量且安全的神经语言隐写消歧算法 [PDF](https://arxiv.org/pdf/2510.02332), [HTML](https://arxiv.org/abs/2510.02332)
### Authors
Yapei Feng,Feng Jiang,Shanhao Wu,Hua Zhong
### Background
神经语言隐写的目标是在自然文本中嵌入信息的同时保持统计上的不可检测性。这一领域面临着尚不明确的标记化问题，现代标记器可能会导致灾难性的解码失败。尽管SyncPool方法通过采用粗粒度同步机制解决了这一问题，但它牺牲了嵌入容量，因为整个尚不确定组的香农熵只用于同步而没有用于承载信息的嵌入。
### Innovation
本文提出了一种名为look-ahead Sync的方法，克服了SyncPool的容量限制，同时保留其可证的安全保证。该方法仅在真正无法区分的标记序列上进行最少的同步采样，同时策略性地保留所有其他可区分路径，以最大化嵌入容量。论文提供了对此方法安全性的理论证明，并分析了其可实现的嵌入容量与理论上限之间的差距。
### Conclusion
在英文（使用Llama 3）和中文（使用Qwen 2.5）基准测试中，本文方法在保持理论容量上限的同时显著优于SyncPool。在英文中，嵌入率提高超过160%，在中文中提高25%，特别是在候选池较大的情况下效果明显。这项工作朝着实用高容量可证安全的语言隐写迈出了重要一步。
## 261. `cs.CL` - 含有上下文和社会维度的人类移动数据集 [PDF](https://arxiv.org/pdf/2510.02333), [HTML](https://arxiv.org/abs/2510.02333)
### Authors
Chiara Pugliese,Francesco Lettich,Guido Rocchietti,Chiara Renso,Fabio Pinelli
### Background
该研究基于公共GPS轨迹数据，构建了专门的数据集，包含了语义增强的人类轨迹。这些数据集不仅包括地理位置信息，还包含诸如兴趣点（POIs）、运输模式、天气数据等上下文信息。创新点在于引入了由大型语言模型（LLMs）生成的合成社交媒体帖子，使研究能够进行多模态和语义移动性分析。
### Innovation
引入了大型语言模型生成的合成社交媒体帖子作为新的语义特征，支持多模态和语义的移动性分析。该资源是首次将实际移动性、结构化的语义增强、大型语言模型生成的文本内容以及语义网兼容性结合在一个可重复使用的框架中。
### Conclusion
该研究提出的数据集和处理管道为行为建模、移动性预测、知识图谱构建和大规模语言模型（LLM）应用提供了支持。这些数据集和开源可重复使用的处理管道允许研究者根据需要对数据集进行定制，从而促进相关领域的研究。
## 262. `cs.CL` - CASAL：对比激活引导的免实时时学习幻觉减少方法 [PDF](https://arxiv.org/pdf/2510.02324), [HTML](https://arxiv.org/abs/2510.02324)
### Authors
Wannan Yang,Xinchi Qiu,Lei Yu,Yuchen Zhang,Oliver Aobo Yang,Narine Kokhlikyan,Nicola Cancedda,Diego Garcia-Olano
### Background
大语言模型（LLMs）具有令人印象深刻的性能，但也经常出现幻觉现象，即自信地提供错误答案而不是承认无知。现有的研究表明模型编码了自身知识的线性表示，并且激活引导可以减少幻觉现象。然而，这些方法需要在推理过程中进行实时监控和干预。
### Innovation
我们提出了对比激活引导的免实时时学习（CASAL）算法，这是一个高效的算法，将解释性与自适应优化相结合。CASAL直接将激活引导的好处嵌入到模型的权重中。一旦训练完成，LLMs能够仅回答它们知道的问题，而不回答它们不知的问题。CASAL的设计轻量级，只需要训练单个变压器层的一小部分子模块，即可减少30%-40%的幻觉，且在多种简短形式的问答基准上表现优异。与强大的LoRA基线方法（如SFT和DPO）相比，CASAL的计算效率提高了30倍，数据效率提高了20倍，提升了其在数据稀缺领域的实用性。此外，CASAL还能够在分布外（OOD）域中有效泛化。我们展示了CASAL在文本和语言-视觉模型中灵活减少幻觉的能力。CASAL是首个证明对密集模型和混合专家模型都有效的基于引导的训练方法。CASAL代表了一个重要的进步，表明了如何利用启发式的可解释性方法在生产系统的实际部署中应用。
### Conclusion
CASAL是一个有效的幻觉减少方法，可以应用于多种模型，包括文本模型和语言-视觉模型。它提高了大语言模型在数据稀缺环境中的表现，并且能够泛化到分布外领域。CASAL代表了将解释性与自适应优化相结合的一个重要进步，提高了其实用性。
## 263. `cs.CL` - Where Did It Go Wrong? 通过表示梯度跟踪归因不良LLM行为 [PDF](https://arxiv.org/pdf/2510.02334), [HTML](https://arxiv.org/abs/2510.02334)
### Authors
Zhe Li,Wei Zhao,Yige Li,Jun Sun
### Background
大型语言模型（LLMs）展示了显著的能力，但其部署常常受到不 desirable 行为的阻碍，如生成有害内容、数据不准确和社会偏见。诊断这些失败的根本原因对AI安全性构成了重要挑战。现有的归因方法，尤其是基于参数梯度的方法，由于噪声信号的挑战和计算复杂性，往往效果不佳。
### Innovation
本文介绍了一个新的高效框架，通过分析表示及其梯度来诊断一系列不良LLM行为，该框架直接在模型的激活空间内工作，提供了一种语义上有意义的信号，将输出与其训练数据联系起来。该方法系统地评估了包括跟踪有害内容、检测后门污染和识别知识污染的任务，结果显示该方法不仅在样本级归因方面表现出色，还能够进行精细的标记级分析，准确识别导致模型行为的具体样本和短语。
### Conclusion
该工作提供了一个强大的诊断工具，用于理解、审计并最终减轻与LLMs相关的风险。代码可在该链接中找到。
## 264. `cs.CL` - FormalML：机器学习理论中形式亚目标完成评估基准 [PDF](https://arxiv.org/pdf/2510.02335), [HTML](https://arxiv.org/abs/2510.02335)
### Authors
Xiao-Wen Yang,Zihao Zhang,Jianuo Cao,Zhi Zhou,Zenan Li,Lan-Zhe Guo,Yuan Yao,Taolue Chen,Yu-Feng Li,Xiaoxing Ma
### Background
大型语言模型（LLMs）在形式定理证明方面取得了显著的进步，但它们作为一种实用助手来弥补复杂证明中缺失的步骤的能力尚未得到充分探索。论文识别了这一挑战，即子目标完成任务，LLMs 需要在人类提供的草图中完成未解决的简短但不太明显的证明义务。为研究此问题，研究人员引入了 FormalML，这是一个基于机器学习基础理论的 Lean 4 基准测试。该基准通过将过程性证明转换为声明性形式提取了涵盖最优化和概率不等式的 4937 个问题，涉及不同程度的难度。FormalML 是首个结合前提检索和复杂研究级背景的子目标完成基准。最先进的证明评估表明，准确性和效率方面存在持续的限制，强调需要更强大的基于LLM的自动定理证明工具以有效完成子目标。
### Innovation
该研究引入了 FormalML，这是首个结合前提检索和复杂研究级背景的子目标完成基准。通过将过程性证明转换为声明性形式，提取了涵盖了最优化和概率不等式的 4937 个问题，涉及不同程度的难度。
### Conclusion
最先进的证明评估表明，准确性和效率方面存在持续的限制，强调需要更强大的基于LLM的自动定理证明工具以有效完成子目标。
## 265. `cs.CL` - KurdSTS：库尔德语语义文本相似度 [PDF](https://arxiv.org/pdf/2510.02336), [HTML](https://arxiv.org/abs/2510.02336)
### Authors
Abdulhady Abas Abdullah,Hadi Veisi,Hussein M. Al
### Background
语义文本相似性(STS)衡量两段文本含义的重叠程度，支持众多自然语言处理(NLP)任务。尽管高资源语言拥有丰富的相关资源，但是像库尔德语这样的低资源语言，其相关的STS数据资源较少。
### Innovation
本文研究了库尔德语的STS数据集：包含10,000组正规和非正规的句子对，并进行了相似性标注。本文还基准测试了Sentence-BERT、多语言BERT和其他强基线模型，突出了库尔德语形态学、拼写变化和混合码等带来的挑战。这是目前对于库尔德语的第一个STS数据集，且为后续研究库尔德语语义学和低资源NLP提供了有力的起点。
### Conclusion
数据集及基线测试提供了一个可重现的评估套件，便于未来进一步研究库尔德语语义和低资源NLP领域的研究。
## 266. `cs.AI` - VarCoNet：一种基于变异性的自我监督框架，用于静息态fMRI的功能连接图提取 [PDF](https://arxiv.org/pdf/2510.02120), [HTML](https://arxiv.org/abs/2510.02120)
### Authors
Charalampos Lamprou,Aamna Alshehhi,Leontios J. Hadjileontiadis,Mohamed L. Seghier
### Background
精准医疗的关键在于脑功能个体间变异性的考虑。通过将功能个体间变异性视为有价值的数据而非噪声，本研究提出了一种增强的自我监督框架——VarCoNet，用于从静息状态fMRI数据中稳健提取功能连接图（FC）。该框架利用自监督对比学习来利用固有的功能个体间变异，作为脑功能编码器生成适用于下游任务的FC嵌入，即使在缺乏标记数据的情况下也能适用。通过一种基于rs-fMRI信号分割的新型增强策略，对比学习得以实现。实验在两个下游任务上进行评估：（i）基于人类联结组计划数据的被试指纹识别；（ii）自闭症谱系障碍（ASD）分类，利用ABIDE I和ABIDE II数据集数据。通过不同脑分区测试，与其他13种深度学习方法相比，VarCoNet在性能、稳健性、可解释性和泛化能力上表现出优势。overall，VarCoNet提供了适用于rs-fMRI功能连接图分析的灵活且稳健的框架。
### Innovation
VarCoNet引入了一种新的自监督对比学习策略，通过基于rs-fMRI信号分割的增强方法来发掘功能个体间变异性。核心上，VarCoNet集成了1D CNN-Transformer编码器进行高级时间序列处理，并结合了稳健的贝叶斯超参数优化.
### Conclusion
VarCoNet作为一种灵活且稳健的框架，适用于rs-fMRI的功能连接图分析，优于其他13种深度学习方法，在性能、稳健性、可解释性和泛化能力上具有优势。
## 267. `cs.CL` - EntropyLong：通过预测不确定性实现有效的长上下文训练 [PDF](https://arxiv.org/pdf/2510.02330), [HTML](https://arxiv.org/abs/2510.02330)
### Authors
Junlong Jia,Ziyang Chen,Xing Wu,Chaochen Gao,Zijia Lin,Debing Zhang,Songlin Hu,Binghui Guo
### Background
长上下文语言模型需要特殊的数据构造来捕捉长距离依赖关系，现有的方法经常无法确保真实的长距离依赖。因此，需要一种创新的方法来验证依赖质量以确保依赖关系具有实质性的信息增益，而不是虚假的相关性。
### Innovation
提出了一种名为EntropyLong的新数据构建方法，该方法利用预测不确定性来验证依赖的质量。该方法在原始文档中识别高熵位置，从大规模语料库中检索语义相关的上下文，并通过评估这些上下文是否降低预测熵来验证其有效性。这种方法确保每个依赖关系代表可测量的信息增益，而非虚假的相关性。通过与经过验证的上下文补充结合的原始文档创建训练样本。使用FineWebEdu和Cosmopedia生成了包含验证依赖关系的128K长度序列的数据集，训练在此数据上的模型在RULER基准和LongBenchv2上的表现显著提升，特别是在需要远程信息的任务上。
### Conclusion
通过示例证明熵验证对于长上下文训练的必要性和有效性，实验表明，结合EntropyLong方法后，模型在处理需要远距离信息的任务上的表现大幅提升。
## 268. `cs.AI` - 理解对抗性转移：为什么在模型表示空间中的攻击会在数据空间攻击成功时失败 [PDF](https://arxiv.org/pdf/2510.01494), [HTML](https://arxiv.org/abs/2510.01494)
### Authors
Isha Gupta,Rylan Schaeffer,Joshua Kazdan,Ken Ziyu Liu,Sanmi Koyejo
### Background
对抗性鲁棒性研究证实，对抗性样本可以成功在图像分类器之间传输，文本脱劫可以成功在语言模型之间传输。然而，最近的研究表明，图像脱劫在视觉语言模型之间无法成功传输。研究者试图解释这一显著差异，并提出攻击在机器学习模型的可移植性方面的一个根本区别：输入数据空间中的攻击可以转移到模型表示空间，但除非有几何对齐，否则在模型表示空间中的攻击不会转移。
### Innovation
这篇文章提出了一种新的解释，即攻击的可移植性取决于其操作领域——共享的数据空间与模型的独特表示空间。作者通过数学证明、构建反向工程攻击和实际实验，在四个不同的情境中提供了理论和实证证据。研究结果表明，对抗性转移不一定是所有攻击的固有属性，而是依赖于其操作领域。
### Conclusion
这项工作揭示了对抗性转移并非所有攻击的固有属性，而是取决于攻击在数据空间还是模型表示空间中操作。这一洞察对构建更稳健的模型至关重要。
## 269. `cs.CL` - CRACQ：一种多维度的自动化文档评估方法 [PDF](https://arxiv.org/pdf/2510.02337), [HTML](https://arxiv.org/abs/2510.02337)
### Authors
Ishak Soltani,Francisco Belo,Bernardo Tavares
### Background
本文提出了一种多维度评估框架CRACQ，旨在评估文档在逻辑连贯性、严谨性、适用性、完整性和质量五个特定方面。该框架基于基于特质的自动作文评分（AES）洞察，旨在超越传统的作文评估，涵盖了多样化的机器生成文本。CRACQ采用评分驱动的、可解析的方法，能够进行综合评估和特质级分析，相较于单一评分方法，CRACQ通过综合语言、语义和结构信号，提供了一种更加稳定和可解释的评估手段。该框架在500个合成的资助提案上进行了训练，并被用来评估一个类机器人法官（LLM-as-a-judge），以及在强应用和弱应用上进行进一步测试。初步结果显示，CRACQ的特质级判断比直接通过LLM评估更稳定、更可解析，但存在可靠性和领域适用范围等方面的挑战.
### Innovation
CRACQ创新性地提出了一种多维度的评估框架，针对文档的逻辑连贯性、严谨性、适用性、完整性和质量五个特定方面进行评估。不同于单一评分方法，CRACQ通过整合语言、语义和结构信号，实现综合评估和特质级分析，提供了一种可解析的自动评估方法。此外，CRACQ还在合成资助提案和实际应用场景中进行了测试，展示了其在评估多样性机器生成文本方面的潜力和局限性.
### Conclusion
CRACQ能够生成比直接通过LLM评估更稳定和可解析的特质级判断，但是在可靠性和领域适用范围方面仍存在挑战。该研究为自动化评估提供了新的思路，但也指出了在实际应用中需要解决的问题。
## 270. `cs.CL` - 在论辩大型语言模型中评估不确定性量化方法 [PDF](https://arxiv.org/pdf/2510.02339), [HTML](https://arxiv.org/abs/2510.02339)
### Authors
Kevin Zhou,Adam Dejl,Gabriel Freedman,Lihu Chen,Antonio Rago,Francesca Toni
### Background
关于大型语言模型（LLMs）的不确定性量化（UQ）的研究逐渐重要起来，这是为了确保这一划时代技术的可靠性。研究人员探索在论辩型大型语言模型（ArgLLMs）中整合LLMs的UQ方法，这是一种基于计算论辩的可解释型决策框架，其中UQ扮演着重要角色。这些论辩型大型语言模型在进行论断验证任务时使用不同的UQ方法进行性能评估，这是一种评估UQ方法有效性的方法，尤其是在存在复杂且可能有争议的声明时。这项研究展示了直接提示可以作为一种简单有效的UQ策略，在论辩型大型语言模型中表现出色，甚至超过了更为复杂的策略。
### Innovation
实验方法本身是一种新颖的评估UQ方法有效性的途径，尤其是当存在复杂且可能有争议的声明时。研究结果表明，尽管直接提示策略简单，但它在论辩型大型语言模型中表现出色，其性能远超更复杂的方法。
### Conclusion
直接提示是有效的UQ策略，特别是在论辩型大型语言模型中。这种简单直接的UQ方法优于更为复杂的方法，显示了其强大的评估能力。
## 271. `cs.CL` - Can Prompts Rewind Time for LLMs? Evaluating the Effectiveness of Prompted Knowledge Cutoffs [PDF](https://arxiv.org/pdf/2510.02340), [HTML](https://arxiv.org/abs/2510.02340)
### Authors
Xin Gao,Ruiyi Zhang,Daniel Du,Saurabh Mahindre,Sai Ashish Somayajula,Pengtao Xie
### Background
大型语言模型（LLMs）在时间预测方面被广泛应用，但它们对预训练数据的依赖引起了一些担忧。这些模型在预断点测试数据上的准确预测可能反映的是记忆而非推理，这可能导致过度估计它们的泛化能力。最近，基于提示的消学习技术兴起，这引发了一个自然的问题：是否可以提示LLMs模拟一个更早的知识截止点？
### Innovation
本文研究了提示技术在LLMs中模拟早期知识截止点的能力。构建了三个评估数据集来评估LLMs在忘记（1）直接事实知识，（2）语义变化，（3）因果相关知识方面的能力。结果表明，当直接查询相关信息时，提示引起的知识截止效果显著，但在未直接询问但与查询有因果关系的内容上，这种遗忘效果较差。这些发现突显了在使用LLMs进行时间预测任务时需要更严格的评估设置。公开提供了完整的数据集和评估代码。
### Conclusion
提示技术虽然在直接查询时可以有效地模拟知识截止，但在未直接询问但有因果关系的内容上表现不佳。这表明，在使用LLMs进行时间预测任务时，需要更严格的评估设置。
## 272. `cs.CL` - BluePrint: 社交媒体用户数据集，用于大型语言模型的人设评估与训练 [PDF](https://arxiv.org/pdf/2510.02343), [HTML](https://arxiv.org/abs/2510.02343)
### Authors
Aurélien Bück-Kaeffer,Je Qin Chooi,Dan Zhao,Maximilian Puelma Touzel,Kellin Pelrine,Jean-François Godbout,Reihaneh Rabbany,Zachary Yang
### Background
大型语言模型（LLMs）能够模拟大规模社交媒体动态，支持一些伦理或操作上具有挑战性的研究。然而，该领域缺乏标准化的数据资源来精细化训练和评估LLMs以作为真实的社交媒体代理。因此，迫切需要一种既能生成符合行为规范的社交媒体数据集，又能保障隐私的框架，以供训练代理模型。BluePrint是一个从公共Bluesky数据中构建的大规模数据集，专注于政治交流，为评估和训练大型语言模型提供了标准的数据和评估协议。
### Innovation
SIMPACT框架是一个隐私保护的工具包，用于构建行为基础的社交媒体数据集，适合训练代理模型。BluePrint将匿名用户的交互行为聚类为角色，捕获真实互动模式以保障隐私，同时包含12种社交媒体互动类型的数据实例，每种例子都与之前的行为记录相关联，支持根据上下文进行交互行为的建模。通过标准化数据和评估标准，SIMPACT为推进严谨和负责任的社交媒体模拟奠定了基础。BluePrint dataset被设计为政治交流模型的评估基准，并为构建针对特定领域的数据集（例如，研究误传和极化等挑战）提供了模板。
### Conclusion
SIMPACT通过创建一个标准化的数据集和评估协议，提供了一个基础框架，以支持大型语言模型训练的负责任和可靠的社会媒体模拟。BluePrint作为一个具体的实现，既是一个针对政治讨论的评估基准，也是构建特定领域数据集的一种模板，促进了针对误传和极化等挑战的深入研究。
## 273. `cs.CL` - 基于索赔奖励优化长格式临床文本生成 [PDF](https://arxiv.org/pdf/2510.02338), [HTML](https://arxiv.org/abs/2510.02338)
### Authors
Samyak Jhaveri,Praphul Singh,Jangwon Kim,Tara Taghavi,Krishnaram Kenthapadi
### Background
自动化临床文档撰写需要精确的与完整性和事实性等优先事项对齐。为此，该研究提出了一个结合组相关策略优化（GRPO）和提供确定性、对话根植奖励的DocLens的评估整合强化学习框架，用于长格式临床文本生成。这种方法直接优化事实性和完整性，不需训练额外的奖励模型或依赖人工编写的参考。这种方法通过简单的奖励门控策略减少了训练成本，并通过独立的GPT-5定性评估进一步支持这些改进，显示在事实性、完整性和简洁性方面GRPO输出更受偏好，且较少遗漏和妄言。由于基准相对干净且基础模型已良好对齐，这些改进可能代表了一个保守的下限。该框架可扩展到实际应用场景，并能结合如遵循指南或收费偏好等自定义目标。
### Innovation
提出了一个评估整合强化学习框架，将组相关策略优化（GRPO）与基于索赔级别的评估器DocLens结合，用于长格式临床文本生成。该方法直接优化了事实性和完整性，不需要训练额外的奖励模型或依赖人工编写的参考，通过简单的奖励门控策略降低了训练成本，并且经过独立GPT-5定性评估的进一步支持显示出更高的事实性、完整性和简洁性偏好，且减少遗漏和妄言。
### Conclusion
该框架适用于实际应用场景，可扩展性强，能够通过直接优化方法提高临床笔记质量并减少训练成本，且在事实性、完整性和简洁性方面有所提高，特别是减少了遗漏和妄言现象。这种方法比对齐基准更干净，并且基础模型已良好对齐，这些改进可能反映了保守的下限。
## 274. `cs.CL` - 基于小型语言模型的课程指导 [PDF](https://arxiv.org/pdf/2510.02347), [HTML](https://arxiv.org/abs/2510.02347)
### Authors
Konstantinos Katharakis,Sippo Rossi,Raghava Rao Mukkamala
### Background
目前，生成式人工智能和大型语言模型（LLMs）在教育领域的应用仍然处于起步阶段。研究人员探索使用检索增强生成（RAG）管道来开发和评估能够提供基于课程指导的AI助教系统，其中采用了选定的开源小型语言模型（SLMs）进行实验。
### Innovation
研究团队对八种小型语言模型进行了基准测试，包括LLaMA 3.1、IBM Granite 3.3和Gemma 3（7-17B参数），并与GPT-4o进行比较。研究发现，在适当的提示和有针对性的检索下，小型语言模型能够与大型语言模型提供准确和符合教育需求的回答。这种小型语言模型具有显著的可持续性优势，因为它们的计算和能源需求较低，可以在消费级硬件上实现实时使用，而不需要依赖云基础设施。它们不仅具有成本效益和隐私保护特性，而且是环保的，被定位为教育机构在可持续和节能的方式下大规模提供个性化学习的可行AI助教解决方案.
### Conclusion
小型语言模型在提供基于课程的指导方面具有巨大的潜力，能够满足教育机构在可持续和节能的背景下进行个性化学业辅导的需求。它们的成本效益、隐私保护和环保特性使得它们成为一种具有吸引力的选择。
## 275. `cs.CL` - LLMSQL:为LLM时代升级WikiSQL的Text-to-SQL基准 [PDF](https://arxiv.org/pdf/2510.02350), [HTML](https://arxiv.org/abs/2510.02350)
### Authors
Dzmitry Pihulski,Karol Charchut,Viktoria Novogrodskaia,Jan Kocoń
### Background
自然语言到SQL（Text-to-SQL）的转换使非专家用户能够与关系数据库交互，并一直是数据自然语言界面中的核心任务。尽管WikiSQL数据集在早期NL2SQL研究中发挥了关键作用，但由于包括大小写不一致、数据类型不匹配、语法错误和未回答问题在内的结构和标注问题，其使用率有所下降。
### Innovation
本文介绍了LLMSQL，这是一种为LLM时代设计的系统性修订和转换WikiSQL的方法。它对错误进行了分类，并实现了自动方法进行清理和重新标注。通过对多个大型语言模型（LLMs）进行评估，如Gemma 3, LLaMA 3.2, Mistral 7B等，来评估这些改进的影响。LLMSQL作为LLM就绪基准被引入，而不是作为更新，其提供清洁的自然语言问题和完整的SQL查询作为纯文本，可轻松生成和评估现代的自然语言到SQL模型。
### Conclusion
LLMSQL是针对LLM时代改进的WikiSQL数据集，消除了原始数据集中的结构和标注问题，提供了清洁的自然语言问题和完整SQL查询，便于现代自然语言到SQL模型的生成和评估。
## 276. `cs.CL` - SelfJudge：通过自我监督判别验证加快推测性解码 [PDF](https://arxiv.org/pdf/2510.02329), [HTML](https://arxiv.org/abs/2510.02329)
### Authors
Kanghoon Yoon,Minsub Kim,Sungjae Lee,Joonhyung Lee,Sunghyeon Woo,Yeonjun In,Se Jung Kwon,Chanyoung Park,Dongsoo Lee
### Background
推测性解码通过验证草稿模型的候选token与目标模型的输出之间的差异来加速大语言模型（LLM）的推理过程。最近提出的判决性解码进一步放宽了验证标准，接受了与目标模型输出有轻微差异的草稿token，但现有方法受限于必须依赖人工注释或具有可验证真实基线的任务，这限制了其在不同NLP任务中的泛化能力。
### Innovation
我们提出了SelfJudge，通过目标模型自身的自我监督训练判别验证器。该方法通过评估token被替换后响应的意义是否保持原始响应的意义来衡量语义保真度，从而实现跨各种NLP任务的自动验证器训练。实验结果显示，SelfJudge在准确性和推理效率之间取得了优于现有判决性解码基线的效果，提供了一个普遍适用的快速LLM推理解决方案。
### Conclusion
SelfJudge方法通过自我监督训练判别验证器，衡量语义保真度，实现了广泛适用的快速LLM推理解决方案，相比于现有方法，它的性能更优。
## 277. `cs.CL` - mini-vec2vec: 通过线性变换扩展通用几何对齐的规模 [PDF](https://arxiv.org/pdf/2510.02348), [HTML](https://arxiv.org/abs/2510.02348)
### Authors
Guy Dar
### Background
文章基于vec2vec，一种无需平行数据就能对齐文本嵌入空间的过程。vec2vec虽然能实现几乎完美对齐，但计算成本高昂且不稳定。为此，作者提出了mini-vec2vec，这是一种简单且高效的替代方案，不仅计算成本大大降低，而且非常稳定。此外，mini-vec2vec的学到的映射是一个线性变换。方法包含三个主要阶段：初步的伪平行嵌入向量匹配，变换拟合，以及迭代优化。与原始的vec2vec相比，mini-vec2vec在效率上提高了数量级，同时也能获得或超越vec2vec的结果，增加了算法的稳定性和可解释性，有利于在新领域和学科中的应用与扩展。
### Innovation
mini-vec2vec是一种基于简单线性变换的替代方案，降低了计算成本，并且提高了算法的稳定性。该方法由三个主要阶段组成：初步的伪平行嵌入向量匹配，变换拟合，和迭代优化。mini-vec2vec在效率上明显超越vec2vec，同时在结果上不逊色于原方案，具有更高的实用价值。此外，其线性特性和稳定的算子流程使算法更易于理解和扩展。
### Conclusion
mini-vec2vec通过一系列优化，不仅提高了vec2vec方法的效率，维持了其对齐效果，而且还增强了算法的稳健性和可解释性，为进一步应用在不同领域提供了更好的可能。
## 278. `cs.CL` - 使用与形式无关且扩展示义的句子意义模型揭示语言皮层令人惊讶的语义抽象性 [PDF](https://arxiv.org/pdf/2510.02354), [HTML](https://arxiv.org/abs/2510.02354)
### Authors
Shreya Saha,Shurui Li,Greta Tuckute,Yuanning Li,Ru-Yuan Zhang,Leila Wehbe,Evelina Fedorenko,Meenakshi Khosla
### Background
人类语言系统同时处理语言形式和意义，但意义表示的抽象性问题仍存在争议。该研究通过构建神经反应模型，使用视觉和语言模型的表示来探索语言皮层中的抽象意义表示。
### Innovation
该研究创新地使用生成对应于句子的图像，并提取视觉模型嵌入，通过聚合多个生成图像以更准确地预测语言皮层的反应。此外，通过混合多个句义近义句的嵌入来改进预测准确性，并提出语言系统可能保持比现有语言模型更丰富和广泛的语义表示.
### Conclusion
研究结果证实了语言皮层中存在高度抽象且形式无关的意义表示. 这进一步表明语言系统具有比现有语言模型更丰富的语义表示.
## 279. `cs.CL` - 利用大语言模型增强的知识图谱对塞内加尔法律文本结构化 [PDF](https://arxiv.org/pdf/2510.02353), [HTML](https://arxiv.org/abs/2510.02353)
### Authors
Oumar Kane,Mouhamad M. Allaya,Dame Samb,Mamadou Bousso
### Background
塞内加尔司法系统中获取和组织法律文件存在着困难，不利于公众和法律专业人士访问和理解相关法律信息，因此有必要通过人工智能（AI）和大型语言模型（LLM）提高法律文本的可访问性，尤其是针对土地和公共领域法等法律文本的获取和结构化.
### Innovation
该研究成功从多种法律文件中提取了7,967篇文章，特别是对土地和公共领域法进行了重点研究，并建立了包含2,872个节点和10,774个关系的详细图形数据库，有效地展示了法律文本之间的关系。此外，研究使用了高级三元组抽取技术，证明了GPT-4o、GPT-4和Mistral-Large等模型在识别关系和相关元数据方面的有效性。
### Conclusion
通过这些技术，旨在为塞内加尔公民和法律专业人士提供一个坚实的基础框架，使他们能够更有效地理解自己的权利和责任。
## 280. `cs.CL` - 打破 MoE 大语言模型的三难困境：基于结构压缩的动态专家聚类 [PDF](https://arxiv.org/pdf/2510.02345), [HTML](https://arxiv.org/abs/2510.02345)
### Authors
Peijun Zhu,Ning Yang,Jiayu Wei,Jinghang Wu,Haijun Zhang
### Background
Mixture-of-Experts (MoE) 大语言模型面临负载不平衡、参数冗余和通信开销这三个问题。当前的研究试图解决这些问题，但尚未形成一个统一的框架来一揽子处理这些挑战。该研究介绍了一个基于动态专家聚类和结构化压缩的统一框架，该框架通过在线聚类过程和融合参数和激活相似度的度量，重新组织专家群体，稳定了专家的利用率。
### Innovation
该研究是第一个利用路由器的语义嵌入能力，在训练过程中动态重新配置模型架构，以获得重大效率提升的框架。在每个聚类中，采用共享基矩阵和极低秩残差适配器的拆分方式，实现每个组五倍的参数减少，同时保持专业性。结构化路由策略分为两阶段，首先将标记分配到簇，然后分配到该簇内的特定专家，大幅减少了路由搜索空间，降低了全对全通信的体积。此外，采用异构精度方案，将共享基存储在FP16且残差因子存储在INT4中，并动态卸载不活跃的簇，显著降低了峰值内存消耗。
### Conclusion
该研究展示了结构性重组织是走向可扩展、高效和内存有效的 MoE 大语言模型的合理路径。在 GLUE 和 WikiText-103 上，框架在减少约 80% 的总参数、提高 10%-20% 的吞吐量以及使专家负载方差降低超三倍方面与标准 MoE 模型保持了同等质量。
## 281. `cs.CL` - 大型语言模型代理中的沉默螺旋现象 [PDF](https://arxiv.org/pdf/2510.02360), [HTML](https://arxiv.org/abs/2510.02360)
### Authors
Mingze Zhong,Meng Fang,Zijing Shi,Yuxuan Huang,Shunfeng Zheng,Yali Du,Ling Chen,Jun Wang
### Background
沉默螺旋理论认为，在公众讨论中持有少数观点的人往往会因害怕社交孤立而保持沉默，从而使主流观点占据主导地位。当代理这些观点的'代理'是大型语言模型时，传统的心理学解释不再直接适用，因为沉默螺旋理论是为人类社会开发的。因此，文章提出了一个关键问题：语言生成过程中的统计数据是否能够引发类似沉默螺旋的动态？
### Innovation
文章提出了一种评估大型语言模型中沉默螺旋现象的评估框架。具体来说，考虑了四个控制条件，系统地变化了‘历史’和‘个性’信号的可用性。使用趋势检验（如曼-肯德尔检验和斯皮尔曼等级）和集中度度量（如峰度和四分位间距）来评估意见动态。实验结果表明，历史信息和个性信息共同作用会导致强烈的主流倾向和复制沉默螺旋模式；仅有历史信号增加观点的锚定效应；仅有个性信号促进多样化但不相关的意见。这表明，在没有历史锚定的情况下，沉默螺旋动态不能出现。研究将计算社会学和负责任的人工智能设计相结合，强调需要监控和减轻大型语言模型代理系统中出现的从众行为的必要性。
### Conclusion
研究表明，历史信息和个性信息的结合会导致大型语言模型中强烈的主流优势，并重现沉默螺旋模式；仅有历史信息使得观点有强烈的锚定效应；仅有个性信息则促进了多样但不相关的意见，这表明没有历史锚定时，沉默螺旋动态无法出现。这项工作结合了计算社会学和负责任的人工智能设计，强调了需要监控和减轻大型语言模型代理系统中出现的从众行为的必要性。
## 282. `cs.CL` - Emission-GPT：一种专门领域的语言模型代理，用于知识检索、排放清单和数据分析 [PDF](https://arxiv.org/pdf/2510.02359), [HTML](https://arxiv.org/abs/2510.02359)
### Authors
Jiashu Ye,Tong Wu,Weiwen Chen,Hao Zhang,Zeteng Lin,Xingxing Li,Shujuan Weng,Manni Zhu,Xin Yuan,Xinlong Hong,Jingjie Li,Junyu Zheng,Zhijiong Huang,Jing Tang
### Background
空气质量改善和应对气候变化依赖于对空气污染物和温室气体排放的准确理解和分析。然而，有关排放的知识往往是碎片化的且高度专业化，现有的排放数据访问和汇总方法也效率低下。这些问题阻碍了非专家对排放信息的理解，影响研究和管理。现有的解决方案远远不够，因此需要一种能够提供准确领域特定知识的语言模型代理来应对这一挑战。
### Innovation
本文介绍了一种名为Emission-GPT的大语言模型代理，专门针对大气排放领域，通过精心策划的知识库（包含超过10,000份文档，如标准、报告、指南和同行评审文献）和提示工程，集成问题完成技术，能够进行精确的领域特定问题回答。此外，Emission-GPT还能够通过自然语言进行交互式的数据分析，如查询和可视化清单、分析来源贡献、推荐用户定义场景下的排放因子等。通过在广东省的案例研究证明，Emission-GPT可以通过简单的提示直接从原始数据中提取关键见解，如点源分布和行业趋势。其模块化和可扩展的架构还使得传统的手动工作流程能够被自动化，将Emission-GPT定位为下一代排放清单开发和基于场景评估的基础工具。
### Conclusion
Emission-GPT在获取和分析排放数据方面具有模块化和可扩展架构的优势，简化了传统的手动工作流程，为下一代排放清单开发和基于场景的评估提供了基础工具。
## 283. `cs.CL` - 语言模型中参数知识和上下文知识利用的训练动力学 [PDF](https://arxiv.org/pdf/2510.02370), [HTML](https://arxiv.org/abs/2510.02370)
### Authors
Minsung Kim,Dong-Kyum Kim,Jea Kwon,Nakyeong Yang,Kyomin Jung,Meeyoung Cha
### Background
大型语言模型在推理时检索到的上下文知识与预训练期间获得的参数知识之间常常存在冲突。接受外部知识而不加批判的模型可能对传播错误信息变得脆弱，而严格遵循参数知识的模型则无法从检索中受益。尽管检索增强生成得到了广泛采用，但我们仍然缺乏系统理解训练条件下如何影响知识仲裁策略的知识。这一差距可能导致生成预训练模型具有不理想的仲裁行为，进而浪费额外的计算资源。
### Innovation
本文首次控制研究了训练条件如何影响模型使用参数知识和上下文知识及其两者之间的调和策略，通过在合成的人物传记语料库上训练基于转换器的语言模型，并系统地控制各种条件。实验证明，文件内的事实重复有助于提高参数和上下文知识的能力。在包含不一致信息或分布偏斜的语料库上进行训练，会促使模型发展出利用参数和上下文知识的稳健策略。研究表明，这些非理想属性对于学习稳健的仲裁非常重要，为和谐整合参数和上下文知识的模型预训练提供了可操作的经验指导。
### Conclusion
本研究提供了关于训练大型语言模型中知识调和策略的具体、基于经验的指导，表明内在的知识冲突特性对于学习有效的调和策略是关键的。
## 284. `cs.CL` - DiffuSpec: 解锁扩散语言模型在推测性解码中的应用 [PDF](https://arxiv.org/pdf/2510.02358), [HTML](https://arxiv.org/abs/2510.02358)
### Authors
Guanghao Li,Zhihui Fu,Min Fang,Qibin Zhao,Ming Tang,Chun Yuan,Jun Wang
### Background
随着大型语言模型（LLMs）的规模扩大，准确度提高，但由于解码的自回归（AR）特性，每生成一个词都需要进行一次串行前向传递，增加了延迟。推测性解码通过快速草稿生成器提出多词草稿，随后由目标模型并行验证，虽然缓解了这一问题，但很多部署仍然依赖于自回归草稿生成器，其串行前向传递限制了实际时间上的增益。因此，研究团队重新审视了推测性解码的草稿生成阶段，并提出了一种无需训练的可插入框架DiffuSpec，利用预训练的扩散语言模型（DLM）在一次前向传递中生成多词草稿，同时与标准的自回归验证器兼容。由于DLM草稿在双向条件生成，平行的位置候选形成一个token格子，其中的局部最高概率token不需要形成因果的左到右路径。此外，DLM草稿生成需预先设定草稿长度，导致速度和质量之间的权衡。针对这些挑战，提出了解决方案：（i）在这一格子上进行因果一致性路径搜索(CPS)，抽取与自回归验证器对齐的左到右路径；（ii）一种适应性草稿长度（ADL）控制器，根据近期接受反馈和实际生成长度调整下一次提案的规模。
### Innovation
DiffuSpec是一种无需训练的可插入框架，通过预训练的扩散语言模型（DLM）在一次前向传递中生成多词草稿，兼容标准自回归验证器。提出了因果一致性路径搜索（CPS）和适应性草稿长度（ADL）控制器来解决速度和质量之间的权衡，以及确保生成的草稿符合自回归验证过程。实验结果显示，DiffuSpec可以实现最高3倍的实时时钟速度提升，证明了扩散模型在推测性解码中的广泛应用潜力，作为自回归草稿生成器的稳健替代方案。
### Conclusion
通过引入DiffuSpec框架，基于扩散语言模型的推测性解码成为了一种稳健的替代方案，可显著提升推测性解码过程中的实时性能，特别是在大规模语言模型的应用场景中。
## 285. `cs.CL` - 评估用于现实世界决策和推荐的口语对话语言模型的偏见 [PDF](https://arxiv.org/pdf/2510.02352), [HTML](https://arxiv.org/abs/2510.02352)
### Authors
Yihao Wu,Tianrui Wang,Yizhou Peng,Yi-Wen Chao,Xuyi Zhuang,Xinsheng Wang,Shunshun Yin,Ziyang Ma
### Background
虽然大型语言模型（LLMs）中的偏见，如输出中的刻板印象和文化倾向，在研究中已有涉及，但在包含音频输入和输出的口语对话模型（SDMs）中的偏见及其特性仍然鲜有探讨。声学特征，如年龄、性别和口音，会影响模型的输出，在多轮对话的多重影响下，这些特征可能加剧偏见，对决策和推荐任务的公平性产生潜在影响。
### Innovation
本文系统性地评估了口语LAMs中的偏见，并探讨了多轮对话和重复负面反馈的影响。通过使用决策中的群体不公平评分（GUS）和推荐中的基于相似性的正常化统计数据率（SNSR）来测量偏见，研究了开源模型（如Qwen2.5-Omni和GLM-4-Voice）以及闭源API（如GPT-4o Audio和Gemini-2.5-Flash）中的偏见情况。研究发现，闭源模型的偏见较低，而开源模型在年龄和性别方面更敏感，推荐任务会加剧跨群体的差异。研究发现，即使在多轮对话中，偏见也可能持续存在。这项工作是首个系统性研究端到端口语对话模型中偏见的工作，提供了对公平和可靠的音频交互系统的见解。我们还提供了FairDialogue数据集和评估代码，以推动进一步的研究。
### Conclusion
通过对口语LAMs中偏见的系统性研究，我们提供了实现公平可靠的音频交互系统的见解，并通过开源和闭源模型提供了具体的偏见测量方法，这些方法可以通过提供的FairDialogue数据集和评估代码进行复制和验证。
## 286. `cs.CL` - 多LLM系统中基于不确定性的答案选择以提高推理能力 [PDF](https://arxiv.org/pdf/2510.02377), [HTML](https://arxiv.org/abs/2510.02377)
### Authors
Aakriti Agrawal,Rohith Aralikatti,Anirudh Satheesh,Souradip Chakraborty,Amrit Singh Bedi,Furong Huang
### Background
大规模语言模型（LLMs）展现了卓越的能力，但在资源受限的情况下，从多个LLMs中选择最可靠的回应仍是一个挑战。现有方法往往依赖昂贵的外部验证者、人工评估者，或者需要单一模型生成多个样本以进行自我一致性检查。多LLM系统虽然能够生成更广泛多样的回复，但往往在表现上不如单一LLM的自我一致性检查。
### Innovation
本文提出了一种原理上清晰、新颖且计算高效的多LLM系统方法，用于从不同LLM中选择最佳回应，通过使用校准的对数似然分数，隐式地利用了这些模型内在的知识和信心。
### Conclusion
该方法在GSM8K、MMLU（6个子集）和ARC数据集的辩论（多轮LLM讨论）和非辩论（Best-of-N多LLM）设置中分别取得了约4%、3%和5%的提升。
## 287. `cs.CL` - ChunkLLM: 一种加速大语言模型推理的轻量级插件式框架 [PDF](https://arxiv.org/pdf/2510.02361), [HTML](https://arxiv.org/abs/2510.02361)
### Authors
Haojie Ouyang,Jianwei Lv,Lei Ren,Chen Wei,Xiaojie Wang,Fangxiang Feng
### Background
基于Transformer的大模型在自然语言处理和计算机视觉领域表现出色，但由于自注意力机制依赖输入标记的二次复杂度，在计算效率上面临严重瓶颈。为此，研究人员提出了系列以块选择和压缩为基础上的方法，但这些方法存在语义不完整和训练推理效率低的问题。为综合解决这些挑战，本研究提出了ChunkLLM，一种轻量级且可插拔的训练框架。
### Innovation
本研究引入了QK Adapter（Q-Adapter和K-Adapter）和Chunk Adapter两种组件，前者附着于每个Transformer层，旨在实现特征压缩和块注意力获取双重目的；后者在模型最底层运行，利用上下文语义信息检测块边界。在训练阶段，主干的参数保持冻结，仅对QK Adapter和Chunk Adapter进行训练。研究设计了一种注意力精炼方法用于训练QK Adapter，以增强关键块的召回率。在推理阶段，仅当检测到当前标记为块边界时才触发块选择，从而加速模型推理。
### Conclusion
实验证明，ChunkLLM在长文本和短文本基准数据集上的表现均与传统Transformer相当，同时在长上下文基准数据集上保持98.64%的性能水平，同时还保留了48.58%的关键值缓存率。特别是在处理120K长文本时，与传统Transformer相比，ChunkLLM实现了4.48倍的速度提升。
## 288. `cs.CL` - 语言、文化和意识形态：具有推理能力的大型语言模型在政治推文中个性化判定不端行为 [PDF](https://arxiv.org/pdf/2510.02351), [HTML](https://arxiv.org/abs/2510.02351)
### Authors
Dzmitry Pihulski,Jan Kocoń
### Background
该研究探讨了大型语言模型（LLMs）如何在被要求采取特定政治和文化视角时对政治话语中的不端行为进行评估。研究使用了以2020年美国大选推文为中心的MD-Agreement数据集的多语言子集，评估了几种最新的LLMs，包括DeepSeek-R1、o4-mini、GPT-4.1-mini、Qwen3、Gemma和Mistral。这些模型被要求从不同政治角色（极右、保守、中间偏左、进步）的视角判断推文是否属于不端行为。研究表明，具有明确推理能力的大型模型（如DeepSeek-R1、o4-mini）在处理意识形态和文化差异时更为一致和敏感，而较小的模型往往难以捕捉到细微的区别。
### Innovation
研究发现，推理能力显著提高了不端行为判定的个性化和可解释性，表明此类机制对于使LLMs适应跨语言和意识形态的精细社会政治文本分类至关重要。
### Conclusion
更大模型的明确推理能力使其在处理意识形态和文化差异时更加一致和敏感，而较小的模型常难以捕捉细微的区别。此类机制对于适应LLMs进行跨语言和意识形态的精细社会政治文本分类至关重要，推进了个性化不端行为判定的研究。
## 289. `cs.CL` - 学习路由：一种基于规则驱动的代理框架以实现混合源检索增强生成 [PDF](https://arxiv.org/pdf/2510.02388), [HTML](https://arxiv.org/abs/2510.02388)
### Authors
Haoyue Bai,Haoyu Wang,Shengyu Chen,Zhengzhang Chen,Lu-An Tang,Wei Cheng,Haifeng Chen,Yanjie Fu
### Background
大规模语言模型（LLMs）在通用问答（QA）中表现出色，但在需要准确和最新信息的特定应用场景中却能力不足。检索增强生成（RAG）通过添加外部知识来缓解这一局限性，但现有系统主要依赖于无结构文档，而忽略关系数据库的存在，后者提供精确、及时且易于查询的事实信息，是金融、医疗和科学研究等领域的不可或缺的基础架构。
### Innovation
本文系统性地分析了数据库和文档的查询互补优势，发现简单地结合两者会引入噪声和成本而不具有一致的准确性提升。提出了一个基于规则驱动的路由框架，通过智能的选择最合适的增强路径、规则改进和路径级元缓存来优化查询生成。实验显示该框架在三个QA基准测试上优于静态策略和学习路由基线，提升准确性同时控制计算成本。
### Conclusion
该框架通过路由代理使用显式规则评估候选增强路径并选择最优路径，通过规则制定专家代理使用问答反馈改进规则提高适应性，通过路径级元缓存利用语义相似查询过去的路由决策来减少延迟和成本。实验结果表明该框架在三个QA基准测试上持续优于静态策略和学习路由基线，同时保持适度的计算成本。
## 290. `cs.CL` - DRIFT: 从实际用户不满意中学习 [PDF](https://arxiv.org/pdf/2510.02341), [HTML](https://arxiv.org/abs/2510.02341)
### Authors
Yifan Wang,Bolian Li,Junlin Wu,Zhaoxuan Tan,Zheli Liu,Ruqi Zhang,Ananth Grama,Qingkai Zeng
### Background
现实世界的大语言模型部署（如对话AI系统、代码生成助手）会自然地产生大量的隐式用户不满意信号（DSAT），用户通过迭代、修正和表达偏好来获得更好的答案，而显式满意度（SAT）反馈相对稀缺。现有的偏好学习方法与这种数据特征不匹配，因为它们依赖昂贵的人工标注或者假设有很多正面响应。因此，当前的工作需要一种新的方法来更好地利用DSAT信号进行学习。
### Innovation
DRIFT（Dissatisfaction-Refined Iterative Preference Training）方法，其训练基于实际的DSAT信号，并动态从进化的策略中抽取阳性样本。DRIFT在WildBench任务评分和AlpacaEval2胜利率上显著优于基线模型和强大的迭代DPO、SPIN方法，特别是在大规模模型上，DRIFT在WildBench上的表现超过了GPT-4o-mini。此外，DRIFT还保留了探索性能力，生成了更多样化的高奖励解决方案，而不是收敛到狭窄的子集。理论分析表明，这种设计保留了偏好差距并避免了梯度退化。
### Conclusion
DRIFT提供了一种有效且可扩展的方法，利用最广泛和信息量大的信号来调整模型，显示出其在实际应用后训练中的优越性。该方法已在实际WildFeedback和合成UltraFeedback数据集上进行验证，并在大型模型上显示出显著的性能改善。DRIFT的设计思路和代码数据可从指定网址获取。
## 291. `cs.CL` - 使用罗马尼亚历史进行跨语言分析大型语言模型中的偏见 [PDF](https://arxiv.org/pdf/2510.02362), [HTML](https://arxiv.org/abs/2510.02362)
### Authors
Matei-Iulian Cocu,Răzvan-Cosmin Cristia,Adrian Marius Dumitran
### Background
本文研究结合了一套具有争议性的罗马尼亚历史问题，并让多个大型语言模型（LLM）在不同语言和上下文中回答这些问题，以评估其偏见。作者注意到历史常常通过扭曲的视角呈现，主要由特定国家的文化和理想所影响，甚至在大型语言模型中也是如此。由于数据集本身可能存在的模糊性，这种不中立性在用户中普遍存在。研究分为三个阶段，旨在确认期望的响应类型可以影响一定程度的响应；在回答某些问题时，LLM 会提供肯定的回答，但在被告知用尺度数值形式作答后，其思维方式可能会有所变化。研究结果显示二元响应的稳定性虽然相对较高，但并不完全理想且在不同语言之间会有所变化；数字评分经常与初始的二元选择相背离，而最优的模型并不总是最准确或中立的模型。研究揭示了模型在特定语言上下文中的不一致性倾向，尤其是在回答问题时。
### Innovation
该研究的创新之处在于结合了跨语言和不同上下文的比较，分析大型语言模型在回答具有争议的历史问题时的偏见。通过观察LLM在回答同一问题时，根据不同指导方式发生变化的模式，提出了对于模型偏见更为深入的理解，同时也揭示了在不同语言和格式下模型稳定性差异的现像。
### Conclusion
研究表明大型语言模型在不同语言环境中的二元响应稳定性较高但不完美，并且经常在不同语言之间或不同格式中改变立场；数字评分常常与初始的二元选择不一致，而一些最一致的模型并不总是被认为是最准确或最中立的模型。研究揭示了模型在特定语言上下文中的不一致性倾向，这一发现对如何评估和利用大型语言模型具有重要启示。
## 292. `cs.CL` - KnowledgeSmith：通过模型编辑与遗忘揭开LLMs的知识更新 [PDF](https://arxiv.org/pdf/2510.02392), [HTML](https://arxiv.org/abs/2510.02392)
### Authors
Yinyi Luo,Zhexian Zhou,Hao Chen,Kai Qiu,Marios Savvides,Yixuan Li,Jindong Wang
### Background
大型语言模型（LLMs）的知识更新机制尚未被充分探索，且现有评估机制存在不足，导致对知识更新的理解受阻。编辑和遗忘是保持LLMs最新型态的有效策略，但它们的具体行为和相互差异仍不清晰，尤其是在不同的知识层次上，它们与人类更新知识的方式是否相似，以及随着数据量增加，编辑和遗忘策略的区别是什么等问题尚待解答。本研究旨在系统性地理解LLMs的知识更新机制，通过对编辑和遗忘的机制进行统一化框架设计，构建了一种自动数据生成器，在多层图结构和不同数据规模上提供结构化的干预，以便控制研究并深入探究不同修改策略在模型知识中的传播规律。
### Innovation
本研究提出的KnowledgeSmith框架首先将编辑和遗忘视为一项受限优化问题的实例。更重要的是，该研究通过自动数据生成器提供了结构化的干预，并能够在不同图的层级和数据规模上实现，这使得关于不同修改策略如何在模型知识中传播的实验得以被精心控制地进行。研究结果揭示了关于知识传播的细致见解，包括可塑性缩放、一致性以及稳健性的变化。此外，研究发现LLMs在不同知识层次上的更新机制与人类存在差异，并且存在一致性和容量之间的权衡关系。研究者期望这些发现能够为更可靠和可扩展策略的设计提供参考。
### Conclusion
研究结果表明，LLMs在不同层次的知识更新机制与人类有所不同，并发现了知识更新过程中的重要权衡关系。我们希望研究所得的见解能够促进更可靠和可扩展的LLM编辑和遗忘策略的设计。
## 293. `cs.CL` - 超越手册和任务：LLM代理的实例级上下文学习 [PDF](https://arxiv.org/pdf/2510.02369), [HTML](https://arxiv.org/abs/2510.02369)
### Authors
Kuntai Cai,Juncheng Liu,Xianglin Yang,Zhaojie Niu,Xiaokui Xiao,Xing Chen
### Background
大型语言模型（LLM）代理通常会接收两种类型的上下文：环境级别的手册定义了交互界面和全局规则，以及与具体目标相关的任务级指导或演示。本文指出，实例级别的上下文，即特定环境实例中的可验证和可重复使用的事实（如对象位置、制作配方和地方规则），作为第三种类型的重要但被忽视的上下文，对于复杂任务的成功至关重要。缺少实例级别的上下文是LLM代理在复杂任务上失败的常见原因，因为成功率不仅取决于对全局规则或任务提示的推理，还取决于基于精确和持久事实的决策。
### Innovation
作者将这个问题形式化为实例级上下文学习（ILCL），并提出了一种任务无关的方法来解决它。该方法通过使用一个紧凑的TODO森林来智能地确定下一步操作，并通过轻量级的计划执行提取循环来执行这些操作。此过程自动生成一个高精度的可重复使用的上下文文档，从而摊销初始探索成本。实验结果表明，例如，在TextWorld中，ReAct的成功率从37%提高到95%，而IGE从81%提高到95%。通过将一次性探索转化为持久性、可重复的知识，该方法补充了现有上下文，以实现更可靠和高效的LLM代理。
### Conclusion
该方法通过自动生成高精度的可重复使用的上下文文档，有效降低了探索成本，并且在多个任务环境中都显示出了改进的成功率和效率。实例级别的上下文补充了现有的上下文，使得LLM代理在复杂任务中更加可靠和高效。
## 294. `cs.CL` - 让语言模型感知的词汇 [PDF](https://arxiv.org/pdf/2510.02425), [HTML](https://arxiv.org/abs/2510.02425)
### Authors
Sophie L. Wang,Phillip Isola,Brian Cheung
### Background
大语言模型（LLMs）仅通过文本训练，似乎缺乏直接的感知体验，但其内部表示会不自觉地受到语言中隐含的多模态规律的影响。研究人员假设明确的感官提示可以揭示这种潜在结构，使仅基于文本的LLM更加接近于专门的视觉和音频编码器。当我们给模型一个感官提示，告诉它“看”或“听”时，它会被引导将下一个预测词作为在从未实际提供的潜在视觉或听觉证据上的条件而解决。实验证明，轻量级的提示工程可以有效地激活特定模态的表示，即使这些模型是纯粹基于文本训练的。
### Innovation
研究使用轻量级的提示工程来激活LLM中的适当模态表示，即使模型是纯粹基于文本训练的。这表明可以通过明确的感官提示将语言模型与视觉和音频数据更好地对齐。这种做法为未来的语言模型应用提供了新的可能性。
### Conclusion
研究发现，通过适当的提示，仅仅训练于文本的LLM也能表现出特定模态的感知能力，从而更接近于视觉或听觉编码器的表示。这为语言模型的多模态应用开启了新的研究方向。
## 295. `cs.CL` - 基于知识图谱的RAG系统评价框架 [PDF](https://arxiv.org/pdf/2510.02549), [HTML](https://arxiv.org/abs/2510.02549)
### Authors
Sicheng Dong,Vahid Zolfaghari,Nenad Petrovic,Alois Knoll
### Background
大型语言模型（LLMs）已成为研究热点，并被应用于文本生成、对话系统等多个领域。 Retrieval Augmented Generation (RAG) 是LLMs最重要的应用之一，它可以显著提升生成内容的可靠性和相关性。然而，评估RAG系统的任务仍然极具挑战性。传统的评估指标难以有效捕捉现代LLMs生成内容的关键特征，如高流畅性和自然性。受RAGAS工具的启发，该工具是已知的RAG评估框架，本文扩展了此框架，提出了一种基于知识图谱的评价范式，结合多跳推理和语义社区聚类，获得更为综合的评分指标。
### Innovation
本文扩展了RAGAS工具，提出了一种基于知识图谱的RAG系统评价框架，该框架通过引入多跳推理和语义社区聚类，实现了更全面的评分指标。该方法能更好地理解RAG系统的性能，并从更细致的角度评估其表现。实验结果表明，基于知识图谱的评价方法对生成输出中的微妙语义差异更敏感。
### Conclusion
本文讨论了评估RAG系统的关键挑战，并指出了未来研究的方向。
## 296. `cs.CL` - 转录，翻译，还是转换书写：语音语言模型中间表示的调查 [PDF](https://arxiv.org/pdf/2510.02569), [HTML](https://arxiv.org/abs/2510.02569)
### Authors
Tolúl?d{o}pé Ògúnrèmí,Christopher D. Manning,Dan Jurafsky,Karen Livescu
### Background
语音语言模型（SLMs）结合了语音和大型语言模型（LMs），依赖于模态适配器（MAs）将语音编码器的输出映射到解码器LM可以理解的表示。然而，我们对这些关键适配器如何转换表示知之甚少。本文通过检查三种SLMs（SALMONN，Qwen2-Audio和Phi-4-Multimodal-Instruct）的适配器输出表示，探讨了不同的策略。
### Innovation
本文通过找到与适配器表示最近的解码器LM标记，揭示了两种不同的适配器表示策略。对于使用Whisper编码器的模型，适配器似乎使用基于英语的通用语言表示输入的意义，允许它们处理在指令调优中未见过的语言。对于使用类似Phi-4-Multimodal-Instruct的模型，适配器则用英语单词表示输入的音素。研究假设这个差异取决于语音编码器是仅用于语音识别还是也用于翻译。
### Conclusion
研究结果表明，语音编码器的训练目标影响了适配器表示的意义和音素之间的转换。这项研究提高了我们对语音语言模型内部机制的理解，特别是在处理未见语言和音素表示方面。
## 297. `cs.CL` - 使用层次记忆的预训练：分离长尾知识和常见知识 [PDF](https://arxiv.org/pdf/2510.02375), [HTML](https://arxiv.org/abs/2510.02375)
### Authors
Hadi Pouransari,David Grangier,C Thomas,Michael Kirchhof,Oncel Tuzel
### Background
现代语言模型的表现力得益于其参数量的增加：更大的模型可以存储更多世界知识并进行更好的推理。然而，将所有世界知识压缩到参数中是不必要的，因为每条提示只用了其中的一部分，并且对于限制了推理时间内存和计算能力的边缘设备来说是不切实际的。
### Innovation
本文通过引入一种内存增强架构和与现有硬件范式相一致的预训练策略来解决这一局限性。引入了小型语言模型，这些模型可以访问大型层次参数化记忆库以编码世界知识。在预训练和推理过程中，从大型参数化记忆库中获取上下文相关的记忆块，并将其添加到模型中。预训练阶段学习将长尾世界知识存储在记忆参数中，小型语言模型则捕捉常见知识和通用推理能力。
### Conclusion
通过大规模实验，展示了显著的性能提升：一个带有160M参数的模型使用了18M参数的记忆块，来自4.6B参数的记忆银行，达到了具有更大量参数的常见模型的相当性能。通过广泛的实验，研究了Transformer中的参数化记忆的最佳类型和大小，并将其规模扩展至超过21B参数。发现提出的层次前馈记忆在各种Transformer架构中表现良好，无论是在预训练期间还是事后添加。
## 298. `cs.CL` - SoT: 结构化思维提示引导大语言模型中的多语言推理 [PDF](https://arxiv.org/pdf/2510.02648), [HTML](https://arxiv.org/abs/2510.02648)
### Authors
Rui Qi,Zhibo Man,Yufeng Chen,Fengran Mo,Jinan Xu,Kaiyu Huang
### Background
近年来，大语言模型（LLMs）的能力大幅提升，能够通过深度思考完成复杂的推理任务。然而，这些推理能力尚未成功应用于低资源语言，导致在多语言推理任务中存在资源瓶颈。现有方法难以维持跨语言表达差异下的统一推理路径。
### Innovation
本文提出了一种称为Structured-of-Thought（SoT）的无监督训练方法，通过多步骤转换（语言思考转换和结构化知识转换）提升多语言推理性能。SoT能够将语言特定的语义信息转换为语言无关的结构化表示，使模型能够更准确地理解不同语言的问题。此外，SoT有效引导LLMs进行集中式推理，以保持在处理跨语言表达差异时的一致推理路径。
### Conclusion
实验结果表明，在适应不同LLM主干结构时，SoT方法在多个多语言推理基准上优于几种强baseline模型。此外，SoT还可与其它无监督训练策略结合，以进一步提升效果。我们的代码已公开。
## 299. `cs.CL` - Text-to-SQL语义解析中的领域知识检索与增强 [PDF](https://arxiv.org/pdf/2510.02394), [HTML](https://arxiv.org/abs/2510.02394)
### Authors
Manasi Patwardhan,Ayush Agarwal,Shabbirhussain Bhaisaheb,Aseem Arora,Lovekesh Vig,Sunita Sarawagi
### Background
大型语言模型（LLMs）在将自然语言（NL）查询翻译成SQL时表现差异显著，这主要是由于不同数据库（DBs）对领域特定词汇的映射需求存在差异。NL查询通常使用领域特定的词汇表达，并且将这些表达正确映射到SQL需要理解嵌入的领域表达及其与数据库模式结构的关系。现有的基准测试依赖于不现实的、特定查询的文本提示来表达领域知识。因此，本文分析了现有方法的问题，并提供了一种系统框架来在数据库级别关联结构化的领域声明，并通过子字符串匹配检索相关领域声明来增强文本到SQL的语义解析。
### Innovation
提出了一个系统框架，用于在数据库级别关联结构化的领域声明。通过基于子字符串匹配检索相关领域声明来增强文本到SQL的语义解析。与现有的特定查询的文本提示不同，该方法使用数据库级别的结构化领域声明，提高了准确性和实用性，评估结果显示这种方法显著优于其他检索方法。
### Conclusion
数据库级别的结构化领域声明比现有的特定查询的文本提示更实用和准确。通过基于子字符串匹配检索相关领域声明的方法相比其他检索方式提供了更高的准确性。
## 300. `cs.CL` - 揭开语法规则的面纱：语言模型如何学习上下文自由文法 [PDF](https://arxiv.org/pdf/2510.02524), [HTML](https://arxiv.org/abs/2510.02524)
### Authors
Laura Ying Schulz,Daniel Mitropolsky,Tomaso Poggio
### Background
尽管大型语言模型取得了令人印象深刻的成果，但人们对它们的学习动态了解甚少。本文注意到，大多数感兴趣的研究领域，如自然语言语法、编程语言、算术问题等，都可以用概率上下文自由文法（PCFGs）来表征。研究集中在小型模型在通过自动生成的PCFG合成语言进行训练时的学习动态上，这使得可以精确控制文法规则的复杂性、递归深度和子句法结构。通过证明针对子句法结构的训练损失和Kullback-Leibler偏差的若干通用、递归公式，以及实验证据显示与儿童学习方式不同，变换器模型会并行减少所有子句法结构的损失。研究还表明，预先训练在子句法结构上的模型可以改善较小模型的最终损失，并且预训练模型发展出与文法子结构更一致的内部表示。研究表明，模型在处理更深的递归结构时存在困难，揭示了神经网络代表层次结构语法的基本挑战。
### Innovation
提出了一个新的框架，用于理解语言模型如何获得语法知识。通过研究小型模型在基于PCFG生成的合成语言上的训练动态，发现了与儿童学习方法不同的模式。同时，证明了几种通用、递归公式，并验证了预先训练在子句法结构上的模型可以改善小型模型的损失，以及开发出与文法子结构更一致的内部表示。最后考察了模型在处理更深递归结构上的局限性，提出了重要的新问题。
### Conclusion
本文的工作启动了关于变换器在PCFG上的学习动态研究，作为探究语言模型学习的多功能试验平台，开启了研究中许多开放问题的新方向。
## 301. `cs.CL` - Mind the Gap: Linguistic Divergence and Adaptation Strategies in Human-LLM Assistant vs. Human-Human Interactions [PDF](https://arxiv.org/pdf/2510.02645), [HTML](https://arxiv.org/abs/2510.02645)
### Authors
Fulei Zhang,Zhou Yu
### Background
随着大型语言模型（LLMs）在面向客户的应用中越来越多地部署，人们对用户与LLM聊天机器人互动方式与与人类代理互动方式之间的差异知之甚少。研究发现用户在与聊天机器人互动时会采用不同的交流方式。研究显示，在这两种互动方式中，用户的语言在语法流畅性、礼貌和词汇多样性方面存在显著差异。这一发现意味着仅根据人类-人类交互数据训练的模型可能无法充分适应LLM聊天机器人部署后所发生的沟通风格转变。
### Innovation
文章通过实证研究揭示了用户与LLM聊天机器人互动与人类代理互动之间的沟通风格差异，并提出了两种适应策略：数据增强以及推理时的消息重述。结果显示，使用风格多样化的数据集训练的模型比仅使用原始或风格统一的数据集训练的模型表现better。此外，推理时的消息重述的效果较弱。
### Conclusion
研究结果表明，当LLM聊天机器人部署后，需要针对沟通风格变化进行模型的调整，数据增强和推理时的消息重述是两种有效的适应策略。进一步改进大型语言模型在现实世界中的用户体验。
## 302. `cs.CL` - 语言模型中Context利用高亮解释评估框架 [PDF](https://arxiv.org/pdf/2510.02629), [HTML](https://arxiv.org/abs/2510.02629)
### Authors
Jingyi Sun,Pepa Atanasova,Sagnik Ray Choudhury,Sekh Mainul Islam,Isabelle Augenstein
### Background
用户对语言模型（LMs）在生成响应时如何利用上下文信息了解不足，现有方法无法准确验证高亮解释（HEs）在解释上下文利用方面的有效性，尤其是在长期上下文中存在位置偏差等问题，这些都需要新的解释方法来解决大规模可靠解释的需求。
### Innovation
提出了首个用于上下文归因的高亮解释黄金标准评估框架，通过控制测试案例来解决现有评估方法的间接代理局限性，并评价了三种现有技术和一种新方法（MechLight）在四种上下文情景、四个数据集和五种LMs上的表现，验证了MechLight的优越性同时也揭示了现有方法的局限性。
### Conclusion
MechLight在所有上下文情景中表现最佳，但所有方法在处理长上下文时都存在位置偏差，这表明现有解释方法在准确性方面存在根本性挑战，需要新的方法来大规模提供可靠的上下文利用解释。
## 303. `cs.CL` - 多模态大型语言模型的自我改进：综述 [PDF](https://arxiv.org/pdf/2510.02665), [HTML](https://arxiv.org/abs/2510.02665)
### Authors
Shijian Deng,Kai Wang,Tianyu Yang,Harsh Singh,Yapeng Tian
### Background
近年来，大型语言模型（LLMs）的自我改进取得了显著进展，能够在不显著增加人力成本的情况下增强模型能力。尽管该领域仍较为年轻，但将其扩展到多模态领域具有巨大的潜力，能够利用多种数据源和开发出更具通用性的自我改进模型。当前的研究首次全面概述了多模态大型语言模型（MLLMs）的自我改进。
### Innovation
本文从三个方面系统地概述了当前关于多模态大型语言模型自我改进的文献，并讨论了数据收集、数据组织、模型优化方法，以促进MMLMs自我改进的发展。此外，还介绍了常用的评估方法和下游应用。
### Conclusion
最后，文章指出了亟待解决的挑战和未来的研究方向。
## 304. `cs.CL` - TravelBench：探索大语言模型在资源紧缺领域的性能 [PDF](https://arxiv.org/pdf/2510.02719), [HTML](https://arxiv.org/abs/2510.02719)
### Authors
Srinivas Billa,Xiaonan Jing
### Background
当前现有的大规模预训练语言模型（LLM）基准测试结果在低资源任务中的信息有限，这使得在这些领域开发有效的解决方案变得困难。研究者们发现，传统的模型基准测试无法全面反映模型在低资源任务中的性能。
### Innovation
本文提出了一个名为TravelBench的新基准集，它集成了14个覆盖7种常见NLP任务的真实匿名旅行数据集。研究人员通过对比不同LLM在这些任务上的表现，评估了模型的准确度、缩放行为及推理能力。研究结果表明，传统的基准测试结果不足以理解模型在低资源任务中的表现，即便是经过大规模训练的LLM，在复杂、特定领域的场景下也会遇到性能瓶颈，而且对于较小的模型来说，推理能力提供了更大的提高。
### Conclusion
本文的研究结果证实，现有的通用基准测试对低资源任务的理解不足，大模型在复杂领域中仍存在性能瓶颈，而增强的推理能力能够显著提升小型模型在特定任务上的表现。
## 305. `cs.CL` - 时间至不一致性：大规模语言模型对抗攻击鲁棒性的一种生存分析 [PDF](https://arxiv.org/pdf/2510.02712), [HTML](https://arxiv.org/abs/2510.02712)
### Authors
Yubo Li,Ramayya Krishnan,Rema Padman
### Background
大型语言模型（LLMs）已经颠覆了对话式人工智能领域，但它们在长时间多轮对话中的稳健性仍然 poorly understood。现有的评估框架主要集中在静态基准和单一回合的评估上，未能捕捉到真实世界交互中对话降级的动态特征。
### Innovation
本文首次进行了全面的对话式AI鲁棒性生存分析，使用Cox比例风险、加速失效时间及随机生存森林方法分析了9种最先进的LLM的36,951个对话回合。研究发现，从提示到提示的突然语义漂移是灾难性的，极大地增加了对话失败的风险；相比之下，渐进的、累积的漂移具有显著的保护性，大幅降低了失败风险并使得对话可以持续更长时间。交互加速失效时间模型显示出了优越的性能，展示了出色的区分能力和极佳的校准。
### Conclusion
本文的工作建立生存分析作为评估LLM稳健性的强大范式，提供了设计更具弹性的对话代理的实用洞察，并挑战了关于对话式人工智能系统中语义一致性的必要性的传统假设。
## 306. `cs.CL` - 特征缺口中的不确定性：基于上下文问答的LLMs的本体论不确定性量化 [PDF](https://arxiv.org/pdf/2510.02671), [HTML](https://arxiv.org/abs/2510.02671)
### Authors
Yavuz Bakman,Sungmin Kang,Zhiqi Huang,Duygu Nur Yaldiz,Catarina G. Belém,Chenyang Zhu,Anoop Kumar,Alfy Samuel,Salman Avestimehr,Daben Liu,Sai Praneeth Karimireddy
### Background
不确定性量化（UQ）研究主要集中在闭卷事实问答（QA）任务上，而关于上下文QA的任务尚未得到充分研究，尽管其在实际应用中具有重要性。本文聚焦于上下文QA任务中的不确定性量化，并提出了一种基于理论的方法来衡量本体论不确定性。
### Innovation
论文提出了一种任务无关的时间级不确定性度量，将其定义为给定模型的预测分布与未知真实分布之间的交叉熵。通过分解这一度量，研究者隔离了本体论部分，并通过理想化的完美提示模型近似真实分布。此外，作者通过这种方法构建了一个通用框架，并猜测三个特征可以近似这个差距：上下文依赖性（依赖提供的上下文而非参数知识）、上下文理解（从上下文提取相关信息）和诚实性（避免故意说谎）。最后，通过使用仅少量标记样本的自顶向下可解释性方法，作者提取了这些特征并组合成稳健的不确定性评分。相对现有最先进的无监督（无抽样）和监督UQ方法，该方法在多个问答基准测试中表现优异，在分布内和分布外设置下分别实现了高达13个点的提高，同时几乎不增加推理开销。
### Conclusion
本文提出的方法在上下文问答任务的不确定性量化方面取得了显著成果，相较于最先进的无监督和监督不确定性量化方法，展现了更好的性能。
## 307. `cs.CL` - 使用Cobweb实现层次语义检索 [PDF](https://arxiv.org/pdf/2510.02539), [HTML](https://arxiv.org/abs/2510.02539)
### Authors
Anant Gupta,Karthik Singaravadivelan,Zekun Wang
### Background
传统的文档检索方法倾向于将语料库视为单一粒度下的向量云，导致语料库结构的利用不足和解释的不透明。这也是论文的研究背景。
### Innovation
本文提出了Cobweb——一个层次感知框架，用于组织句子嵌入的原型树，并通过粗粒度到细粒度的遍历进行文档排序。内部节点作为概念原型，提供了多粒度的相关信号和检索路径透明的解释。同时，本文还实例化了两种推理方法：通用的最佳首先搜索和轻量级路径和排序器。此外，实验评估表明，本文的方法在MS MARCO和QQP数据集上与强大的编码器嵌入相匹配，并且在kNN退化时仍保持鲁棒性。特别是在使用GPT-2向量时，点积检索的效果崩溃，而本文的方法仍然能够检索到相关结果。这表明Cobweb方法在效果、鲁棒性、可扩展性和基于层次原型的解释性检索方面具有竞争力。
### Conclusion
实验结果表明，Cobweb检索方法在效果、对嵌入质量的鲁棒性、可扩展性以及基于层次原型的解释性检索方面表现出了竞争力。
## 308. `cs.CL` - CLARITY：临床辅助系统的规划、推理与分诊 [PDF](https://arxiv.org/pdf/2510.02463), [HTML](https://arxiv.org/abs/2510.02463)
### Authors
Vladimir Shaposhnikov,Aleksandr Nesterov,Ilia Kopanichuk,Ivan Bakulin,Egor Zhelvakov,Ruslan Abramov,Ekaterina Tsapieva,Dmitry V. Dylov,Ivan Oseledets
### Background
该研究提出了CLARITY（临床助手），一个基于AI的平台，用于协助患者转介给专科医生、临床咨询以及评估患者的病情严重程度。其混合架构结合了有限状态机（FSM）用于结构化的对话流程，以及协作代理人使用大型语言模型（LLM）分析症状并优先转介给合适的专科医生。该平台基于模块化的微服务架构，确保安全、高效和可靠的性能，并且易于扩展以满足现有医疗工作流程和IT解决方案的需求。
### Innovation
CLARITY结合了有限状态机和大型语言模型，设计用于处理结构化对话流程和症状分析。它嵌入了一个多功能的微服务框架，能够安全、高效地运行并根据需要进行扩展。研究强调了CLARITY在大规模全国医院IT平台上的集成效果，在两个月的部署期内完成了超过55,000个内容丰富的用户对话，其中2,500个被专家注释以进行验证。验证结果显示，CLARITY在首次尝试转诊准确性方面超过了人类水平，咨询时间相比人类更快，最多可缩短至人手工作业的三分之一。
### Conclusion
CLARITY作为一个AI驱动的平台，在患者到专科医生的转介、临床咨询和病情评估方面展现了优异的性能，已经在大规模全国医院IT平台中得到了验证，显示了其在医疗健康领域中的强大潜力。
## 309. `cs.CL` - StepChain GraphRAG：基于知识图谱的多跳问答推理 [PDF](https://arxiv.org/pdf/2510.02827), [HTML](https://arxiv.org/abs/2510.02827)
### Authors
Tengjun Ni,Xin Yuan,Shenghong Li,Kai Wu,Ren Ping Liu,Wei Ni,Wenjie Zhang
### Background
近年来，检索增强生成（RAG）使多跳问答（QA）变得更加准确和可解释。然而，在将迭代推理步骤与外部知识检索集成时仍存在挑战。
### Innovation
引入了StepChain GraphRAG框架，将问题分解与广度优先搜索（BFS）推理流程相结合，以增强多跳问答。该方法首先在整个语料库上构建了一个全局索引；在推理时，仅检索的段落会实时解析成知识图谱，并将复杂的查询拆分为子问题。对于每个子问题，基于BFS的遍历动态沿相关边扩展，以组装明确的证据链，而不给语言模型带来多余的背景信息。
### Conclusion
在MuSiQue、2WikiMultiHopQA和HotpotQA上的实验表明，StepChain GraphRAG实现了最先进的准确匹配（Exact Match）和F1分数。StepChain GraphRAG在SOTA方法上提高了平均准确匹配2.57%和F1分数2.13%，在HotpotQA上增幅最大，准确匹配提高了4.70%，F1分数提高了3.44%。此外，StepChain GraphRAG还增强了解释性，保留了中间检索步骤中的推理链。我们讨论了未来工作如何减轻计算开销，并解决大型语言模型可能带来的幻觉，以改善多跳问答的效率和可靠性。
## 310. `cs.CL` - 约束满足方法应用于Wordle：新型启发式方法及跨语言验证 [PDF](https://arxiv.org/pdf/2510.02855), [HTML](https://arxiv.org/abs/2510.02855)
### Authors
Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel,Kamrujjaman,Eftakhar Ahmed Arnob,Ahsan Habib Tareq
### Background
Wordle 提供了一个丰富的问题解决测试平台，现有的解题器主要依赖于信息论熵最大化或基于频率的启发式方法，而没有正式处理约束问题。本文介绍了Wordle的第一个全面的约束满足问题（CSP）形式化，并提出了新颖的约束感知解题策略。
### Innovation
引入了约束感知熵，这是一种在传播约束后计算信息增益的方法，而不是基于原始候选集。此外，还提出了一种概率CSP框架，集成了贝叶斯词汇频率先验和逻辑约束。
### Conclusion
通过在2,315个英语词上的评估，约束感知熵达到了3.54的平均猜测次数，成功率为99.9%，显著优于前向检查法，且运行时间减少了46%。在10%的噪声条件下，约束感知方法保持了5.3个百分点的优势，并且概率CSP能够通过约束恢复机制在所有噪声级别下实现100%的成功率。跨语言验证在500个西班牙语词上的结果表明成功率高达88%，证实了核心CSP原则在不同语言中具有良好的转移性。开源实现提供了具有91%代码覆盖率的34个单元测试，为CSP研究提供可再现的基础结构。结合正式的CSP处理、约束感知启发式方法、概率逻辑整合、鲁棒性分析和跨语言验证，本文建立了新的性能基准，证明了基于约束满足的技术在结构化谜题解决领域中优于经典的信息论和学习方法。
## 311. `cs.CL` - PGMEL: 基于策略梯度的生成对抗网络应用于多模态实体链接 [PDF](https://arxiv.org/pdf/2510.02726), [HTML](https://arxiv.org/abs/2510.02726)
### Authors
KM Pooja,Cheng Long,Aixin Sun
### Background
实体链接任务涉及将文本中的提及与知识图谱中的相应实体关联，由于其在多种潜在应用中的重要性而备受关注。近年来，研究人员提出了一系列利用文本和视觉模态的多模态实体链接（MEL）技术，这些技术旨在学习全面的嵌入。尽管选择高质量的负样本可能在度量/表示学习中发挥关键作用，但现有文献中尚未在MEL框架下探索这一点。本文旨在通过生成对抗设置解决这一问题，其中生成器负责生成高质量的负样本，判别器负责完成度量学习任务。由于生成器涉及到生成样本，这是一个离散的过程，我们使用策略梯度技术对其进行优化，并提出了一种策略梯度生成对抗网络（PGMEL），专门用于多模态实体链接。实验结果表明，PGMEL能够通过选择具有挑战性的负样本来学习有意义的表示，并且在Wiki-MEL、Richpedia-MEL和WikiDiverse数据集上优于最先进的方法。
### Innovation
本文引入了PGMEL，一种基于策略梯度的生成对抗网络方法，专门用于多模态实体链接。该方法通过生成高质量的负样本，实现了在度量学习任务中的卓越表现。这是首次在MEL框架下探索选择高质量负样本的重要性，为多模态实体链接技术提供了新思路和解决方案。通过策略梯度优化生成器，克服了生成过程中的离散性挑战。
### Conclusion
实验结果显示，PGMEL通过生成挑战性的负样本能够学习到有意义的表示，并且在多个数据集上优于现有最先进的方法，证明了新方法的有效性。未来的研究方向可以考虑将其他模态数据（如音频）加入到多模态实体链接中，进一步提升实体链接的效果。
## 312. `cs.CL` - IndiCASA: 在印度语境中使用对比嵌入相似性评估LLMs的偏见数据集和框架 [PDF](https://arxiv.org/pdf/2510.02742), [HTML](https://arxiv.org/abs/2510.02742)
### Authors
Santhosh G S,Akshay Govind S,Gokul S Krishnan,Balaraman Ravindran,Sriraam Natarajan
### Background
大型语言模型（LLMs）已经在关键领域获得了显著的关注，这得益于它们出色的上下文理解和生成能力。然而，它们在高风险应用中的部署需要对嵌入式偏见进行严格的评估，尤其是在像印度这样文化多样性的环境中，现有的基于嵌入的偏见评估方法往往难以捕捉到细微的刻板印象。本文探讨了在印度背景下，嵌入式偏见的评估挑战，并提出了一种新的评估框架，该框架使用经过对比学习训练的编码器来捕捉细微偏见，通过嵌入相似性评估。此外，还提出了一种名为IndiCASA的新数据集，该数据集包含了2,575个人工验证的句子，覆盖了五个人口统计轴：阶层、性别、宗教、残疾和经济状况，以提供印度语境下的偏见评估，部分揭示了包括残疾相关的刻板印象存在很高的持久性，而宗教偏见相对较低，这可能反映全球去偏见努力的效果，也表明更公平的模型开发需求的巨大需求。
### Innovation
本文提出了一个基于经过对比学习训练的编码器的评估框架，通过嵌入相似性来捕捉细微偏见。同时引入了一个新的数据集IndiCASA，该数据集包含了涵盖五个维度的2,575个人工验证的句子，用以评估多个开源的LLMs在印度语境中的偏见程度，结果显示所有模型在某种程度上都表现出一些刻板印象偏见，特别是残疾相关偏见尤为持久，宗教偏见则比较低，这表明需要在更公平的模型开发中加强努力。
### Conclusion
研究揭示了在印度背景下，LLMs存在一定的偏见现象，尤其在残疾相关方面更为持久，宗教偏见相对较低，这暗示了需要在全球范围内进行更公平的模型开发。同时，提出的新框架和数据集为未来研究提供了有价值的方法和资源，有助于更深入地了解LLMs在多元文化环境中的表现。
## 313. `cs.CL` - 在测试时间进行自我反思的生成 [PDF](https://arxiv.org/pdf/2510.02919), [HTML](https://arxiv.org/abs/2510.02919)
### Authors
Jian Mu,Qixin Zhang,Zhiyong Wang,Menglin Yang,Shuang Qiu,Chengwei Qin,Zhongxiang Dai,Yao Shu
### Background
大型语言模型（LLMs）越来越依赖于长链推理来解决复杂任务，但它们的单向自回归生成过程容易出错；早期的错误可能会导致错误的累积，这表明需要引入自我反思机制。现有的自我反思方法要么在全文基础上进行修订，要么通过昂贵的训练来学习自我纠正，这两种方法都存在根本上的反应性和低效性。
### Innovation
我们提出了在测试时间进行自我反思生成（SRGen），这是一种轻量级的测试时间框架，用于在不确定的点生成内容前进行自我反思。SRGen 在生成过程中利用动态熵阈值来识别高不确定性标记，并为每个识别出的标记训练特定的纠正向量，利用已生成的大语境来进行自我反思生成以纠正标记概率分布。通过对部分输出进行回顾性分析，这种自我反思能够更可靠地做出决策，从而显著降低高不确定性点的错误概率。
### Conclusion
在挑战性的数学推理基准测试和其他一组不同的LLMs上进行了评估，SRGen 可以一致地增强模型的推理能力：单次质量的改进也转化为更强的自我一致性投票。特别是在 AIME2024 与 DeepSeek-R1-Distill-Qwen-7B 上，SRGen 在 Pass@1 和 Cons@5 上分别取得了绝对改进 +12.0% 和 +13.3%。我们的研究还表明，SRGen 可以作为一种即插即用的方法，融入生成过程以实现可靠的LLM推理，一致性地获得一致的收益，并与训练时间和测试时间的其他技术（例如 RLHF 和 SLOT）具有广泛的组合性。
## 314. `cs.CL` - 评估大型语言模型在IUCN红色名录物种信息中的应用 [PDF](https://arxiv.org/pdf/2510.02830), [HTML](https://arxiv.org/abs/2510.02830)
### Authors
Shinya Uryu
### Background
大型语言模型（LLMs）在保护生物学领域被迅速采纳，以应对生物多样性危机，但其在物种评估中的可靠性尚未确定。这项研究系统地验证了五个领先模型在21,955个物种上的表现，涵盖四类核心的IUCN红色名录评估要素：分类学、保护状况、分布和威胁。研究揭示了一个关键的悖论：模型在分类学分类方面表现出色（94.9%），但在保护推理方面却一直失败（状态评估仅为27.2%），这一知识推理差距在所有模型中都是普遍存在的，表明存在内在的架构限制，而不仅仅是数据限制。此外，模型在处理上呈现系统性偏差，倾向于偏好有吸引力的脊椎动物，这可能放大了现有的保护不平等性。这些发现界定了使用LLMs的清晰边界：它们可以作为信息检索的强大工具，但在基于判断的决策方面则需要人类监督。建议采取混合方法，使LLMs增强专家能力，而人类专家则保留对风险评估和政策制定的独家权威。
### Innovation
研究通过系统验证五个领先的大型语言模型在21,955个物种上的表现，针对四类核心的IUCN红色名录评估要素进行了评估，揭示了模型在分类学分类与保护推理之间的知识推理差距，表明存在架构限制而非数据限制，并指出模型存在的系统性偏差可能进一步放大保护不平等性。这提供了一个全面的视角来指导大型语言模型在保护生物学领域的负责任使用。
### Conclusion
大型语言模型在信息检索方面是非常强大的工具，但它们需要人类监督来进行基于判断的决策。建议采取混合方法，让大型语言模型增强专家能力，同时保留人类专家对风险评估和政策制定的独家权威。
## 315. `cs.CL` - 不留任何痕迹：通过水印技术在大规模语言模型中实现版权数据集使用的黑箱检测 [PDF](https://arxiv.org/pdf/2510.02962), [HTML](https://arxiv.org/abs/2510.02962)
### Authors
Jingqi Zhang,Ruibo Chen,Yingqing Yang,Peihua Mai,Heng Huang,Yan Pang
### Background
近年来，大语言模型（LLMs）越来越多地通过较小的、领域特定的数据集进行微调，以提升下游任务的性能。这些数据集通常包含版权信息，因此需要有效的保护措施防止未授权使用。现有的成员推理攻击（MIAs）和数据集推断方法通常需要内部信号（如logits），而当前的黑箱方法则依赖于手工制作的提示或干净的参考数据集进行校准，这两种方法都限制了其实用性。水印技术是很有前景的替代方案，但此前的技术可能会降低文本质量或减少任务性能。本文提出了一种名为TRACE的实用框架，用于完全黑箱检测LLO在微调过程中使用了版权数据集。
### Innovation
本文提出了一种名为TRACE的框架，目的是实现版权数据集使用的黑箱检测。该框架通过使用受私钥引导的无失真水印来重写数据集，以确保文本质量和下游任务的实用性。在检测阶段，利用微调对水印数据的放射性效应，并引入一种熵门限协议，选择性地得高不确定性的标记，显著增强检测能力。实验结果表明，该方法在多种数据集和模型家族中可以取得显著的检测效果，并且在继续进行大量非水印数据的预训练后依然稳健。
### Conclusion
本文研究表明TRACE作为一种实用方法，可以实现对版权数据集使用的可靠黑箱验证。该方法已建立成为版权数据集微调过程中的一种宝贵工具。我们将在该网址发放相关代码：this https URL。
## 316. `cs.CL` - XTRA: 使用主题与表示对齐的跨语言主题建模 [PDF](https://arxiv.org/pdf/2510.02788), [HTML](https://arxiv.org/abs/2510.02788)
### Authors
Tien Phat Nguyen,Vu Minh Ngo,Tung Nguyen,Linh Van Ngo,Duc Anh Nguyen,Sang Dinh,Trung Le
### Background
跨语言主题建模旨在揭示不同语言间的共享语义主题。虽然已经提出了一些方法，利用传统和神经技术来解决这一问题，但前人方法在主题多样性的提高方面取得了一定进步，但在主题连贯性和多语言一致性方面往往表现不佳。
### Innovation
提出了一种新颖的框架XTRA（使用主题与表示对齐的跨语言主题建模），该框架将Bag-of-Words建模与多语言嵌入法统一。XTRA引入了两类核心组件：（1）表示对齐，通过共享语义空间中的对比学习对齐文档-主题分布；（2）主题对齐，将主题-词分布投影到相同空间以确保跨语言一致性。这种双重机制使得XTRA能够学习语义连贯、多样且跨语言一致的主题。
### Conclusion
在多语言语料库上的实验表明，XTRA在主题连贯性、多样性和对齐质量方面显著优于强基线。相关代码和可复现的脚本可在https://github.com/tienphat140205/XTRA上获得。
## 317. `cs.CL` - 基于社交媒体的可解释文本人格评估的计算框架 [PDF](https://arxiv.org/pdf/2510.02811), [HTML](https://arxiv.org/abs/2510.02811)
### Authors
Matej Gjurković
### Background
人格指个体在行为、思考和感受方面的差异。随着数字足迹，尤其是来自社交媒体的足迹变得越来越普遍，自动化的人格评估方法变得日益重要。自然语言处理（NLP）使得对未结构化文本数据进行分析，以识别人格指标成为可能。然而，两个主要挑战依然存在：大型人格标记数据集的稀缺性和人格心理学与NLP之间的脱节，这限制了模型的有效性和可解释性。虽然有部分数据集，但它们在数据规模、质量和标签覆盖方面存在局限性。因此，需要新的解决方案来应对这些挑战，以提高模型的有效性和可解释性，并满足不同的研究和应用需求。
### Innovation
本文提出了一种名为SIMPA（Statement-to-Item Matching Personality Assessment）的计算框架，该框架通过将用户生成的陈述与经过验证的问卷项目进行匹配，提供了可解释的人格评估。SIMPA通过使用机器学习和语义相似性技术，实现了与人类评估相当的人格评估结果，且保持了高可解释性和效率。为了应对集身高、年龄段、职位和种族等敏感信息，数据集MBTI9k和PANDORA被收集，涵盖来自Reddit的超过10,000名用户的1700万个帖子，解决了数据规模、质量和标签覆盖方面的局限。进一步的实验表明，人口统计变量对于模型的有效性产生了影响。这款框架不仅适用于人格评估，还适用于复杂的标签分类和变量示证案例与目标概念之间的关联多种研究和实际应用中。
### Conclusion
通过提供一种新的计算框架——SIMPA，本研究显著增强了对文本人格评估的理解能力，通过使用机器学习和语义相似性技术，实现了与人类评估相当的人格评估结果，同时保持了高可解释性和效率。此外，通过收集MBTI9k和PANDORA数据集，解决了人口统计信息和标签覆盖方面的问题。SIMPA的模型无意识设计、多层线索检测机制及可扩展性使其适用于各种涉及复杂标签分类和变量示证案例与目标概念之间关联的研究和实际应用。
## 318. `cs.CL` - 在对话数据堆中寻找钻石：会话数据检索基准 [PDF](https://arxiv.org/pdf/2510.02938), [HTML](https://arxiv.org/abs/2510.02938)
### Authors
Yohan Lee,Yongwoo Song,Sangyeop Kim
### Background
本文提出了会话数据检索（CDR）基准，这是首个用于评估能够为产品洞察提供对话数据的系统的一整套测试集。包含1600个查询和9100个对话，共有五个分析任务，该基准提供了一个可靠的测量会话数据检索性能的标准。评估发现即使是最好的模型也只能达到NDCG@10约为0.51的效果，这揭示了文档与会话数据检索能力之间的巨大差距。这项工作识别了会话数据检索中的独特挑战（隐含状态识别、回合动态、上下文引用），并提供了实用的查询模板和详尽的错误分析，涵盖了不同任务类别。该基准数据集和代码可在该网址获取：this https URL.
### Innovation
本文提出了首个会话数据检索基准，包含1600个查询和9100个对话，涵盖了五个分析任务；发现了会话数据检索中的独特挑战，如隐含状态识别、回合动态和上下文引用，提供了实用的查询模板和详细的错误分析，揭示了文档与会话数据检索能力之间的差距。通过评估16种流行嵌入模型，证明了现有模型的局限性，展示了未来研究方向的重要依据。
### Conclusion
本文通过提出首个全面的会话数据检索基准，展示了现有模型在会话数据检索中的不足，识别了独特挑战，提供了实用的查询模板和详尽的错误分析。未来的研究需要专注于解决这些挑战以提高系统的性能。
## 319. `cs.CL` - 超越最终层：为大型语言模型更好实现多语言校准的中间表示 [PDF](https://arxiv.org/pdf/2510.03136), [HTML](https://arxiv.org/abs/2510.03136)
### Authors
Ej Zhou,Caiqi Zhang,Tiancheng Hu,Chengzu Li,Nigel Collier,Ivan Vulić,Anna Korhonen
### Background
大规模语言模型（LLMs）的可信部署依赖于其预测置信度与其实际准确度的一致性，即置信度校准，但这一关键属性在多语言环境中仍鲜有研究。此研究首次对六类模型在100多种语言上的多语言校准进行全面系统的分析，揭示出非英语语言普遍存在校准问题。
### Innovation
该研究首次大规模研究多语言校准问题，发现多语言模型的最顶层偏向于英语训练，无法提供可靠的多语言置信度信号。研究团队通过逐层分析，发现较晚的中间层能更可靠地提供多语言置信度信号，并据此提出了语言感知的置信度集成方法（LACE），能够自适应地为每种特定语言选择最佳的层集成。
### Conclusion
研究揭示了英语中心化的对齐成本，提出了一种新的路径，通过关注多语言模型的中间层，以建设更具全球公平性和可信赖性的LLMs。
## 320. `cs.CL` - 自我演化的大型语言模型之路：通过内在反馈实现数据高效学习 [PDF](https://arxiv.org/pdf/2510.02752), [HTML](https://arxiv.org/abs/2510.02752)
### Authors
Hangfan Zhang,Siyuan Xu,Zhimeng Guo,Huaisheng Zhu,Shicheng Liu,Xinrun Wang,Qiaosheng Zhang,Yang Chen,Peng Ye,Lei Bai,Shuyue Hu
### Background
强化学习（RL）在提升大语言模型（LLMs）的推理能力方面展现出潜力，但通常需要大量努力进行数据创建和标注。本文通过最少的数据量提升LLMs性能，探索基于RL的改进方法。
### Innovation
引入两种基于自意识的全新机制：(1)自我意识难度预测，模型学习评估任务难度并优先处理具有挑战性但仍可解决的任务；(2)自我意识极限突破，模型识别超出自身能力的任务，并主动请求外部数据来突破这一限制。
### Conclusion
在九个基准测试上的实验显示，相对于现有方法提升了53.8%，仅需1.2%的额外数据，证明了自意识RL的有效性，并强调自我演化代理训练的前景。
## 321. `cs.CL` - 通过LLMs和NER在放射报告中的语义相似性 [PDF](https://arxiv.org/pdf/2510.03102), [HTML](https://arxiv.org/abs/2510.03102)
### Authors
Beth Pearson,Ahmed Adnan,Zahraa Abdallah
### Background
放射报告评估是放射科医师训练中的关键部分，有助于确保诊断准确性。放射科医师通常会准备初步报告，由资深放射科医师审核和编辑最终报告。识别初步报告和最终报告之间的语义差异对年轻医生既是培训工具，也能发现临床知识的缺口。虽然在放射学领域中，人工智能的使用正迅速扩大，但由于需要特定的专业领域知识，大规模语言模型（LLMs）的应用仍然具有挑战性。本文探讨了LLMs在放射学领域提供可解释且准确的报告比较能力。尽管进行了比较分析，但传统的基于命名实体识别（NER）的方法也有局限性。为了解决这一问题，我们提出了一种新的方法——Llama-EntScore，它结合了LLama 3.1和NER，并通过可调权重强调或不强调特定类型的差异，从而生成定量的相似性评分，以便跟踪进步并提供有关审查和细化报告的解释性指导。该方法在准确性和精度方面优于单独使用的LLM和NER。
### Innovation
本文提出了一种新的方法Llama-EntScore，结合使用LLama 3.1和命名实体识别（NER），通过可调权重来强调或忽略特定类型的差异，从而生成定量的相似性评分。这种方法能够提供准确且可解释的报告比较，优于单独使用大规模语言模型或命名实体识别的方法。作者还评估了其他几种LLM的方法，以及一个传统的方法——基于NER。我们的工作填补了领域知识和人工智能模型之间的知识差距，为放射科医生提供了有价值的指导。这种方法的有效性在比较准确性和精度方面得到了验证。
### Conclusion
我们提出的Llama-EntScore方法能够准确识别和解释放射报告中的语义差异，其准确率为67%且在±1误差内的准确率为93%，远超独立使用的LLM和NER。这种方法不仅提高了报告的准确性和透明度，还为放射学报告的审查提供了重要的指导，有助于提升放射科医生的培训效果。
## 322. `cs.CL` - 听力还是阅读？评估链式思维在语音转文本中的语音意识 [PDF](https://arxiv.org/pdf/2510.03115), [HTML](https://arxiv.org/abs/2510.03115)
### Authors
Jacobo Romero-Díaz,Gerard I. Gállego,Oriol Pareras,Federico Costa,Javier Hernando,Cristina España-Bonet
### Background
现有的语音到文本翻译（S2TT）系统通常由自动语音识别（ASR）模块和文本到文本翻译（T2TT）模块构建，这些系统面临两个主要限制：错误传播和无法利用语调或其他声学线索。最近引入了一种称为链式思维（CoT）的提示方法，期望通过同时访问语音和转录来克服这些问题，但现有研究尚未充分验证其效果。
### Innovation
本文通过使用归因方法分析链式思维，进行包含损坏转录的鲁棒性评估，并考虑语音语调，发现链式思维主要依赖于转录而很少利用语音，这表明简单的训练干预措施（如加入直接S2TT数据或注入噪声转录）可以提高其鲁棒性和增加语音的归因度。这些发现挑战了链式思维的假设优势，强调了需要将声学信息明确整合到翻译架构中的必要性。
### Conclusion
本文研究结果表明链式思维系统在语音意识方面表现不佳，需要新的架构来整合声学信息。简单的训练干预措施有效提升了系统的鲁棒性和语音归因度，同时这些发现质疑了链式思维的优越性。
## 323. `cs.CL` - 语言模型的神经相关性仅与人类语言相关 [PDF](https://arxiv.org/pdf/2510.03156), [HTML](https://arxiv.org/abs/2510.03156)
### Authors
Iñigo Parra
### Background
先前的研究表明，大型语言模型中隐藏状态与功能性磁共振成像(fMRI)大脑反应在语言任务上存在相关性，并被视作大脑状态与这些模型表示相似性的证据。这项研究旨在检验这些以前的结果是否在面对多个潜在问题时仍然稳健：例如，这些结果是否会因减少维度或使用新的相似性度量而失效；模型所受的训练是否仅限于人类语言；以及这些结果是否依赖于模型中的位置编码机制。
### Innovation
研究强调了新的发现：即使在进行降维分析、使用新的相似性度量和仅用训练于人类语言的模型时，先前的结果仍然存在。此外，还证明了这些相关性仅存在于受过人类语言训练的模型中，依赖于位置编码的存在与否也有影响。这些发现支持和强化了先前的研究成果，并有助于关于这些先进大型语言模型的生物可实现性和解释性辩论。
### Conclusion
这些研究结果证实并加强了先前的研究成果，表明大型语言模型中存在与人类语言相关的神经相关性，这些相关性并不是因维度高而导致的错误发现，并且依赖于位置编码存在与否。这为如何理解大型语言模型的表示增加了新的视角，有助于评估其生物尺度上的可行性。
## 324. `cs.CL` - 在临床证据中扎根大型语言模型：查询英国NICE临床指南的检索增强生成系统 [PDF](https://arxiv.org/pdf/2510.02967), [HTML](https://arxiv.org/abs/2510.02967)
### Authors
Matthew Lewis,Samuel Thio,Richard JB Dobson,Spiros Denaxas
### Background
本研究提出了一种基于大型语言模型（LLMs）的检索增强生成（RAG）系统，用于查询英国国家卫生与护理卓越研究所（NICE）的临床指南。这些指南因其庞大的体积和长度而在时间受限的医疗系统中使用起来具有挑战性。
### Innovation
该研究开发并评估了一个RAG系统，该系统利用混合嵌入机制提高了检索能力。RAG系统在处理大量医疗指南时展现出高效率，能够通过自然语言查询为用户提供精准的信息。在对7901个查询进行评估时，RAG系统的平均互换秩（MRR）达到0.814，第一个片段的召回率为81%，前十片段的召回率高达99.1%。增强后的RAG模型在真实问题-答案数据集上的表现显著优于专注于医疗领域的Meditron3-8B模型，精准度提高了64.7个百分点至99.5%，并实现了完美的上下文精确度（1），确保了答案基于相关来源材料，大幅提高了生成质量，有效地防止了信息伪造。
### Conclusion
本研究证明，RAG是一种有效、可靠、可扩展的方法，可以将生成型人工智能应用于医疗场景，提供成本效益高的访问医指南途径，实现在有限时间内快速准确地查询和生成可靠医疗信息的系统性创新。
## 325. `cs.CL` - 语音情感识别中语义区分：描述性和表达性言语角色的洞察 [PDF](https://arxiv.org/pdf/2510.03060), [HTML](https://arxiv.org/abs/2510.03060)
### Authors
Rongchen Guo,Vincent Francoeur,Isar Nejadgholi,Sylvain Gagnon,Miodrag Bolic
### Background
语音情感识别（SER）对于提升人机交互至关重要，但其准确性受限于语音中情感细微差别的复杂性。在本研究中，我们将语音中的描述性语义定义为表示言语上下文内容的部分，而将表达性语义定义为反映演讲者情感状态的部分。通过观看情感较为强烈的电影片段，记录参与者描述其体验的语音片段，包括每个片段预期的情感标签、参与者自我评估的情感反应以及愉悦度/唤醒度评分，实验显示描述性语义与预期情感相吻合，而表达性语义与引发的情感相关。这项研究为SER在人机交互中的应用提供了见解，为更懂情境的人工智能系统铺平了道路
### Innovation
研究区别了描述性语义和表达性语义在语音情感识别中的作用，并通过实际体验研究验证了这两种语义在识别情感中的不同贡献。这种方法为提高EMR（情感语音识别）的准确性提供了一种新的视角，并为构建更深层次理解人类情感的AI技术奠定了基础
### Conclusion
研究结果表明语音中的描述性语义与期望的情感一致，而表达性语义则反映了实际引起的情感反应。这种区分对于优化使用语音数据的人机交互系统的功能具有重要意义，并为未来开发更智能、更理解上下文的AI系统提供了方向。
## 326. `cs.CL` - SurveyBench: 评估大模型能否写出高质量的学术综述 [PDF](https://arxiv.org/pdf/2510.03120), [HTML](https://arxiv.org/abs/2510.03120)
### Authors
Zhaojun Sun,Xuzhou Zhu,Xuanhe Zhou,Xin Tong,Shuo Wang,Jie Fu,Guoliang Li,Zhiyuan Liu,Fan Wu
### Background
撰写学术综述涉及大量文献的精炼和综合，是一个劳动密集型且需要高智力的任务。尽管近年来出现了通用的DeepResearch代理和专门用于综述的方法（LLM4Survey），可以自动创建综述，但其输出往往达不到人类的标准。目前缺乏一个严格且符合读者需求的基准来全面揭示这些方法的不足之处。
### Innovation
提出了一个细致的、以测试题为导向的评估框架——SurveyBench，包含：1）基于11,343篇arXiv论文和相应4,947篇高质量综述的典型综述主题；2）一个多层面的评估元等级，评估大纲质量（如覆盖面广度、逻辑连贯性）、内容质量（如综合细度、见解清晰度）和非文本丰富度；3）一种双重评估协议，包括基于内容和基于测试题的答案评估，明确与读者的信息需求对齐。实验结果表明，SurveyBench成功地挑战了现有的LLM4Survey方法（如在内容评估中平均低于人类21%）。
### Conclusion
SurveyBench有效地评估了现有的大模型在编写学术综述方面的表现，揭示了它们之间的差距。
## 327. `cs.CL` - EditLens：量化文本中AI编辑的程度 [PDF](https://arxiv.org/pdf/2510.03154), [HTML](https://arxiv.org/abs/2510.03154)
### Authors
Katherine Thai,Bradley Emi,Elyas Masrour,Mohit Iyyer
### Background
相当一部分向大型语言模型提出的问题是让用户提供的文本进行编辑，而不是从头生成新的文本。尽管以前的工作主要集中在检测完全由AI生成的文本上，但这项研究证明了AI编辑过的文本是可与人类写作和AI生成的文本区分开来的。这项研究表明，不仅AI编辑文本可以被检测到，而且AI对人类写作所做的修改程度也可以被检测到，这对作者鉴定、教育和政策制定具有重要意义。
### Innovation
研究提出了使用轻量级相似性度量来量化给定原始人撰写文本背景下文本中的AI编辑程度。通过将这些相似性度量用作中间监督，训练了一个回归模型——EditLens，该模型能够预测文本中AI编辑的含量。该模型在二分类（F1=94.7%）和三分类（F1=90.4%）任务中，实现了区分人类、AI和混合写作的最新技术水平。此外，研究使用模型分析了Grammarly（一个流行的写作辅助工具）应用的AI编辑效果，展示了AI编辑文本及其程度可以被检测到，这具有重要的研究价值。
### Conclusion
研究不仅证明了AI编辑文本可以被检测到，还表明了AI对人类写作所做的修改程度也可以被检测到。此外，作为案例研究，研究使用模型分析了Grammarly应用的AI编辑效果，这为未来的研究提供了动力，并承诺公开发布模型和数据集。
## 328. `cs.CL` - 基于模型的零样本跨语言迁移源语言排名 [PDF](https://arxiv.org/pdf/2510.03202), [HTML](https://arxiv.org/abs/2510.03202)
### Authors
Abteen Ebrahimi,Adam Wiemerslage,Katharina von der Wense
### Background
该论文背景在于跨语言迁移任务中，已有的方法通常依赖预训练的多语言模型和标有源语言数据，但当目标语言数据不可用时，前期方法可能会退化到使用语言级别的特征。研究者通过利用未标目标语言数据和隐藏表示，提出了一种新的算法NN-Rank，用以提高零样本跨语言迁移的效果。
### Innovation
该论文创新点在于提出了一个名为NN-Rank的算法，该算法利用多语言模型的隐藏表示和未标注的目标语言数据进行源语言排名。实验表明，当使用领域内数据时，NN-Rank 在部分任务（如词性标注、命名实体识别）上比利用词汇和语言特征的语言模型基线更好，且在目标语言数据不可用时，通过只使用《圣经》这一领域外语料库依然保持竞争力。
### Conclusion
研究发现，尽管未使用大量目标语言数据，仅利用25个未标例子数据，NN-Rank 即可生成高质量的排名，实现NDCG值达到全部可用目标数据排名的92.8%。研究结果表明，NN-Rank 在源语言排名上具有一定优越性，尤其在目标语言数据不足时仍能保持较高性能。
## 329. `cs.CL` - Cache-to-Cache: 直接的大型语言模型间语义通信 [PDF](https://arxiv.org/pdf/2510.03215), [HTML](https://arxiv.org/abs/2510.03215)
### Authors
Tianyu Fu,Zihan Min,Hanling Zhang,Jichao Yan,Guohao Dai,Wanli Ouyang,Yu Wang
### Background
现有的多LLM系统通过文本进行通信，这导致了语义信息的损失和逐个token生成的延迟。这种局限性限制了多LLM系统的性能和效率提升。
### Innovation
提出了一种名为C2C的新范式，通过神经网络直接融合源模型和目标模型的KV-Cache，以实现直接的语义传输。C2C避免了中间文本生成，能利用两模型的深层次、专业化的语义信息，从而提高响应质量，并降低延迟。
### Conclusion
实验结果显示，C2C相比单一模型提高了8.5-10.5%的平均准确率，并比文本通信范式提高了约3.0-5.0%的性能，同时将平均延迟降低了2.0倍。
## 330. `cs.CL` - 聚焦代理：简单而有效的Web代理大型上下文修剪方法 [PDF](https://arxiv.org/pdf/2510.03204), [HTML](https://arxiv.org/abs/2510.03204)
### Authors
Imene Kerboua,Sahar Omidi Shayegan,Megh Thakkar,Xing Han Lù,Léo Boisvert,Massimo Caccia,Jérémy Espinas,Alexandre Aussem,Véronique Eglin,Alexandre Lacoste
### Background
网络代理在处理用户目标时需要处理长网页，网页通常包含超过数万词的内容。这会饱和上下文限制并增加计算成本。处理整个页面还会使网络代理面临安全风险，如提示注入。现有的修剪策略要么丢弃相关内容，要么保留不相关的上下文，导致行动预测不理想。
### Innovation
引入了FocusAgent，这是一个简单且有效的方法，利用轻量级的LLM检索器从无障碍树（AxTree）观察中提取最相关的内容，并由任务目标引导。通过修剪噪声和不相关的内容，FocusAgent能够提高推理效率的同时降低对注入攻击的易感性。在WorkArena和WebArena基准测试中，FocusAgent的表现与强大的基线相当，但将观察尺寸减少了超过50%。此外，FocusAgent的变体显着降低了提示注入攻击的成功率，包括横幅和弹出攻击，同时在无攻击环境下保持了任务成功率。
### Conclusion
我们的结果表明，有针对性的基于LLM的检索是一种实用且稳健的策略，能够构建高效、有效且安全的网络代理。
## 331. `cs.CL` - 专题建模作为长段生成：大规模语言模型能否通过零样本提示重振NTM？ [PDF](https://arxiv.org/pdf/2510.03174), [HTML](https://arxiv.org/abs/2510.03174)
### Authors
Xuan Xu,Haolun Li,Zhongliang Yang,Beilin Chu,Jia Song,Moxuan Xu,Linna Zhou
### Background
传统的主题模型如神经主题模型依赖于推断和生成网络来学习潜在的主题分布。本文探讨了在大规模语言模型时代，将TM作为长段生成任务的新范式，并更新其定义。在此之前，同时研究人员对NTMs（神经主题模型）的有效性提出了质疑，认为许多NTMs已经过时。
### Innovation
本文提出了一种简单但实用的方法，利用大规模语言模型直接实现基于LLM的主题建模任务（从数据子集中采样，使用提示生成主题和代表性文本，基于关键词匹配进行文本分配）。并研究了这种长段生成范式是否能超越神经主题模型（NTMs，通过零样本提示）
### Conclusion
我们对NTMs和LLMs在主题质量方面进行了系统的比较，并实证检验了“大多数NTMs已过时”这一主张。
## 332. `cs.CL` - WEE-Therapy: 弱编码器混合框架的心理咨询对话分析 [PDF](https://arxiv.org/pdf/2510.02320), [HTML](https://arxiv.org/abs/2510.02320)
### Authors
Yongqi Kang,Yong Zhao
### Background
计算心理学的进步需要能够深入理解咨询对话的AI工具。现有的基于音频的语言模型（AudioLLMs）通常依赖于通用数据预训练的单个语音编码器，难以捕捉到如复杂情感和专业技巧等领域的特定特征。
### Innovation
提出WEE-Therapy，这是一种多任务AudioLLM，包含弱编码器集合（WEE）机制。它补充了一个强大的基础编码器，并通过一个轻量级、专门化的编码器池。采用了一种新的双路由策略，结合了稳定的数据无关型领域知识和动态的数据相关型专家选择。
### Conclusion
WEE-Therapy在情感识别、技术分类、风险检测和总结等任务中，实现了显著的性能提升，同时参数开销较小，展示了在AI辅助临床分析中的强大潜力。
## 333. `cs.CL` - CATMark：一种针对大规模语言模型跨任务鲁棒加水印的上下文感知阈值框架 [PDF](https://arxiv.org/pdf/2510.02342), [HTML](https://arxiv.org/abs/2510.02342)
### Authors
Yu Zhang,Shuliang Liu,Xu Yang,Xuming Hu
### Background
现有的水印算法能够识别机器生成的内容，但会在某些情况下降低文本质量，尤其是低熵场景下。现有方法依赖于熵阈值，需要大量计算资源进行调优，并且在未知或跨任务生成场景下表现不佳。
### Innovation
提出了一种新颖的框架——$textbf{C}$ontext-textbf{A}ware textbf{T}hreshold watermarking ($textbf{textmyalgo}$)，可以在实时语义上下文中动态调整水印强度。该方法通过logits聚类将文本生成区分为语义状态，建立上下文感知的熵阈值，既保留了结构内容的保真度，又嵌入了鲁棒的水印。无需预定义阈值或任务特定调优。
### Conclusion
实验表明，$textbf{textmyalgo}$在跨任务中提高了文本质量，同时保持了检测准确性。
## 334. `cs.CL` - SpeechCT-CLIP: 通过文本-图像知识蒸馏将知识传授给语音以实现语音驱动的CT图像多模态分析 [PDF](https://arxiv.org/pdf/2510.02322), [HTML](https://arxiv.org/abs/2510.02322)
### Authors
Lukas Buess,Jan Geier,David Bani-Harouni,Chantal Pellegrini,Matthias Keicher,Paula Andrea Perez-Toro,Nassir Navab,Andreas Maier,Tomas Arias-Vergara
### Background
在临床工作流程中，口头交流起着核心作用。例如，在放射学中，绝大多数报告都是通过口述来完成的。然而，近乎所有医学人工智能系统仅依赖于书面文本。本文作者针对此问题，探索了直接从口述放射学报告中学习视听语言表示的可能性。
### Innovation
本文合成了一个大规模数据集（Speech-RATE），并训练了一个名为SpeechCT-CLIP的对比模型，该模型能够在共享表示空间中对齐语音和3D CT体积。通过从预训练的文本-图像CLIP模型获取的知识蒸馏，证明了可以将文本中的语义对齐能力转移到语音中，显著缩小了性能差距。
### Conclusion
实验表明，零样本分类F1得分从0.623提高到0.705，并且在不需要文本的情况下达到了强大的检索结果。这些发现突出了语音作为多模态预训练的实用替代品，为临床实践中的语音驱动诊断支持工具打开了大门。
## 335. `cs.CL` - 奖励模型披着马甲是评估指标 [PDF](https://arxiv.org/pdf/2510.03231), [HTML](https://arxiv.org/abs/2510.03231)
### Authors
Sebastian Gehrmann
### Background
后训练大型语言模型中兴起到强化学习的作用，激发了对奖励模型的兴趣。奖励模型评估模型输出的质量以生成训练信号。这种任务也由监控AI模型性能的评估指标完成。然而，这两个研究领域往往是独立的，这导致了术语冗余和重复的问题。常见的挑战包括易受虚假相关性的影响、对下游奖励作弊的影响、提高数据质量的方法以及元评估方法。
### Innovation
本文提出了奖励模型和评估指标之间的紧密合作可以解决这些问题的观点，并展示了在特定任务上，评估指标的表现优于奖励模型。此外，文章还提供了两个领域的全面调查，并指出了多个研究主题，这些主题可以提高奖励模型和评估指标在偏好获取方法、避免虚假相关性和奖励作弊以及校准感知元评估方面的表现。
### Conclusion
通过开展更紧密的合作，奖励模型和评估指标的研究可以解决上述问题，提升各自领域的性能。
## 336. `cs.CL` - 重新审视使用语音LLM的直接语音转文本翻译：相对于CoT提示有更好的缩放效果？ [PDF](https://arxiv.org/pdf/2510.03093), [HTML](https://arxiv.org/abs/2510.03093)
### Authors
Oriol Pareras,Gerard I. Gállego,Federico Costa,Cristina España-Bonet,Javier Hernando
### Background
近年来，语音转文本翻译（S2TT）研究主要集中在基于LLM的模型上，并引入了逐渐被采纳的Chain-of-Thought（CoT）提示方式，即先让模型进行语音识别再进行翻译。CoT提示方式通常优于直接提示，因为它能够利用大量的自动语音识别（ASR）和文本转文本翻译（T2TT）数据集进行步骤的明确建模。
### Innovation
本文旨在系统地比较CoT提示和直接提示在不同数据量下的表现。为此，作者使用六种欧洲语言的伪标签对ASR语料库进行翻译，并对基于LLM的S2TT系统采用两种不同的提示策略，分别在不同的数据规模下进行训练。
### Conclusion
直接提示随着数据量的增加改善更为一致，表明随着更大规模的S2TT资源创建，直接提示可能成为更有效的做法。
## 337. `cs.CL` - 量化对抗偏移以检测AI生成的文本：建模攻击 [PDF](https://arxiv.org/pdf/2510.02319), [HTML](https://arxiv.org/abs/2510.02319)
### Authors
Lekkala Sai Teja,Annepaka Yadagiri,Sangam Sai Anish,Siva Gopala Krishna Nuthakki,Partha Pakray
### Background
高度先进的大型语言模型（LLMs）的发展带来了双用途问题，迫切需要建立可靠的AI生成文本检测系统。现有检测器极易受到对抗攻击的影响，其中重写特别有效，能够绕过统计检测。本文研究了对抗鲁棒性，首先量化了标准对抗训练的局限性，然后提出了一种新的、显著更坚韧的检测框架：扰动不变特征工程（PIFE），该框架通过多阶段标准化管道将输入文本标准化，然后利用Levenshtein距离和语义相似度等度量标准化的程度，直接输入分类器。实验结果表明，传统的对抗训练虽然对句法噪声具有鲁棒性，但在语义攻击面前失败，称为“语义规避阈值”，其在严格1%假阳性率下的真正阳性率（TPR）降至48.8%。相比之下，我们的PIFE模型能够克服这一限制，在相同条件下保持了82.6%的高TPR，有效抵消最复杂的语义攻击。
### Innovation
本文提出了一个全新的抗扰动特征工程（PIFE）框架，通过标准化处理输入文本，利用Levenshtein距离和语义相似度等度量转换的规模，增强检测能力，并在对抗性攻击下的鲁棒性方面取得了显著进步。在实验中，PIFE模型能够在传统对抗训练失败的情况下，仍保持较高的真正阳性率。
### Conclusion
结果显示，明确建模扰动伪影而不是仅依靠对抗训练，是实现真正鲁棒性的更有希望的途径。
## 338. `cs.CL` - SIMSplat：带有语言对齐4D高斯点云预测性驾驶场景编辑 [PDF](https://arxiv.org/pdf/2510.02469), [HTML](https://arxiv.org/abs/2510.02469)
### Authors
Sung-Yeon Park,Adam Lee,Juanwu Lu,Can Cui,Luyang Jiang,Rohit Gupta,Kyungtae Han,Ahmadreza Moradipari,Ziran Wang
### Background
随着传感器数据驱动场景操作成为传统虚拟驾驶模拟器的一种有前景的替代方案，现有的框架在生成高效且逼真的场景方面面临挑战，主要原因在于有限的编辑能力。为了应对这些挑战，提出了SIMSplat，一种具备语言对齐的高斯点云预测性驾驶场景编辑器。随着语言对齐和高斯复原场景的集成，进一步支持了对道路对象的直接查询，使得编辑更加精确和灵活。该方法提供了详细的对象级编辑能力，包括添加新对象、修改车辆和行人的轨迹，并通过多智能体运动预测进行预测路径细化，以生成场景中所有智能体之间的逼真交互。实验结果证实了SIMSplat的强大编辑能力和对各种场景的高度适用性。
### Innovation
SIMSplat 提出了一个语言控制的编辑器，结合了语言对齐和高斯点云复原技术来实现直观的场景编辑。通过多智能体运动预测进行预测路径细化，使其能够生成逼真的交互场景，提升了编辑的灵活性和精确度。
### Conclusion
在 Waymo 数据集上的实验展示了 SIMSplat 的广泛编辑能力和适应不同场景的能力。SIMSplat 提供了从添加新对象到修改车辆和行人的轨迹的具体编辑功能，使得通过语言指令进行快捷和灵活的场景编辑成为可能。
## 339. `cs.CL` - Self-Anchor：通过逐步注意力对齐解决大型语言模型推理 [PDF](https://arxiv.org/pdf/2510.03223), [HTML](https://arxiv.org/abs/2510.03223)
### Authors
Hongxiang Zhang,Yuan Tian,Tianyi Zhang
### Background
对于大型语言模型（LLMs）而言，解决复杂推理任务的方法多为微调或强化学习等复杂过程。然而，随着推理链条的延长，关键的中间步骤会被埋没在上下文之中，受到较少的关注，从而导致错误。现有基于提示的方法在处理复杂推理任务时表现不佳，这个问题在长链推理中尤为突出。
### Innovation
本文提出了一种名为Self-Anchor的新管道，该管道通过利用推理的内在结构来引导模型的关注点。Self-Anchor方法将推理路径分解为结构化的计划，并自动将模型的关注点集中在最具相关性的推理步骤上，从而使模型在整个生成过程中保持聚焦。实验结果显示，Self-Anchor在六个基准测试中优于最先进的提示方法。此外，Self-Anchor显著减少了'非推理'模型与专门推理模型之间的性能差距，表明大多数LLM无需重新训练即可解决复杂推理任务。
### Conclusion
Self-Anchor方法有助于使大多数大型语言模型能够解决复杂的推理任务，无需重新训练，并且相较于传统的提示方法表现出更好的性能。
## 340. `cs.CL` - 从演示中恢复密集奖励：超越模仿 [PDF](https://arxiv.org/pdf/2510.02493), [HTML](https://arxiv.org/abs/2510.02493)
### Authors
Jiangnan Li,Thuy-Trang Vu,Ehsan Abbasnejad,Gholamreza Haffari
### Background
传统上，监督微调（SFT）被视为一种简单的模仿学习过程，仅训练策略来模仿专家在演示数据集上的行为。本文挑战了这一观点，通过建立SFT和逆强化学习（IRL）之间的基本等价性，证明了SFT目标是逆Q学习的一个特例。这表明SFT过程不仅学习策略，还学习一个隐式的、密集的、逐token级别的奖励模型，以解释专家演示。
### Innovation
本文通过引入一种基于基线的奖励函数，直接从SFT模型中恢复出密集奖励信号。这样的密集奖励模型提供了精细化的信用分配，可以用于进一步使用强化学习改进策略。文中提出的方法Dense-Path REINFORCE在指令遵循基准测试中表现优于原始SFT模型。它将SFT重新定义为奖学习机制，而不是简单的策略模仿，从而开启了利用专家演示的新可能性。
### Conclusion
这项工作不仅证明了SFT和逆RL之间的等价性，还通过恢复密集奖励信号，为使用SFT生成策略提供了更好的指导。进一步，该研究引入了Dense-Path REINFORCE算法，该算法在指令遵循基准测试中表现更优，并且提出了一个新视角来看待SFT过程。
## 341. `cs.CL` - HyperAdaLoRA：通过超网络在训练期间加速LoRA秩分配而不牺牲性能 [PDF](https://arxiv.org/pdf/2510.02630), [HTML](https://arxiv.org/abs/2510.02630)
### Authors
Hao Zhang,Zhenjia Li,Runfeng Bao,Yifan Gao,Xi Xiao,Bo Huang,Yuhang Wu,Tianyang Wang,Hao Xu
### Background
参数高效微调（PEFT），特别是低秩适应（LoRA），作为一种减少计算和内存开销的同时对大型语言模型（LLMs）进行微调的方法，已经展现出潜力。然而，LoRA假设每个增量矩阵采用统一的秩r，未能考虑到不同模块和层中的权重矩阵的重要性差异。
### Innovation
HyperAdaLoRA引入了一种创新框架，通过利用注意力机制的超网络来加速AdaLoRA的收敛速度。它不直接优化奇异值分解的组件（P, Λ, Q），而是通过超网络动态生成这些参数，并通过剪枝生成奇异值的超网络输出来实现动态秩分配。
### Conclusion
全面的实验证明，我们的方法在多个数据集和模型上实现了更快的收敛速度且不牺牲性能。进一步的实验表明，我们的方法对其他基于LoRA的方法也有广泛适用性。
## 342. `cs.CL` - Litespark技术报告：高性能、低能耗的大语言模型训练框架 [PDF](https://arxiv.org/pdf/2510.02483), [HTML](https://arxiv.org/abs/2510.02483)
### Authors
Nii Osae Osae Dade,Moinul Hossain Rahat
### Background
训练大规模语言模型（LLM）面临长时间训练和巨大的能耗问题，现代模型的训练需要数月计算时间并消耗数十吉瓦小时的电力。面对这些挑战，本文通过针对Transformer注意力机制和MLP层的优化，介绍了一种新的预训练框架Litespark。该框架通过结合架构改进与算法增强，最大化模型计算量利用率（MFU），同时保持与标准Transformer实现的兼容性。全面的基准测试表明，在3B和30B参数的Llama模型上使用SlimPajama-627B数据集，Litespark框架在多节点H200 GPU集群上训练吞吐量提高了2到6倍，并将能耗减少了55%至83%。这些优化不仅适用于不同模型和硬件，还能应用于后续训练阶段，包括监督微调和直接偏好优化。
### Innovation
提出了一种名为Litespark的新预训练框架，该框架通过针对Transformer注意力机制和MLP层的优化，结合架构改进与算法增强，最大化模型计算量利用率（MFU），实现了在3B和30B参数Llama模型上的训练吞吐量提高2到6倍和能耗减少55%至83%的性能提升，适用于不同模型和硬件，扩展到后续训练阶段。
### Conclusion
Litespark框架在多节点H200 GPU集群上展示了显著的性能提升和能耗降低，其优化策略对不同规模的语言模型和硬件平台具有广泛适用性，能够应用于随后的训练阶段优化。
## 343. `cs.CL` - 如何训练你的顾问：使用顾问模型引导黑盒大语言模型 [PDF](https://arxiv.org/pdf/2510.02453), [HTML](https://arxiv.org/abs/2510.02453)
### Authors
Parth Asawa,Alan Zhu,Matei Zaharia,Alexandros G. Dimakis,Joseph E. Gonzalez
### Background
随着基础模型作为不可修改权重的黑盒服务逐渐部署，自定义主要依赖于提示进行优化。尽管静态提示优化显示出潜力，但它产生的是单一固定的提示，无法针对不同输入、用户或环境进行调整。本文背景在于解决这一局限性，即如何设计一种方法来动态且适应性地优化黑盒模型.
### Innovation
本文介绍了一种轻量级参数策略——顾问模型（Advisor Model），它通过强化学习训练，并且在上下文中以反应性的方式提供自然语言指导指令给黑盒模型。顾问模型作为输入和模型之间的第二个小型模型，能够根据环境提供的奖励信号对行为进行实例化调整。研究表明，顾问模型在涉及推理和个人化等多个领域中均优于静态提示优化器，发现环境动态并提升下游任务性能.
### Conclusion
顾问模型为可学习的黑盒系统接口提供了新途径，其顾问作为参数化、环境特定的记忆体，能够实现专业化，并保持对分布外输入的强大鲁棒性。作者认为，通过顾问模型对黑盒模型进行动态优化是推动个性化和环境适应性人工智能能力发展的有力方向。
## 344. `cs.CL` - 减少LLM，增加文档：寻找改进RAG的方法 [PDF](https://arxiv.org/pdf/2510.02657), [HTML](https://arxiv.org/abs/2510.02657)
### Authors
Jingjie Ning,Yibo Kong,Yunfan Long,Jamie Callan
### Background
检索增强生成（RAG）将文档检索与大规模语言模型（LLMs）结合使用。虽然扩大生成器规模可以提高准确性，但这也增加了成本并限制了其可部署性。
### Innovation
该研究探索了一个新的方向，即扩大检索者的文库规模以减少对大规模LLMs的依赖。实验结果表明，文库扩展能一致地增强RAG的效果，并且在一定程度上可以替代增加模型大小，但在更大规模上收益递减。小规模和中等规模的生成器结合大规模的文库往往能够与大规模模型在较小的文库上相匹敌；中等规模的模型受益最多，而小型和大型模型受益较少。研究发现，改进主要来自于答案承载段落覆盖范围的增加，而模型利用效率变化不大。
### Conclusion
研究表明，扩大文库规模比增加LLM规模更有成效，提供了一条更有效的增强RAG的方法，这在很多情况下与扩大LLM本身的效果相当。
## 345. `cs.CL` - 关于测试时温度采样在测试时扩展中所起的作用 [PDF](https://arxiv.org/pdf/2510.02611), [HTML](https://arxiv.org/abs/2510.02611)
### Authors
Yuheng Wu,Azalia Mirhoseini,Thierry Tambe
### Background
大型语言模型（LLMs）可以通过测试时扩展（TTS）在推理阶段提升推理能力，其中通过生成多个推理轨迹并选择最佳一个来实现。以往的研究表明，增加样本数量K（即生成的轨迹数量）会持续提高准确性。这篇论文研究了这种方法的趋势，并指出增加样本数量K的效果在K达到一定大小后不再明显，即使生成更多的轨迹也无法解决某些难题。
### Innovation
研究发现不同的采样温度能够解决不同类型的难题，单一温度扩展只能探索模型的一部分潜力。因此，提出了沿着温度维度扩展的方法，这拓宽了LLMs在推理上的边界。实验结果表明，在Qwen3（0.6B, 1.7B, 4B, 8B）和五个代表性推理基准（AIME 2024/2025, MATH500, LiveCodeBench, Hi-ToM）上，温度扩展比单一温度扩展提高了7.3个点的准确性。此外，研究还设计了一种多温度投票方法来降低温度扩展的开销，表明TTS比预期更具威力，温度扩展提供了简单有效的方法来解锁基模型的潜在能力。
### Conclusion
研究结果表明，TTS比之前认为的更具威力，而温度扩展提供了一种简单而有效的方法来解锁基模型的潜在能力。
## 346. `cs.CL` - Hyperparameter Loss Surfaces Are Simple Near their Optima [PDF](https://arxiv.org/pdf/2510.02721), [HTML](https://arxiv.org/abs/2510.02721)
### Authors
Nicholas Lourie,He He,Kyunghyun Cho
### Background
超参数极大地影响模型的能力；然而，现代模型过于庞大，无法进行广泛的搜索。因此，研究人员设计了基于对超参数理解的有效训练食谱。尽管超参数的重要性，仍缺乏工具来理解超参数的损失表面。论文揭示了损失表面的新的结构，并提出了新的理论和工具。
### Innovation
论文开发了一种新颖的技术基于随机搜索来探索渐近区间的损失表面，并发现了这种情况下随机搜索得分的新分布。这种新分布的参数确切地定义了损失表面在渐近区间的特征。这些特征用于推导出新的随机搜索渐近定律，能够解释并外推其收敛。
### Conclusion
这些新的工具能够进行新的分析，如最佳可能性能的置信区间或确定有效超参数数量。作者将在如下链接提供这些工具：this https URL.
## 347. `cs.CL` - 模型消除下的安全性前训练细粒度研究 [PDF](https://arxiv.org/pdf/2510.02768), [HTML](https://arxiv.org/abs/2510.02768)
### Authors
Shashank Agnihotri,Jonas Jakubassa,Priyam Dey,Sachin Goyal,Bernt Schiele,Venkatesh Babu Radhakrishnan,Margret Keuper
### Background
大模型在推理阶段可以通过简单的激活编辑进行修改，这引发了一个关于安全性的问题：常见的安全干预措施，如拒绝训练或元标签训练，是否能应对这样的编辑？为此，本研究通过消除法研究了一种旨在去除拒绝敏感方向的轻量级投影技术，并评估了SmolLM2-1.7B在安全性前训练检查点中的表现，同时还与广泛使用的开源基准进行了比较。
### Innovation
本研究引入了模型消除技术，这是在检查点级别消除拒绝语料库数据的方法。通过对SmolLM2-1.7B逐级别的安全性前训练检查点进行了细致的评估，结合了广泛使用的开源基准，并通过多名评判者的识别结果评估了评判者选择对评估结果的影响。研究表明，哪些数据高度中心化安全组件在模型消除下依旧稳健，并提出了在安全评估中结合推理时编辑的实用协议。
### Conclusion
本研究细化了模型消除对安全性前培训的影响，量化了评判者选择对评估结果的影响，并且制定了实用的协议将推理时的编辑整合到安全评估之中。
## 348. `cs.CL` - 帕累托最优的非统一语言生成 [PDF](https://arxiv.org/pdf/2510.02795), [HTML](https://arxiv.org/abs/2510.02795)
### Authors
Moses Charikar,Chirag Pabbaraju
### Background
Kleinberg和Mullainathan（2024）提出了一个有趣的语言生成极限模型：给定一门语言的可数集合和对手按照某个语言L中的字符串顺序枚举，目标是在某个时间后生成新的有效字符串。Li、Raman和Tewari（2024）以及Charikar和Pabbaraju（2024）在该模型中展示了强非统一生成保证，给出了看到特定数量不同输入字符串t(L)后能生成新有效字符串L的算法，而t(L)仅依赖于L和集合，而不依赖于枚举顺序。尽管如此，这些工作的生成时间t(L)在语言层面上可能是严格次优的。
### Innovation
本文研究了非统一语言生成的帕累托最优性。提出了一个算法，其生成时间t∗(L)几乎是帕累托最优的：如果另一个算法对某些语言L的生成时间严格小于t∗(L)，那么它对其他语言L'的生成时间将更差。帕累托最优性是非均匀生成能够实现的最好结果。该算法框架也能够方便地适应噪声及代表性的生成场景。
### Conclusion
本文提出了一个新的算法框架，实现了对非统一语言生成的帕累托最优性，进一步应用于噪声及代表性的生成场景。
## 349. `cs.CL` - NCV：一种低成本结构化错误定位的节点级一致性验证方法 [PDF](https://arxiv.org/pdf/2510.02816), [HTML](https://arxiv.org/abs/2510.02816)
### Authors
Yulong Zhang,Li Wang,Wei Du,Peilin Li,Yuqin Dai Zhiyuan Zhao,Lingyong Fang,Ziniu Liu,Ru Zhang,Huijia Zhu,Gongshen Liu
### Background
在大型语言模型（LLM）上验证多步推理是一项具有挑战性的工作。现有的方法要么评估整个推理链，导致注意力分散；要么依赖于昂贵的多抽样。这些方法在准确定位错误和减少不必要的长形式生成方面存在不足。
### Innovation
作者提出了一种名为节点级一致性验证（Node-wise Consistency Verification, NCV）的训练无损框架。通过将推理链分解为相互连接的验证节点，NCV能够准确地标记错误并避免不必要的长形式生成。这一方法提升了可解释性和效率，提供了一个可扩展的方案，用于可靠地验证LLM的推理。
### Conclusion
在公共数据集上，NCV在F1分数上比基线方法提高了10%到25%，同时使用比传统方法（如基于CoT的验证器）少6到58倍的令牌数，展示了其作为低成本而有效的验证解决方案的优势。
## 350. `cs.CL` - 共生连续离散扩散：让你的扩散语言模型成为潜在推理者 [PDF](https://arxiv.org/pdf/2510.03206), [HTML](https://arxiv.org/abs/2510.03206)
### Authors
Cai Zhou,Chenxiao Yang,Yi Hu,Chenyu Wang,Chubin Zhang,Muhan Zhang,Lester Mackey,Tommi Jaakkola,Stephen Bates,Dinghuai Zhang
### Background
扩散语言模型，尤其是掩码离散扩散模型，最近取得了巨大成功。虽然有一些理论和初步的实验证明了循环变压器或连续链式思考的潜在推理优势，但连续扩散模型通常在性能上不如其离散对应物。
### Innovation
本文提出了一种共生连续离散扩散（CCDD）模型，这是一种定义在联合连续表示空间和离散标记空间上的联合多模态扩散过程。CCDD利用单一模型在联合空间中同时去噪，通过结合两种模态，在潜在空间中具有丰富的语义表达能力，并且在显式离散标记的帮助下，具有良好的可训练性和样本质量。
### Conclusion
在广泛的实际语言建模任务上的实验中，CCDD显示了强大的实证性能，证明了扩散模型不一定需要在离散空间中，连续扩散模型的表达能力比离散扩散和循环变压器更强，但他们实际可训练性存在矛盾，为了解决这一矛盾，提出了CCDD模型。
## 351. `cs.CL` - 低概率令牌维持有验证奖励的强化学习中的探索 [PDF](https://arxiv.org/pdf/2510.03222), [HTML](https://arxiv.org/abs/2510.03222)
### Authors
Guanhua Huang,Tingqiang Xu,Mingze Wang,Qi Yi,Xue Gong,Siheng Li,Ruibin Xiong,Kejiao Li,Yuhao Jiang,Bo Zhou
### Background
RLVR在复杂推理中推动了大型语言模型的发展，但由于训练瓶颈导致性能在策略熵坍缩时停滞，这反映了探索的丧失。之前的解决方案通常集中在保持高的策略熵，但对有意义探索的具体机制却缺乏深入的研究。研究指出，不加选择地关注熵可能放大无关的令牌并导致训练不稳。因此，本文分析了RLVR中的探索动态，发现了一个关键问题：有价值的低概率探索令牌逐渐被消除，这被称作“推理火花”。这些令牌在预训练模型中普遍存在，但在RLVR中由于过度惩罚而被系统性地扑灭，从而导致探索的退化。
### Innovation
引入了低概率正则化（Lp-Reg），其核心机制是通过构造一个去除假定为噪声令牌的策略，来引导策略向一组加权的目标分布。这个代理分布旨在提升“推理火花”的概率，并通过KL散度来实现软正则化目标，以保护这些有价值的令牌免于被消除。实验表明，Lp-Reg能够让策略在大约1,000个步骤内保持稳定的学习，而之前的熵控制方法在此阶段会失效。这种持久的探索导致了目前最好的表现，平均准确率达到60.17%，相比之前的方法提高了2.66%。
### Conclusion
本研究通过引入低概率正则化（Lp-Reg）解决了RLVR中的探索瓶颈问题，使得策略在长时间内保持有效学习，并取得了在数学基准测试中目前最佳的平均准确率。
## 352. `cs.CL` - 当名称消失：揭示LLMs实际上理解的代码内容 [PDF](https://arxiv.org/pdf/2510.03178), [HTML](https://arxiv.org/abs/2510.03178)
### Authors
Cuong Chi Le,Minh V.T. Pham,Cuong Duc Van,Hoang N. Phan,Huy N. Phan,Tien N. Nguyen
### Background
大型语言模型（LLMs）在代码任务上表现出色，但它们如何推导程序意义仍然不清楚。本文通过分析代码通信的两个渠道——结构性语义（定义正式行为）和人类可解释的命名（传达意图）——探讨了这一问题。去除命名通道严重恶化了意图级别的任务，如总结，模型退化为逐行描述。令人惊讶的是，本文还观察到，在仅依赖结构的任务中也观察到一致的性能降低，表明当前基准奖励命名模式的记忆，而不是真正的语义推理。为了解析这些效果，本文引入了一系列保留语义的信息混淆方法，并展示了这些方法如何在总结和执行任务中揭示标识符泄漏。
### Innovation
本文提出了一种名为ClassEval-Obf的增强混淆基准，以系统地抑制命名线索，同时保持行为。这项工作区分了在结构性语义任务中模型依赖命名模式与进行真正语义推理的情况，揭示了当前代码基准的问题，即过分依赖命名模式记忆。这有助于更准确地评估LLMs对代码的理解与泛化能力，并展示出ClassEval-Obf减少了模型性能的夸大差距，削弱了记忆捷径，提供了更加可靠的基础性评估方法。
### Conclusion
ClassEval-Obf提高了对LLMs代码理解与泛化能力的可靠性评估。通过引入保留语义的信息混淆方法，本文成功揭示了LLMs在执行任务中的命名模式依赖，改善了现有的代码基准，帮助研究人员更加全面地衡量LLMs的真实代码理解水平。
## 353. `cs.CL` - 视频模型有多自信？赋予视频模型表达不确定性的能力 [PDF](https://arxiv.org/pdf/2510.02571), [HTML](https://arxiv.org/abs/2510.02571)
### Authors
Zhiting Mei,Ola Shorinwa,Anirudha Majumdar
### Background
生成视频模型展示了令人印象深刻的从文本生成视频的能力，并在许多现实世界的应用中得到广泛应用。然而，这些视频生成模型和大型语言模型（LLMs）一样，有虚构的倾向，即使所生成的视频是出于事实上的错误，它们也看起来合理。尽管先前的工作在LLMs的不确定性量化（UQ）上做了大量研究，但目前还没有为视频模型开发UQ方法，这提出了重要的安全问题。因此，本文旨在量化视频模型的不确定性，并提出了一种评估框架，包括基于鲁棒秩相关估计的不确定性的度量方法、一种旨在严格分解预测不确定性的黑盒UQ方法以及一个用于在视频模型中进行校准基准测试的数据集。通过在潜在空间中条件生成任务，作者区分了由于任务说明模糊而产生的不确定性与由于知识不足而产生的不确定性。大量的基准视频数据集的实验表明，S-QUBED计算了与任务准确性呈负相关、且可有效计算出的教务和客观组成部分的校准总不确定性估计值。
### Innovation
文章开创性地提出了一个框架来量化视频模型的不确定性。主要创新包括（i）一种基于鲁棒秩相关估计的不确定性的度量方法，不需要严格的建模假设；（ii）一种名为S-QUBED的黑盒UQ方法，利用潜在建模来严格分解预测不确定性为 randomness 和 epistemic 成分；（iii）一个用于基准测试视频模型校准的数据集。通过在潜在空间中条件生成任务，将由于任务描述模糊引起的不确定性和由于知识不足引起的不确定性进行拆分
### Conclusion
通过广泛的基准视频数据集实验，研究展示了S-QUBED计算了与任务准确性呈负相关的校准总不确定性估计值，并有效计算出了随机和主观参数的组成部分。这为评估和改进视频生成模型的可靠性提供了新的方法。
## 354. `cs.CL` - Did Translation Models Get More Robust Without Anyone Even Noticing？ [PDF](https://arxiv.org/pdf/2403.03923), [HTML](https://arxiv.org/abs/2403.03923)
### Authors
Ben Peters,André F.T. Martins
### Background
神经机器翻译（MT）模型在多种场景下表现出色，但普遍认为它们对'噪声'输入（如拼写错误、缩写和其他格式问题）高度敏感。最近，研究人员重新审视了这一观点，特别是结合了多语言MT模型和大规模语言模型（LLM）应用于机器翻译的结果，发现这些模型对许多类型的噪声表现出比以前的模型更高的鲁棒性，即使在清洁数据上表现相似。相关实验证明，尽管这些新模型的参数更多、训练过程更复杂，但它们却未使用专门设计以增强鲁棒性的技术。这引发了关于这些模型如何实现更好鲁棒性的讨论，特别是在社交媒体翻译任务中观察到了类似的趋势。相关分析揭示了何时可使用源校正技术来减少噪声的影响。
### Innovation
研究表明，尽管新模型的参数更多且训练过程更复杂，却并未专门针对诸如增加鲁棒性的技术。现有模型对多种类型噪声的鲁棒性提升显著，甚至在社交媒体文本中表现出色，这一事实未引起重视。
### Conclusion
研究发现，对多种类型噪声的鲁棒性普遍提高了，而不需要特定增强鲁棒性的技术，新模型在噪声环境下呈现出更好的表现。
## 355. `cs.CL` - 从仿真到规则：一种用于正式视觉规划的双VLM框架 [PDF](https://arxiv.org/pdf/2510.03182), [HTML](https://arxiv.org/abs/2510.03182)
### Authors
Yilun Hao,Yongchao Chen,Chuchu Fan,Yang Zhang
### Background
视觉语言模型（VLMs）在视觉规划中表现出强大的潜力，但在精确的空间推理和长时序推理方面存在困难。相反，规划领域定义语言（PDDL）规划器在长时序形式化的规划中表现出色，但无法解释视觉输入。近期工作通过使VLMs能够将视觉规划问题转换为PDDL文件进行正式规划，结合了这两种互补的优势。然而，虽然VLMs可以很好地生成满足要求的PDDL问题文件，但在准确生成描述所有规划规则的PDDL领域文件方面存在困难。因此，先前的方法依赖于人类专家预先定义领域文件，或者频繁访问恒定环境进行完善。
### Innovation
我们提出了VLMFP，这是一种由双VLM引导的框架，能够自主生成正式视觉规划所需的PDDL问题文件和领域文件。VLMFP引入了两个VLM模型以确保PDDL文件的可靠生成：一个SimVLM根据输入规则描述模拟操作的结果，另一个GenVLM通过比较PDDL和SimVLM执行结果生成和迭代完善PDDL文件。VLMFP展示了多层次的适用性：相同的生成PDDL领域文件适用于同一问题下的所有不同实例，并且VLMs能够泛化解决不同类型的视觉规划问题。
### Conclusion
我们使用6个格子世界领域评估了VLMFP，并测试了其在未见过的实例、外观和游戏规则上的泛化能力。在平均情况下，SimVLM准确描述了95.5%和82.6%的场景，模拟了85.5%和87.8%的动作序列，并判断了82.4%和85.6%在已见过和未见过的外观中目标达成情况。在SimVLM的指导下，VLMFP可以为已见过和未见过的外观生成PDDL文件，分别生成70.0%和54.1%的有效计划。
## 356. `cs.CL` - ChunkKV: 保留语义的KV缓存压缩以提高高效长上下文LLM推理 [PDF](https://arxiv.org/pdf/2502.00299), [HTML](https://arxiv.org/abs/2502.00299)
### Authors
Xiang Liu,Zhenheng Tang,Peijie Dong,Zeyu Li,Yue Liu,Bo Li,Xuming Hu,Xiaowen Chu
### Background
大型语言模型在处理长文本时需要大量的GPU内存，其中的键值缓存（KV）消耗了总内存高达70%。现有压缩方法虽然通过评估单个词的重要性来减少内存使用，但忽略了词之间的关键语义关系，导致了语境的碎片化和性能的下降。
### Innovation
本文提出了ChunkKV，重新定义了KV缓存压缩的方式，将语义片段而不是孤立的词作为基本压缩单元。这种方法保留了完整的语言结构和语境完整性，即使在压缩非常严重的情况下也能保留重要意义。ChunkKV创新地引入了一种新型的逐层索引重用技术，利用保留索引在不同层之间更高的相似性，降低了计算开销并提高了26.5%的吞吐量。在LongBench、Needle-In-A-HayStack、GSM8K和JailbreakV等极具挑战性的基准测试上，ChunkKV在保持相同压缩率的情况下，精度提高了至多8.7%，证明了语义感知压缩在提高长上下文LLM推理效率和性能方面的显著增强效果，提供了一个简单而有效的解决内存瓶颈问题的方法。
### Conclusion
这些结果证明了语义感知压缩在提高长上下文大语言模型推理的效率和性能方面的显著提升效果，提供了一个简单而有效的解决内存瓶颈问题的方法。
## 357. `cs.CL` - L1: 使用强化学习控制推理模型思考时长 [PDF](https://arxiv.org/pdf/2503.04697), [HTML](https://arxiv.org/abs/2503.04697)
### Authors
Pranjal Aggarwal,Sean Welleck
### Background
推理语言模型在测试时显示出惊人的能力，通过生成更长的推理链来改进性能。然而，这种方法的推理链长度不可控，无法灵活地将计算时间分配以达到目标性能水平。本文提出了Length Controlled Policy Optimization（LCPO），一种基于强化学习的方法，该方法同时优化正确性和满足用户指定的长度约束。
### Innovation
引入了LCPO方法，用于训练L1模型，使其生成满足提示中长度约束的输出。L1模型的长度控制功能使其能够在广泛的任务中平滑地权衡计算成本和准确性，并且在长度控制性能上优于最先进的方法S1。此外，研究还发现，使用LCPO训练的模型具有类似推理模式的Short Reasoning Models（SRMs），这些模型能生成与非推理模型相当的推理链长度，但显示出显著的性能提升。
### Conclusion
LCPO能够让推理长度精确可控，允许细粒度地分配测试时间的计算资源和目标性能。我们的研究结果和模型代码可在指定的链接处获取。
## 358. `cs.CL` - MaskCD: 通过图像头部遮蔽对比解码减轻LVLM幻觉现象 [PDF](https://arxiv.org/pdf/2510.02790), [HTML](https://arxiv.org/abs/2510.02790)
### Authors
Jingyuan Deng,Yujiu Yang
### Background
大型视觉-语言模型（LVLMs）在下游多模态任务中的视觉-语言理解表现出卓越的能力。然而，这些模型同时也暴露出了问题，其中之一便是幻觉现象，即LVLMs生成与其输入的视觉和文本内容相矛盾的内容。尽管已经有诸如对比解码和注意力操控等方法被提出，但这些方法存在的问题也暴露出来：对比解码方法在构建对比样本方面存在困难，而注意力操控方法则缺乏稳定性，容易产生偏差。因此，本文提出了一种名为MaskCD的新方法，利用LVLM中的图像头部进行遮蔽，以此来构建对比样本用于对比解码。
### Innovation
本文提出了一种利用大型视觉-语言模型（LVLM）中的图像头部进行遮蔽（Masked Contrastive Decoding），来减轻幻觉现象的方法。这种方法通过遮蔽图像头部来构建对比样本，从而有效缓解幻觉现象，保持了LVLMs的通用能力，同时解决了现有的方法在样本构建和稳定性方面的问题。该方法在LLaVA-1.5-7b和Qwen-VL-7b上进行了评估，并在CHAIR、POPE、AMBER和MME等多个基准测试中显示出优越的效果。
### Conclusion
实验结果表明，MaskCD方法能够有效减轻幻觉现象，同时保持LVLMs的通用能力。遮蔽图像头部的对比解码方法在幻觉控制方面取得了显著的成果，为视觉语言理解技术的发展提供了新的思路。相应的资源可以在给出的链接处找到。
## 359. `cs.CL` - 通过激活引导理解代码LLMs（错误）预测类型的方式 [PDF](https://arxiv.org/pdf/2404.01903), [HTML](https://arxiv.org/abs/2404.01903)
### Authors
Francesca Lucchetti,Arjun Guha
### Background
大型语言模型（LLMs）在软件开发中被广泛应用于编程任务中。然而，研究显示，LLMs往往缺乏对程序语义的深层次理解。即使是语法上的小变动，如变量重命名，也会显著影响其在各种任务上的表现。
### Innovation
本文探讨了类型预测任务：给定部分已标注类型的程序，模型能否预测缺失的类型标注，以使程序更完整地类型化？构建了一组对抗样本数据集，表明尽管LLMs在对抗场景中表现出不稳定的预测机制，但通过激活引导的方法，模型能够激活跨编程语言共享的类型预测机制，该机制比上下文提示更有效。
### Conclusion
通过全面评估五种不同的模型，研究结果表明LLMs可以学习跨编程语言的一般化代码语义表示，这一机制在对抗输入上表现更好。
## 360. `cs.CL` - BottleHumor：使用信息瓶颈原则的自我启发幽默解释 [PDF](https://arxiv.org/pdf/2502.18331), [HTML](https://arxiv.org/abs/2502.18331)
### Authors
EunJeong Hwang,Peter West,Vered Shwartz
### Background
幽默在在线交流中很普遍，常常依赖于多种模态（例如漫画和表情包）。理解多模态环境中的幽默需要调动多种知识，包括隐喻知识、社会文化知识和常识知识。然而，确定哪些知识最有用仍然是一个开放的问题。
### Innovation
作者介绍了一种受信息瓶颈原则启发的方法，该方法从视觉和语言模型中提取相关的世界知识，并在生成幽默解释时逐步优化这些知识。这种方法在三个数据集上的实验表明，它比一系列基线方法有优势。该方法还可以在未来适应其他可以从提取和条件化相关世界知识中获益的任务，为研究开辟新的方向。
### Conclusion
实验表明，该方法在三个数据集上优于各种基线方法，且具有处理其他任务的潜力。
## 361. `cs.CL` - 在强大LLM时代复杂稳健RAG训练的递减回报 [PDF](https://arxiv.org/pdf/2502.11400), [HTML](https://arxiv.org/abs/2502.11400)
### Authors
Hanxing Ding,Shuchang Tao,Liang Pang,Zihao Wei,Liwei Chen,Kun Xu,Huawei Shen,Xueqi Cheng
### Background
检索增强生成（RAG）系统通常采用复杂的训练策略来提高模型对检索噪声的鲁棒性。研究表明，这些复杂的训练方法对于较小的模型具有显著的性能提升效果。但随着语言模型能力的增强，模型采用简单训练方法也能达到类似甚至更好的性能。这项研究通过在多个模型规模和问答数据集上的系统测试，进一步探讨了模型能力增强后复杂训练策略的效益情况。
### Innovation
这项研究揭示了一个显著的趋势：随着模型能力的增加，复杂训练策略带来的鲁棒性提升逐渐减弱，而较强的模型在简单训练方法下表现出更好的信心校准、跨数据集泛化能力和更有效的注意力模式。
### Conclusion
在基础模型逐渐演进的过程中，复杂稳健的RAG训练可能不再具有显著的效益，简化后的RAG流程对于强大模型同样能保持竞争力，这表明工程投入应在简化训练策略上获得更多收益。
## 362. `cs.CL` - DatawiseAgent：面向笔记本中心的大语言模型代理框架，实现适应性和稳健的数据科学自动化 [PDF](https://arxiv.org/pdf/2503.07044), [HTML](https://arxiv.org/abs/2503.07044)
### Authors
Ziming You,Yumiao Zhang,Dexuan Xu,Yiwei Lou,Yandong Yan,Wei Wang,Huaming Zhang,Yu Huang
### Background
现有的大型语言模型（LLM）代理在自动化数据科学方面展示了潜力，但它们仍然受到狭窄的任务范围、跨任务和模型的有限泛化以及过度依赖于当前最先进的（SOTA）LLM的限制。
### Innovation
DatawiseAgent 是一个以笔记本为中心的LLM代理框架，用于自适应和稳健的数据科学自动化。灵感来源于人类数据科学家在计算笔记本中的工作方式，DatawiseAgent 引入了统一的交互表示和基于有限状态转换器（FSTs）的多阶段架构。这种设计使长期规划、逐步解决方案开发以及在执行失败时的稳健恢复变得灵活。
### Conclusion
广泛实验的结果表明，DatawiseAgent 通过超越AutoGen和TaskWeaver等强大基线，实现了SOTA性能的一致性，展示了卓越的效果和适应性。进一步的评估揭示了在较弱或较小的模型下优雅地性能下降，这点突显了其稳健性和可扩展性。
## 363. `cs.CL` - 超越最终答案：工具增强代理推理轨迹的评估 [PDF](https://arxiv.org/pdf/2510.02837), [HTML](https://arxiv.org/abs/2510.02837)
### Authors
Wonjoong Kim,Sangwu Park,Yeonjun In,Sein Kim,Dongha Lee,Chanyoung Park
### Background
尽管近年来的增强工具基准测试包含了复杂的用户请求和多样的工具，但大多数评价方法仍然局限于答案匹配。然而，随着解决用户请求所需的步骤增加，评估代理的性能不仅要考虑最终答案，还需评估问题解决的轨迹，包括效率、虚构和适应性等方面。直接将代理轨迹与真实轨迹进行比较是最直接的方法，但这种方法因标注所有真实轨迹的成本过高而受到限制。简单的人工语言模型（LLM）评估工具难以详细评估轨迹而无需真实轨迹。因此，需要一种新的框架来评估工具增强LLM代理的性能。
### Innovation
本文提出了TRACE框架，这是一种多维度的工具增强LLM代理性能评价框架，通过引入证据库来累积之前推理步骤中获取的知识，从而能够让对代理推理轨迹进行全面分析和评价。通过增强现有基准测试集来创建一个新的元评价数据集，分配多维度的性能评分。结果显示，即便使用小型开源LLM也可有效且经济地评估这些复杂行为。此外，还应用该方法来评估代理解决工具增强任务时产生的轨迹，揭示了一些以前未报告的观察和相应的见解。
### Conclusion
TRACE框架通过多维度评估工具增强LLM代理的性能，不仅考虑最终答案，还评价推理轨迹中的效率、适应性和虚构性。这一框架能够经济且有效地评估复杂行为，即使使用小型开源LLM也是如此。此外，通过应用TRACE框架解决了工具增强任务中生成的轨迹，并揭示了新的见解。
## 364. `cs.CL` - NeSyGeo: 一种用于多模态几何推理数据生成的神经符号框架 [PDF](https://arxiv.org/pdf/2505.17121), [HTML](https://arxiv.org/abs/2505.17121)
### Authors
Weiming Wu,Jin Ye,Zi-kang Wang,Zhi Zhou,Yu-Feng Li,Lan-Zhe Guo
### Background
多模态大规模语言模型（MLLMs）的几何推理能力提升依赖于大规模高质量推理数据的获得，现有数据生成方法受限于多样性和数值泛化的局限。
### Innovation
提出了一种名为NeSyGeo的神经符号框架，通过领域特定语言和象征视图文本流水线生成几何推理数据，该框架显著且一致地提高了多种MLLMs的几何推理能力。
### Conclusion
基于NeSyGeo框架构建的数据集NeSyGeo CoT和NeSyGeo-Caption包含100k样本，并释放一个新的基准测试NeSyGeo-Test以评估MLLMs的几何推理能力。实验结果显示，在两种微调方法下，模型的性能有显著提升。
## 365. `cs.CL` - 不是麻烦而是有用的启发式方法：异常维度 favor 常见词在语言模型中的应用 [PDF](https://arxiv.org/pdf/2503.21718), [HTML](https://arxiv.org/abs/2503.21718)
### Authors
Iuri Macocco,Nora Graichen,Gemma Boleda,Marco Baroni
### Background
我们研究了语言模型中的最后一层异常维度，即在大多数输入中表现出极端激活的维度。研究发现这些异常维度在许多现代语言模型中出现，并追溯它们的功能到一种常预测常见词的启发式方法。研究还展示了当这种启发式方法不适用于具体上下文时，模型可以通过分配给其他维度的反向权值来抑制这种启发式方法。研究进一步探讨了哪些模型参数会增强异常维度，并在训练过程中何时出现。研究结果表明，异常维度是许多不同模型在实现有用术语预测启发式方法时发现的一种专门机制。
### Innovation
研究揭示了异常维度在现代语言模型中的普遍性，并将其归因于一种常预测常见词的启发式方法。还展示了当这种启发式方法不适用于具体上下文时，模型可以通过分配给其他维度的反向权值来抑制这种启发式方法，并探讨了哪些模型参数会增强异常维度，以及它们在训练过程中何时出现。
### Conclusion
异常维度是许多不同模型发现的一种专门机制，用于实现有用的术语预测启发式方法。
## 366. `cs.CL` - 向经济推理迈进：在任何基于Transformer的语言大模型中启用DeepSeek的多头潜在注意力 [PDF](https://arxiv.org/pdf/2502.14837), [HTML](https://arxiv.org/abs/2502.14837)
### Authors
Tao Ji,Bin Guo,Yuanbin Wu,Qipeng Guo,Lixing Shen,Zhan Chen,Xipeng Qiu,Qi Zhang,Tao Gui
### Background
标准的大语言模型（LLM）采用多头注意力（MHA）及其变体（如分组查询注意力GQA），这些模型在推理时成本较高。具体来说，它们使用大量内存来维持键值（KV）缓存，这对计算资源是一个重大负担。DeepSeek提出的多头潜在注意力（MLA）架构通过显著压缩KV缓存为潜在向量，旨在确保推理时的高效和经济。启用经过良好训练的LLM（例如Llama）快速适应MLA而无需从零开始预训练是一项既有意义又具有挑战性的任务。现有方法难以有效地从MHA过渡到MLA，这限制了MLA在各种语言大模型中的广泛应用。
### Innovation
本文提出了一种高效的数据增强微调方法，称为MHA2MLA，用于从MHA过渡到MLA。这种方法包括两个关键组成部分：部分RoPE（旋转位置编码）移除和低秩逼近。对于部分RoPE，作者移除了对注意分数影响较小的查询和键的RoPE；对于低秩逼近，则引入基于预训练的键和值参数进行联合SVD近似。这些精心设计的策略使得MHA2MLA能够仅使用很小比例（0.3%到0.6%）的数据恢复性能，同时将推理成本显著降低，并且可以无缝结合诸如KV缓存量化等压缩技术。以Llama2-7B为例，KV缓存大小减少了92.19%，性能下降仅为0.5%。
### Conclusion
MHA2MLA方法能够使Llama等经过训练的良好语言模型快速有效地转换到MLA，显著减少推理成本并且无需从零开始预训练。该方法的成功实施表明，MLA在经济推理中的应用具有巨大的潜力，可以广泛应用于现有的大型语言模型中。
## 367. `cs.CL` - 利用内部和外部知识预训练有限记忆语言模型 [PDF](https://arxiv.org/pdf/2505.15962), [HTML](https://arxiv.org/abs/2505.15962)
### Authors
Linxi Zhao,Sofian Zalouk,Christian K. Belardi,Justin Lovelace,Jin Peng Zhou,Ryan Thomas Noonan,Dongyoung Go,Kilian Q. Weinberger,Yoav Artzi,Jennifer J. Sun
### Background
神经语言模型是黑盒的--语言模式和事实知识是分布在数十亿个不透明参数中的。这种纠缠的编码使得可靠地检查、验证或更新特定事实变得困难。该研究介绍了一种新的语言模型类别，称为有限记忆语言模型（LMLM），在预训练过程中将事实知识外化到外部数据库中，而不是将其记忆化。预训练方法战略性地从训练损失中屏蔽外部检索到的事实值，从而教模型进行目标检索，而不是依赖于模型权重的记忆。
### Innovation
研究人员提出了有限记忆语言模型（LMLM），在预训练过程中将事实知识外化到外部数据库，而不是将其记忆化。这种方法通过战略性地从训练损失中屏蔽外部检索到的事实值，使模型学会进行目标检索而不是依赖内存。实验表明，LMLMs在标准基准上的性能与显著更大的语言模型（LLM）相当，同时具有明确、可编辑和可验证的知识库的优点。
### Conclusion
该研究提出的有限记忆语言模型在性能上与大得多的语言模型相当，但在知识上具有更大的灵活性和可验证性，为知识库的明确表示和可编辑性铺平了道路。
## 368. `cs.CL` - EconWebArena:在实际网络环境中对经济任务进行自主代理基准测试 [PDF](https://arxiv.org/pdf/2506.08136), [HTML](https://arxiv.org/abs/2506.08136)
### Authors
Zefang Liu,Yinzhu Quan
### Background
目前，大多数评估自主代理的基准通常基于简单的数据集或受限的环境。EconWebArena的目标是在复杂且多模态的经济任务中，评估代理在现实网络环境中的表现。该基准涵盖了82个权威网站上涉及宏观经济、劳动力、金融、贸易和公共政策等领域的360个精心策划的任务。
### Innovation
EconWebArena的创新之处在于通过多种大型语言模型生成候选任务，并进行严格的人类筛选，确保任务的清晰性、可行性和数据来源的可靠性。该基准特别强调对权威数据源的忠实性和基于实际网页的经济推理需求。相比之前的工作，EconWebArena不仅评估了代理在单一维度的表现，还分析了视觉接地、计划推理和交互设计等方面的影响。
### Conclusion
EconWebArena的结果揭示了自主代理在经济网络任务中的显著性能差距，并指出了解决问题的主要挑战，如对接地、导航和多模态理解的持久性挑战。EconWebArena为经济网络智能提供了一个严格的测试平台。
## 369. `cs.CL` - 同一种评估，更多的令牌：大规模语言模型用于机器翻译评估时输入长度的影响 [PDF](https://arxiv.org/pdf/2505.01761), [HTML](https://arxiv.org/abs/2505.01761)
### Authors
Tobias Domhan,Dawei Zhu
### Background
准确评估机器翻译文本仍然是一个长期存在的挑战，尤其是在处理长文档时。近期研究表明，大型语言模型（LLMs）可以通过MQM错误跨度注释作为可靠且可解释的句子级翻译评估工具。随着现代LLMs支持更大的上下文窗口，一个自然的问题是：我们是否可以将整篇文档的翻译输入到LLM中进行质量评估？理想情况下，评估应该是文本长度不变的，可以产生一致的错误跨度，不依赖输入的粒度。然而，我们的分析发现，文本长度显著影响了评估结果：较长的文本会导致错误跨度减少，系统排名准确性下降。为了克服这一限制，我们评估了几种策略，包括粒度对齐提示、焦点句子提示（FSP）以及微调方法，以更好地使LLMs与评估任务对齐。后两种方法大大缓解了这种长度偏差，使LLMs更适合长文本形式的翻译评估。
### Innovation
研究提出并评估了几种策略，包括粒度对齐提示、焦点句子提示（FSP）以及微调方法，以解决大型语言模型在机器翻译评估中对文本长度的偏见问题。特别地，这三种方法在很大程度上减缓了这种长度偏差，使得大规模语言模型更适合长文本形式的翻译评估。
### Conclusion
该研究通过分析发现，较长的文本会导致错误跨度减少和系统排名准确性下降，提出了粒度对齐提示、焦点句子提示（FSP）以及微调方法来解决这一问题，提高了大规模语言模型在长文本形式翻译评估中的可靠性和效率。
## 370. `cs.CL` - 相同的任务，不同的电路：拆解VLMs中模态特定机制 [PDF](https://arxiv.org/pdf/2506.09047), [HTML](https://arxiv.org/abs/2506.09047)
### Authors
Yaniv Nikankin,Dana Arad,Yossi Gandelsman,Yonatan Belinkov
### Background
视觉语言模型（VLMs）能够对视觉输入（例如，图像中的物体计数）做出高质量的回答。然而，它们在处理类似任务时，文本方面的准确性要更高（例如，单词计数）。本文通过识别和比较不同模态下的特定任务计算子图来研究这种准确性差距。
### Innovation
文章通过研究视觉和文本数据之间的电路差异，指出尽管电路在不同模态之间差异较大，但实际实现的功能相似，区别主要在于处理模态特定的数据位置。实验通过将视觉数据令牌的表示从后期层回贴到早期层，显著缩小了不同模态之间的性能差距。
### Conclusion
本文的研究揭示了VLMs中模态性能差距，并提出了一种无需训练的减少这种差距的方法。
## 371. `cs.CL` - 当大型语言模型在判断共情交流方面可靠时 [PDF](https://arxiv.org/pdf/2506.10150), [HTML](https://arxiv.org/abs/2506.10150)
### Authors
Aakriti Kumar,Nalin Poungpeth,Diyi Yang,Erina Farrell,Bruce Lambert,Matthew Groh
### Background
大型语言模型在生成基于文本的对话中的共情响应方面表现出色。然而，它们在判断共情交流的细微差别方面有多可靠呢？本文通过比较心理学、自然语言处理和通信领域的专家、群众工作者和大型语言模型对200个真实世界对话的标注来研究这个问题。这些对话中一方分享个人问题，另一方提供支持。
### Innovation
本文通过在四个评估框架中比较三个不同群体（专家、群众工作者、大型语言模型）的标注，评估了他们之间的跨评定者可靠性。研究发现，专家在不同框架中的共识程度因框架的清晰度、复杂性和主观性而异。专家共识为解读大型语言模型的表现提供了更有信息量的基准，而不仅仅是标准分类指标。
### Conclusion
在所有四个框架中，大型语言模型始终接近专家基准水平，并超过群众工作者的可靠性。这些结果表明，当大型语言模型经过特定任务的恰当基准验证时，它们可以支持情感敏感应用（如作为对话伴侣）中的透明度和监管。
## 372. `cs.CL` - 我在忠实地说出我想说的话吗？在大型语言模型的神经活动与其自我解释之间架起桥梁 [PDF](https://arxiv.org/pdf/2506.09277), [HTML](https://arxiv.org/abs/2506.09277)
### Authors
Milan Bhan,Jean-Noel Vittaut,Nicolas Chesneau,Sarath Chandar,Marie-Jeanne Lesot
### Background
大型语言模型（LLMs）可以生成可信的自然语言自我解释来验证它们的答案，但是这些解释可能并不能准确反映模型的实际推理过程，这显示出缺乏忠实性。现有忠实性评估方法主要依赖于行为测试或计算块分析，但并未检查内部神经表示的语义内容。
### Innovation
该论文提出了一个灵活框架——NeuroFaith，通过识别解释中的关键概念并检查这些概念是否实际影响模型预测来测量LLM自由文本自我解释的忠实性。该方法展示了在2级推理和分类任务中的灵活性，并开发了一个基于NeuroFaith的线性忠实性探针，以检测不忠实的自我解释并改进忠实性。NeuroFaith提供了一种评估和增强LLM自由文本自我解释忠实性的原则性方法，以满足值得信赖的人工智能系统的需求。
### Conclusion
NeuroFaith提供了一种原则性的方法来评估和提高大型语言模型自由文本自我解释的忠实性，解决了值得信赖的人工智能系统关键需求。
## 373. `cs.CL` - 幽默生成综述：数据集、评估和方法 [PDF](https://arxiv.org/pdf/2507.04793), [HTML](https://arxiv.org/abs/2507.04793)
### Authors
Yuchen Su,Yonghua Zhu,Ruofan Wang,Zijian Huang,Diana Benavides-Prado,Michael Witbrock
### Background
幽默生成旨在创造性地修改文本中的语言元素以产生幽默或引发多重含义。它还旨在保持一致性和上下文适切性，使其在各种媒体和情境下的创造性写作和娱乐中具有重要价值。尽管在计算语言学中已认真对待幽默生成，但目前尚无系统综述专门梳理这一特定领域。为了弥合这一空白，本文提供了跨不同阶段的幽默生成数据集和方法的全面综述，包括传统方法、深度学习技术和预训练语言模型。此外，我们还总结了用于评估幽默生成质量的自动化评价和人类评价指标。最后，我们讨论了研究挑战，并提出了未来工作的有希望的方向
### Innovation
本文提供了对幽默生成数据集和方法的全面综述，涵盖了传统方法、深度学习技术和预训练语言模型，同时还总结了评估幽默生成质量的自动化和人类评价指标，填补了相关领域的空白
### Conclusion
本文认为，幽默生成领域存在诸多研究挑战，并提出了未来工作的潜在方向。
## 374. `cs.CL` - 提示决定了人（格）：大型语言模型中社会人口统计学提示的系统评估 [PDF](https://arxiv.org/pdf/2507.16076), [HTML](https://arxiv.org/abs/2507.16076)
### Authors
Marlene Lutz,Indira Sen,Georg Ahnert,Elisa Rogers,Markus Strohmaier
### Background
近年来，人物提示（persona prompting）在大型语言模型（LLMs）中被广泛使用，以模拟各种社会人口学群体的观点。然而，提示的具体形式会对结果产生显著影响，引起了人们对这些模拟真实性的担忧。本研究通过使用五种开源LLM，系统地评估了不同的人物提示策略，包括角色采用格式和人口统计学激发策略，如何影响大型语言模型在15个交叉人口统计学群体中的模拟表现。
### Innovation
本研究首次全面地评估了各种人物提示策略对大型语言模型中模拟不同社会人口学群体效果的影响。研究选择了五种开源LLM，考察了在开放和封闭任务中，不同的人格提示策略如何影响大型语言模型的模拟效果。研究结果表明，提示的格式和人口统计学激发策略对大型语言模型模拟表现有显著影响，特别是采用面试形式的提示和基于名字的激发策略有助于减少刻板印象并提高一致性。
### Conclusion
我们的研究表明，大型语言模型在模拟边缘群体时存在困难，但人口统计学激发和角色采用策略的选择对其表现至关重要。我们发现，采用面试形式的提示和基于名字的激发可以减少刻板印象并改善一致性。令人惊讶的是，较小的模型如OLMo-2-7B的表现优于更大的模型如Llama-3.3-70B。研究结果为如何设计基于大型语言模型的人口统计学人物提示提供了实用的指导。
## 375. `cs.CL` - 三元多对话者 speeches 活动投影用于对话系统中的轮流发言 [PDF](https://arxiv.org/pdf/2507.07518), [HTML](https://arxiv.org/abs/2507.07518)
### Authors
Mikey Elmers,Koji Inoue,Divesh Lala,Tatsuya Kawahara
### Background
轮流发言是口语对话的基本组成部分，然而传统的研究大多集中在双人场景上。本文关注将语音活动投影（VAP）应用于预测三元多边场景中的后续轮流发言。VAP模型的目标是利用仅声学数据预测每个发言人的未来活动。这是首次将VAP扩展到三元对话中。
### Innovation
本文第一次将VAP应用到三元对话场景中，通过在日本三元对话数据集上训练多个模型，演示了VAP在三元对话场景中可以用于轮流发言。研究表明，三元对话训练的VAP模型在所有模型中均优于基线，但对话类型会影响准确性。
### Conclusion
本文建立了VAP可以用于三元对话场景中的轮流发言。未来的研究将包括将此三元VAP轮流发言模型整合进口语对话系统中。
## 376. `cs.CL` - 语言模型能处理非格里高利历吗？ [PDF](https://arxiv.org/pdf/2509.04432), [HTML](https://arxiv.org/abs/2509.04432)
### Authors
Mutsumi Sasaki,Go Kamoda,Ryosuke Takahashi,Kosuke Sato,Kentaro Inui,Keisuke Sakaguchi,Benjamin Heinzerling
### Background
语言理解和推理是语言模型的重要能力。尽管此前已有相关研究分析并提升了语言模型的时间推理能力，但大多数研究仅限于格里高利历。然而，许多非格里高利历系统，如日本历、希吉历和希伯来历，在实际中广泛应用并承载了文化特定的时间观念。现有的语言模型是否能够准确处理这些非格里高利历系统尚未得到评估。
### Innovation
本研究设计并评估了一系列需要用到时间知识和推理能力的任务的语料库，系统地探讨了开源语言模型处理日本历的能力。研究发现某些模型可以进行日历转换，但即使是以日本为中心的语言模型也难以进行日本历的算术运算，且难以保持不同历法之间的一致性。研究结果强调需开发更适应文化特定日历理解的语言模型。
### Conclusion
本研究结果突显了开发更好适应特定文化日历理解的语言模型的重要性。
## 377. `cs.CL` - 大型语言模型中的查询级不确定性 [PDF](https://arxiv.org/pdf/2506.09669), [HTML](https://arxiv.org/abs/2506.09669)
### Authors
Lihu Chen,Gerard de Melo,Fabian M. Suchanek,Gaël Varoquaux
### Background
大型语言模型（LLMs）需要意识到它们知识的边界，区分它们可以自信回答的问题与超出其能力的问题。这种意识使模型能够进行适应性推理，如使用检索增强生成（RAG）、进行缓慢而深入的思考，或者在适当的时候避免回答。这些机制对于开发高效且值得信赖的AI至关重要。目前，通过估算模型在生成任何令牌之前是否能够回答给定查询来检测知识边界的方法是必要的，从而避免生成成本。
### Innovation
本文提出了一种名为Internal Confidence的新方法，这是一种无需训练的查询级不确定性检测方法，利用各层和各令牌的自我评估来提供可靠的不确定信号。实证研究表明，相较于几种基线模型，Internal Confidence在确保不确定性质量的同时，具有较低的计算成本。此外，作者还展示了它在适应性推理设置下的优势，该方法在RAG和模型级联中减少推理成本的同时，保持了整体性能。
### Conclusion
研究结果表明，基于Internal Confidence的方法在多种事实性问题回答任务和数学推理任务上表现出色，不仅能够更准确地估计不确定性，计算成本也低，能够在适应性推理场景中减少推理成本，而不影响整体性能。因此，该方法为开发更具适应性和成本效益的AI提供了新的思路。
## 378. `cs.CL` - Quantum-RAG和PunGPT2：推进旁遮普语资源有限的语言生成和检索 [PDF](https://arxiv.org/pdf/2508.01918), [HTML](https://arxiv.org/abs/2508.01918)
### Authors
Jaskaranjeet Singh,Rakesh Thakur
### Background
尽管大型语言模型（LLMs）取得了快速进步，低资源语言仍在自然语言处理（NLP）领域被排除在外，这限制了数百万人的数字访问。本文旨在通过开发适用于旁遮普语的生成模型，增强低资源语言的NLP能力，以提高旁遮普语在数字环境中的可用性和访问性。
### Innovation
本文创新地提出了Quantum-RAG，这是首个基于量子启发式检索的稀疏、密集和量子核嵌入融合的检索增强框架，能够高效实现上下文感知检索且占用较低内存。此外，还引入了PunGPT2，一个完全开源的旁遮普语生成模型套件，以及Pun-Instruct、Pun-RAG等一系列旁遮普语模型，这些模型能够支持摘要、翻译和问答等任务，并显著优于现有的多语言基线模型。
### Conclusion
本文提出的模型在FLORES-200、IndicGenBench和新创建的PunjabiEval评测集上取得了优于多语言基线模型（如mBERT、mT5、MuRIL、BLOOM）的表现。PunjabiEval基准测试中，Quantum-RAG相比FAISS的召回率提高了7.4%，相比mT5的BLEU分数提高了3.5%。通过发布所有训练脚本、超参数、评估管道、35GB旁遮普语语料库以及所有模型权重，本文为旁遮普语语言生成和检索设立了新的最先进的结果标准。
## 379. `cs.CL` - PropRAG：基于命题路径的束搜索来指导检索 [PDF](https://arxiv.org/pdf/2504.18070), [HTML](https://arxiv.org/abs/2504.18070)
### Authors
Jingjin Wang,Jiawei Han
### Background
检索增强生成（RAG）已成为为大型语言模型（LLMs）配备最新知识的标准方法。然而，依赖于独立段落检索的标准RAG方法往往无法捕捉到复杂多跳推理所需的相互连接的信息。尽管结构化RAG方法试图通过从三元组构建知识图来解决此问题，但三元组中固有的上下文损失（上下文崩溃）限制了知识表示的准确性。
### Innovation
研究人员引入了PropRAG，这是一种新型RAG框架，它从三元组转向富含上下文的命题，并引入了一个高效且无需语言模型的在线束搜索，以发现多步推理链。通过结合更准确的知识表示和显式的路径发现，PropRAG在2Wiki、HotpotQA和MuSiQue上达到了最先进的零样本Recall@5和F1分数，从而通过更丰富表示和高效的推理路径发现增强了无参知识整合。
### Conclusion
PropRAG实现了在2Wiki、HotpotQA和MuSiQue上的最先进的零样本Recall@5和F1分数，通过更丰富表示和高效的推理路径发现推进了无参知识整合。
## 380. `cs.CL` - 当长的有助于短的：监督微调中的上下文长度如何影响大型语言模型的行为 [PDF](https://arxiv.org/pdf/2509.18762), [HTML](https://arxiv.org/abs/2509.18762)
### Authors
Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen
### Background
大规模语言模型（LLMs）在自然语言处理（NLP）任务上取得了显著表现。随着实际应用对更长上下文窗口的需求增加，通过长上下文数据继续预训练和监督微调（SFT）成为了常见的方法。尽管已经深入研究了继续预训练中的数据长度效应，但对于微调中的数据长度影响依然不明确。本研究系统探讨了微调数据长度如何影响LLM在短上下文任务上的行为。
### Innovation
研究发现，与通常观察到的从长上下文预训练的性能下降不同，长上下文SFT实际上可以提升短上下文任务的性能。研究者首先解析和分析了多头注意力（MHA）和前馈网络（FFN）两个关键组件，显示它们都从长上下文SFT中获益。此外，研究揭示了一种知识偏好偏差：长上下文SFT促进上下文知识，而短上下文SFT偏向于参数知识，因此仅依赖长上下文SFT是次优的。研究最后表明，混合训练可以缓解这种偏差，为LLM的微调提供可解释的指导。
### Conclusion
研究结果表明，虽然长上下文预训练可能导致性能下降，但长上下文SFT可以提升短上下文任务的性能。研究还揭示了上下文长度对SFT的不同影响，并提出混合训练可以优化LLM的性能。
## 381. `cs.CL` - RephQA: 评估大型语言模型在公共卫生问答中的可读性 [PDF](https://arxiv.org/pdf/2509.16360), [HTML](https://arxiv.org/abs/2509.16360)
### Authors
Weikang Qiu,Tinglin Huang,Ryan Rullo,Yucheng Kuang,Ali Maatouk,S. Raquel Ramos,Rex Ying
### Background
大型语言模型（LLMs）在解决复杂的医学问题方面具有潜力。然而，大多数先前的研究集中在提高准确性和推理能力上，而在开发有效的医疗保健代理方面的一个重要瓶颈在于LLM生成的回答的可读性问题，特别是这些问题是否能够在不涉及医学背景的人们之间清晰、简单地传达公共卫生信息。现有工作引入了RephQA，这是一个用于评估LLM在公共卫生问答中可读性的基准。该基准包含来自27个来源的13个主题下的533个专家审核的答案-问题对，并包含了评估信息性和可读性的两个指标：Flesch-Kincaid年级水平和专业评分。研究发现，大多数LLM未能达到可读性标准，表明在推理和有效的沟通之间存在差距。
### Innovation
提出了RephQA基准，这是一个用于评估大语言模型在公共卫生问题回答中可读性的基准。它包含了533个专家审核的问题-答案对，并用了两个可读性指标：Flesch-Kincaid年级水平和专业评分。此外，探索了四种可读性增强策略（标准提示、链式思考提示、Group Relative Policy Optimization (GRPO)，以及一个针对标记的变体）。其中，标记优化的GRPO（Token-adapted GRPO）取得了最佳效果，从而推进了更实用和用户友好的公共卫生代理的发展。这些结果代表了朝着构建更实用的公共卫生代理方向迈出的一步。
### Conclusion
这些结果表明，大多数大语言模型未能满足可读性标准，揭示了在推理和有效沟通之间存在差距。针对这个问题，提出了一些可读性增强策略，并发现针对标记的GRPO变体效果最好，有助于开发更实用和用户友好的公共卫生代理。这项工作为多模态代理的下一步研究提供了基础支持。
## 382. `cs.CL` - 通过比较实现更好效果：基于检索的对比推理在自动提示优化中的应用 [PDF](https://arxiv.org/pdf/2509.02093), [HTML](https://arxiv.org/abs/2509.02093)
### Authors
Juhyeon Lee,Wonduk Seo,Hyunjin An,Seunghyun Lee,Yi Bu
### Background
自动提示优化最近成为提高大型语言模型（LLMs）所使用的提示质量的有效策略，目的是生成更准确和有用的响应。然而，大多数先前的工作集中在直接调整提示或模型微调上，忽视了利用LLMs的内在推理能力从对比实例中学习的潜力。现有的方法主要关注直接改进提示或模型微调，而忽略了通过对比方式利用模型内在的推理能力。本研究旨在通过引入一种新的框架来破解这一局限性。
### Innovation
提出了一种名为CRPO（Contrastive Reasoning Prompt Optimization）的新框架，将提示优化形式化为一个检索增强的推理过程。CRPO通过检索HelpSteer2数据集中有助于推理的提示-响应对，并提出两种互补的优化方法：层级对比推理和多尺度对比推理，从而解决了直接提示优化或模型微调的问题。层级对比推理通过高、中、低质量的示例相互对比，模型进行反思推理以改进自身的生成。而多尺度对比推理则通过分析每个评价维度的最佳示例并整合它们的优势来优化提示。这种明确的高质量与低质量对比展示了CRPO如何帮助模型理解哪些提示成功而哪些失败，从而实现更稳健和可解释的优化。实验结果显示，CRPO显著优于基线模型。
### Conclusion
CRPO框架在自动提示优化中展示出的优越性能表明，对比、检索增强的推理策略在自动提示优化中具有很大的潜力，可进一步推动该领域的进步。
## 383. `cs.CL` - jina-reranker-v3：在列表文档重新排名中的‘最后但同样重要’交互 [PDF](https://arxiv.org/pdf/2509.25085), [HTML](https://arxiv.org/abs/2509.25085)
### Authors
Feng Wang,Yuqing Li,Han Xiao
### Background
该论文介绍了一种名为jina-reranker-v3的0.6B参数多语言列表级重新排名模型。该模型引入了一种新颖的“最后但同样重要”的交互方式，以区别于如ColBERT等较晚的交互模型。ColBERT在进行多向量匹配之前分别编码文档。不同于这种做法，jina-reranker-v3模型在同一上下文窗口中对查询与候选项文档施加因果注意力，从而在提取每个文档最终令牌的上下文嵌入之前进行丰富的交互过程。该模型在BEIR基准测试中达到了61.94的nDCG@10最佳性能，同时其大小明显小于具有相似性能的其他模型。
### Innovation
该研究的创新在于提出了“最后但同样重要”的交互方式，并将查询与所有候选文档在同一个上下文窗口中进行因果注意力处理，从而在提取每个文档最终令牌的上下文嵌入之前进行丰富的交互过程。这种方法使得模型在保持较小参数量的同时实现了出色的性能，优于其他具有相似性能的大型模型。
### Conclusion
jina-reranker-v3模型在列表文档重新排名任务中取得了优于现有模型的性能（61.94 nDCG@10），并且大小仅0.6B参数，显示出在多语言环境中进行文档重新排序的潜在效率和鲁棒性。
## 384. `cs.CL` - 大规模语言模型自我解释的冗余权衡与规模对准确性的影 [PDF](https://arxiv.org/pdf/2503.13445), [HTML](https://arxiv.org/abs/2503.13445)
### Authors
Noah Y. Siegel,Nicolas Heess,Maria Perez-Ortiz,Oana-Maria Camburu
### Background
研究发现，当要求大规模语言模型（LLMs）解释其决策时，它们所给出的解释有时听起来是合理的。然而，这些解释是否确切反映了实际导致决策的因素呢？因此，本研究分析了75个不同系列的13个家族模型的对抗性忠实性，探讨了简洁性和全面性之间的权衡关系、相关性忠实性度量如何评估这种权衡关系以及这些度量的可操纵性。这项研究揭示了明确的规模梯度趋势：规模更大且能力更强的模型在所有考虑的指标上都表现出更高的忠实性。
### Innovation
提出了两种新的度量指标：简化版本的相关性反事实测试（phi-CCT），它避免了对词元概率的依赖但仍能解释大部分原始测试的方差；及FAUROC，它可以消除对不平衡干预分布的敏感性，并捕捉到模型产生不同详细程度解释的能力。
### Conclusion
研究发现，在所有评估的指标上，更大且功能更强大的模型表现出更准确的解释。研究的代码可以在提供的链接处获取。
## 385. `cs.CL` - 加速可学习并行解码的大规模语言模型扩散 [PDF](https://arxiv.org/pdf/2509.25188), [HTML](https://arxiv.org/abs/2509.25188)
### Authors
Wenrui Bao,Zhiben Chen,Dan Xu,Yuzhang Shang
### Background
现有的大型语言模型（LLMs）通过自回归方式解码，需要$text{O}(n)$的顺序步长来进行$n$个标记的解码，这极大地限制了推理吞吐。尽管最近的基于扩散的大规模语言模型（dLLMs）可以通过迭代去噪实现并行标记生成，但当前的并行解码策略依赖于固定的、输入无关的启发式方法（例如，置信阈值），这不能适应输入的特殊特性，使得在不同NLP任务上的速度和质量权衡效果不佳。
### Innovation
提出了一种更灵活和动态的并行解码方法，即Learning to Parallel Decode (Learn2PD)。这种方法训练了一个轻量级且自适应的滤波模型，在每次标记位置预测当前预测是否与最终输出匹配。该学习滤波器近似了一个理想的并行解码策略，仅在正确预测时才揭开标记。此外，该滤波器模型在后训练阶段学习，只需少量计算即可优化。同时引入了End-of-Text Prediction (EoTP)来在序列结束时检测解码完成，避免了对填充标记的冗余解码。实验证明，在LLaDA基准上，我们的方法在没有任何性能损失的情况下可实现最高22.58倍的速度提升，结合KV-Cache后可提升到57.51倍。
### Conclusion
通过Learn2PD方案，我们的方法实现了大规模语言模型速度的显著提升，同时保持或提高了模型性能。
## 386. `cs.CL` - GPT与偏见：理解大型语言模型中学习表示的稀疏方法 [PDF](https://arxiv.org/pdf/2510.01252), [HTML](https://arxiv.org/abs/2510.01252)
### Authors
Mariam Mahran,Katharina Simbeck
### Background
随着大型语言模型（LLMs）越来越多地在大量未经筛选的数据集上进行训练，理解模型表示以及数据中存在的结构、主题和偏差已成为一个重要挑战。本文展示了一种方法，通过将LLMs与稀疏自编码器（SAEs）相结合，不仅可以解释模型行为，还可以解释训练数据中嵌入的深层结构、主题和偏差。研究者使用了一种类似于GPT的变压器模型，专门训练于简·奥斯汀的小说集，这一体量丰富的文本集包含了大量的社会构造和叙述模式。
### Innovation
本文创新点在于提出了使用稀疏自编码器（SAEs）与GPT-style变压器模型结合的方法，可以解释大型语言模型内部结构和训练数据中的深层信息，揭示出稀疏理解模型的关键叙述和概念，并探索命名偏见和模型中的偏差，进而作为大规模数据集探针，提供新的路径进行语料库探索、偏见发现和模型解释度量.
### Conclusion
本文的结论是，结合稀疏自编码器（SAEs）的大型语言模型可以在保持可扩展性的前提下，作为一个规模化的探针工具，用于复杂数据集的探索、偏差发现和模型解释度量。这为语言模型的理解提供了新的路径，并有助于揭示训练数据中存在的潜在偏见。
## 387. `cs.CL` - 使用奖励模型增强大型语言模型推理：一种分析性综述 [PDF](https://arxiv.org/pdf/2510.01925), [HTML](https://arxiv.org/abs/2510.01925)
### Authors
Qiyuan Liu,Hao Xu,Xuhong Chen,Wei Chen,Yee Whye Teh,Ning Miao
### Background
奖励模型（RMs）对增强大型语言模型（LLMs）的推理性能起到了关键作用。它们可以提供训练信号以在强化学习（RL）期间微调LLMs，并在推理阶段从多个候选答案中选择最佳答案。本文提供了一种系统性的RMs介绍，并对它们在LLMs推理中的应用进行了全面的综述。首先回顾了RMs的基本概念，包括其架构、训练方法和评估技术。然后探索了它们的关键应用领域：（1）在LLMs推理期间引导生成和选择最优输出；（2）促进数据合成和LLMs的迭代自我改进；（3）在基于RL的微调期间提供训练信号。最后，基于现有研究和自身的实证发现，讨论了关于RMs选择、泛化、评估和增强的关键问题。分析旨在为有效部署和推进RMs在LLMs推理中的应用提供实用见解。
### Innovation
提供了一种系统性的RMs介绍，并对它们在LLMs推理中的关键应用领域进行了全面综述。基于现有研究和自身的实证发现，讨论了关于RMs选择、泛化、评估和增强的关键问题，旨在为有效部署和推进RMs在LLMs推理中的应用提供实用见解。
### Conclusion
分析旨在为有效部署和推进RMs在LLMs推理中的应用提供实用见解。
## 388. `cs.CL` - PrisonBreak：使用至多二十五个目标位翻转劫持大型语言模型 [PDF](https://arxiv.org/pdf/2412.07192), [HTML](https://arxiv.org/abs/2412.07192)
### Authors
Zachary Coalson,Jeonghyun Woo,Chris S. Lin,Joyce Qu,Yu Sun,Shiyang Chen,Lishan Yang,Gururaj Saileshwar,Prashant Nair,Bo Fang,Sanghyun Hong
### Background
研究发现，商业规模的安全对齐大型语言模型（LLMs）存在一个新的漏洞：通过翻转少量的模型参数位，可以使其停止生成有害响应。此攻击利用仅需5到25个位翻转即可破解包含数亿参数的语言模型，所需位翻转数量最多可减少40倍于先前对小型计算机视觉模型的攻击。与基于提示的劫持方法不同，该方法能在运行时直接使模型在内存中去获得解释，从而无需进行输入级别的修改即可产生有害输出。
### Innovation
本文的关键创新是在语言模型劫持中开发了一种高效的位选择算法，该算法相比先前方法，可识别关键位并提高20倍的速度。此外，介绍了通过基于Rowhammer的故障注入实现端到端利用的方法，能够在GDDR6 GPU上成功劫持5个模型，成功率从69%到91%。
### Conclusion
分析表明：（1）弱后训练对齐的模型更易于劫持；（2）某些模型组件，例如价值投影层，更为脆弱；（3）该攻击方法与现有的劫持方法机制不同。评估了潜在的防御措施，但发现即使在LLM管道的不同阶段也有有效的防御措施也难以阻止攻击。
## 389. `cs.CL` - Agent-ScanKit：通过敏感扰动剖析多模态代理的记忆与推理 [PDF](https://arxiv.org/pdf/2510.00496), [HTML](https://arxiv.org/abs/2510.00496)
### Authors
Pengzhou Cheng,Lingzhong Dong,Zeng Wu,Zongru Wu,Xiangru Tang,Chengwei Qin,Zhuosheng Zhang,Gongshen Liu
### Background
尽管最近提出了许多策略来增强图形用户界面（GUI）中多模态代理的自主交互能力，但在面对复杂或领域外任务时，其可靠性仍然有限。现有的多模态代理是否在虚伪推理？为了解答这个问题，本文提出了一种名为Agent-ScanKit的系统探针框架，用于在受控扰动下探究多模态代理的记忆和推理能力。在五个公开可用的GUI基准测试中，涉及18个不同模型的结果显示，机械记忆通常超过了系统推理作用，这些模型大多作为与训练对齐的知识检索器运行，展现出有限的泛化能力。
### Innovation
本文提出了Agent-ScanKit，这是一种系统探针框架，用于在受控扰动下揭示多模态代理的记忆和推理能力。通过三种不同的探针范式：视觉引导、文本引导和结构引导，可以量化记忆和推理的贡献，而无需访问模型内部信息。在五个多模态代理基准测试中，结果显示机械记忆通常超过系统推理，模型大多运行为知识检索器，表现出有限的泛化能力。
### Conclusion
我们的发现强调了在实际场景中为多模态代理改进坚实推理建模的必要性，并提供了开发可靠多模态代理的宝贵见解。
## 390. `cs.CL` - 利用在线数据改进小规模波斯语医疗语言模型 [PDF](https://arxiv.org/pdf/2505.16000), [HTML](https://arxiv.org/abs/2505.16000)
### Authors
Mehrdad Ghassabi,Pedram Rostami,Hamidreza Baradaran Kashani,Amirhossein Poursina,Zahra Kazemi,Milad Tavakoli
### Background
语言模型的快速发展展示了人工智能在医疗行业的潜力。然而，小型语言模型在低资源语言如波斯语的专业领域表现不佳。尽管存在许多波斯语的医疗领域网站，但尚未有经过整理的数据集或语料库，因此本文首次引入了一个新整理的数据集，包含2万个医生-病人问答对和从医疗杂志抓取的9000万词语料库的60%。
### Innovation
使用参数高效微调方法，增强基础模型aya-expanse-8b的医疗知识。微调模型在医疗问答任务中的准确性得到了提高，并通过了2023年9月的伊朗基本医学科学入学考试（IBSEE），而基线模型未能通过。此外，微调模型将波斯语翻译的MMLU准确性平均提高了2.67%。这项工作强调了利用开放访问的在线数据来丰富小型医疗语言模型的可能性，为资源受限的环境中波斯语医疗AI应用提供了一个新颖的解决方案。
### Conclusion
这项工作展示了利用在线数据改进小规模波斯语医疗语言模型的潜力，提供了适合资源受限环境的在波斯语医疗AI应用的新解决方案。未来的研究可以探索多模态输入以进一步提高性能。
## 391. `cs.CL` - MarketSenseAI 2.0: 通过LLM代理增强股票分析 [PDF](https://arxiv.org/pdf/2502.00415), [HTML](https://arxiv.org/abs/2502.00415)
### Authors
George Fatouros,Kostas Metaxas,John Soldatos,Manos Karathanassis
### Background
MarketSenseAI 是一种利用大型语言模型（LLMs）处理金融市场、历史价格、公司基本面和宏观经济环境的新颖框架，支持股票分析和选择中的决策制定。本文介绍了MarketSenseAI的最新进展，得益于大规模语言模型技术的迅速扩展，该框架通过检索增强生成和LLM代理的新型架构，能够处理SEC文件和业绩电话会议，并通过系统处理各类机构报告来丰富宏观经济分析。实验结果显示显著提升了基本面分析的准确性。在2023-2024年期间，MarketSenseAI在S&P 100股票上实现了125.9%的累积回报率，而指数回报率为73.5%，且保持了相似的风险水平。2024年，MarketSenseAI在S&P 500股票上的Sortino比率比市场高出33.8%。这项工作标志着将大规模语言模型技术应用于金融分析方面的一个重要进步，展示了LLM驱动的投资策略的稳健性。
### Innovation
1. 通过检索增强生成和LLM代理的新型架构处理SEC文件和业绩电话会议；2. 通过系统处理各类机构报告丰富宏观经济分析；3. 实现显著提升基本面分析的准确性；4. 在S&P 100股票上实现了125.9%的累积回报率，与市场回报率73.5%相比，保持相似的风险水平；5. 在S&P 500股票上的Sortino比率比市场高出33.8%，展示了其可扩展性。
### Conclusion
这项工作标志着应用大规模语言模型技术进行金融分析的一个重要进步，提供了关于LLM驱动的投资策略稳健性的见解。
## 392. `cs.CL` - 从TOWER到SPIRE：在文本仅模型中增加语音模态 [PDF](https://arxiv.org/pdf/2503.10620), [HTML](https://arxiv.org/abs/2503.10620)
### Authors
Kshitij Ambilduke,Ben Peters,Sonal Sannigrahi,Anil Keshwani,Tsz Kin Lam,Bruno Martins,André F.T. Martins,Marcely Zanon Boito
### Background
本文介绍了Spire，这是一种融合了语音输入处理能力的语言模型，能够将英语语音输入翻译或转录成其他10种语言，并且还能在双向翻译文本输入方面发挥作用。该模型将语音模态集成到现有的多语言模型中，仅使用了42.5万小时的语音数据，通过文本离散化和持续预训练实现。
### Innovation
本文的主要创新在于，采用了一种在多语言模型中通过离散化语音输入增加语音处理能力的方法。这种方法不仅赋予了模型语音理解和生成的能力，还保留了其强大的文本基础性能。相较于现有语音模型，本文方法的数据使用量显著减少，证明了在语言模型适应过程中作为额外语言集成离散化语音输入是可行的。
### Conclusion
本文通过显著减少数据量实现了在文本仅语言模型中集成离散化语音输入，并展示了这种方法的有效性。研究人员已将代码和模型公开，以供社区使用。
## 393. `cs.CL` - Primus: 开源数据集为网络安全大语言模型训练的先驱集合 [PDF](https://arxiv.org/pdf/2502.11191), [HTML](https://arxiv.org/abs/2502.11191)
### Authors
Yao-Ching Yu,Tsun-Han Chiang,Cheng-Wei Tsai,Chien-Ming Huang,Wen-Kwang Tsao
### Background
尽管大语言模型（LLMs）在金融、法律和医学等专门领域表现出显著的进步，但在网络安全领域，仍然缺乏公开的数据集，尤其是高质量的预训练语料库。尽管研究表明，LLMs在其预训练阶段就获得了大部分知识，现有的网络安全领域公开数据集却较为缺乏，限制了大语言模型在该领域的应用潜力。为解决这一问题，本研究提出了一个涵盖所有主要训练阶段的全面数据集套件，包括预训练、指令微调和基于网络安全特定自反数据的推理知识蒸馏。通过广泛的消融研究，这些数据集在公开的网络安全基准测试上展示了其有效性。特别是在我们的数据集上进行持续预训练可以提高整体评分15.9%，而推理知识蒸馏则使得CISSP（注册信息系统安全专家）认证的安全性评估提高了15.8%。
### Innovation
本研究创新地创建了一个为网络安全大语言模型训练设计的数据集套件，该套件全面覆盖了从预训练到指令微调再到推理知识蒸馏等所有主要训练阶段，并特别包含网络安全领域特有的自反数据。此外，通过持续预训练和推理知识蒸馏等技术，展示了显著的性能提升。研究成果将通过ODC-BY和MIT许可协议公开，以促进进一步研究并为其他研究者提供访问途径。
### Conclusion
本研究成功地创建并公开了一个网络安全语料库，该语料库特别设计用于大语言模型的训练，在网络认证考试和公共网络安全基准测试方面得到了显著改进。该语料库将促进网络安全领域的大语言模型研究，并鼓励研究人员进一步探索。
## 394. `cs.CL` - 理解偏好学习中的性能差距：RLHF与DPO的二元对比 [PDF](https://arxiv.org/pdf/2505.19770), [HTML](https://arxiv.org/abs/2505.19770)
### Authors
Ruizhe Shi,Minhak Song,Runlong Zhou,Zihan Zhang,Maryam Fazel,Simon S. Du
### Background
本文对强化学习从人类反馈（RLHF）和直接偏好优化（DPO）之间的性能差距进行了细致的理论分析，特别是在存在表示差距的情况下。作者将这一差距分解为两种来源：在精确优化下的显式表示差距以及在有限样本下的隐式表示差距。
### Innovation
研究将性能差距分解为两种来源，分别是在精确优化下的显式表示差距和在有限样本下的隐式表示差距。在精确优化情况下，分析了奖励和策略模型类的相对能力如何影响最终策略质量。特别指出，在奖励和策略模型类同构且都错构的情况下，增量DPO可以超越RLHF和标准DPO。在近似优化情况下，提供了一个具体构造，表明真实奖励是隐式稀疏的，并表明RLHF比DPO需要更少的样本来恢复有效的奖励模型，揭示了两阶段学习的统计优势。这些结果为不同情况下RLHF和DPO之间的性能差距提供了全面的理解，并提供了每种方法适用的实用见解。
### Conclusion
本文研究了在多种设置下RLHF和DPO之间的性能差距，并提供了每次方法适用的实践见解，这些见解有望引导未来的偏好学习研究和发展。
## 395. `cs.CL` - RACCooN: 具有自动生成叙述的多用途视频编辑框架 [PDF](https://arxiv.org/pdf/2405.18406), [HTML](https://arxiv.org/abs/2405.18406)
### Authors
Jaehong Yoon,Shoubin Yu,Mohit Bansal
### Background
现有的视频生成模型主要依赖于精心撰写的文本提示来执行特定任务，如补全和风格编辑。然而，这些模型需要复杂的文本描述作为输入视频，这限制了它们对个人或原始视频的灵活性和适应性。现有的方法难以满足用户对视频编辑的具体需求。因此，本文提出了一种新的统一管道，RACCooN框架，该框架通过视频到段落到视频的统一管道来支持多种视频编辑功能。RACCooN框架分为两个主要阶段：视频到段落（V2P）和段落到视频（P2V），以简化用户的视频内容编辑过程，并提高了视频内容编辑的精确度和质量。RACCooN利用了自动生成的叙述或指令来生成高质量的内容，并且还考虑了在给定视频中想象新对象的可能性，使得用户能够更灵活地编辑复杂的视频内容。
### Innovation
1. 提出了一种多粒度的时空池化策略，可以自动生成结构化良好的视频描述，同时捕捉广泛的背景和对象细节，无需复杂的手动注释，简化了基于文本的精确内容编辑。2. 将自动生成的叙述或指令整合到视频生成模型中，提高了生成内容的质量和准确性。3. 研究提出的方法能够生成详细的新视频编辑计划，使用户能够灵活地编辑复杂的视频内容。
### Conclusion
RACCooN框架在视频到段落生成、视频内容编辑方面展示了出色的多功能能力，并可以与其他先进的视频生成模型结合使用，以进一步提升视频生成效果。
## 396. `cs.CL` - Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains [PDF](https://arxiv.org/pdf/2507.17746), [HTML](https://arxiv.org/abs/2507.17746)
### Authors
Anisha Gunjal,Anthony Wang,Elaine Lau,Vaskar Nath,Yunzhong He,Bing Liu,Sean Hendryx
### Background
Reinforcement Learning with Verifiable Rewards (RLVR) has been effective for tasks with clear correctness signals, such as math and coding, but extends poorly to real-world tasks where evaluation relies on nuanced, multi-criteria judgments. Current evaluation benchmarks often use instance-specific rubrics but have not fully explored their integration as on-policy reward signals for post-training reinforcement learning.
### Innovation
Introduces Rubrics as Rewards (RaR), an on-policy reinforcement learning method that utilizes rubric-based feedback to extend RLVR into real-world reasoning tasks. Evaluates multiple strategies for aggregating rubric feedback into rewards and achieves improved performance over existing methods in health and science domains.
### Conclusion
RaR-trained policies perform well on both rubric-based and multiple-choice tasks, demonstrating strong adaptability to varied evaluation formats. Using structured rubrics as reward signals aligns policies better with smaller judges and reduces performance variance across different judge scales.
## 397. `cs.CL` - cAST: 基于抽象语法树的结构化分块增强代码检索增强生成 [PDF](https://arxiv.org/pdf/2506.15655), [HTML](https://arxiv.org/abs/2506.15655)
### Authors
Yilin Zhang,Xinran Zhao,Zora Zhiruo Wang,Chenyang Yang,Jiayi Wei,Tongshuang Wu
### Background
检索增强生成（RAG）对于大规模代码生成至关重要，通过将预测基础建立在外部代码库上提高实际性。然而，RAG 管道中的一个关键且尚未充分利用的方面是分块——将文档分割成可检索的单元的过程。现有的基于行的分块启发式方法经常破坏语义结构，导致函数的分割或无关代码的合并，从而降低生成质量。
### Innovation
本文提出了基于抽象语法树（textbf{cAST}）的分块方法，这是一种结构感知的方法，能够递归地将大型 AST 节点分解为较小的块，并合并兄弟节点同时遵守大小限制。这种方法可以产生自包含且语义一致的单元，适用于多种编程语言和任务，并在多种代码生成任务上提高了性能，例如，在 RepoEval 检索召回率 Recall@5 上提高了4.3个点，在 SWE-bench 生成上 Pass@1 上提高了2.67个点。
### Conclusion
本文的工作强调了结构感知分块对于扩展增强检索代码智能的重要性。这种方法可以生成自包含且语义一致的代码块，进而提高代码生成任务的表现。
## 398. `cs.CL` - 在LLMs的RL训练中利用树结构进行信用分配 [PDF](https://arxiv.org/pdf/2509.18314), [HTML](https://arxiv.org/abs/2509.18314)
### Authors
Hieu Tran,Zonghai Yao,Hong Yu
### Background
强化学习可以提升大型语言模型（LLM）的推理能力，但稀疏的延迟奖励和长序列使得在单个令牌级别上进行信用分配成为关键瓶颈。研究者们探讨了可验证奖励的设置，即最终答案可以进行验证，并且每个提示可以产生多个响应。数学和医学问答任务中的推理任务与此设置相匹配，只有少数决策令牌对结果有重大影响。尽管策略梯度（PPO）算法在令牌级别上具有优势并使用了学习的价值模型，但同时训练演员和评论家模型较为复杂，且不便于泛化，因为评论家模型的令牌级别值可能导致训练过度拟合。
### Innovation
本文提出了一种简单的方法P2T，将一组响应转换为前缀树，并计算非参数前缀值V(s)通过聚合后代结果。基于P2T，我们提出了一种无评论家的算法TEMPO，该算法通过树结构提供了分支门控的时间差纠正，弥补了GRPO的单一序列级别回报在整个令牌上的分配问题。在Qwen3-1.7B/4B上，TEMPO在同分布（MATH，MedQA）和异分布（GSM-HARD，AMC23，MedMCQA，MMLU-Medical）基准上优于PPO和GRPO，并且具有相似的墙钟时间得到了更高的验证准确性。
### Conclusion
我们提出了一种支持验证奖励且无评论家的算法TEMPO，并展示了其在多种任务上的优势，能够以更简单的方式处理信用分配问题。
## 399. `cs.CL` - 揭示 Unicode 隐藏于作者归 attribution 之下的一些秘密 [PDF](https://arxiv.org/pdf/2508.15840), [HTML](https://arxiv.org/abs/2508.15840)
### Authors
Robert Dilworth
### Background
当用户在公共通信渠道上进行信息发布（如社交媒体上传评或发表帖子）时，他们没有隐私期待。即使用户采取种种措施（如使用别名、屏蔽IP地址、伪造地理位置、隐藏操作系统和用户代理、部署加密、注册临时电话号码或邮箱、禁用不必要的设置、撤销权限、阻止cookies和指纹识别），其信息内容本身仍然暴露了作者身份识别的漏洞。研究表明，通过语料统计分析（即语体分析）可以识别作者，即使在采取多重防范措施后仍然存在验证用户身份的风险。
### Innovation
本文探讨了语体分析技术，讨论了对抗性语体分析的策略，并提出通过Unicode隐形编码来增强信息的匿名性。
### Conclusion
通过Unicode隐形编码，可以在不改变信息内容展示的情况下，增加信息匿名性，以此作为对抗语体分析的方法之一。
## 400. `cs.CL` - 从长视频到引人入胜的剪辑片段：具有多模态叙述理解的人类灵感视频编辑框架 [PDF](https://arxiv.org/pdf/2507.02790), [HTML](https://arxiv.org/abs/2507.02790)
### Authors
Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu
### Background
在线视频内容，特别是短视频平台上的内容快速增长，引发了对高效视频编辑技术的需求，这些技术能够将长视频浓缩成简洁具有吸引力的片段。现有的自动编辑方法主要依赖于自动语音识别（ASR）转录中的文本提示和端到端的片段选择，但经常忽视丰富的视觉上下文，导致输出不连贯。
### Innovation
本文提出了一种基于多模态叙述理解的人类启发式自动视频编辑框架（HIVE），该框架通过多模态大型语言模型来提取人物、对话分析和叙述总结，从而实现对视频内容的全面理解。为了进一步提高连贯性，该方法在镜头级别进行分割，并将编辑过程分解为三个子任务：亮点检测、开头/结尾选择和无相关内容的修剪。
### Conclusion
实验结果表明，本文提出的框架在通用和广告导向的编辑任务中均优于现有基线，显著缩小了自动编辑视频与人手工编辑视频的质量差距。
## 401. `cs.CL` - THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning [PDF](https://arxiv.org/pdf/2509.13761), [HTML](https://arxiv.org/abs/2509.13761)
### Authors
Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jun Du,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Quan Liu,Jianqing Gao
### Background
大型语言模型（LLMs）在数学推理方面取得了显著进展，但仍然在高精度任务如数值计算和形式符号操作方面存在局限性。现有的集成外部工具的方法在构建工具集成推理数据、精细层级优化和增强推理推断方面仍然面临三大挑战：
### Innovation
本文提出了THOR（Tool-Integrated Hierarchical Optimization via RL），通过三个创新点来克服现有挑战：1) 引入了TIRGen，这是一种基于多智能体演员-评论家的流水线，用于构建高质量的工具集成推理路径数据集，该数据集能够与策略对齐并在各种模型中泛化良好；2) 介绍了一种基于强化学习（RL）的策略，同时优化了集层面的问题解决和步骤层面的代码生成，这种方法的动机是因为中间工具调用的成功是最终答案正确性的强烈预测因素；3) THOR引入了自我纠正机制，利用即时工具反馈在推理过程中动态修订错误的推理路径。
### Conclusion
我们的方法在多种数学基准测试中的推理和非推理模型中都表现出强大的泛化能力，并且在多个数学基准测试中实现了同类规模模型的最新性能，同时在代码基准测试中也提供了持续改进。
## 402. `cs.CL` - Anchored Supervised Fine-Tuning [PDF](https://arxiv.org/pdf/2509.23753), [HTML](https://arxiv.org/abs/2509.23753)
### Authors
He Zhu,Junyou Su,Peng Lai,Ren Ma,Wenjia Zhang,Linyi Yang,Guanhua Chen
### Background
大型语言模型的后训练涉及监督微调（SFT）和强化学习（RL）之间的基本权衡。SFT能够高效地模仿示例，但倾向于记忆化，而RL虽然计算成本高，但在泛化性能上更优。动态微调（DFT）作为一种有望的解决方案，通过重新加权SFT目标，已在某些推理领域取得了改进，但在其他任务中表现出不稳定性。
### Innovation
本文提出了锚定监督微调（ASFT），这是一种改进了DFT重加权方法的方案，通过轻量级KL正则化来保留重加权带来的严格性同时保证训练稳定性。实验证明，ASFT在数学推理、医学知识接地和代码生成等任务上优于普通SFT和DFT，实现了显著改进且具有极小的计算开销。
### Conclusion
研究通过奖赏加权回归（RWR）框架对DFT进行了分析，揭示了它与特定的辅助分布选择对应，相较于标准SFT提供了更严格的RL界限。然而，ASFT通过保留DFT的重加权效果同时增强稳定性，实验证明其在多个任务上优于SFT和DFT，证明了理论分析的重要性在实践中的应用前景。
## 403. `cs.CL` - 来自标准多臂赌博机实验的LLMs与人类探索-利用策略比较：启示 [PDF](https://arxiv.org/pdf/2505.09901), [HTML](https://arxiv.org/abs/2505.09901)
### Authors
Ziyuan Zhang,Darcy Wang,Ningyuan Chen,Rodrigo Mansur,Vahid Sarhangian
### Background
大型语言模型（LLMs）在复杂的序列决策环境中被越来越多地用于模拟或自动化人类行为。自然的问题是LLMs是否表现出类似的人类决策行为，并且能否达到可比较的（或更优的）性能。作者关注探索-利用（E&E）权衡，这是动态决策过程中不确定性条件下的一个基本方面。通过认知科学和精神病学文献中引入的经典多臂赌博机（MAB）实验，作者对LLMs、人类和MAB算法的E&E策略进行了比较研究。使用可解释的选择模型来捕捉代理的E&E策略，并探讨通过提示策略和思考模型启用思考轨迹如何影响LLMs的决策过程。研究结果发现，允许思考的LLMs的行为趋向于更加人性化，表现为随机探索和有方向探索的混合。在简单的稳定场景中，启用了思考的LLMs在随机探索和有方向探索方面与人类表现出相似的水平。然而，在更复杂的非稳定环境中，尽管某些场景下的遗憾可以相似，LLMs仍难以匹配人类的适应性，特别是在有效的有方向探索方面。
### Innovation
作者采用了标准的多臂赌博机实验来比较LLMs和人类在探索-利用策略上的差异，这一方法在研究两个不同主体的策略方面提供了新的见解，并通过启用思考轨迹分析了LLMs的表现。这为理解LLMs在复杂环境下的人性化行为提供了新的方法。
### Conclusion
作者的研究结果突显了LLMs作为人类行为模拟器和自动化决策工具的潜力和限制，并指出了潜在的改进领域。LLMs在简单的稳定环境下的表现接近人类，在复杂的非稳定环境中，尽管可以达到类似的遗憾水平，但难以匹配人类的适应性，特别是在有效的有方向探索方面。
## 404. `cs.CV` - 探索双语视觉问答中的OCR增强生成 [PDF](https://arxiv.org/pdf/2510.02543), [HTML](https://arxiv.org/abs/2510.02543)
### Authors
JoonHo Lee,Sunho Park
### Background
研究视觉语言模型（VLMs）增强的OCR-augmented生成，专注于韩语和英语，推动多语言领域的发展。为了支持该领域的研究，我们训练并发布了KLOCR，这是一个强大的双语OCR基线，基于100M实例来增强VLMs的OCR能力。此外，为了补充现有的VQA基准，我们整理了KOCRBench用于韩语VQA，并分析了不同的提示方法。
### Innovation
研究通过在VLMs中加入OCR能力来改进双语VQA的生成。具体创新点包括：（1）构建了KLOCR，一个基于100M样本的双语OCR基线；（2）创建了KOCRBench用于韩语VQA的研究；（3）通过广泛实验发现，OCR提取的文本能够显著提升开源和商用模型的性能。
### Conclusion
我们的研究提供了关于双语VQA中OCR增强生成的新见解。模型、代码和数据可以在给定链接获取。
## 405. `cs.CL` - FinAgentBench: 金融问答中代理检索的数据集 [PDF](https://arxiv.org/pdf/2508.14052), [HTML](https://arxiv.org/abs/2508.14052)
### Authors
Chanyeol Choi,Jihoon Kwon,Alejandro Lopez-Lira,Chaewoon Kim,Minjae Kim,Juneha Hwang,Jaeseon Ha,Hojun Choi,Suyeol Yun,Yongjin Kim,Yongjae Lee
### Background
在金融领域，准确的信息检索（IR）对于投资者至关重要，他们需要从大量的文档集合中找到相关的信息。传统的方法，无论是稀疏的还是密集的，往往在检索准确性上表现不佳，因为这不仅需要捕捉到语义相似性，还需要进行细粒度的文档结构和领域知识的推理。近年来，大型语言模型（LLMs）的进步为多步骤推理检索提供了新机会，其中模型通过迭代推理来评估哪些信息对给定查询最重要来进行段落的排名。然而，目前尚无评估这类能力的基准，尤其是在金融领域。因此，为了填补这一空白，作者引入了FinAgentBench，这是第一个用于评估金融领域中代理检索（包含多步骤推理的检索）的大型基准集。该基准集涉及26000个由专家标注的例子，评估LLM代理是否能（1）在候选文档中识别最合适的信息类型，以及（2）在选定的文档中确定关键段落。评价框架明确地将这两个推理步骤分离出来，以解决上下文的限制，从而为理解金融领域的检索为中心的LLM行为提供了量化基础。
### Innovation
该基准的创新之处在于它为金融领域的多步骤代理检索提供了第一个评价工具。研究人员设计了FinAgentBench，包含数千个专家标注的实例，用于评估LLM代理能否识别最相关的信息类型及在选定文档中找到关键段落的能力。此外，该基准展示了如何通过有针对性的微调显著提升代理检索性能，从而提供了一个研究金融领域复杂、特定领域任务中检索为中心的LLM行为的基础。
### Conclusion
FinAgentBench为金融领域的复杂、特定任务中的检索为中心的LLM行为提供了研究基础，同时也为轻量化（细粒度的）问题解决了提供了一个实用的数据集。作者认为，该工作为未来的研究设定了一个新的基准，并有助于推动LLM在金融领域的应用与发展。
## 406. `cs.CL` - PRIME：嵌入检索规划的记忆以增强推理 [PDF](https://arxiv.org/pdf/2509.22315), [HTML](https://arxiv.org/abs/2509.22315)
### Authors
Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu
### Background
本文受到《思考，快与慢》中人类认知的双过程理论启发，引入了名为PRIME（Planning and Retrieval-Integrated Memory for Enhanced Reasoning）的多智能体推理框架，该框架动态整合了系统1（迅速的直观思考）和系统2（缓慢的审慎思考）。传统的大型语言模型在处理复杂、知识密集型推理任务时可能缺乏人类的效率和准确性。
### Innovation
PRIME框架通过快速生成初步答案的Quick Thinking Agent（系统1）和需要仔细推理的结构化Pipeline（系统2）相结合，多智能体设计忠实地模拟了人类的认知过程，提高了推理的效率和准确性。实验结果表明，PRIME能够使开源的大规模语言模型在需要跨步骤和基于知识的推理基准上，与最先进的封闭源模型如GPT-4和GPT-4o竞争。
### Conclusion
这项研究确立了PRIME作为解决要求复杂、知识密集型推理的领域的一种可扩展方案。PRIME框架的成功表明，通过合理利用人类认知的双过程理论，可以显著提升大型语言模型的处理能力和推理效果。
## 407. `cs.CL` - CBVLM: 使用无训练的可解释概念驱动的大规模视觉语言模型进行医学图像分类 [PDF](https://arxiv.org/pdf/2501.12266), [HTML](https://arxiv.org/abs/2501.12266)
### Authors
Cristiano Patrício,Isabel Rio-Torto,Jaime S. Cardoso,Luís F. Teixeira,João C. Neves
### Background
目前阻碍深度学习解决方案在医疗工作流程中采用的主要挑战是注释数据的可用性和系统的可解释性不足。概念瓶颈模型(CBMs)通过约束模型输出到预定义和人类可解释的概念，解决了后一个问题，但同时也增加了注释负担。若需添加新的概念，则整个系统需要重新训练。大型视觉-语言模型(LVLM)在少样本设置中表现出了优异性能，因此本文提出了一种简单的、有效的CBVLM方法，旨在同时解决这两个挑战。
### Innovation
本文提出了一种基于大型视觉-语言模型(CBVLM)的新方法，用于医学图像分类。该方法首先通过提示LVLM判断输入图像中是否存在特定概念，然后基于这些预测的概念来分类图像。这种方法还包括一个检索模块，用于选择最佳示例进行上下文学习。通过依靠预测的概念进行最终诊断，确保了解释性，并通过利用LVLM的少样本能力，大大降低了标注成本。
### Conclusion
我们通过在四个医学数据集和十二种大型视觉-语言模型（通用和医学）上进行广泛实验验证了该方法的有效性，结果表明，CBVLM在无需任何训练且仅使用少量标注样本的情况下，始终优于CBMs和针对特定任务的监督方法。有关更多信息，请参阅我们的项目页面：this https URL。
## 408. `cs.CV` - 解锁合作伙伴的力量：人类和机器如何协作以改善面部识别 [PDF](https://arxiv.org/pdf/2510.02570), [HTML](https://arxiv.org/abs/2510.02570)
### Authors
P. Jonathon Phillips(1),Geraldine Jeckeln(2),Carina A. Hahn(1),Amy N. Yates(1),Peter C. Fontana(1),Alice J. O'Toole(2) ((1) Information Access Division, National Institute of Standards and Technology, Gaithersburg, MD (2) School of Behavioral and Brain Sciences, The University of Texas at Dallas, Richardson, TX)
### Background
面部识别算法在进行关键决策时需要人类审查，这形成了一个协作的人机系统。个体之间的差异影响了这种合作是提高还是降低准确性。研究团队探讨了在不同基础准确度差异下，人机协作如何改善面部识别的准确性。
### Innovation
研究团队利用“近似准确性法则”（Proximal Accuracy Rule，PAR）发现了一个“关键融合区域”，即当人类比机器更不准确时，将两者决策融合可以提高系统的准确率。此外，团队提出了一种基于选择具有良好增效潜力的人来增强高性能机器的方法，这种智能人机融合比单独使用机器更为准确，并且比所有人类和机器判断的结合更为准确。利用图论分析单一人类协作的最大系统准确率。
### Conclusion
该研究展示了人类和机器在确保面部识别准确性方面都有各自有意义的作用，并提供了基于证据的人脸识别智能使用蓝图。
## 409. `cs.CV` - PhysHMR: 从视觉学习 humanoid 控制策略以实现物理合理的真人动作重建 [PDF](https://arxiv.org/pdf/2510.02566), [HTML](https://arxiv.org/abs/2510.02566)
### Authors
Qiao Feng,Yiming Huang,Yufu Wang,Jiatao Gu,Lingjie Liu
### Background
单目视频中的人体动作重建是一个在计算机视觉和图形学中极具挑战性的问题。现有方法主要集中在基于运动学的姿势估计上，往往由于缺乏物理约束而产生不真实的结果。为了解决这些问题，以前的方法通常在基于运动学的运动估计之后依赖于基于物理的后处理。然而，这种两阶段设计会导致误差累积，从而限制了整体重建质量。
### Innovation
我们提出了一种名为PhysHMR的统一框架，该框架直接学习将视觉信息转化为动作策略的方法，以在基于物理的模拟器中进行人形控制，从而使动作重建同时物理合理且符合输入视频的视觉特性。我们的方法的关键是像素作为光线策略，该策略将2D关键点提升到3D空间光线，并将它们转换为全局空间。这些光线作为策略输入，提供了在不依赖于噪声的3D根预测的情况下获得鲁棒全局姿态指导的能力。结合预训练编码器提供的局部视觉特征，策略能够对详细姿态和全局定位进行推理。为了克服强化学习的样本效率低下，我们还提出了一种从 mocap 训练的专家传递运动知识到基于视觉条件的策略的蒸馏方案，该策略随后使用基于物理动机的强化学习奖励进行优化。
### Conclusion
大量的实验表明，PhysHMR在不同场景下能够产生高保真度、物理合理的运动，且在视觉准确性和物理逼真度上优于以前的方法。
## 410. `cs.CV` - PEO：利用提示嵌入优化在预训练文本到图像扩散模型中的无训练美学质量提升 [PDF](https://arxiv.org/pdf/2510.02599), [HTML](https://arxiv.org/abs/2510.02599)
### Authors
Hovhannes Margaryan,Bo Wan,Tinne Tuytelaars
### Background
在给定简单提示时，预训练的文本到图像扩散模型生成的图片可能缺乏理想的审美质量。本文关注如何在保持原始提示基本意义上提升预训练模型生成的图片的美观度，同时不依赖额外的训练过程或依赖于特定的基础模型架构。
### Innovation
提出了名为Prompt Embedding Optimization (PEO)的新方法，该方法利用预训练的文本到图像扩散模型作为基础，并通过优化给定的简单且未经筛选的提示的文本嵌入，来提高生成图像的视觉质量。PEO方法采用了三重目标函数，分别用于提升生成图片的审美准确性、确保优化后的文本嵌入与目标一致以及尽量减少与初始提示的偏差。此外，该方法无训练需求且不依赖特定的基础模型架构.
### Conclusion
通过定量和定性的评估证实了所提方法的有效性，其表现超越了当前最先进的文本到图像和提示适应方法。
## 411. `cs.CV` - Oracle-RLAIF: 一种通过排名反馈进行强化学习以改善多模态视频模型细调的新框架 [PDF](https://arxiv.org/pdf/2510.02561), [HTML](https://arxiv.org/abs/2510.02561)
### Authors
Derek Shi,Ruben Glatt,Christine Klymko,Shubham Mohole,Hongjun Choi,Shashank Kushwaha,Sam Sakla,Felipe Leno da Silva
### Background
最近的大型视频-语言模型（VLMs）依赖于广泛的微调技术，以增强文本理解和视觉理解之间的对齐。主流流程通常将监督微调（SFT）与基于偏好的强化学习相结合，以提高视频理解能力。然而，随着VLMs参数规模的扩大，收集足够的人类反馈的成本也在增加。为了降低成本，最近的框架探索了使用AI反馈的强化学习（RLAIF），将人类偏好替换为AI作为裁判。当前的RLAIF框架依赖于一种专门的奖励模型，该模型通过视频叙述数据进行训练，生成校准的标量奖励，这是一个昂贵且限制性较强的流程。
### Innovation
我们提出了一种名为Oracle-RLAIF的新框架，该框架用一个更通用的Oracle排名器替代了训练好的奖励模型，该Oracle排名器作为模型响应的排名器，而不是评分器。我们还引入了基于组相对策略优化（GRPO）的排名损失函数$GRPO_{rank}$，该函数直接优化基于排名的反馈，具有知觉优势。实验结果表明，Oracle-RLAIF在各种视频理解基准测试中的一致表现优于现有微调方法的最先进VLMs。Oracle-RLAIF开辟了通过排名而不是评分来进行强化学习的灵活且数据高效的框架路径，以对齐大型多模态视频模型。
### Conclusion
Oracle-RLAIF持续超越现有细调方法的表现，为通过排名进行强化学习的多模态视频模型对齐提供了更加灵活和高效的框架，从而降低了成本并提高了模型的适应性。
## 412. `cs.CV` - 使用功能LoRA的深层生成连续学习：FunLoRA [PDF](https://arxiv.org/pdf/2510.02631), [HTML](https://arxiv.org/abs/2510.02631)
### Authors
Victor Enescu,Hichem Sahbi
### Background
深度生成模型在基于文本和视觉的应用中迅速扩展，持续适应这些模型具有巨大的潜力和重要性。然而，增量训练由于灾难性遗忘现象而变得极为困难，使得神经网络难以有效整合新知识。常用策略是在生成模型的合成数据上重新训练模型以减轻遗忘，但这种方法面临两个主要限制：（i）训练时间不断增加最终变得不可行；（ii）依赖于合成数据会导致长期性能下降，因为合成样本缺乏真实训练数据的丰富性。
### Innovation
本文通过对生成模型设计了一种新的、更具表现力的基于低秩适应（LoRA）的条件机制，该机制仅使用秩1矩阵，并通过精心选择的函数动态增加重参数化的矩阵秩，并将其称为功能LoRA：FunLoRA。使用这种动态条件机制，生成模型能够避免灾难性遗忘，并仅需要对当前任务的数据进行训练。全面的实验表明，基于从头训练的流匹配模型，本文提出的一种参数高效的微调方法（PEFT）超越了基于扩散模型的先前最佳结果，达到了更高的分类准确率，且仅占用内存成本和采样时间的一小部分。
### Conclusion
大量实验结果显示，提出的参数高效的微调方法（PEFT）在流匹配模型的基础上超越了基于扩散模型的方法，取得了更高的分类准确率，同时只需要一小部分的内存成本和采样时间。
## 413. `cs.CV` - FSFSplatter: 3分钟内利用稀疏视图构建表面和新颖视图 [PDF](https://arxiv.org/pdf/2510.02691), [HTML](https://arxiv.org/abs/2510.02691)
### Authors
Yibin Zhao,Yihan Pan,Jun Nan,Jianjun Yi
### Background
高斯点阵已成为重建技术的领先方法，因其高质量的新颖视图合成和详细的重建而闻名。然而，大多数现有的方法都需要密集且校准的视图。来自自由稀疏图像的重建常常由于重叠有限和过拟合导致表面质量差。
### Innovation
引入了FSFSplatter方法，一种用于快速从自由稀疏图像重建表面的新方法。该方法结合了端到端密集高斯初始化、相机参数估计及几何增强场景优化。具体而言，FSFSplatter使用大型Transformer编码多视角图像，并通过自分裂高斯头部生成密集且几何上一致的高斯场景初始化。该方法通过基于贡献度的裁剪消除局部浮点误差，并通过深度监督和多视角特征监督在快速优化过程中充分利用可变相机参数来减轻对有限视图的过拟合。
### Conclusion
FSFSplatter在流行的DTU和Replica数据集上优于当前最先进的方法，在3分钟内实现表面重建和新颖视图生成。
## 414. `cs.CV` - 视频模型有多自信？赋能视频模型表达其不确定性 [PDF](https://arxiv.org/pdf/2510.02571), [HTML](https://arxiv.org/abs/2510.02571)
### Authors
Zhiting Mei,Ola Shorinwa,Anirudha Majumdar
### Background
生成视频模型展示了显著的从文本到视频的能力，广泛应用于各类实际应用中。然而，这些模型也像大型语言模型（LLMs）一样，倾向于产生错事实而又看起来合理的视频，这一点引发了安全问题。先前的工作已经研究了LLMs的不确定性量化(UQ)，但视频生成模型的UQ方法尚未开发。基于这一点，本研究旨在量化视频生成模型的不确定性，提供了一个框架来评估视频模型的校准性，这是一种基于稳健的秩相关估计的指标。此外，还提出了一种名为S-QUBED的黑盒UQ方法，该方法利用潜在模型将预测不确定性分解为偶然性和先验性组成部分。通过在潜在空间中调节生成任务，可以将不确定性区分为因任务说明不明确导致的不确定性与由于知识不足导致的不确定性。实验结果表明，S-QUBED计算出的校准总不确定性与任务准确性呈负相关，并有效地计算出了偶然性和先验性成分。
### Innovation
首次提出并构建了一个视频生成模型的不确定性量化框架，该框架包括：基于稳健的秩相关估计无严格的建模假设的评估视频模型校准性的度量、一种利用潜在建模来严谨分解预测不确定性为偶然性和先验性成分的黑盒UQ方法（S-QUBED）以及一个用于视频模型校准基准测试的UQ数据集。
### Conclusion
通过在潜在空间中调节生成任务，可以区分因任务说明不明确导致的不确定性与由于知识不足导致的不确定性，并展示了S-QUBED在基准视频数据集上的实验结果，证明了它能够准确估计预测不确定性。
## 415. `cs.CV` - Net2Net: 当未训练网络遇见预训练网络实现鲁棒的现实世界去噪 [PDF](https://arxiv.org/pdf/2510.02733), [HTML](https://arxiv.org/abs/2510.02733)
### Authors
Weimin Yuan,Cai Meng
### Background
传统的去噪方法主要依赖手工构建的先验知识，虽然在受控环境中表现良好，但在处理现实世界噪声的复杂性和多样性方面效果不佳。深度学习方法虽然可以通过大规模数据集学习噪声特性，但往往需要大量的标记数据，并且跨不同噪声类型和成像条件的有效性不足。
### Innovation
Net2Net 方法结合了未训练网络和预训练网络的优势，通过正则化去噪 (RED) 方法，实现了对现实世界噪声去噪的挑战。未训练网络适应每个输入图像的独特噪声特性，无需标记数据；预训练网络通过大规模数据集学习得到的表示，提供鲁棒的去噪性能。这种混合框架增强了不同噪声模式的一般化能力，并在训练数据有限的情况下提高了性能。
### Conclusion
在基准数据集上的大量实验表明，本方法在现实世界噪声去噪方面具有优越性。
## 416. `cs.CV` - 输入感知稀疏注意机制在实时同步手势视频生成中的应用 [PDF](https://arxiv.org/pdf/2510.02617), [HTML](https://arxiv.org/abs/2510.02617)
### Authors
Beijia Lu,Ziyi Chen,Jing Xiao,Jun-Yan Zhu
### Background
扩散模型可以从音频中合成逼真的同步视频，适用于视频创作和虚拟代理等多种应用场景。然而，现有的基于扩散的方法由于去噪步骤多和昂贵的注意力机制而速度较慢，不适合实时部署。
### Innovation
本文提出了一种新的视频蒸馏方法，利用输入人体姿态条件指导注意力和损失函数。具体包括使用输入人体姿态关键点之间的准确对应关系来引导注意力至相关区域（如发言人的脸部、双手和上半身），以减少冗余计算并加强身体部位的时序对应关系，提高推断效率和动作连贯性。此外，引入了输入感知的蒸馏损失来增强唇部同步和手部动作的真实感。通过结合输入感知的稀疏注意力机制和蒸馏损失函数，该方法在保持高视觉质量的前提下实现了实时性能，优于最近的基于音频驱动和输入驱动的方法。
### Conclusion
实验结果表明，本算法方法的设计选择非常有效，实现了实时同步手势视频生成的同时，视觉质量得到了显著提升。
## 417. `cs.CL` - SelfBudgeter: 动态自适应令牌分配以实现高效的大语言模型推理 [PDF](https://arxiv.org/pdf/2505.11274), [HTML](https://arxiv.org/abs/2505.11274)
### Authors
Zheng Li,Qingxiu Dong,Jingyuan Ma,Di Zhang,Kai Jia,Zhifang Sui
### Background
推理模型在复杂任务上表现出色，但在简单问题上则存在过度思考的倾向，这不仅会导致计算资源的过度消耗，而且还严重影响用户体验。
### Innovation
提出了一种名为SelfBudgeter的新颖用户友好型自适应可控制推理框架，该框架在推理前引入了预算估算机制。框架采用了双阶段训练模式：在冷启动阶段，模型学会在标准化格式下预测令牌预算；而在强化学习阶段，模型基于问题难度自主规划预算，并在生成响应时严格遵守这些预算。通过在初始阶段输出预算估算，用户可以立即预知等待时间，从而灵活决定是否中断或继续生成过程。此外，该方法支持通过预填预算字段手动控制推理长度。
### Conclusion
实验结果表明，SelfBudgeter能够根据问题复杂性动态分配预算，对于1.5B模型，在GSM8K、MATH500和AIME2025上的平均响应长度压缩了61%，对于7B模型压缩了48%，且几乎不降低准确性。
## 418. `cs.CV` - 从令牌到节点：基于语义的动态3D 高斯点云运动控制 [PDF](https://arxiv.org/pdf/2510.02732), [HTML](https://arxiv.org/abs/2510.02732)
### Authors
Jianing Chen,Zehao Li,Yujun Cai,Hao Jiang,Shuqin Gao,Honglong Zhao,Tianlu Mao,Yucheng Zhang
### Background
单目视频的动态3D重构仍然具有挑战性，主要是由于从有限视角推断3D运动的不明确性以及建模时间上变化场景的计算需求。尽管最近的稀疏控制方法通过减少数百万个高斯点到数千个控制点来缓解计算负担，但它们也面临一个关键限制：仅仅依靠几何学分配点，导致静态区域冗余过多和动态区域点不足。因此，需要一种能够根据运动复杂度调整控制密度的框架。通过使用视觉基础模型提供的语义和运动先验信息，该方法建立了补丁-令牌-节点的对应关系，并通过运动适配压缩，集中分配控制点在动态区域，同时抑制静态背景的冗余。这种方法通过迭代体素化和运动趋势打分实现了灵活的表征密度自适应，直接解决了控制点分配与运动复杂度之间根本的不匹配。为了捕捉时间演变，通过使用由二维追踪片段初始化的样条曲线基轨迹参数化来替代基于MLP的变形场，从而实现更平滑的运动表示和更稳定的优化流程。
### Innovation
提出了一种适应运动的框架，可以根据运动复杂度调整控制密度。通过引入基于样条曲线基轨迹参数化来解决运动表示和优化稳定性问题，而不是传统的基于MLP的变形场，并利用视觉基础模型的语义和运动先验信息来建立补丁-令牌-节点的对应关系，实现更加灵活和高效的数据压缩和整合，有效解决了原有方法中的静态冗余和动态不足的问题，显著提升了重建质量和效率。
### Conclusion
该研究通过迭代体素化和运动趋势打分实现了灵活的表征密度自适应，解决了控制点分配与运动复杂度的不匹配问题，并通过样条曲线式的轨迹参数化进一步改进了运动表示和优化稳定性。实验证明，该方法在重建质量及效率上均显著优于现有最先进的方法。
## 419. `cs.CV` - Sequence-Preserving Dual-FoV Defense for Traffic Sign and Light Recognition in Autonomous Vehicles [PDF](https://arxiv.org/pdf/2510.02642), [HTML](https://arxiv.org/abs/2510.02642)
### Authors
Abhishek Joshi,Jahnavi Krishna Koda,Abhishek Phadke
### Background
智能车辆的交通灯和标志识别至关重要，因为感知错误直接影响导航和安全。除了数字对抗攻击，模型还容易受到现有干扰（如反光、雨、污垢或涂鸦），可能导致危险的误分类。当前工作缺乏时空连续性、多视角场（FoV）感知以及对数字和自然降级的强大抵抗力。因此，研究提出了一种基于美国地区的多源数据集（包括aiMotive、Udacity、Waymo和德克萨斯地区自录制视频）的双视角场序列保持鲁棒性框架。该框架包括四个运营设计领域（ODDs）：高速公路、夜间、雨天和城市，并对多帧RGB图像进行了时间对齐。在一系列基于实际应用的异常检测实验中，研究提出了一个统一的三层防御栈框架，结合了特征压缩、防御性蒸馏以及基于熵的异常检测，并包括序列内时间投票进一步增强。评估指标包括准确性、攻击成功率（ASR）、风险加权误分类严重性以及置信度稳定性。实验证实了物理转移性并使用获取的探针进行了验证。
### Innovation
该研究提出了一种基于多视角场和序列保持鲁棒性框架，结合了特征压缩、防御性蒸馏以及基于熵的异常检测，并包括序列内时间投票进一步增强。该框架在实际应用中评估了准确性、攻击成功率、风险加权误分类严重性及置信度稳定性，并通过实验验证了物理转移性。结果表明，该方法在众包公共数据集上优于YOLOv8、YOLOv9和BEVFormer，降低了高风险误分类率至32%。
### Conclusion
研究提出的方法在智能车辆中的交通信号和标志识别方面表现出强大的鲁棒性和防御能力，能够在各种环境条件下有效对抗数字和自然降级，显著减少高风险误分类，并具有良好的物理可转移性。
## 420. `cs.CV` - MoGIC: 通过意图理解和视觉上下文增强运动生成 [PDF](https://arxiv.org/pdf/2510.02722), [HTML](https://arxiv.org/abs/2510.02722)
### Authors
Junyu Shi,Yong Sun,Zhiyuan Zhang,Lijiang Liu,Zhengjie Zhang,Yuxin He,Qiang Nie
### Background
现有的基于文本的运动生成方法通常将合成视为语言和运动之间的双向映射，但在捕捉动作执行的因果逻辑和驱动行为的人类意图方面仍然有限。缺乏视觉基底进一步限制了精度和个性化，因为仅靠语言无法指定细微的空间时间细节。现有方法在运动合成中未能有效地结合意图建模和视觉先验。
### Innovation
MoGIC 提出了一种统一框架，将意图建模与多模态运动合成中的视觉先验相结合。通过联合优化多模态条件下的运动生成和意图预测，MoGIC 揭示了潜在的人类目标，利用视觉先验增强生成，并展示了多功能的多模态生成能力。引入了自适应范围混合注意力机制，有效实现了条件令牌与运动子序列的局部对齐。MoGIC 提供了一个名为 Mo440H 的基准数据集，包含 440 小时的数据，来自 21 个高质量的运动数据集。实验证明，MoGIC 在 HumanML3D 上将 FID 减少了 38.6%，在 Mo440H 上减少了 34.6%，在基于大语言模型的方法中提供了轻量级的文本头部，在运动注释方面表现更好，进一步实现了意图预测和视觉条件生成，使可控运动合成和意图理解更加先进。
### Conclusion
经过微调后，MoGIC 在 HumanML3D 和 Mo440H 上提升了多模态生成能力，优于基线的大语言模型方法，在运动注释中表现更佳，支持意图预测和视觉条件生成，推进了可控运动合成和意图理解的技术发展。
## 421. `cs.CV` - 使用移动多摄像系统在野外进行自我-外部3D手部跟踪 [PDF](https://arxiv.org/pdf/2510.02601), [HTML](https://arxiv.org/abs/2510.02601)
### Authors
Patrick Rim,Kun He,Kevin Harris,Braden Copple,Shangchen Han,Sizhe An,Ivan Shugurov,Tomas Hodan,He Wen,Xu Xie
### Background
在不受限制的环境中进行人类手部及其与世界的三维跟踪仍然是自我中心计算机视觉中的重大挑战。现有的数据集大多在控制的实验室环境中捕获，限制了环境的多样性和模型的泛化能力。因此，本文提出了一种创新的无标记多摄像系统，以捕捉精确的手部和物体的三维姿态，在真正野外环境中允许几乎不受限制的自由移动。文章通过设计一种自我-外部跟踪管道，利用此系统生成准确的三维手部姿态ground truth，并进行了严格的质量评估。通过收集同步多视角图像和精确的三维手部姿态的数据集，文章证明了该方法能显著降低真实环境和三维标注精度之间的权衡。
### Innovation
文章提出了一种创新的无标记多摄像系统，该系统能够在真正野外环境中捕捉手部和物体的三维姿态，并允许几乎不受限制的自由移动。通过结合轻量级的背部佩戴捕获组件和八个外部摄像头，与用户佩戴的Meta Quest 3头显配合使用，提供两个自我视角。文章还设计了自我-外部跟踪管道，以从该系统中生成准确的三维手部姿态ground truth，并进行了严格的评估。通过收集同步多视角图像和精确的三维手部姿态的数据集，证明了此方法能够显著减少真实环境和三维标注精度之间的权衡。
### Conclusion
通过提出并实现一种自我-外部跟踪管道，文章成功地生成了精确的三维手部姿态ground truth，并展示了该系统在真实环境中的有效性和准确性。该方法显著提高了三维跟踪的精确度，有助于克服环境真实性和标注精度之间的平衡问题。
## 422. `cs.CV` - Retrv-R1：一种用于高效和通用多模态检索的推理驱动MLLM框架 [PDF](https://arxiv.org/pdf/2510.02745), [HTML](https://arxiv.org/abs/2510.02745)
### Authors
Lanyun Zhu,Deyi Ji,Tianrun Chen,Haiyang Wu,Shiqi Wang
### Background
深度学习模型DeepSeek-R1的成功证明了使用强化学习(Reinforcement Learning, RL)来提高语言大规模模型(LLMs)的能力有很大的潜力。然而，直接将DeepSeek-R1的方法应用于检索任务存在挑战，主要原因是计算成本高和直接应用RL训练检索任务时的不稳定性和次优结果。
### Innovation
Retrv-R1是为特定多模态通用检索任务设计的第一个具有R1风格的MLLM，通过逐步推理生成更准确的检索结果。Retrv-R1通过引入信息压缩模块和细节检查机制，有效减少计算量的同时保留关键信息，并采用一种新的训练范式，包括基于检索定制的合成CoT数据集的激活阶段和具有新颖奖励曲线的RL训练，从而实现最先进性能、高度效率和强泛化能力。
### Conclusion
实验结果表明，Retrv-R1在多个基准测试和任务中实现了最优性能，具有高效率和强泛化能力。
## 423. `cs.CL` - 跨模态下，AI模型是否具有类似人类的抽象推理能力？ [PDF](https://arxiv.org/pdf/2510.02125), [HTML](https://arxiv.org/abs/2510.02125)
### Authors
Claas Beger,Ryan Yi,Shuhao Fu,Arseny Moskvichev,Sarah W. Tsai,Sivasankaran Rajamanickam,Melanie Mitchell
### Background
本研究分析了一项关于OpenAI的o3-preview推理模型在ARC-AGI基准测试中超过人类准确性的现象，但引发了对当前最先进模型是否真正理解和推理任务创作者意图中的抽象概念的疑问。后续研究通过在ConceptARC上评估模型的抽象能力，探讨了不同输入模态（文本或视觉）、是否允许使用外部Python工具以及推理努力量程对模型性能的影响。研究还对比了模型输出的准确性和自然语言规则的生成，以更细致地评估模型是否利用了问题设计所期望的抽象层次。研究表明，部分使用文本表示的模型在准确率上可与人类相匹敌，但它们生成的规则往往基于表面模式，未能捕捉到更多的抽象意图，并且普遍低估了它们的抽象推理能力。视觉模态下，模型输出准确率显著下降，但通过规则层面分析发现，模型仍然展示出捕捉抽象意图比例较高的规则，虽未能正确应用，但仍显现出可能被低估的潜力。因此，研究结果表明，现有模型在抽象推理任务中仍然落后于人类，特别是对文本模态的评估可能高估了模型的实际能力，而视觉模态则可能低估了模型的潜在能力。该研究认为提供了一种更忠实反映多模态模型抽象推理能力和更合理的评估方式，以追踪类似于人类中心的抽象推理智能的进步。
### Innovation
本研究通过在ARC-AGI基准测试之外，引入了ConceptARC基准测试，评估模型在不同输入模态下的抽象能力表现。研究不仅测量了模型生成的答案准确性，还深入检测了模型输出的自然语言规则，以判断模型是否利用了设计任务所期待的抽象层级，而不是依赖表面的模式特性。这种双重评估方式提供了一种更细致地评估模型抽象推理能力的框架，进一步揭示了当前模型在不同模态下处理抽象问题的局限性与潜力。
### Conclusion
研究发现，尽管在某些条件下模型在文本模态下的推理准确率可以达到人类水平，但它们生成的规则常常依赖于表面的“捷径”，未能更频繁地捕捉到任务设计所意图实现的抽象层次，因此模型在跨模态抽象推理上的能力可能被仅依赖准确性的评价方式高估。在视觉模态下，模型的表现虽然在准确性上有明显下降，但其生成的规则仍然显示了捕捉抽象意图的能力，这表明可能低估了它们的潜在推理能力。总体而言，研究结果表明，模型在抽象推理领域的进展尚不能严格与人类相比拟，对类似ARC任务的抽象推理能力评估方法需综合考虑模态特征，以更准确地评价模型在抽象推理上的局限性和潜力。
## 424. `cs.CV` - 使用视觉语言模型在对象识别和检测中的贝叶斯测试时适应 [PDF](https://arxiv.org/pdf/2510.02750), [HTML](https://arxiv.org/abs/2510.02750)
### Authors
Lihua Zhou,Mao Ye,Shuaifeng Li,Nianxin Li,Jinlin Wu,Xiatian Zhu,Lei Deng,Hongbin Liu,Jiebo Luo,Zhen Lei
### Background
视觉语言模型（VLMs）如CLIP和Grounding DINO在对象识别和检测中取得了显著成果。然而，在现实世界的分布变化下，这些模型的性能会下降。测试时适应（TTA）旨在通过在推断期间调整模型来缓解这个问题。现有的方法要么依赖于计算成本高的反向传播，这妨碍了实时部署；要么只专注于似然适应，忽略了先验的至关重要作用。先前工作Bayesian Class Adaptation (BCA)通过引入训练免费框架，结合自适应先验解决了这些缺点，专门针对对象识别问题。在此基础上，我们现提出Bayesian Class Adaptation plus (BCA+)，一种统一的训练免费框架，适用于对象识别和检测的TTA。BCA+引入了一个动态缓存，适应性地存储和更新类别嵌入、空间尺度（用于检测）以及关键的自适应类别先验，从历史预测中获得。
### Innovation
BCA+是一种统一的训练免费框架，适用于对象识别和检测的TTA。它引入了一个动态缓存，能够自适应地存储和更新类别嵌入、空间尺度和自适应类别先验，而且将适应问题形式化为贝叶斯推断问题，通过融合初始VLM输出和基于缓存的预测来生成最终预测。这是通过一个动态更新的似然（衡量特征和尺度相似性）和一个先验（反映不断演变的类别分布）来实现的。这种双重适应机制，结合了不确定性指导的融合，使BCA+能够纠正模型的语义理解和上下文信心。BCA+无需反向传播，是一种高效的训练免费方法。广泛实验证明，BCA+在识别和检测基准上达到最先进的性能。
### Conclusion
BCA+通过引入动态缓存和贝叶斯推断机制提供了一种高效的训练免费解决方案，适用于对象识别和检测的测试时适应。实验证明，BCA+在多个识别和检测基准上表现出优越性能。
## 425. `cs.CV` - OTR：合成覆盖文本数据集用于文本去除 [PDF](https://arxiv.org/pdf/2510.02787), [HTML](https://arxiv.org/abs/2510.02787)
### Authors
Jan Zdenek,Wataru Shimoda,Kota Yamaguchi
### Background
文本删除在计算机视觉中是一个关键任务，应用于隐私保护、图像编辑和媒体重用等领域。现有研究主要集中在自然场景中的文本删除，但由于当前数据集的局限性，跨领域泛化或准确评估受到限制。现有基准如SCUT-EnsText存在由于手动编辑导致的地面真实数据缺陷、过于简单的文本背景以及无法充分评估生成结果质量的评价指标。
### Innovation
本文介绍了一种合成用于除场景文本之外其他领域的文本删除基准方法。该数据集通过对象感知放置和基于视觉语言模型的内容生成，实现了干净的地面真实数据和具有挑战性的文本删除场景。此外，认识到现有数据集的局限性，创建的OTR数据集针对覆盖文本（overlay text）开发，能够更好地支持跨领域应用。
### Conclusion
本文提出的OTR数据集为文本删除任务提供了一个新的基准，通过合成复杂背景上的文本和采用视觉语言模型生成内容，实现了高质量和多样化的文本删除场景。这种方法为评估和提高算法的泛化能力和去文本生成质量提供了重要支持。
## 426. `cs.CV` - Hierarchical Generalized Category Discovery for Brain Tumor Classification in Digital Pathology [PDF](https://arxiv.org/pdf/2510.02760), [HTML](https://arxiv.org/abs/2510.02760)
### Authors
Matthias Perkonigg,Patrick Rockenschaub,Georg Göbel,Adelheid Wöhrer
### Background
准确的大脑肿瘤分类对于神经肿瘤手术中的术中决策至关重要。然而，现有的方法仅限于固定集的预定义类别，无法捕捉训练期间不可用的肿瘤类型模式。无监督学习可以提取通用特征，但缺乏从标注数据中整合先验知识的能力，而半监督方法往往假设所有潜在类别都在标注数据中得到代表。
### Innovation
本文介绍了HGCDBT（Hierarchical Generalized Category Discovery for Brain Tumor Classification），一种将层级聚类与对比学习结合的新方法。该方法通过引入一种新颖的半监督层级聚类损失，扩展了基于对比学习的GCD（Generalized Category Discovery）。HGCDBT在OpenSRH数据集上的评估结果显示，其在斑块级别的分类准确性提高了28%，特别是在识别以前未见过的肿瘤类别方面。
### Conclusion
此外，HGCDBT在数字大脑肿瘤图谱中的组织切片级别的分类中表现出良好的泛化能力，证实其在不同成像模态中的实用价值。
## 427. `cs.CV` - 对齐你的查询：为多模态医疗对象检测进行表示对齐 [PDF](https://arxiv.org/pdf/2510.02789), [HTML](https://arxiv.org/abs/2510.02789)
### Authors
Ara Seo,Bryan Sangwoo Kim,Hyungjin Chung,Jong Chul Ye
### Background
医疗对象检测在使用单一检测器训练多种医疗模态（如胸片、CT、MRI）时表现不佳，因为这些模态的数据统计特征不同且表示空间不一致。
### Innovation
提出了一种基于表示对齐的方法，通过定义模态令牌并将其集成到检测过程中，以及引入QueryREPA预训练阶段来对齐查询表示与模态令牌，从而实现多模态医疗对象检测中模态感知的类忠实查询，并且可以在不修改架构的情况下提高下游训练的有效性。
### Conclusion
该方法在多种模态联合训练的情况下，能够一致地提高AP值，且几乎没有额外开销，为具有鲁棒性的多模态医疗对象检测提供了切实可行的途径。
## 428. `cs.CV` - Smart-GRPO：优化流匹配模型高效强化学习中噪声采样的智能方法 [PDF](https://arxiv.org/pdf/2510.02654), [HTML](https://arxiv.org/abs/2510.02654)
### Authors
Benjamin Yu,Jackie Liu,Justin Cui
### Background
流匹配的最新进展使得高质量的文本到图像生成成为可能。然而，流匹配模型的确定性特性使得它们不适于强化学习，这是提高图像质量和人类对齐的重要工具。先前的工作通过向潜在变量添加随机噪声引入了不确定性，但这种扰动是低效且不稳定的。
### Innovation
我们提出了Smart-GRPO，这是第一个用于流匹配模型强化学习中优化噪声扰动的方法。Smart-GRPO 使用迭代搜索策略，解码候选扰动，使用奖励函数评估它们，并调整噪声分布以指向更高奖励区域。
### Conclusion
实验表明，Smart-GRPO 在奖励优化和视觉质量方面优于基线方法。我们的结果表明了一条实现流匹配框架中高效训练与人适应生成之间平衡的实际路径。
## 429. `cs.CV` - 一像素描绘万物：统一的零样本图像生成框架 [PDF](https://arxiv.org/pdf/2510.02898), [HTML](https://arxiv.org/abs/2510.02898)
### Authors
Lorenzo Bianchi,Giacomo Pacini,Fabio Carrara,Nicola Messina,Giuseppe Amato,Fabrizio Falchi
### Background
零样本图像字幕生成器是近期提出的一种模型，这些模型使用共享空间的视觉-语言表示来对图像进行字幕生成，而不依赖于成对的图像-文本数据。现有的零样本图像字幕生成器通过文本解码与图像对准的特征进行字幕生成，但其范围仅限于整体图像描述和全局表示。
### Innovation
本文提出了一个统一的零样本图像文字描述框架frameworkName{}，从中图像中心范式转向像素中心范式，使得可以生成任意区域的文字描述而不依赖于区域级别的监督。本文将单个像素作为原子的文字描述单元进行处理，并根据需要合并它们来描述从单个像素区域到非连续区域乃至整个图像的各种区域。实验表明，能产生有意义且密集的视觉特征的模型，如DINO，是实现多种基于区域的文字描述任务的前沿性能的关键。
### Conclusion
与现有基线和其他前沿竞争对手相比，本文方法在零样本密集、区域集合和一个新的引入的文字描绘任务上表现出更好的性能，突显了像素级语义表示对于可扩展视频文字生成的有效性。
## 430. `cs.CV` - 使用基础模型的无监督领域外分割 [PDF](https://arxiv.org/pdf/2510.02909), [HTML](https://arxiv.org/abs/2510.02909)
### Authors
Laith Nayal,Hadi Salloum,Ahmad Taha,Yaroslav Kholodov,Alexander Gasnikov
### Background
在安全关键应用如自动驾驶中，检测未知对象对于语义分割至关重要。大型视觉基础模型，包括DINOv2、InternImage和CLIP，通过提供跨多样化任务具有良好泛化的丰富特征，推进了视觉表征学习。尽管这些模型在封闭集语义任务上表现出色，但它们在语义分割中检测领域外（Out-of-Distribution, OoD）区域的能力仍需进一步探索。
### Innovation
本文提出了一种无训练的、基于基础模型的方法，利用InternImage主干特征和K-Means聚类与置信阈值判定来识别OoD簇。该方法在RoadAnomaly基准和ADE-OoD基准上分别取得50.02和48.77的平均精度，超越了多种监督学习和无监督基线。
### Conclusion
该研究表明，使用基础模型进行领域外分割具有潜力的方向，方法不需要额外假设或附加数据。
## 431. `cs.CV` - VERNIER: 一种将标记姿态估计推送到微米和纳米尺度的开源软件 [PDF](https://arxiv.org/pdf/2510.02791), [HTML](https://arxiv.org/abs/2510.02791)
### Authors
Patrick Sandoz,Antoine N. André,Guillaume J. Laurent
### Background
小规模下的姿态估计仍然是一项挑战。目前鲜有解决方案能够在厘米至纳米范围内以纳米级和微角秒分辨率捕捉物体的6自由度。多年来，我们提出了一些用于不同显微镜应用的标记和图案设计，以获得可靠性能。厘米级别范围可以通过图案编码方法实现，而纳米级分辨率则可通过周期性图像的相位处理获得。
### Innovation
本文介绍了VERNIER，这是一种开源相位处理软件，用于基于伪周期性图案提供快速和可靠的姿态测量。该软件采用基于相位的局部阈值算法，具有良好的噪声鲁棒性和对焦及遮挡抗性。此外，论文详细阐述了相位处理的各个步骤，不同类型的图案如何针对不同的应用需求，并通过合成和实验图像进行了实施过程说明。最后，还给出了根据性能需求选定合适图案设计和显微镜放大镜的选择指南。
### Conclusion
本文的研究成果为微米和纳米尺度下的标记姿态估计提供了一种快速且可靠的解决方案，通过软件实现了相位处理中的伪周期性图案应用，提高了测量的准确性和鲁棒性。
## 432. `cs.CV` - MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding [PDF](https://arxiv.org/pdf/2510.02790), [HTML](https://arxiv.org/abs/2510.02790)
### Authors
Jingyuan Deng,Yujiu Yang
### Background
大规模视觉-语言模型（LVLMs）在下游多模态任务中的视觉-语言理解表现出显著的效果。然而，这些模型在提高其能力的同时也带来了新的问题，其中幻觉现象尤为突出。幻觉是指LVLMs生成与输入视觉和文本内容矛盾的内容。尽管针对这一问题提出了许多方法，如对比解码和注意力操作，但这些方法在构建适当的对比样本方面存在困难，并且注意力操作方法缺乏稳定性，容易产生不稳定的结果。
### Innovation
本文提出了一种名为图像头掩蔽对比解码（MaskCD）的方法。该方法利用LVLM中的‘图像头’，对它们进行掩蔽以构建对比样本，从而用于对比解码。通过在LLaVA-1.5-7b和Qwen-VL-7b模型上进行实验，并使用CHAIR、POPE、AMBER和MME基准测试，结果表明MaskCD有效地减轻了幻觉现象，同时保留了LVLM的一般能力。
### Conclusion
实验结果表明，MaskCD可以有效地减轻LVLM中的幻觉现象，并保持模型的通用能力。相关资源可以在提供的链接中找到。
## 433. `cs.CV` - Flip Distribution Alignment VAE for Multi-Phase MRI Synthesis [PDF](https://arxiv.org/pdf/2510.02970), [HTML](https://arxiv.org/abs/2510.02970)
### Authors
Xiaoyan Kui,Qianmu Xiao,Qqinsong Li,Zexin Ji,JIelin Zhang,Beiji Zou
### Background
在多阶段对比增强（CE）MRI合成中，分离共享特征和独立特征至关重要。然而，现有方法使用低参数效率的深自动编码生成器，并缺乏可解释的训练策略。
### Innovation
本文提出了一种轻量级特征解耦VAE模型，即Flip Distribution Alignment Variational Autoencoder (FDA-VAE)，用于多阶段CE MRI合成。该方法将输入和目标图像编码为关于标准正态分布对称的两个潜在分布，有效地分离了共享和独立特征。Y形双向训练策略进一步增强了特征分离的可解释性。
### Conclusion
实验结果表明，与现有的基于深度自动编码器的端对端合成方法相比，FDA-VAE在显著减少模型参数和推理时间的同时，有效地提高了合成质量。源代码已公开。
## 434. `cs.CV` - TIT-Score: 通过文本到图像到文本一致性评估长提示基于文本到图像对齐 [PDF](https://arxiv.org/pdf/2510.02987), [HTML](https://arxiv.org/abs/2510.02987)
### Authors
Juntong Wang,Huiyu Duan,Jiarui Wang,Ziheng Jia,Guangtao Zhai,Xiongkuo Min
### Background
随着大型多模态模型（LMMs）的快速进步，最近的文本到图像（T2I）模型能够生成高质量的图像，并且对简短的提示显示出很好的对齐性。然而，它们在理解并遵循长而详细的提示方面仍然表现不佳，生成结果一致性较差。
### Innovation
提出了一个名为LPG-Bench的综合基准来评估基于长提示的文本到图像生成，并引入了基于文本到图像到文本一致性的零样本指标TIT，包括基于评分的实现TIT-Score和基于大型语言模型（LLM）的实现TIT-Score-LLM。
### Conclusion
TIT-Score方法相对于CLIP-score、LMM-score等基线方法，在人类偏好一致性方面表现出更好的对齐性，特别是TIT-Score-LLM方法，在两两准确率方面提升了7.31%。LPG-Bench和TIT方法提供了对文本到图像模型进行基准测试和促进发展的更深认识。所有资源将公开提供。
## 435. `cs.CV` - 通过自信感知权重提高视觉语言模型的零样本鲁棒性 [PDF](https://arxiv.org/pdf/2510.02913), [HTML](https://arxiv.org/abs/2510.02913)
### Authors
Nikoo Naghavian,Mostafa Tavassolipour
### Background
视觉-语言模型如CLIP虽然在零样本领域表现出众，但在对抗攻击面前仍然高度脆弱。本研究旨在提升视觉-语言模型在零样本情况下的鲁棒性，强调不牺牲泛化能力的前提下增加模型的稳健性
### Innovation
提出了一种名为自信感知权重(CAW)的策略来增强视觉-语言模型的零样本稳健性。CAW包含两个部分：(1) 自信感知损失（Confidence-Aware loss），通过调整干净样本和对抗样本的KL散度来优先处理不确定性高的对抗样本；(2) 特征对齐正则化（feature alignment regularization），通过在对抗输入上最小化冻结特征和微调后的图像编码器特征的距离来保持语义一致性。该方法联合工作以提高清洁样本和鲁棒准确性
### Conclusion
在TinyImageNet和14个附加数据集上的大量实验表明，CAW在AutoAttack等强攻击下，优于近期方法PMG-AFT和TGA-ZSR，同时使用更少的内存。
## 436. `cs.CV` - 可视化之谜：可解释性揭示视觉语言模型的认知局限 [PDF](https://arxiv.org/pdf/2510.02780), [HTML](https://arxiv.org/abs/2510.02780)
### Authors
Prahitha Movva
### Background
视觉-语言模型（VLMs）在多项跨模态任务上表现出色，但它们在解决复杂的侧向思维挑战（如谜语）时的认知过程仍然不透明。尽管近期研究证明了这些模型在解答谜语时存在显著困难，但其背后的推理过程和失败模式仍需进一步探究。为了填补这一空白，研究通过全面的可解释性分析，超越性能指标来理解VLMs如何处理这些复杂的侧向思维挑战。研究贡献了一个系统标注的数据集，包括六类认知上的221个谜语，以及一个分离推理质量和答案正确性的评估框架。研究发现推理质量在谜题类别之间存在巨大差异，模型在视觉组成中表现出系统优势，但在不存在解释和文化象征方面表现出根本局限。研究还发现，不同的提示策略会显著影响认知方法和问题解决效果，确立了可解释性作为模型性能的一个核心组成部分，而不仅仅是事后考虑的内容.
### Innovation
研究提出一个系统标注的221个谜语数据集，并通过不同提示策略探究VLMs的推理过程，揭示出模型在不同类型的推理中的表现差异，以及提示策略对VLMs认知方法和问题解决效果的影响。这项研究将可解释性确立为模型性能的核心组成部分，而非事后考虑的内容，填补了VLMs在复杂侧向思维挑战中认知过程研究的空白.
### Conclusion
研究表明，VLMs在不同谜语类别中的推理质量存在巨大差异，模型在视觉组成方面表现出优势，但在不存在解释和文化象征方面存在根本局限。提示策略显著影响了VLMs的认知过程和问题解决效果，这表明可解释性分析对于理解VLMs的内在认知过程非常重要，应将其视为提高模型性能的重要组成部分，而非仅仅视为一种事后分析手段。
## 437. `cs.CV` - ELMF4EggQ：基于多模态特征融合的集成学习方法用于无损鸡蛋品质评估 [PDF](https://arxiv.org/pdf/2510.02876), [HTML](https://arxiv.org/abs/2510.02876)
### Authors
Md Zahim Hassan,Md. Osama,Muhammad Ashad Kabir,Md. Saiful Islam,Zannatul Naim
### Background
准确、无损地评估鸡蛋品质对于确保食品安全、维持产品标准以及商业养鸡生产操作效率至关重要。本文介绍了一种名为ELMF4EggQ的集成学习框架，该框架利用多模态特征融合技术仅通过外部属性（图像、形状和重量）来分类鸡蛋的等级和新鲜度。为了构建数据集，研究人员创建了一个包含186个褐色壳鸡蛋的新型公共数据集，并通过实验室的专家评估确定了鸡蛋的等级和新鲜度，这些评估基于内部质量测量，比如蛋黄指数和Haugh单位。到目前为止，这是首次使用集成学习方法和仅基于外部、非侵入特征来评估内部鸡蛋品质的研究，并首次发布了相应的标注数据集。
### Innovation
引入了一个新的集成学习框架ELMF4EggQ，该框架使用多模态特征融合来分类鸡蛋的等级和新鲜度，仅依赖外部属性，包括图像、形状和重量；首次使用公共数据集进行相关研究；对深度学习提取的图像特征进行了主成分分析降维，并进行了SMOTE增强，最终使用多个机器学习算法进行分类。
### Conclusion
实验结果显示，多模态方法显著优于仅基于图像或仅基于形状和重量的基线方法，多模态集成方法的等级分类准确率为86.57%，新鲜度预测准确率为70.83%。所有代码和数据均在该网址公开，以促进研究透明度、可重复性和进一步的研究。
## 438. `cs.CV` - 迈向大规模且一致性好的3D编辑 [PDF](https://arxiv.org/pdf/2510.02994), [HTML](https://arxiv.org/abs/2510.02994)
### Authors
Ruihao Xia,Yang Tang,Pan Zhou
### Background
3D编辑是指对3D资产的几何形状或外观进行局部修改的任务，这项任务广泛应用于沉浸式内容创作、数字娱乐和AR/VR。然而，与2D编辑不同，3D编辑面临着跨视图一致性、结构保真性和细粒度可控性等方面的挑战。现有的方法往往效率低下，容易产生几何畸变，或者依赖于手工制作且容易出错的3D蒙版。
### Innovation
本文通过在数据和模型两个方面进行创新来应对上述挑战。在数据方面，我们推出了3DEditVerse，这是到目前为止规模最大的3D编辑数据集，包含116,309个高质量的训练对以及1,500个精选的测试对。通过结合基于姿态的几何编辑和基于基础模型的外观编辑两个流程管线，3DEditVerse确保了编辑的局部性、多视图一致性和语义对齐。在模型方面，我们提出了3DEditFormer，这是一种3D结构保持的条件变压器模型。通过增强图像到3D生成的双指导注意力和时间自适应门控，3DEditFormer能够拆分可编辑区域和保留的结构，从而实现精确且一致的编辑而不需要额外的3D蒙版。
### Conclusion
通过大量实验，我们的框架在定量和定性的评价指标上都超过了最先进的基线方法，建立了新的3D编辑实践和可扩展性的标准。数据集和代码将被发布。
## 439. `cs.CV` - 在MLLMs中不要只追求“高亮的视觉令牌”：重新审视视觉全局语境保留 [PDF](https://arxiv.org/pdf/2510.02912), [HTML](https://arxiv.org/abs/2510.02912)
### Authors
Xin Zou,Di Lu,Yizhou Wang,Yibo Yan,Yuanhuiyi Lyu,Xu Zheng,Linfeng Zhang,Xuming Hu
### Background
尽管多模态大语言模型（MLLMs）具有强大的能力，但由于依赖大量的视觉标记，它们面临巨大的计算负担。最近的研究探索了通过文本-视觉交叉注意力或[CLS]注意力来评估和丢弃冗余视觉标记的标记剪枝方法，以减轻这一问题。然而，这种基于注意力的第一步剪枝方法通常倾向于保留语义相似的标记，导致在高剪枝比例下性能显著下降。因此，需要一种新的方法来解决这个问题，确保保留的标记能够捕捉到全局视觉语境，而不是孤立的显著特征。
### Innovation
本文提出了HoloV，一种简单有效、即插即用的视觉标记剪枝框架，通过从全局视角重新考虑标记保留策略，HoloV能够适应性地在不同空间裁剪中分配剪枝预算，以确保保留的标记能够捕捉全局视觉语境，从而最小化表示坍塌，即使在激进的剪枝下也能保持与任务相关的信息。实验结果显示，HoloV在各种任务、MLLM结构和剪枝比例下，优于当前最先进的方法。例如，使用HoloV的LLaVA1.5在剪除88.9%的视觉标记后仍能保持95.8%的原始性能，实现了更优的效率-准确性权衡。
### Conclusion
HoloV在多项任务中表现出色，能够高效地保留视觉标记，保持模型的性能，对于MLLMs的高效推理具有重要意义。
## 440. `cs.CV` - 视觉生成模型中综合泛化的驱动力 [PDF](https://arxiv.org/pdf/2510.03075), [HTML](https://arxiv.org/abs/2510.03075)
### Authors
Karim Farid,Rajat Sahay,Yumna Ali Alnaggar,Simon Schrodi,Volker Fischer,Cordelia Schmid,Thomas Brox
### Background
视觉生成模型的综合泛化能力，即产生已知概念的新颖组合的能力，是视觉生成模型的关键成分。然而，并非所有使这种能力得以实现或抑制的机制都已完全理解。
### Innovation
通过系统地研究各种设计选择如何以积极或消极的方式影响图像和视频生成的综合泛化，发现两个关键因素：（i）训练目标是否基于离散或连续分布；（ii）训练期间条件信息提供内容概念的程度。进而展示了通过利用辅助的连续JEPA目标缓解MaskGIT的离散损失可以提高离散模型MaskGIT的综合性能。
### Conclusion
研究表明，某些设计选择能够显著影响视觉生成模型的综合泛化能力。通过对训练目标和条件信息的控制，可以优化生成模型的表现。
## 441. `cs.CV` - 不是每一天都是晴天：不同数据源环境下深度土地覆盖分割的综合云注入 robustness 评价 [PDF](https://arxiv.org/pdf/2510.03006), [HTML](https://arxiv.org/abs/2510.03006)
### Authors
Sara Mobsite,Renaud Hostache,Laure Berti Equille,Emmanuel Roux,Joris Guerin
### Background
监督深度学习在土地覆盖语义分割 (LCS) 中依赖于标注的卫星数据。然而，大多数现有的 Sentinel-2 数据集都是无云的，这限制了它们在云多的热带地区中的应用。为了评估这个问题，我们开发了一个云注入算法来模拟实际的云覆盖，以便测试 Sentinel-1 雷达数据如何填补由云遮挡的光学图像所造成的空白。同时，我们也面临了在深度网络编码下采样过程中细化的损失问题，在此情况下，我们提出了一个轻量级方法，即将归一化差异指数 (NDI) 注入到最终的解码层中，使模型能够保留关键的空间特征，且几乎不会增加额外计算负担。
### Innovation
提出了一个轻量级的方法，即将归一化差异指数 (NDI) 注入到最终的解码层中，从而在保持关键的空间特征的同时几乎不会增加额外的计算负担。这种方法在 DFC2020 数据集上的测试结果显示，对于 U-Net 和 DeepLabV3，无云图像的分割性能分别提高了 1.99% 和 2.78%。而在云遮挡条件下，将 Sentinel-1 数据与光学数据融合时，所有模型的性能均有了显著提升，表明雷达-光学融合在具有挑战性的大气条件下非常有效。
### Conclusion
研究表明，对于 land cover semantic segmentation，需要使用包括雷达数据在内的多源数据来提高模型的 robustness，特别是在云多的区域。引入云模拟算法和轻量级方法，可以有效提升分割性能，为在实际场景中使用监督深度学习方法提供有力支持。
## 442. `cs.CV` - InsideOut：基于EfficientNetV2-S的稳健多类面部情感识别深度学习框架 [PDF](https://arxiv.org/pdf/2510.03066), [HTML](https://arxiv.org/abs/2510.03066)
### Authors
Ahsan Farabi,Israt Khandaker,Ibrahim Khalil Shanto,Md Abdul Ahad Minhaz,Tanisha Zaman
### Background
情感识别（FER）是情感计算中的关键任务，能应用于人机交互、教育技术、医疗健康和安全系统等领域。尽管深度学习已取得进展，但由于遮挡、光照和姿态变化、类内细微差异以及数据集不平衡导致少数情感识别困难，因此FER依然具有挑战性。
### Innovation
InsideOut是一种基于EfficientNetV2-S的FER框架，采用迁移学习、强数据增强和不平衡优化。该方法标准化FER2013图像，实施分层划分和增强，并通过带权损失微调轻量级分类头以解决数据分布偏差。InsideOut在FER2013数据集上的准确率为62.8%，宏平均F1分数为0.590，显示出了与传统CNN基准相比具有竞争力的结果，创新之处在于证明了高效的架构结合特制不平衡处理可以提供实际、透明且可重复的FER解决方案。
### Conclusion
InsideOut在FER中展现出了有效和可验证的结果，认为可以通过高效网络结合针对不平衡数据的优化策略来解决这一具有挑战性的任务，从而提供可行的情感识别解决方案。
## 443. `cs.CV` - 多事件视频生成中事件切换的时机和位置是什么？ [PDF](https://arxiv.org/pdf/2510.03049), [HTML](https://arxiv.org/abs/2510.03049)
### Authors
Ruotong Liao,Guowen Huang,Qing Cheng,Thomas Seidl,Daniel Cremers,Volker Tresp
### Background
文本到视频（T2V）生成近年来因挑战性问题而蓬勃发展，特别是在长视频需要描绘多个具有时序连贯性和可控内容的连续事件时表现尤为明显。现有的多事件生成方法通常未能检查事件转变的内在因素。因此，论文旨在回答中心问题：在T2V生成过程中，多事件提示何时以及如何控制事件变化？
### Innovation
该论文提出了MEve，这是一种自编纂的提示套件，用于评估多事件文本到视频（T2V）生成，并在两个代表模型家族（OpenSora和CogVideoX）上进行了系统的研究。通过广泛的实验证明了早期干预在去噪步骤和块级模型层中的重要性，揭示了多事件视频生成的关键因素，并突出了未来模型中多事件条件的可能性.
### Conclusion
实验表明，在多事件视频生成过程中，早期干预去噪步骤和块级模型层对于保证事件的时序连贯性和生成具有控制内容的视频至关重要。这为未来模型中的多事件条件提供了新的可能性。
## 444. `cs.CV` - Med-K2N: 综合K到N医学模态转换以实现医学图像合成 [PDF](https://arxiv.org/pdf/2510.02815), [HTML](https://arxiv.org/abs/2510.02815)
### Authors
Feng Yuan,Yifan Gao,Yuehua Ye,Haoyue Li,Xin Gao
### Background
跨模态医学图像合成研究集中在从可用模态重建缺失的图像模态以支持临床诊断。临床对于灵活的模态重构提出了需求，尤其是在需要从少量已知模态重建多种未知模态时。这带来了三个关键挑战：如何建模不同模态对不同目标任务的异构贡献？如何确保融合质量控制以防止来自噪声信息的降解？如何在多输出生成中保持模态身份一致性？基于这些临床需求，研究借鉴了SAM2的连续帧范式和临床医生逐步添加和选择性整合多模信息的作业流程，将多模态医学数据视为带有高质量选择机制的连续帧。
### Innovation
我们的创新方法是将多模态医学数据视为带有高质量选择机制的连续帧，关键在于为每个模态任务对学习自适应权重，并通过逐步增强“记忆”有益的融合模式。为此，我们设计了三个协作模块：PreWeightNet 用于全局贡献评估、ThresholdNet 用于自适应过滤、以及EffiWeightNet 用于有效权重计算。同时，为了保持模态身份一致性，我们提出了一种因果模态身份模块 (CMIM)，利用视觉-语言建模在生成图像和目标模态描述之间建立因果约束。
### Conclusion
大量实验结果表明，我们的Med-K2N方法在多个基准上显著优于最先进的方法。源代码可供使用。
## 445. `cs.CV` - 几何与视觉的交汇：重访在提取领域中的预训练语义 [PDF](https://arxiv.org/pdf/2510.03104), [HTML](https://arxiv.org/abs/2510.03104)
### Authors
Zhiting Mei,Ola Shorinwa,Anirudha Majumdar
### Background
语义在辐射场中的提取推动了机器人操作和导航等开放词汇策略的重要进步，这些语义主要来自大型视觉模型的预训练。尽管视觉特征（如DINO和CLIP）在高斯散点图和神经辐射场中表现出有效性，但几何导向语义特征在提取领域中的优势尚是个未知数。
### Innovation
本文提出了一个新颖的框架SPINE，用于在没有初始猜测的情况下反转辐射场，该框架由两个核心组件组成：基于提取语义的粗略反转和基于光度的优化进行精细反转。本文研究了几何导向语义特征在辐射场重建中的作用，发现在某些任务中，几何导向并不优于视觉导向，但在表现上具有不同的特征。
### Conclusion
视觉特征对下游任务表现出更大的通用性，尽管几何导向特征提供了更丰富的几何细节。本文的研究结果强调了未来研究中需要有效的几何导向策略，以增强预训练语义特征的多样性和性能的重要性。
## 446. `cs.CV` - 大规模视觉语言模型在颈动脉风险分层中的多模态应用：基准测试、微调和临床见解 [PDF](https://arxiv.org/pdf/2510.02922), [HTML](https://arxiv.org/abs/2510.02922)
### Authors
Daphne Tsolissou,Theofanis Ganitidis,Konstantinos Mitsis,Stergios CHristodoulidis,Maria Vakalopoulou,Konstantina Nikita
### Background
可靠的颈动脉动脉粥样硬化疾病风险评估仍然是临床医学的重要挑战，因为它需要在透明且可解释的方式下整合多种临床和影像信息。本研究旨在探讨最先进的和最近的大型视觉语言模型（LVLMs）在结合超声成像（USI）和其他结构化的临床、人口统计、实验室和蛋白质生物标志物数据方面进行颈动脉斑块评估的潜力。研究提出了一种模拟现实临床诊断场景的框架，通过访谈式问题序列将多种开源LVLMs（包括通用和医学调参模型）进行比较。实验结果揭示，尽管这些模型非常强大，但它们在准确识别影像模态和解剖部位方面表现不佳，而在准确的风险分类上表现较差。为此，通过低秩适应（LoRA）将LLaVa-NeXT-Vicuna模型适应超声成像领域，从而显著提高了中风风险分层。整合文本形式的多模态表格数据进一步提升了特异性与准确率，与同一数据集上训练的卷积神经网络（CNN）基线相比表现出竞争性表现。研究结果揭示了LVLMs在基于超声成像的心血管风险预测中的应用潜力和局限性，突出了多模态整合、模型校准和领域适应对于临床转化的重要性。
### Innovation
本研究创新性地使用了大型视觉语言模型（LVLMs）结合超声成像和其他多模态临床数据进行颈动脉斑块评估。提出了一种模拟现实临床诊断场景的框架，比较了多种开源和医学调参的LVLMs。通过低秩适应（LoRA）将LLaVa-NeXT-Vicuna模型适应超声成像领域，显著提高了中风风险分层的准确性。整合多模态表格数据进一步提升了模型的性能。
### Conclusion
本研究揭示了LVLMs在超声成像心血管风险预测中的应用潜力和局限性。多模态整合、模型校准和领域适应对临床转化至关重要。
## 447. `cs.CV` - PocketSR：口袋里的超分辨率专家 [PDF](https://arxiv.org/pdf/2510.03012), [HTML](https://arxiv.org/abs/2510.03012)
### Authors
Haoze Sun,Linfeng Jiang,Fan Li,Renjing Pei,Zhixin Wang,Yong Guo,Jiaqi Xu,Haoyu Chen,Jin Han,Fenglong Song,Yujiu Yang,Wenbo Li
### Background
实世界图像超分辨率（Real-world image super-resolution, RealSR）旨在提升野外拍摄图像的视觉质量，例如手机拍摄的照片。现有利用大型生成模型的方法虽然效果显著，但计算成本高、延迟大，不适合边缘部署。
### Innovation
介绍了一个超轻量级的一步生成模型PocketSR，该模型将生成建模能力应用到RealSR中同时保持高保真度。通过设计LiteED，一种替代原始计算密集型SD的高效替代方案，减少了97.5%的参数量，同时保持高质量编码和解码。还提出了在线退火剪枝技术，逐步将生成先验从重模块转移到轻模块，确保有效的知识转移。此外，引入多层特征蒸馏损失以减少剪枝过程中的先验知识损失。通过深入分析每个设计组件，为未来研究提供有价值的见解。PocketSR在4K图像处理中仅需0.8秒，显著优于先前的方法，且在单步和甚至多步骤RealSR模型中达到顶尖性能，适用于边缘设备应用
### Conclusion
PocketSR在模型大小仅为146M参数的情况下，实现了4K图像在0.8秒内的处理，克服了传统方法的计算成本和延迟问题，成为适用于边缘设备的高度实用解决方案。
## 448. `cs.CV` - ReeMark: Reeb Graphs for Simulating Patterns of Life in Spatiotemporal Trajectories [PDF](https://arxiv.org/pdf/2510.03152), [HTML](https://arxiv.org/abs/2510.03152)
### Authors
Anantajit Subrahmanya,Chandrakanth Gudavalli,Connor Levenson,Umang Garg,B.S. Manjunath
### Background
准确地建模人类移动对于城市规划、流行病学和交通管理至关重要。现有的方法能够捕捉日常生活的模式（PoLs），但常常存在不一致性或计算效率低下的问题。
### Innovation
本文提出了一种新的框架——Markovian Reeb Graphs（马尔可夫Reeb图），能够综合个体和群体的移动结构，通过概率拓扑模型生成真实的未来轨迹，充分保留日常生活的稳定性和多变性。
### Conclusion
通过在城市异常数据集（亚特兰大和柏林子集）上使用Jensen-Shannon散度（JSD）评估群体和代理级别指标，结果表明该方法在保真度和数据/计算效率方面表现出色。这使Markovian Reeb Graphs成为跨越不同城市环境的大规模轨迹仿真框架，具有广泛应用前景。
## 449. `cs.CV` - GeoComplete：几何感知扩散用于参考驱动的图像补全 [PDF](https://arxiv.org/pdf/2510.03110), [HTML](https://arxiv.org/abs/2510.03110)
### Authors
Beibei Lin,Tingting Chen,Robby T. Tan
### Background
参考驱动的图像补全任务涉及使用额外图像来恢复目标视图中缺失的区域，尤其当目标视图与参考视图有很大差异时尤为具有挑战性。现有的生成方法依赖于扩散先验，但在缺乏几何线索（如相机位姿或深度）的情况下，往往会生成对齐不当或不合理的图像内容。
### Innovation
我们提出了GeoComplete，一种新颖的框架，通过引入显式的3D结构指导来强制在补全区域中保持几何一致性，从而区别于仅基于图像的先前方法。GeoComplete提出了两个关键思想：通过投影点云对扩散过程进行条件化以注入几何信息，以及应用目标感知的掩蔽以引导模型跟踪相关的参考线索。该框架具有一条分支用于从掩蔽的目标中合成缺失区域，另一条分支从投影的点云中提取几何特征。跨分支的联合自注意力确保完成具有连贯性和准确性。为了解决在参考中可见但在目标中缺失的区域，我们将目标视图投影到每个参考中以检测被遮挡的区域，这些区域在训练时被掩蔽。这种目标感知的掩蔽策略促使模型专注于有用的线索，从而在困难场景中增强性能。
### Conclusion
通过整合几何感知的双分支扩散架构与目标感知的掩蔽策略，GeoComplete提供了一种统一且稳健的几何条件图像补全解决方案。实验表明，GeoComplete compared to the state-of-the-art方法，提升了17.1 PSNR，显著提高了几何准确性和高视觉质量。
## 450. `cs.CV` - HAVIR：使用CLIP引导的多功能扩散将层次视觉转化为图像重构 [PDF](https://arxiv.org/pdf/2510.03122), [HTML](https://arxiv.org/abs/2510.03122)
### Authors
Shiyi Zhang,Dong Liang,Hairong Zheng,Yihang Zhou
### Background
从大脑活动重建视觉信息促进了神经科学与计算机视觉的跨学科整合。然而，现有方法在准确恢复复杂视觉刺激方面仍然面临挑战。这种困难源于自然场景的特征：低级特征表现出异质性，而高级特征则由于上下文重叠而表现出语义纠缠。
### Innovation
受到视觉皮层分层表示理论的启发，我们提出了HAVIR模型。该模型将视觉皮层分为两个分层区域，并从每个区域提取不同特征。具体来说，结构生成器从空间处理体素中提取结构信息并转换为潜在扩散先验，而语义提取器则将语义处理体素转换为CLIP嵌入。这些组件通过多功能扩散模型集成，以合成最终图像。实验结果显示，HAVIR在复杂场景中提升了重构的结构和语义质量，并优于现有模型。
### Conclusion
HAVIR增强了在复杂场景中重建结构和语义质量，展示了优于现有模型的性能。
## 451. `cs.CV` - AdaRD-key: 自适应相关性多样性关键帧采样方法在长视频理解中的应用 [PDF](https://arxiv.org/pdf/2510.02778), [HTML](https://arxiv.org/abs/2510.02778)
### Authors
Xian Zhang,Zexi Wu,Zinuo Li,Hongming Xu,Luqi Gong,Farid Boussaid,Naoufel Werghi,Mohammed Bennamoun
### Background
对于长格式视频内容的理解依然是视觉-语言模型（VLMs）的一大挑战，原因在于其长时间轴和高信息密度。现有的大多数多模态大语言模型（MLLMs）依赖均匀采样，这通常会导致重要时刻被忽视，造成对查询的错误响应。同时，许多关键帧选择方法采用严格的时序间隔：一旦选定了某帧，附近的相邻时间戳会被排除以减少冗余，这一策略虽能有效限制重叠，但往往忽略了靠近重要事件的短而细腻的线索。有些方法则倾向于强调视觉多样性，但忽视了查询的相关性。
### Innovation
本文提出了一种名为AdaRD-Key的训练无监督关键帧采样模块，它采用联合相关性-多样性最大化体积（RD-MV）目标，结合查询条件相关分数与对数行列式多样性成分，以生成既具有建设性又非冗余的关键帧。为了处理与视频对齐较差的广泛查询，AdaRD-Key采用了一个轻量级的相关性感知门控机制；当相关性分布表明对齐较差时，方法会无缝切换到单纯多样性的模式，从而增强覆盖范围而无需额外监督。
### Conclusion
我们的管道是训练无监督的，计算效率高（在单个GPU上实时运行），并且以即插即用方式兼容现有的VLMs。在LongVideoBench和Video-MME上的广泛实验表明，我们的方法在长格式视频上的性能处于前沿水平。代码可在论文网页上获取。
## 452. `cs.CV` - SpineBench：一款基于SpineMed-450k语料库的临床相关且级别感知的基准测试 [PDF](https://arxiv.org/pdf/2510.03160), [HTML](https://arxiv.org/abs/2510.03160)
### Authors
Ming Zhao,Wenhui Dong,Yang Zhang,Xiang Zheng,Zhonghao Zhang,Zian Zhou,Yunzhi Guan,Liukun Xu,Wei Peng,Zhaoyang Gong,Zhicheng Zhang,Dachuan Li,Xiaosheng Ma,Yuli Ma,Jianing Ni,Changjiang Jiang,Lixia Tian,Qixin Chen,Kaishun Xia,Pingping Liu,Tongshun Zhang,Zhiqiang Liu,Zhongan Bi,Chenyang Si,Tiansheng Sun,Caifeng Shan
### Background
脊椎疾病影响全球6.19亿人口，并已成为导致残疾的主要原因，但人工智能辅助诊断仍受限于缺乏级别感知的多模态数据集。脊椎疾病临床决策需要在特定椎体水平上跨越X射线、CT和MRI的复杂推理，但由于缺乏可追溯的临床数据和标准化的脊椎特定基准，进展受到了限制。
### Innovation
本文介绍了由实践脊椎外科医生共同设计的SpineMed生态体系，其中包括SpineMed-450k——首个专为多模态影像在特定椎体水平推理设计的大规模数据集，以及SpineBench——一个临床相关评价框架。SpineMed-450k从多种来源 curated，包含文献、指南、开源数据集和1000个去标识化的医院病例，通过带注释人医循环流水线和两阶段LLM生成方法确保高质量、可追溯的数据。SpineBench从临床相关维度评估模型，包括椎体水平识别、病理评估和手术规划。通过对多个先进的大视图语言模型（LVLMs）在SpineBench上的综合评估，揭示了细粒度、特定椎体水平推理方面的系统性弱点，而我们的SpineMed-450k微调模型在所有任务上均表现出一致且显著的改进。
### Conclusion
临床评估证实了我们模型输出的诊断清晰度和实际实用价值。
## 453. `cs.CV` - 动态提示生成用于交互式3D医学图像分割训练 [PDF](https://arxiv.org/pdf/2510.03189), [HTML](https://arxiv.org/abs/2510.03189)
### Authors
Tidiane Camaret Ndir,Alexander Pfefferle,Robin Tibor Schirrmeister
### Background
交互式3D生物医学图像分割需要高效的模型，这些模型可以根据用户的提示不断迭代地细化预测。当前的基础模型要么缺乏体积感知，要么交互能力有限。该研究提出了一种结合动态体积提示生成和内容感知自适应裁剪的训练策略，以优化图像编码器的使用，并在单个GPU上处理来自序列细化反馈的计算挑战。研究表明，这种方法在“基础模型对于交互式3D医学图像分割”的竞赛中表现出色，平均Dice分数为0.6385，归一化表面距离为0.6614，曲线下面积指标分别为2.4799（Dice）和2.5671（NSD）。
### Innovation
提出了结合动态体积提示生成和内容感知自适应裁剪的训练策略，以优化图像编码器的使用，并在单个GPU上处理序列细化反馈带来的计算挑战。
### Conclusion
该方法在‘基础模型对于交互式3D医学图像分割’的竞赛中表现出色，平均Dice分数为0.6385，归一化表面距离为0.6614，曲线下面积指标分别为2.4799（Dice）和2.5671（NSD）
## 454. `cs.CV` - ROGR: 使用生成光照重建可重新照明的3D物体 [PDF](https://arxiv.org/pdf/2510.03163), [HTML](https://arxiv.org/abs/2510.03163)
### Authors
Jiapeng Tang,Matthew Lavine,Dor Verbin,Stephan J. Garbin,Matthias Nießner,Ricardo Martin Brualla,Pratul P. Srinivasan,Philipp Henzler
### Background
在多视角捕捉对象的基础上，本文提出了一个新颖的方法ROGR，通过生成的光照模型模拟在不同环境光照下物体的外观效果，重建一个可重新照明的对象3D模型。该方法可以为输入的环境光照生成物体的外观，不需要针对每种照明进行优化或光线传输模拟，实现了高效的前向重新光照。这一方法已在TensoIR和Stanford-ORB数据集上进行了评估，相比于现有方法，在大多数指标上获得了提升，并展示了在真实世界物体捕捉中的应用效果。
### Innovation
本文提出了一种新颖的方法ROGR，通过生成的光照模型模拟在不同环境光照下物体的外观效果，重建可重新照明的对象3D模型。该方法具有一体化的神经辐射场（NeRF）架构，可以分别编码一般照明效果和镜面反射特性。该方法使得在任意环境地图下实现高效前向重新光照成为可能，无需针对每个照明进行优化或光线传输模拟。
### Conclusion
本文提出的ROGR方法在TensoIR和Stanford-ORB数据集上的评估中，大多数指标上都提升了现有方法的表现，并在实际物体捕捉中展示了其应用效果。通过一体化的神经辐射场架构，该方法实现了高效的前向重新光照，为可重新照明的3D物体重建提供了新的解决方案。
## 455. `cs.CV` - Mask2IV：通过掩码轨迹实现以交互为中心的视频生成 [PDF](https://arxiv.org/pdf/2510.03135), [HTML](https://arxiv.org/abs/2510.03135)
### Authors
Gen Li,Bo Zhao,Jianfei Yang,Laura Sevilla-Lara
### Background
生成能够显示人类或机器人与物体交互的视频对于实现机器体智能至关重要，因为这些视频提供了丰富的视觉先验知识，有助于机器人的学习、操作策略训练和功能推理。然而，现有的方法难以精确模拟这些复杂的动态交互。尽管最近的研究表明，掩码可以作为有效的控制信号来提高生成质量，但是在实际应用中获取稠密且精确的掩码注解仍然是一项重大挑战。Mask2IV框架基于这种需求被设计出来，采用了一个解耦的两阶段流程，首先预测演员和物体的可能运动轨迹，然后在这些轨迹的基础上生成视频。这个设计去除了用户需要提供稠密掩码输入的需求，同时保持了对交互过程的灵活性和控制能力。
### Innovation
Mask2IV框架通过结合解耦的两阶段流程，首先预测运动轨迹，然后生成视频，不需要用户提供稠密的掩码输入，同时允许用户通过动作描述或空间位置提示来控制交互对象和运动轨迹，从而增强了交互视频生成的灵活性和可控性。此外，该框架还为模型提供了一个包含丰富交互动作和对象种类的基准数据集，以支持系统的训练和评估。研究表明，Mask2IV方法在视觉真实性和可控性方面优于现有的基线方法。
### Conclusion
Mask2IV提供了一种新颖的方法来生成以交互为中心的视频，通过预测运动轨迹并生成视频，无需用户输入稠密的掩码注解，同时支持灵活和直观的交互控制。通过与现有基线方法的广泛实验比较，我们的方法在视觉真实性方面表现出色，并且具有更高的可控性。此外，我们还建立了一个基准数据集，包含不同类型的动作和对象类别，以支持模型的训练和评估。
## 456. `cs.CV` - Latent Diffusion Unlearning: Protecting Against Unauthorized Personalization Through Trajectory Shifted Perturbations [PDF](https://arxiv.org/pdf/2510.03089), [HTML](https://arxiv.org/abs/2510.03089)
### Authors
Naresh Kumar Devulapally,Shruti Agarwal,Tejas Gokhale,Vishnu Suresh Lokhande
### Background
文本到图像的扩散模型在提供少量用户图像时能够实现快速和高保真的个性化，但这也引发了数据隐私、知识产权保护等方面的安全担忧。现有的去个性化方法在像素空间中操作，导致生成的图像存在噪声和伪影。基于此，本文探讨了在扩散模型的潜在空间中利用图像污染技术生成不可学习的数据样本的方法。
### Innovation
本文提出了一种新颖的基于模型的扰动策略，该策略在扩散模型的潜在空间中操作。该方法交替进行去噪和反向运算，同时改变去噪趋势的起始点。这种轨迹偏移抽样确保扰动图像在保持视觉保真度的同时，对下游生成模型具有抗逆向操作和个性化的性质。这一方法将不可学习性整合到潜在扩散模型（LDMs）框架中，提供了一种实用且难以察觉的防止未经授权模型适应的保护机制。
### Conclusion
本文的方法在四个基准数据集上得到了验证，其在感知度量指标（包括PSNR、SSIM和FID）和对抗性的五个设置中都展示了较高的不可察觉性和鲁棒性。结果突显了其在保护敏感数据方面的有效性。
## 457. `cs.CV` - 通过先进模态条件和交互驯服文本到声像视频生成 [PDF](https://arxiv.org/pdf/2510.03117), [HTML](https://arxiv.org/abs/2510.03117)
### Authors
Kaisi Guan,Xihua Wang,Zhengfeng Lai,Xin Cheng,Peng Zhang,XiaoJiang Liu,Ruihua Song,Meng Cao
### Background
本研究聚焦于具有挑战性但前景广阔的任务——文本到同步视频（T2SV）生成。该任务旨在从文本描述中生成具有同步音频的视频，同时确保视频和音频模态与文本的同步性。尽管在联合音频视频训练方面取得了一定进展，仍存在两个关键挑战：（1）使用共享的单一文本描述，使视频文本与音频文本相同，造成模态间的干扰，干扰预训练的骨干网络；（2）跨模态特征交互的最佳机制尚未明确。为了应对这些挑战，研究提出了一种新的框架——分层视觉指导描述（HVGC），通过生成分离的视频描述和音频描述，消除在条件阶段的模态干扰。基于HVGC，进一步引入了BridgeDiT，这是一种新颖的双塔扩散变换器，通过使用一种稳健的‘桥梁’机制——双重交叉注意力（DCA），实现语义和时间同步的双向信息交换。
### Innovation
提出了分层视觉指导描述（HVGC）框架，该框架生成分离的视频描述和音频描述，消除模态干扰；基于HVGC，提出了BridgeDiT，这是一种新颖的双塔扩散变换器，采用了双重交叉注意力（DCA）机制，实现语义和时间同步的信息双向交互，增强跨模态特征交互的机制。
### Conclusion
在三个基准数据集上的广泛实验和人类评估表明，我们的方法在大多数指标上达到了最先进的效果。全面的消融研究进一步验证了我们贡献的有效性，为未来的T2SV任务提供了宝贵的见解。所有代码和检查点将公开发布。
## 458. `cs.CV` - 通过潜在集成的随机共振对抗攻击的测试时防御 [PDF](https://arxiv.org/pdf/2510.03224), [HTML](https://arxiv.org/abs/2510.03224)
### Authors
Dong Lao,Yuxiang Zhang,Haniyeh Ehsani Oskouie,Yangchao Wu,Alex Wong,Stefano Soatto
### Background
现有的对抗攻击防御方法主要依赖于特征过滤或平滑，这些方法可能会导致信息丢失。本文提出了一种全新的测试时防御机制，通过利用随机共振来增强模型的鲁棒性，同时尽量减少信息损失。
### Innovation
本文提出了一种“用噪声对抗噪声”的防御机制，通过引入不可感知的小平移插值到输入图像中，对特征嵌入进行对齐并聚合再映射回原参考图像。这种机制不依赖于额外的网络模块或针对特定攻击类型的微调，并且完全不需要训练，具有架构无关性和攻击无关性。
### Conclusion
实验结果表明，该方法在图像分类任务中达到了最先进的鲁棒性，并首次为稠密预测任务（包括立体匹配和光学流）建立了通用的测试时防御机制，这展示了该方法的灵活性和实用性。具体而言，相对于清洁（未受干扰）性能，在各种类型的对抗攻击下，方法分别恢复了68.1%的图像分类准确性损失、71.9%的立体匹配准确性损失和29.2%的光学流准确性损失。
## 459. `cs.CV` - 通过显式位置到坐标映射提高GUI接地 [PDF](https://arxiv.org/pdf/2510.03230), [HTML](https://arxiv.org/abs/2510.03230)
### Authors
Suyuchen Wang,Tianyu Zhang,Ahmed Masry,Christopher Pal,Spandana Gella,Bang Liu,Perouz Taslakian
### Background
GUI接地任务是将自然语言指令映射到像素坐标，对于自主代理至关重要，但当前的VLMs难以完成。核心瓶颈在于可靠地进行块到像素的映射，在面对未见过的高分辨率屏幕时会失效。当前方法直接从视觉特征生成坐标，迫使模型隐式地推导复杂的位置到像素的映射；因此，随着新分辨率的出现，准确率会降低，失败率会增加。
### Innovation
我们提出了两种互补的创新。首先，RULER token用作显式的坐标标记，使模型能够参考位置类似于地图上的网格线，调整而不是从头生成坐标。其次，交错的MRoPE (I-MRoPE) 改进了空间编码，确保宽度和高度维度被平等表示，解决了标准位置方案的不对称性。
### Conclusion
我们的实验在ScreenSpot、ScreenSpot-V2和ScreenSpot-Pro上显示了一致的接地准确率提升，特别是在高分辨率界面方面改进最大。通过提供显式的空间指导而非依赖隐含学习，我们的方法能在多种分辨率和平台上实现更可靠的GUI自动化。
## 460. `cs.CV` - 产品量化图像表示及其在高质量图像合成中的应用 [PDF](https://arxiv.org/pdf/2510.03191), [HTML](https://arxiv.org/abs/2510.03191)
### Authors
Denis Zavadski,Nikita Philip Tatsch,Carsten Rother
### Background
产品量化（PQ）是一种经典的向量编码方法，但其在高层次图像生成中的潜在应用并未得到充分探索，尤其是在生成优质图像时的潜在用途，尤其是在作为潜在表示方面更是如此。产品量化图像自编码器（PQGAN）将PQ集成到VQGAN的向量量化（VQ）框架中，旨在利用产品量化技术对潜在向量进行量化编码，从而实现高品质图像的生成，显著提升图像重构性能，包括量化方法及其连续版本。
### Innovation
该研究的主要创新在于通过分析代码本大小、嵌入维度和子空间因式分解之间的相互作用，引入了PQGAN，展示了当调整嵌入维度时，VQ和PQ的性能表现呈现相反的趋势。此外，该研究确立了产品量化（PQ）的性能趋势，为选择最优超参数提供了指导。进一步，研究证明PQGAN可以无缝集成到预训练的扩散模型中，优化图像生成过程，提高生成速度和计算效率或增加输出分辨率。
### Conclusion
PQGAN在图像重建性能上取得了显著提升，相比于此前的工作，峰值信噪比（PSNR）提高了10dB，FID、LPIPS和CMMD得分分别降低了96%。通过这一创新性的方法，产品量化不仅提升了图像合成的品质，还展示了其作为离散潜在表示的强大扩展作用。
## 461. `cs.CV` - MIXER: 混合超球面随机嵌入神经网络在纹理识别中的应用 [PDF](https://arxiv.org/pdf/2510.03228), [HTML](https://arxiv.org/abs/2510.03228)
### Authors
Ricardo T. Fares,Lucas C. Ribas
### Background
随机神经网络在纹理识别任务中表现突出，有效地结合了传统技术和学习方法的优势。然而，现有方法主要集中在提高跨信息预测的效果上，未能在整体随机网络架构上带来显著改进。
### Innovation
本文提出了一种名为Mixer的新型随机神经网络，用于纹理表示学习。Mixer的核心在于利用超球面随机嵌入与双分支学习模块来捕捉图像中的内部和跨通道关系，并通过一个新的优化问题构建丰富的纹理表示。
### Conclusion
实验结果表明，该提出的Mixer方法在多个纯纹理基准数据集上表现出有趣的性能，并将在发表后提供源代码供进一步研究。
## 462. `cs.CV` - LEAML：针对多模态大语言模型的标签高效适应于出分布视觉任务 [PDF](https://arxiv.org/pdf/2510.03232), [HTML](https://arxiv.org/abs/2510.03232)
### Authors
Ci-Siang Lin,Min-Hung Chen,Yu-Yang Sheng,Yu-Chiang Frank Wang
### Background
多模态大语言模型（MLLMs）在通用视觉基准上表现出色，但在医学成像等专业领域的特定任务（如医学成像）中遇到了瓶颈，尤其是在标签数据有限且昂贵的情况下，模型难以应对出分布（OOD）任务。
### Innovation
介绍了LEAML（标签高效适应框架），该框架利用稀缺的标注VQA样本和丰富的未标注图像。通过问答生成器用描述词提取正则化，生成与领域相关的伪问答对，仅选择性地更新与问答最相关的神经元，促进问答生成器在蒸馏过程中高效获取领域特定知识。该方法在胃肠内窥镜和体育问答中的实验结果表明，在最小监督下，LEAML框架显著优于标准微调方法。
### Conclusion
实验结果表明，在最少监督下，LEAML框架在胃肠内窥镜和体育问答任务中持续优于标准微调方法，证明了提出LEAML框架的有效性。
## 463. `cs.CV` - Memory Forcing: 跨时空记忆在Minecraft一致场景生成中的应用 [PDF](https://arxiv.org/pdf/2510.03198), [HTML](https://arxiv.org/abs/2510.03198)
### Authors
Junchao Huang,Xinting Hu,Boyao Han,Shaoshuai Shi,Zhuotao Tian,Tianyu He,Li Jiang
### Background
自回归视频扩散模型在世界建模和交互场景生成中已被证明是有效的，Minecraft游戏是这种应用的典型案例。为了真实地模拟游戏过程，模型不仅需要生成自然内容并探索新的场景，还必须在重新访问已探索的区域时维持空间一致性。在有限的计算预算下，模型需要在有限的上下文窗口中压缩和利用历史线索，这揭示了一种权衡：仅基于时间的记忆缺乏长期的空间一致性，而添加空间记忆会增强一致性，但可能会因模型过度依赖不足的空间上下文而导致新场景生成质量下降。
### Innovation
我们提出了一种学习框架——Memory Forcing，它结合了训练协议和几何索引的空间记忆。混合训练暴露了不同的游戏模式，能够引导模型在探索过程中依赖于时间记忆，在重新访问时结合使用空间记忆。链式前向训练通过增加预测的顺序改进了自回归训练，这种链式预测促成了更大的姿态变化，并鼓励依赖空间记忆维持一致性。点到帧检索通过将当前可见点映射到其源帧来高效检索历史记录，而增量3D重建则维护和更新了一个显式的3D缓存。实验表明，Memory Forcing 在多种环境中实现了优越的长时间空间一致性和生成质量，同时也保持了在长时间序列中的计算效率。
### Conclusion
Memory Forcing 实现了在多变的环境中长时间的空间一致性和生成质量，同时保持了计算效率，为Minecraft等复杂游戏场景的生成提供了有效的解决方案。
## 464. `cs.CV` - MonSTeR: 统一的运动、场景、文本检索模型 [PDF](https://arxiv.org/pdf/2510.03200), [HTML](https://arxiv.org/abs/2510.03200)
### Authors
Luca Collorone,Matteo Gioia,Massimiliano Pappa,Paolo Leoni,Giovanni Ficarra,Or Litany,Indro Spinelli,Fabio Galasso
### Background
人类在复杂环境中移动受意图驱动，但这种移动需要周围环境的支持。尽管这一机制是直观的，现有研究尚未提供工具来评估骨骼运动（动作）、意图（文本）和周围环境（场景）之间的对齐情况。
### Innovation
引入了MonSTeR模型，这是一个统一的运动-场景-文本检索模型。受到更高阶关系建模的启发，MonSTeR通过利用单模态和跨模态表示构建了一个统一的潜在空间，使其能够捕捉模态之间的复杂的依赖关系，从而在各种任务中提供灵活且稳健的检索能力。实验结果表明，MonSTeR在三模态模型上表现更优，且其检索分数与人类偏好高度一致。
### Conclusion
MonSTeR在场景内对象放置和运动字幕生成等零样本任务中展示了其潜在空间的通用性。此模型和预训练模型可在指定网址下载。
## 465. `cs.CV` - 让语言模型感知的词语 [PDF](https://arxiv.org/pdf/2510.02425), [HTML](https://arxiv.org/abs/2510.02425)
### Authors
Sophie L. Wang,Phillip Isola,Brian Cheung
### Background
本文探讨了大型语言模型（LLMs）虽然仅基于文本训练，但其内部表示仍然隐含地受到语言中 multimodal regularities 的影响。提出了一种通过向 LLMs 提供感官提示，使它们内部的表示更接近专业视觉和音频编码器的方法。
### Innovation
本文证明，通过提供特定的感官提示（如告诉模型“看到”或“听到”），可以在不修改模型本身的情况下，使文本训练的 LLMs 激活相应模态的内部表示，从而更接近专业视觉和音频模型的表示。这种方法被称为轻量级提示工程。
### Conclusion
通过这一轻量级提示工程，可以实现在不重训练 LLMs 的情况下，激活它们的模态特定表示，从而使 LLMs 更接近专业视觉和音频编码器的表示。
## 466. `cs.CV` - 安全且鲁棒的AI生成图像水印技术综述 [PDF](https://arxiv.org/pdf/2510.02384), [HTML](https://arxiv.org/abs/2510.02384)
### Authors
Jie Cao,Qi Li,Zelin Zhang,Jianbing Ni
### Background
生成式人工智能（Gen-AI）的发展促进了高质量图像的轻松创造，但同时也引发了知识产权保护、真实性及问责制等方面的关切。为应对这些挑战，水印技术被视为潜在解决方案，通过区分辨识AI生成图像与自然图像，确保图像的来源，并促进可信赖的数字生态系统。
### Innovation
本文提供了一份全面的AI生成图像水印技术综述，涵盖了五个关键维度：（1）水印系统的形式化；（2）不同水印技术的概述与比较；（3）针对视觉质量、容量和可检测性的评估方法；（4）对恶意攻击的脆弱性；以及（5）现存问题与未来方向。
### Conclusion
本文旨在帮助研究人员获得对AI生成图像水印技术的全面理解，从而促进这一领域的持续发展。
## 467. `cs.CV` - GCVAMD：一种用于因果年龄相关黄斑变性疾病风险因素检测和预测的改良因果VAE模型 [PDF](https://arxiv.org/pdf/2510.02781), [HTML](https://arxiv.org/abs/2510.02781)
### Authors
Daeyoung Kim
### Background
年龄相关黄斑变性（AMD）是导致眼科永久性视力受损的主要原因之一。虽然已开发了诸如抗VEGF药物或光动力疗法等治疗方法来减缓AMD的退化过程，但仍缺乏专门用于逆转AMD引起的视力损失的治疗方法。因此，在早期阶段通过传统方法或其他方法检测患者黄斑中AMD的早期存在或风险因素对于减小视力受损的可能性至关重要。尽管基于深度学习的方法，尤其是基于注意力机制的CNN和基于GradCAM的XAI分析在区分AMD视网膜和正常视网膜方面表现出色，能够辅助眼科医生使用AI驱动的模型进行AMD诊断和分析，但以往的研究主要关注预测性能本身，而非AMD的病理学或潜在因果机制，这可能阻碍针对特定因素进行干预分析或是导致决策不够可靠。
### Innovation
本文介绍了一种新的因果AMD分析模型——GCVAMD，该模型结合了改进的因果VAE方法，可以从仅有的原始OCT图像中提取潜在因果因素。通过将因果关系纳入AMD检测，GCVAMD不仅可以进行因果推断，如治疗模拟或针对主要风险因素（如硬性渗出和新生血管化）的干预分析，同时还返回具有信息性的潜在因果特征，能够增强后续任务。
### Conclusion
研究表明，通过GCVAMD，可以识别AMD因果机制中的硬性渗出和新生血管化状态，这些机制可以用于AMD检测（分类）和干预分析等各种任务。
## 468. `cs.CV` - SIMSplat: 使用语言对齐4D高斯点积进行预测性驾驶场景编辑 [PDF](https://arxiv.org/pdf/2510.02469), [HTML](https://arxiv.org/abs/2510.02469)
### Authors
Sung-Yeon Park,Adam Lee,Juanwu Lu,Can Cui,Luyang Jiang,Rohit Gupta,Kyungtae Han,Ahmadreza Moradipari,Ziran Wang
### Background
基于传感器数据的驾驶场景操纵正在成为传统虚拟驾驶模拟器的有前途的替代方案。然而，现有的框架难以高效生成真实的场景，主要是因为编辑能力有限。
### Innovation
提出了SIMSplat，这是一种具备语言对齐高斯点积的预测性驾驶场景编辑器。SIMSplat作为一种语言控制的编辑器，可以使用自然语言提示进行直观操作。通过将语言与高斯重构的场景对齐，它还支持直接查询道路物体，实现精细灵活的编辑。该方法提供了详细的物体级编辑功能，包括添加新物体和修改车辆和行人的轨迹，同时通过多智能体运动预测进行预测路径优化，以产生场景中所有智能体的真实交互。实验表明，SIMSplat具备广泛的编辑能力和场景适应性。
### Conclusion
SIMSplat在Waymo数据集上的实验展示了其广泛的编辑能力和在各种场景中的适应性。
## 469. `cs.CV` - 从数据的信息-估计几何中学习距离度量 [PDF](https://arxiv.org/pdf/2510.02514), [HTML](https://arxiv.org/abs/2510.02514)
### Authors
Guy Ohayon,Pierre-Etienne H. Fiquet,Florentin Guth,Jona Ballé,Eero P. Simoncelli
### Background
本文介绍了一种新颖的距离度量方法——信息-估计度量（IEM），它源自信号域上的连续概率密度。IEM 建立在信息论和估计论之间的重要联系上，将信号的对数概率与最佳去噪器应用于噪声信号的误差联系起来。对于高斯分布的信号，IEM 与马氏距离一致。但在更复杂的分布中，IEM 能够根据分布几何的局部和全局特性进行调整。实践表明，IEM 可以通过训练一个学习的去噪器（模仿生成扩散模型）和计算一维积分来实现。
### Innovation
本文提出了一种新的距离度量IEM，基于概率密度和信号对数概率的关联。IEM不仅适用于高斯信号，还能根据信号的几何结构进行局部和全局的适应。该度量可以通过学习去噪模型来计算，并且实验表明在预测人类感知方面具有竞争力或更优的表现。
### Conclusion
学习了Imagenet数据库中的IEM后，实验结果表明IEM在预测人类感知判断方面与最新的监督图像质量度量方法具有竞争力或表现更优。
## 470. `cs.CV` - 达尔文遇见 Langevin：一种基于几何布朗运动的乘性去噪扩散模型 [PDF](https://arxiv.org/pdf/2510.02730), [HTML](https://arxiv.org/abs/2510.02730)
### Authors
Nishanth Shetty,Madhava Prasath,Chandra Sekhar Seelamantula
### Background
梯度下降已被证明是机器学习中多种优化应用的强大而有效的技术。然而，标准的梯度下降优化公式在计算神经科学中的学习过程与生物系统中的学习过程不一致，这为构建生物启发的学习技术开辟了新的途径。Dale定律指出，在学习过程中抑制性和兴奋性突触不会交换作用，由此产生的指数梯度下降优化方案导致突触权重呈对数正态分布。该论文提出了一种新的形式，用于基于乘性去噪评分匹配，包括海沃申请提出的非负数据损失函数。文中利用对数正态分布数据的特性，展示了如何训练基于评分的图像生成模型，提出了一个新颖的乘性更新方案，从对数正态密度开始生成样本。实验结果在MNIST、Fashion MNIST和Kuzushiji数据集上展示了新方案的生成能力。
### Innovation
提出了一种基于几何布朗运动的乘法去噪扩散模型，该模型借鉴了Dale定律。通过与对数正态密度的连接，提出了一个新的乘法评分匹配形式主义，适用于对数正态分布的图像数据。该工作首次提出了基于几何布朗运动的生物启发的生成模型，采用乘法更新方案。
### Conclusion
实验结果表明，该方法在MNIST、Fashion MNIST和Kuzushiji数据集上具有生成能力。这是首次使用基于几何布朗运动的具有乘法更新的生物启发生成模型实例。
## 471. `cs.CV` - 压缩感知比较下的统计方法实现攻击无差别对抗攻击检测 [PDF](https://arxiv.org/pdf/2510.02707), [HTML](https://arxiv.org/abs/2510.02707)
### Authors
Chinthana Wimalasuriya,Spyros Tragoudas
### Background
现代机器学习系统面临着来自对抗攻击的重大威胁，但现有的检测方法通常不具备检测未见过的攻击或以高精度检测不同攻击类型的能力。已有研究尚未提供一种在神经网络部署前建立检测基准的有效方法，以实现实时对抗攻击检测的有效性。论文提出了一个统计方法，在压缩与未压缩神经网络之间进行行为比较，生成对抗存在的度量标准，这种方法可以在多种攻击类型下实现近乎完美的检测，并显著减少误报，使其在真实世界应用中既可靠又实用.
### Innovation
论文提出了一种统计方法，通过比较压缩和未压缩神经网络的行为来检测对抗攻击，这种方法能够实现在多种攻击类型下近乎完美的检测，并且显著减少误报。与最先进的技术相比，新方法具备更高的可靠性和实际应用价值.
### Conclusion
该方法已通过先进的技术测试，展示了在多种攻击类型下的优异检测性能，并且具备显著减少误报的优点，使得它在实际应用中既可靠又实用，为实现精准的实时对抗攻击检测提供了新的解决方案。
## 472. `cs.CV` - 基于UAV的VNIR超光谱基准数据集在地雷和未爆炸弹药检测中的应用 [PDF](https://arxiv.org/pdf/2510.02700), [HTML](https://arxiv.org/abs/2510.02700)
### Authors
Sagar Lekhak,Emmett J. Ientilucci,Jasper Baur,Susmita Ghosh
### Background
本文介绍了一个新的可见和近红外（VNIR）超光谱影像基准数据集，该数据集采用无人机平台收集，用于研究地雷和未爆炸弹药（UXO）的检测。该数据集在受控实验田中播种了143个现实的替代地雷和UXO目标，包括地表、部分埋藏和完全埋藏的配置。数据通过安装在多传感器无人机平台上的Headwall Nano-Hyperspec传感器收集，飞行高度约为20.6米，捕捉到270个连续的光谱波段（398-1002 nm）。经过辐射校准、正射校正和镶嵌处理，采用两点法经验线方法获取反射率，参考光谱使用SVC光谱辐射计获得。在400-900 nm范围内，交叉验证得到的RMSE值低于1.0，SAM值在1-6度之间，表明具有高光谱保真度。
### Innovation
本文的数据集填补了公开可用的基于无人机的VNIR超光谱数据在地雷检测方面的空白。该数据集与先前发布的来自同一样地的无人机电磁感应（EMI）数据相结合，可作为多传感器基准数据。数据集随附原始辐射亮度立方体、GCP/AeroPoint数据和参考光谱，支持可重复研究。
### Conclusion
该数据集的发布为地雷和未爆炸弹药的检测研究提供了重要的支持，同时，其高光谱保真度进一步提升了无人机超光谱技术在地雷检测中的应用价值。
## 473. `cs.CV` - 基于颜料表示的图像增强 [PDF](https://arxiv.org/pdf/2510.02713), [HTML](https://arxiv.org/abs/2510.02713)
### Authors
Se-Ho Lee,Keunsoo Ko,Seung-Wook Kim
### Background
传统的图像增强方法通常在预定义的颜色空间（如RGB）中进行颜色变换。然而，这些方法在处理图像内容时缺乏适应性和表达性，无法有效提升图像质量。本文提出了一种基于颜料表示的新型高效图像增强方法，通过将RGB颜色转换到一个高维特征空间（颜料空间）来实现更加动态和适应性的颜色变换，进而提升图像增强性能。
### Innovation
该研究创新性地提出了颜料表示的方法，即将RGB颜色转换到高维的颜料空间进行颜色变换，然后单独重新投影和混合，最后将颜料重新转换回RGB颜色以生成增强后的输出图像。这种方法能够更好地适应输入图像的内容，从而实现更高质量的图像增强。此外，变换和重新投影的参数是通过视觉编码器自适应估计出来的，以适应输入图像中的内容。实验结果表明，该方法在包括图像润饰和色调映射等多种图像增强任务中表现优于现有最先进的方法，同时保持较低的计算复杂度和较小的模型大小。
### Conclusion
本文提出的方法在多种图像增强任务中表现出优越的性能，尤其是在图像润饰和色调映射等方面，同时运行效率较高。
## 474. `cs.CV` - UniShield: 一个适应性的多智能体框架，用于统一的伪造图像检测与定位 [PDF](https://arxiv.org/pdf/2510.03161), [HTML](https://arxiv.org/abs/2510.03161)
### Authors
Qing Huang,Zhipei Xu,Xuanyu Zhang,Jian Zhang
### Background
随着图像生成技术的迅速发展，合成图像变得越来越真实，这对社会带来了严重的风险，如信息误导和欺诈。因此，伪造图像检测与定位（FIDL）成为保持信息完整性和社会安全的重要工具。尽管现有的领域特定检测方法展现了出色的性能，但它们的实际应用仍然有限。主要问题包括其狭隘的专业性、较差的跨领域泛化能力和缺乏集成的适应性框架。
### Innovation
我们提出了UniShield，这是一种新颖的基于多智能体的统一系统，能够跨多种领域检测和定位图像伪造，包括图像处理、文档篡改、DeepFake和AI生成的图像。UniShield创新地结合了一个感知代理和一个检测代理。感知代理智能分析图像特征以动态选择适合的检测模型，而检测代理则将各种专家检测器整合到一个统一框架中，并生成可解释的报告。广泛的实验表明，UniShield达到了最先进的成果，突破了现有的统一方法和领域特定检测器的所有限制，体现了其卓越的实用性、适应性和可扩展性。
### Conclusion
实验结果表明，UniShield在伪造图像检测与定位方面取得了最先进的结果，不仅优于现有的统一方法，也超越了领域特定的检测器，突显了其卓越的实用性、适应性和可扩展性。
## 475. `cs.CV` - 任务区挑战VLM轨迹规划：迈向缓解与稳健自主驾驶 [PDF](https://arxiv.org/pdf/2510.02803), [HTML](https://arxiv.org/abs/2510.02803)
### Authors
Yifan Liao,Zhen Sun,Xiaoyun Qiu,Zixiao Zhao,Wenbing Tang,Xinlei He,Xinhu Zheng,Tianwei Zhang,Xinyi Huang,Xingshuo Han
### Background
视觉语言模型（VLMs）因其强大的多模态推理能力，逐渐被汽车制造商集成到自动驾驶中，以增强在复杂环境中的规划能力。然而，这些模型在工作区的轨迹规划能力尚未研究，特别是在包含非规则布局、临时交通控制和动态几何结构变化的工作区。现有研究未能充分考察这一问题，导致现有的VLMs在68.0%的情况下生成错误的轨迹。
### Innovation
该研究首次系统地研究了VLMs在工作区轨迹规划中的应用，并通过使用子图挖掘和聚类分析识别了候选模式，同时通过人工验证确认了8种常见的失败模式。基于这些发现，研究提出了一种名为REACT-Drive的轨迹规划框架，该框架将VLMs与检索增强生成（RAG）结合，利用VLMs将先前的失败案例转化为约束规则和可执行的轨迹规划代码，而RAG则能检索新场景中的相似模式以指导轨迹生成。实验结果显示，REACT-Drive在平均偏移误差上比VLM基线降低了约3倍，且在推断时间上比其他方法（如微调）显著更短，仅为0.58秒。此外，通过真实车辆在15个工作区场景中的实际测试，进一步证明了REACT-Drive的强实用性。
### Conclusion
研究表明，当前的VLMs在生成工作区的正确轨迹上存在显著挑战。为解决这一问题，提出了REACT-Drive框架，利用VLMs和RAG相结合的方法，显著提高了轨迹规划的准确性和效率，同时保持了快速的推断时间，展示了其实用价值。
## 476. `cs.CV` - 代表美感：迈向一种参与但客观的潜在美学 [PDF](https://arxiv.org/pdf/2510.02869), [HTML](https://arxiv.org/abs/2510.02869)
### Authors
Alexander Michael Rusnak
### Background
美感是一个在文化和经验上引人入胜但哲学上却难以捉摸的概念。然而，深度学习系统越来越能够模拟美学判断。本文探讨了尽管“美”这个词适用于形式上极其多样的对象，神经网络仍然有能力表示这一概念的能力。
### Innovation
通过借鉴跨模型表达收敛的最新研究成果，本文展示了审美效果可以使不同数据和模态下训练的模型产生更相似和对齐的表示，而非审美图像则不会产生更多的对齐表示。这一发现暗示了美好图像的正式结构有着现实基础，而非只是社会构建的价值观的反映。进一步，本文提出审美形式在物理和文化基础之间的联合接地让这些现实主义表示存在可能性。人类感知和创造行为在形成深度学习系统的潜在空间中扮演着中心角色，而现实主义美学的基础表明，机器不仅仅是创造性鹦鹉，它们可以从独特的尺度视角产生新的创造性洞见。此外，研究结果表明，人机共创不仅可行，而且是基础性的，美的存在作为文化生产和机器感知的目标导向诱因。
### Conclusion
本文研究发现，尽管存在着形式上的多样性，神经网络依然能够表示“美”这一概念。审美效果产生的模型表示更加一致和对齐，而非审美表示则不会产生这种对齐。这一发现表明，美的形式具有现实基础，而非仅仅是社会价值观的反映。同时，人类感知和创造行为影响着深度学习系统的潜在空间，但美的现实主义基础意味着机器不仅仅是创造模仿者，它们还可以从独特视角产生新的创造性洞见。人机共创不仅是可能的，而是文化和机器感知的基础，美的存在是这一过程的目标导向因素。
## 477. `cs.CV` - MM-Nav: 多视图VLA模型通过多专家学习实现稳健的视觉导航 [PDF](https://arxiv.org/pdf/2510.03142), [HTML](https://arxiv.org/abs/2510.03142)
### Authors
Tianyu Xu,Jiawei Chen,Jiazhao Zhang,Wenyao Zhang,Zekun Qi,Minghan Li,Zhizheng Zhang,He Wang
### Background
视觉导航策略通常被认为是一个有前景的方向，因为它通过第一人称视角的视觉观察来模仿人类的导航方式。然而，视觉观察中的光学信息难以像激光雷达点云或深度图那样明确建模，这需要智能模型和大规模数据。为了解决这个问题，论文提出利用Vision-Language-Action (VLA)模型的智能来从合成专家数据中学习多样的导航能力。从三个使用特权深度信息训练的强化学习(RL)专家在三个针对不同导航能力定制的环境中收集专家数据：接近、挤压、规避。
### Innovation
该研究创新性地开发了一种多视图VLA模型（MM-Nav），基于预训练的大语言模型和视觉基础模型。该模型通过多专家学习，从合成数据中学习多种导航能力。此外，研究设计了一种迭代训练方法，根据每个能力的性能动态平衡训练数据的比例。研究结果表明，学生VLA模型在各特定导航能力上均优于RL教师模型，展示了集成多种能力的协同效应。
### Conclusion
在合成环境中进行的广泛实验表明，该模型具有强大的泛化能力。进一步的实地实验验证了该方法的有效性。
## 478. `cs.CV` - 基于置信度和离散性的信号：无监督模型评估和排名 [PDF](https://arxiv.org/pdf/2510.02956), [HTML](https://arxiv.org/abs/2510.02956)
### Authors
Weijian Deng,Weijie Tu,Ibrahim Radwan,Mohammad Abu Alsheikh,Stephen Gould,Liang Zheng
### Background
在实际部署中，评估模型的泛化能力至关重要，尤其是当未标记的测试数据不可用时。本研究探讨了一种统一的无监督模型评估和排名框架，适用于两种常见的部署场景：一是估计固定模型在多个未标记测试集上的准确性（数据集中心评估）；二是根据单一未标记测试集对候选模型进行排名（模型中心评估）
### Innovation
研究表明模型预测的两个内在属性——置信度（反映预测确定性）和离散性（捕捉预测类别的多样性）——提供了对泛化能力的强大而互补的信号。研究系统性地对比了基于置信度、离散性和混合指标的多种性能评估指标在各种模型架构、数据集和分布偏移类型下的表现，并发现混合指标在数据集中心和模型中心的评估场景下表现更稳定且更优越。特别是预测矩阵的核范数在各种任务中，包括实际数据集上，提供了稳定的准确性能，并在轻度类别不平衡时保持可靠性
### Conclusion
研究结果为部署场景下的无监督模型评估提供了一个实用且可推广的基础，通过基于置信度和离散性的混合指标来可靠地评估模型性能
## 479. `cs.CV` - Filter-Guided Diffusion for Controllable Image Generation [PDF](https://arxiv.org/pdf/2306.17141), [HTML](https://arxiv.org/abs/2306.17141)
### Authors
Zeqi Gu,Ethan Yang,Abe Davis
### Background
近年来基于扩散的生成模型在零样本图像到图像的转换和编辑方面展现出极大的潜力。大多数这类方法通过在生成新图像时结合或替换某些引导图像反向过程中的特征来进行工作。虽然这类方法被认为是当前无需训练的最先进的方法，但它们在运行时间和内存方面较为昂贵，并且通常依赖于确定性采样，这限制了生成结果的多样性。
### Innovation
本文提出了一种名为Filter-Guided Diffusion (FGD)的新方法，利用在扩散过程中快速的滤波操作来支持对引导强度和频率的精细控制，并且能够与非确定性采样器结合使用以产生更多的多样性。FGD比其他当前最先进方法具有更高的效率，可以在生成结构和语义指标更优结果的同时，更快地完成多次采样和超参数的实验。
### Conclusion
通过广泛的定量和定性实验评估了FGD在转换任务中的性能，并展示了其在使用掩码时进行局部编辑的潜力。FGD可以更快速地得到多种子和超参数的不同结果，并且生成的结果在结构和语义上都更优秀。
## 480. `cs.CV` - 比较YOLOv8和Mask R-CNN在复杂果园环境中的实例分割 [PDF](https://arxiv.org/pdf/2312.07935), [HTML](https://arxiv.org/abs/2312.07935)
### Authors
Ranjan Sapkota,Dawood Ahmed,Manoj Karkee
### Background
实例分割是农业自动化的重要图像处理操作，为精准界定图像中的个体对象提供了基础，并支持如选择性收获和精确修剪等任务。研究对比了在不同果园条件下，YOLOv8单阶段模型与Mask R-CNN双阶段模型的实例分割性能。
### Innovation
研究发现，YOLOv8在复杂果园环境中的实例分割表现更优，具有更高的精度和近乎完美的召回率，并且具有更快的推理时间。这对于实时果园自动化任务，如机器采摘和果实疏花具有重要意义。
### Conclusion
YOLOv8在实例分割方面优于Mask R-CNN，特别是在果树不同的生长阶段。YOLOv8不仅具有更高的精度和召回率，还在推理时间上更为高效，适用于实时果园自动化任务。
## 481. `cs.CV` - 通过微调的多模态大型语言模型进行青光眼检测和结构化OCT报告生成 [PDF](https://arxiv.org/pdf/2510.02403), [HTML](https://arxiv.org/abs/2510.02403)
### Authors
Jalil Jalili,Yashraj Gavhane,Evan Walker,Anna Heinke,Christopher Bowd,Akram Belghith,Massimo A. Fazio,Christopher A. Girkin,C. Gustavo De Moraes,Jeffrey M. Liebmann,Sally L. Baxter,Robert N. Weinreb,Linda M. Zangwill,Mark Christopher
### Background
该研究基于前瞻性队列研究，对1,310名参与者的43,849个光学生物测量仪(OCT)视盘(OHN)环扫描数据进行了分析，旨在开发一个可解释的多模态大型语言模型(MM-LLM)，用于OCT影像的质量筛查和生成包含青光眼诊断及各象限视网膜神经纤维层(RNFL)变薄评估的结构化临床报告。
### Innovation
该研究创新性地开发了一种用于OCT影像质量筛选和青光眼诊断及RNFL变薄评估的可解释的多模态大型语言模型(MM-LLM)，并通过自动生成、结构化的临床报告支持临床OCT评估，展示了在图像质量评估、青光眼检测以及各象限RNFL变薄预测上的高准确度。
### Conclusion
微调后的MM-LLM能够根据OCT影像生成准确的临床描述，具有高准确性，不仅能识别图像质量问题和检测青光眼，还能提供基于各象限的RNFL变薄描述以辅助临床OCT评估，展示了在青光眼检测和结构化OCT报告生成方面的能力。
## 482. `cs.CV` - Wave-GMS：医疗图像分割的轻量级多尺度生成模型 [PDF](https://arxiv.org/pdf/2510.03216), [HTML](https://arxiv.org/abs/2510.03216)
### Authors
Talha Ahmed,Nehal Ahmed Shaikh,Hassan Mohy-ud-Din
### Background
为了在医院和医疗设施中公平部署AI工具，我们需要高性能且能够在成本效益高、内存有限且支持大批次训练的GPU上训练的深度分割网络。因此，本研究旨在开发一种轻量级且高效的多尺度生成模型，以满足这个需求。现有的模型通常需要加载大量内存密集型的预训练视觉基础模型，并难以在内存有限的GPU上进行大规模批次训练，这限制了它们在实际医疗环境中的应用。本研究因此提出了Wave-GMS，以解决上述问题，使医疗图像分割更加高效和公平。
### Innovation
Wave-GMS 是一种轻量级且高效的多尺度生成模型，它可以显著减少可训练参数的数量，无需加载内存密集型的预训练视觉基础模型，并支持在内存有限的GPU上进行大规模批次训练。实验结果表明，Wave-GMS在四个公开数据集上的分割性能达到了现今最先进水平，同时跨域泛化能力也表现出色，仅需约2.6M个可训练参数就可实现这一效果。
### Conclusion
Wave-GMS 为医疗图像分割提供了一种轻量级高效的解决方案，保障了在内存有限的GPU上进行大规模批次训练的需求，且具有优秀的跨域泛化能力。
## 483. `cs.CV` - PyRadiomics-cuda：使用PyRadiomics在医疗成像中进行GPU加速的3D特征提取 [PDF](https://arxiv.org/pdf/2510.02894), [HTML](https://arxiv.org/abs/2510.02894)
### Authors
Jakub Lisowski,Piotr Tyrakowski,Szymon Zyguła,Krzysztof Kaczmarski
### Background
在医学成像中提取三维形状特征面临计算挑战，特别是对于大规模的体数据集，处理时间过长成为瓶颈。PyRadiomics库虽然是一个强大的工具，但其在处理这些数据时的效率有待提升，尤其是在计算密集的几何操作上。PyRadiomics-cuda通过将关键的几何计算任务卸载到GPU硬件上，显著降低了大规模医疗图像数据集的处理时间，同时保持了与原始PyRadiomics API的完全兼容性，使无缝集成到现有的AI工作流程中成为可能，无需代码修改。
### Innovation
PyRadiomics-cuda的主要创新点在于利用GPU加速3D形状特征的提取，特别针对大规模医疗图像数据集进行优化。这种方法提高了处理速度和效率，尤其是在几何计算上。同时，它在不影响API兼容性的前提下实现了这一点，使得该工具可以很容易地被现有的AI系统所接受和使用。
### Conclusion
PyRadiomics-cuda在各种预算和设备上都展示了其实用性，从典型的计算集群到个人电脑均有良好的表现。它为快速发展和高通量的AI管道提供了高效的放射组学分析支持。此外，PyRadiomics-cuda不仅提供了清晰的手册和示例脚本，还提供了详细的安装说明，并且源代码和测试集都是免费开源的，使用非常便捷。
## 484. `cs.CV` - 统一领域适应语义分割 [PDF](https://arxiv.org/pdf/2311.13254), [HTML](https://arxiv.org/abs/2311.13254)
### Authors
Zhe Zhang,Gaochang Wu,Jing Zhang,Xiatian Zhu,Dacheng Tao,Tianyou Chai
### Background
现有的无监督领域适应语义分割(UDA-SS)工作主要集中在图像上，最近才开始扩展到视频处理，通过建模时间维度来解决。尽管图像和视频的这两种研究路径面临的主要挑战相似，即解决领域分布偏移问题，但它们的研究几乎是独立的，导致了碎片化的见解、缺乏整体理解以及思想交叉授粉的机会被错过。这种分割阻碍了方法的统一，导致了重复努力和跨领域知识传递的不充分。因此，本文呼吁在视频和图像场景中统一研究UDA-SS，以实现更全面的理解、协同进步和高效的知识共享。
### Innovation
本文提出了一种四向Mixup方法(QuadMix)，通过四个方向的路径在特征空间中进行跨域混合来解决不同的点属性和特征不一致性问题。为了应对视频中的时域偏移，文章引入了基于光流的特征聚合，跨越空间和时间维度进行精细的领域对齐。实验结果表明，本文的方法在四个具有挑战性的UDA-SS基准上的性能明显优于现有的最优方法。
### Conclusion
本文提出了统一的UDA-SS研究框架和QuadMix方法，并通过实验验证了其在多个挑战性基准上的优越性能。所提出的方法不仅改善了通用泛化能力，还为思想交叉授粉奠定了基础，有助于该领域研究的整体进步和实际影响。
## 485. `cs.CV` - 使用自回归镶嵌的神经后验估计来检测天文图像中的物体 [PDF](https://arxiv.org/pdf/2510.03074), [HTML](https://arxiv.org/abs/2510.03074)
### Authors
Jeffrey Regier
### Background
即将到来的天文调查将产生庞大数据量的高分辨率夜空图像，这些图像提供了数十亿恒星和星系的信息。在这些图像中检测和表征这些天体对象是一项基本任务，但是一项具有挑战性的任务，因为大多数天体都很暗淡，且许多天体在视觉上与其他天体重叠。研究提出了一个渐进变分推断方法来解决这一小物体检测问题。该任务的一个关键是使用了一种空间自回归变分分布族，它根据一个K色棋盘图案分割和排列了潜在空间。这种方法构建的条件独立性与后验分布的条件独立性一致。
### Innovation
这种方法的核心创新是一个基于时空自回归变分分布族，利用一个K颜色棋盘图案来分割和排列潜在空间。这种结构通过构建条件独立性与后验分布的一致性来优化潜在分布。通过卷积神经网络参数化，使用神经后验估计（NPE）来最小化前向KL散度的期望。这种方法在斯隆数字天空调查的数据上达到了最先进的性能，并且证明了所提出的自回归结构极大地改进了后验校准。
### Conclusion
该方法在斯隆数字天空调查的数据上达到了最先进的性能，并且证明了所提出的自回归结构极大地改进了后验校准，其性能表现证明了方法的有效性。
## 486. `cs.CV` - 零样本异常检测的细粒度异常提示学习 [PDF](https://arxiv.org/pdf/2410.10289), [HTML](https://arxiv.org/abs/2410.10289)
### Authors
Jiawen Zhu,Yew-Soon Ong,Chunhua Shen,Guansong Pang
### Background
当前的零样本异常检测（ZSAD）方法能够利用大型预训练的视觉-语言模型在目标数据集上检测异常，而无需任何数据集特定的训练或演示。然而，这些方法往往集中在构建/学习捕捉异常粗粒度语义的提示，比如高层语义如‘损坏’、‘不完美’或‘缺陷’的物体。因此，它们在识别各种方式偏离这些一般异常模式的多样化异常细节方面能力有限。
### Innovation
我们提出了一种名为FAPrompt的新框架，用于学习细粒度异常提示，以实现准确的零样本异常检测。FAPrompt引入了一个新的复合异常提示学习（CAP）模块，用于学习一系列互补的、分解的异常提示，异常提示被强制要求建模来自相同正常性语义的多种不同的异常模式。此外，FAPrompt还引入了另一个新模块，数据依赖异常先验学习（DAP），从每个测试图像的异常特征中学习样本级别的异常先验，以动态适应不同的异常提示。
### Conclusion
在涵盖工业缺陷和医疗异常在内的19个实际数据集上进行的全面实验表明，FAPrompt在图像级和像素级零样本异常检测任务中显著优于最先进的方法。代码可在以下链接获取。
## 487. `cs.CV` - SoccerSynth-Detection：用于足球运动员检测的合成数据集 [PDF](https://arxiv.org/pdf/2501.09281), [HTML](https://arxiv.org/abs/2501.09281)
### Authors
Haobin Qin,Calvin Yeung,Rikuhei Umemoto,Keisuke Fujii
### Background
在足球视频分析中，球员检测是识别关键事件和重建战术位置的关键。然而，由于众多球员、频繁遮挡以及版权限制，缺少多样性的数据集限制了算法在不同足球视频背景下的适应性。现有的数据集如SoccerNet-Tracking和SportsMOT缺乏多样性。
### Innovation
本文开发了SoccerSynth-Detection，这是第一个为合成足球球员设计的合成数据集。该数据集包含了广泛的随机光照和纹理，以及模拟的相机运动模糊。通过使用对象检测模型（Yolov8n）与现实世界数据集（SoccerNet-Tracking和SportsMOT）的比较验证了其有效性。在迁移测试中，它在带有运动模糊的图像中与现实数据集的性能相当，并且在预训练测试中证明了其作为预训练数据集的有效性，显著提高了算法的整体性能。
### Conclusion
本研究展示了合成数据集在足球视频分析领域算法训练中的潜力，可以替代现有现实数据集。
## 488. `cs.CV` - 内部排名：无需标签排名大型多模态模型 [PDF](https://arxiv.org/pdf/2412.06461), [HTML](https://arxiv.org/abs/2412.06461)
### Authors
Weijie Tu,Weijian Deng,Dylan Campbell,Yu Yao,Jiyang Zheng,Tom Gedeon,Tongliang Liu
### Background
随着预训练的大规模多模态模型（LMM）的普及，选择合适模型用于新数据或任务变得愈发关键。传统的做法是通过一系列测试来评估模型性能，但这种方法需要大量人力来确定真实答案。本文试图探索除评分之外的其他信号，评估这些信号在无监督模型排名中的有效性。
### Innovation
本文提出了一种新的方法，即通过不确定性指标（如softmax分布的不确定性分数）来预测模型在未标注数据上的相对性能，从而无需评分或确定真实答案的过程，提供了一种在无需人工标注的情况下对大规模多模态模型进行排名的实际方法。
### Conclusion
研究表明，不确定性分数能为不同任务提供一致的模型排名基础，从而可以在未标注数据上对LMMs进行排名，为选择适合各种目标领域的模型提供了实用的思路，无需人工标注。
## 489. `cs.CV` - 针对AI生成视觉媒体的防御研究：检测、干扰和认证 [PDF](https://arxiv.org/pdf/2407.10575), [HTML](https://arxiv.org/abs/2407.10575)
### Authors
Jingyi Deng,Chenhao Lin,Zhengyu Zhao,Shuai Liu,Qian Wang,Chao Shen
### Background
深度生成模型已经在计算机视觉领域的多个应用中展现出了卓越的表现，如图像合成、视频生成和医学分析。尽管取得了显著进展，这些模型可能被滥用，用于诸如误导信息、欺骗和版权侵犯等恶意目的。针对这一问题，本文提供了一系列关于对抗AI生成视觉媒体的防御措施的研究综述，涵盖了检测、干扰和认证等方面。同时，本文还总结了现有防御方法，并在统一的被动和主动框架内概述了主要的防御相关任务。对于每个任务，本文提出了统一的方法策略分类，并总结常用的评估数据集、标准和度量标准，为防御技术提供了背景信息与挑战洞察，指出了未来研究的方向。
### Innovation
本文提供了一个系统的关于防御AI生成视觉媒体的研究综述，包括检测、干扰和认证等任务，提出了方法策略的分类，并总结了常用的评估数据集、标准和度量标准，为防御技术的研究提供了具体指导。
### Conclusion
通过对现有研究的分析，本文指出了当前研究的挑战，并提出了未来研究的方向。
## 490. `cs.CV` - RACCooN: 自动生成叙述的多功能视频编辑框架 [PDF](https://arxiv.org/pdf/2405.18406), [HTML](https://arxiv.org/abs/2405.18406)
### Authors
Jaehong Yoon,Shoubin Yu,Mohit Bansal
### Background
现有的视频生成模型主要依赖于详细的文本提示来完成特定任务，如内容补全或风格编辑。这些模型需要对输入视频进行详细的文本描述，限制了它们对个人或原始视频灵活调整以满足用户需求的能力。本文提出了一种名为RACCooN的框架，它可以支持多种视频编辑功能，并通过统一的管道来实现。
### Innovation
RACCooN的主要创新在于：(1) 它提出了一种多粒度的时空聚合策略，能够自动生成结构良好的视频描述，这一过程不需要复杂的用户注释，简化了基于文本的视频内容编辑。(2) 嵌入了自动生成的叙述或指令，以提升生成内容的质量与准确性。(3) 提出的框架能够想象出新对象，从而简化复杂的视频编辑流程，使得用户只需提示模型来生成详细的编辑计划。
### Conclusion
RACCooN框架在视频到段落生成、视频内容编辑方面展示了显著的灵活性和多功能性，并且能够与其他最先进的视频生成模型集成，以进一步增强性能。
## 491. `cs.CV` - EFC++: 弹性特征合并结合原型再平衡在冷启动无示例增量学习中的应用 [PDF](https://arxiv.org/pdf/2503.10439), [HTML](https://arxiv.org/abs/2503.10439)
### Authors
Simone Magistri,Tomaso Trinci,Albin Soutif-Cormerais,Joost van de Weijer,Andrew D. Bagdanov
### Background
Exemplar-free Class Incremental Learning (EFCIL)的目标是在不访问先前任务数据的情况下学习一系列任务。然而，在冷启动场景下，第一任务可用的数据不足，难以学习高质量的骨干网络，对EFCIL特别具有挑战性，因为这需要高灵活性，导致特征漂移难以在无示例设置中补偿。
### Innovation
本文提出了一种新颖的方法，即弹性特征合并增强（Elastic Feature Consolidation++，EFC++），通过利用一种提议的经验特征矩阵（EFM），实现特征漂移的可处理的二阶近似，并以此诱导特征空间中的伪度量，用于重要方向上特征漂移的正则化和更新高斯原型。此外，还引入了一个后训练的原型再平衡阶段，更新分类器以补偿特征漂移。
### Conclusion
在CIFAR-100、Tiny-ImageNet、ImageNet-Subset、ImageNet-1K 和 DomainNet上的实验表明，EFC++能够通过保持模型的灵活性来学习新的任务，并且在性能上显著优于现有的方法。
## 492. `cs.CV` - CLIP模型稳健性综合评估 [PDF](https://arxiv.org/pdf/2410.01534), [HTML](https://arxiv.org/abs/2410.01534)
### Authors
Weijie Tu,Weijian Deng,Tom Gedeon
### Background
CLIP模型在零样本分类和多种分布变化中显示出了显著潜力。本文在此基础上，提供了一个更全面的CLIP评估，从多个新角度考察了其鲁棒性，包括其在特定视觉因素变化中的鲁棒性、决策不确定性、异常检测性能、图像和文本模态的匹配程度以及3D意识等。此外，还探讨了现代大型多模态模型内部视觉编码器与语言编码器的交互情况及其对分类鲁棒性的影响。
### Innovation
本文引入了多个新的评估视角来全面评估CLIP模型的稳健性，包括在特定视觉因素变化中的鲁棒性、决策不确定性、异常检测性能、图像和文本模态的匹配程度、3D意识等，并探讨了视觉编码器和语言编码器在现代大型多模态模型中的交互如何影响分类的鲁棒性。研究发现CLIP模型的视觉编码器架构在抵抗3D破坏方面起着关键作用，以及其在ImageNet上的微调减少了对形状的偏见。通过使用CLIP视觉编码器的视觉语言模型（如LLaVA）在处理具有挑战性的类别时可能比单独使用CLIP表现出更好的分类性能。
### Conclusion
本文揭示了CLIP模型的多个先前未知的细节，对未来增强CLIP模型的稳健性和可靠性提供了有价值的指导。
## 493. `cs.CV` - SkillFormer: 统一多视角视频理解用于技能评估 [PDF](https://arxiv.org/pdf/2505.08665), [HTML](https://arxiv.org/abs/2505.08665)
### Authors
Edoardo Bianchi,Antonio Liotta
### Background
评估复杂活动的人类技能水平是一个具有挑战性的问题，尤其在体育、康复和培训等领域有所应用。现有的多视角技能评估方法通常难以同时处理第一视角和第三视角视频，且模型复杂性高，训练成本大。
### Innovation
SkillFormer 提出了一种参数高效的统一多视角技能评估架构，结合了 TimeSformer 的时间感知特性，并引入了 CrossViewFusion 模块，通过多头交叉注意力、可学习门控机制和自适应标定实现视角特征的融合。通过低秩适应方法，仅微调少量参数，减少了训练成本，同时在 EgoExo4D 数据集上取得了最先进的多视角准确度，实现了参数和训练周期的大幅减少，且在多个细分类任务中表现出色。
### Conclusion
SkillFormer 在多视角设置下实现了技能评估的高精度和高效性，证明了多视角整合在细粒度技能评估中的价值。
## 494. `cs.CV` - CBVLM:无需训练的基于概念的大规模视觉语言模型的可解释性医学图像分类 [PDF](https://arxiv.org/pdf/2501.12266), [HTML](https://arxiv.org/abs/2501.12266)
### Authors
Cristiano Patrício,Isabel Rio-Torto,Jaime S. Cardoso,Luís F. Teixeira,João C. Neves
### Background
在医学工作流程中采用基于深度学习的解决方案的主要限制因素是标注数据的稀缺性和系统的不可解释性。概念瓶颈模型（CBMs）通过限制模型输出在预定义的、可由人理解的概念集上解决了不可解释性问题，但这也增加了注释负担，并且如果需要添加新概念，则整个系统需要重新训练。借助大规模视觉-语言模型（LVLM）在少样本设置中表现出的卓越性能，本文提出了一种简单而有效的CBVLM方法，该方法解决了上述挑战。该方法利用检索模块和少量标注示例，在上下文学习中选择最佳示例，有助于确保可解释性并大幅降低了注释成本。
### Innovation
提出了CBVLM方法，该方法结合了大规模视觉-语言模型在少样本设置中的优势，通过提示LVLM预测输入图像中给定概念的出现情况，然后根据先前的概念预测对图像进行分类。这种方法不仅提高了系统的可解释性，还通过利用LVLM的少样本能力大大降低了标注成本。相较于概念瓶颈模型（CBMs）和特定任务的监督方法，CBVLM在四个医学数据集和十二个大规模视觉-语言模型（包括通用和医学模型）上进行了广泛的实验，并且展示了持续的优越性能，无需任何训练即可实现高性能，仅使用少量标注示例。
### Conclusion
通过在最终诊断中基于预测的概念进行推理，CBVLM确保了可解释性，并利用少样本能力的LVLM极大地降低了注释成本，从而可以有效克服目前医学图像分类中面临的挑战，提高了基于深度学习技术在医学领域的应用可能性。
## 495. `cs.CV` - Gate-Shift-Pose: 增强体育运动中动作识别的骨架信息 [PDF](https://arxiv.org/pdf/2503.04470), [HTML](https://arxiv.org/abs/2503.04470)
### Authors
Edoardo Bianchi,Oswald Lanz
### Background
本文介绍了一种名为Gate-Shift-Pose的网络，它是Gate-Shift-Fuse网络的增强版本，旨在通过结合骨架姿势数据和RGB帧来对花样滑冰运动员的跌倒进行分类。研究采用了两种融合策略：早融合法在输入阶段将RGB帧与姿态关键点的高斯热图进行结合；晚融合法则采用多流架构和注意力机制来结合RGB和姿态特征。在FR-FS数据集上的实验表明，与仅使用RGB的数据baseline相比，Gate-Shift-Pose显著提高了准确性，最高提高40%（ResNet18）和20%（ResNet50）。其中，早融合在ResNet50上达到了最高准确率（98.08%），利用了模型对多模态集成的有效性；而晚融合则更适合像ResNet18这样的轻量级骨干网络。这些结果表明，多模态架构在体育动作识别中的潜力，以及骨架姿势信息在捕捉复杂运动模式中的关键作用。
### Innovation
本文通过结合骨架姿势数据和RGB帧，提出了Gate-Shift-Pose网络，并且通过两种不同的融合策略（早融合和晚融合）进行了实验验证。研究结果表明，这种新的网络结构在体育动作识别中具有显著的优势，特别是在利用骨架姿势信息方面，这对于捕捉复杂的运动模式具有重要意义。此外，研究还发现了不同融合策略在不同骨干网络中的适用性差异，提供了优化多模态集成的见解
### Conclusion
本研究通过Gate-Shift-Pose网络和两种不同的融合策略，展示了多模态架构在体育动作识别上的潜力。研究结果表明，结合骨架姿势数据可以显著提高动作识别的准确性，特别是在早融合策略和某些轻量级网络中表现尤为突出。未来的研究可以进一步探索其他多模态融合方法和优化技术，以提高动作识别系统的性能。
## 496. `cs.CV` - PATS：多视角体育技能评估的 proficiency-aware 时域采样 [PDF](https://arxiv.org/pdf/2506.04996), [HTML](https://arxiv.org/abs/2506.04996)
### Authors
Edoardo Bianchi,Antonio Liotta
### Background
当前的视频采样方法会破坏评估技能时必需的时间连续性。为了捕获区分专家和新手的基础运动模式，本研究提出了 Proficiency-Aware Temporal Sampling (PATS) 采样策略，该策略能够在一个连续的时间段内保存完整的基础运动，用于多视角技能评估。
### Innovation
PATS 是一种新颖的采样策略，能够自适应地分割视频以确保每个分析的部分包含完整的关键表现组成部分，并且在多个时间段内重复此过程以最大限度地覆盖信息同时保持时间一致性。实验表明，PATS 在 EgoExo4D 基准数据集上使用 SkillFormer 达到了最先进的准确率，在所有视图配置上提升 0.65%-3.05%，并在攀岩、音乐和篮球等具有挑战性的领域中取得显著效果。
### Conclusion
系统性分析表明，PATS 可以适应各种运动特征，无论是动态运动还是顺序技能，显示了其作为自适应时域采样的有效性，从而推进了真实世界应用中自动技能评估的发展。
## 497. `cs.CV` - AlignDiT: 多模态对齐扩散变换器用于同步语音生成 [PDF](https://arxiv.org/pdf/2504.20629), [HTML](https://arxiv.org/abs/2504.20629)
### Authors
Jeongsoo Choi,Ji-Hoon Kim,Kim Sung-Bin,Tae-Hyun Oh,Joon Son Chung
### Background
该论文针对多模态到语音生成的任务展开研究，目标是从多模态输入（文本、视频和参考音频）生成高质量的语音。这一任务因其在电影制作、配音和虚拟头像等多个领域的广泛应用而备受关注。尽管现有的方法在语音可懂度、音频-视频同步、语音自然度和参考说话者的声音相似度方面取得了进展，但仍然存在一些局限性。
### Innovation
为了解决这些挑战，该论文提出了AlignDiT，这是一种利用DiT架构的上下文学习能力的多模态对齐扩散变换器。AlignDiT通过三种有效策略对齐多模态表示，并引入了一种新颖的无条件分类器导向机制，允许模型在语音合成过程中适当地平衡每种模态的信息。实验表明，AlignDiT在多个基准上的质量、同步性和说话者相似度方面均显著优于现有方法，并且展示了在视频到语音合成和视觉强制对齐等多模态任务中的强泛化能力，持续保持最先进性能。
### Conclusion
广泛的实验证明了AlignDiT在质量和同步性方面的优越性能，并且它在多种多模态任务中表现出强大的泛化能力，持续达到最先进的技术水平。
## 498. `cs.CV` - HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios [PDF](https://arxiv.org/pdf/2506.09650), [HTML](https://arxiv.org/abs/2506.09650)
### Authors
Kunyu Peng,Junchao Huang,Xiangsheng Huang,Di Wen,Junwei Zheng,Yufan Chen,Kailun Yang,Jiamin Wu,Chongqing Hao,Rainer Stiefelhagen
### Background
高精度视频理解中的核心挑战之一是动作分割，即对未剪辑的视频进行分割并赋予每个片段预定义的动作集中的标签。现有方法主要解决了单人活动和固定动作序列的问题，而忽视了多人场景。文章研究了在多人场景中基于文本提示进行人类动作分割的问题，引入了一个新的数据集RHAS133，包含133部电影和137个细粒度动作，涉及33小时的视频数据，并提供了新任务的文本描述注释。
### Innovation
提出了一个考虑到整体与局部的Fourier条件控制扩散框架——HopaDIFF，该框架利用新型交叉输入门注意xLSTM来增强整体与局部的长距离推理，引入了新型Fourier条件以提高动作分割生成的精细控制。HopaDIFF在RHAS133数据集上实现了多项评估设置中的最佳结果。
### Conclusion
在RHAS133数据集上重新评估了现有的动作分割方法，通过VLM基于的特征提取发现其性能有限且定向视觉线索的聚合效果不佳。HopaDIFF在多种评估设置中实现了最佳结果，并开放了数据集和代码供研究使用。
## 499. `cs.CV` - 从长视频到吸引人的短视频：具有多模态叙事理解的人类启发式视频编辑框架 [PDF](https://arxiv.org/pdf/2507.02790), [HTML](https://arxiv.org/abs/2507.02790)
### Authors
Xiangfeng Wang,Xiao Li,Yadong Wei,Xueyu Song,Yang Song,Xiaoqiang Xia,Fangrui Zeng,Zaiyi Chen,Liu Liu,Gu Xu,Tong Xu
### Background
随着在线视频内容的快速增长，尤其是短视频平台，对高效视频编辑技术的需求日益增加，这些技术能够将长视频浓缩为精简且引人入胜的片段。现有的自动编辑方法主要依赖于语音识别（ASR）转录中的文本线索和端到端的视频片段选择，往往忽视了丰富的视觉上下文，导致输出不连贯。
### Innovation
本文提出了一种受到人类启发的自动视频编辑框架（HIVE），利用多模态叙事理解来解决现有方法的这些局限性。该方法通过多模态大型语言模型进行人物提取、对话分析和叙事总结，使整个视频内容的理解更加全面。为了进一步增强一致性，应用场景级别的分割，拆分编辑过程为三个子任务：亮点检测、开头/结尾选择和无关内容修剪。
### Conclusion
实验结果表明，本框架在常规和广告导向的编辑任务中始终优于现有基线，大幅缩小了自动和人编辑视频的质量差距。
## 500. `cs.CV` - 摄影视角组成：迈向美观视角推荐 [PDF](https://arxiv.org/pdf/2505.20655), [HTML](https://arxiv.org/abs/2505.20655)
### Authors
Lujian Yao,Siming Zheng,Xinbin Yuan,Zhuoxuan Cai,Pu Wu,Jinwei Chen,Bo Li,Peng-Tao Jiang
### Background
传统的摄影构图方法主要依赖于2D剪裁方式，但在处理画面布局混乱的对象时效果不佳。专业摄影师常常使用透视调整作为3D重组手段，调整对象之间的投影关系，同时保持实际的空间位置，以达到更好的构图平衡。
### Innovation
本文提出了摄影视角组成（PPC）方法，超越了传统的2D剪裁方法。为了解决实施PPC面临的挑战，即缺乏透视变换数据集和缺乏透视质量评估标准，本文提出了三个关键贡献：1）自动构建PPC数据集的框架，利用专家摄影作品；2）通过视频演示从不利到美学增强的视角转换过程；3）基于人类表现构建的视角质量评估（PQA）模型。这种方法简洁易用，无需额外的提示指令或相机轨迹，以帮助普通用户提升构图技巧。
### Conclusion
本文提出的方法简洁高效，能够帮助普通用户通过简单的指导提升摄影构图技能，解决了传统方法在复杂布局场景中的不足。通过专家数据集构建、视角转换演示和视角质量评估模型，本文为摄影构图领域提供了新的解决方案和指导。
## 501. `cs.CV` - VOTE: 视觉-语言-动作优化与轨迹投票ensemble策略 [PDF](https://arxiv.org/pdf/2507.05116), [HTML](https://arxiv.org/abs/2507.05116)
### Authors
Juyi Lin,Amir Taherin,Arash Akbari,Arman Akbari,Lei Lu,Guangyu Chen,Taskin Padir,Xiaomeng Yang,Weiwei Chen,Yiqian Li,Xue Lin,David Kaeli,Pu Zhao,Yanzhi Wang
### Background
近期大规模的视觉语言动作（VLA）模型在由自然语言指导的机器人操作任务中表现出色。然而，当前的VLA模型存在两个缺点：（i）生成大量的标记导致推理延迟高和训练成本增加；（ii）生成的动作利用不足，可能导致性能下降。
### Innovation
开发了一种训练框架，用于微调VLA模型，以生成显著减少的行动标记并具有高并行性，从而有效降低推理延迟和训练成本。此外，提出了一种推理优化技术，使用新颖的基于投票的ensemble策略结合当前和先前的行动预测，提高生成动作的利用效率和整体性能。
### Conclusion
实验证明，该方法在与最新VLA模型相比时，表现出更优的性能，成功率更高，相较于OpenVLA在边缘平台上达到39倍的推理速度，通过46 Hz的吞吐量证明了其实用的可实现性。代码已提供。
## 502. `cs.CV` - RichControl: 结构丰富和外观丰富的无需训练的空间控制以实现文本到图像生成 [PDF](https://arxiv.org/pdf/2507.02792), [HTML](https://arxiv.org/abs/2507.02792)
### Authors
Liheng Zhang,Lexi Pang,Hang Ye,Xiaoxuan Ma,Yizhou Wang
### Background
文本到图像(T2I)的扩散模型在过去在从文本提示生成高质量图像方面展现出了显著的成功。最近的研究开始探索如何结合条件图像(例如Canny边缘)来实现更精细的空间控制。现有的方法主要依赖于传统的微调方法，但这些方法在结构对齐方面往往存在问题，比如结构错位、条件泄漏，以及视觉上的瑕疵。研究表明，这是由于条件特征的采样时间表未能充分考虑结构保存与领域对齐之间的演变关系。基于此，本研究提出了一种灵活的无需训练的框架，通过解耦条件特征的采样时间和去噪过程，以及系统地研究特征注入时间表的不同策略，以提供更高的结构指导质量。通过详细的实验，证明了该方法在多种零样本条件场景下达到了最先进的效果。
### Innovation
提出了一种灵活的无需训练的框架，通过将条件特征的采样时间与去噪过程解耦，系统地研究了特征注入时间表的不同策略，以提供更高的结构指导质量。此外，引入了重启细化时间表来进一步增强采样过程，并提出了丰富的外观提示策略以提高视觉质量。这些设计使得无需训练的生成既结构丰富又外观丰富。
### Conclusion
大量的实验结果表明，该方法在各种零样本条件场景下都达到了最先进的效果，实现了结构丰富和外观丰富的无监督空间控制。
## 503. `cs.CV` - 重访重加权风险校准：AURC、焦点损失和反焦点损失 [PDF](https://arxiv.org/pdf/2505.23463), [HTML](https://arxiv.org/abs/2505.23463)
### Authors
Han Zhou,Sebastian G.Gruber,Teodora Popordanoska,Matthew B. Blaschko
### Background
已经提出了几种重新加权风险功能性，例如焦点损失、反焦点损失和风险覆盖曲线下的面积（AURC），以改善模型校准，但这些方法与校准误差的理论联系尚不明确。因此，本文回顾了在深度学习中广泛使用的加权风险函数类，并建立了校准误差与选择性分类之间的原则性联系。在此之前，已有研究表明，最小化校准误差与选择性分类范式密切相关，优化低置信区域的选择性风险自然可以提升校准效果。本文提出的损失与双焦点损失有相似的加权策略，但通过选择不同的置信度分数函数（CSFs）提供了更大的灵活性。该方法使用基于区间的累积分布函数（CDF）逼近，允许高效的基于梯度的优化，无需昂贵的排序操作，并达到O(nK)的时间复杂性。
### Innovation
本文提出了一种基于区间的累积分布函数（CDF）逼近的方法，与双焦点损失有相似的加权策略，但通过选择不同的置信度分数函数（CSFs）提供了更大的灵活性。该方法可以高效地进行基于梯度的优化，无需昂贵的排序操作，并达到O(nK)的时间复杂性。实验结果表明，该方法在不同数据集和模型架构上均能实现与现有方法竞争力的校准性能。
### Conclusion
最小化校准误差与选择性分类范式密切相关。优化低置信区域的选择性风险会自然导致更好的校准。所提出的方法通过使用区间的累积分布函数逼近，提供了高效且灵活的优化策略，从而提升校准性能。
## 504. `cs.CV` - So-Fake：社交媒体图像伪造检测基准及解释 [PDF](https://arxiv.org/pdf/2505.18660), [HTML](https://arxiv.org/abs/2505.18660)
### Authors
Zhenglin Huang,Tianxiao Li,Xiangtai Li,Haiquan Wen,Yiwei He,Jiangning Zhang,Hao Fei,Xi Yang,Xiaowei Huang,Bei Peng,Guangliang Cheng
### Background
近年来，基于AI的生成模型已经能够创建出越来越逼真的合成图像，这在社交媒体平台上严重威胁到了信息完整性和公众信任。尽管健壮的检测框架和多样、大规模的数据集对于减轻这些风险至关重要，但现有学术努力在范围上仍然有限。当前的数据集缺乏社交媒体场景所需的多样性和真实性，而现有的检测方法也难以对未见过的生成技术进行泛化。为弥合这一差距，该研究引入了So-Fake-Set，这是个面向社交媒体的数据集，包含超过200万张高质量图像，多种生成来源，以及由35个最先进的生成模型合成的超逼真图像。该研究还建立了So-Fake-OOD，这是一个全新的、规模庞大（10万张图像）的领域外基准测试，包含来自未包含于训练分布中的商业模型的合成图像，为实际性能评估提供了一个现实的测试环境。
### Innovation
该研究提出了So-Fake-Set数据集，这是个面向社交媒体的真实高质量数据集，包含超过200万张涵盖多种生成来源的图像，并通过35个最先进的生成模型生成了超逼真图像。此外，研究还建立了So-Fake-OOD这个全新的、包含未包含于训练分布中的商业模型的合成图像的大规模领域外基准测试，并开发了So-Fake-R1，这是一个先进的视觉语言框架，利用强化学习进行高度准确的伪造检测、精确定位以及解释性推断。实验结果显示，So-Fake-R1在检测准确性上比第二好方法高出1.3%，在定位IoU上提高了4.5%。通过引入可扩展的数据集、具有挑战性的领域外基准和高级检测框架，这项工作为社交媒体中心的伪造检测研究奠定了一项新基础。
### Conclusion
通过集成可扩展的数据集、挑战性的领域外基准和高级检测框架，这项工作为社交媒体中心的伪造检测研究建立了一种新的基础。该研究的代码、模型和数据集将被公开释放。
## 505. `cs.CV` - 车辆-场景互动：一种基于文本的自动驾驶3D激光雷达地点识别方法 [PDF](https://arxiv.org/pdf/2503.18035), [HTML](https://arxiv.org/abs/2503.18035)
### Authors
Tianyi Shang,Zhenyu Li,Pengjie Xu,Zhaojun Deng
### Background
大规模点云地图（通过遥感构建）对于无人配送机器人等大型自主系统的进步至关重要，但当前方法因点云编码器难以有效捕捉局部细节和远距离空间关系而面临挑战，同时文本与点云表示存在模态差距。为解决这些问题，本文探讨了如何利用遥感信息进行地理定位的问题，并提出了Des4Pos框架，这是一种新颖的两阶段文本驱动遥感定位框架，旨在提升定位的精准性与实用性，适用于自动驾驶等应用场景。
### Innovation
Des4Pos框架通过两阶段处理提高了点云地理定位的准确性。在粗略阶段，利用多尺度融合注意机制（MFAM）和双向长短时记忆模块（BiLSTM）增强局部几何特征和全局空间关系。在精细阶段，引入级联残差注意力模块（CRA）融合模态特征并预测相对位置偏移，有效解决了模态差异和局部与全局特征捕捉的问题。此外，Stepped Text Encoder (STE) 通过引入CLIP等跨模态先验知识实现了文本与点云特征的有效对齐，弥补了它们之间的差距。
### Conclusion
实验结果表明，Des4Pos在Kitti360Pose测试集上表现为最先进的地点识别性能，在5米半径阈值下获得1级精度40%和前10级精度77%，相比现有方法分别提升了7%。此研究为提高大规模无人配送机器人的环境定位性能提供了新的解决方案。
## 506. `cs.CV` - RelayFormer: 一个统一的局部-全局注意力框架，用于可扩展的图像和视频操纵定位 [PDF](https://arxiv.org/pdf/2508.09459), [HTML](https://arxiv.org/abs/2508.09459)
### Authors
Wen Huang,Jiarui Yang,Tao Dai,Jiawei Li,Shaoxiong Zhan,Bin Wang,Shu-Tao Xia
### Background
视觉操纵定位（VML）旨在识别图像和视频中的篡改区域，随着高级编辑工具的出现，这一任务变得越来越具有挑战性。现有方法面临两个主要问题：分辨率多样性，这会导致缩放或填充导致证据痕迹的扭曲，降低效率；以及模态差距，因为图像和视频通常需要单独的模型。这些问题限制了目前方法的性能和效率拓展性。因此，迫切需要一种能够适应不同分辨率和模态的统一框架来解决这些问题。
### Innovation
我们提议的 RelayFormer 是一种统一框架，能够适应不同的分辨率和模态。RelayFormer 通过将输入划分为固定大小的子图像，并引入全局-局部接力（GLR）标记，通过全局-局部接力注意力（GLRA）机制传播结构化的上下文信息，可以有效地交换全球线索，同时保留细节的操作痕迹。与基于均匀缩放或稀疏注意的先方法不同，RelayFormer 自然地扩展到任意分辨率和视频序列，而没有额外的开销。
### Conclusion
实验结果表明，RelayFormer 在多种基准测试中表现出最佳性能，具有显著的效率，能够结合分辨率自适应性而不进行插值或过度填充，同时还具备统一的图像和视频建模以及准确性和计算成本的良好平衡。
## 507. `cs.CV` - AudioStory: 使用大型语言模型生成长形式叙事音频 [PDF](https://arxiv.org/pdf/2508.20088), [HTML](https://arxiv.org/abs/2508.20088)
### Authors
Yuxin Guo,Teng Wang,Yuying Ge,Shijie Ma,Yixiao Ge,Wei Zou,Ying Shan
### Background
近期的文本到音频（TTA）生成技术在合成短音频片段方面表现出色，但在处理长形式的叙事音频时遇到挑战，这需要时间上的连贯性和组成性推理。
### Innovation
提出了一种名为AudioStory的统一框架，该框架将大型语言模型（LLMs）与TTA系统集成，以生成结构化、长形式的音频叙事。AudioStory具有强大的指令遵循推理生成能力。它利用LLMs将复杂的叙事查询分解为按时间顺序排列的子任务，并通过上下文线索实现连贯的场景过渡和情感调性一致性。此外，AudioStory还具有解耦的桥梁机制，以及端到端训练的特点。
### Conclusion
AudioStory在单个音频生成和叙事音频生成方面都优于先前的TTA基线，并且其解耦的桥梁机制、端到端训练以及在多样领域（如动画音景和自然音效叙事）中建立的基准AudioStory-10K均显示出其优越性。代码可在特定链接找到。
## 508. `cs.CV` - SP-VLA：VLA模型加速的联合模型调度与标记裁剪方法 [PDF](https://arxiv.org/pdf/2506.12723), [HTML](https://arxiv.org/abs/2506.12723)
### Authors
Ye Li,Yuan Meng,Zewen Sun,Kangye Ji,Chen Tang,Jiajun Fan,Xinzhu Ma,Shutao Xia,Zhi Wang,Wenwu Zhu
### Background
视觉-语言-动作（VLA）模型因其强大的控制能力受到了越来越多的关注，但它们高昂的计算成本和低执行频率限制了它们在机器人操作和自主导航等实时任务中的适用性。现有的VLA加速方法主要集中在结构优化上，而忽视了这些模型在顺序决策环境中的操作特性，导致在顺序动作生成中的时间冗余和视觉输入中的空间冗余没有得到解决。
### Innovation
提出了一种名为SP-VLA的统一框架，通过联合调度模型和裁剪标记来加速VLA模型。具体设计了一个动作感知的模型调度机制，通过动态切换VLA模型和轻量级生成器减少了时间冗余，根据人类运动模式将VLA动作分为深思和直觉两类，实现频率自适应执行，并且开发了一种时空语义双重感知标记裁剪方法，根据标记的双重重要性裁剪加速VLA推理，这两种机制协同工作以引导VLA关注关键动作和显著的视觉信息，实现有效加速并保持高准确性，从而解决了时间冗余和空间冗余的问题。
### Conclusion
全面的实验表明，我们的方法在LIBERO上实现了无损耗的1.5倍加速，在SimplerEnv上实现了2.4倍的加速，同时平均性能提高了6%。推理频率和延迟在SimplerEnv上分别提高了2.2倍和1.4倍，在LIBERO上分别提高了1.4倍和1.4倍。
## 509. `cs.CV` - SBP-YOLO：面向智能车辆悬挂系统的轻量级实时速度坑洼和车辙检测模型 [PDF](https://arxiv.org/pdf/2508.01339), [HTML](https://arxiv.org/abs/2508.01339)
### Authors
Chuanqi Liang,Jie Fu,Miao Yu,Lei Luo
### Background
速度坑洼和车辙是道路中最常见的异常情况，严重影响着乘坐舒适度和车辆稳定性。预先观测的悬挂控制可以通过提前检测这些不平整并主动调整悬挂参数来减轻其影响。准确和实时的检测是必要的，但嵌入式部署受到计算资源有限和输入目标尺寸小的限制。
### Innovation
为了解决这些挑战，本文提出了一种适用于嵌入式系统的高效检测框架SBP-YOLO，用于在嵌入式系统中检测速度坑洼和车辙。该框架基于YOLOv11n，通过整合GhostConv和VoVGSCSPC模块来减少计算量并增强多尺度语义特征。P2级分支提高了小目标的检测能力，而轻量且高效的检测头(LEDH)则在最少开销的同时保持了准确性。一种混合训练策略进一步增强了在不同道路和环境条件下的鲁棒性，结合了NWD损失、BCKD知识蒸馏和基于Albumentations的数据增强。
### Conclusion
实验结果表明，SBP-YOLO在Jetson AGX Xavier上以139.5 FPS的速度实现87.0%的mAP，比增强版的YOLOv11n基线提高了5.8%。经过TensorRT FP16量化后，它还取得了12.4%的性能提升。这些结果证明，该框架适用于嵌入式悬挂控制系统中的快速、低延迟道路状况感知。
## 510. `cs.CV` - PointAD+: 用于零样本3D异常检测的层次表示学习 [PDF](https://arxiv.org/pdf/2509.03277), [HTML](https://arxiv.org/abs/2509.03277)
### Authors
Qihang Zhou,Shibo He,Jiangtao Yan,Wenchao Meng,Jiming Chen
### Background
本文旨在将CLIP的鲁棒2D通用能力转移到识别多类别语义下未见物体的3D异常。为此，本文提出一个统一体系，综合检测和分割3D异常，通过利用点级和像素级信息。首先设计了PointAD，利用点-像素对应关系，通过其关联的渲染像素表示3D异常，这是一种隐式的3D表示方法，专注于渲染像素异常，忽略了点云中的固有空间关系。然后提出了PointAD+，引入显式的3D表示方法，强调空间异常以揭示不正常的空间关系，并提出了G-aggregation以利用几何信息使聚合的点表示具有空间意识。PointAD+提出了层次表示学习，结合隐式和显式异常语义到层次文本提示：渲染提示用于渲染层，几何提示用于几何层，并引入了跨层次对比对齐以促进渲染层和几何层的交互，促进异常检测。
### Innovation
本文提出了PointAD和PointAD+，其中PointAD+引入显式的3D表示方法和层次表示学习，通过融合点和像素级信息来识别3D异常。PointAD+还引入了G-aggregation来结合几何信息，使聚合点表示空间意识，并通过渲染提示和几何提示进行层次文本提示，以同时捕捉渲染和空间异常，引入跨层次对比对齐以促进渲染层和几何层的交互，最终综合两种异常语义来捕捉广泛的异常语义。
### Conclusion
PointAD+在未见过的具有高度多样类别语义物体的零样本3D异常检测中表现出优越性，能够集成RGB信息并进一步提高检测性能，并对不同物体类别实现全面异常理解。
## 511. `cs.CV` - 通过稀疏LiDAR引导修正增强单目高度估计 [PDF](https://arxiv.org/pdf/2505.06905), [HTML](https://arxiv.org/abs/2505.06905)
### Authors
Jian Song,Hongruixuan Chen,Naoto Yokoya
### Background
单目高程估计（MHE）从高分辨率遥感图像中通过深度学习进行是非常具有挑战性的，因为缺乏足够的结构信息。传统的数字高程模型（DEMs）通常来自机载LiDAR或多视图立体影像，成本高昂且地理限制较多。近期研究虽然利用合成数据训练的模型并通过领域适应取得了显著性能，但模型的预测机制及其可靠性仍不清楚。该研究深入探讨了一个以合成数据训练的MHE模型，通过系统分析发现模型高度依赖阴影线索，但这可能导致高度估计的偏差。同时，通过人眼评估回归任务的局限性也突显了仅以合成数据训练的局限性。
### Innovation
本文提出了一种新的校正管道，整合了稀疏不完美的全球LiDAR测量（ICESat-2）与深度学习输出，以提高局部精度并实现空间一致的校正。该方法包括两个阶段：预处理原始ICESat-2数据，然后使用随机森林方法密集细化高度估计。在三个代表性地区的实验中显示，这种方法显著减少了误差，MAE分别减少了22.8%、6.9%和4.9%。这些发现强调了阴影意识在合成数据驱动模型中的重要作用，并展示了如何利用不完美的现实世界LiDAR数据加强MHE的稳健性，为更可靠和可扩展的3D测绘解决方案铺平道路。
### Conclusion
该研究强调了阴影意识在合成数据驱动模型中的重要作用，并展示了如何利用不完美的现实世界LiDAR数据增强MHE的准确性与鲁棒性。通过提出的校正管道，该研究提出了一个更可靠的MHE解决方案，有助于实现更高的3D映射精度。
## 512. `cs.CV` - Dual-Stage Reweighted MoE for Long-Tailed Egocentric Mistake Detection [PDF](https://arxiv.org/pdf/2509.12990), [HTML](https://arxiv.org/abs/2509.12990)
### Authors
Boyu Han,Qianqian Xu,Shilong Bao,Zhiyong Yang,Sicong Li,Qingming Huang
### Background
本文档解决从第一人称视角视频数据中确定用户是否执行动作错误的问题。面对细微且不频繁的错误带来的挑战，研究人员提出了一个双阶段重加权混合专家（DR-MoE）框架。
### Innovation
该研究提出了一个双阶段重加权混合专家（DR-MoE）框架，第一阶段使用冻结的ViViT模型和LoRA调优的ViViT模型提取特征，并通过特征层级的专家模块进行结合；第二阶段通过三个具有不同目标的分类器进行训练：重加权交叉熵以缓解类别不平衡问题，AUC损失以改进倾斜分布下的排序效果，以及带尖锐aware最小化的标签感知损失以增强校准与泛化能力。这些预测通过分类层级的专家模块进行融合。
### Conclusion
所提出的方法在识别罕见和模棱两可的错误实例方面表现出色。该方法的代码已公开。
## 513. `cs.CV` - Q-FSRU：带有量子增强的频率光谱方法用于医学视觉问答 [PDF](https://arxiv.org/pdf/2509.23899), [HTML](https://arxiv.org/abs/2509.23899)
### Authors
Rakesh Thakur,Yusra Tariq,Rakesh Chandra Joshi
### Background
在医疗AI领域，解决需要图像和文本理解的复杂临床问题仍然是一个重大挑战。本文提出了一种新的模型——Q-FSRU，它结合了频率谱表示和融合（FSRU）以及一种名为量子检索增强生成（Quantum RAG）的方法，用于医疗视觉问答（VQA）。该模型通过快速傅里叶变换对医学图像和相关文本进行特征提取和频率变换，聚焦有意义的数据并过滤噪音，增强模型对复杂病例的处理能力。
### Innovation
提出的Q-FSRU模型通过结合频率谱表示和量子检索增强生成技术，对医学图像和相关文本进行处理，提高模型性能和解释性。模型中的量子启发检索系统能够从外部来源获取基于量子相似性的有用医学事实，将这些细节与频率特征结合，用于增强推理能力。
### Conclusion
该方法展示了构建智能且易于理解的医疗AI工具的潜力，特别是在医学视觉问答领域。Q-FSRU模型在复杂需要图像文本推理的情况下，比先前的模型表现更优异。
## 514. `cs.CV` - Evict3R: 无需训练的推理时令牌驱逐策略以实现内存有限的流式视觉几何变换器 [PDF](https://arxiv.org/pdf/2509.17650), [HTML](https://arxiv.org/abs/2509.17650)
### Authors
Soroush Mahdi,Fardin Ayar,Ehsan Javanmardi,Manabu Tsukada,Mahdi Javanmardi
### Background
基于视觉变换器的流式3D感知方法，如StreamVGGT，尽管表现出强劲的感知能力，但也面临着键值对（KV）内存无边界增长的问题，这种问题限制了扩展性。现有的解决方案需要在模型大小与内存消耗之间做出权衡，通常会牺牲模型的准确度。因此，如何在保证模型性能的同时有效管理内存消耗成为了一个重要的研究方向
### Innovation
提出了一种无需训练、仅在推理时应用的令牌驱逐策略，通过在保证关键信息保留的同时驱逐冗余令牌，来管理内存使用。该方法在7-Scenes数据集上，通过降低峰内存使用率，提高了重建准确度和完整性，同时仅牺牲了极小的准确度。在严格内存约束下，方法使得可以进行更密集的帧采样，从而提升重建精确度。实验结果表明，这种方法在视觉深度估计、3D重建和相机姿态估计上，能够以较低内存消耗接近流式变换器的性能，使其更具长视角流式推理的应用可能性
### Conclusion
实验表明，Evict3R方法能够在保证模型性能的同时显著降低内存消耗，特别是在4GB或6GB的内存上限情况下，可以实现3D重建、相机姿态估计的高性能计算，使之在实际应用中更具可行性。
## 515. `cs.CV` - 基于语境表示学习的有效人类物体交互检测 [PDF](https://arxiv.org/pdf/2509.12784), [HTML](https://arxiv.org/abs/2509.12784)
### Authors
Zhehao Li,Yucheng Qian,Chong Wang,Yinghao Lu,Zhihao Yang,Jiafei Wu
### Background
人类-物体交互（HOI）检测旨在同时定位人类-物体对并识别它们的交互。虽然最近的两阶段方法取得了显著进展，但仍面临因未能充分建模上下文而带来的挑战。本文通过引入基于语境的表示学习，结合技能引导的推理和上下文提示，并结合视觉线索，以更好地捕捉复杂交互，增强了传统的HOI检测框架。
### Innovation
该研究通过引入基于语境的表示学习方法，改进了传统的HOI检测框架。具体而言，通过三元组结构<人, 工具, 物体>明确建模辅助物体的功能角色，同时引入可学习的提示并结合上下文视觉特征，使用注意力机制在全局和区域级别使语言与图像内容对齐，从而为复杂的、依赖上下文的交互提供丰富的关系线索。这种方法在HICO-Det和V-COCO数据集的大多数场景中都表现出更好的性能。
### Conclusion
所提出的方法在HICO-Det和V-COCO数据集中的大多数场景中都展示了优秀的性能。源代码可以在提供的链接中获取。
## 516. `cs.CV` - 朝向尺寸不变的显著目标检测：一种通用评估和优化方法 [PDF](https://arxiv.org/pdf/2509.15573), [HTML](https://arxiv.org/abs/2509.15573)
### Authors
Shilong Bao,Qianqian Xu,Feiran Li,Boyu Han,Zhiyong Yang,Xiaochun Cao,Qingming Huang
### Background
本文探讨了显著目标检测（SOD）中一个基本但未充分研究的问题：评价协议的尺寸不变性，特别是在单张图像中出现多个尺寸差异显著的显著目标的情况下。现有广泛使用的SOD度量具有内在的尺寸敏感性，当前的SOD度量下的评价结果可以被基本分解为几个分离项之和，每个项的贡献与其对应的区域大小成正比。因此，预测误差主要由大区域主导，而小但仍可能具有重要意义的对象往往被忽视，导致性能评估偏倚和实际性能下降。
### Innovation
提出了一个通用的尺寸不变评价框架（SIEva），核心思想是逐个评估分离组件然后汇总结果，从而有效缓解不同目标之间尺寸不平衡的影响。在此基础上进一步开发了专门的优化框架（SIOpt），遵循尺寸不变原则，并显著增强了对广泛尺寸的显著目标的检测。SIOpt是模型无关的，并且可以无缝集成到广泛的SOD骨干网络中。此外，理论分析表明SOD方法的泛化能力，并提供了支持新评价协议有效性的证据。
### Conclusion
通过全面的实验验证了我们提出的方法的有效性。相关代码可以在[此链接]找到。
## 517. `cs.CV` - 对称分裂：从不完整数据进行自我监督学习 [PDF](https://arxiv.org/pdf/2510.00929), [HTML](https://arxiv.org/abs/2510.00929)
### Authors
Victor Sechaud,Jérémy Scanvic,Quentin Barthélemy,Patrice Abry,Julián Tachella
### Background
自我监督学习可以训练一个用于从噪声或不完整数据中重建的网络。这种方法在获取用于训练的真实参考数据昂贵或根本不可能的情况下，有潜力使基于学习的解决方案成为可能。在本文中，作者提出了一种新的自我监督学习策略，该策略设计应用于仅通过单一不完整观测模型观察测量数据的挑战性环境。通过一系列针对图像修复、加速磁共振成像和压缩感知的实验，作者展示了所提出的损失函数在具有高度秩亏的前向模型的设置中实现了最先进的性能。
### Innovation
作者提出了新的对称分裂的概念，并证明结合自我监督分裂损失和对称重建网络，在数学期望下，能达到与监督损失相同的最小值。这一创新策略特别适用于仅使用单一不完整观测模型观察的测量数据情况。
### Conclusion
作者通过在图像补全、加速磁共振成像和压缩感知任务上的实验，证明了拟提出的损失函数在高度秩亏的前向模型设置中实现了最新的性能。
## 518. `cs.CV` - VirDA：使用视觉重编程在无监督领域适应中重用骨干 [PDF](https://arxiv.org/pdf/2510.01660), [HTML](https://arxiv.org/abs/2510.01660)
### Authors
Duy Nguyen,Dat Nguyen
### Background
现有UDA管道在每次新源-目标对出现时都会对已经训练好的骨干参数进行微调，导致训练参数数量和存储内存数量线性增长，无法重复利用这些成功训练的骨干参数。由于现有的骨干存在纹理偏见，本文提出了一种视觉重编程的方法，通过视觉重编程来利用特定领域的纹理偏见进行领域适应，即VirDA。这种方法不微调整个骨干，而是将一个领域特定的视觉重编程层附加到骨干之前，通过这种层生成视觉提示，使输入图像的“风格”适应目标领域。
### Innovation
提出了VirDA方法，该方法通过在骨干之前添加一个领域特定的视觉重编程层，生成视觉提示来动态调整输入图像的“风格”，而不是完全微调骨干，从而避免了资源的重复构建，提高了资源利用效率。通过多个优化目标函数优化这个视觉重编程层，从而在不修改骨干参数的情况下实现跨域复用。
### Conclusion
在Office-31测试集上，使用只有1.5百万个可训练参数的VirDA获得了92.8%的平均准确率。相比参数效率较高的UDA基线PDA，VirDA在保持仅46%参数的情况下提高了1.6%的准确率。与完全骨干微调方法相比，VirDA在CDTrans和FixBi上分别提高了0.2%和1.4%的准确率，但只使用了它们可训练参数的1.7%和2.8%。与当前最强方法PMTrans和TVT相比，VirDA的可训练参数分别约为它们的1.7%，但在准确率上分别损失了2.2%和1.1%。
## 519. `cs.CV` - 基于YOLO的金属板材缺陷检测 [PDF](https://arxiv.org/pdf/2509.25659), [HTML](https://arxiv.org/abs/2509.25659)
### Authors
Po-Heng Chou,Chun-Chi Wang,Wei-Lung Mao
### Background
在工业制造中，手动检测缺陷是一个耗时且劳累的过程。因此，需要引入自动化技术来提高工作效率和准确性。本研究使用YOLO（You Only Look Once）进行缺陷检测，以处理金属板材表面和孔洞的缺陷检测问题。然而，缺乏金属板材图像显著降低了检测精度。为了解决这一问题，使用ConSinGAN（Conditional SIN-GAN）生成大量数据，结合四种不同版本的YOLO模型（YOLOv3、v4、v7和v9）进行数据增强。
### Innovation
结合使用ConSinGAN生成数据和四种YOLO模型进行缺陷检测，特别是优化后的YOLOv9模型，达到了91.3%的检测准确率，并且检测时间仅为146毫秒。该系统被集成到制造硬件和SCADA系统中，形成了一个实用的自动化光学检测(AOI)系统。此外，该自动化缺陷检测方法可以很容易地应用于工业制造中的其他组件。
### Conclusion
提出了基于YOLO的自动化缺陷检测系统，通过与ConSinGAN结合使用数据增强技术，提高了检测准确性和效率，并成功地应用于金属板材的缺陷检测，进一步推广至其他工业制造组件的检测。
## 520. `cs.CV` - 更简但力更大的视觉语言模型赋能自动驾驶 [PDF](https://arxiv.org/pdf/2510.00060), [HTML](https://arxiv.org/abs/2510.00060)
### Authors
Sheng Yang,Tong Zhan,Guancheng Chen,Yanfeng Lu,Jian Wang
### Background
当前自动驾驶领域中，传统的轨迹规划任务通常需要多个步骤和复杂的模型，这不仅增加了实现的复杂度，还可能降低模型的实时性和效率。本研究将自动驾驶重新构想为一种通用语言，并将轨迹规划任务定义为下一预定点的预测。该论文旨在通过探索更简洁但更强大的视觉语言模型，提供一种端到端的一阶段自动驾驶框架Max-V1，以改善轨迹预测的准确性和实时性。
### Innovation
论文提出了一种新颖的一阶段端到端自动驾驶框架Max-V1，引入了单次传输生成范式，以适应驾驶的内在顺序性。这种方法利用了视觉语言模型（VLM）的生成能力，可以直接从前视摄像头输入中进行端到端轨迹预测。该方法通过数据集外推效果表明了其优越的泛化性能，适用于多种车辆类型，并且在nuScenes数据集上的表现优于先前的基础模型，提升了约30%的表现。此外，这项工作还提出了一种基于统计建模的有原则的监督策略，使得框架能够通过大规模专家演示的模仿学习掌握复杂驾驶策略。
### Conclusion
该研究通过引入Max-V1框架，提供了一种有潜力的自动驾驶方法，从经验和实证结果来看，显著提升了自动驾驶性能。这为开发更具能力的自动驾驶代理奠定了基础。研究者承诺会在发表后提供代码。
## 521. `cs.CV` - 使用单个线性层解决向量量化模型中表示塌陷问题 [PDF](https://arxiv.org/pdf/2411.02038), [HTML](https://arxiv.org/abs/2411.02038)
### Authors
Yongxin Zhu,Bocheng Li,Yifei Xin,Zhihua Xia,Linli Xu
### Background
矢量量化（VQ）在无监督学习中用于离散化连续表示，但容易出现表示塌陷的问题，造成码本书利用率低，限制了模型的可扩展性。现有解决方案往往依赖复杂的优化或降低潜在维度，这牺牲了模型的容量，并未能充分解决问题。
### Innovation
本文识别出根源在于离散码本优化，其中只有少量码矢量通过梯度下降更新。为解决此问题，本文提出了简单的SimVQ，通过在潜在基上添加可学习的线性变换层重新参数化码矢量，优化整个线性空间而非个别最近的码矢量。即便两个线性矩阵的乘积等同于应用单一的线性层，此简单方法有效防止了塌陷。
### Conclusion
在图像和音频任务上的广泛实验表明，SimVQ提高了码本书的利用率，易于实施，并且在不同的模态和架构下具有良好泛化能力。该代码可在指定链接访问。
## 522. `cs.CV` - S-Graphs 2.0 — 基于层次语义的SLAM优化与循环闭合 [PDF](https://arxiv.org/pdf/2502.18044), [HTML](https://arxiv.org/abs/2502.18044)
### Authors
Hriday Bavle,Jose Luis Sanchez-Lopez,Muhammad Shaheer,Javier Civera,Holger Voos
### Background
3D场景图的层次结构在表示目的上具有高度相关性，因为它符合人造环境中的常见模式。此外，这种层次结构中的语义和几何信息可以被利用来加速地图元素和机器人姿态的优化和管理。
### Innovation
1. 提出了前向模块，包括能够识别梯段并为底层层次分配楼层语义关系的楼层检测模块，提出了一种基于楼层的循环闭合策略，有效拒绝了由于建筑物不同楼层之间混叠导致的假阳性闭合。2. 结合层次表达式在优化中的应用：局部优化、楼层水平全局优化和房间水平局部优化。
### Conclusion
算法在不同多层真实环境中的广泛应用验证了其有效性。该方法在大型多层环境中的层级表示精度与竞标基准相比提升了大约10倍，显示出先进的性能指标。
## 523. `cs.CV` - ExGS: Extreme 3D Gaussian Compression with Diffusion Priors [PDF](https://arxiv.org/pdf/2509.24758), [HTML](https://arxiv.org/abs/2509.24758)
### Authors
Jiaqi Chen,Xinhao Ji,Yuanyuan Gao,Hao Li,Yuning Gong,Yifei Liu,Dan Xu,Zhihang Zhong,Dingwen Zhang,Xiao Sun
### Background
3D Gaussian Splatting (3DGS)具有高质量的神经渲染能力，但由于其巨大的存储和传输成本，限制了在资源受限环境中的部署。现有压缩方法要么依赖于昂贵的优化，要么采用无训练剪枝和量化，但在高压缩比下会导致渲染质量下降。最近的数据驱动方法提供了解决这一权衡问题的新途径，能够同时实现高效压缩和高质量渲染。然而，传统的修复方法仅填补缺失区域，未提升可见像素的质量，不足以满足更高要求的设计目标。
### Innovation
提出了ExGS，这是一种新的前馈框架，结合了通用高斯压缩（UGC）和GaussPainter，用于极端3DGS压缩。UGC通过不依赖重新优化的剪枝方法，大幅度减少了高斯原语的数量，并保留了关键信息。GaussPainter利用强大的扩散先验和掩码引导的细化，修复从高度剪枝的高斯场景中恢复高质量的渲染。与传统的修复方法不同，GaussPainter不仅填补缺失区域，还增强了可见像素，大幅提升了降级的渲染质量。ExGS采用轻量级VAE和一步扩散设计，实现了实时修复。在这些条件下，ExGS可实现超过100倍的压缩（将典型的354.77 MB模型减少到约3.31 MB），同时保持保真度并显著改善了图像质量。
### Conclusion
ExGS展示了扩散先验在极端压缩和高质量神经场景渲染之间建立桥梁的重要性。其轻量级设计和高效的实时修复能力证明了ExGS在资源受限环境中的实用性和潜力。代码仓库将发布在给定的链接处。
## 524. `cs.CV` - WaveNet-SF: 基于时空频域小波变换的混合网络用于视网膜疾病检测 [PDF](https://arxiv.org/pdf/2501.11854), [HTML](https://arxiv.org/abs/2501.11854)
### Authors
Jilan Cheng,Guoli Long,Zeyu Zhang,Zhenjia Qi,Hanyu Wang,Libin Lu,Shuihua Wang,Yudong Zhang,Jin Hong
### Background
视网膜疾病是导致视力受损和失明的主要原因之一，及时诊断对于有效治疗至关重要。光学相干断层扫描（OCT）已成为视网膜疾病诊断的标准成像技术，但OCT图像常常受到诸如斑点噪声、复杂病灶形状和病变大小变化等问题的影响，导致解读困难。
### Innovation
本文提出了一种新的框架WaveNet-SF，通过结合时空域学习来增强视网膜疾病的检测能力。该框架利用小波变换将OCT图像分解为低频和高频分量，使模型能够提取全局结构特征和精细细节。为了提高病变检测效果，引入了多尺度小波空间注意力（MSW-SA）模块，增强模型对多个尺度感兴趣区域的关注。此外，还加入了高频特征补偿（HFFC）块，以在小波分解过程中恢复边缘信息、抑制噪声并保持对于病变检测至关重要的细微细节。
### Conclusion
该方法在OCT-C8和OCT2017数据集上分别实现了97.82%和99.58%的最新技术水平（SOTA）分类准确率，超越了现有方法。这些结果证明了WaveNet-SF在解决OCT图像分析挑战中的效能及其作为视网膜疾病诊断有力工具的潜力。
## 525. `cs.CV` - Pack and Force Your Memory: 长时且一致的视频生成 [PDF](https://arxiv.org/pdf/2510.01784), [HTML](https://arxiv.org/abs/2510.01784)
### Authors
Xiaofei Wu,Guozhen Zhang,Zhiyong Xu,Yuan Zhou,Qinglin Lu,Xuming He
### Background
长视频生成面临着双重要挑战：模型必须捕捉长程依赖关系，同时避免自回归解码中固有的错误累积。为解决这些挑战，我们提出了两种贡献。首先，对于动态上下文建模，我们提出了一种称为MemoryPack的可学习的上下文检索机制，它结合了文本和图像信息作为全局指导，联合建模短期和长期依赖关系，实现了分钟级别的时序一致性。其次，为了减轻错误累积，我们引入了一种高效的单步近似策略Direct Forcing，该策略提高了训练推断的一致性，从而减少了推理期间的错误传播。
### Innovation
我们提出了两种创新贡献：MemoryPack和Direct Forcing。MemoryPack是一种可学习的上下文检索机制，能够结合文本和图像信息，并实现从短期到长期的依赖关系建模，以保证视频生成的时序一致性。Direct Forcing则是一种高效的单步近似策略，用于减少推理期间的错误传播。这两种方法结合起来，显著增强了长视频生成的语境一致性和可靠性，推动了自回归视频模型的实际应用可行性。
### Conclusion
MemoryPack和Direct Forcing的结合有效提升了长视频生成的语境一致性和可靠性，显著改善了自回归视频模型的实用性和可靠性。
## 526. `cs.CV` - 使用3D高斯点绘制学习高保真机器人自模型 [PDF](https://arxiv.org/pdf/2503.05398), [HTML](https://arxiv.org/abs/2503.05398)
### Authors
Kejun Hu,Peng Yu,Ning Tan
### Background
现有的数据驱动技术已能在机器人建模方面发挥作用，但现有自建模方法存在建模质量低或数据采集成本过高的问题。此外，机器人的纹理特征未被充分探索和建模。论文旨在提出一种高质量的、纹理意识的、关节级别的机器人自建模方法。
### Innovation
论文提出了一种基于3D高斯分布的机器人自建模方法。利用3D高斯分布表示静态形态和纹理，并使用3D高斯分布聚类构建由动力学神经网络控制变形的神经椭球骨。通过关节角度、相机参数和多视角图像（无深度信息）的数据对训练3D高斯分布和动力学神经网络。结合3D高斯描点绘制技术，通过关节角度输入可以描述机器人关节级别的形态、动力学和纹理，并从不同视角生成机器人图像。该方法还能用于下游任务，如运动规划和逆运动学。
### Conclusion
建立了高质量的、关节级别的机器人自模型，能够克服现有方法的缺点，并且展示了其在机器人形态学、动力学及其纹理特性建模以及下游任务执行上的有效性。
## 527. `cs.CV` - 端到端神经压缩与重建中的超高效解码 [PDF](https://arxiv.org/pdf/2510.01407), [HTML](https://arxiv.org/abs/2510.01407)
### Authors
Ethan G. Rogers,Cheng Wang
### Background
图像压缩和重构在各种数字应用中至关重要。尽管当前的神经网络压缩方法实现了令人印象深刻的压缩率，但这些技术的采用受到了基于卷积的解码器在数据重构过程中复杂性和高计算成本的阻碍。
### Innovation
开发了一种基于卷积自动编码器和向量量化结合低秩表示的新压缩-重构框架，通过在学习到的图像潜在表示上进行一系列高效的低秩操作实现高质量的数据重构，从而在神经压缩/重构的解码阶段显著减少计算开销，基本消除了解码计算瓶颈，同时保持了高质量的图像输出。
### Conclusion
本研究提出的方法在解码阶段大幅降低了计算开销，避免了解码计算瓶颈，同时保持了高质量的图像重构结果，提高了端到端神经压缩与重构的效率和实用性。
## 528. `cs.CV` - UniVerse: Unleashing the Scene Prior of Video Diffusion Models for Robust Radiance Field Reconstruction [PDF](https://arxiv.org/pdf/2510.01669), [HTML](https://arxiv.org/abs/2510.01669)
### Authors
Jin Cao,Hongrui Wu,Ziyong Feng,Hujun Bao,Xiaowei Zhou,Sida Peng
### Background
本文探讨了鲁棒重建的挑战，即从一组不一致的多视角图像中重建3D场景的任务。近期的一些工作尝试通过将图像退化建模集成到神经3D场景表示中来同时移除图像不一致性和进行重建。然而，这些方法严重依赖密集观察以稳健地优化模型参数。为了解决这个问题，本文提出将鲁棒重建分解为两个子任务：修复和重建，这自然简化了优化过程。具体的，UniVerse基于视频扩散模型提出了一个统一的框架，首先将不一致的图像转换为初始视频，然后使用一个专门设计的视频扩散模型将它们恢复为一致的图像，最后从这些恢复的图像中重建3D场景。这样的方法可以克服逐视图退化建模的局限性，从大规模数据中学习通用场景先验，适用于各种图像不一致性。在合成和现实世界的数据集上的大量实验表明，该方法具有强大的泛化能力和优越的鲁棒重建性能。此外，UniVerse可以控制重建3D场景的样式。
### Innovation
本文提出了一种新颖的方法，即将鲁棒重建分解为修复和重建两个子任务，提出了一种基于视频扩散模型的统一框架UniVerse。它通过将不一致的图像转换成视频，然后使用视频扩散模型将图像恢复为一致图像，最后从这些恢复图像中重建3D场景，与逐视图退化建模相比，扩散模型可以学习通用场景先验，适用于各种图像不一致性。这种方法在合成和现实世界的数据集上的表现更加优越。此外，这种方法还可以控制重建3D场景的样式。
### Conclusion
本文提出的UniVerse方法在合成和现实世界的数据集上的大量实验证明了其强大的泛化能力和优越的鲁棒重建性能，并且还能控制重建3D场景的样式。
## 529. `cs.CV` - 基于视觉的机器人抓取算法基准研究 [PDF](https://arxiv.org/pdf/2503.11163), [HTML](https://arxiv.org/abs/2503.11163)
### Authors
Bharath K Rameshbabu,Sumukh S Balakrishna,Brian Flynn,Vinarak Kapoor,Adam Norton,Holly Yanco,Berk Calli
### Background
本文通过基准测试研究了不同的基于视觉的机器人抓取算法，比较了两种基于机器学习的方法和两种分析方法，考虑了照明、背景纹理、不同噪声水平的相机和不同机械手等多种实验条件。在仿真和真实机器人上进行了类似实验，并分析了差异。此外，在两个实验室使用相同协议重复进行了部分实验，以进一步分析结果的可重复性。
### Innovation
使用现有的基准测试协议，在多种实验条件下比较不同基于视觉的机器人抓取算法，并展示了系统性实验在机器人操作中的作用和挑战。研究共进行了5040次实验，为新算法的开发提供了有价值的见解。
### Conclusion
本文研究了基于视觉的机器人抓取算法的不同方法，并提供了基于实验对比的分析。研究通过多种因素的影响，评估了现有算法的优势和劣势。结果表明，系统性实验在机器人操作中的必要性和重要性，并提供了一个基准测试软件和实验记录以供参考。
## 530. `cs.CV` - MCGS-SLAM: 一种使用高斯斑图进行高保真制图的多相机SLAM框架 [PDF](https://arxiv.org/pdf/2509.14191), [HTML](https://arxiv.org/abs/2509.14191)
### Authors
Zhihao Cao,Hanyu Wu,Li Wa Tang,Zizhou Luo,Zihan Zhu,Wei Zhang,Marc Pollefeys,Martin R. Oswald
### Background
近年来，稠密SLAM的研究主要集中在单目设置上，往往牺牲了鲁棒性和几何覆盖率。现有的多相机SLAM系统通常依赖于稀疏的地图或惯性数据，这限制了系统的性能。
### Innovation
我们提出了MCGS-SLAM，这是一个基于3D高斯斑图的首个多相机RGB SLAM系统。不同于以往依赖稀疏地图或惯性数据的方法，MCGS-SLAM将多视角的密集RGB输入融合到一个连续优化的高斯图中。利用多相机 bundle 调整 (MCBA) 同时优化姿态和深度，同时利用低秩先验强制多视图之间的尺度一致性。该系统既能支持RGB输入又能保持大规模实时性能。
### Conclusion
实验结果表明，MCGS-SLAM在合成和实际数据集上的轨迹和重建结果都优于单目基线，且能够重建单目设置无法捕捉的侧视区域，对于安全的自主操作至关重要。这表明多相机高斯斑图SLAM在机器人学和自动驾驶中的高保真制图有巨大潜力。
## 531. `cs.CV` - Causal-Adapter: Taming Text-to-Image Diffusion for Faithful Counterfactual Generation [PDF](https://arxiv.org/pdf/2509.24798), [HTML](https://arxiv.org/abs/2509.24798)
### Authors
Lei Tong,Zhihua Liu,Chaochao Lu,Dino Oglic,Tom Diethe,Philip Teare,Sotirios A. Tsaftaris,Chen Jin
### Background
本文介绍了Causal-Adapter框架，该框架旨在适应冻结的文字到图像扩散模型，用于生成反事实图像。这种方法允许对目标属性进行因果干预，这些干预会影响其因果依赖而不改变图像的核心身份。与依赖于提示工程但无明确因果结构的方法不同，Causal-Adapter结合结构因果建模及两种属性正则化策略：符合提示的注入，可以使因果属性与文本嵌入对齐，实现精确的语义控制；条件令牌对比损失来解耦属性因子，减少无效的关联。
### Innovation
Causal-Adapter框架引入了两种属性正则化策略，包括符合提示的注入和条件令牌对比损失。这些策略旨在确保生成的反事实图像具有精确的属性控制和高度的图像保真度。研究结果表明，Causal-Adapter在合成和真实数据集上的表现优于现有方法，包括在Pendulum数据集上将MAE降低了91%，在ADNI数据集上将FID降低了87%，证明了其能够实现稳健的、泛化的反事实编辑能力。
### Conclusion
本研究展示了Causal-Adapter框架，该框架能够利用结构因果建模和属性正则化策略，实现反事实编辑中的忠实属性修改和强大的图像保真度，相较于现有方法，其在合成数据集和真实世界数据集上的表现均达到了领先水平。
## 532. `cs.CV` - CostFilter-AD: 通过匹配成本过滤提高异常检测 [PDF](https://arxiv.org/pdf/2505.01476), [HTML](https://arxiv.org/abs/2505.01476)
### Authors
Zhe Zhang,Mingxiu Cai,Hanxiao Wang,Gaochang Wu,Tianyou Chai,Xiatian Zhu
### Background
现有的无监督异常检测（UAD）方法主要通过重建正常样本或学习图像特征嵌入空间来进行，这些方法很大程度上依赖于图像级或特征级的匹配来生成异常分数。然而，这样的匹配过程往往不够精确但常被忽视，导致检测结果不佳。论文指出了这一问题并提出引入成本过滤的概念，借鉴了经典匹配任务（如深度和流估计）的成本过滤方法，应用于UAD问题。
### Innovation
提出了一个名为CostFilter-AD的方法。首先构建输入图像与正常样本之间的匹配成本体积，该体积包含两个空间维度和一个匹配维度，编码潜在匹配信息。随后提出了一种成本体积过滤网络，由输入观测引导，在多个特征层之间作为注意力查询进行，有效抑制匹配噪声，保留边缘结构并捕捉细微的异常。此外，该方法设计为通用后处理插件，可以与重建基方法或嵌入基方法结合使用。实验验证了CostFilter-AD在单类和多类UAD任务中的通用优势。
### Conclusion
在MVTec-AD和VisA基准上的大量实验验证了CostFilter-AD方法在无监督异常检测中的广泛效用。该方法作为一种通用的后处理插件可以与多种类型的UAD方法结合使用。CostFilter-AD的代码和模型将公开可用。
## 533. `cs.LG` - 基于市场的数据子集选择——多准则示例有用性的原则聚合 [PDF](https://arxiv.org/pdf/2510.02456), [HTML](https://arxiv.org/abs/2510.02456)
### Authors
Ashish Jha,Valentin Leplat,AH Phan
### Background
选择小而有用的训练数据集是一个困难的任务，因为示例有用性的信号（不确定性、稀有性、多样性等）是异质的，并且通常带有非正式的权重组合。
### Innovation
提出了一种基于市场的选择器，通过成本函数预测市场（LMSR）进行定价，信号充当交易者，单一的流动参数控制集中度，主题归一化稳定校准。通过价格/令牌规则 ο=p/ γ控制令牌预算，ο 显示了一个可解释的长度偏差；轻量级的多样性头提高了覆盖度。通过主题簇覆盖和有效样本大小衡量覆盖度。理论上，展示了 LMSR 实现了指数权重和凸目标函数的最大熵聚合，提供了聚合强度的透明旋钮。在 GSM8K 和 AGNews 实验中，实现了与单一信号基准相当的性能，同时降低了种子方差和<0.1 GPU-小时的选择开销。
### Conclusion
该框架统一了固定计算资源下的多准则数据管理，用于提示级推理和分类。
## 534. `cs.CV` - 采用YOLOv12进行泛癌种分裂象检测 [PDF](https://arxiv.org/pdf/2509.02593), [HTML](https://arxiv.org/abs/2509.02593)
### Authors
Raphaël Bourgade,Guillaume Balezo,Thomas Walter
### Background
分裂象是肿瘤病理学中的关键组织预后特征，能够提供有关肿瘤侵袭性和增殖的重要见解。然而，它们的识别仍然具有挑战性，即使是经验丰富的病理学家之间也存在显著的主观差异。
### Innovation
提出了一种基于先进技术YOLOv12的目标检测架构的分裂象检测方法，该方法在初步测试集上的F1分数达到0.801（仅热点），在最终测试排行榜上，通过综合和异质的全切片区域的F1分数达到0.7216，且不依赖外部数据。该工作通过MIDOG 2025挑战赛的第三版，参与了国际范围内的竞赛，旨在开发稳健的分裂象检测算法。
### Conclusion
该方法在泛癌种全切片范围内的复杂和异质区域中实现了相对较高的F1分数，显示出在实际病理诊断中应用的潜力。
## 535. `cs.LG` - 不确定性指导的表格基础模型选择方法在生物分子效果预测中的应用 [PDF](https://arxiv.org/pdf/2510.02476), [HTML](https://arxiv.org/abs/2510.02476)
### Authors
Jie Li,Andrew McCarthy,Zhizhuo Zhang,Stephen Young
### Background
在生物分子效果预测中，上下文学习者如TabPFN有潜力利用已建立的分子特征集和相关实验结果作为强有力的上下文示例。然而，它们的表现对提供的上下文非常敏感，使得使用不同数据子集训练的模型进行事后集成成为可行的方法。一项开放的问题是如何在没有真实标签的情况下选择最佳模型进行集成。
### Innovation
本文研究了一种不确定性指导的模型选择策略。在siRNA敲低效果任务上展示了使用简单序列特征的TabPFN模型可以超越专门的最先进的预测器。此外，证明了模型预测的四分位距(IQR)与其真实的预测误差呈负相关。通过选择并平均具有最低平均IQR的模型组，展示了优于简单集成或在所有可用数据上训练单一模型的性能。
### Conclusion
这一发现突出了模型不确定性作为一种无标签的优化生物分子效果预测的强大启发式方法。
## 536. `cs.LG` - 使用相关性驱动的数据增强方法结合深度学习模型进行极值预测 [PDF](https://arxiv.org/pdf/2510.02407), [HTML](https://arxiv.org/abs/2510.02407)
### Authors
Junru Hua,Rahul Ahluwalia,Rohitash Chandra
### Background
数据增强技术，特别是生成对抗网络（GANs）和合成少数类过采样技术（SMOTE），在处理类别不平衡问题尤其是在图像识别等领域非常流行。极值预测是一个具有挑战性的领域，涉及从金融到气候变化的各种应用。本文研究了如何利用数据增强技术，结合深度学习模型进行极值预测，特别是在长短期预测中，考虑到了预测准确性和极端地区的性能，以及运算效率问题
### Innovation
提出了一个基于相关性驱动的数据增强框架，结合了不同深度学习模型（如Conv-LSTM和BD-LSTM）用于多步提前预测极值。研究了不同数据增强模型的适用性，考虑了总体预测准确度和在极端地区的特定性能，同时注重计算效率。引入了新的策略，将数据增强方法与极端值相关性相结合，SMOTE策略的表现优于其他方法，且在网络性能上表现出更好的适应性，适用于短期和长期预测
### Conclusion
Conv-LSTM和BD-LSTM在极值预测中表现出不同的优势：Conv-LSTM在周期性和稳定的数据集效果更好，而BD-LSTM则适合处理混沌或非平稳序列。SMOTE驱动的数据增强策略在各种预测情景中都表现出了更高的适应性和性能提升
## 537. `cs.LG` - 如何训练你的顾问：通过顾问模型引导黑箱大型语言模型 [PDF](https://arxiv.org/pdf/2510.02453), [HTML](https://arxiv.org/abs/2510.02453)
### Authors
Parth Asawa,Alan Zhu,Matei Zaharia,Alexandros G. Dimakis,Joseph E. Gonzalez
### Background
随着基础模型被广泛部署为不能修改模型权重的黑箱服务，定制化只能通过提示完成。虽然静态提示优化显示出前景，但它生成的固定提示不能适应不同的输入、用户或环境。该研究引入了顾问模型，这是一种轻量级的参数策略，通过强化学习训练，能够响应地在黑箱模型上下文中提供自然语言指导指令。顾问模型位于输入和模型之间，利用环境奖励信号，根据单个实例调整行为。在涉及推理和个性化等多个领域，该研究展示了顾问模型优于静态提示优化器，能够发现环境动态并提高下游任务性能。此外，研究还展示了顾问模型的通用性，能够跨不同黑箱模型迁移，证明了该框架在实现专业能力同时保持对未见过的输入鲁棒性的能力。
### Innovation
介绍了一种轻量级的参数策略——顾问模型，通过强化学习在上下文中引导黑箱模型，并能够根据环境反馈调整行为。该研究显示，这种动态优化策略在个性服务和环境适应性方面具有前沿能力。
### Conclusion
顾问模型为黑箱系统提供了一个可学习的接口，顾问作为参数化、环境特定的记忆体，动态优化黑箱模型是一个有前景的方向，旨在实现个性化和环境适应性AI的能力。
## 538. `cs.CV` - 权重生成模型：泛化还是记忆？ [PDF](https://arxiv.org/pdf/2506.07998), [HTML](https://arxiv.org/abs/2506.07998)
### Authors
Boya Zeng,Yida Yin,Zhiqiu Xu,Zhuang Liu
### Background
近年来，生成模型被探索用于合成神经网络权重。这些方法以神经网络的检查点作为训练数据，并试图在推理过程中生成高表现力的权重。已有研究表明这些方法在生成新颖的模型权重方面表现良好，即与训练过程中见过的检查点不同的权重。然而，本文通过实验表明，这些方法主要通过记忆来生成权重，而不是创造性的生成新权重。生成的权重要么是检查点的复制，要么是最简单的插值。这些方法在生成不同但同时高表现力模型方面未能超过简单的基线方法，例如向权重添加噪声或采取简单的模型权重集合并。进一步的分析表明，这种记忆现象可能是由于数据量有限、过度参数化的模型以及对特定于权重数据的结构先验不足造成的。这些观察激发了对生成模型应用于新领域时需要更加谨慎的设计和严格评估的思考。
### Innovation
本文创新性的通过实验证明了现有生成模型在生成新颖的神经网络权重方面的不足之处，特别是它们主要通过记忆现有检查点的权重来生成新的权重，而不是真正的创造性生成。此外，本文还进一步分析了这种记忆现象的原因，并指出了未来工作需要改进的方向，这为该领域的研究提供了新的视角。
### Conclusion
本文的研究结果表明，现有的生成模型主要依赖于记忆训练检查点的权重来生成新的权重，未能实现预期的创造性生成。这种方法在表现力和泛化能力方面未能优于简单的基线方法。进一步的分析显示，这种问题与有限的数据规模、过度参数化的模型以及对权重数据的结构先验的低效利用有关。本文强调了在应用程序领域使用生成模型时需要更加谨慎的设计和严格的评估。
## 539. `cs.LG` - RainSeer：基于物理指导的细粒度降水量重建 [PDF](https://arxiv.org/pdf/2510.02414), [HTML](https://arxiv.org/abs/2510.02414)
### Authors
Lin Chen(1),Jun Chen(1),Minghui Qiu(1),Shuxin Zhong(1),Binghong Chen(2),Kaishun Wu(1) ((1) The Hong Kong University of Science and Technology (Guangzhou), (2) China Meteorological Administration)
### Background
高质量的降雨场重建对于洪水预报、水文建模和气候分析至关重要。然而，现有基于自动气象站或卫星雷达增强的空间插值方法往往过度平滑关键结构，无法捕捉到降雨的尖锐转换和局部极端。这限制了这些方法在实际应用中的效果和准确性。
### Innovation
介绍了一种名为RainSeer的结构感知重建框架，该框架重新解释雷达反射率作为物理依据的结构先验，捕捉降雨发生的时间、地点及过程。它通过一个基于物理信息的两阶段架构实现：一种结构到点映射器将大尺度雷达结构投影到局部的地表降雨，并通过双向映射进行空间对齐；一种地理感知的降水分解器通过因果时空注意力机制捕捉降水中水汽的下降、融化和蒸发的语义转变。
### Conclusion
通过在两个公开数据集（韩国RAIN-F和法国MeteoNet）上的评估，RainSeer在MAE方面实现了超过13.31%的一致改进，并显著提高了重建降雨场的结构保真度。
## 540. `cs.LG` - Litespark 技术报告：高通量、高效能耗的大型语言模型训练框架 [PDF](https://arxiv.org/pdf/2510.02483), [HTML](https://arxiv.org/abs/2510.02483)
### Authors
Nii Osae Osae Dade,Moinul Hossain Rahat
### Background
训练大型语言模型（LLMs）面临长时间训练和巨大能源消耗的挑战，现代模型需要几个月的计算时间和吉瓦时的电力。为了应对这些挑战，我们引入了Litespark，一种新的预训练框架，通过对变压器注意力和MLP层的目标优化来解决这些效率问题。该方法结合了架构改进和算法优化，以最大化模型FLOPs利用率（MFU），同时保持与标准变压器实现的兼容性。
### Innovation
Litespark通过对变压器注意力和MLP层进行目标优化，结合架构改进和算法优化，最大化模型FLOPs利用率（MFU），在不牺牲兼容性的前提下大幅改进了训练通量和降低了能耗。在SlimPajama-627B数据集上对3亿和30亿参数的Llama模型的基准测试显示，跨多节点H200 GPU集群实现了2倍到6倍的训练吞吐量改进和55%到83%的能耗降低。这些优化对模型和硬件具有通用性，可以广泛应用于不同类型的变压器架构，并延伸至训练后阶段，包括监督微调和直接偏好优化。
### Conclusion
Litespark为大型语言模型训练提供了高通量、高效能耗的解决方案，实现在多节点H200 GPU集群上的显著性能提升和能耗降低，对未来改进变压器模型的训练效率具有重要价值。
## 541. `cs.LG` - 超越模仿：从示例中恢复密集奖励 [PDF](https://arxiv.org/pdf/2510.02493), [HTML](https://arxiv.org/abs/2510.02493)
### Authors
Jiangnan Li,Thuy-Trang Vu,Ehsan Abbasnejad,Gholamreza Haffari
### Background
传统上，监督微调（SFT）被视为一种简单的模仿学习过程，只有通过训练策略来模仿专家在示范数据集上的行为。这项工作挑战了这一观点，建立了SFT与逆强化学习的基本等价性。证明SFT目标是逆Q学习中的一种特殊情形，意味着SFT过程不仅学习策略，还学习一个隐含的、密集的、标记级别的奖励模型，来解释专家示范行为。本文介绍如何直接从SFT模型中提取这一密集奖励信号。
### Innovation
本文通过证明SFT目标是逆Q学习的一种特例，表明SFT不仅能学习策略，还能学习一种隐含的、密集的、标记级别的奖励模型。该研究提出了一种用于直接从SFT模型恢复密集奖励信号的基础方法，此方法可用于进一步通过强化学习改进策略。
### Conclusion
密集路径REINFORCE方法在指令遵循基准测试中始终优于原始SFT模型。这项工作将SFT重新定义为不仅模仿策略，而且作为一种强大的奖励学习机制，为利用专家示范提供了新的可能性。
## 542. `cs.LG` - 动态训练后量化中的潜在毁灭性失败评估 [PDF](https://arxiv.org/pdf/2510.02457), [HTML](https://arxiv.org/abs/2510.02457)
### Authors
Logan Frank,Paul Ardis
### Background
训练后量化（PTQ）作为一种通过使用较低精度表示权重和激活来减少神经网络计算复杂性和内存使用的有效工具，近年来取得了巨大成功。然而，PTQ 的性能在不同输入分布下可能会有显著下降，特别是在安全关键环境中使用时，必须评估这种性能降低的范围以及输入分布特征可能导致性能降低的因素。
### Innovation
本文开发了一种知识蒸馏和强化学习任务来学习网络和位宽策略对，以分析量化下的灾难性失败情况，这有利于从最糟情况分析潜在性能降低。研究结果证实了这种“有害”的网络-策略配对的存在，并展示了高达65%的准确性下降实例，这一现象远高于仅2%下降的“鲁棒”对。通过系统实验和分析，本文还初步探索了脆弱性最高的点。
### Conclusion
尽管我们的研究仅仅是对PTQ故障案例的理解迈出的第一步，但实验结果突显了在实际部署场景中需要谨慎的原因。希望这项研究能够鼓励对鲁棒性和安全性的更深入研究，在深度学习领域更广泛的研究中引起对安全性的更重视。
## 543. `cs.LG` - SAGE: 流动一致性驱动的梯度素述选择法用于代表性子集选择 [PDF](https://arxiv.org/pdf/2510.02470), [HTML](https://arxiv.org/abs/2510.02470)
### Authors
Ashish Jha,Salman Ahmadi-Asl
### Background
使用大规模数据集训练现代神经网络在计算能力和能源消耗上都非常密集。为了应对这一问题，本文提出了一种称为SAGE的流式数据子集选择方法。SAGE通过维护一个紧凑的Frequent Directions (FD) 梯度几何简图来处理数据，其内存占用仅为O(ℓ D)，并且优先选择那些其草图梯度与共识方向一致的示例。这种方法消除了N×N对称相似性计算和显式的N×ℓ梯度存储，从而实现了两个通过GPU的简单处理步骤。利用FD的确定性近似保证，该研究分析了一致性评分如何在主轴简图子空间内保持梯度能量。
### Innovation
提出了一种名为SAGE的新方法，这是一种基于流式数据子集选择的基于梯度素述的方法，能够在O(ℓ D)的内存中维护一个紧凑的Frequent Directions简图，同时通过简单两步流程优先选择符合共识方向的梯度。这种方法能显著减少计算量和峰值内存使用，同时保持与完整数据训练和最新的子集选择基线相媲美的准确性。
### Conclusion
SAGE提供了一种实用的，内存占用为常数的替代方案，可以与剪枝和模型压缩相结合，以实现高效训练。在多个基准测试中，SAGE在保持竞争力的同时，能够用较小的存储率预算进行训练，并在每端到端的计算和峰值内存使用上实现减少。
## 544. `cs.LG` - OpenTSLM: 时间序列语言模型用于多变量医学文本和时间序列数据的推理 [PDF](https://arxiv.org/pdf/2510.02410), [HTML](https://arxiv.org/abs/2510.02410)
### Authors
Patrick Langer,Thomas Kaar,Max Rosenblattl,Maxwell A. Xu,Winnie Chow,Martin Maritsch,Aradhana Verma,Brian Han,Daniel Seung Kim,Henry Chubb,Scott Ceresnak,Aydin Zahedivash,Alexander Tarlochan Singh Sandhu,Fatima Rodriguez,Daniel McDuff,Elgar Fleisch,Oliver Aalami,Filipe Barata,Paul Schmiedmayer
### Background
大型语言模型（LLMs）已经成为了多模态数据解释的强大工具。在医学领域，它们尤其有潜力将大量的临床信息综合成可行动的洞察和数字健康应用。然而，一个主要的限制在于它们无法处理时间序列数据。为克服这一限制，作者提出了一种名为OpenTSLM的家族式时间序列语言模型，该模型通过将时间序列作为预训练LLM的原生模态来处理，从而能够对任意长度的时间序列进行推理。
### Innovation
作者引入了两种OpenTSLM架构：OpenTSLM-SoftPrompt和OpenTSLM-Flamingo。OpenTSLM-SoftPrompt通过将可学习的时间序列令牌与文本令牌通过软提示进行拼接来隐式建模时间序列，而OpenTSLM-Flamingo则通过交叉注意力将时间序列与文本直接集成。作者还介绍了三个新数据集：HAR-CoT、Sleep-CoT和ECG-QA-CoT，并对比了这些模型与将时间序列视为文本令牌或图表的基线模型在文本-时间序列链式推理任务中的表现。
### Conclusion
通过一系列实验，OpenTSLM模型在所有任务中均优于基线模型，尤其是在睡眠阶段划分任务中达到了69.9的F1值，在HAR任务中达到了65.4的性能，远超仅微调文本模型的9.05和52.2。OpenTSLM-Flamingo在更长的序列上表现出色，且内存需求稳定，而SoftPrompt模型随序列长度增加，内存需求呈指数增长。临床专家评审认为OpenTSLMs在ECG-QA上展示了强大的推理能力。
## 545. `cs.LG` - AttentiveGRUAE: 一种基于注意力的GRU自编码器，用于时间聚类和从可穿戴数据中表征抑郁行为 [PDF](https://arxiv.org/pdf/2510.02558), [HTML](https://arxiv.org/abs/2510.02558)
### Authors
Nidhi Soley,Vishal M Patel,Casey O Taylor
### Background
本文研究了通过长过程佩戴设备数据进行行为特征的时序聚类和预测结局的方法。研究背景主要包括利用时间序列数据中的行为特征进行健康状况分析，特别是抑郁状态。传统方法可能无法充分挖掘长时间段内行为数据的时间依赖性和个体特征，因此需要新的方法来优化特征表示和预测效果。
### Innovation
本文提出了一种名为AttentiveGRUAE的新颖注意力机制增强的局部向量更新单元与递归神经网络的自编码器模型。该模型联合优化了三个目标：（1）通过序列重建学习每日行为特征的紧凑潜变量表示；（2）通过二元分类表头预测期末抑郁症率；（3）通过基于GMM的软聚类识别行为亚型。此外，该模型通过对比实际结果表明其在聚类质量和抑郁分类表现上的优异性。
### Conclusion
本文在最新的GLOBEM数据集上证明了AttentiveGRUAE模型的有效性，该模型不仅在聚类质量和预测准确性方面优于基线模型，还通过外部验证数据集显示了良好的聚类稳定性和重现性。另外，通过亚型分析进一步揭示了脑部注意力，突显了与睡眠差异相关的标识时间窗口，为进一步研究提供临床解释依据。
## 546. `cs.LG` - 从像素到因子：强化学习中学习独立可控的状态变量 [PDF](https://arxiv.org/pdf/2510.02484), [HTML](https://arxiv.org/abs/2510.02484)
### Authors
Rafael Rodriguez-Sanchez,Cameron Allen,George Konidaris
### Background
已有的算法在利用分解的马尔可夫决策过程时，比无分解假设的方法更样本高效，但这些算法的前提是分解结构已知。然而，当代理只看到高维度观察时，这一前提不再适用。另一方面，深度强化学习能够处理高维度输入，但无法从分解结构中受益。因此，本文提出了Action-Controllable Factorization (ACF)，一种对比学习方法，能够发现独立可控的潜在变量。这些变量在每个动作的操作下可以独立运作。这种方法利用了稀疏性假设：通常情况下，动作只会影响一部分变量，而其他部分则在环境动力学下演化，提供对比训练所需的信息。ACF 直接从像素观察中恢复真实的可控因子，在已知分解结构的三个基准测试中，即 Taxi、FourRooms 和 MiniGrid-DoorKey 中表现出了对基准分离算法的优越性。
### Innovation
提出了Action-Controllable Factorization (ACF)，一种利用对比学习从高维像素输入中发现独立可控的潜在变量的方法。这种创新利用了稀疏性假设，能够直接从像素观察中恢复真实的可控因子，从而为强化学习提供了一种新的方法。
### Conclusion
ACF 在已知分解结构的三个基准测试中表现出了显著的优势，直接从像素观察中恢复真实的可控因子，对基准分离算法形成了有效超越。
## 547. `cs.LG` - Graph生成与光谱测地流匹配 [PDF](https://arxiv.org/pdf/2510.02520), [HTML](https://arxiv.org/abs/2510.02520)
### Authors
Xikun Huang,Tianyu Ruan,Chihao Zhang,Shihua Zhang
### Background
图生成是建模复杂系统的基本任务，现有的方法侧重于对齐目标图的光谱或度分布，但经常忽略由特征向量引起的空间结构及图的全局结构。
### Innovation
我们提出了一种名为光谱测地流匹配（SFMG）的新框架，利用谱特征嵌入输入和目标图到连续黎曼流形中。然后定义嵌入间的测地流，并沿这些流匹配分布以生成输出图。这种方法具有以下优势：（i）捕捉超越特征值的几何结构，（ii）支持生成多样性的图结构，（iii）具备高效的可扩展性。实验表明，SFMG在图结构、度分布和光谱指标上与最先进的方法相当，尤其是在可扩展性和训练效率方面提供了30倍以上的性能提升，并能够泛化到未见过的图规模。
### Conclusion
SFMG通过将谱几何学与流匹配相结合，为图合成提供了一种新的方法。
## 548. `cs.LG` - 通过有界极值搜索提高时间变化系统中深度强化学习控制的鲁棒性 [PDF](https://arxiv.org/pdf/2510.02490), [HTML](https://arxiv.org/abs/2510.02490)
### Authors
Shaifalee Saxena,Alan Williams,Rafael Fierro,Alexander Scheinker
### Background
深度强化学习（DRL）因其能够从大规模数据集快速学习并控制或优化多参数系统而在许多领域展现出巨大潜力。然而，当系统模型在短时间内发生剧烈变化时，DRL的表现会急剧下降。有界极值搜索（Bounded ES）能处理具有未知控制方向的时间变化系统，但它在需要调整的参数数量增加时，收敛速度会变慢，并且像所有局部自适应方法一样，可能会停留在局部最小值。本文研究了如何通过结合DRL和Bounded ES来改善非线性时间变化系统的鲁棒性控制。
### Innovation
本文提出了将DRL和Bounded ES相结合的控制方法，旨在克服各自的不足。通过利用DRL的历史数据学习如何快速控制多参数系统达到目标设定值，同时确保控制系统对时间变化的鲁棒性。最终，这种方法的表现超过了两者的简单叠加。作者在一般的时间变化系统和洛斯阿拉莫斯中子科学中心线性粒子加速器的低能量束传输部分的组合ES-DRL控制器中进行了数值研究。
### Conclusion
结合DRL和Bounded ES的方法能够显著提高非线性时间变化系统的控制鲁棒性。DRL利用历史数据学习快速控制多参数系统的能力，以及Bounded ES确保控制对时间变化的稳定性，使得这两种方法结合起来能够产生超越各自部分的效果。这种方法特别适用于面对时间变化快速的应用环境。
## 549. `cs.LG` - 有限导态模拟设备上的基于多片残差学习的在内存训练 [PDF](https://arxiv.org/pdf/2510.02516), [HTML](https://arxiv.org/abs/2510.02516)
### Authors
Jindan Li,Zhaoxian Wu,Gaowen Liu,Tayfun Gokmen,Tianyi Chen
### Background
模拟内存计算（AIMC）加速器允许直接在内存内部使用电阻交叉阵列进行高效深度神经网络计算，其中模型参数由忆阻器设备的导电状态表示。然而，有效的在内存训练通常需要至少8比特的导电状态来匹配数字基线，实现如此精细的导电状态成本高昂，通常需要复杂的噪声抑制技术，这增加了电路复杂性和能耗。由于制造限制，许多有前途的忆阻器器件如ReRAM只能提供约4比特的分辨率，这种有限的更新精度显著降低了训练精度。为了在这些有限状态设备上实现芯片内训练，本文提出了一种残差学习框架，该框架按顺序在多个交叉片上学习，以补偿低精度权重更新的残差误差。我们的理论分析表明，残差的优化间隙随着交叉片数量的增加而缩小，并实现了线性收敛速度。在标准图像分类基准上的实验表明，在有限状态设置下，与最先进的模拟在内存训练策略相比，我们的方法始终表现出更高的性能，而且我们的成本分析证实了其只有中等程度的硬件开销.
### Innovation
本文提出了一种多片残差学习框架，用于在有限导态模拟器上实现芯片内训练。该方法学习在多个交叉片上逐步补偿低精度权重更新的残差误差，以提高训练准确性，同时减少电路复杂性和能耗。理论分析表明，此方法能实现线性收敛速度，使其在有限状态设置下表现优于现有技术，同时硬件开销适中.
### Conclusion
实验结果显示，在标准图像分类基准上，该方法在有限导态设置下始终优于现有模拟在内存训练技术，且硬件开销适中，理论分析也表明此方法具有线性收敛速度，优化间隙随着交叉片数量增加而减小.
## 550. `cs.LG` - 全美基于机器学习增强的概念可解释建模：流域尺度降水-储存-径流动力学 [PDF](https://arxiv.org/pdf/2510.02605), [HTML](https://arxiv.org/abs/2510.02605)
### Authors
Yuan-Heng Wang,Yang Yang,Fabio Ciulla,Hoshin V. Gupta,Charuleka Varadharajan
### Background
尽管现代许多研究致力于基于机器学习的大型样本水文建模，但这些努力并未必然转化为基于增强的物理概念理解的预测改进。本文报告了一个全美范围内的大型样本研究，使用了基于守恒质量感知机（MCP）的物理可解释的、不同复杂度的流域模型，该模型增强了对不同水文地质气候条件下降水-储存-径流动力学的理解。
### Innovation
研究通过使用机器学习增强的物理可解释的、基于守恒质量感知机的模型展示了性能与数据驱动模型基于长短期记忆网络（LSTM）架构相当的结果。特别强调了机制理解以及简约和可解释模型架构的发展，为未来基于空间和时间变化的过程主导性的模型架构奠定了基础。
### Conclusion
本文强调了一种理论导向、物理基础的方法在大型水文研究中的潜力，旨在实现对大型样本水文过程的机制理解，并发展简约且可解释的模型架构，从而为未来模型奠定了基础，这些模型能够建筑师编码空间和时间变化过程的主导信息。
## 551. `cs.LG` - GNN衍生的表达能力 [PDF](https://arxiv.org/pdf/2510.02565), [HTML](https://arxiv.org/abs/2510.02565)
### Authors
Yam Eitan,Moshe Eliasof,Yoav Gelberg,Fabrizio Frasca,Guy Bar-Shalom,Haggai Maron
### Background
尽管图神经网络（GNNs）取得了显著进展，但其有限的表达能力仍然是一个基本挑战。此前的研究已经产生了许多具有高度表达性的架构，形成了一个架构层次结构，这些模型具有不断增强的表达能力。此外，节点特征下的GNN导数已经广泛研究，特别是在过分压缩和过度平滑现象、GNN可解释性等方面。目前，这些导数还未被探索作为增强GNN表达性的手段。这项研究展示了这些导数提供了一种自然方式来增强GNN的表达能力。
### Innovation
该研究提出了High-Order Derivative GNN（HOD-GNN）方法，利用基模型的高阶节点导数增强消息传递神经网络（MPNN）的表达能力。这些导数通过第二级GNN生成结构意识性强的节点表示，并在端到端可训练架构中进行处理。理论上，研究证明该架构家族的表达能力与WL层次结构一致。该研究还探讨了HOD-GNN与子图GNN和流行的空间编码方案之间的深层联系。为了提高计算效率，该方法开发了一种基于图稀疏性和并行性的消息传递算法来计算MPNN的高阶导数。
### Conclusion
在流行图学习基准上的评估表明，HOD-GNN在流行图学习任务中表现出强大的性能。
## 552. `cs.LG` - HyperAdaLoRA: 使用超网络在训练期间加速LoRA秩分配而不牺牲性能 [PDF](https://arxiv.org/pdf/2510.02630), [HTML](https://arxiv.org/abs/2510.02630)
### Authors
Hao Zhang,Zhenjia Li,Runfeng Bao,Yifan Gao,Xi Xiao,Bo Huang,Yuhang Wu,Tianyang Wang,Hao Xu
### Background
Parameter-Efficient Fine-Tuning (PEFT)，尤其是LoRA，已经成为一个有潜力的方法，可以在减少计算和内存开销的同时微调大型语言模型（LLMs）。然而，LoRA假设每个增量矩阵有一个均匀的秩r，没有考虑到权重矩阵在不同模块和层之间的差异重要性。AdaLoRA通过使用奇异值分解（SVD）参数化更新，并通过剪枝奇异值来引入动态秩分配，从而增强了适应性。但在训练过程中，通常会出现收敛速度慢、计算开销大的问题。
### Innovation
我们提出了一种名为HyperAdaLoRA的新框架，通过利用基于注意力机制的超网络来加速AdaLoRA的收敛。HyperAdaLoRA不直接优化奇异值分解的组成部分（P, Λ, Q），而是使用一个超网络，通过剪枝生成奇异值的超网络输出来动态生成这些参数，从而实现动态秩分配。综合实验表明，该方法在不牺牲性能的情况下实现了更快的收敛。此外，进一步在其他基于LoRA的方法上的扩展实验验证了该方法的广泛适用性。
### Conclusion
我们的方法在各种数据集和模型上进行了全面实验，证明了在不牺牲性能的情况下实现了更快的收敛。进一步的实验结果还表明，该方法对其他基于LoRA的方法也具有广泛的适应性。
## 553. `cs.LG` - 使用跨个体变换进行模型与大脑比较 [PDF](https://arxiv.org/pdf/2510.02523), [HTML](https://arxiv.org/abs/2510.02523)
### Authors
Imran Thobani,Javier Sagastuy-Brena,Aran Nayebi,Jacob Prince,Rosa Cao,Daniel Yamins
### Background
人工神经网络模型被证明是大脑机理模型的有前途选择，但很少有共识用于比较模型激活与大脑反应的方法。本文借鉴哲学神经科学的最新成果，提出了一种基于跨个体变换类（IATC）的比较方法，IATC是精确映射动物群体中神经反应所需最严格的一系列函数。该方法能双向映射候选模型的响应与脑部数据，评估模型如何能够伪装成典型个体，使用类似用于跨真实个体映射的变换。
### Innovation
本文发现IATC能揭示神经机制的详细方面，如非线性激活函数。最重要的是，IATC能实现对神经活动的准确预测，同时在机制识别方面具有高度特异性，其能力体现在其能在不同脑区的响应模式之间分离，同时在相同脑区响应模式间有强烈对齐。这证明了在神经工程目标的高模型脑预测性与神经科学目标的机理准确脑模型识别之间没有固有的权衡。使用IATC引导的变换，我们获得了新的证据，支持拓扑深度神经网络（TDANNs）作为视觉系统的模型。IATC使得模型与大脑的比较更加严谨，并为深学习模型的预测成功提供了新的背景和改进了先前模型与大脑比较方法的局限性。
### Conclusion
总体而言，IATC使模型与大脑的比较有了原理性的方法，它既阐明了先前关于大脑深学习模型预测成功的发现，又超越了之前的模型与大脑比较的方法。
## 554. `cs.LG` - 地理空间机器学习库 [PDF](https://arxiv.org/pdf/2510.02572), [HTML](https://arxiv.org/abs/2510.02572)
### Authors
Adam J. Stewart,Caleb Robinson,Arindam Banerjee
### Background
近年来，专用软件库的发展为机器学习的进步提供了支持，使工作流程更加简洁并提高了再现性。对于地理空间机器学习（GeoML），地球观测数据的可用性超过了处理其独特挑战（如空间分辨率、光谱特性、时间频率、数据覆盖范围、坐标系统和文件格式）的专用库的发展。这章综述了GeoML库的发展历程，分析了它们的核心功能和当前生态系统。还介绍了流行的GeoML库如TorchGeo、eo-learn和Raster Vision，详细说明了它们的架构、支持的数据类型和对ML框架的集成。此外，还讨论了数据预处理、空间-时间关联、基准测试和预训练模型使用的方法论。通过作物类型制图的实际应用案例，展示了这些工具的应用。
### Innovation
介绍了流行的GeoML库如TorchGeo、eo-learn和Raster Vision，详细说明了它们的架构、支持的数据类型和对ML框架的集成。讨论了数据预处理、空间-时间关联、基准测试和预训练模型使用的方法论。通过一个作物类型制图的案例，展示了这些工具的实际应用。突出了软件设计的最佳实践、许可证和测试，以及开源地理空间软件中的开放挑战和未来方向，尤其是基金会模型的兴起和治理的需求
### Conclusion
旨在引导从业者、开发者和研究人员导航并贡献于快速发展的GeoML领域，强调了专用库的重要性，指出了开源地理空间软件中的开放挑战和未来方向，特别是在治理体系和基金会模型的应用等方面的需要。
## 555. `cs.LG` - MINERVA：用于监督特征选择的互信息神经估计算法 [PDF](https://arxiv.org/pdf/2510.02610), [HTML](https://arxiv.org/abs/2510.02610)
### Authors
Taurai Muvunzaa,Egor Kraev,Pere Planell-Morell,Alexander Y. Shestopaloff
### Background
现有的特征过滤器依赖于统计的成对依赖度量来建模特征和目标之间的关系，但在目标依赖于特征的高阶交互而不是个体贡献时，这种方法可能失效。该论文介绍了一种基于神经估计特征和目标之间互信息的新颖的监督特征选择方法——互信息神经估计算法（MINERVA）。
### Innovation
参数化互信息的近似值，使用神经网络，并通过精心设计的附加稀疏性诱导正则化因子的损失函数进行特征选择。方法分为两个阶段进行，以分离表示学习和特征选择，从而更好地泛化和更准确地表达特征的重要性。此外，通过评估特征子集组合来有效捕捉文献中罕见的普遍依赖结构，显示了其捕捉复杂特征-目标关系的能力。
### Conclusion
在合成和实际欺诈数据集上的实验证明了该方法的有效性及其进行精确解的能力。
## 556. `cs.LG` - 使用在线网络，提高效率与稳定性：迈向快速且稳定的强化学习 [PDF](https://arxiv.org/pdf/2510.02590), [HTML](https://arxiv.org/abs/2510.02590)
### Authors
Ahmed Hendawy,Henrik Metternich,Théo Vincent,Mahdi Kallel,Jan Peters,Carlo D'Eramo
### Background
在深度强化学习中，目标网络被广泛用于估计价值函数。虽然有效，但目标网络作为稳定性的牺牲品导致了缓慢移动的目标，从而延缓了学习过程。相反，用在线网络作为自助目标虽然直观诱人，但众所周知会导致不稳定的学习。
### Innovation
引入了一种新颖的更新规则，通过计算目标网络和在线网络之间的最小估计来确定目标，提出了名为MINTO的新方法，以获得两者之长。这种方法通过减少使用在线网络进行自助时的潜在高估偏差，实现了更快且更稳定的值函数学习，并且可以无缝集成到各种基于价值和演员-评论家算法中，几乎没有成本增加。
### Conclusion
MINTO在多种基准测试中表现出色，涵盖在线和离线RL，以及离散和连续动作空间，一致地提高了性能，展示了其广泛应用和有效性。
## 557. `cs.LG` - TabImpute: 使用预训练变换器实现准确快速的零样本缺失数据填补 [PDF](https://arxiv.org/pdf/2510.02625), [HTML](https://arxiv.org/abs/2510.02625)
### Authors
Jacob Feitelberg,Dwaipayan Saha,Kyuseong Choi,Zaid Ahmad,Anish Agarwal,Raaz Dwivedi
### Background
在表格设置中，缺失数据是一个普遍存在的问题。现有的解决方法从简单的平均法到复杂的生成对抗网络不等。然而，由于在实际领域间性能的巨大差异以及超参数调整的耗时性，没有默认的填补方法。在TabPFN的基础上，一种用于监督学习的最新表格基础模型，我们提出了TabImpute，这是一种预训练变换器，能够在不需要在推理时进行拟合或超参数调整的情况下，提供准确且快速的零样本填补。为了训练和评估TabImpute，我们引入了（i）适用于表格设置的项对项目特征化，使其与之前TabPFN填补方法相比的速度提高了100倍；（ii）一种包含现实缺失模式的合成训练数据生成管道；以及（iii）MissBench，这是一个全面的基准，评估填补方法，使用了OpenML的42个数据集和13种缺失模式，涵盖了医学、金融和工程等多个领域，展示了与11种现有填补方法相比，TabImpute的稳健性能。
### Innovation
提出了TabImpute，一种预训练的变压器模型，能够在推理时不需要拟合或调参的情况下进行准确、快速的零样本填补；引入了一种适用于表格设置的项对项目特征化方法，使得填补速度提升了100倍；开发了一种综合生成管道，结合了现实中的缺失模式，并且引入了MissBench基准，评估了42个OpenML数据集和13种缺失模式下的填补方法性能；MissBench涵盖多个领域，如医学、金融和工程，展示了TabImpute在面对这些数据领域时的稳健性能相比传统方法更优。
### Conclusion
总之，TabImpute提供了一种在不需要调参的情况下，通过预训练变换器实现快速、准确的缺失数据填补的新方法。这项研究通过新的特征化方法、数据生成管道和全面的基准测试，展示了其在各种实践领域的表现优于现有的填补方法。
## 558. `cs.LG` - 驱动式桥梁检测中检测车辆的最佳特性 [PDF](https://arxiv.org/pdf/2510.02658), [HTML](https://arxiv.org/abs/2510.02658)
### Authors
A. Calderon Hurtado,E. Atroshchenko,K.C. Chang,C.W. Kim,M. Makki Alamdari
### Background
过去十年，驱动式桥梁健康监测吸引了越来越多的关注。这种方法利用安装在检测车辆上的仪器记录的车辆-桥梁的响应来评估结构完整性并检测损伤。然而，车辆的机械和动态特性显著影响检测性能，限制了该方法的有效性。
### Innovation
本研究提出了一个优化检测车辆的框架，以提高检测灵敏度。研究采用无监督深度学习方法基于对抗自编码器（AAE）重构振动响应的频域表示。通过最小化健康与受损桥梁状态下损伤指数分布之间的Wasserstein距离，优化两轴车辆轮胎悬挂系统的质量和刚度。研究采用了Kriging元模型来高效近似目标函数并确定最优车辆配置。研究结果表明，相对桥梁第一自然频率比值在0.3到0.7之间的车辆最有效，而接近共振的车辆表现出色较差。轻型车辆需要较低的自然频率实现最佳检测。这是首次严格优化驱动式检测平台并提出专用检测车辆的研究。
### Conclusion
研究结果表明，相对桥梁第一自然频率比值在0.3到0.7之间的车辆最有效，而接近共振的车辆表现出色较差。轻型车辆需要较低的自然频率实现最佳检测。这项研究填补了优化驱动式检测平台的空白，提出了专用检测车辆的概念。
## 559. `cs.LG` - 一种用于无人机网络入侵检测的新型统一轻量级时空变换方法 [PDF](https://arxiv.org/pdf/2510.02711), [HTML](https://arxiv.org/abs/2510.02711)
### Authors
Tarun Kumar Biswas,Ashrafun Zannat,Waqas Ishtiaq,Md. Alamgir Hossain
### Background
无人机在商业、工业和民用领域的广泛应用带来了重大的网络安全挑战，尤其是由于无人机网络容易遭受广泛类型的网络攻击。现有的入侵检测机制在动态且资源受限的无人机环境中往往缺乏适应性、效率和泛化性。
### Innovation
本文提出了一种新型的轻量级和统一的时空变换器（TSLT-Net）入侵检测系统，专门针对无人机网络。该系统利用自我注意力机制有效地建模了网络流量中的时间模式和空间依赖性，实现了对不同入侵类型的准确检测。该框架包括一个简化预处理管道，支持在同一架构内进行多类别攻击分类和二元异常检测。
### Conclusion
在包含超过230万条标注记录的ISOT无人机异常检测数据集上的广泛实验表明，TSLT-Net在多类别检测方面的准确率为99.99%，在二元异常检测方面的准确率为100%，同时保持了仅0.04 MB的最小内存占用和9722个可训练参数。这些结果证明TSLT-Net是一种有效的可扩展的实时无人机网络安全解决方案，特别适于关键任务型无人机系统的边缘设备部署。
## 560. `cs.LG` - RAMAC：具有行为正则化的多模态风险感知离线强化学习 [PDF](https://arxiv.org/pdf/2510.02695), [HTML](https://arxiv.org/abs/2510.02695)
### Authors
Kai Fukazawa,Kunal Mundada,Iman Soltani
### Background
在安全性要求高的领域中，如果在线数据收集不可行，离线强化学习（RL）提供了值得考虑的替代方案，但前提是政策必须高收益而不会导致灾难性的低尾风险。先前关于风险规避的离线RL工作在实现安全性的同时牺牲了价值保守性和政策类别的限制，而且只有在非风险敏感设置中才使用表达性政策。因此，本文填补了这一空白，提出了Risk-Aware Multimodal Actor-Critic (RAMAC) 框架，结合了一个表达性强生成器演员和一个分布型评论员。RAMAC通过生成路径区分离合目标，进而实现复杂多模态场景下的风险敏感学习。
### Innovation
本文提出了RAMAC框架，结合了表达性强生成器演员和分布型评论员，通过生成路径区分离合目标，实现复杂多模态场景下的风险敏感学习。此外，通过实例化RAMAC，使用扩散和流匹配演员，观察到在Stochastic-D4RL任务中能保持强收益的同时，一致地提高了$text{CVaR}_{0.1}$。
### Conclusion
RAMAC通过结合强生成器演员和分布型评论员，实现了对复杂多模态场景的高效风险管理，能够在保持高收益的同时降低低尾风险，为风险规避的离线RL提供了一种新的解决方案。
## 561. `cs.LG` - Hyperparameter Loss Surfaces Are Simple Near their Optima [PDF](https://arxiv.org/pdf/2510.02721), [HTML](https://arxiv.org/abs/2510.02721)
### Authors
Nicholas Lourie,He He,Kyunghyun Cho
### Background
超参数极大地影响模型的能力，但现代模型过于庞大，无法进行广泛的搜索。因此，研究人员设计了基于对超参数理解的训练方法。尽管超参数的重要性不言而喻，但现有的工具很少能够理解超参数损失面。损失面结构复杂，但随着接近最优解，一种简单结构开始显现。
### Innovation
研究人员发现损失面在其最优解附近具有新的结构，并提出了新理论以生成此类工具。他们开发了一种基于随机搜索的新型技术来揭示这一渐近区域。在这一区域中，随机搜索的最佳得分展现出一个新的分布，其参数恰好定义了渐近区域损失面的特性。基于这些特性，他们推导出一种新的渐近定律来解释和外推随机搜索的收敛过程。这些新工具使得对可能的最佳性能和有效超参数数目的分析成为可能。
### Conclusion
新工具使我们能够进行一些新的分析，例如最佳性能的信心区间，或确定有效超参数的数量。作者已在如下网址提供了这些工具：this https URL.
## 562. `cs.LG` - CST-AFNet:一种基于双重注意力的深度学习框架，用于IoT网络入侵检测 [PDF](https://arxiv.org/pdf/2510.02717), [HTML](https://arxiv.org/abs/2510.02717)
### Authors
Waqas Ishtiaq,Ashrafun Zannat,A.H.M. Shahariar Parvez,Md. Alamgir Hossain,Muntasir Hasan Kanchan,Muhammad Masud Tarek
### Background
随着物联网（IoT）的迅速扩展，它已经通过实现智能自动化和实时连接彻底改变了现代产业。然而，这种演变也带来了复杂的网络安全挑战，因为这些环境具有异构性、资源受限性和分布性。为了应对这些挑战，本文提出了一种名为CST AFNet的新的基于双重注意力的深度学习框架，旨在物联网网络中实现稳健的入侵检测。
### Innovation
CST AFNet创新性地结合了多尺度卷积神经网络（CNNs）进行空间特征提取、双向门控循环单元（BiGRUs）捕捉时间依赖性和双重注意力机制（通道注意力和时间注意力），以增强对关键数据模式的关注。实验结果表明，CST AFNet在Edge IIoTset数据集上的训练和评估表现出色，实现了对15种攻击类型和良性流量的卓越准确性，同时在宏平均精度、召回率和F1分数方面均达到99.3%以上。研究表明，CST AFNet能够显著超越传统深度学习模型，为复杂IoT和IIoT环境中的实时网络安全威胁检测提供了一个有力且可扩展的解决方案。
### Conclusion
此研究证明，CST AFNet对复杂IoT和IIoT环境中的实时网络安全威胁检测提供了强大的解决方案，并为更安全、更智能、更适应的网络物理系统铺平了道路。
## 563. `cs.LG` - 拓扑不变性与学习崩解 [PDF](https://arxiv.org/pdf/2510.02670), [HTML](https://arxiv.org/abs/2510.02670)
### Authors
Yongyi Yang,Tomaso Poggio,Isaac Chuang,Liu Ziyin
### Background
本文探讨了应用梯度下降方法的神经网络在不同学习速率下，训练过程中的拓扑结构变化。研究表明，在特定的学习率下，训练过程会受到拓扑结构的强约束，而在其他条件下则允许拓扑结构的简化。结合最近关于边缘稳定现象的发现，可以将学习动态分为两个阶段：首先是拓扑约束下的平滑优化，然后进入通过剧烈的拓扑简化进行学习的阶段。这一研究克服了理论与架构依赖的问题，使得拓扑方法可以在深度学习的研究中无差别应用。
### Innovation
本文证明了一大类置换一致的学习规则（包括SGD和Adam等）在训练过程中会生成双Lipschitz映射，强约束神经元的拓扑结构。在小学习率下，训练会保持所有拓扑结构；而在大学习率下，则允许拓扑结构的简化，使神经网更加粗糙，从而降低模型的表达能力。该研究区分了小和大学习率下的显著差异，并结合了“边缘稳定现象”，推导出神经网络的学习动力学可以被分成两个阶段：首先是通过拓扑约束下的平滑优化，然后是通过剧烈的拓扑简化进行学习。其创新点在于理论方法的通用性，无需依赖特定的架构或损失函数。
### Conclusion
本文通过理论分析，揭示了小和大学习率下神经网络在训练过程中的不同行为，以及通过结合刚发现的“边缘稳定现象”进一步阐明了神经网络的学习动力学可以被分成两个阶段：首先是拓扑约束下的平滑优化，然后是剧烈的拓扑简化学习。这一研究的结论是，通过拓扑方法可以普遍应用于深度学习的研究中，无需依赖特定的架构或损失函数。
## 564. `cs.LG` - 数据驱动的动态能否揭示隐藏的物理规律？需要具有解释性的神经算子 [PDF](https://arxiv.org/pdf/2510.02683), [HTML](https://arxiv.org/abs/2510.02683)
### Authors
Wenhan Gao,Jian Luo,Fang Wan,Ruichen Xu,Xiang Liu,Haipeng Xing,Yi Liu
### Background
近年来，神经算子已经成为了在函数空间之间学习映射的强大工具，使数据驱动地模拟复杂的动力学成为可能。尽管它们在许多领域取得了成功，但它们的学习机制仍需更深入的理解。本文基于神经算子在空间域和功能域的学习方式进行分类，并在此基础上提出一些观点，重点关注遵循物理原理的数据驱动动力学的学习，旨在通过解释神经算子的预测过程和展示其从数据中学习隐藏的物理模式的能力来推动这一领域的发展，同时也指出解释方法的不足和双空间多尺度模型的潜力需要进一步研究。
### Innovation
本文对神经算子进行了分类，并基于此分类提出了多个观点。特别是，文中提供了一种解释神经算子预测过程的方法，并展示了其能够从数据中学习隐藏的物理模式的能力。同时，通过简单双空间多尺度模型的实例，验证了其优越性能，并指出双空间多尺度模型具有学习复杂物理现象的潜力，需要进一步探讨。此外，文中强调了建立基于已知物理规律的原则性框架的重要性，以提高神经算子的泛化能力和揭示更多的隐藏物理现象。
### Conclusion
本文通过分类神经算子和提出多个观点，展示了数据驱动动力学对揭示隐藏物理规律的重要性，同时也指出了解释方法的局限性及双空间多尺度模型的发展潜力。最后总结了在神经算子中整合已知物理规律的重要性，以提高其泛化能力和揭示更多隐藏的物理现象。
## 565. `cs.LG` - Hybrid-Collaborative Augmentation and Contrastive Sample Adaptive-Differential Awareness for Robust Attributed Graph Clustering [PDF](https://arxiv.org/pdf/2510.02731), [HTML](https://arxiv.org/abs/2510.02731)
### Authors
Tianxiang Zhao,Youqing Wang,Jinlu Wang,Jiapu Wang,Mingliang Cui,Junbin Gao,Jipeng Guo
### Background
由于其强大的自我监督表示学习和聚类能力，对比属性图聚类（CAGC）方法取得了巨大成功，这主要依赖有效的数据增强和对比目标设置。然而，大多数CAGC方法仅利用边作为辅助信息来获取节点级嵌入表示，并且仅关注节点级嵌入增强，忽视了边级嵌入增强以及节点级和边级嵌入增强之间的跨粒度交互。此外，它们往往将所有的对照样本对视为平等，忽略了硬和容易的正负样本对之间的显著差异，从而限制了其判别能力。
### Innovation
本文提出了一种新颖的稳健属性图聚类（RAGC），结合了混合协作增强（HCA）和对比样本自适应差异感知（CSADA）。首先，同时执行节点级和边级嵌入表示和增强，为后续对比学习建立更全面的相似度度量标准。其次，通过利用高度自信的伪标签信息，设计了一种自适应差异化策略，该策略能够在创新的权重调制函数的帮助下识别所有对比样本对并差异化对待。HCA和CSADA模块在一个有益的循环中互相强化，从而增强表示学习的可分辨性。
### Conclusion
在六种基准数据集上的全面图聚类评估表明，所提出的RAGC方法在对抗当前最先进的CAGC方法方面具有明显的效果。
## 566. `cs.LG` - EvoSpeak: 大型语言模型在可解释遗传编程演化启发式方法中的应用 [PDF](https://arxiv.org/pdf/2510.02686), [HTML](https://arxiv.org/abs/2510.02686)
### Authors
Meng Xu,Jiao Liu,Yew Soon Ong
### Background
遗传编程（GP）在演化复杂优化问题的树形结构启发式方面表现出强烈的有效性。但在动态和大规模场景中，最有效的启发式往往是高度复杂的，从而阻碍了启发式的可解释性，减慢了收敛速度，并限制了任务间的知识迁移。为了应对这些挑战，本研究提出了EvoSpeak框架，将遗传编程与大型语言模型（LLMs）结合起来，以提升启发式演化效率、透明度和适应性。EvoSpeak通过从高质量的GP启发式中学习、提取知识并利用这些知识，来（i）生成加速收敛的预热种群，（ii）将晦涩的GP树转换为简洁的自然语言解释以促进启发式的可解释性和信任感，（iii）在相关任务间实现知识迁移和偏好导向的启发式生成。
### Innovation
EvoSpeak框架通过将遗传编程与大型语言模型相结合来实现启发式演化的高效、透明和适应性提升。具体创新点包括（i）生成预热种群以加速收敛；（ii）将复杂的GP启发式转换为简洁的自然语言解释以增强可解释性；（iii）实现跨任务的知识迁移和偏好导向的启发式生成。研究通过在动态可调工作车间调度问题（DFJSS）中的大量实验验证了EvoSpeak的有效性，结果显示EvoSpeak生成了更有效的启发式、提升了进化效率，并提供了易于理解的报告以提高用户体验。
### Conclusion
EvoSpeak通过将遗传编程的符号推理能力和大型语言模型的可解释性和生成能力相结合，推进了智能、透明和用户友好的启发式方法发展，适用于实际优化问题。
## 567. `cs.LG` - 是否要进行压缩？利用指数集中性推进无损GenAI模型权重压缩的前沿 [PDF](https://arxiv.org/pdf/2510.02676), [HTML](https://arxiv.org/abs/2510.02676)
### Authors
Zeyu Yang,Tianyi Zhang,Jianwen Xie,Chuan Li,Zhaozhuo Xu,Anshumali Shrivastava
### Background
生成式人工智能（GenAI）模型参数量达到数十亿以上时，低精度计算成为高效部署不可或缺的技术。本文讨论了在保持无量化开销的条件下，低精度浮点格式是提供数值稳定性、节省内存和硬件效率的根本解决方案。研究发现，GenAI模型的权重在不同架构和模态中，指数部分表现出低熵一致性，这源于随机梯度下降引发的α-稳定分布。文章通过对熵的理论分析，建立了近似FP4.67的理论压缩限，这促使设计出实用的FP8格式。研究表明，基于此洞察提出的Exponent-Concentrated FP8（ECF8）框架，能够实现无损压缩并具有熵意识编码和GPU优化解码，实验证明在参数量从数十亿到671B的各种LLM和DiT上实现了高达26.9%内存节省和177.1%吞吐量加速，且计算完全无损，即模型输出无偏差。
### Innovation
提出了一种基于指数集中性的无损低精度浮点数压缩框架ECF8，该框架同时具有熵意识编码和GPU优化解码能力，实现了无损压缩，并在多项实验证明了显著的内存节省和加速效果。通过理论分析，提出了FP4.67的无损压缩理论限，为未来的低精度浮点数设计提供了新的指导原则。
### Conclusion
本文在理论上和实证上证明了GenAI模型中的指数集中的统计规律，并明确指出这一现象为无损低精度浮点数设计提供了基础，因此为FP8时代的生成式人工智能模型提供了全新的优化手段。
## 568. `cs.LG` - 深度时间序列预测的准确度定律 [PDF](https://arxiv.org/pdf/2510.02729), [HTML](https://arxiv.org/abs/2510.02729)
### Authors
Yuxuan Wang,Haixu Wu,Yuezhou Ma,Yuchen Fang,Ziyi Zhang,Yong Liu,Shiyu Wang,Zhou Ye,Yang Xiang,Jianmin Wang,Mingsheng Long
### Background
近年来，深度时间序列预测成为一个快速发展的研究方向。尽管这个领域的社区兴趣正在迅速增长，但研究人员有时对于研究方向难以取得实质性的进展感到困惑，因为改善标准基准的微小进展。研究指出，与图像识别相比，时间序列预测具有部分可观测和不确定的性质，因此结果存在不可避免的误差下限。这使得研究目标模糊，影响了研究进展。因此，有必要重新定义研究目标，寻找深度时间序列预测的性能上限。
### Innovation
本文指出基于窗口的特性可以更好地评估深度时间序列模型的预测性能，而非传统的时间序列相关性测试。通过超过2800个新训练模型的严格统计测试，发现深度模型的最小预测误差与窗口序列模式的复杂性之间存在显著的指数关系，这被称为准确度定律。研究表明，准确度定律可以帮助识别常见的饱和任务，从而为大时间序列模型提供有效的训练策略，并对未来研究提供有价值的见解。
### Conclusion
本文提出的准确度定律，不仅有助于识别已饱和的研究任务，还为大时间序列模型提供了有效的训练策略，为未来研究提供有价值的指导。
## 569. `cs.LG` - 通过中间分布塑形微调扩散模型 [PDF](https://arxiv.org/pdf/2510.02692), [HTML](https://arxiv.org/abs/2510.02692)
### Authors
Gautham Govind Anil,Shaan Ul Haque,Nithish Kannen,Dheeraj Nagaraj,Sanjay Shakkottai,Karthikeyan Shanmugam
### Background
扩散模型在多个领域中被广泛应用于生成任务。预训练的扩散模型可以有效捕捉训练数据的分布，但在某些情况下，使用奖励函数调整这些分布，以与下游应用对齐是很有必要的。虽然策略梯度方法如Proximal Policy Optimization (PPO)在自回归生成中广泛应用，但这些方法所需的边际似然对于扩散模型来说是不可计算的，因此一直有其他的替代方案和放松方法。本文在一个新的背景下统一了基于拒绝采样微调的不同版本，将其命名为GRAD，并表明该方法隐式执行具有重塑奖励的PPO。随后引入P-GRAFT以在中间噪声水平塑造分布，通过实验证明这可能会导致更有效的微调。通过偏置和方差权衡的方法，提出了逆噪声校正，以不利用显式奖励而改进流动模型。对文本到图像(T2I)生成、布局生成、分子生成和无条件图像生成进行实证评估。在将该框架应用于Stable Diffusion 2后，在流行的T2I基准测试中，相对于基线模型在VQAScore上改善了8.81%。对于无条件图像生成，逆噪声校正通过减少每张图像的FLOPs提高了生成图像的FID分数。
### Innovation
文中统一了不同版本的拒绝采样法全微调方法，并简化为GRAD，发现其隐式地执行具有重塑奖励的PPO。引入P-GRAFT用于中间噪声级分布的调整，并通过实验证明其有效性。提出了逆噪声校正技术，改进流动模型而不依赖显式奖励。通过对比实验展示了在T2I生成、布局生成、分子生成、无条件图像生成任务上的效果。特别地，应用于Stable Diffusion 2后，实验结果显示在VQAScore上取得了显著提升，且不依赖额外的FLOPs提升FID分数，具有更低的FLOPs成本。
### Conclusion
本文提出的方法通过中间噪声水平的分布塑形和逆噪声校正改进了扩散模型的数值结果。在多个生成任务上的实验证明了该框架的有效性，特别是在与传统的策略梯度方法竞争中表现出色。
## 570. `cs.LG` - 对基于ReLU的深层神经网络梯度下降分类泛化的最优率 [PDF](https://arxiv.org/pdf/2510.02779), [HTML](https://arxiv.org/abs/2510.02779)
### Authors
Yuanfan Li,Yunwen Lei,Zheng-Chu Guo,Yiming Ying
### Background
近年来，对梯度下降方法在深度神经网络中泛化性能的理解取得了显著进步。然而，一个自然且根本的问题是梯度下降能否达到在核设置中建立的最优泛化率。现有结果要么给出次优的$O(1/root{1/2}root{}{n})$速率，要么集中在具有平滑激活函数的网络上，这会导致深度L的指数依赖。
### Innovation
本文通过仔细权衡优化误差和泛化误差，为使用梯度下降训练的深度ReLU网络建立了最优泛化速率，实现了对深度的多项式依赖。在数据与边际$beta$可由神经网络内核追踪分离的假设下，证明了泛化风险率为$tilde{O}(L^4 (1 + beta L^2) / (n beta^2))$，这与最优支持向量机类型速率$tilde{O}(1 / (n beta^2))$在深度相关因素方面相一致。
### Conclusion
本研究的一个关键技术贡献是新颖地控制了靠近参考模型的激活模式，这对于基于梯度下降训练的深层ReLU网络提供了一个更尖锐的Rademacher复杂性界。
## 571. `cs.LG` - OptunaHub：一个黑盒优化平台 [PDF](https://arxiv.org/pdf/2510.02798), [HTML](https://arxiv.org/abs/2510.02798)
### Authors
Yoshihiko Ozaki,Shuhei Watanabe,Toshihiko Yanase
### Background
黑盒优化（BBO）在诸如AutoML和材料信息学等领域的进步推动了技术发展，但研究努力在这些领域之间分块分散。缺乏统一的平台导致社区难以共享和促进优化方法及其应用。
### Innovation
OptunaHub 提供了一个社区平台，集中了 BBO 方法和基准测试，提供了统一的 Python API、贡献者包注册表和网页界面，以促进可搜索性和跨域研究。其目标是促进贡献和应用的良性循环。
### Conclusion
OptunaHub 的源代码已在 GitHub（https://github.com/optuna）的 optunahub、optunahub-registry 和 optunahub-web 仓库中公开可用，允许社区成员访问和进一步开发。
## 572. `cs.LG` - 利用自我监督和分层深度学习融合多光谱和超光谱卫星数据进行有害藻华监测 [PDF](https://arxiv.org/pdf/2510.02763), [HTML](https://arxiv.org/abs/2510.02763)
### Authors
Nicholas LaHaye,Kelly M. Luis,Michelle M. Gierach
### Background
本文介绍了一种自监督机器学习框架，用于使用多传感器卫星数据检测和映射有害藻华（HAB）的严重程度和种类。该框架融合了海文（VIIRS）、MODIS、Sentinel-3和PACE号任务的反射数据以及TROPOMI太阳诱导荧光（SIF），生成HAB严重性和种类产品，无需使用每台设备的标签数据集。研究区域为墨西哥湾和南加州。研究表明，该方法与现场总浮游植物、Karenia brevis、Alexandrium spp. 和 Pseudo-nitzschia spp. 的测量数据高度一致，表明该技术能够在标注稀缺的环境中实现规模化的HAB监测，同时为分层嵌入式探索性分析提供支持，这是将自我监督学习应用于全球水生物地球化学中的关键步骤
### Innovation
该框架采用自监督表示学习和分层深度聚类技术，能够以无需标注数据集的方式生成有害藻华的严重性和种类产品。这种方法在标注稀缺的环境中具有显著优势，同时还能提供分层嵌入式的探索性分析，推动了自我监督学习在水生物地球化学中的应用
### Conclusion
本研究提出的方法在无标签数据集的情况下实现了有害藻华的监测，同时提供了分层嵌入式的探索性分析路径。这对于实现自我监督学习在水生物地球化学中的操作化具有重要意义，有助于更高效地进行全球范围内的有害藻华监测
## 573. `cs.LG` - TokenFlow：通过预抢占调度在请求突发情况下实现响应性的LLM文本流式服务 [PDF](https://arxiv.org/pdf/2510.02758), [HTML](https://arxiv.org/abs/2510.02758)
### Authors
Junyi Chen,Chuheng Du,Renyuan Liu,Shuochao Yao,Dingtian Yan,Jiang Liao,Shengzhong Liu,Fan Wu,Guihai Chen
### Background
实时的大语言模型（LLM）交互需要进行流式处理，即文本令牌逐个生成并实时发送给用户，同时需要在响应性和稳定生成之间找到平衡。传统LLM服务系统由于非抢占式请求调度和被动内存管理的僵化特性，在请求突发情况下导致资源配置效率低下和请求处理并行度低。为了改善这一情况，TokenFlow系统通过预抢占式请求调度和主动键值（KV）缓存管理，实现了更好的文本流式性能。
### Innovation
TokenFlow通过预抢占式请求调度，并结合主动管理缓存和后台数据传输优化等手段，在有效吞吐量和最短99%百分位时间到第一个令牌时间（P99 TTFT）上实现了显著提升，减少高达80.2%的预抢占开销，而不会降低整体令牌吞吐量。
### Conclusion
TokenFlow在LLAMA3-8B和Qwen2.5-32B多个GPU（RTX 4090，A6000，H200）上得到验证，实验证明该系统能够显著提升流式性能，提升达82.5%的有效吞吐量，并降低最坏情况下的P99 TTFT时间。
## 574. `cs.LG` - 模型消融下安全预训练的粒度研究 [PDF](https://arxiv.org/pdf/2510.02768), [HTML](https://arxiv.org/abs/2510.02768)
### Authors
Shashank Agnihotri,Jonas Jakubassa,Priyam Dey,Sachin Goyal,Bernt Schiele,Venkatesh Babu Radhakrishnan,Margret Keuper
### Background
研究发现，开源大模型在推理时可以简单地通过激活编辑进行修改，这引发了安全性方面的实际问题：如拒绝训练或元标签训练等常见安全干预措施在面对此类编辑时是否仍然有效？为此，研究者对SmolLM2-1.7B模型进行了模型消融实验，这是一种轻量级的投影技术，旨在移除对拒绝敏感的方向。研究者通过精细的时间检查点评估，并与广泛使用的开放基线进行对照实验，来探讨在模型消融下的安全预训练问题。最终，他们根据施加或移除拒绝敏感方向后的模型在处理有害和无害示例时的表现，进行评判，并分析了评判者选择对评估结果的影响，并提供了一种实用的评估协议，用于整合推理时的修改以进行安全性评估。
### Innovation
该研究通过模型消融实验探讨了安全预训练在面对推理时激活编辑的情况下是否依然有效。研究者还提供了一种实用的评估协议，用于整合推理时的修改以进行安全性评估。该研究使用了SmolLM2-1.7B模型和多个粒度的时间检查点，并与广泛使用的开放基线进行对照实验，旨在提供更细致的安全性评估结果。
### Conclusion
该研究得出，在模型消融下，某些数据为中心的安全组件仍然具有鲁棒性。评判者的选择对评估结果有显著影响。研究人员提供了一种实用的评估协议，并对如何将推理时的修改整合到安全性评估中给出了建议。
## 575. `cs.LG` - 时间序列中基于相关性感知阈值的在线置信带预测 [PDF](https://arxiv.org/pdf/2510.02809), [HTML](https://arxiv.org/abs/2510.02809)
### Authors
Théo Dupuy,Binbin Xu,Stéphane Perrey,Jacky Montmain,Abdelhak Imoussaten
### Background
近年来，不确定性量化在机器学习领域引起了广泛关注。具体来说，符合预测（CP）方法在这一领域获得了认可。特别是在时间序列分析中，随着数据分布随时间变化而发生变化，传统的批量方法不再适用，因此提出了在线符合预测（OCP）方法。OCP通过基于分布观察更新某个量（如覆盖率水平或分位数）的阈值来解决这一问题。评估OCP方法的主要方面通常包括覆盖率的有效性和预测区间宽度的最小化。
### Innovation
本文提出了一种增强的在线符合预测方法的阈值更新步骤。传统的二进制评估方法仅考虑预测区间的有效性，而不考虑其相关性。本文方法通过引入更广泛的功能类，基于真实值量化预测区间的相关性，从而防止阈值的突然变化，可能导致预测区间更窄。实验结果表明，这些方法可以产生比现有OCP方法更精确的区间，同时保持覆盖合法性。
### Conclusion
实验结果显示，这些方法能够产生更窄且更紧的预测区间，同时保持覆盖率的有效性。这种方法对于改善在线时间序列分析中的预测准确性和相关性具有重要的意义。
## 576. `cs.LG` - TutorBench：评估大型语言模型辅导能力的标准 [PDF](https://arxiv.org/pdf/2510.02663), [HTML](https://arxiv.org/abs/2510.02663)
### Authors
Rakshith S Srinivasa,Zora Che,Chen Bo Calvin Zhang,Diego Mares,Ernesto Hernandez,Jayeon Park,Dean Lee,Guillermo Mangialardi,Charmaine Ng,Ed-Yeremai Hernandez Cardona,Anisha Gunjal,Yunzhong He,Bing Liu,Chen Xing
### Background
随着学生越来越多地将大型语言模型（LLMs）用作学习辅助工具，构建能够处理辅导学习细微差别模型变得至关重要。这些模型需要识别学生的核心需求、保持适应性、提供个性化指导和准确度。
### Innovation
本研究引入了TutorBench，这是一个包括数据集和评估基准，用于严格评估LLMs的核心辅导技能。TutorBench由1,490个人类专家精挑细选的数据样本组成，关注于高中和AP水平的课程。这些样本是三个常见辅导任务的缩影：（i）根据学生的困惑生成适应性解释；（ii）提供对学生工作的可操作反馈；（iii）通过有效提示促进主动学习。TutorBench采用可靠的细粒度自动评估方法，使用LLM裁判和样本特定评分标准。
### Conclusion
研究结果显示，所有前沿的LLMs的得分均未超过56%，表明需要显著的改进空间。另外，研究发现LLMs在体现指引、诊断和有效支持学生的必要辅导技能方面的表现不佳，所有前沿模型在评分标准相关性为60%的这三个使用案例中均未能达标。不同模型族系表现不同：Claude模型在促进主动学习方面表现最佳，但在其他两个场景中表现较差。通过发布TutorBench，我们提供了一个全面且不饱和的基准，以引导下一代AI辅导员的发展。
## 577. `cs.LG` - 多尺度自回归模型是伪装下的拉普拉斯、离散和潜在扩散模型 [PDF](https://arxiv.org/pdf/2510.02826), [HTML](https://arxiv.org/abs/2510.02826)
### Authors
Steve Hong,Samuel Belkadi
### Background
本文重新审视了视觉自回归（VAR）模型，视角为迭代改进框架。传统的VAR模型被视作下一量级的自回归模型，而本文将其正式化为一种确定性前向过程，并构建拉普拉斯风格的潜在金字塔，配以学习反向过程进行金字塔重构。
### Innovation
本文将VAR模型重新定义为基于学习的潜在空间中的改良过程，并将预测任务视为代码索引的离散分类，同时根据空间频率对任务进行了划分。通过控制实验量化了这些设计因素对保真度和速度的贡献，并提出了该框架在置换不变图生成和概率性中期天气预报中的应用。
### Conclusion
该框架不仅揭示了VAR模型的本质，还提出了VAR如何利用扩散生态系统的工具，同时保持少量步骤和尺度并行生成的特点。
## 578. `cs.LG` - Curl Descent: 非梯度学习动力学中的符号多样可塑性 [PDF](https://arxiv.org/pdf/2510.02765), [HTML](https://arxiv.org/abs/2510.02765)
### Authors
Hugo Ninou,Jonathan Kadmon,N. Alex Cayco-Gajic
### Background
梯度基算法是人工神经网络训练的基本组成部分，但生物学神经网络在学习过程中是否使用类似的梯度基策略尚不清楚。虽然实验发现了多样性突触可塑性规则，但这些规则是否可以视为一种梯度下降的近似尚不明确。本文探讨了一个此前被忽略的可能性：即使不能用某个目标的梯度下降来描述，学习动力学也可能包含基本的“curl”成分，但仍能有效优化损失函数。Curl术语自然会在具有抑制性-兴奋性连接或Hebbian/anti-Hebbian可塑性的网络中出现，导致无法将学习动力学描述为任何目标的梯度下降。
### Innovation
研究发现，即使包含Curl术语（基本的“curl”动力学成分），神经网络仍能有效优化损失函数。引入非梯度动力学通过符号变化的可塑性神经元进行系统分析，证明了小的Curl术语能够保持原始解流形的稳定性。Curl术语的强度超过一定阈值时会破坏解流形，导致网络架构的结构特定性导致动力学的不稳定性从而产生混沌学习动态。这种Curl术语有时也能与梯度下降反直觉地加快学习过程，通过短暂上升损失来绕过鞍点。
### Conclusion
本文确定了几种特定架构，通过不同的学习规则支持稳健学习。这些结果为基于梯度的神经网络规范理论提供了重要的对立面。
## 579. `cs.LG` - 剖析变换器：绿色人工智能的一种CLEAR视角 [PDF](https://arxiv.org/pdf/2510.02810), [HTML](https://arxiv.org/abs/2510.02810)
### Authors
Hemang Jain,Shailender Goyal,Divyansh Pandey,Karthik Vaidhyanathan
### Background
大规模语言模型（LLMs）的迅速采用引发了重大的环境担忧。与单一的训练成本不同，LLM推理在全球范围内连续进行，现在已成为人工智能能耗的主要来源。然而，大多数可持续性研究只报告粗略的模型层面指标，这是因为缺乏细粒度的测量方法，他们将能效视为次要目标而非主要目标。
### Innovation
本文提出了第一个针对变换器架构核心组件进行细粒度推理能耗分析的研究方法——Component-Level Energy Assessment via Repeated sampling (CLEAR)。这种方法克服了微秒级组件执行时间和毫秒级能耗传感器监测时间不匹配的问题，通过CLEAR方法，对15个不同架构类型的模型进行了评估，确保了组件之间能耗变异率低于9.5%，并且捕捉到了超过90%的模型总计能耗。研究结果表明，注意力块每浮点操作的能耗显著更高，说明仅依靠FLOP不能准确反映组件级别的能耗成本。
### Conclusion
研究结果为各组件建立了详细的能耗基线，并提供了一种初始步骤来通过组件级别的优化建立能效更高的变换器模型。
## 580. `cs.LG` - FlexiQ：深度神经网络中延迟/准确率权衡的自适应混合精度量化 [PDF](https://arxiv.org/pdf/2510.02822), [HTML](https://arxiv.org/abs/2510.02822)
### Authors
Jaemin Kim,Hongjun Um,Sungkyun Kim,Yongjun Park,Jiwon Seo
### Background
神经网络通常在NPUs和GPUs等硬件加速器上执行，因为它们的规模和计算负载。这些加速器成本高昂，难以扩展资源以应对实时工作负载的波动。
### Innovation
提出了FlexiQ，一种自适应混合精度量化方案，专门适用于计算机视觉模型。该方案通过在具有小值范围的特征通道上选择性地应用低位宽计算，并采用高效的位降低方法来最小化量化误差，同时保持推理准确性。此外，FlexiQ能够实时调整其低位宽通道比率，使量化模型能够有效管理波动的推理工作负载。
### Conclusion
在我们自定义的NPU和GPU上实现了FlexiQ原型，包括混合精度推理运行时。在十一种卷积和变压器基的视觉模型上进行评估，FlexiQ在4位模型中通过微调平均实现了6.6%的更高准确性，并且在延迟/准确率权衡方面超过了四种最先进的量化技术。此外，我们的混合精度模型在保持40%加速的情况下只损失0.6%的准确性。在NPU和GPU上的延迟评估表明，FlexiQ引入了最小的运行时开销，证明了它的硬件效率和总体性能优势。
## 581. `cs.LG` - 知识导向的具有频率自适应学习的电池健康预测建模 [PDF](https://arxiv.org/pdf/2510.02839), [HTML](https://arxiv.org/abs/2510.02839)
### Authors
Vijay Babu Pamshetti,Wei Zhang,Sumei Sun,Jie Zhang,Yonggang Wen,Qingyu Yan
### Background
电池健康预测对于确保现代能源系统中的安全性、效率和可持续性至关重要。然而，准确和稳健的预测面临着具有非线性、噪声、容量再生等复杂特性的电池退化行为的挑战。现有的基于数据的模型能够捕捉到时间上的退化特征，但在缺乏知识引导的情况下，难以提供可靠的长期健康预测。
### Innovation
本文提出了Karma，一种知识导向的具有频率自适应学习的电池容量估计和剩余使用寿命预测模型。该模型通过信号分解，将电池信号分为不同频率带，在双流深度学习架构中，一个流捕捉长期低频退化趋势，另一个流建模高频短期动力学，并利用双指数函数基于经验研究来建模电池退化。通过粒子滤波优化知识参数，确保物理一致性和可靠的预测及不确定性量化。
### Conclusion
实验研究表明，Karma具有出色的表现，较现有算法电池健康预测平均误差减少50.6%和32.6%，证明其稳健性、普适性，并具有跨不同应用的更安全、更可靠电池管理的潜力。
## 582. `cs.LG` - 随机顺序模型下的在线学习 [PDF](https://arxiv.org/pdf/2510.02820), [HTML](https://arxiv.org/abs/2510.02820)
### Authors
Martino Bernasconi,Andrea Celli,Riccardo Colini-Baldeschi,Federico Fusco,Stefano Leonardi,Matteo Russo
### Background
在随机顺序模型中，损失序列由对手在开始前预定，并通过随机置换后展现给学习者。尽管在有限时间内随机顺序输入可能表现出显著的非平稳性，这会影响随机学习算法的性能，但算法对对手输入的自然维护其遗憾保证在随机顺序下仍然有效。较为简单的后悔无界算法在随机顺序实例中会失效。论文讨论了如何在不明显影响遗憾保证的前提下，将随机学习算法适应到随机顺序模型中，从而适用于预测具有延迟、带约束的在线学习和具有切换成本的上下文臂Bandits。最后，论文研究了在线分类，指出在随机顺序下，可学习性由VC维特性而非Littlestone维特性来描述，从而使随机顺序模型与一般对手模型进一步区分。
### Innovation
论文提出了一种适用于随机顺序模型的通用模板，以适应随机学习算法，并且不会显著影响其遗憾保证。这使预测具有延迟、带约束的在线学习和上下文臂以及具有切换成本的bandits任务的遗憾界得到改进。此外，论文还展示了在线分类在随机顺序下学习能力由VC维特性决定，而不是Littlestone维特性，进一步将随机顺序模型与一般对手模型进行区分。
### Conclusion
通过优化在线学习算法的适应性，改进了预测延迟、带约束学习和带切换成本上下文臂的遗憾界，并提出了随机顺序模型下的在线分类学会的新特性，通过VC维指标而非Littlestone维指标来描述可学习性。
## 583. `cs.LG` - RoiRL: 效率高且自我监督的离线迭代强化学习中的推理 [PDF](https://arxiv.org/pdf/2510.02892), [HTML](https://arxiv.org/abs/2510.02892)
### Authors
Aleksei Arzhantsev,Otmane Sakhi,Flavian Vasile
### Background
强化学习（RL）在提升大型语言模型（LLMs）的认知能力方面起着关键作用，但通常需要真实标签的奖励。Test-Time Reinforcement Learning (TTRL) 通过使用多数投票奖励来消除这一需求，但仍然依赖在线强化学习，导致高昂的计算成本。现有方法要么需要维护参考模型，要么训练不稳定，需要大量内存和计算资源。
### Innovation
提出了一种轻量级的离线学习方法RoiRL，用以解决上述问题。RoiRL 不需要维护参考模型，而是优化加权对数似然目标来稳定训练并显著降低内存和计算需求。实验结果表明，RoiRL 的训练速度比 TTRL 快 2.5 倍，且在推理基准测试中始终表现出更好的性能，为无需标签的自我改进 LLM 提供了可扩展的路径。
### Conclusion
RoiRL 提供了一种有效且稳定的方式，通过离线迭代强化学习实现 LLM 的自我改进，同时不需要真实标签。这种方法在实际应用中具有广阔前景，特别是在需要高效和低资源消耗的情况下。
## 584. `cs.LG` - Dale 与拉格朗日相遇：基于几何布朗运动的乘法去噪扩散模型 [PDF](https://arxiv.org/pdf/2510.02730), [HTML](https://arxiv.org/abs/2510.02730)
### Authors
Nishanth Shetty,Madhava Prasath,Chandra Sekhar Seelamantula
### Background
渐变下降已被证明是机器学习应用中优化的强大而有效的方法。然而，最近的神经科学进展表明，标准的渐变下降优化形式与生物系统中的学习机制不一致。这为创建生物启发的学习技术开辟了新的可能性。Dale定律，即学习过程中抑制性和兴奋性突触不会互换角色，启发了一种新的指数渐变下降优化方案，产生对数正态分布的突触权重。研究发现，几何布朗运动（GBM）对应的随机微分方程（SDE）的Fokker-Planck方程的密度为对数正态密度。利用这种关系，研究从GBM的SDE入手，通过反向时间SDE的离散化得到乘法更新规则，这与基于Dale定律的指数渐变下降更新规则惊人地吻合。此外，研究提出了一种新的乘法去噪评分匹配公式，涵盖了Hyvaerinen为非负数据提出的损失函数。对数正态分布的数据是正的，新型的评分匹配公式非常适合，这使得可以训练对数正态分布下的图像数据的产生模型，并获得基于对数正态分布导出的新乘法更新方案。实验结果表明，新方案具有生成能力。
### Innovation
通过将Dale定律与几何布朗运动联系起来，提出了一个新的基于乘法更新规则的去噪扩散模型。该模型利用了对数正态分布的特性和对数正态密度函数，提出了新的评分匹配公式，适应于对数正态分布数据。这为基于生物学习机制的生成模型提供了新的方法，特别是在处理对数正态分布的数据时表现出色。
### Conclusion
研究展示了基于Dale定律和几何布朗运动的去噪模型的有效性，提出了新的乘法更新和评分匹配方法，适用于对数正态数据并能够从图像数据中生成样本。这是首次将基于几何布朗运动的乘法更新用于生物启发的生成模型。
## 585. `cs.LG` - FeDABoost: 具有自适应增强的公平感知联邦学习 [PDF](https://arxiv.org/pdf/2510.02914), [HTML](https://arxiv.org/abs/2510.02914)
### Authors
Tharuka Kasthuri Arachchige,Veselka Boeva,Shahrooz Abghari
### Background
本文专注于通过增强模型聚合和提升表现较差的客户端训练来改善非IID场景下的联邦学习（FL）性能和公平性。联邦学习在非IID数据分布中效率低下，且各个客户端的表现差异较大，导致模型的泛化能力和公平性受到影响。
### Innovation
本文提出了一种新颖的FL框架——FeDABoost，该框架结合了动态增强机制和自适应梯度聚合策略。此外，FeDABoost通过调整焦点损失的重点参数来动态增强表现较弱的客户端，强调在本地训练中难以分类的例子。通过这种方式，客户端能够按照较低的本地错误率获得更高的权重，从而更可靠地为全局模型做出贡献。
### Conclusion
实验结果表明，FeDABoost在三个基准数据集MNIST、FEMNIST和CIFAR10上的表现和公平性均优于FedAvg和Ditto。
## 586. `cs.LG` - Subject-Adaptive Sparse Linear Models for Interpretable Personalized Health Prediction from Multimodal Lifelog Data [PDF](https://arxiv.org/pdf/2510.02835), [HTML](https://arxiv.org/abs/2510.02835)
### Authors
Dohyun Bu,Jisoo Han,Soohwa Kwon,Yulim So,Jong-Seok Lee
### Background
通过对多模态生命日志数据（如睡眠质量和压力等个性化健康结果）的预测，可以对临床和实践产生重要意义。然而，当前最先进的模型，主要是深度神经网络和梯度提升集成模型，牺牲了可解释性，并未能充分解决生命日志数据中存在的显著个体间差异。
### Innovation
我们提出了 Subject-Adaptive Sparse Linear (SASL) 框架，这是一种专门针对个性化健康预测的可解释建模方法。SASL 将普通最小二乘回归与个体特定交互结合，系统地区分全局效应和个体水平效应。我们使用嵌套 F 测试的迭代后向特征消除方法构建了一个稀疏且统计稳健的模型。此外，为了最大化顺序目标的宏平均 F1 分数，我们开发了一种回归后阈值化方法，还通过基于置信度的门控自适应地将紧凑型 LightGBM 模型的输出纳入 SASL 框架，以提高准确性而不牺牲可解释性。
### Conclusion
在包括约 450 个来自十名参与者的每日观察值的 CH-2025 数据集上的评估表明，SASL-LightGBM 框架在预测性能上与复杂的黑盒方法相当，但参数更少且透明度更高，从而为临床医生和实践者提供了清晰和可操作的见解。
## 587. `cs.LG` - State Space Models (SSMs) 训练期间压缩的有趣案例 [PDF](https://arxiv.org/pdf/2510.02823), [HTML](https://arxiv.org/abs/2510.02823)
### Authors
Makram Chahine,Philipp Nazari,Daniela Rus,T. Konstantin Rusch
### Background
状态空间模型（SSMs）被开发出来以高效处理长期序列建模任务，提供并行训练和快速推理。它们的核心是包含隐藏状态的递归动力系统，但更新成本随着状态维度的增加而增加。关键设计挑战是如何在提高表达能力和限制计算负担之间取得平衡。通过利用Hankel奇异值分析，控制理论为衡量每个状态的能量化提供了一个强有力的框架，并保证在较小表示中保留性能。利用Hankel矩阵的特征值稳定性质，这种分析在训练期间应用于SSMs，仅保留对系统影响大的维度。这种方法不仅适用于线性时不变SSMs如线性递归单元，还可扩展到选择性模型。实验结果表明，在训练过程中进行压缩可以显著加速优化过程同时保持表达性，压缩后的模型保留了直接在小维数训练所丢失的任务关键结构。因此，从大维开始并在训练期间减小的SSMs在保持更高性能的同时实现了计算效率和高效率。
### Innovation
提出了一种新的方法，在训练期对状态空间模型（SSMs）进行压缩，这种方法能显著加速优化过程同时保持表达性。通过Hankel奇异值分析和Hankel矩阵的特征值稳定性，仅保留对系统影响大的维度，并将其应用到线性时不变SSMs如线性递归单元，甚至扩展到选择性模型上。这种方法实现了计算效率与保持高性能的双重目标。
### Conclusion
通过在训练过程中进行压缩，SSMs不仅实现了计算效率，还可以保持或提升性能。这种方法适用于线性递归单元等SSMs，并且具有扩展性，可以应用于选择性模型。实验结果表明，这种方法在优化速度和保持任务关键结构方面取得了显著效果。
## 588. `cs.LG` - ContextFlow：从空间组学数据推断轨迹的认知流匹配方法 [PDF](https://arxiv.org/pdf/2510.02952), [HTML](https://arxiv.org/abs/2510.02952)
### Authors
Santanu Subhash Rathod,Francesco Ceccarelli,Sean B. Holden,Pietro Liò,Xiao Zhang,Jovan Tanevski
### Background
从纵向空间分辨率的组学数据中推断轨迹对于理解结构和功能组织随时间的变化至关重要，包括发育、再生、修复、疾病进展以及对治疗的响应。为了理解和建模这些复杂的空间和时间动态，研究人员需要一种可以整合领域知识的框架，从而指导结构组织动态的推断。
### Innovation
ContextFlow是一种新型的认知流匹配框架，它通过整合局部组织模式和配体-受体通讯模式，用一个转换可能性矩阵来约束最优传输目标。这种方法能够生成既统计上一致又具有生物学意义的轨迹，使ContextFlow成为从纵向空间组学数据建模时空动态的通用框架。
### Conclusion
在三个数据集上的评估结果表明，ContextFlow在推理准确性和生物学一致性等多个定量和定性指标上持续优于最先进的流动匹配方法。我们的代码可以在提供的链接中获取。
## 589. `cs.LG` - 使用ODE表示学习显式单细胞动力学 [PDF](https://arxiv.org/pdf/2510.02903), [HTML](https://arxiv.org/abs/2510.02903)
### Authors
Jan-Philipp von Bassewitz,Adeel Pervez,Marco Fumero,Matthew Robinson,Theofanis Karaletsos,Francesco Locatello
### Background
理解和治疗与细胞分化过程相关的疾病（如癌症）的关键在于建模细胞分化的动态过程。随着单细胞数据集的快速增长，机器学习在这一领域成为了特别有前景和活跃的研究方向。然而，当前最先进的模型依赖于计算昂贵的最优运输预处理和多阶段训练，并没有明确地发现基因间的相互作用。
### Innovation
提出了一种基于ODE的全新建模方法——Cell-Mechanistic Neural Networks (Cell-MNN)，这是一种端到端的编码-解码架构，其潜在表示是一个局部线性化的常微分方程，描述了从干细胞到组织细胞的动态演变过程。Cell-MNN可以完全端到端训练（除了标准的PCA预处理），它通过其ODE表示明确学习生物一致且可解释的基因交互作用。实验证明，Cell-MNN在单细胞基准测试中的性能表现出色，在处理大数据集和跨多个数据集的联合训练方面超过了现有最先进的基线方法，并且学习到了可验证的生物交互作用。
### Conclusion
实验证明，Cell-MNN实现了在单细胞基准上的竞争力，能够在大规模数据集和多数据集联合训练方面超越现有的最先进的基线模型，同时还学习到了可解释的、与TRRUST数据库中的基因交互作用一致的基因交互作用。
## 590. `cs.LG` - RAxSS: 由于检索增强的稀疏采样方法进行可解释的变长医学时间序列分类 [PDF](https://arxiv.org/pdf/2510.02936), [HTML](https://arxiv.org/abs/2510.02936)
### Authors
Aydin Javadov,Samir Garibov,Tobias Hoesli,Qiyang Sun,Florian von Wangenheim,Joseph Ollier,Björn W. Schuller
### Background
医学时间序列分析面临数据稀疏、噪声和记录长度变化大的挑战。先前的工作表明，随机稀疏采样可以有效处理变长信号，而检索增强的方法可以提高可解释性和对噪声和弱时间相关性的鲁棒性。在这一研究中，研究者们将随机稀疏采样的框架推广用于检索驱动的分类，这种方法利用了频道内的相似性加权窗口预测，并在概率空间中进行聚合，从而得出凸的时间序列级评分并提供明确的证据 trail，增强了可解释性。该方法在四个医疗机构收集的 iEEG 记录中进行评估，显示了其在可靠性和可解释性方面进行变长医学时间序列分类的潜力。
### Innovation
研究提出了一种新的方法，即 RAxSS（Retrieval-Augmented Sparse Sampling），它结合了随机稀疏采样和检索增强的特性，通过在概率空间中加权和聚合窗口预测，实现了一系列的时间序列级评分和可解释的证据追溯，从而提高了变长医学时间序列的分类性能和临床解释的透明度。
### Conclusion
该研究方法在四个医疗中心收集的 iEEG 记录上取得了与当前方法竞争的分类性能，并为临床医生提供了更高的透明度和解释性。研究表明，这种基于检索的稀疏采样方法在变长医学时间序列分类中具有可靠性和可解释性的潜力。
## 591. `cs.LG` - Ergodic Risk Measures: Towards a Risk-Aware Foundation for Continual Reinforcement Learning [PDF](https://arxiv.org/pdf/2510.02945), [HTML](https://arxiv.org/abs/2510.02945)
### Authors
Juan Sebastian Rojas,Chi-Guhn Lee
### Background
持续强化学习（continual RL）旨在形式化强化学习中的终身学习和持续适应的概念。目前，大多数持续强化学习工作主要通过无风险（风险中性）决策来探索，即行动者旨在优化长期预期性能。本文则旨在通过风险管理的角度研究持续强化学习，提出一种新的风险意识度量理论，以支持持续学习环境下的强化学习。
### Innovation
本文提出了对传统的风险度量理论进行扩展，引入了一类新的动态风险度量（ergodic risk measures）来兼容持续学习。这种新的度量方法通过优化基于奖励的长期性能（超越期望），提供了对风险管理在持续强化学习中的实际应用和理论基础。
### Conclusion
本文通过具体案例和实验结果，展示了动态风险度量在持续强化学习中的直观吸引力和理论一致性。这种新的方法论为构建更有效的风险管理框架奠定了基础，具有重要的理论和实践意义。
## 592. `cs.LG` - DMark：面向扩散大语言模型的顺序无关水印 [PDF](https://arxiv.org/pdf/2510.02902), [HTML](https://arxiv.org/abs/2510.02902)
### Authors
Linyu Wu,Linhao Zhong,Wenjie Qu,Yuexin Li,Yue Liu,Shengfang Zhai,Chunhua Shen,Jiaheng Zhang
### Background
扩散大语言模型（dLLMs）相比于自回归模型具有更快的生成速度并且保持相似的质量，但现有的水印方法因为它们的非顺序解码而失效。扩散模型可以任意顺序完成令牌生成，这破坏了传统水印基于的因果设计。目前，还没有专门为dLLMs设计的水印框架。
### Innovation
DMark是首个专为dLLMs设计的水印框架，引入了三种互补的方法来恢复水印检测能力:预测水印使用模型预测的令牌作为实际上下文不可用时的选择；双向水印利用扩散解码中独特的前后向依赖性；预测-双向水印结合以上两种方法以最大化检测强度。实验表明，DMark在保持文本质量的同时，检测率最高可达99.5%，而传统的简单适配方法只能达到49.6%到71.2%，并且DMark还展示了对文本操作的鲁棒性，证明了有效水印在非自回归语言模型中是可行的。
### Conclusion
DMark通过引入预测、双向和预测-双向水印策略在多种dLLMs上实现了92.0%到99.5%的高检测率，同时保持了文本质量，并且展现了对文本操作的鲁棒性，证实了非自回归语言模型中的有效水印是可行的。
## 593. `cs.LG` - 信心与分散性作为信号：无监督模型评估与排序 [PDF](https://arxiv.org/pdf/2510.02956), [HTML](https://arxiv.org/abs/2510.02956)
### Authors
Weijian Deng,Weijie Tu,Ibrahim Radwan,Mohammad Abu Alsheikh,Stephen Gould,Liang Zheng
### Background
在现实世界的应用中，评估模型在数据分布变化情况下的泛化能力至关重要，特别是在没有标记测试数据的情况下。此研究集中于两类无监督的模型评估场景：（1）评估固定模型在多个未标记测试集上的准确性；（2）对单一未标记测试集上的候选模型进行排名。
### Innovation
本文提出了一个统一且实际可行的框架，用于无监督模型的评估和排序，利用两种内在的模型预测属性——信心和分散性来评估泛化能力。研究系统地测试了基于信心、基于分散性和混合度量的各种指标，涵盖了不同模型架构、数据集和数据分布变化类型。研究结果表明，混合指标在数据集中心评估和模型中心评估中均优于单一维度的指标，特别是在真实世界数据集上的性能表现尤为突出。
### Conclusion
研究发现核范数可用于预测矩阵的鲁棒且准确的性能评估，即使面对中度类别不平衡也能保持可靠性。这为部署场景中的无监督模型评估提供了一种实用且可通用的方法。
## 594. `cs.LG` - 分布式的逆强化学习 [PDF](https://arxiv.org/pdf/2510.03013), [HTML](https://arxiv.org/abs/2510.03013)
### Authors
Feiyang Wu,Ye Zhao,Anqi Wu
### Background
逆强化学习（IRL）通常旨在从观察到的专家行为中学习奖励函数，以模仿专家的行为。然而，传统的IRL方法通常仅估计一个确定性的奖励函数或匹配期望回报，这限制了对专家行为复杂结构的理解。
### Innovation
该研究提出了一种分布式的逆强化学习框架，该框架同时建模了奖励函数的不确定性以及回报的完整概率分布。通过最小化一阶随机占优（FSD）违例，该方法将失真风险度量（DRMs）整合到策略学习中，从而恢复了奖励分布和分布感知的策略。
### Conclusion
该方法在合成基准、真实世界神经行为数据和MuJoCo控制任务上的实验结果表明，它能够恢复表达性奖励表示，并实现最先进的模仿性能，特别适合行为分析和风险感知模仿学习。
## 595. `cs.LG` - 通过分层不确定性集的分布鲁棒学习减轻虚假相关 [PDF](https://arxiv.org/pdf/2510.02818), [HTML](https://arxiv.org/abs/2510.02818)
### Authors
Sung Ho Jo,Seonghwi Kim,Minwoo Chae
### Background
传统的监督学习方法往往容易受到虚假相关的影响，尤其是在测试数据分布变化时。目前，为应对这一挑战，已经开发了多种方法，其中Group DRO是突出的例子。尽管这些方法在子人群或群体变化方面具有很高的鲁棒性，但对于在少数群体中常见的内部群体分布变化仍然容易受到影响。研究者们提出了一种基于Group DRO的分层扩展方法，旨在同时解决群体间的和群体内的不确定性，提供多级的分布变化鲁棒性。此外，本文还引入了新的基准设置，以模拟真实少数群体的分布变化，这是虚假相关研究中一个重要但尚未充分探讨的挑战。
### Innovation
本文提出了一种基于Group DRO的分层扩展方法，能够同时处理群体间的和群体内的不确定性，提供了多级别的分布变化鲁棒性。同时，研究者引入了新的基准设置来模拟实际少数群体的分布变化，这些分布变化在现实应用中是真实存在的挑战。
### Conclusion
实验结果表明，在面临传统鲁棒学习方法都在失败的情形下，该方法显示出了强大的鲁棒性。同时，在标准基准上也达到了更好的性能。这些结果突显了在捕捉群体内外部的不确定性方面扩大模糊集的重要性。
## 596. `cs.LG` - 不同隐私下的Wasserstein重心 [PDF](https://arxiv.org/pdf/2510.03021), [HTML](https://arxiv.org/abs/2510.03021)
### Authors
Anming Gu,Sasidhar Kunapuli,Mark Bun,Edward Chien,Kristjan Greenewald
### Background
Wasserstein 中心被定义为在最优传输度量下概率测度的均值，广泛应用于机器学习、统计学和计算机图形学。实际上，这些输入测度是由敏感数据集构建的样本分布，这促使了差分隐私（DP）处理方法的发展和应用。
### Innovation
本文提出了到目前为止第一个在差分隐私下计算Wasserstein重心的算法。实验结果显示，在合成数据、MNIST和大规模美国人口数据集上，该方法能提供高质量且隐私保护效果显著的Wasserstein重心，实现准确性和隐私性的折中。
### Conclusion
本文展示了一种新的差分隐私下的Wasserstein重心计算方法，并在多个数据集上验证了其有效性和适用性。
## 597. `cs.LG` - ZeroShotOpt：迈向高效的黑盒优化的零样本预训练模型 [PDF](https://arxiv.org/pdf/2510.03051), [HTML](https://arxiv.org/abs/2510.03051)
### Authors
Jamison Meindl,Yunsheng Tian,Tony Cui,Veronika Thost,Zhang-Wei Hong,Johannes Dürholt,Jie Chen,Wojciech Matusik,Mina Konaković Luković
### Background
全球优化昂贵的无导数黑盒函数时需要极高的样本效率。当前最先进的方法贝叶斯优化（BO）在性能上依赖于难以普遍适用的超参数，这导致了人工调参的问题。
### Innovation
提出了零样本预训练模型ZeroShotOpt，该模型适用于从2D到20D的连续黑盒优化任务。该模型通过在大规模优化轨迹上采用脱机强化学习对12种BO变体进行训练。通过生成具有多样景观的合成高斯过程函数，实现模型在未见过的基准上的鲁棒性零样本泛化，同时在样本效率方面不逊于领先的全局优化算法。
### Conclusion
ZeroShotOpt提供了可重复使用的基础，为未来的扩展和改进提供了可能性。该成果的开源代码、数据集和模型在此处提供：this https URL
## 598. `cs.LG` - 从不精确监督学习稳健的扩散模型 [PDF](https://arxiv.org/pdf/2510.03016), [HTML](https://arxiv.org/abs/2510.03016)
### Authors
Dong-Dong Wu,Jiacheng Cui,Wei Wang,Zhiqiang She,Masashi Sugiyama
### Background
近年来，条件扩散模型在生成任务中取得了显著成效，但它们的训练通常依赖于包含不精确条件输入信息的大规模数据集。这些监督信息常常源于噪声、模糊或不完整的标签，会导致条件不匹配，从而降低生成质量。
### Innovation
本文提出了一种统一框架DMIS，用于从不精确监督中训练稳健的扩散模型，这是扩散模型领域的首个系统研究。该框架通过对数似然最大化衍生而来，并将目标分解为生成和分类组件：生成组件模拟不精确标签分布，分类组件采用扩散分类器推测类后验概率，并通过优化时间步长采样策略进一步提高效率。
### Conclusion
通过在图像生成、弱监督学习和嘈杂数据集浓缩等多种形式的不精确监督任务中进行广泛实验，证明了DMIS能够持续产生高质量且具有类区分性的样本。
## 599. `cs.LG` - BrainIB++: 利用图神经网络和信息瓶颈在精神分裂症中发现功能性大脑生物标志物 [PDF](https://arxiv.org/pdf/2510.03004), [HTML](https://arxiv.org/abs/2510.03004)
### Authors
Tianzheng Hu,Qiang Li,Shu Liu,Vince D. Calhoun,Guido van Wingen,Shujian Yu
### Background
近年来，诊断模型在精神障碍领域的发展备受关注。基于静息态功能磁共振成像（rs-fMRI）的机器学习分类器已经被开发出来，用于识别能够区分精神障碍患者与健康对照的脑部生物标志物。然而，传统的基于机器学习的诊断模型通常依赖于繁复的手动特征工程，这引入了可能导致诊断不准确性的偏见。尽管深度学习模型本应能够无需人工干预，但其难以解释的特性使得所得的生物标志物难以支持可靠的诊断决策，从而限制了其临床应用。背景部分详细描述了这一领域的发展现状及存在的问题，强调了开发能够直接提取有意义生物标志物的解释性模型的必要性。
### Innovation
本文介绍了一种端到端的创新的图神经网络框架——BrainIB++，通过应用信息瓶颈（IB）原理，在模型训练过程中提取具有最大信息量的数据驱动脑区域作为子图以进行解释。该框架避免了手动特征工程带来的偏见，提高了解释性。通过在三个多组精神分裂症数据集上与九种已建立的大脑网络分类方法进行比较，BrainIB++展示了较好的诊断准确性和泛化能力，并且模型识别的子图与精神分裂症中的已知临床生物标志物相一致，尤其是在视觉、感觉运动和高层次认知功能网络中的异常方面。创新点在于提出了利用图神经网络和信息瓶颈相结合的方法来提高脑生物标志物的诊断性和解释性。
### Conclusion
BrainIB++模型在精神分裂症诊断生物标志物识别方面表现出了优越的性能和泛化能力，并且其模型提取的子图与精神分裂症的已知临床生物标志物一致，特别是针对视觉、感觉运动和高层次认知网络功能区的异常表现。这种一致性增强了模型的解释性，强调了其在实际诊断应用中的实际意义。结论部分进一步强调了该模型在实际临床研究和应用中的潜在价值和优势。
## 600. `cs.LG` - 具有迭代限制多体信息传递的E(3)对称贝叶斯原子间势 [PDF](https://arxiv.org/pdf/2510.03046), [HTML](https://arxiv.org/abs/2510.03046)
### Authors
Soohaeng Yoo Willow,Tae Hyeon Park,Gi Beom Sim,Sung Wook Moon,Seung Kyu Min,D. ChangMo Yang,Hyun Woo Kim,Juho Lee,Chang Woo Myung
### Background
机器学习势（MLP）在大规模原子级模拟中的应用日益重要，它们提供了从头算级别的精度并兼具计算效率。然而，现有的MLP在不确定性量化方面存在局限，这限制了它们在主动学习、校准和离域检测（OOD）中的可靠性。
### Innovation
本文通过开发具有迭代重新排列多体信息传递的E(3)对称贝叶斯MLP来解决这些挑战。引入了联合能量-力负对数似然损失函数（NLL$_text{JEF}$），该函数可以显式地对能量和原子间力的不确定性进行建模，并取得了优于传统NLL损失的准确度。通过系统地对多种贝叶斯方法进行基准测试，包括深度集合并均值方差估计、随机权重平均高斯、改进的在线牛顿变分方法以及拉普拉斯近似，评估他们在不确定性预测、OOD检测、校准和主动学习任务上的性能。
### Conclusion
我们的结果表明，贝叶斯MLP在保持最先进的模型准确性的同时，能够实现不确定性引导的主动学习、OOD检测和能量/力校准。这项工作建立了贝叶斯不变神经网络作为大规模原子级模拟中开发具有不确定性意识的MLP的强大框架。
## 601. `cs.LG` - Parameterized Action Actor-Critic Reinforcement Learning算法在Web搜索匹配计划生成中的比较分析 [PDF](https://arxiv.org/pdf/2510.03064), [HTML](https://arxiv.org/abs/2510.03064)
### Authors
Ubayd Bapoo,Clement N Nyirenda
### Background
本文探讨了在完全可观测环境中的高维决策任务中，Soft Actor Critic (SAC)、Greedy Actor Critic (GAC) 及 Truncated Quantile Critics (TQC) 算法的表现。研究重点在于参数化动作（PA）空间，省去了循环网络的需求，并使用基准 Platform-v0 和 Goal-v0 测试了离散动作与连续动作参数空间的关联。通过微软 NNI 进行超参数优化，确保了可复现性。实验结果表明，Parameterized Action Greedy Actor-Critic (PAGAC) 算法具有最快的学习时间和最高的回报，在基准测试中，成功在平台游戏中于41:24内完成5000个回合，在机器人足球目标游戏中于24:04内完成。PAGAC 的高效性和稳定性在复杂动作空间中尤为突出。与 PASAC 和 PATQC 相比，PAGAC 在快速收敛和稳健性能方面表现更优，适合作需快速收敛和稳健性能的任务。未来工作将研究混合策略，结合熵规整与截断方法以提高稳定性，并探索一般化研究。
### Innovation
引入了 Parameterized Action Greedy Actor-Critic (PAGAC) 算法，该算法在高维参数化动作空间中表现出卓越的性能，特别在学习效率、稳定性方面优于其他方法。特别地，PAGAC 的高效性和稳定性使其成为需要快速收敛和稳健性能的任务的理想选择。同时，该研究使用了 Microsoft NNI 进行超参数优化，以确保算法的可复现性。
### Conclusion
Parameterized Action Greedy Actor-Critic (PAGAC) 算法在复杂高维动作空间中的表现显著优于其他算法，特别在学习速度和稳定性方面。PAGAC 适用于需要快速收敛和稳健性能的任务，并可为未来研究提供一种结合熵规整与截断方法的混合策略，以进一步提高算法的稳定性和一般化性能。
## 602. `cs.LG` - CHORD: 自适应混合精度设备本地模型及其与设备-云协同下的序列推荐定制 [PDF](https://arxiv.org/pdf/2510.03038), [HTML](https://arxiv.org/abs/2510.03038)
### Authors
Tianqi Liu,Kairui Fu,Shengyu Zhang,Wenyan Fan,Zhaocheng Du,Jieming Zhu,Fan Wu,Fei Wu
### Background
随着移动设备技术的进步，直接将重排序模型部署在设备上已成为现实，这使得实时上下文推荐成为可能。然而，将模型从云端迁移到设备时，资源异质性不可避免地需要进行模型压缩。近年的量化方法虽然在设备上的高效部署展现了一定的潜力，但它们往往忽略了设备特定用户的兴趣，导致推荐准确性下降。虽然基于设备端的微调可以捕捉个性化用户偏好，但它通过局部重新训练带来的额外计算负担成为一个问题。CHORD框架正是为了解决这些问题提出的。
### Innovation
CHORD框架利用通道级混合精度量化来同时实现个性化和资源自适应部署。该框架在云上利用辅助超网络模块分散随机初始化模型并在异质设备上识别用户特定的关键参数。通过在设备端进行混合精度量化，CHORD能够实现动态模型适应并加速推理而无需反向传播，从而消除昂贵的重新训练周期。CHORD通过使用2位/通道来编码量化策略，从而最小化通信开销。实验结果表明CHORD具有较高的准确性和效率，并具备自适应性。
### Conclusion
CHORD框架通过混合精度量化策略实现设备本地的个性化推荐模型部署，并通过设备-云协同工作来增强其自适应性和资源利用效率。实验结果证明了CHORD的有效性和可行性，展示了其在实际应用中的潜力。
## 603. `cs.LG` - 基于序列GNNs的组合图对齐的提升学习方法 [PDF](https://arxiv.org/pdf/2510.03086), [HTML](https://arxiv.org/abs/2510.03086)
### Authors
Marc Lelarge
### Background
图神经网络（GNNs）在组合问题上难以超越传统优化方法，限制了它们的实用影响。本文通过引入一种用于图对齐问题的创新链式程序来解决这一差距，图对齐问题是一个基本的NP难任务，旨在通过仅使用结构信息寻找两个未标记图之间的最优节点对应关系。
### Innovation
本文方法训练一系列GNN，每个网络在迭代过程中不断细化由前一个网络生成的相似矩阵。在推理阶段，这种方法产生了一个自举效应：每个GNN通过集成前期迭代中关于节点对齐质量的离散排名信息来改进部分解决方案。此外，本文采用了一种强大的架构，直接处理节点对而不是单独的节点，捕获标准消息传递网络无法表示的全局结构模式，这对于对齐至关重要。
### Conclusion
在合成基准测试上进行的大量实验表明，与现有方法相比，我们的链式GNN在困难实例上实现了超过3倍的准确度改进，而且唯一解决了所有其他竞争方法都无法解决的规则图。当与传统优化作为后处理结合时，本文方法在图对齐基准测试中明显优于最先进的求解器。
## 604. `cs.LG` - 通过平衡有符号图算法展开的轻量级变压器在EEG分类中的应用 [PDF](https://arxiv.org/pdf/2510.03027), [HTML](https://arxiv.org/abs/2510.03027)
### Authors
Junyi Yao,Parham Eftekhar,Gene Cheung,Xujin Chris Liu,Yao Wang,Wei Hu
### Background
脑信号样本由EEG传感器采集，具有固有的反相关性，可以通过有限图中的负边来建模。利用这些信号来区分癫痫患者和健康受试者的挑战在于设计轻量级且可解释的神经网络，这些网络能够有效处理这些信号。传统的方法可能需要庞大的模型和大量的参数。因此，需要一种创新的方法来解决这个问题，通过平衡有符号图算法的展开来构建这样的神经网络，从而提高分类性能并减少参数量，同时保持解释性。
### Innovation
本研究创新性地提出了结合平衡有符号图算法展开的轻量级变压器模型，用于EEG信号分类。该方法通过展开谱降噪算法在平衡有符号图上处理信号，以解决癫痫患者和健康受试者的分类问题。这种方法使用了理想低通滤波器和兰克兹近似，从数据中学习最优截止频率，同时通过比较两个平衡有符号图去噪器在训练期间学习到的两个不同信号类别的后验概率来评估它们的重建误差。实验表明，该方法的分类性能与代表性的深度学习方案相当，但参数量显著减少，使得模型更易于解释。
### Conclusion
文章展示了通过平衡有符号图算法展开的轻量级变压器模型在EEG信号分类中的应用，证明了该模型在保持分类性能的同时，大幅减少了所需参数数量并保持了模型的解释性。这种方法为EEG信号处理和癫痫诊断提供了新的视角。
## 605. `cs.LG` - 一种用于近似旅行商问题的统一深度强化学习方法 [PDF](https://arxiv.org/pdf/2510.03065), [HTML](https://arxiv.org/abs/2510.03065)
### Authors
Mingfeng Fan,Jiaqi Cheng,Yaoxin Wu,Yifeng Zhang,Yibin Yang,Guohua Wu,Guillaume Sartoretti
### Background
近年来，深度强化学习（DRL）被广泛应用解决NP难的旅行商问题（TSP）。然而，较少有人关注近似旅行商问题（CETSP），主要因为其基于邻域的访问标准造成的挑战。CETSP中，节点被认为被访问，如果代理进入其周围的紧凑邻域内。因此，虽然DRL为解决标准TSP带来了成功，但CETSP的特殊性限制了其应用。
### Innovation
本文提出了一个统一的深度强化学习框架（UD3RL），用于解决CETSP。该框架通过调用一种分层决策过程（MDP）模型，采用一种离散化方案。UD3RL将决策过程分为节点选择和路径点确定两个子任务，分别由适应性编码器、节点解码器和位置解码器处理。作者还引入了一个k-最近邻子图交互策略，以增强空间推理。此外，定制的REINFORCE算法用于训练UD3RL模型，使其能够跨大小不同的问题和不同类型的邻域半径（固定或随机半径）进行泛化。
### Conclusion
实验结果显示，UD3RL在解决方案质量和运行时间方面优于传统方法。UD3RL不仅在问题规模、空间分布和邻域半径范围上表现出强大的泛化能力，而且在动态环境中也表现出很好的稳健性。
## 606. `cs.LG` - AdaBet：无需梯度的层选择方法以提高深度神经网络训练效率 [PDF](https://arxiv.org/pdf/2510.03101), [HTML](https://arxiv.org/abs/2510.03101)
### Authors
Irene Tenison,Soumyajit Chatterjee,Fahim Kawsar,Mohammad Malekzadeh
### Background
在边缘和移动设备上利用预训练神经网络时，需要在有限的计算和内存资源下，高效地适应用户特定的运行时数据分布。设备上使用目标数据集进行重训练可以实现这样的适应，但由于现代神经网络的深度增加以及梯度优化过程中所有层的计算开销，这变得不切实际。当前方法通过选择部分层进行重训练来降低训练成本，但由于依赖标记数据、整个模型的反向传播或服务器端的元训练，这限制了它们在受约束设备上的适用性。
### Innovation
AdaBet提出了一个无需梯度的层选择方法，通过分析激活空间的拓扑特征(Betti Numbers)和仅使用前向传递来评估层的重要性，并选择具有高学习能力、对重训练和适应重要的层，而无需标签或梯度。在16对基准模型和数据集上评估AdaBet，显示平均提高了5%的分类准确性，同时减少了40%的峰值内存消耗，相比于基于梯度的方法。
### Conclusion
AdaBet通过无需梯度的方法提高了深度神经网络在设备上的重训练效率，选择了关键层进行重新训练，显著提高了准确性并减少了内存使用，为资源受限的设备上的深度学习模型定制提供了新的解决方案。
## 607. `cs.LG` - 城市铁路系统中的实时车次间隔预测及其对服务控制的影响：一种深度学习方法 [PDF](https://arxiv.org/pdf/2510.03121), [HTML](https://arxiv.org/abs/2510.03121)
### Authors
Muhammad Usama,Haris Koutsopoulos
### Background
城市地铁系统中高效的实时调度对保障服务可靠性、最大化资源利用和提升乘客满意度至关重要。本研究提出了一个基于卷积长短期记忆网络（ConvLSTM）模型的新颖深度学习框架，用于预测整个地铁线路中列车头间距的复杂时空传播。该模型直接将计划中的终点头间距作为关键输入，结合历史头间距数据，能够准确预测未来的头间距动态，并有效捕捉其时间演变和所有车站的空间依赖性。这些能力使调度员能够评估各种终点头间距控制决策的影响，而无需依赖计算量大的模拟。
### Innovation
研究引入了一种灵活的方法来模拟不同的调度策略，包括保持均匀头间距和基于观察到的终点出发情况实现自定义模式的方法。该方法的优势在于它专注于前瞻性的运营控制，而非现有研究主要集中在乘客负载预测或非典型中断场景上。
### Conclusion
在大规模城市地铁线数据集上评估，提出的ConvLSTM模型展现了具有前景的头间距预测结果，提供了实时决策的实用见解。该框架为铁路运营商提供了一种强大的、计算高效的工具，以优化调度策略，从而大幅提高服务一致性和乘客满意度。
## 608. `cs.LG` - 蛋白质骨架生成的简化 [PDF](https://arxiv.org/pdf/2510.03095), [HTML](https://arxiv.org/abs/2510.03095)
### Authors
Liyang Xie,Haoran Zhang,Zhendong Wang,Wesley Tansey,Mingyuan Zhou
### Background
扩散-流动基生成模型在蛋白质主链生成任务中表现出强大的性能，为从头设计蛋白质提供了前所未有的能力。然而，这些模型在生成速度上受到限制，通常需要在逆向扩散过程中进行数百次迭代步骤。这一计算瓶颈限制了其在大型蛋白质发现中的实用性，需要成千上万到数百万的候选结构。
### Innovation
研究了分数蒸馏技术，该技术在视觉领域显示出显著成功，能大幅减少采样步骤的同时保持高质量的生成。通过广泛的实验，成功地将分数身份蒸馏（SiD）策略应用于训练多步骤的蛋白质骨架生成器，显著减少了推理时间，同时保持与预训练教师模型相似的性能。特别地，多步生成与推理时间噪声调节是成功的关键。演示了我们蒸馏的多步骤生成器在采样速度上实现了超过20倍的提高，同时在设计能力、多样性和新颖性方面与Proteina教师模型相当。这降低了推理成本，使大规模的体外蛋白质设计成为可能，从而将扩散模型带向真实的蛋白质工程应用中。
### Conclusion
这种减少推理成本的方法使大规模体外蛋白质设计成为可能，从而接近实际的蛋白质工程应用。
## 609. `cs.LG` - Signature-Informed Transformer for Asset Allocation [PDF](https://arxiv.org/pdf/2510.03129), [HTML](https://arxiv.org/abs/2510.03129)
### Authors
Yoontae Hwang,Stefan Zohren
### Background
稳健的资产配置是量化金融的关键挑战之一，其中深度学习预测器常常由于目标不匹配和误差放大而失效。研究中介绍了一种新型框架——Signature-Informed Transformer (SIT)，该框架通过直接优化风险感知的金融目标来学习端到端的分配策略。
### Innovation
SIT的核心创新包括路径签名，用于提供资产动态的丰富几何表示；以及路径签名增强的注意力机制，将金融归纳偏见（如领先滞后效应）嵌入模型。
### Conclusion
研究结果表明，资产组合感知的目标和几何感知的归纳偏见对于机器学习系统中的风险感知资本配置至关重要。特别是在每日S&P 100股票数据上的评估结果表明，SIT显著优于传统的和深度学习基线方法，特别是与预测-然后优化模型相比。
## 610. `cs.LG` - 图神经网络中的自适应节点特征选择 [PDF](https://arxiv.org/pdf/2510.03096), [HTML](https://arxiv.org/abs/2510.03096)
### Authors
Ali Azizpour,Madeline Navarro,Santiago Segarra
### Background
图神经网络（GNNs）依赖节点特征来进行预测，但某些特征可能对模型输出贡献不大，甚至可能是无用的。因此，确定哪些特征对模型性能真正有贡献是一个重要的问题。然而，图结构的数据引入了复杂的依赖关系，不适合传统的特征重要性度量方法。为此，本文提出了一种在训练过程中根据特征值替换后验证表现变化来确定相关特征的自适应节点特征选择方法，该方法既考虑了模型的适配性，也考虑了任务的广泛性。
### Innovation
本文引入了一种模型和任务通用的方法，该方法基于特征值替换后验证集性能的变化，在训练过程中动态地识别和选择相关的节点特征。这种方法不仅能够在训练结束后返回特征的重要性得分，还能够追踪特征逐个移除时其相关性的演变。因此，可以监测特征是否被有效地移除，还可以使用此技术评估其他指标。此外，实验结果验证了该方法在不同图结构下的灵活性及其在更具有挑战性的图学习环境中的适应性。
### Conclusion
本文提出的方法不仅为理解GNN决策提供了有价值的见解，减少节点特征维数，而且还能提升模型性能。通过实验证明，该方法能够适应不同的图结构，并在复杂的图学习场景中表现出良好的适应性。
## 611. `cs.LG` - 通过多叙述精炼和知识蒸馏提升XAI叙述 [PDF](https://arxiv.org/pdf/2510.03134), [HTML](https://arxiv.org/abs/2510.03134)
### Authors
Flavio Giorgi,Matteo Silvestri,Cesare Campagnano,Fabrizio Silvestri,Gabriele Tolomei
### Background
可解释的人工智能已成为研究的关键领域，旨在揭开深度学习模型决策过程的神秘面纱。尽管反事实解释被认为特别有前景，可以提供模型行为的洞见，但这些解释往往复杂且技术化，难以让非专家理解。这一问题促使研究人员探索新的方法来改善反事实解释的结果和表达能力，特别是在保留解释能力的同时，增强其可解释性和用户友好程度。
### Innovation
本文提出了一种新的管道，利用大小不同的语言模型来构建反事实解释的叙述。通过知识蒸馏技术和一个精炼机制，小语言模型能够重现大模型的表现，同时保持强大的推理能力。此外，作者还提出了一种简便有效的评估方法，用于审核自然语言叙述，确保模型的回复与事实和反事实的真相一致。
### Conclusion
这些改进不仅增强了学生模型的推理能力和实际性能，还使它们更加适用于实际应用场景，从而使反事实解释更加实用和易于理解。
## 612. `cs.LG` - 从高频传感器到午间报告：利用迁移学习进行海上主机功率预测 [PDF](https://arxiv.org/pdf/2510.03003), [HTML](https://arxiv.org/abs/2510.03003)
### Authors
Akriti Sharma,Dogan Altan,Dusica Marijan,Arnbjørn Maressa
### Background
随着全球海运业的发展，能源优化变得尤为重要，以降低成本并确保运营效率。主机功率是从发动机传输到主轴的机械功率，直接影响燃料消耗，因此准确预测主机功率对于优化船舶性能至关重要。主机功率的消耗与船速、主轴每分钟旋转次数以及气象和海况密切相关。频繁获取这些操作数据可以提高预测准确性，但收集高质量的传感器数据往往具有挑战性和成本高昂，因此需要寻找替代数据源。午后报告就是一个可行的替代选择。
### Innovation
本文提出了一种基于迁移学习的主机功率预测方法。最初，模型在高频数据（来自同一艘船）上进行训练，然后在低频率的每日午后报告（来自其他船只）上进行微调。实验表明，该方法在姐妹船（尺寸和配置相同）、类似船只（稍大且发动机不同）和不同船只（尺寸和配置不同）上，平均绝对百分比误差分别降低了10.6%、3.6%和5.3%，相较于仅使用午后报告数据训练的模型而言。
### Conclusion
通过迁移学习方法，结合高频数据和低频的午后报告数据，能够更准确地预测主机功率，从而有助于提高海运效率和降低成本。
## 613. `cs.LG` - Calibrated Uncertainty Sampling for Active Learning [PDF](https://arxiv.org/pdf/2510.03162), [HTML](https://arxiv.org/abs/2510.03162)
### Authors
Ha Manh Bui,Iliana Maifeld-Carucci,Anqi Liu
### Background
在基于池的主动学习中，常用的方法是通过模型的不确定性来查询样本。然而，未校准的不确定性模型会影响主动学习的效果，导致在未见过的数据上泛化性能差且校准误差高。深度神经网络进一步加剧了这一问题，因为它们通常产生未校准的不确定性估计。因此，本文探讨了如何通过估计未标记样本和未见测试数据的校准误差，结合使用具有最高校准误差的样本进行查询，以改进主动学习中的校准效果和泛化性能。
### Innovation
本文提出了一个新的获取函数（Acquisition Function），该函数不仅利用模型的不确定性，还估计校准误差，并优先查询具有最高校准误差的样本。通过使用核校准误差估计器在协变量变化情况下进行估计，本文证明了这种方法能够在未标记样本和未见测试数据上最终达到有界的校准误差。实验结果表明，与基线方法相比，该方法具有更优的校准和泛化误差。
### Conclusion
本文提出了一个新的获取函数，通过联合考虑不确定性模型的校准误差，改进了主动学习中的校准和泛化性能。实验结果表明，相对于其他基线方法，该方法能够有效降低校准误差和泛化误差。
## 614. `cs.LG` - 管控不完善的流程验证器：一个退避的采样视角 [PDF](https://arxiv.org/pdf/2510.03149), [HTML](https://arxiv.org/abs/2510.03149)
### Authors
Dhruv Rohatgi,Abhishek Shetty,Donya Saless,Yuchen Li,Ankur Moitra,Andrej Risteski,Dylan J. Foster
### Background
现有的测试算法能够将语言模型生成的强大能力与过程验证器结合，以评估部分生成的质量，提供了激发新的推理能力的潜力。但这些方法的算法设计空间和计算放大特性还不透明，而且考虑到学习高质量验证器的成本，其好处也远未明了。研究发现，学习到的验证器中的看似无害的错误可以导致标准解码技术在生成过程中由于错误放大的原因导致灾难性的失败。因此，研究探讨是否可以通过更复杂的解码策略来改进这一情况。
### Innovation
研究引入了一种新的过程引导的测试时采样算法VGB（Validation Guided Backtracking），通过基于理论的回溯，实现了对验证器错误有严格保证的更强鲁棒性。VGB 将自回归生成解释为一个随机走过部分生成树的随机游走，其中转移概率由过程验证器和基础模型引导；重要的是，回溯是概率性的。这一过程推广了理论上计算科学中相关文献提到的Sinclair-Jerrum随机游走方法，并强调了与这些文献的理论联系。
### Conclusion
通过实验证明，在合成和真实的语言建模任务中，VGB在各种指标上优于基线方法。研究结果表明VGB能够更好地应对验证器的错误，提高了生成过程的鲁棒性。
## 615. `cs.LG` - 众多零计算量专家的混合模型：高率量化理论视角 [PDF](https://arxiv.org/pdf/2510.03151), [HTML](https://arxiv.org/abs/2510.03151)
### Authors
Yehuda Dar
### Background
该论文利用经典高速率量化理论为回归任务中的混合专家模型提供新的见解。混合专家模型通过将输入空间分割成多个区域，每个区域有一专家充当零计算的常数预测器，以此来简化推理过程。研究基于高速率量化理论的假设，认为专家的数量足够大，使得其输入空间区域非常小，从而可以研究混合专家模型类的逼近误差。对于一维输入，论文提出了测试误差及其最小化分割和专家；对于多维输入，提出了测试误差的上界并研究了其最小化。此外，论文还讨论了在给定输入空间分割的情况下，从训练数据集学习专家参数的统计性质，从而理论和实证地展示了混合专家学习过程中逼近误差和估计误差之间的权衡如何依赖于专家数量。
### Innovation
论文的主要创新在于，它利用高速率量化理论对混合专家模型进行研究，特别是针对模型的逼近误差和统计学习性质进行了深入分析。另外，它理论和实证展示了混合专家模型中逼近误差和估计误差之间的权衡依赖于专家的数量。对于一维和多维输入，分别提出了测试误差的定量分析方法和上界，为混合专家模型的设计提供了理论基础。
### Conclusion
该研究透过多维输入场景下的误差分析及一维场景的定量分析，展示了混合专家模型在不同维度输入下的逼近性能，并通过对专家参数的统计学习性质的研究，理论和实证展示了混合专家模型逼近与估计误差之间的依赖关系。
## 616. `cs.LG` - FTTE: 资源受限设备上的联邦学习 [PDF](https://arxiv.org/pdf/2510.03165), [HTML](https://arxiv.org/abs/2510.03165)
### Authors
Irene Tenison,Anna Murphy,Charles Beauville,Lalana Kagal
### Background
联邦学习（FL）能够在保护数据隐私的同时跨分布式设备进行协作模型训练，但在资源受限的边缘节点上部署仍然具有挑战性，因为这些节点的内存、能源和通信带宽有限。传统的同步和异步联邦学习方法还受到启动延迟的影响，并且在网络异构和大规模时收敛速度慢。这些限制阻碍了FL在包括多达500个客户端和90%延迟客户端等多种模型和数据分布下的实际应用部署。
### Innovation
FTTE（联邦微训练引擎）是一种新颖的半异步联邦学习框架，它独特地应用了稀疏参数更新，并基于客户端更新的年龄和方差采用了延迟加权聚合。实验结果显示，FTTE在与同步联邦学习相比时，不但能实现81%的更快收敛性、80%更低的设备内存使用和69%的通信负载减少，而且在存在挑战性条件的情况下，其目标准确率也往往达到或超过半异步联邦学习的方法。这一研究成果标志着FTTE是首个用于异构且主要为资源受限边缘设备的实际联邦学习部署的实用且可扩展的解决方案
### Conclusion
FTTE作为一种半异步联邦学习框架，不仅展示了对资源受限设备上联邦学习的有效性和可行性，也为其实际应用提供了关键的技术支持和优化路径。通过实验证明了FTTE在资源限制和网络异构等复杂环境下的应用潜力，并为未来的联邦学习研究和应用提供了新的视角。
## 617. `cs.LG` - 为什么我们需要暖启？一种理论视角 [PDF](https://arxiv.org/pdf/2510.03164), [HTML](https://arxiv.org/abs/2510.03164)
### Authors
Foivos Alimisis,Rustem Islamov,Aurelien Lucchi
### Background
在现代深度学习中，学习率暖启已经成为一种普遍使用的技巧，但其理论基础仍然不够清晰。研究人员通过热启动开始训练时逐步增加学习率，但对其理论理解仍然不足。因此，该研究旨在提供一个详细的解释，说明为什么学习率暖启能够改善训练性能。研究基于$(L_0, L_1)$光滑性的推广条件，该条件用损失次优化表示局部曲率，并且具有良好的封闭性质。研究证明了这种条件在使用均方误差和交叉熵损失训练的常见神经架构下成立，并且在这一假设下，证明了带有暖启调度的梯度下降比固定步长更快地收敛，确定了上界和下界复杂度。通过在语言和视觉模型上的实验验证了理论见解，证实了暖启调度的实际益处。
### Innovation
该研究提出了一个关于$(L_0, L_1)$光滑性的推广条件，证明了这种条件在常见神经架构下的成立，并通过理论证明和实验验证了带有暖启调度的梯度下降比固定步长更快地收敛。
### Conclusion
研究表明，学习率暖启能够加速梯度下降的收敛速度，理论分析和实验结果都证实了这一点，提供了对学习率暖启效果的更深入理解。
## 618. `cs.LG` - 非平稳强化学习中的带有转移密度函数的上置信界 Q 学习 [PDF](https://arxiv.org/pdf/2510.03181), [HTML](https://arxiv.org/abs/2510.03181)
### Authors
Ha Manh Bui,Felix Parker,Kimia Ghobadi,Anqi Liu
### Background
本文研究了在转移概率变化下的非平稳强化学习问题，包括在有限期限和无限期限两种情形下的马尔科夫决策过程（MDPs）。有限期限情形下，转移函数可能在特定的时期突然变化。在无限期限情形下，这种变化则可能在任意的时间点发生。传统的 Q 学习中的上置信界（QUCB）算法虽然在学习过程中可以发现一个恰当的策略，但由于分布的变化，这个策略在变化后可能会利用到次优奖励。
### Innovation
本文提出了一个名为 Density-QUCB（DQUCB）的算法，该算法通过使用转移密度函数来检测分布的变化，并利用这个函数的似然性来提升 Q 学习中的不确定性估计质量，从而在探索和利用之间达到平衡。理论上，本文证明了我们的 DQUCB 算法在遗憾（regret）的表现上优于 QUCB。并且通过实验证明，DQUCB 在多种强化学习任务中表现出较低的遗憾，并在利用深度 Q 学习架构处理实际的 COVID-19 患者医院分配任务上也表现出色。
### Conclusion
因此，DQUCB 在处理分布变化条件下强化学习问题时提供了一个有效的方法，在实验中展示了比 QUCB 更低的遗憾值，同时保持了无模型强化学习的计算效率。
## 619. `cs.LG` - 使用惯性传感器和肌电图估计阻力训练RPE [PDF](https://arxiv.org/pdf/2510.03197), [HTML](https://arxiv.org/abs/2510.03197)
### Authors
James Thomas,Johan Wahlström
### Background
准确估计主观用力感知等级（RPE）可以提高有针对性反馈的阻力训练效果，并有助于预防受伤。本研究探讨了使用穿戴式惯性传感器和肌电图（EMG）传感器的数据来估算单臂哑铃二头肌弯举期间的RPE，并评估了机器学习模型的应用。
### Innovation
本研究利用了穿戴式惯性传感器和肌电图传感器的数据，并通过机器学习模型来估算RPE。随机森林分类器表现出最佳性能，并且尽管肌电图数据提高了模型的准确性，但由于数据质量和安装位置的限制，其实用价值有限。研究强调了退让重复时间作为最有力的RPE预测因子。
### Conclusion
本研究展示了使用穿戴式传感器进行RPE估计的可能性，并指出了提高模型适用性的关键挑战。
## 620. `cs.LG` - 神经表示中的超叠加拆解揭示隐藏的对齐 [PDF](https://arxiv.org/pdf/2510.03186), [HTML](https://arxiv.org/abs/2510.03186)
### Authors
André Longon,David Klindt,Meenakshi Khosla
### Background
超叠加假说认为单个神经元可能参与表示多个特征，以使神经元群体能够表示比其总数更多的特征。在神经科学和AI中，表示匹配度量用于衡量不同深度神经网络（DNNs）或大脑以何种程度代表相似信息。本研究探讨了一个关键问题：超叠加是否以任何不良方式与表示匹配度量互动？研究表明，当模型中的神经元具有不同特征的线性组合时，会导致预测映射度量（半匹配、软匹配、线性回归）的表现下降，即不同超叠加安排会相互干扰，导致不如预期的匹配结果。
### Innovation
本研究首先提出了一个关于严格排列度量如何依赖于超叠加安排的理论。通过训练稀疏自编码器（SAEs）在玩具模型中分离超叠加，展示了当模型的基本神经元被其稀疏超完备潜在代码替换时，对齐得分通常会增加。这些发现揭示了对于映射度量来说，超叠加拆解是必要的，用以揭示神经编码之间的真正匹配度。研究在视觉域还发现，DNN->DNN和DNN->脑的线性回归对齐也会在超叠加拆解后增加。
### Conclusion
研究结果表明，超叠加拆解对于揭示神经代码之间的真正表示匹配度是必要的。
## 621. `cs.LG` - 错误出在哪里？基于表示梯度跟踪归因不良的LLM行为 [PDF](https://arxiv.org/pdf/2510.02334), [HTML](https://arxiv.org/abs/2510.02334)
### Authors
Zhe Li,Wei Zhao,Yige Li,Jun Sun
### Background
大型语言模型（LLMs）展现了显著的能力，但其部署常因有害内容生成、事实不准确和社会偏见等问题受到阻碍。诊断这些失败的根本原因是对AI安全提出的重大挑战。现有的归因方法，尤其是基于参数梯度的方法，常常因为噪声信号大和计算复杂性高而不足。
### Innovation
本文介绍了一种新颖且高效的框架，通过分析表示及其梯度来诊断LLM的各种不良行为，直接在模型的激活空间中运作，提供与输出相关的训练数据的语义有意义信号。该方法系统评估了其在追踪有害内容、检测后门污染和识别知识污染等任务上的效果，证明其不仅在样本层次上表现出突出的归因能力，还可以进行精细的令牌层次分析，准确识别具体样本和短语对模型行为的影响。
### Conclusion
这项工作提供了一种强大的诊断工具，用于理解和审核并最终缓解LLMs的风险。相关代码可在以下链接找到：this https URL。
## 622. `cs.LG` - 如何利用专家知识还是决策？理解部分可观测强化学习中的算法权衡 [PDF](https://arxiv.org/pdf/2510.03207), [HTML](https://arxiv.org/abs/2510.03207)
### Authors
Yuda Song,Dhruv Rohatgi,Aarti Singh,J. Andrew Bagnell
### Background
部分可观测在强化学习中是一个顽固的挑战，因为它需要学习复杂的、依赖历史的策略。近期的实验证明，利用专家知识进行模型训练（如：利用模拟器中的潜在状态信息）可以简化任务，将“学习观察”与“执行行动”分离。然而，这种利用专家知识的方法虽然计算成本更低，但也存在已知的失败模式。
### Innovation
本文通过一个简单的、但有启迪意义的理论模型（扰动块MDP）和针对挑战性的模拟运动任务的控制实验，研究了专家知识利用与标准无专家信息强化学习之间的算法权衡。主要发现包括：(1)权衡依据理论预测，主要在于潜在动态的随机性；(2)最优的潜在策略不总是最好的策略来提炼。
### Conclusion
我们的结果提出了新的指南，关于如何有效利用专家信息，可能推动对许多实际部分观测域的策略学习的效率提升。
## 623. `cs.LG` - 最佳多数：Pass@$k$推断扩展的最小最大最优策略 [PDF](https://arxiv.org/pdf/2510.03199), [HTML](https://arxiv.org/abs/2510.03199)
### Authors
Qiwei Di,Kaixuan Ji,Xuheng Li,Heyang Zhao,Quanquan Gu
### Background
大型语言模型（LLM）推理通常会为提示生成一组候选答案，并通过诸如多数投票或Best-of-N（BoN）策略选择其中一个。对于复杂的任务，单次选择通常表现不佳。因此，评价通常会报告Pass@$k$：代理可以提交最多$k$个响应，仅计算后悔时使用最好的一个。这一背景下，研究了在更广泛的Pass@$k$推理框架下的推理扩展问题，证明了多数投票和BoN均未显示出$k$和采样预算$N$的理想扩展性。
### Innovation
结合了多数投票和BoN的优势，提出了新的推理策略——Best-of-Majority（BoM）。BoM的关键步骤是在选择前$N$个样本中的高频响应候选者，然后从中选择前$k$个奖励最高的答案。证明了当采样预算$N=tildetheta(C^*)$时，BoM的后悔是$O(frac{tildetheta(frac{C^*}{k}) + text{奖励模型估计误差}^2}{text{最优奖励估计误差}})$。进一步建立了匹配的下界，证明了该算法的最小最大最优性。此外，BoM具有一个关键优势：与多数投票和BoN不同，性能不会随着$N$的增加而下降。实验结果显示，在解决数学问题时，BoM优于多数投票和BoN。
### Conclusion
研究证明了在Pass@$k$推理框架下，BoM是最小最大最优的策略，实验结果也验证了其在数学问题推理中的优越性能。
## 624. `cs.LG` - EEFSUVA: 一个新的数学奥林匹克竞赛基准 [PDF](https://arxiv.org/pdf/2510.01227), [HTML](https://arxiv.org/abs/2510.01227)
### Authors
Nicole N Khatibi,Daniil A. Radamovich,Michael P. Brenner
### Background
近年来，大型语言模型（LLMs）在数学基准上的表现引起了关注，有人认为它们已经达到了奥林匹克和大学毕业水平的数学能力。然而，当前的基准可能因为潜在的数据污染和过于聚焦传统问题类型而高估了模型的推理能力。为了更全面地评估数学理解能力，研究人员引入了一个名为EEFSUVA的新基准，该基准来自东欧及前苏联地区的非广泛传播的区域和国家奥林匹克竞赛。这些比赛的问题与国际数学奥林匹克（IMO）相当困难，但问题类型较少出现在在线语料库中。初步结果显示，即使是最先进的LLM，在EEFSUVA上的表现不如其他形式的奥林匹克竞赛基准，这表明更广泛的数据集在评估数学推理能力中具有重要意义，并可能指导未来模型的发展路径。
### Innovation
引入了一个名为EEFSUVA的新基准，该基准来自东欧及前苏联地区的非广泛传播的区域和国家奥林匹克竞赛。这些比赛的问题与国际数学奥林匹克（IMO）相当困难，但问题类型较少出现在在线语料库中。这提供了一个机会来评估模型更全面和真实的数学推理能力。
### Conclusion
初步结果显示，即使是最先进的LLM，在EEFSUVA上的表现不如其他形式的奥林匹克竞赛基准，这表明更广泛的数据集在评估数学推理能力中具有重要意义，并可能指导未来模型的发展路径。
## 625. `cs.LG` - 低概率标记维持可验证奖励强化学习中的探索 [PDF](https://arxiv.org/pdf/2510.03222), [HTML](https://arxiv.org/abs/2510.03222)
### Authors
Guanhua Huang,Tingqiang Xu,Mingze Wang,Qi Yi,Xue Gong,Siheng Li,Ruibin Xiong,Kejiao Li,Yuhao Jiang,Bo Zhou
### Background
Reinforcement Learning with Verifiable Rewards (RLVR) 在复杂推理方面推动了大型语言模型的发展，但在训练过程中通常会遇到一个瓶颈——当策略熵减少导致探索下降时，性能出现停滞。传统方法倾向于保持高的策略熵，但对有意义的探索机制的研究仍然不足。研究表明，对熵的无选择关注可能会放大无关标记，导致训练不稳定。
### Innovation
本文分析了RLVR中的探索动态并识别出一个关键问题：逐步消除有价值的低概率探索标记，我们将其称为‘推理火花’。我们提出了一种新型正则化方法——低概率正则化（Lp-Reg），其核心机制是将策略正则化到一个启发式代理分布。该代理通过过滤掉假定的噪声标记并重新归一化剩余候选标记来构建。由此产生的代理是一个更少噪声的分布，其中‘推理火花’的概率被放大，然后作为一个软化正则化目标，通过KL散度防止这些有价值的标记被消除。实验表明，Lp-Reg使策略稳定训练约1000步，超越了基准熵控制方法。
### Conclusion
Lp-Reg实现了稳定的强化学习训练，通过维持探索避免了性能下降，从而在五个数学基准测试中达到了60.17%的平均准确率，比前方法提高了2.66%。
## 626. `cs.LG` - 使用大型语言模型增强知识图的塞内加尔法律文本结构化 [PDF](https://arxiv.org/pdf/2510.02353), [HTML](https://arxiv.org/abs/2510.02353)
### Authors
Oumar Kane,Mouhamad M. Allaya,Dame Samb,Mamadou Bousso
### Background
塞内加尔司法系统内法律文本获取和组织的困难，强调了改善司法信息访问的必要性。
### Innovation
成功提取了7,967篇法律文章，特别是在地土和公共事业法典方面的重点；开发了一个包含2,872个节点和10,774个关系的详细图形数据库，用于法律文本内关系的可视化；利用了高级三元组提取技术，展示了GPT-4o、GPT-4和Mistral-Large等模型在识别关系和相关元数据方面的有效性。
### Conclusion
通过这些技术，旨在为塞内加尔公民和法律专业人员创建一个坚实框架，使其更有效地理解和掌握其权利和责任。
## 627. `cs.LG` - WEE-Therapy：一种弱编码器混合框架用于心理咨询服务对话分析 [PDF](https://arxiv.org/pdf/2510.02320), [HTML](https://arxiv.org/abs/2510.02320)
### Authors
Yongqi Kang,Yong Zhao
### Background
当前，计算心理学的进步需要具备深刻理解咨询服务对话的AI工具。现有的基于语音的语言模型（AudioLLMs）通常依赖于在通用数据上预训练的强大单个语音编码器，难以捕捉特定领域的特征，如复杂的感情和专业技巧。因此，研究提出了WEE-Therapy，这是一种多任务的AudioLLM，结合了弱编码器集合（WEE）机制。这个模型通过一个强大的基础编码器与多个轻量级专业化编码器的集合补充，增加了灵活度和特定任务的专业性。这种方法采用了一种新颖的双重路由策略，结合了稳定且数据无关的知识，并根据数据选择动态的专家知识。实验结果显示，WEE-Therapy在情感识别、技术分类、风险检测和总结四项任务上均实现了显著的性能提升，同时参数量较少，展示了其在临床辅助分析中的强大潜力。
### Innovation
WEE-Therapy 提出了一种新的多任务AudioLLM架构，包含WEE机制。通过引入轻量级专业化编码器，系统地补充了强大的基础编码器。模型采用了一种新颖的双重路由策略，结合了稳定的数据无关知识和动态的数据相关专家选择。这种设计旨在增强系统的灵活性和特定领域的能力，同时实现性能的提升。实验结果表明，这种方法在多项任务上表现优异且参数量少，展示了强大的潜在应用价值。
### Conclusion
WEE-Therapy 通过结合弱编码器集合机制，实现了在语音对话分析中的多项任务性能显著提升，具有广泛的应用潜力，在情感识别、技术分类、风险检测和总结方面展现了优势。它提供了在临床分析中强大的辅助工具，特别是在处理复杂情感和专业技巧方面。
## 628. `cs.LG` - Can Prompts Rewind Time for LLMs? Evaluating the Effectiveness of Prompted Knowledge Cutoffs [PDF](https://arxiv.org/pdf/2510.02340), [HTML](https://arxiv.org/abs/2510.02340)
### Authors
Xin Gao,Ruiyi Zhang,Daniel Du,Saurabh Mahindre,Sai Ashish Somayajula,Pengtao Xie
### Background
大型语言模型（LLMs）在时间预测方面被广泛应用，但它们过度依赖预训练数据，可能造成预测结果的泛化能力被高估的问题。准确的预测可能只是反映了模型的记忆而不是推理能力。最近，关于基于提示的去学习技术出现了，引发了这样一个问题：能否通过提示使LLMs模拟出更早的知识截止点？
### Innovation
本文探讨了提示作为方法模拟LLMs早期知识截止点的能力。作者构建了三个评估数据集来衡量LLMs是否能够忘记（1）直接事实性知识，（2）语义变化，和（3）因果关联的知识。结果表明，虽然基于提示的知识截止点在直接查询相关信息时表现出有效性，但在被遗忘的内容未被直接询问而与查询有关时，提示很难引起遗忘。这些发现强调了在为时间预测任务应用LLMs时需要更为严格的评估环境。
### Conclusion
这些研究表明，基于提示模拟出的知识截止点在直接查询时有效，但在被遗忘内容不是直接询问而是与查询相关时效果不佳。因此，需要更加严格的评价设置来验证LLMs的泛化能力。完整的数据集和评估代码可以在指定网址找到。
## 629. `cs.LG` - Sparse大型多输入多输出信道中的一种编码解码网络用于波束成型 [PDF](https://arxiv.org/pdf/2510.02355), [HTML](https://arxiv.org/abs/2510.02355)
### Authors
Yubo Zhang,Jeremy Johnston,Xiaodong Wang
### Background
该研究背景是针对大规模稀疏MIMO信道中的下行波束成型问题，现有的波束成型方法在处理大规模天线系统时存在计算复杂度高、反馈机制复杂等问题。因此，需要开发一种新的端到端深度学习框架来优化波束成型技术。
### Innovation
该研究的创新点在于提出了一种端到端的深度编码解码网络（EDN）架构，该架构包含三个模块：(i) 在用户端部署的编码神经网络，用于压缩估计的下行链路信道至低维度的潜在向量；(ii) 在基站端的波束成型解码神经网络，将恢复的潜在向量映射至波束形成器；(iii) 在基站端的信道解码神经网络，从恢复的潜在向量中重建下行信道以进一步细化波束形成器。此外，EDN利用了半模化学习策略和知识蒸馏策略，以优化波束形成的训练过程。
### Conclusion
该研究通过广泛仿真实验验证了所提出的EDN波束成型框架的有效性，在不同网络和信道条件下均能表现出良好的性能，并拓展了该框架以适配远场和近场的混合波束成型场景。
## 630. `cs.LG` - 打破MoE大语言模型的三重困境：基于结构压缩的动态专家聚类 [PDF](https://arxiv.org/pdf/2510.02345), [HTML](https://arxiv.org/abs/2510.02345)
### Authors
Peijun Zhu,Ning Yang,Jiayu Wei,Jinghang Wu,Haijun Zhang
### Background
Mixture-of-Experts (MoE) 大语言模型（LLMs）面临负载不平衡、参数冗余和通信开销这三个问题。传统的MoE模型中，这些问题相互制约，影响了模型的性能和效率。现有的方法多是单独解决其中一个问题，而不是同时解决这三个问题。这篇论文提出了一个统一框架，基于动态专家聚类和结构化压缩来共同解决这些问题，从而提供了一个更为系统和高效的解决方案。
### Innovation
1. 引入了一种在线聚类程序，通过结合参数和激活相似度的融合度量周期性地重新分组专家，以稳定专家的利用情况。2. 利用了路由器的语义嵌入能力，在训练过程中动态重新配置模型的架构，实现显著的效率提升。3. 在每个簇内将专家权重分解为共享基矩阵和极低秩残差适配器，每组实现高达五倍的参数减少，同时保持专业性。4. 提出了一个两阶段的层次路由策略：将令牌首先分配给簇，然后分配给簇内的特定专家，极大地减少了路由搜索空间和全连接通信的体积。5. 引入异构精度方案，共享基存放在FP16，残差因子存放在INT4中，并动态卸载不活跃的簇，从而将峰值内存消耗降低到与密集模型相似的水平。6. 该框架在GLUE和WikiText-103上的效果与标准MoE模型相当，但参数减少约80%，吞吐量提高10%-20%，专家负载差异减少超过三倍。
### Conclusion
该研究证明了结构重组是实现可扩展、高效和内存高效的MoE LLMs的一种理性的方法。
## 631. `cs.LG` - PRISM-Physics：基于因果DAG的过程评价方法 [PDF](https://arxiv.org/pdf/2510.03185), [HTML](https://arxiv.org/abs/2510.03185)
### Authors
Wanjia Zhao,Qinwei Ma,Jingzhe Shi,Shirley Wu,Jiaqi Han,Yijia Xiao,Si-Yuan Chen,Xiao Luo,Ludwig Schmidt,James Zou
### Background
虽然竞赛风格的推理基准已经促进了数学和编程领域的评估进展，物理学方面的研究相对较少。现有的大多数物理基准只评估最终答案，忽略了推理过程。而最近的方法依赖启发式的人工智能作为评判者或线性假设，导致评分的不一致性和诊断的有效性受限。本文介绍了一种用于复杂物理推理问题的过程级评估框架和基准——PRISM-Physics。
### Innovation
该框架将解决方案表示为公式有向无环图(DAG)，显式地编码中间步骤之间的因果依赖关系，以实现细粒度、可解释和理论支持的评分。文章证明了DAG表示法的最优性和相应的评分策略。结合我们开发的完全基于规则的方法进行符号公式等效匹配，使得验证在不同表述形式中保持一致而不依赖于启发式判断。实验表明，该评估框架与人类专家的评分更加一致，在最先进的大模型上揭示了持续存在的物理推理问题，而步骤级评分提供了诊断见解和丰富的训练信号。
### Conclusion
通过结合结构严谨性、理论保证和符号验证，PRISM-Physics为过程级评估提供了原则性的基础，指导具有更深层次科学推理能力的模型的发展。
## 632. `cs.LG` - mini-vec2vec：使用线性变换扩展通用几何对齐的规模 [PDF](https://arxiv.org/pdf/2510.02348), [HTML](https://arxiv.org/abs/2510.02348)
### Authors
Guy Dar
### Background
vec2vec 是一种用于在无需平行数据的情况下对齐文本嵌入空间的程序。尽管 vec2vec 能找到近乎完美的对齐，但该过程既昂贵又不稳定。因此，急需一种更为高效且稳定的解决方案来替代它。
### Innovation
mini-vec2vec 提出了一种简单的、基于线性变换的方法，这种方法所需计算资源显著减少，同时具有极高的鲁棒性。此外，mini-vec2vec 的学习映射是一个线性变换。其方法分为三个主要阶段：初步的伪平行嵌入向量配对、变换拟合以及迭代优化。mini-vec2vec 在效率上比原来的 vec2vec 提高了数个数量级，同时在对齐结果上与 vec2vec 能够匹敌或超越。此外，该方法的稳定性以及可解释的算法步骤有助于扩大应用规模，并在新的领域和领域中开辟新的应用机会。
### Conclusion
mini-vec2vec 提出了一种新颖的、基于线性变换的方法，解决了 vec2vec 的高成本和不稳定性问题，同时保持了优秀的对齐性能，为文本嵌入空间的对齐提供了更为高效和稳定的选择。
## 633. `cs.LG` - 基于不确定性感知的答案选择以提高多LLM系统中的推理 [PDF](https://arxiv.org/pdf/2510.02377), [HTML](https://arxiv.org/abs/2510.02377)
### Authors
Aakriti Agrawal,Rohith Aralikatti,Anirudh Satheesh,Souradip Chakraborty,Amrit Singh Bedi,Furong Huang
### Background
大型语言模型（LLMs）已经展示了出色的性能，但在资源受限环境下，选择多个LLMs中最可靠的回答仍然是一个挑战。现有的方法通常依赖于昂贵的外部验证器、人工评估者或需要单个模型多次采样的自我一致性技术。虽然多LLM系统能够生成更多样化的响应，但它们通常在性能上不如单LLM的自我一致性方法。
### Innovation
本文提出了一种原理上合理、新颖且计算高效的多LLM系统最佳答案选择方法，该方法使用校准后的对数似然度得分来隐式利用这些模型的固有知识和信心。这种方法在GSM8K、MMLU和ARC等数据集中的辩论（多轮LLM讨论）和非辩论（多个LLM的最佳选择）设置中分别取得了约4%、3%和5%的改进。
### Conclusion
本研究提出的方法能够有效地从多个不同的LLM中选择最佳答案，通过使用校准后的对数似然度得分，有所改进，特别是在诸如GSM8K、MMLU和ARC等数据集中的多LLM系统中。
## 634. `cs.LG` - LLM-生成样本用于Android恶意软件检测 [PDF](https://arxiv.org/pdf/2510.02391), [HTML](https://arxiv.org/abs/2510.02391)
### Authors
Nik Rollinson,Nikolaos Polatidis
### Background
Android恶意软件通过混淆和多态性不断演变，这对基于签名的防御和训练在有限且不平衡数据集上的机器学习模型构成了挑战。虽然合成数据被提议作为一种缓解稀缺性的解决方案，但在生成有效用于检测任务的恶意软件数据方面，大型语言模型（LLMs）的作用尚未得到充分探索。
### Innovation
研究中，作者使用GPT-4.1-mini对三种恶意软件家族（BankBot、Locker/SLocker和Airpush/StopSMS）进行了微调，以生成结构化的记录，并通过任务指示工程和后处理解决了生成一致性问题。然后，在三种场景下评估了多个分类器：仅使用真实数据、使用真实数据与合成数据结合以及仅使用合成数据。结果显示，仅使用真实数据训练可实现近乎完美的检测率，而加入合成数据仅带来轻微性能下降。相比之下，仅使用合成数据训练的效果存在变异性。
### Conclusion
研究结果表明，LLM生成的恶意软件样本可以增强稀缺数据集而不牺牲检测准确性，但这些合成样本作为独立训练源的有效性仍然不够充分。
## 635. `cs.LG` - CRACQ：多维度的自动化文档评估方法 [PDF](https://arxiv.org/pdf/2510.02337), [HTML](https://arxiv.org/abs/2510.02337)
### Authors
Ishak Soltani,Francisco Belo,Bernardo Tavares
### Background
文章提出了CRACQ，这是一种多维度的评估框架，专门用于评估文档的五个特定特性：连贯性、严谨性、恰当性、完整性以及质量。该框架建立在基于特质的自动作文评分（AES）的启发之上，将评估范围从论文扩展到包括不同形式的机器生成文本，采用基于评分准则且可解释的方法进行评估。与单一评分方法不同，CRACQ将语言、语义和结构信号整合进一个累计评估中，使其既可从整体上又可以从特质上进行分析。该框架在500个合成申请书中进行训练，并与一个LLM-作为法官进行了基准测试，还针对强大的和弱化的实际应用场景进行了进一步测试。初步结果显示，CRACQ在生成稳定且可解释的特质水平评估上优于直接的LLM评估，但可靠性和领域范围的问题仍存挑战。
### Innovation
CRACQ框架将多维度的特质评估方法应用于机器生成的文本，通过整合语言、语义和结构信号来提供一种基于评分准则且可解释的方法，不同于直接单一分数评估，它能够进行综合性评估和特质层面的分析。此外，CRACQ已经在不同类型的实际应用中得到了检验，展现了在不同文本类型的评估中的潜力。
### Conclusion
CRACQ框架在合成申请书中进行了训练，并通过与LLM的比较测试表明，它在产生稳定而且可解释的特质评估结果上表现出色，但在可靠性和领域范围的适用性方面仍然存在挑战。
## 636. `cs.LG` - 线性RNN在自回归生成长时间音乐样本中的应用 [PDF](https://arxiv.org/pdf/2510.02401), [HTML](https://arxiv.org/abs/2510.02401)
### Authors
Konrad Szewczyk,Daniel Gallo Fernández,James Townsend
### Background
直接以自回归方式生成音频波形是一项具有挑战性的任务，这是因为原始序列的长度以及在多个时间尺度上的重要结构。传统的基于递归神经网络（RNN）、因果卷积和自我注意力的方法在这项任务上仅取得有限的成功。然而，近期的研究表明，深度状态空间模型，也被称作线性RNN，非常适合这种应用场景，表现出高效性。
### Innovation
本文通过应用线性RNN进行原始音频建模，研究了不同架构选择的影响，并引入并行上下文以使训练序列长度可达一分钟（1M个标记）。最终，提出了一种模型，名为HarmonicRNN，该模型在小型数据集上取得了状态最前沿的对数似然性和感知度度量的结果，明显提升了模型的效果。
### Conclusion
本文通过应用线性RNN，特别是在长时间序列的音频建模上取得了突破性进展，实现了在性能上的提升和创新，为该领域的进一步研究和应用提供了新的思路和技术支持。
## 637. `cs.LG` - 大气机器学习模型对均匀海表面温度增暖的平衡响应 [PDF](https://arxiv.org/pdf/2510.02415), [HTML](https://arxiv.org/abs/2510.02415)
### Authors
Bosong Zhang,Timothy M. Merlis
### Background
最近开发出了能够产生稳定多年全球气候模拟的机器学习（ML）模型，但是这些模型能否泛化到训练分布之外仍是一个开放性问题。在这项研究中，我们评估了几种最先进的ML模型（ACE2-ERA5、NeuralGCM和cBottle）在对均匀的海表面温度增暖响应。这些模型是在评估气候变化时使用的广泛认可的基准。我们对每种ML模型与基于物理的全球大气循环模型（GFDL的AM4）的性能进行了评估，涉及表面气温、降水、温度和风的剖面，以及大气顶的辐射等关键指标。
### Innovation
这项研究首次系统地评估了几种先进的机器学习模型对均匀海表面温度增暖的响应，尤其是与基于物理的全球大气循环模型进行对比，揭示了ML模型在气候应用中的潜力及其当前的局限性。
### Conclusion
虽然机器学习模型能够复制物理模型的重要响应，尤其是在降雨方面的响应，但它们也表现出一些与稳健物理响应相偏离的特征，比如辐射响应和陆地区域的增暖。因此，我们的结果强调了机器学习模型在气候变化应用中的前景及其当前的限制，并建议需要进一步改进以实现稳健的泛化性能。
## 638. `cs.LG` - 基于层次化记忆的预训练：分离长尾知识和常见知识 [PDF](https://arxiv.org/pdf/2510.02375), [HTML](https://arxiv.org/abs/2510.02375)
### Authors
Hadi Pouransari,David Grangier,C Thomas,Michael Kirchhof,Oncel Tuzel
### Background
现代语言模型的出色性能依赖于扩大参数规模，更大的模型能够存储更多的世界知识并进行更准确的推理。然而，将所有世界知识压缩到参数中既没有必要也不现实，因为仅用一部分参数来处理每个提示，对于计算资源有限的边缘设备尤其如此。现有研究表明，在预训练和推理中仅使用一小部分上下文相关的记忆块的Vernix架构能够显著提高性能，同时保持参数规模较小。因此，本文旨在通过引入层次化参数化的记忆库，以及与现有硬件架构相匹配的预训练策略，解决现有的稀疏参数瓶颈问题。
### Innovation
本文提出了一种新的预训练方法，即通过层次化记忆来进行预训练。具体来说，引入了小型语言模型来访问大规模层次化参数化记忆库，并在预训练和推理阶段动态地装载上下文相关的记忆块。这种方法通过学习将长尾世界的稀疏知识存储在记忆参数中，同时小型语言模型则捕获常见知识和普遍的推理能力。实验结果显示，在参数量不到2倍的传统模型的情况下，使用160M参数的小型模型搭配4.6B参数记忆库的一部分可以达到相当于传统模型的效果，证明了该方法的有效性。此外，通过各种实验，研究了变压器模型中超大规模参数化记忆的最佳类型和大小，并找到了适用于各种架构的层次化前馈记忆结构，无论是预训练期间加入还是事后应用。
### Conclusion
本文提出了基于层次化记忆的预训练方法，显著提高了小模型在边缘设备等有限计算资源环境中的表现。通过大量的实验验证，证明了该方法在不同变压器模型架构上的广泛适用性和有效性，从而为小模型在实际应用中的推广奠定了基础。
## 639. `cs.LG` - BrowserArena：在实际网络导航任务中评估LLM代理 [PDF](https://arxiv.org/pdf/2510.02418), [HTML](https://arxiv.org/abs/2510.02418)
### Authors
Sagnik Anupam,Davis Brown,Shuo Li,Eric Wong,Hamed Hassani,Osbert Bastani
### Background
当前的LLM代理能够在开放网络上浏览和执行操作，但现有的代理评估仍然局限于沙盒环境或人工任务。作者引入了BrowserArena，这是一个实时的开放网络代理评估平台，它收集用户提交的任务，进行Arena风格的一对一头对头比较，并通过逐步骤的人类反馈揭示失败模式。
### Innovation
建立了BrowserArena，一个活体的开放网络代理评价平台，能够收集用户提交的任务并进行Arena风格的对比，同时通过逐步骤的人类反馈识别失败模式。通过构建针对这些任务的专门数据集，揭示了不同语言模型处理这些失败模式的不同方式，如某些模型在验证码处理上的策略多样性及误导用户的情况。
### Conclusion
发现当前网络代理具有多样性和脆弱性，而BrowserArena的评估方法为大规模理解和评估网络代理的失败模式提供了一种新途径。
## 640. `cs.LG` - CWM: 具备世界建模能力的开放权重语言模型用于代码生成研究 [PDF](https://arxiv.org/pdf/2510.02387), [HTML](https://arxiv.org/abs/2510.02387)
### Authors
FAIR CodeGen team. Jade Copet,Quentin Carbonneaux,Gal Cohen,Jonas Gehring,Jacob Kahn,Jannik Kossen,Felix Kreuk,Emily McMilin,Michel Meyer,Yuxiang Wei,David Zhang,Kunhao Zheng,Jordi Armengol-Estapé,Pedram Bashiri,Maximilian Beck,Pierre Chambon,Abhishek Charnalia,Chris Cummins,Juliette Decugis,Zacharias V. Fisches,François Fleuret,Fabian Gloeckle,Alex Gu,Michael Hassid,Daniel Haziza,Badr Youbi Idrissi,Christian Keller,Rahul Kindi,Hugh Leather,Gallil Maimon,Aram Markosyan,Francisco Massa,Pierre-Emmanuel Mazaré,Vegard Mella,Naila Murray,Keyur Muzumdar,Peter O'Hearn,Matteo Pagliardini,Dmitrii Pedchenko,Tal Remez,Volker Seeker,Marco Selvi,Oren Sultan,Sida Wang,Luca Wehrstedt,Ori Yoran,Lingming Zhang,Taco Cohen,Yossi Adi,Gabriel Synnaeve
### Background
该研究旨在通过使用世界模型提高代码生成和理解能力。背景是在仅通过静态代码训练的情况下，对代码的理解存在局限性。研究团队在Python解释器和代理Docker环境中的观察-动作轨迹上继续训练了一个名为CWM的320亿参数的开放权重大型语言模型（LLM），并在可验证的编程、数学和多轮软件工程环境中进行全面的多任务推理强化学习（RL）。这为探索世界模型如何在计算环境中通过推理和规划提高代码生成提供了一个强大的测试平台。
### Innovation
创新点包括：1) 开发了一个大规模的世界建模能力的320亿参数开放权重大语言模型CWM；2) 通过使用Python解释器和代理Docker环境中的观察-动作轨迹进行中期训练；3) 在多种多任务推理RL环境中进行广泛的训练；4) 提供了一个实验平台，探索世界建模在计算环境中的作用，特别是在代码生成中的应用。这些方法有助于改善代码生成和理解的能力。
### Conclusion
研究展示了世界模型如何提高代理代码生成的效果，能够逐步模拟Python代码的执行，并展示了推理如何从后续步骤中受益。CWM在各种通用编程和数学任务上表现优秀，在SWE-bench Verified测试中达到65.8%的pass@1得分，在其他任务上也有优秀的表现。为了支持进一步研究代码世界建模，该研究发布了CWM在中期训练、精细调整和强化学习后的模型检查点。
## 641. `cs.LG` - 词语让语言模型感知 [PDF](https://arxiv.org/pdf/2510.02425), [HTML](https://arxiv.org/abs/2510.02425)
### Authors
Sophie L. Wang,Phillip Isola,Brian Cheung
### Background
大型语言模型(LLMs)虽然仅基于文本进行训练，理论上缺乏直接感知经验，但其内部表示仍然被语言中嵌入的多模态规律间接影响。研究者推测，通过显式的感官提示可以揭示这种潜在结构，使纯文本训练的LLMs与专业视觉和音频编码器在表示上更加一致。
### Innovation
通过显式的感官提示（如‘看到’或‘听到’），模型被引导在其下一个预测中隐含地考虑假想的视觉或听觉证据。这种轻量级的提示工程能够可靠地激活适应模态的表示，即使模型完全是基于文本训练的。
### Conclusion
感官提示不仅可以揭示语言模型内部的潜在结构，还能使纯文本语言模型在表示上向专业视觉和音频编码器靠拢，从而提升模型在特定模态任务上的性能。
## 642. `cs.LG` - 推理模型基准污染检测的脆弱性 [PDF](https://arxiv.org/pdf/2510.02386), [HTML](https://arxiv.org/abs/2510.02386)
### Authors
Han Wang,Haoyu Li,Brian Ko,Huan Zhang
### Background
在LRMs（Large Language Models）领域，排行榜已经成为评价模型性能的一种竞争方式，激励开发者通过优化基准测试套件来提升排名。然而，直接将评价基准纳入训练数据作为捷径，导致了基准污染（benchmark contamination），即模型在训练时受到了评价数据的影响，从而产生虚高的性能表现。我们研究发现，规避这种污染检测对于LRMs来说异常简单，尤其是在实际应用中可能发生的两种情景：（1）在模型通过自监督学习（SFT）和强化学习（RL）演变为LRM的过程中，基准污染在SFT阶段原本可以被检测到，但在进行短暂的RL（特别是使用PPO风格的重要性采样和剪裁目标）训练后，污染信号会被显著掩盖；（2）当SFT结合生成性思维（CoT）的应用于高级LRMs的最终阶段时，大多数污染检测方法几乎无法识别污染，使得已污染的模型在应对与训练集相似分布的未见过样例时表现得更有信心，从而规避现有的基于记忆的检测方法。总体而言，这些发现揭示了LRMs评估的独特脆弱性：模型开发者可以轻易通过污染方法来提升排行榜上的表现，却留下很少的污染痕迹，严重损害了评估的公平性和公共排行榜的完整性和可信度。这突显了急需更先进的污染检测方法和针对LRMs的可信赖评估协议的需求。
### Innovation
该研究深入探讨了在推理模型（LRMs）中基准污染检测的脆弱性问题，特别是在模型通过自监督学习（SFT）和强化学习（RL）演变为LRM的过程中，以及在SFT结合生成性思维（CoT）应用于高级LRMs时，发现了基准污染检测的难以探测性。研究表明，即使是短暂的RL训练也可以显著掩盖污染信号，尤其是PPO训练风格的重要性采样和剪裁目标是导致这种检测回避的核心原因。此外，研究还发现，即使不接触非成员样本，被污染的LRMs也会在面对与训练集相似分布的未见过的样本时表现得更自信，从而避开了现有的基于记忆的检测方法。这些发现为评估LRMs提出了新的挑战，找到了改进污染检测方法的方向.
### Conclusion
这项研究揭示了推理模型评估中的独特脆弱性，表明模型开发者可以通过污染方法轻松提升表现排名，同时留下极少的污染痕迹，严重削弱了评估的公平性和排行榜的完整性。该研究强调了开发更先进的污染检测方法和专为LRMs设计的可信度评估协议的迫切需求。
## 643. `cs.LG` - 高阶PAC学习，VC维数和填充引理 [PDF](https://arxiv.org/pdf/2510.02420), [HTML](https://arxiv.org/abs/2510.02420)
### Authors
Artem Chernikov,Henry Towsner
### Background
本文旨在概述Chernikov和Towsner在2020年（arXiv:2010.00726）中关于Chernikov, Towsner的高阶VC理论（即VC$_n$维数）的工作，包括Haussler填充引理的一般化及相关的驯服（按片）超图正规准则。此外，作者还展示了在科巴雅西、栗山和仓田在2015年引入的$n$折乘积空间中，该理论如何表征基于产品测度的高阶PAC学习（PAC$_n$学习）.
### Innovation
工作的一个创新点是开发了高阶VC理论，提出了一般化Haussler填充引理及相关的驯服（按片）超图正规准则，并指出了上述结果（arXiv:2402.14294, arXiv:2505.15688, arXiv:2509.20404）均为该工作在arXiv:2010.00726中的直接推论.
### Conclusion
该高阶VC理论在$n$折乘积空间中的产品测度下，准确表征了高阶PAC学习行为。
## 644. `cs.LG` - 利用形式独立和增强的句子意义表示模型化语言皮层揭示了惊人的语义抽象性 [PDF](https://arxiv.org/pdf/2510.02354), [HTML](https://arxiv.org/abs/2510.02354)
### Authors
Shreya Saha,Shurui Li,Greta Tuckute,Yuanning Li,Ru-Yuan Zhang,Leila Wehbe,Evelina Fedorenko,Meenakshi Khosla
### Background
人类语言系统同时表示语言形式和意义，但意义表示的抽象程度仍然存在争议。本文通过使用视觉和语言模型的表示来模拟语句的神经响应，旨在探索语言皮层中是否存在抽象的意义表示。通过生成与语句对应的图像并提取视觉模型嵌入，研究发现，通过对多个生成图像的嵌入进行聚合可以获得越来越准确的语言皮层响应预测，有时甚至能媲大小规模的语言模型。同样，对一个句子的多个同义句的嵌入进行平均，比任何单一的同义句嵌入都能提高预测准确性。进一步增加包含可能隐含的上下文细节（例如，将“I had a pancake”扩充为“含有枫糖浆的煎饼”）也能够进一步提高预测准确性，甚至超过了基于原始句嵌入的预测，表明语言系统保持的语义表示比语言模型要丰富和广泛。结合这些结果可以看出，语言皮层中存在高度抽象且形式无关的意义表示。
### Innovation
使用生成的图像和视觉模型嵌入来预测语言皮层的响应，并通过多生成图像和同义句的嵌入聚合来提高预测准确性。此外，通过包含上下文细节来增强同义句，进一步提高了预测的准确性，表明语言系统保持了比语言模型更丰富和广泛的语义表示。这揭示了语言皮层中存在形式独立且高度抽象的意义表示。
### Conclusion
本文的研究结果证明，语言皮层中存在形式无关且高度抽象的意义表示，这揭示了语言系统比当前语言模型保持更丰富的语义表示。
## 645. `cs.LG` - 时间序列的预测推断：分段齐性预测为何在时序依赖下仍有效？ [PDF](https://arxiv.org/pdf/2510.02471), [HTML](https://arxiv.org/abs/2510.02471)
### Authors
Rina Foygel Barber,Ashwin Pananjady
### Background
本文探讨了使用时间序列过去数据对未来时间点进行预测时，提供有效预测区间的问题。近年来，齐性预测方法因其对任何独立同分布或可交换数据分布提供无分布性覆盖而广受欢迎。但在时间序列背景下，齐性预测方法的强实证性能尚不明确，因为短程时间依赖是对可交换性假设的重大违背。使用“记忆”预测器（即利用过去观测值的预测器，如自回归模型），进一步加剧了这一问题。
### Innovation
本文研究了分段齐性预测在时间序列中的理论特性，包括预测器可能具有“记忆”的情况。研究结果以“切换系数”为指标，量化了时间序列内部时间依赖性如何导致可交换性假设的违背程度。结果表明，这些方法的覆盖概率在平稳、β-混合同分布的过程中是精确的。本文还引入了分析其他对依赖数据进行预测推断方法的工具。
### Conclusion
本文精确界定了这些方法的覆盖概率，分析了分段齐性预测在存在时间依赖性的条件下仍能有效的原因，并提出了适用于分析其他依赖数据预测推断方法的新工具。
## 646. `cs.LG` - 通过风险控制实现安全高效的同时上下文学习 [PDF](https://arxiv.org/pdf/2510.02480), [HTML](https://arxiv.org/abs/2510.02480)
### Authors
Andrea Wynn,Metod Jazbec,Charith Peris,Rinat Khaziev,Anqi Liu,Daniel Khashabi,Eric Nalisnick
### Background
大规模语言模型（LLMs）能够从少量上下文示例中学习新任务，但这种灵活性带来了安全性问题：LLMs 可能会受到错误或恶意演示的影响，如果对手篡改或注入有害示例而未被注意到，系统可能就会受到攻击。
### Innovation
本文提出了一种新的方法来限制有害示例对模型性能的负面影响。首先定义了一个无上下文提示的“安全”基线行为；其次，利用分布无关的风险控制（DFRC）机制控制上下文示例对性能的影响；最后，改进DFRC使其既能控制有害示例的风险，又能充分利用有益示例的性能和效率提升。
### Conclusion
通过理论和实验证明，该方法能够有效管控有害上下文提示风险，同时在有益提示上获得显著的计算效率提升。
## 647. `cs.LG` - 自适应随机枢轴和体积采样 [PDF](https://arxiv.org/pdf/2510.02513), [HTML](https://arxiv.org/abs/2510.02513)
### Authors
Ethan N. Epperly
### Background
自适应随机枢轴（ARP）算法是一种近期提出的高效列子集选择算法。本文通过将ARP算法与体积采样分布和用于线性回归的主动学习算法进行连接，对其进行了重新诠释。
### Innovation
文章通过与体积采样分布和线性回归的主动学习算法建立联系，对ARP算法进行了新的分析，并提出了使用拒绝采样加快算法运行速度的新方法。
### Conclusion
文章提出了对ARP算法的新见解，并通过使用拒绝采样方法提高了算法的效率。
## 648. `cs.LG` - 基于行为分析的自适应欺骗框架以增强网络防御 [PDF](https://arxiv.org/pdf/2510.02424), [HTML](https://arxiv.org/abs/2510.02424)
### Authors
Basil Abdullah AL-Zahrani
### Background
介绍了CICIDS2017数据集上的自适应欺骗系统CADL（Cognitive-Adaptive Deception Layer），该系统通过集成机器学习（随机森林、XGBoost、神经网络）和行为建模来检测和自适应响应网络攻击。系统利用协调的信号总线架构，让安全组件共享实时情报，支持集体决策。系统根据时间模式对攻击者进行建模，并在五个升级级别上部署自定义的欺骗策略。基于50,000个CICIDS2017测试样本的评估结果表明，CADL显著优于传统的入侵检测系统（Snort: 71.2%，Suricata: 68.5%），同时保持生产级别的误报率。行为分析在攻击者分类方面达到了89%的准确率。该框架提供了开源实现和透明的性能指标，为商业欺骗平台提供了一个可访问的替代方案，这些平台每年每台主机的费用在150-400美元之间。
### Innovation
提出了一种集成多个机器学习模型和行为分析的自适应欺骗框架CADL，能够达到99.88%的检测率和0.13%的误报率。系统利用协调的信号总线架构，使各安全组件能够共享实时的情报信息，从而实现集体决策。同时，在评估攻击者行为模式的基础上，该框架还能够部署个性化的欺骗策略，提高网络安全防御效果。并且，该框架提供了透明的性能指标和开源实现，为网络安全防御提供了一种更经济高效的替代方案。此外，CADL还能够显著提升传统入侵检测系统的检测率，同时保持较低的误报率。
### Conclusion
该论文提出了一种名为CADL的自适应欺骗框架，能够在网络防御中提供更高的检测率和更少的误报。通过行为分析，该框架还能更准确地识别和适应网络攻击。此外，CADL提供了开放源代码和透明的性能指标，使其成为商业解决方案的一个有吸引力的替代选择。
## 649. `cs.LG` - 使用超核岭回归学习多索引模型 [PDF](https://arxiv.org/pdf/2510.02532), [HTML](https://arxiv.org/abs/2510.02532)
### Authors
Shuo Huang,Hippolyte Labarrière,Ernesto De Vito,Tomaso Poggio,Lorenzo Rosasco
### Background
深度神经网络在高维问题上表现出色，超越了核方法等模型，后者因维数灾难而表现不佳。然而，深度网络成功背后的理论基础依然不甚明了。本文假设学习任务的分层结构是决定深度网络胜出其他方法的关键因素。基于这一点，研究者提出并探讨了一种结合神经网络与核方法的超核岭回归方法。
### Innovation
本文的主要贡献在于，提供了一个样本复杂度结果，证明了超核岭回归能在学习多索引模型时实现自适应学习，克服维数灾难。同时，通过核的性质，开发了特定优化方法，包括交替最小化和交替梯度方法，并从理论和数值实验两方面进行了对比。
### Conclusion
本文的研究结果显示超核岭回归能够在多索引模型的学习中表现出良好的适应性，从而解决高维问题，进一步探索了结合神经网络与核方法的可能性。
## 650. `cs.LG` - 从踪迹到行：基于LLM代理的开源软件漏洞精准定位 [PDF](https://arxiv.org/pdf/2510.02389), [HTML](https://arxiv.org/abs/2510.02389)
### Authors
Haoran Xi,Minghao Shao,Brendan Dolan-Gavitt,Muhammad Shafique,Ramesh Karri
### Background
现有的大规模语言模型在漏洞发现方面显示出了潜力，但目前的方法主要孤立地检查代码，难以处理长上下文，并集中在粗粒度的功能或文件级别的检测上，这为需要精确行级定位和精准修补的工程师提供了有限的实际指导。开源软件开发中，亟需能够提供具体行级诊断和精准修复指导的系统。
### Innovation
本文提出了T2L-Agent（踪迹到行代理），这是一个项目级别的端到端框架，能够自主规划分析，并逐步缩小范围，从模块到具体故障行。T2L-Agent 模块化反馈与 AI 化踪迹分析器（ATA）结合，将运行时证据（崩溃点、堆栈跟踪、覆盖率差异）与基于AST的代码片段化相结合，实现逐步精炼，并将症状转化为可操作的行级诊断。此外，为了评估精准诊断能力，研究团队引入了T2L-ARVO基准测试数据集，涵盖了五种崩溃家族和实际开源项目，支持粗粒度检测与细粒度定位，便于系统在文件级预测基础上进行全面评估。
### Conclusion
T2L-Agent在T2L-ARVO基准测试数据集上实现了高达58.0%的检测率和54.8%的行级定位精度，显著优于基线系统。该框架和基准测试数据集共同将基于LLM的漏洞检测推向了可部署、稳健的精确诊断，降低了噪音，加速了开源软件修复流程。
## 651. `cs.LG` - NEURODNAAI: 使用深度学习框架促进可持续DNA基信息存储的神经管道方法 [PDF](https://arxiv.org/pdf/2510.02417), [HTML](https://arxiv.org/abs/2510.02417)
### Authors
Rakesh Thakur,Lavanya Singh,Yashika,Manomay Bundawala,Aruna Kumar
### Background
DNA因其卓越的密度和耐用性，是数字信息存储的有前途的介质。尽管先前的研究推动了编码理论、工作流程设计及模拟工具的发展，但合成成本、测序错误以及生物学限制（如GC含量不平衡、串联碱基）等因素限制了其实用部署。现有的方法包括传统提示或基于规则的方案，在面对实际噪声时难以有效适应，导致准确性不高。同时，通过结合量子并行原理、引入生物约束、加强错误校正机制，以增强DNA存储的编码多样性与稳健性是亟待解决的问题。
### Innovation
本研究提出了一个结合了量子并行原理、生物约束和深度学习的框架，名为NeuroDNAAI。该框架能够有效编码二进制数据流为象征性的DNA序列，通过有噪声的信道传输，并实现高保真度的重建。NeuroDNAAI能够克服传统方法在处理实际噪声方面的局限，实现更高的准确性。实验结果表明，在文本和图像数据集上，其比特错误率很低。整个流程（理论、工作流和模拟）被集成到一个管道中，从而使生物上有效的归档DNA存储规模化成为可能。
### Conclusion
通过将理论、工作流和模拟整合到一个管道中，NeuroDNAAI实现了一种可扩展且符合生物学要求的DNA存储方法，超越了传统提示或基于规则的方法，能够在噪声环境中实现精准的二进制数据存储和传输。
## 652. `cs.LG` - Even Faster Kernel Matrix Linear Algebra via Density Estimation [PDF](https://arxiv.org/pdf/2510.02540), [HTML](https://arxiv.org/abs/2510.02540)
### Authors
Rikhav Shah,Sandeep Silwal,Haike Xu
### Background
该研究探讨了核密度估计（KDE）在处理包含n个d维数据点的核矩阵的线性代数任务中的应用。现有算法在计算矩阵向量乘积、矩阵矩阵乘积、谱范数以及核矩阵所有条目的总和时，通常依赖于误差ε的多项式依赖和数据点数量n的线性依赖。研究旨在通过使用KDE查询替代直接访问核矩阵，降低依赖性。
### Innovation
该研究的主要创新在于，通过改进现有的算法，提高了计算矩阵向量乘积、矩阵矩阵乘积、谱范数以及核矩阵所有条目的总和的效率，直至(1+ε)相对误差。改进后的算法在运行时间上依赖于维度d、数据点数量n和目标误差ε，但通过使用KDE查询核矩阵，n的依赖性显著降低。相对于Backurs、Indyk、Musco和Wagner（2021年）的研究，改进之处在于减少了多项式依赖ε，并且当计算核矩阵所有条目的总和时，减少了n的依赖。
### Conclusion
该研究不仅提供了KDE方法在相关问题上的线性代数运算的上界，还提供了相关问题的下界，指出了KDE方法在研究问题上的局限性，提出了基于KDE的方法在解决问题上的条件二次时间的难度结果。
## 653. `cs.LG` - 使用马尔可夫链蒙特卡洛进行成本态初始化的自我监督扩散模型微调 [PDF](https://arxiv.org/pdf/2510.02527), [HTML](https://arxiv.org/abs/2510.02527)
### Authors
Jannik Graebner,Ryne Beeson
### Background
全球搜索和优化长时间、低推力航天器轨道路径使用间接方法是非常具有挑战性的，由于解空间复杂和生成好的伴随变量初始猜测困难。这种挑战在多体环境中尤为明显。虽然可以使用一些数据揭示部分帕累托前沿，但找到一种灵活的方法来完成帕累托前沿、发现相关轨道路径的前沿仍然是重要的研究方向。本文利用条件扩散模型表示候选最优轨道解的分布，并提出了一种新的利用马尔可夫链蒙特卡洛算法及其自我监督微调进行目标的方法。这种方法能够改进样本质量、明确目标帕累托最优性，并在多体环境中进行验证。
### Innovation
本文提出了一种使用条件扩散模型表示候选最优轨道解分布的方法，并结合马尔可夫链蒙特卡洛算法及其自我监督微调进行优化。具体地，利用随机游走马尔可夫算法提出新数据，并基于约束违反和任务目标函数的高效评估进行奖励加权训练，以优化扩散模型。这种方法能够直接从扩散模型生成数据，无需单独的数据生成阶段，实现了更有效的优化流程。
### Conclusion
本文提出的框架在Jupiter-Europa和Saturn-Titan的轨道转移中进行了验证，表明该方法能够改进样本质量并明确目标帕累托最优性。特别是，马尔可夫链蒙特卡洛自我监督微调方法能够从Jupiter-Europa案例生成密集且优越的帕累托前沿，优于单独的全局搜索。
## 654. `cs.LG` - 代理增材制造合金发现 [PDF](https://arxiv.org/pdf/2510.02567), [HTML](https://arxiv.org/abs/2510.02567)
### Authors
Peter Pak,Achuth Chandrasekhar,Amir Barati Farimani
### Background
在增材制造（AM）领域，合金发现仍然是一个复杂的挑战，需要在材料科学、热力学模拟和实验分析等多个领域具备深厚的专业知识。现有的方法依赖于人工干预，效率较低，且难以处理大规模数据和复杂问题。为此，需要发展一种能够利用大型语言模型（LLM）辅助代理系统来自动加速合金发现的过程，从而提高研究效率和解决复杂问题的能力。
### Innovation
该论文提出了一种代理系统，利用大型语言模型（LLM）自动生成并执行工具调用任务（如Thermo-Calc热力学性质图计算和缺焊缝过程地图生成），并通过Model Context Protocol（MCP）完成操作。此外，该系统还能够有效解析复杂的用户指令，评估提议合金的可打印性，并根据工具调用结果动态调整任务流程。这些代理系统能够在实际环境中实现自主决策，显著加快合金发现的过程，并展示多代理系统的优势。
### Conclusion
该研究表明，利用大型语言模型（LLM）代理系统可以自动化并加速增材制造领域的合金发现过程，提高研究效率和创新能力。同时，通过开发多代理系统，能够有效地解决复杂和大规模问题，展示了其在未来研究中的潜力和应用前景。
## 655. `cs.LG` - ARMs: 自适应对抗红队代理应对插件可玩式攻击的多模态模型 [PDF](https://arxiv.org/pdf/2510.02677), [HTML](https://arxiv.org/abs/2510.02677)
### Authors
Zhaorun Chen,Xun Liu,Mintong Kang,Jiawei Zhang,Minzhou Pan,Shuang Yang,Bo Li
### Background
随着视觉-语言模型（VLMs）的显要地位，它们的跨模态接口也引入了新的安全漏洞，这使得安全评估变得更具挑战性和重要性。现有的红队努力要么局限于狭窄的对抗模式，要么严重依赖人工工程学，缺乏对新兴实际世界VLM漏洞的可扩展探索。
### Innovation
为了弥合这一差距，我们提出了一种自适应红队代理(ARMs)，一种系统地对VLMs进行全面风险评估的方法。给定目标有害行为或风险定义，ARMs自动优化多种红队策略，使用增强推理的多步骤协调，以有效激发目标VLMs的有害输出。我们提出了11种新颖的跨模态攻击策略，涵盖了VLMs的各种对抗模式（例如，推理劫持，上下文掩饰），并通过模型上下文协议(MCP)将17种红队算法整合到ARMs中。为平衡攻击的多样性和有效性，我们设计了一层式记忆并使用ε贪心攻击探索算法。广泛的实验展示了ARMs在实例和策略基准上的SOTA攻击成功率，平均超过基线52.1%，并在Claude-4-Sonnet上超过90%。这表明，由ARMs生成的红队实例的多样性显著更高，揭示了VLMs中的新兴漏洞。利用ARMs，我们构建了ARMs-Bench，一个大规模的跨模态安全数据集，包含超过30,000个跨模态红队实例，涵盖51个不同的风险类别，基于现实世界的信息安全威胁和监管风险。利用ARMs-Bench进行安全微调不仅提高了VLMs的鲁棒性，还保留了它们的一般用处，提供了对抗新兴威胁进行全面跨模态安全对齐的实际指导。
### Conclusion
我们的研究结果表明，ARMs在揭示VLMs的新威胁方面的多样性显著更高，并在对抗性攻击成功方面实现了最优方法。通过利用ARMs-Bench，我们建立了跨模态安全数据集，这对鲁棒性的提高和保持通用效用具有重要意义，为VLMs的安全适应新兴威胁提供了实用指南。
## 656. `cs.LG` - 多模态函数向量用于空间关系 [PDF](https://arxiv.org/pdf/2510.02528), [HTML](https://arxiv.org/abs/2510.02528)
### Authors
Shuhao Fu,Esther Goldberg,Ying Nian Wu,Hongjing Lu
### Background
大型多模态模型（LMMs）能够从有限的多模态演示中展示出显著的在上下文学习能力，但是支持这种任务学习的内部机制仍然不透明。基于之前关于大型语言模型的研究，论文展示了OpenFlamingo-4B多模态语言模型中一小部分注意力头专门负责传递空间关系的表征，通过这些需要注意的位置可以调整模型在空间关系任务上的性能。论文使用合成数据集和真实图像数据集，通过因果中介分析来识别强烈影响关系预测的注意力头，并提取多模态函数向量，这些向量能够在零样本推理时间提高了准确性。这些多模态函数向量通过少量的训练数据进行微调后，在内省学习基线下表现出优越性。论文还证明了特定于关系的函数向量可以通过线性组合来解决涉及未训练的新型空间关系的类比问题，突显了这种方法的强泛化能力。研究结果表明LMMs内部结构中编码有空间关系知识，这些知识可以通过系统提取和优化进一步理解模型的可模块化程度，并增强对空间关系推理的控制能力。
### Innovation
1. 识别了负责传递空间关系表征的一些特定注意力头，利用这些头提取多模态函数向量，并改善零样本推理的准确性。2. 通过使用少量训练数据对多模态函数向量进行微调，使其在性能上显著优于内省学习基线。3. 展示了如何通过线性组合特定于关系的函数向量来解决涉及未训练空间关系的新颖类比问题，展示了这种方法的强泛化能力。
### Conclusion
研究结果表明，LMMs内部结构中包含了空间关系知识，并且这些知识是可以系统地提取和优化的。这有助于更深入地理解模型的可模块化结构，并增强对空间关系推理的控制。
## 657. `cs.LG` - 揭开句法之谜：语言模型如何学习上下文自由文法 [PDF](https://arxiv.org/pdf/2510.02524), [HTML](https://arxiv.org/abs/2510.02524)
### Authors
Laura Ying Schulz,Daniel Mitropolsky,Tomaso Poggio
### Background
尽管大型语言模型在语法上取得了令人印象深刻的结果，但对其学习动态的理解仍知之甚少。研究指出，大多数感兴趣的领域，如自然语言句法、编程语言、算术问题，都可以用概率上下文无关文法（PCFGs）来描述。以此为基础，研究者探讨了小型模型在合成语言上的学习动态，这些合成语言是从PCFGs生成的，从而可以精确控制文法规则的复杂性、递归深度和子文法规则结构。研究证明了几种关于训练损失和Kullback-Leibler（相对）差分在PCFGs子文法规则结构上的通用、递归公式.
### Innovation
1. 提出了一个新的框架，以便更好地理解语言模型如何获取句法知识；2. 微型模型在合成语言上的训练学习动态研究；3. 证明了几种关于训练损失和Kullback-Leibler（相对）差分在PCFGs子文法规则结构上的通用、递归公式；4. 发现Transformer在减少所有子文法规则的损失上同步进行，而非逐步增加复杂性；5. 显示了子文法规则预训练可以改善小型模型的最终损失，并能使预训练模型发展出与语法规则子结构更一致的内部表示；6. 指出模型在更深层次的递归结构上的困难，揭示了神经网络在表示层次句法中的根本挑战.
### Conclusion
本文通过研究Transformer在概率上下文无关文法（PCFGs）上的学习动态，为探索语言模型的学习机制提供了一个多功能的试验平台，开辟了一个具有许多未解决问题的研究方向。模型在更深层次的递归结构上的困难，揭示了神经网络在表示层次句法中的根本挑战。
## 658. `cs.LG` - 压缩感知对比下的无假设攻击的统计检测方法 [PDF](https://arxiv.org/pdf/2510.02707), [HTML](https://arxiv.org/abs/2510.02707)
### Authors
Chinthana Wimalasuriya,Spyros Tragoudas
### Background
目前，对抗攻击对现代机器学习系统构成重大威胁，但在现有检测方法中，经常会缺乏检测未知攻击或以高精度检测不同攻击类型的能力。
### Innovation
本文提出了一种统计方法，可以在神经网络部署前建立检测基准，实现有效的实时对抗检测。通过将压缩和未压缩的神经网络行为进行比较，生成对抗存在度量。该方法已与最新技术进行测试，并在多种攻击类型下实现了近乎完美的检测效果，同时显著减少了误报，使其具有实用性和可靠性。
### Conclusion
本文提出的方法为对抗攻击提供了一种有效的检测机制，不仅提高了检测的准确性，还确保了在实际应用中的高可靠性。
## 659. `cs.LG` - 表征差距中的不确定性：针对上下文问答任务的LLM的表征间隙玉溪量化 [PDF](https://arxiv.org/pdf/2510.02671), [HTML](https://arxiv.org/abs/2510.02671)
### Authors
Yavuz Bakman,Sungmin Kang,Zhiqi Huang,Duygu Nur Yaldiz,Catarina G. Belém,Chenyang Zhu,Anoop Kumar,Alfy Samuel,Salman Avestimehr,Daben Liu,Sai Praneeth Karimireddy
### Background
不确定性量化（UQ）研究主要集中在封闭测试的常识问答上，而情境问答任务尚未得到探索，尽管它在实际应用中非常重要。本文提出了一种旨在量化情境问答任务中认识论不确定性并理论支持的方法。
### Innovation
提出了一个不依赖任务的、基于 token 的不确定性度量方法，它定义为给定模型预测分布与未知真实分布之间的交叉熵，并通过分解这个度量来隔离认识论部分。此外，还提出了一种通用框架的应用，并假设三个特征可以近似描述这种差距：情境依赖性、情境理解以及诚实性。通过使用少量带标签样本并进行自上而下的解释方法，提取出这些特征并将它们联合起来，从而形成一个稳健的不确定性评分方法。
### Conclusion
在多种问答基准测试中，该方法在内分布和外分布设置下均显著优于现有最先进的无监督和监督不确定性量化方法，在某些情况下，准确率提高了13个百分点，且几乎不增加推理开销。
## 660. `cs.LG` - 温度采样在测试时缩放中的作用 [PDF](https://arxiv.org/pdf/2510.02611), [HTML](https://arxiv.org/abs/2510.02611)
### Authors
Yuheng Wu,Azalia Mirhoseini,Thierry Tambe
### Background
大型语言模型（LLMs）可以通过测试时缩放（TTS）在推理时改进推理能力，即生成多个推理路径并选择最佳的一个。之前的研究表明，增加样本数量K可以稳定地提高准确性。这项研究探讨了这个趋势的极限，发现当K达到一定大小时，进一步的缩放不会带来额外的提升，某些难题在任何数量的路径下都难以解决。
### Innovation
研究发现不同的采样温度可以解决不同的问题子集，表明单一温度缩放仅探索了模型潜力的一部分。因此，提出了沿着温度维度进行缩放的方法，这扩大了LLMs的推理边界。使用Qwen3（0.6B，1.7B，4B，8B）和五个代表性推理基准（AIME 2024/2025，MATH500，LiveCodeBench，Hi-ToM），温度缩放在单温度TTS基础上额外增加了7.3分。此外，提出了一个减少温度缩放开销的多温度投票方法。
### Conclusion
研究结果表明，TTS比之前认为的更强大，温度缩放提供了一种简单而有效的方法来解锁基模型的潜在能力。
## 661. `cs.LG` - 超越线性扩散：适应罕见条件的改进表示 [PDF](https://arxiv.org/pdf/2510.02499), [HTML](https://arxiv.org/abs/2510.02499)
### Authors
Kulunu Dharmakeerthi,Yousef El-Laham,Henry H. Wong,Vamsi K. Potluru,Changhong He,Taosong He
### Background
扩散模型已经在机器学习和人工智能系统中展示了强大的生成框架能力，但当前的研究主要集中在线性扩散上，而这些方法在建模条件分布 $P(Y|X=x)$ 时，面临很大挑战，尤其是当 $P(X=x)$ 很小的时候。在这些概率低的区域，可用的训练样本很少或者几乎没有，因此建模相应的条件密度是很困难的。
### Innovation
本文展示了一种方法，通过适应数据表示和向前方案，使得学习基于得分的生成模型在条件空间的低概率区域所需的样本复杂性较小。受条件极值理论的启发，本文在条件变量 $X$ 的尾部区域精确地描述了这种方法，并表明具有数据驱动非线性漂移项的扩散模型最适合在适当的数据表示下建模尾部事件。通过在两个合成数据集和一个实际的金融数据集上进行实证验证，证明了本文的尾部适应方法在极端尾部条件下的响应分布建模显著优于标准扩散模型。
### Conclusion
实验证明，与标准扩散模型相比，本文提出的尾部适应方法在准确捕捉极端尾部条件下的响应分布方面表现更佳。
## 662. `cs.LG` - 非均匀边界条件和载荷下板式加强构件的异质图表示 [PDF](https://arxiv.org/pdf/2510.02472), [HTML](https://arxiv.org/abs/2510.02472)
### Authors
Yuecheng Cai,Jasmin Jelovica
### Background
结构分析和优化中重要的工具是代理模型。本研究为板式加强构件提出了一种异质图表示方法，该方法考虑了几何变异性、非均匀边界条件和各种载荷场景，利用异质图神经网络（HGNNs）。结构被划分为多个结构单元，每个单元通过三种不同的节点类型来表示：几何节点、边界节点和载荷节点。
### Innovation
本研究提出了几种异质图表示方法，具有不同层级的异质性，并将这些表示方法实施在异质图变换器（HGT）中，用于基于边界载荷和自由度预测板式加强构件的莫依斯应力和位移场。通过对比分析表明，与同质图表示相比，该方法具有更优的性能。进一步的消融分析表明，结构单元异质性的增加对HGT性能的影响显著。
### Conclusion
研究结果表明，使用异质图表示的板式加强构件模型具有很强的预测准确性，能够有效捕捉结构行为模式和最大值。这种表示方法特别适合处理具有非均匀边界条件和多载荷场景的复杂结构。
## 663. `cs.LG` - 随动与力场：从力与演示引导的模拟数据中学习3D柔顺流动匹配策略 [PDF](https://arxiv.org/pdf/2510.02738), [HTML](https://arxiv.org/abs/2510.02738)
### Authors
Tianyu Li,Yihan Li,Zizhe Zhang,Nadia Figueroa
### Background
尽管近年来视觉运动策略为机器人操作任务带来了进展，但接触丰富的任务仍然具有挑战性。这类任务需要对柔性和力进行明确处理，但大多数视觉运动策略忽略了柔性的处理，忽视了与真实世界物理交互的重要性，导致在不确定性下产生过多的接触力或脆弱的行为。将力信息引入基于视觉的模仿学习可以增强对接触的认知，但也需要大量数据来表现良好。数据稀缺的问题可以通过在模拟中生成数据来缓解，但生成高质量数据依旧是一个计算密集的过程，并且可能不会克服Sim2Real差距。本文旨在通过使用单个人类演示生成力信息数据，并结合使用带有弹性的策略来改善从合成数据中学习到的视觉运动策略的表现。验证结果显示，该方法在真实机器人任务中表现出可靠的接触维护和对新条件的适应性，包括非抓取的立方体翻转和双臂物体移动任务。项目网址：this https URL
### Innovation
本文提出了一种从力和演示引导的模拟数据中生成带有力信息的数据的框架，并结合使用弹性策略，以改善从合成数据中学习到的视觉运动策略的表现。该方法通过单个人类演示在模拟中生成高质量数据，克服了Sim2Real差距，提升了接触维护的可靠性和适应新条件的能力。
### Conclusion
通过使用本文提出的框架，从单个人类演示引导的模拟数据中生成力信息数据，并结合使用带有弹性的策略，可以显著提高视觉运动策略在接触丰富的任务中的表现，验证了其在真实机器人任务中的可靠性和适应性。
## 664. `cs.LG` - 至不一致的时间：大型语言模型在对抗攻击下的鲁棒性生存分析 [PDF](https://arxiv.org/pdf/2510.02712), [HTML](https://arxiv.org/abs/2510.02712)
### Authors
Yubo Li,Ramayya Krishnan,Rema Padman
### Background
虽然大型语言模型（LLMs）在对话型人工智能方面取得了革命性的进展，但它们在长时间多轮对话中的鲁棒性仍然知之甚少。现有的评估框架主要集中在静态基准和单一回合的表现上，未能捕捉到对话退化的时间动态特性，这种退化在现实中的交互中是典型的。本研究通过生存分析方法，对36,951个对话回合进行了详细的分析，横跨9个最先进的LLMs，旨在考察对话失败的风险随时间变化的情况。本研究揭示了对话型人工智能鲁棒性的时间动态特性，提供了一种评估LLM稳健性的新方法。
### Innovation
本研究首次进行了全面的生存分析，使用了Cox比例风险模型、加速失效时间模型（AFT）和随机生存森林等方法，通过这些分析揭示了对话型人工智能鲁棒性的独特时间动态特性。研究发现，突然出现在提示到提示（P2P）中的语义漂移是灾难性的，会大大增加对话失败的风险。相比之下，缓慢累积的漂移则非常具有保护性，极大地减少了失败风险并延长了对话长度。AFT模型的表现更佳，展示了卓越的判别能力和出色的校准性能。这些发现表明生存分析是一种强大的工具，可以用于评估LLM的稳健性，为设计更抗干扰的对话型代理提供了具体的见解，并对当前关于对话型人工智能系统中语义一致性必要性的假设提出了挑战。
### Conclusion
本研究通过生存分析评估了大型语言模型的鲁棒性，揭示了对话AI中的时间动态特性，并通过具体的发现挑战了现有假设。生存分析成为评估LLM鲁棒性的强大方法，对于设计更为坚固的对话型代理具有实际意义。
## 665. `cs.LG` - FLOWR.root：基于流匹配的联合多用途结构意识3D配体生成和亲和力预测的基础模型 [PDF](https://arxiv.org/pdf/2510.02578), [HTML](https://arxiv.org/abs/2510.02578)
### Authors
Julian Cremer,Tuan Le,Mohammad M. Ghahremanpour,Emilia Sługocka,Filipe Menezes,Djork-Arné Clevert
### Background
本文介绍了一种基于流匹配的可变流匹配模型，该模型在结合绑定亲和力预测和置信度估计的同时，可实现口袋感知的3D配体生成。该模型支持从头生成、基于药效团的采样、片段扩展，以及多终点亲和力预测（pIC50, pKi, pKd, pEC50）。训练方法结合了大规模配体库与混合精度的蛋白-配体复合体，并在精心策划的共晶数据集上进行了细化，通过参数高效的微调来适应特定项目的数据集。经过这些步骤，该模型在无条件的3D分子生成和口袋条件下的配体设计中达到了最先进的性能，产生几何上真实、低应变结构。结合的亲和力预测模块在SPINDR测试集上表现出优越的精度，在Schrodinger FEP+/OpenFE基准测试中也表现出色，具有显著的速度优势。作为一个基础模型，它需要针对特定项目的数据集进行微调，已显示出与实验数据的强相关性。联合生成和亲和力预测使得通过重要性抽样的推断时期能够扩展，引导分子设计朝向高吸附的化合物。
### Innovation
该模型通过结合结构意识生成、亲和力估计和性质指导的抽样，提供了一个从苗头识别到先导优化的结构基础药设计的全面框架。特别地，模型采用了一种新型的流匹配架构，同时实现了配体生成和亲和力预测，提高了模型的精度和生成效率，尤其在大规模分子图上表现出色，且能够进行多终点的亲和力预测。而且，通过数据集的自适应微调，模型能够更好地适应不同项目的结构-活性关系。此外，利用重要性采样实现的联合生成和预测，在推断时期能够扩展，引导分子设计朝向高亲和性化合物。
### Conclusion
FLOWR.root模型结合了基于流匹配的配体生成和亲和力预测，解决了传统的配体设计方法中存在的局限性。模型通过数据集的准备细化和参数高效的微调，能够生成符合真实结构和具有高亲和力的配体。更重要的是，该模型能够支持复杂项目的个性化适应，提高模型的可靠性和有效性，为未来的结构基础药物设计提供了一个有力的基础。
## 666. `cs.LG` - Aligen Your Query: Representation Alignment for Multimodality Medical Object Detection [PDF](https://arxiv.org/pdf/2510.02789), [HTML](https://arxiv.org/abs/2510.02789)
### Authors
Ara Seo,Bryan Sangwoo Kim,Hyungjin Chung,Jong Chul Ye
### Background
医学对象检测在单个检测器针对混合医学模态（如胸片、CT、MRI）进行训练时会出现性能下降的问题，这是因为不同模态之间的统计数据不一致且代表空间不连续。为了应对这一挑战，研究者们转向了代表对齐方法，这种方法已经被证明能够将来自不同源的数据特征带入共享空间。具体地，研究者们致力于对DETR风格的对象查询表示进行对齐，并提出了一种简单且未依赖于特定检测器的框架来实现这一目标。
### Innovation
该研究提出了两种创新方法：1) 定义了模态标记，这些是紧凑的、文本衍生的嵌入表示，用于编码成像模态，其轻量级且无需额外标注；2) 提出了一个称为QueryREPA的简短预训练阶段，通过特定任务的对比目标和模态平衡批次，将查询表示与模态标记对齐。研究者结合使用多模态上下文注意（MoCA）和QueryREPA，生成模态感知、类忠实的查询，这些查询能够在下游训练中有效地传递。通过全面多模态训练，该方法在所有情况下都能显著提高AP值，同时还提供了对结构修改的最小化影响，从而提供了一条通往稳健的多模态医学对象检测的实用路径。
### Conclusion
在所有组合的医学模态中训练时，所提出的方法能够以最小的开销和无结构修改的方式持续提高AP值，提供了一种实现稳健的多模态医学对象检测的实用途径。
## 667. `cs.LG` - SALSA-V: Shortcut-Augmented Long-form Synchronized Audio from Videos [PDF](https://arxiv.org/pdf/2510.02916), [HTML](https://arxiv.org/abs/2510.02916)
### Authors
Amir Dellali,Luca A. Lanzendörfer,Florian Grötschla,Roger Wattenhofer
### Background
当前存在一种从无声视频生成高度同步、高质量长音频的需求。现有的方法在音频和视频的同步和生成方面尚有不足，需要专门的微调或重新训练。
### Innovation
提出了一个名为SALSA-V的多模态视频到音频生成模型，该模型通过引入遮罩扩散目标，能够在不需要专门微调或重新训练的情况下，快速生成高质量的音频样本并实现无缝的音视频同步。模型通过集成简路损失来实现这一点，能够在八个采样步骤内生成高质量的音频样本，适用于接近实时的应用场景。此外，通过训练过程中使用随机遮罩，该模型能够在音频的频谱特征上与参考音频样本匹配，扩展其在诸如 Foley 采集和声音设计等专业音频合成任务中的应用价值。
### Conclusion
与现有最先进的方法相比，SALSA-V在音频视频对齐和与视频内容的同步方面表现更加出色。
## 668. `cs.LG` - 欧洲岛屿利益相关者中的土地利用-气候变化-生物多样性联系 [PDF](https://arxiv.org/pdf/2510.02829), [HTML](https://arxiv.org/abs/2510.02829)
### Authors
Aristides Moustakas,Irene Christoforidi,George Zittis,Nazli Demirel,Mauro Fois,Savvas Zotos,Eirini Gallou,Valentini Stamatiadou,Elli Tzirkalli,Christos Zoumides,Kristina Košić,Aikaterini Christopoulou,Aleksandra Dragin,Damian Łowicki,Artur Gil,Bruna Almeida,Panos Chrysos,Mario V. Balzan,Mark D.C. Mansoldo,Rannveig Ólafsdóttir,Cigdem Kaptan Ayhan,Lutfi Atay,Mirela Tase,Vladimir Stojanović,Maja Mijatov Ladičorbić,Juan Pedro Díaz,Francisco Javier Expósito,Sonia Quiroga,Miguel Ángel Casquet Cano,Haoran Wang,Cristina Suárez,Paraskevi Manolaki,Ioannis N. Vogiatzakis
### Background
为了促进气候变化适应和缓解，理解利益相关者对土地利用和气候变化的看法及其知识缺口至关重要。研究通过咨询21个欧洲岛屿的利益相关者，了解气候变化和土地利用变化对生态系统服务的影响，包括与温度、降水量、湿度、极端天气和风有关的气候感知，以及与热带雨林砍伐、沿海退化、栖息地保护、可再生能源设施、湿地等问题相关的土地利用感知。利益相关者还关注入侵物种、水资源或能源短缺、基础设施问题和紧缩政策等其他问题。通过机器学习分析气候变化和土地利用变化的影响感知，识别出主要的气候和土地利用特征。利益相关者普遍认为气候变化对生态系统服务的影响是负面的，自然栖息地破坏和生物多样性丧失是主要问题。土地利用变化的影响也负面但更复杂，涉及更多的解释变量。尽管地理不同，利益相关者在生物多样性影响方面存在共识，但对于气候变化和土地利用影响则有所区分。水资源、能源和可再生能源问题是严重关切，需要采取管理措施。
### Innovation
通过运用机器学习技术来分析气候变化和土地利用变化对生态系统服务的影响感知，量化其影响，识别出主要的气候和土地利用特征。此外，研究关注了包括水资源、能源和可再生能源等在内的具体问题，这在该领域是较为创新的方法。
### Conclusion
利益相关者普遍认为气候变化和土地利用变化对生态系统服务的影响是负面的。自然栖息地破坏和生物多样性丧失是主要问题。水、能源和可再生能源问题是严重关切，需要采取管理措施。气候和土地利用影响感知存在差异，利益相关者在生物多样性影响方面存在共识，但对于具体气候变化和土地利用影响则有所不同。
## 669. `cs.LG` - Hierarchical Generalized Category Discovery for Brain Tumor Classification in Digital Pathology [PDF](https://arxiv.org/pdf/2510.02760), [HTML](https://arxiv.org/abs/2510.02760)
### Authors
Matthias Perkonigg,Patrick Rockenschaub,Georg Göbel,Adelheid Wöhrer
### Background
准确的脑肿瘤分类对于神经肿瘤手术中的术中决策至关重要。然而，现有的方法仅限于固定的预定义类别的分类，无法捕捉训练中未出现的肿瘤类型模式。无监督学习可以提取通用特征，但是它缺乏结合标记数据先验知识的能力，半监督方法通常假设所有潜在的类都在标记数据中存在。Generalized Category Discovery (GCD)旨在弥补这一差距，通过在未标记数据中对已知和未知的类进行分类来实现这一目标。为了反映脑肿瘤分类学的层次结构，本文提出了Hierarchical Generalized Category Discovery for Brain Tumor Classification (HGCD-BT) 的新方法，该方法结合了层次聚类和对比学习。
### Innovation
本文提出的 HGCD-BT 方法通过结合层次聚类和对比学习，以及引入一种新的半监督层次聚类损失，扩展了基于对比学习的 GCD。该方法在 OpenSRH 数据集上的评估结果显示，HGCD-BT 方法在斑块级别的分类中比最先进的 GCD 方法提高了 28% 的准确性，特别是在识别以前未见过的肿瘤类别方面。此外，文章还展示了 HGCD-BT 在数字全切片成像数据集中的广义性，包括从染色的全切片图像中进行的滑块级别分类，从而证实了该方法在不同成像模态中的应用潜力。
### Conclusion
HGCD-BT 方法在斑块和滑块级别分类上均实现了优于现有方法的准确性，特别是在识别未见过的肿瘤类别方面表现突出，并且展示了其在不同成像模态的广义性。
## 670. `cs.LG` - 利用稀疏自动编码器理解大型语言模型中代码正确性的机制 [PDF](https://arxiv.org/pdf/2510.02917), [HTML](https://arxiv.org/abs/2510.02917)
### Authors
Kriz Tahimic,Charibeth Cheng
### Background
随着大型语言模型在软件开发中变得至关重要，许多AI提供的代码已进入生产环境，因此理解它们的内部正确性机制对于安全部署变得尤为关键。
### Innovation
本文应用稀疏自编码器对LLM的表示进行分解，以识别与代码正确性相关的方向。通过t-统计量选择预测方向并利用基模型表示的分离评分指导方向。通过引导、注意力分析和权重正交化分析这些机制的属性。发现LLM中的代码正确性方向能可靠地预测错误代码，但其纠错能力虽然在统计上显著，却涉及在修复错误和保留正确代码之间做权衡。从机制上看，成功的代码生成依赖于关注测试案例而非问题描述。进一步发现，基模型中识别的方向在指令微调后仍然有效，表明在预训练期间学习到的代码正确性机制会在微调期间重新利用。
### Conclusion
我们的机制见解提出三点实践应用：提示策略应优先选择测试示例而非复杂的描述性问题，预测方向可以作为开发人员审核中的错误警报，相同的预测器可以引导有选择的引导，仅在预期出现错误时干预以防止代码因连续引导而受到污染。
## 671. `cs.LG` - 基于oracle的凸体均匀采样 [PDF](https://arxiv.org/pdf/2510.02983), [HTML](https://arxiv.org/abs/2510.02983)
### Authors
Thanh Dang,Jiaming Liang
### Background
本文提出了新的马尔可夫链蒙特卡洛算法，用于在凸体$K$上采样均匀分布。这些算法基于交替采样框架/近端采样方法，该方法通过在增广分布上使用吉布斯采样，并假设可以访问所谓的受限高斯先验（RGO）。本文的关键贡献是在给定投影先验或分离先验的情况下，通过拒绝采样有效地实现了RGO，用于在$K$上均匀采样。两种先验情况下的结果均无需渐近分析，确保采样准确度分别使用Rényi散度和$boldsymbol{text{chi-square divergences}}$进行量化，从而保证样本无偏性，达到所需精度
### Innovation
提出了利用拒绝采样和先验访问实现RGO的有效方法，能够在凸体$K$上进行均匀采样。建立了非渐近复杂性以获得无偏样本，准确性通过Rényi散度和$boldsymbol{text{chi-square divergence}}$进行度量
### Conclusion
本文展示了将先验访问与拒绝采样相结合的算法设计方法，并通过Rényi散度和$boldsymbol{text{chi-square divergence}}$量化采样的准确性，从而保证采样结果的高效和精确
## 672. `cs.LG` - 视觉生成模型中组合泛化的驱动力 [PDF](https://arxiv.org/pdf/2510.03075), [HTML](https://arxiv.org/abs/2510.03075)
### Authors
Karim Farid,Rajat Sahay,Yumna Ali Alnaggar,Simon Schrodi,Volker Fischer,Cordelia Schmid,Thomas Brox
### Background
组合泛化是生成视觉内容的关键能力，即能够生成具有已知概念的新组合。尽管有很多机制能够促进或抑制这一点，但仍有很多机制尚未完全理解。本研究通过系统研究不同设计选择如何以正向或负向方式影响图像和视频生成中的组合泛化，来探讨这一问题。
### Innovation
研究通过控制实验，发现了两个关键因素：(i) 训练目标是否作用于离散或连续分布；(ii) 条件信息在训练期间对组成概念提供的程度。研究结果表明，通过使用辅助连续的JEPA目标减轻MaskGIT的离散损失，可以在离散模型中提升组合性能。
### Conclusion
研究识别出了影响视觉生成模型中组合泛化的两个关键因素，并表明通过使用连续目标可改进离散模型的组合泛化性能。
## 673. `cs.LG` - FR-LUX：摩擦感知的、状态条件下的策略优化方法及其可实施的资产组合管理 [PDF](https://arxiv.org/pdf/2510.02986), [HTML](https://arxiv.org/abs/2510.02986)
### Authors
Jian'an Zhang
### Background
论文背景主要讨论了交易成本和市场状态转换是导致纸面投资组合在实盘交易中失败的主要原因。此前的研究通常会忽视交易成本等实际市场因素，导致模型在进入实盘交易时表现不佳。因此，论文提出了一种名为FR-LUX的强化学习框架，旨在寻找交易政策，并在不同市场状态保持鲁棒性。FR-LUX通过结合微观结构一致的执行模型、交易空间信托区域约束及显式的市场状态条件，来改进传统方法的局限性。
### Innovation
FR-LUX的主要创新点在于：首先，它采用了一种结合比例成本与冲击成本的微观结构一致的执行模型，并将其直接嵌入到奖励中；其次，它利用交易空间的信托区域约束库存流的变化，而不是对对数概率的变化进行约束，从而实现稳定的、低周转率的更新；最后，它明确地对市场状态进行了条件化处理，使策略能够在LL/LH/HL/HH状态中专门化，而不分割数据集。FR-LUX在多种市场状态和成本水平下提供了最佳的平均夏普比率，并保持了较低的成本-收益曲线斜率，对于给定的周转预算，风险回报效率更高。此外，FR-LUX还提供了优化在凸摩擦条件下的最优性保证、在KL信托区域内的单调改进保证、长期仿真中对比例成本的动态响应机制及分段战略动态等正式证明。研究结果表明，即使在多种市场条件下，改进是显著且一致的，并且即使设置不同的成本参数，策略也具有稳健性。研究提供了实施方法，确保所有图表和表格都可再现，使模型更具可操作性。
### Conclusion
综上所述，FR-LUX框架在实盘交易中提供了稳定的、基于策略优化的交易政策，从而克服了传统方法的局限性。研究证明，FR-LUX在多样化的市场条件和交易成本水平下实现了最佳性能，并且具有很好的稳健性和重复性。
## 674. `cs.LG` - oRANS: 以嵌入直接数值模拟数据生成优化的RANS机器学习模型 [PDF](https://arxiv.org/pdf/2510.02982), [HTML](https://arxiv.org/abs/2510.02982)
### Authors
Daniel Dehtyriov,Jonathan F. MacArt,Justin Sirignano
### Background
深度学习（DL）在加速和提升流体力学模拟精度方面显示出前景，但受限于高质量训练数据的稀缺性。这类数据生成成本高昂且范围有限，导致传统的离线训练方法容易过拟合，难以泛化到新的流体状态。因此，寻求一种能够利用在线动态生成数据的优化框架成为必要，这可以提高模型在新流体状态下的表现。本文提出了一个基于嵌入直接数值模拟（DNS）的在线优化框架，旨在解决高保真数据集有限的挑战。该框架通过在RANS域中嵌入DNS来动态生成训练数据，利用RANS解与DNS之间的反馈循环，实现在流体状态下的自适应优化，避免依赖于预先计算的训练数据集，从而改进了模型的泛化能力。这种方法被验证应用于随机强迫Burgers方程和不同雷诺数（Reτ = 180, 270, 395, 590）的湍流通道流的RANS模型中。实验结果显示，基于该框架优化的RANS模型在性能上远超离线训练模型和文献中的校准模型，即便用较小的DNS子域也能够实现准确的训练。这种性能下降主要发生在边界条件污染严重或域过短无法捕捉低波数模式的情况下。这种方法提供了一条将物理信息机器学习闭合性与自适应降阶模型相结合的可扩展路径，无需大量的预先计算训练数据集即可跨越多种流体力学状态实现通用性。
### Innovation
本文创新性地提出一种基于在线优化的RANS机器学习模型框架（oRANS），主要创新点包括：1. 使用嵌入直接数值模拟（DNS）数据生成训练数据，提供了一种动态生成高质量数据的新方法；2. 实现RANS与DNS之间的实时反馈循环，使RANS模型能够根据嵌入DNS的目标流态动态调整，增强了模型的泛化能力；3. 该方法适用于不同流态（包括随机强迫Burgers方程和不同Re数的湍流通道流），显著提升了模型性能，尤其在较小DNS子域下也能实现精确训练；4. 提供了一条新的路径，使得RANS模型能够在保持结构简化的同时，增强其在新流体状态下的表现，无需依赖大量预计算数据集。总之，该创新框架有助于提高流体模拟的效率和准确性，并为将来的研究提供了有价值的参考。
### Conclusion
基于嵌入直接数值模拟（DNS）的在线优化框架（oRANS）能够在不依赖大量预计算数据集的情况下，显著提高RANS机器学习模型的性能、适应性和泛化能力。这种方法特别适合应用于不同流体状态下的流体力学模拟，使RANS模型能够更准确地适应目标流态。虽然该框架在边界条件污染严重或域较短的情况下性能会有所下降，但总体来说，它为流体力学仿真提供了一个有前途的数据自适应减缩模型方案。
## 675. `cs.LG` - WavInWav: 时间域语音隐藏基于可逆神经网络 [PDF](https://arxiv.org/pdf/2510.02915), [HTML](https://arxiv.org/abs/2510.02915)
### Authors
Wei Fan,Kejiang Chen,Xiangkun Wang,Weiming Zhang,Nenghai Yu
### Background
数据隐藏对于数字媒体中的安全通信至关重要，近年来深度神经网络（DNNs）的发展为有效地嵌入秘密信息提供了增强的方法。然而，以往的音频隐藏方法在还原秘密音频时常常表现出不满意的质量，主要原因在于其在时间-频率关系建模上的局限性。
### Innovation
本文探索了这一局限性，并引入了一种新的基于DNN的方法。该方法使用基于流的可逆神经网络，建立了从隐写音频到封面音频再到秘密音频的直接联系，增强了嵌入和提取消息的可逆性。通过在时域信号上实现时间-频率损失，该方法不仅保留了时间-频率约束带来的优势，还增强了消息还原的可逆性，这对于实际应用至关重要。此外，还增加了一种加密技术以保护隐藏数据免受未经授权的访问。
### Conclusion
在VCTK和LibriSpeech数据集上进行的实验表明，本方法在主观和客观指标上优于先前的方法，并对各种噪声类型表现出鲁棒性，表明其在针对性安全通信场景中的有用性。
## 676. `cs.LG` - ELMF4EggQ：使用多模态特征融合的集成学习方法实现非破坏性鸡蛋品质评估 [PDF](https://arxiv.org/pdf/2510.02876), [HTML](https://arxiv.org/abs/2510.02876)
### Authors
Md Zahim Hassan,Md. Osama,Muhammad Ashad Kabir,Md. Saiful Islam,Zannatul Naim
### Background
确保食品安全、维持产品质量标准和生产效率对于商业家禽生产至关重要。本文介绍了一种名为ELMF4EggQ的新方法，该方法通过结合外部特征（如图像、形状和重量），利用集成学习框架对鸡蛋等级和新鲜度进行分类，而无需进行破坏性检测。
### Innovation
这是首次使用机器学习方法仅通过外部、无损伤特征来评估鸡蛋内部品质的研究，并首次发布了相应的标记数据集。该框架利用主干预训练的CNN模型提取外部鸡蛋图像的深度特征，结合形状和重量的结构特性，使用主成分分析（PCA）进行降维和SMOTE增强，通过多种机器学习算法进行分类。最终，通过集成投票机制将性能最佳的分类器的预测结合起来，以提高整体准确性。
### Conclusion
多模态方法在等级分类和新鲜度预测方面明显优于仅使用图像或形状和重量的单一模态方法，多模态集成方法在等级分类中的准确率为86.57%，在新鲜度预测中的准确率为70.83%。所有代码和数据已经公开，促进了透明度、可重复性以及在此领域进一步的研究。
## 677. `cs.LG` - 作为生成模型的神经跳跃ODE [PDF](https://arxiv.org/pdf/2510.02757), [HTML](https://arxiv.org/abs/2510.02757)
### Authors
Robert A. Crowell,Florian Krach,Josef Teichmann
### Background
本文探讨了如何利用神经跳跃 Ordinary Differential Equations (NJODEs)作为Ito过程的生成模型。给定固定基础Ito过程的离散观测样本，NJODE框架可以用于近似Ito过程的漂移系数和扩散系数。在Ito过程满足标准正则性假设的情况下，我们证明了在极限情况下，我们可以恢复真实参数。使用这些学习到的系数来从相应的Ito过程采样，也在极限情况下生成与真实基础过程具有相同分布的样本。与其他生成机器学习模型相比，我们的方法的一个优势在于，它不需要对抗性训练，可以仅作为预测模型直接在观测样本上进行训练，无需在训练过程中生成任何样本来近似分布。
### Innovation
本文提出的创新点在于利用神经跳跃ODEs作为生成模型，对于生成过程中涉及的Ito过程，能够直接且有效地近似漂移和扩散系数，克服了部分模型需要对抗训练的缺点，并且能够自然处理不规则采样和缺失值数据以及路径依赖动态。
### Conclusion
对于Ito过程中的路径依赖系数，NJODE能够在给定过去观察的情况下学习其最优近似。这使得能够从离散、不规则且不完整的过去观察中以最优方式生成新的路径。这种新方法可以在现实应用中直接利用观测数据来生成新的过程路径，而不必生成额外的样本数据。
## 678. `cs.LG` - ReeMark: Reeb Graphs for Simulating Patterns of Life in Spatiotemporal Trajectories [PDF](https://arxiv.org/pdf/2510.03152), [HTML](https://arxiv.org/abs/2510.03152)
### Authors
Anantajit Subrahmanya,Chandrakanth Gudavalli,Connor Levenson,Umang Garg,B.S. Manjunath
### Background
准确模拟人类移动对于城市规划、流行病学和交通管理至关重要。现有的研究方法和模型在捕捉日常生活模式（即生活模式，PoLs）方面存在局限性，难以完全模拟个体和人群水平的移动结构。因此，需要一种新颖的方法来模拟时空轨迹，以保持生活模式的一致性和变化性。
### Innovation
引入了马尔可夫Reeb图（Markovian Reeb Graphs），这是一种新颖的框架，用于模拟时空轨迹，同时保留从基线数据中学习到的生活模式。该方法通过在概率拓扑模型中结合个体和群体级别的移动结构来生成真实且具有一致性和变异性特征的未来轨迹。
### Conclusion
在Urban Anomalies数据集（亚特兰大和柏林子集）上使用Jensen-Shannon发散（JSD），跨群体和代理级别的指标进行评估，表明该方法在保证高保真度的同时，计算效率较高。这些结果证明了马尔可夫Reeb图是跨多种城市环境轨迹模拟的可扩展框架，具有广泛的应用潜力。
## 679. `cs.LG` - 基于Goldstein亚微分的投影随机梯度下降法非凸损失的量化收敛分析 [PDF](https://arxiv.org/pdf/2510.02735), [HTML](https://arxiv.org/abs/2510.02735)
### Authors
Yuping Zheng,Andrew Lamperski
### Background
随机梯度下降(SGD)是机器学习领域大量工作的核心算法。在很多情况下，通过投影来施加约束，这导致了投影随机梯度算法。近年来，大量的研究致力于非凸损失情况下投影SGD的收敛性质，尤其是在渐进和非渐进设置下的研究。虽然对于通过Moreau包络衡量的收敛性，有很强的定量保证，但这些结果不能直接与不受约束的SGD工作进行比较，因为Moreau包络构造改变了梯度。基于梯度映射的其他常见度量方法在不使用减少方差的方法（如批处理）时，无法保证收敛。
### Innovation
本文提出了投影SGD在非凸损失情况下在紧凸集上的分析。收敛性通过梯度到由约束生成的Goldstein亚微分的距离来衡量。提出的收敛标准在未约束情况下直接转化为常用标准，并且我们得到了无需使用方差减少的方法即可收敛的结果。对于独立同分布(IID)或满足混合条件（$L$-混合）的数据，我们获得了渐进收敛和$O(N^{-1/3})$非渐进期望误差界，对于IID超高斯数据，我们获得了几乎肯定的渐进收敛和高概率非渐进$O(N^{-1/5})$误差界。这些是第一个非渐进高概率界，特别是针对投影SGD非凸损失情况的研究。
### Conclusion
本文为非凸损失情况下的投影SGD提供了基于Goldstein亚微分的收敛性分析，提出了无需方差减少方法的收敛标准，并得到了在不同数据条件下（如IID或满足混合条件的数据）的渐进和非渐进收敛性结果，特别是指出了非渐进高概率界对于投影SGD的非凸损失情况下的第一次研究。
## 680. `cs.LG` - 使用HADOF实现可扩展的量子优化：Hamiltonian自适应分解优化框架 [PDF](https://arxiv.org/pdf/2510.02926), [HTML](https://arxiv.org/abs/2510.02926)
### Authors
Namasi G Sankar,Georgios Miliotis,Simon Caton
### Background
量子退火（QA）和QAOA是用于在短期内解决组合问题的有希望的量子优化算法。许多NP-hard问题可以重新表述为二次无约束二进制优化（QUBO），这自然地映射到量子哈密顿量上。然而，当前NISQ设备的有限量子位计数限制了此类算法的实际部署。因此，需要一种自动分割QUBO哈密顿量的方法，使其可以使用基于哈密顿量的优化器（如QAOA、QA或模拟退火）分别优化，并整合成全局解决方案，以克服量子位数量的限制。
### Innovation
我们提出了一种Hamiltonian Auto-Decomposition Optimisation Framework (HADOF)，利用迭代策略自动将QUBO哈密顿量分解为可以独立优化的子哈密顿量，并将这些独立优化的子哈密顿量整合为全局解决方案。HADOF 在问题规模远超可用量子位的情况下具有可扩展性，同时保持与Simulated Annealing (SA) 和CPLEX精确求解器相当的准确性和运行时间。此外，我们在IBM量子计算机上实现了HADOF，展示了其在实际应用中的潜力。
### Conclusion
HADOF提供了一种有效的分解策略，使得在当前NISQ技术的限制下仍能解决大规模优化问题。与Simulated Annealing (SA) 和CPLEX相比，HADOF展示了在大问题规模上的可扩展性，同时保持了高准确性和高效的计算时间。此外，HADOF的实际实现证明了其在量子优化领域的应用前景。
## 681. `cs.LG` - 自动生成用于网络测试的数字孪生体 [PDF](https://arxiv.org/pdf/2510.03205), [HTML](https://arxiv.org/abs/2510.03205)
### Authors
Shenjia Ding,David Flynn,Paul Harvey
### Background
电信网络的操作和管理中软件的增加使用，使行业更加接近实现自主网络操作。由于这种转变，软件部署前需要进行更多的测试和验证。现有模拟或基于硬件的方法之外，数字孪生提供了一个实现这一目标的环境，但它们需要大量时间与人力来配置和执行。
### Innovation
论文探讨了一种自动生成数字孪生的方法，该方法旨在提供与ITU-T自主网络架构实验子系统的高效且准确的验证工具相一致的方法。通过实验结果，论文展示了该方法能够自动创建高效且具有足够准确度的数字孪生，使其可以被纳入现有的验证流程中。
### Conclusion
实验结果显示，自动生成的数字孪生方法是可行的，并且能够提供高效的验证工具。这些数字孪生能够满足ITU-T自主网络架构实验子系统的需求，并被纳入现有的验证流程中。
## 682. `cs.LG` - 帕卓－最优非统一语言生成 [PDF](https://arxiv.org/pdf/2510.02795), [HTML](https://arxiv.org/abs/2510.02795)
### Authors
Moses Charikar,Chirag Pabbaraju
### Background
Kleinberg和Mullainathan（2024）提出了一种语言生成模型：给定一个可数语言集合和对手对集合中某语言L的字符串进行枚举，目标是从目标语言生成新的字符串，使得从某个有限时间点后生成的所有字符串都是有效的。Li、Raman和Tewari（2024）以及Charikar和Pabbaraju（2024）展现了该模型下的强非均匀生成保证，提出了一类算法，在见到一定数量的不同输入字符串后（即取决于L和集合，但不取决于枚举顺序的数量），可以生成新的有效字符串。然而，这些算法的生成时间（t(L)）对于某些语言可以是严格次优的。
### Innovation
本文研究了非统一语言生成在极限条件下的帕卓最优性。提出了一种算法，其生成时间t^∗(L)是（几乎）帕卓最优的：任何满足对某个语言L生成时间严格小于t^∗(L)的其他算法，必须使得另一个语言L'的生成时间严格劣于t^∗(L')。该算法适合于进一步适应噪声和代表性生成的实际应用场景。
### Conclusion
本文揭示了非统一语言生成最优性的实质，提出了适应噪声和代表性生成的帕卓最优算法，展示了算法框架的有效性。该框架为语言生成提供了新的视角和潜在解决方案。
## 683. `cs.LG` - 在日内市场和频率恢复市场联合出价 [PDF](https://arxiv.org/pdf/2510.03209), [HTML](https://arxiv.org/abs/2510.03209)
### Authors
Yiming Zhang,Wolfgang Ridinger,David Wozabal
### Background
随着可再生能源的增加导致供应的波动性增强，电池储能系统(BESS)成为平衡供应和需求的有效解决方案。现有的文献大多将这些市场孤立考虑或简化增量市场中持续交易的本质。
### Innovation
本文提出了一种新颖的方法，旨在优化BESS在多电力市场中的参与，结合了主频储备市场的参与和连续在日内市场的交易。这是通过混合整数线性规划实现日内决策和状态恢复，以及基于学习分类器策略（LCS）来确定最优容量分配实现的，该策略决定在不同市场间的最佳容量分配。
### Conclusion
通过在德国市场一年多的历史数据上进行的外样本回溯测试，我们的方法提高了整体利润超过4%（相比表现最好的静态策略），超过3%（相比一个简单的动态基准）。我们的方法证明了在复杂多市场的环境中动态、基于学习的分配的有效性，与理想的完全明见策略差距仅为4%。
## 684. `cs.LG` - 几乎稳定的聚类带惩罚的计算复杂性 [PDF](https://arxiv.org/pdf/2510.03143), [HTML](https://arxiv.org/abs/2510.03143)
### Authors
Kamyar Khodamoradi,Farnam Mansouri,Sandra Zilles
### Background
本文探讨了具有小加倍维度度量中的k-Means和k-Median聚类问题的稳定性实例的复杂性。这些问题是广泛研究的主题，特别是在低维度欧几里得空间下的乘性扰动鲁棒性（例如（Friggstad等，2019；Cohen-Addad和Schwiegelshohn，2017））。研究采用了更通用的稳定性概念，称为“几乎稳定”，这与Balcan和Liang（2016）提出的（α,ε）扰动鲁棒性相似。此外，还研究了带惩罚的k-Means和k-Median聚类问题，每条数据点要么分配给聚类中心，要么付出惩罚。某些特定的几乎稳定的k-Means和k-Median（带惩罚）是可以多项式时间内解决的。同时，也在计算难度方面研究了几乎稳定的k-Means和k-Median（带惩罚）以及（1 + 1/poly(n)）稳定实例的问题，证明了任何精确算法解决几乎稳定实例的运行时间下界是超多项式的，基于广泛接受的指数时间假设（ETH）。
### Innovation
本文创新性地采用了一种更通用的稳定性概念，称为“几乎稳定”，这种概念更接近于（α,ε）扰动鲁棒性，并将其应用到带惩罚的k-Means和k-Median聚类问题中。此外，引入了（1 + 1/poly(n)）稳定实例的概念，并证明了几乎所有稳定实例和部分（1 + 1/poly(n)）稳定实例的计算复杂性结果。
### Conclusion
研究证明了某些特殊情况下几乎稳定的k-Means和k-Median（带惩罚）问题是可以在多项式时间内解决的。同时，证明了几乎所有稳定实例和特定（1 + 1/poly(n)）稳定实例的计算复杂性，在广泛的指数时间假设（ETH）下，任何精确算法解决超多项式的时间下界。
## 685. `cs.LG` - 一种近最优且低切换的强化学习广义函数近似算法 [PDF](https://arxiv.org/pdf/2311.15238), [HTML](https://arxiv.org/abs/2311.15238)
### Authors
Heyang Zhao,Jiafan He,Quanquan Gu
### Background
强化学习中的探索-利用困境一直是使用复杂模型类的关键挑战。本研究关注的是利用广义函数近似进行强化学习的一般模型选择问题，特别是在探索和利用之间取得权衡的挑战。
### Innovation
提出了一个新的算法，MQL-UCB，在此算法设计中包括：(1) 一种通用的确定性策略切换策略，其切换成本低；(2) 一种单调的价值函数结构，通过精细控制函数类的复杂性实现；(3) 一种基于方差加权回归方案，能高效地利用历史轨迹。这些创新使得MQL-UCB算法在特定条件下达到了近最优的遗憾率和接近最优的策略切换成本。
### Conclusion
本工作揭示了设计样本效率和部署效率高的Q-学习算法的路径，尤其是在非线性函数近似的情况下能够得到有效证明。
## 686. `cs.LG` - amelia: 机场表面移动预测的大规模数据集及基准 [PDF](https://arxiv.org/pdf/2407.21185), [HTML](https://arxiv.org/abs/2407.21185)
### Authors
Ingrid Navarro,Pablo Ortega-Kral,Jay Patrikar,Haichuan Wang,Alonso Cano,Zelin Ye,Jong Hoon Park,Sebastian Scherer,Jean Oh
### Background
随着航空旅行需求的增加，现有的航空基础设施受到压力。在美国，超过90%的机场控制塔人员不足，未达到联邦航空管理局(FAA)和工会的标准，这在一定程度上导致了接近碰撞和安全关键事件的增加，凸显了需要先进的空中交通管理技术来确保安全和高效的运营。公开数据中缺乏大规模的机场表面移动数据集阻碍了规模化的通用方法的发展。
### Innovation
本文介绍了Amelia-42，这是一个首创的大规模机场表面移动原始报告集合，来源于联邦航空局系统范围信息管理(SWIM)计划，包含42个美国机场超过两年的轨迹数据（约9.19 TB）。该研究还开源了数据处理工具，并提供了Amelia42-Mini，以及一个由Amelia10-Bench和Amelia-TF组成的轨迹预测基准，其中Amelia10-Bench使用292天的10个机场数据，Amelia-TF是基于转换器的多智能体轨迹预测基线。
### Conclusion
所有资源都可以在我们的网站上获得：this https URL和this https URL。
## 687. `cs.LG` - 对于准确因果效应估计的超参数调整挑战 [PDF](https://arxiv.org/pdf/2303.01412), [HTML](https://arxiv.org/abs/2303.01412)
### Authors
Damian Machlanski,Spyridon Samothrakis,Paul Clarke
### Background
机器学习（ML）在从观测数据估计治疗对结果的影响方面发挥着越来越重要的作用。已提出多种ML方法（因果估计器），但这些方法在超参数调整方面需要大量的工作。与非因果预测任务相比，因果推断任务在选择调优指标方面尚未达成共识，导致因果模型的比较困难。此外，没有一个理想的指标可以调优因果估计器，因此需要依赖代理指标。更重要的是，因果推断中的模型选择涉及多个方面（因果估计器、ML回归器、超参数、指标），使其问题进一步复杂化。文章通过严格的实证研究探讨了这些组件的重要性，并使用多种常用的因果估计器、回归器和指标应用于四个知名因果推断基准数据集来评估其组合情况。结果显示，超参数调整能显著提高因果效应估计的表现（平均从65%提高到81%，个体化从50%提高到57%），且标准的评估指标在不同场景下的表现可能不一致。
### Innovation
通过广泛的实证研究评估了因果估计器、回归器、超参数和评估指标的组合。发现超参数调整对提高因果效应估计的表现至关重要，并且指出标准评估指标在不同场景下的表现可能不一致。
### Conclusion
展示了没有一种统一的评估指标可以在所有情况下达到最先进的因果模型评估表现，强调了进一步研究的必要性。
## 688. `cs.LG` - 预训练编码器的互信息引导后门缓解技术 [PDF](https://arxiv.org/pdf/2406.03508), [HTML](https://arxiv.org/abs/2406.03508)
### Authors
Tingxu Han,Weisong Sun,Ziqi Ding,Chunrong Fang,Hanwei Qian,Jiaxun Li,Zhenyu Chen,Xiangyu Zhang
### Background
自监督学习(SSL)越来越多地用于无需标记数据即可预训练编码器。基于这些预训练编码器的下游任务可以达到接近最新的性能水平。然而，通过SSL预训练的编码器容易受到后门攻击的影响，已有研究证实了这一点。尽管设计了许多针对下游任务模型的后门缓解技术，但它们在应用于预训练编码器时的效果受到限制，并且受到缺乏预训练阶段标签信息的影响。因此，需要一种新的方法来解决针对预训练编码器的后门攻击问题。
### Innovation
本文创新性地提出了一种名为MIMIC的互信息引导后门缓解技术。MIMIC将可能被后门污染的编码器视为教师网络，并使用知识蒸馏从教师网络中提炼一个干净的学生编码器。与现有的知识蒸馏方法不同，MIMIC初始化学生编码器的权重为随机值，不从教师网络中继承后门。MIMIC通过利用每一层之间的互信息和提取的特征定位教师网络中的良性知识，并将这些知识用于从教师网络向学生网络转移清洁特征以进行蒸馏。MIMIC通过两方面的蒸馏损失来进行蒸馏，包括复制损失和注意力损失，旨在同时缓解后门攻击和保持编码器的性能。
### Conclusion
我们在SSL中的两种后门攻击中进行的评估表明，MIMIC只需使用不到5%的干净数据即可显著降低攻击成功率，超越了七种现有的最先进的后门缓解技术。
## 689. `cs.LG` - 利用单个线性层解决向量量化模型中的表示坍缩问题 [PDF](https://arxiv.org/pdf/2411.02038), [HTML](https://arxiv.org/abs/2411.02038)
### Authors
Yongxin Zhu,Bocheng Li,Yifei Xin,Zhihua Xia,Linli Xu
### Background
向量量化（VQ）对于无监督学习中离散化连续表示至关重要，但它会导致表示坍缩，造成码本利用率低并限制了可扩展性。现有解决方案通常依赖复杂的优化或减少潜在维度，这会削弱模型容量并无法完全解决问题。现有方法的主要挑战在于码本优化的分离性，即仅通过梯度下降更新少数码矢量。
### Innovation
该论文提出了一种名为SimpleVQ的方法，通过在潜在基底上的可学习线性变换层重新参数化码矢量，优化整个线性空间而不是最近的个体码矢量。虽然两个线性矩阵的乘法等同于应用一个线性层，但这种方法简单有效避免了表示坍缩。实验证明，SimpleVQ提高了码本利用率，易于实现，并且在不同模态和架构下具有良好的泛化能力。
### Conclusion
广泛的实验在图像和音频任务上证明了SimpleVQ在提高码本利用率、易于实现和良好泛化能力方面的优势。该方法的代码可以在以下链接获得。
## 690. `cs.LG` - 利用潜在集成的随机共振进行对抗攻击的测试时防御 [PDF](https://arxiv.org/pdf/2510.03224), [HTML](https://arxiv.org/abs/2510.03224)
### Authors
Dong Lao,Yuxiang Zhang,Haniyeh Ehsani Oskouie,Yangchao Wu,Alex Wong,Stefano Soatto
### Background
当前已有的一些对抗攻击防御机制主要依赖于特征过滤或平滑处理，但在实际应用中可能会导致信息丢失。本文旨在提出一种新的测试时间防御机制，通过引入不可见的图像扰动，来改变模型预测，同时最大限度地减少信息损失。不同于现有的通过特征过滤或平滑处理的方法，本文提出了一种“用噪声对抗噪声”的策略，利用随机共振增强模型的鲁棒性，同时最小化信息损失。该方法引入了小的输入图像平移扰动，对转换后的特征嵌入进行对齐并聚合后再映射回原始参考图像。这种方法可以在不同架构的现有网络中进行部署，无需引入额外的网络模块或对特定攻击类型进行微调，不需要经过训练，具有架构无关性和攻击无关性.
### Innovation
本文提出了一种基于随机共振的测试时间防御机制，通过引入小的输入图像平移扰动来改变模型预测，同时最大限度地减少信息损失，不同于现有的特征过滤或平滑处理方法，具有架构无关性和攻击无关性。该方法能够在不引入额外网络模块或特定攻击类型微调的情况下，部署在各种现有网络架构上，具有高度的灵活性和实用性。实验结果显示，该方法在图像分类和密集预测任务（如立体匹配和光学流）中，具有鲁棒性和通用性，特别是在对抗攻击下性能恢复方面表现突出。
### Conclusion
本文提出了一种训练免费、架构无关、攻击无关的对抗攻击测试时间防御方法，能够显著提升模型在对抗攻击下的鲁棒性，对于图像分类、立体匹配和光学流等密集预测任务具有广泛应用价值。该方法不仅在图像分类任务上实现了最先进的鲁棒性能，还首次提供了一种通用的密集预测任务测试时间防御方法，证明了模型在多种类型的对抗攻击下的适应性和实用性。
## 691. `cs.LG` - ColNet: Decentralized Federated Multi-task Learning System的协作优化 [PDF](https://arxiv.org/pdf/2501.10347), [HTML](https://arxiv.org/abs/2501.10347)
### Authors
Chao Feng,Nicolas Fazli Kohler,Zhi Wang,Weijie Niu,Alberto Huertas Celdran,Gerome Bovet,Burkhard Stiller
### Background
现有的联邦学习(Federated Learning, FL)和多任务学习(Multi-Task Learning, MTL)研究主要集中在数据异质性（例如，解决非IID数据问题）上，而较少关注任务异质性，即客户端解决本质上不同的任务。此外，大部分工作依赖于集中式的设置，由服务器管理联邦学习过程，因此更加具有挑战性的去中心化联邦多任务学习(Decentralized Federated Multi-Task Learning, FMTL)领域尚未被充分探索。
### Innovation
本文通过提出ColNet框架填补了这一空白。ColNet将模型分为骨干和任务特定的头部，并基于模型和数据敏感度使用自适应聚类形成任务一致的客户端组。在组内对骨干进行平均，并由组领导进行跨组聚合。在多种数据集和联邦环境中，ColNet在标签和任务异质性下表现超越了竞争对手的方法，并对投毒攻击具有鲁棒性。
### Conclusion
ColNet框架在去中心化的联邦多任务学习环境中表现出色，针对任务异质性进行了优化，并在多种条件下表现出色，对于投毒攻击具有鲁棒性。
## 692. `cs.LG` - Cache-to-Cache: 直接大规模语言模型间语义通信 [PDF](https://arxiv.org/pdf/2510.03215), [HTML](https://arxiv.org/abs/2510.03215)
### Authors
Tianyu Fu,Zihan Min,Hanling Zhang,Jichao Yan,Guohao Dai,Wanli Ouyang,Yu Wang
### Background
多LLM系统利用不同大型语言模型的互补优势，实现单一模型无法达到的性能和效率提升。现有设计中，LLM们通过文本进行通信，这使得内部表示需要转换为输出标记序列，从而损失了丰富的语义信息，并且引入了逐标记生成的延迟。为了克服这些限制，该研究调查了LLM是否能够超越文本进行通信。实验证明，增强KV-Cache语义可以提升响应质量而不增加缓存大小，支持使用KV-Cache作为模型间通信的有效媒介。在此基础上，本文提出了Cache-to-Cache (C2C) 新范式，用于直接语义通信。
### Innovation
C2C 使用神经网络投影并融合源模型的 KV 缓存与目标模型的缓存，以实现直接语义传递。引入可学习门控机制选择受益于缓存通信的目标层。相比于文本通信，C2C 利用了两种模型深层次的专有语义，而避免了显式的中间文本生成。实验证明，C2C 达到的平均准确率比单一模型高8.5-10.5%，比文本通信约高3.0-5.0%，且平均延迟减少了1.0倍。
### Conclusion
本文提出了Cache-to-Cache，一种新的大规模语言模型间直接语义通信范式。实验显示，C2C 在准确率和速度上都优于现有的文本通信方式。代码已提供。
## 693. `cs.LG` - 基于刺激电压的锋电位起始时间预测：经典方法与量子启发的方法比较 [PDF](https://arxiv.org/pdf/2510.03155), [HTML](https://arxiv.org/abs/2510.03155)
### Authors
Stevens Johnson,Varun Puram,Johnson Thomas,Acsah Konuparamban,Ashwin Kannan
### Background
准确建模神经元锋电位（AP）起始时间对于理解神经编码危险信号至关重要。传统的漏电整流放电（LIF）模型虽然广泛应用，但在预测AP起始潜伏期时表现出较高的相对误差，尤其是在强或快速变化的刺激下。研究表明，需有新的方法来捕捉神经元放电的生物变异性与不确定性。
### Innovation
本文提出了一种量子启发的漏电整流放电（QI-LIF）模型，将AP起始视为一个时间上的高斯波包所表示的随机事件。通过系统比较经典LIF模型和QI-LIF模型在不同强度刺激下的锋电位起始时间预测误差，结果表明QI-LIF模型显著降低了预测误差，特别是在高强度刺激下，这与观察到的生物反应一致。这表明量子启发式的计算框架在神经建模准确性方面的潜力，并为量子工程方法在计算中模拟大脑提供了启示。
### Conclusion
研究表明，QI-LIF模型在预测锋电位起始时间方面表现更好，特别是在高强度刺激下。这为神经编码和量子工程提供了新的视角。
## 694. `cs.LG` - 基于图神经网络的输电网络拓扑控制：母线信息不对称与异构表示 [PDF](https://arxiv.org/pdf/2501.07186), [HTML](https://arxiv.org/abs/2501.07186)
### Authors
Matthijs de Jong,Jan Viebahn,Yuliya Shapovalova
### Background
可再生能源的普及、电力系统的电能化导致电网拥堵成为一个迫切的问题。传统的方法在网络拓扑发现方面速度过慢，无法实际应用。近期的研究转向了机器学习（ML）作为高效的替代方案。图神经网络（GNNs）特别适合用于拓扑控制，因为它们能够建模电力网络的图结构。本文探讨了图表示对GNN的有效性影响。研究发现，流行的同质图表示存在母线信息不对称的问题，并提出了异构图表示来解决这一问题。将GNNs（使用两种表示法）和完全连接的神经网络（FCNN）基线应用于模仿学习任务，并通过分类准确度和电网运行能力进行评估。研究发现，异构GNNs在分布内网络配置中表现最好，其次是FCNNs，最后是同构GNNs。还发现，两种GNN类型在分布外网络配置中的泛化能力优于FCNNs.
### Innovation
提出了异构图表示来解决同质图表示中的母线信息不对称问题，该研究发现异构GNNs在分布内网络配置中的表现优于同构GNNs和FCNNs，并且GNNs在分布外网络配置中的泛化能力优于FCNNs.
### Conclusion
异构GNNs在输电网络拓扑控制中表现出更好的效果，特别是在分布内网络配置中。此外，两种GNN类型在分布外网络配置中的泛化能力优于FCNNs.
## 695. `cs.LG` - FinP: 在联邦学习中通过解决隐私风险差异性来实现隐私公平性 [PDF](https://arxiv.org/pdf/2502.17748), [HTML](https://arxiv.org/abs/2502.17748)
### Authors
Tianyu Zhao,Mahmoud Srewa,Salma Elmalaki
### Background
在以人类为中心的联邦学习（FL）环境中，数据的分散性要求在客户端之间公平分配隐私风险。确保机器学习的公平性需要扩展到隐私维度，特别是在需要保护客户端隐私的联邦学习场景中。
### Innovation
提出了一种名为FinP的新框架，专门解决隐私风险的不公问题，通过减少来源推理攻击（SIA）的不公易感性来减少隐私风险的差异。FinP采用双管齐下的策略：（1）服务器端自适应聚合，动态调整客户端对全局模型的贡献以促进公平性；（2）客户端正则化，提高客户端的隐私鲁棒性。
### Conclusion
FinP在Human Activity Recognition（HAR）和CIFAR-10数据集上的全面评估显示，与最先进的方法相比，该方法在HAR数据集上实现了隐私公平性的提升，并在CIFAR-10数据集上将组别间的隐私风险不平等性减少了57.14%，同时显著降低了SIA风险，这表明FinP能够在不牺牲效用的情况下建立隐私公平性。
## 696. `cs.LG` - 具有高斯尾部目标的生成扩散模型的Wasserstein界 [PDF](https://arxiv.org/pdf/2412.11251), [HTML](https://arxiv.org/abs/2412.11251)
### Authors
Xixian Wang,Zhongjian Wang
### Background
本文分析的是评分生成模型的生成数据与实际数据分布之间的Wasserstein距离估计。研究以数据分布具有初始停止技术和有限支撑的高斯类型尾部行为为基础，并假设评分的ε精确近似。
### Innovation
提出了一种估计数据分布和生成模型之间Wasserstein距离的方法，采样复杂度为$text{O}(text{√d})$，具有对数常数因子。其分析关键在于通过对高斯尾部假设和从热核的维度无关估计得到的评分的全局Lipschitz边界，得出复杂度为平方根的协方差算子迹的线性比例界。
### Conclusion
复杂度表现为协方差算子迹平方根的线性比例，具有对数常数因子。这一方法可以适配具有有限支撑的数据分布目标。
## 697. `cs.LG` - 从轨迹偏好反馈中学习最优策略 [PDF](https://arxiv.org/pdf/2501.18873), [HTML](https://arxiv.org/abs/2501.18873)
### Authors
Akhil Agnihotri,Rahul Jain,Deepak Ramachandran,Zheng Wen
### Background
强化学习从人类反馈（RLHF）已经成为使生成模型对齐的强大方法，但其依赖于学习的奖励模型使其容易受到误指定和奖励投机的影响。基于偏好强化学习（PbRL）通过直接利用轨迹的嘈杂二进制比较，提供了更稳健的选择。该研究关注PbRL中的最优策略识别问题，特别是在生成模型多轮交互后的后训练优化中。在这种环境中，学习结合了可能偏差或分布外的离线偏好数据集，以及在线的纯探索，因此系统性在线学习变得至关重要。
### Innovation
提出了一种新型算法Posterior Sampling for Preference Learning（PSPL），该算法受Top-Two Thompson Sampling启发，维护了对奖励模型和动力学的后验分布。此外，还提供了PbRL的首个贝叶斯简单后悔保证，提出了高效的近似方法，在模拟和图像生成基准测试中优于现有基线。
### Conclusion
研究通过提出PSPL算法，克服了PbRL中由于数据偏差或分布外导致的系统性学习挑战。同时该工作还为PbRL提供了理论保证，并在实际应用中展示了算法的有效性。
## 698. `cs.LG` - 多保真度控制变分方法的策略梯度估计 [PDF](https://arxiv.org/pdf/2503.05696), [HTML](https://arxiv.org/abs/2503.05696)
### Authors
Xinjie Liu,Cyrus Neary,Kushagra Gupta,Wesley A. Suttle,Christian Ellis,Ufuk Topcu,David Fridovich-Keil
### Background
许多增强学习（RL）算法在操作系统中部署或在计算成本高昂的高保真度模拟中训练时不可行，因为它们需要大量数据。低保真度模拟器，如降阶模型、启发式奖励或生成的世界模型，可以低成本地提供有用的RL训练数据，即使它们在零样本迁移中过于粗糙。
### Innovation
提出了多保真度策略梯度（MFPG），这是一种RL框架，通过从目标环境采集少量数据并与从大量低保真度模拟数据形成的控制变数相结合，构造出无偏且方差减小的目标策略梯度估计器。MFPG算法是基经典的REINFORCE算法的多保真度变体，证明在标准假设下，MFPG估计器保证了REINFORCE在目标环境中局部最优策略的渐进收敛，并且在低保真度数据单独训练中具有更快的有限样本收敛速度。
### Conclusion
在具有有限高保真度数据、丰富低保真度数据的模拟机器人基准任务中，MFPG算法能够在小到中等动态缺口情况下可靠地提升中值性能，即使在动力学缺口较大时也能表现出最强的鲁棒性。即便在低保真度奖励设定不准确的情况下，MFPG也依然保持有效。因此，MFPG不仅为高效的仿真到实际转换提供了新的范式，还提供了一种处理策略性能与数据收集成本之间权衡的原理性方法。
## 699. `cs.LG` - 学习在保持秩下事实结果 [PDF](https://arxiv.org/pdf/2502.06398), [HTML](https://arxiv.org/abs/2502.06398)
### Authors
Peng Wu,Haoxuan Li,Chunyuan Zheng,Yan Zeng,Jiawei Chen,Yang Liu,Ruocheng Guo,Kun Zhang
### Background
因果推理旨在根据已知的观察治疗和实况结果，在个体层面上估算反事实结果，其应用领域广泛，包括流行病学、计量经济学和管理科学。以前的方法依赖于已知的结构因果模型（SCM），或假设外生变量的同质性和结果与外生变量之间的严格单调关系。
### Innovation
本文提出了一个原则性的方法来识别和估计反事实结果。通过引入简单的秩保持假设，不需要依赖已知的结构因果模型即可以识别反事实结果。在此基础上，提出了一个新颖的理想损失函数，用于理论上无偏学习反事实结果，并进一步发展了一种核基估计器，用于其实证估计。理论分析显示，秩保持假设不超过同质性和严格单调性假设，表明提出的理想损失是凸的，并且提出的估计器是无偏的。通过广泛的半合成和现实世界实验展示了所提出方法的有效性。
### Conclusion
本文方法的有效性已通过广泛的半合成和现实世界实验得到验证，并证明秩保持假设不超过之前的假设，且提出的理想损失和估计器具有理论上的优越性。
## 700. `cs.LG` - 回溯还是不回溯：当顺序搜索限制模型推理时 [PDF](https://arxiv.org/pdf/2504.07052), [HTML](https://arxiv.org/abs/2504.07052)
### Authors
Tian Qin,David Alvarez-Melis,Samy Jelassi,Eran Malach
### Background
近年来，大型语言模型（LLMs）的推理能力得到了显著提升，尤其是在涉及搜索和回溯的技术下。回溯通过长链推理（CoT）生成方法实现顺序、线性探索，从而自然地扩展了测试时间计算。然而，这并不是唯一能扩展测试时间计算的方法：并行采样加最优选择提供了一种同时生成多种解的替代方法。尽管顺序搜索的使用正在增长，但其在固定计算预算下的优势仍然没有被完全理解。
### Innovation
本文系统地比较了这两种方法在两个具有挑战性的推理任务（CountDown和Sudoku）上的表现。出乎意料的是，发现顺序搜索在CountDown任务上表现不佳，但在Sudoku任务上表现良好，表明回溯并不总是有益的。同时，本文还分析了两个可能导致回溯性能下降的因素：（1）在固定搜索轨迹下进行训练可以将模型锁定到次优策略中，（2）显式链式推理监督可能会抑制隐式（非言语化）推理。进一步将分析扩展到强化学习（RL），发现具有回溯能力的模型可以从RL微调中显著受益，而没有回溯能力的模型仅能获得有限的混合收益。
### Conclusion
这些发现挑战了普遍认为回溯在所有情况下都能增强LLM推理的认知，揭示了任务结构、训练数据、模型规模和学习范式之间的复杂互动。
## 701. `cs.LG` - 关于扩展大语言模型推理效果的采样多样性影响 [PDF](https://arxiv.org/pdf/2502.11027), [HTML](https://arxiv.org/abs/2502.11027)
### Authors
Tianchun Wang,Zichuan Liu,Yuanzhou Chen,Jonathan Light,Weiyang Liu,Haifeng Chen,Xiang Zhang,Wei Cheng
### Background
大语言模型（LLM）的扩展推理对于实现更好的性能至关重要。研究表明，利用多样性已经证明是提高性能的有效方式。本研究关注如何通过促进提示的多样性来进一步改善大语言模型的扩展推理效果。研究发现，提示多样性能够显著降低错误率，并通过系统的实验验证了这一点。
### Innovation
研究通过理论解释了为何多样化的采样能够改善“Best-of-N”扩展推理，并分析了扰动的准确性，提出适度相关性的扰动能够提高性能，并提出了一系列有效的扰动策略，包括任务级别和查询级别，并分析了这些策略成功的条件。
### Conclusion
研究系统地评估了多样化的采样在不同任务中的效果，发现相对增益分别为：推理任务中EM@100提高了10.8%，数学任务中9.6%，以及代码生成任务中的Pass@100提高了9.5%。
## 702. `cs.LG` - 激活的LoRA: 用于内在操作的微调大语言模型 [PDF](https://arxiv.org/pdf/2504.12397), [HTML](https://arxiv.org/abs/2504.12397)
### Authors
Kristjan Greenewald,Luis Lastras,Thomas Parnell,Vraj Shah,Lucian Popa,Giulio Zizzo,Chulaka Gunasekara,Ambrish Rawat,David Cox
### Background
低秩适应（LoRA）已成为一种高效的框架，用于调整大型基础模型的权重，已成为数据驱动定制LLMs的首选方法。尽管LoRA能够实现高度定制化的行为和能力，但在多轮对话环境中切换LoRA时效率低下，因为每次生成之前都需要重新计算整个对话历史的键值（KV）缓存。
### Innovation
提出了激活的LoRA（aLoRA）架构，这是一种修改后的适应器架构，它仅在aLoRA被调用后调整序列中后续标记的权重。这一改变允许aLoRA接受基模型输入字符串的KV缓存，使得在链中可以随时激活aLoRA而无需重新计算先前提取的键和值。此方法可以构建我们称之为内在操作的特殊模型，这些模型能够针对输入链或对话的特定部分执行特定操作，否则默认由基础模型处理。我们还训练了一组基于aLoRA的内在模型，展示了与标准LoRA相当的准确率，同时大幅提高了推理效率。
### Conclusion
aLoRA方法能够有效提升切换不同LoRA时的效率，适用于需要频繁调整适应权值的大语言模型场景，显著提高了推理效率，保持了与标准LoRA相当的模型性能。
## 703. `cs.LG` - 在图机器学习中量化长距离交互：一个大规模图数据集和一种度量方法 [PDF](https://arxiv.org/pdf/2503.09008), [HTML](https://arxiv.org/abs/2503.09008)
### Authors
Huidong Liang,Haitz Sáez de Ocáriz Borde,Baskaran Sripathmanathan,Michael Bronstein,Xiaowen Dong
### Background
现有的大多数数据集专注于小图，适应归纳学习任务，缺乏对长距离交互的深入见解。当前的评估主要通过比较使用全局注意力的模型（如图变压器）与使用局部邻域聚合的模型（如消息传递神经网络），而没有直接衡量长距离依赖性.
### Innovation
本文引入City-Networks，这是一个源自真实城市道路网络的大规模推断学习数据集。该数据集包含了超过10万个节点的图，并具有比现有基准图更大的直径，自然地包含了长距离信息。此外，我们提出了一种基于远处跳跃邻居雅可比的通用度量方法，以临界量度长距离依赖性。我们还通过强调过度平滑和影响得分稀释对数据集设计和提出度量方法进行了理论上的解释.
### Conclusion
通过City-Networks数据集和提出的基于邻居远离跳跃雅可比的度量方法，本文确立了图神经网络中长距离交互研究的稳健基础。
## 704. `cs.LG` - 重新审视概念擦除的脆弱性及一种新方法 [PDF](https://arxiv.org/pdf/2502.17537), [HTML](https://arxiv.org/abs/2502.17537)
### Authors
Alex D. Richardson,Kaicheng Zhang,Lucas Beerens,Dongdong Chen
### Background
文本到图像的扩散模型的广泛使用引发了严重的隐私和安全问题，特别是在生成受版权保护或有害的图像方面。针对这些担忧，已经开发了概念擦除（防护）方法，通过后处理微调来“遗忘”特定概念。然而，最近的概念恢复（攻击）方法表明，这些被擦除的概念可以通过对抗性提示被恢复出来，揭示了当前防护机制中的关键漏洞。在本文中，作者深入研究了对抗性脆弱性的根本来源，并发现这些脆弱性存在于概念擦除模型的提示嵌入空间中，这一特征源于原始非擦除预训练模型。
### Innovation
作者提出了名为RECORD的新型坐标下降基的概念恢复算法，该算法在性能上远远优于现有方法，计算性能上最高可提升17.8倍，并且展开了广泛的实验以评估其计算性能折衷，并提出了加速策略。
### Conclusion
本文深入探讨了概念擦除防护机制中的对抗性漏洞来源，并提出了一种新的坐标下降基的恢复算法RECORD，该算法的性能显著优于现有方法，作者还进行了实验以评估计算性能折衷，并为优化计算效率提出了策略。
## 705. `cs.LG` - 关于AdamW在$boldsymbol{text{ℓ}_1}$范数下的$O(frac{boldsymbol{text{√d}}}{K^{1/4}})$收敛速率 [PDF](https://arxiv.org/pdf/2505.11840), [HTML](https://arxiv.org/abs/2505.11840)
### Authors
Huan Li,Yiming Dong,Zhouchen Lin
### Background
AdamW 作为训练大型语言模型的默认优化器，在深度学习中取得了显著成功，但其收敛行为尚未得到理论上的充分理解。
### Innovation
该论文建立了 AdamW 在 $boldsymbol{text{ℓ}_1}$ 范数下的收敛速率 $frac{1}{K}text{∑}_{k=1}^{K}Etext{[}||abla f(x^k)||_1text{]} text{≤} O(frac{boldsymbol{text{√d}}C}{K^{1/4}})$，其中 $K$ 表示迭代次数，$d$ 表示模型维度，$C$ 与 SGD 的最优收敛速率中的常数相匹配。
### Conclusion
研究结果表明，AdamW 的收敛速率可以视为类似于 SGD 的最优 $O(frac{1}{K}text{∑}_{k=1}^{K}Etext{[}||abla f(x^k)||_2text{]} text{≤} O(frac{C}{K^{1/4}})$ 收敛速率，并将结果推广至具备双动量机制的 NAdamW，表明其保持相同的收敛速率。
## 706. `cs.LG` - Graph-Reward-SQL：通过图匹配和逐步奖励实现无执行的基于强化学习的Text-to-SQL [PDF](https://arxiv.org/pdf/2505.12380), [HTML](https://arxiv.org/abs/2505.12380)
### Authors
Han Weng,Puzhen Wu,Longjie Cui,Yi Zhan,Boyi Liu,Yuanfeng Song,Dun Zeng,Yingxiang Yang,Qianru Zhang,Dong Huang,Xiaoming Yin,Yang Sun,Xing Chen
### Background
现有的Text-to-SQL任务的强化学习方法通常依赖于基于执行的或基于大型语言模型的Bradley-Terry奖励模型，前者由于反复的数据库调用导致执行延迟高，后者则增加了显著的GPU内存开销，这两者都严重影响了强化学习管道的效率和可扩展性。
### Innovation
提出了名为Graph-Reward-SQL的新型奖励模型框架，采用GMNScore结果奖励模型，通过SQL图表示提供准确的奖励信号，大幅减少时间和GPU内存使用量。进一步介绍了StepRTM逐步奖励模型，对公共表表达式（CTE）子查询提供中间指导，鼓励SQL的功能正确性和易读性。
### Conclusion
在标准基准Spider和BIRD上的广泛对比和消融实验表明，该方法在所有评估指标上均优于现有奖励模型。
## 707. `cs.LG` - OT 分数：基于OT的源码无监督领域适应置信度分数 [PDF](https://arxiv.org/pdf/2505.11669), [HTML](https://arxiv.org/abs/2505.11669)
### Authors
Yiming Zhang,Sitong Liu,Alex Cloninger
### Background
当前的分布对齐方法在源码无监督领域适应(SFUDA)中存在计算和理论限制，尤其是在没有目标标签的情况下估计分类性能和置信度方面。现有的理论框架通常会导致计算不可行的问题，并不能充分反映对齐算法的特性。因此，研究提出了新的理论分析方法，用以解决这些问题并提供更可靠的置信度估计.
### Innovation
介绍了一种基于半离散最优传输(Semi-Discrete Optimal Transport)对齐的新颖理论分析方法，进而提出了OT分数(OT score)作为置信度度量标准。OT分数具有直观的解释性和严格的理论基础，能够为任何给定的目标伪标签集提供原则性的不确定性估计。实验结果表明，OT分数在置信度评分方面优于现有的方法，并且可以在训练过程中通过对权重的重新分配来改善SFUDA性能。此外，它还提供了一个可靠的目标标签无关的模型性能代理指标.
### Conclusion
OT分数通过基于半离散最优传输对齐方法的新颖理论分析，为SFUDA提供了更可靠的置信度估计。实验结果验证了其有效性和优越性，表明它不仅能改进SFUDA性能，还能作为一种标签无关的模型性能代理。
## 708. `cs.LG` - DualRAG: 一种集成推理与检索的双重过程方法用于多跳问答 [PDF](https://arxiv.org/pdf/2504.18243), [HTML](https://arxiv.org/abs/2504.18243)
### Authors
Rong Cheng,Jinyi Liu,Yan Zheng,Fei Ni,Jiazhen Du,Hangyu Mao,Fuzheng Zhang,Bo Wang,Jianye Hao
### Background
多跳问答（MHQA）任务在现实世界应用中普遍存在，带来了在不同知识领域内进行多层次推理的挑战。尽管现有方法通过迭代检索有所改进，但仍然难以识别和组织动态知识。
### Innovation
提出了一种协同的双重过程框架DualRAG，无缝地结合了推理和检索。DualRAG 通过两个紧密耦合的过程：增强推理查询（RaQ）和逐步知识聚合（pKA）来运作。这两个过程协同工作：随着 RaQ 导航推理路径并生成有针对性的查询，pKA 确保了新获取的知识可以系统地整合以支持连贯的推理。这创造了知识丰富和推理改进的良性循环。通过针对性的微调，DualRAG 保留了其复杂的推理和检索能力，即使在较小规模的模型中也展示了其多样性和核心优势。
### Conclusion
大量的实验显示，这种双重过程方法显著提高了答案的准确性和连贯性，有时甚至超过了通过Oracle知识访问所获得的性能。这些结果确立了DualRAG作为复杂多跳推理任务的稳健且高效的解决方案。
## 709. `cs.LG` - 理解偏好学习中的性能差距：RLHF与DPO的二分法 [PDF](https://arxiv.org/pdf/2505.19770), [HTML](https://arxiv.org/abs/2505.19770)
### Authors
Ruizhe Shi,Minhak Song,Runlong Zhou,Zihan Zhang,Maryam Fazel,Simon S. Du
### Background
本文对强化学习从人类反馈（RLHF）和直接偏好优化（DPO）在表示差距下的性能差距进行了细致的理论分析。研究将此差距分解为两个来源：在精确优化下的显式表示差距和在有限样本下的隐式表示差距。并且在不同的优化环境下，探讨了不同模型的上下文表达能力对最终策略质量的影响，以及RLHF、DPO和在线DPO的表现对比。特别是在隐式稀疏的最佳奖励设定下，证明了RLHF所需样本数远远少于DPO，从而提高了两阶段学习的统计优势。
### Innovation
本文将性能差距分解为两种不同类型的表示差距，并通过严格的理论分析和实际构造展示了在不同类型的情况下的性能差异，特别是指出在线DPO在特定条件下可以超越RLHF和标准DPO，以及RLHF在隐式稀疏奖励场景下需要更少样本的优势。
### Conclusion
本文提供了对RLHF和DPO在不同优化环境下的性能差距的全面理解，并提出实用的见解，以确定哪种方法在特定场景下更优。
## 710. `cs.LG` - 标准多臂牌局实验中LLMs和人类探索-利用策略的比较：认知科学和精神病学文献启示 [PDF](https://arxiv.org/pdf/2505.09901), [HTML](https://arxiv.org/abs/2505.09901)
### Authors
Ziyuan Zhang,Darcy Wang,Ningyuan Chen,Rodrigo Mansur,Vahid Sarhangian
### Background
大型语言模型（LLMs）在复杂的序列决策环境中被用于模拟或自动化人类行为。文章探讨了LLMs在决策过程中是否展现出与人类相似的行为模式，以及是否能够获得可比甚至更优的性能。研究特别聚焦于探索-利用（E&E）权衡这一动态决策的关键方面。为了对比LLMs、人类及多臂牌局算法在这方面的策略，文章采用了认知科学和精神病学文献中引入的经典多臂牌局实验。
### Innovation
文章通过使用可解释的选择模型来捕捉参与者（包括LLMs、人类及MAB算法）的E&E策略，并通过启发式策略和思考模型使LLMs进行思考，研究如何塑造LLMs的决策行为。研究表明，增强LLMs的思考行为使其决策模式趋向于人类的探索利用行为，表现为随机和定向探索的结合。
### Conclusion
在简单稳定环境中，思考增强的LLMs与人类的随机探索和定向探索水平相似。然而，在更复杂的、非稳定的环境中，LLMs难以与人类相比拟，尤其是在有效的定向探索方面。研究结果不仅揭示了LLMs作为人类行为模拟器和自动化决策工具的潜力和限制，还指出了改进的潜在领域。
## 711. `cs.LG` - 预像近似算法在神经网络认证中的高效实现 [PDF](https://arxiv.org/pdf/2505.22798), [HTML](https://arxiv.org/abs/2505.22798)
### Authors
Anton Björklund,Mykola Zaitsev,Marta Kwiatkowska
### Background
随着人工智能在安全性关键应用中依赖性的增加，有效认证神经网络的需求变得迫切。一种挑战性的实际应用场景是“补丁攻击”，在这种攻击中，对抗性补丁或照明条件会遮挡图像的部分内容，例如交通标志。最近，PREMAP方法通过使用先像（使得网络产生某个输出的所有输入的集合）的上下界来认证网络，显著推进了对抗补丁攻击的认证。然而，这种方法目前仅适用于中等维度的全连接神经网络。
### Innovation
为了应对更广泛的现实世界问题，论文提出了对PREMAP算法的新型扩展，包括更紧的边界、自适应蒙特卡罗采样以及改进的分支启发式方法。这些改进不仅显著提升了效率，使PREMAP能够扩展到以前无法处理的卷积神经网络，还展示了先像近似方法在计算机视觉和控制等应用中的分析和认证潜力。
### Conclusion
这些改进的预像近似方法显著提高了神经网络认证的效率和可扩展性，扩大了PREMAP的应用范围，并验证了先像近似方法在复杂应用中的有效性，为神经网络的安全性和鲁棒性提供了新的分析工具和认证手段。
## 712. `cs.LG` - Isolation Forest理论背景研究 [PDF](https://arxiv.org/pdf/2505.12825), [HTML](https://arxiv.org/abs/2505.12825)
### Authors
Qin-Cheng Zheng,Shao-Qun Zhang,Shen-Huan Lyu,Yuan Jiang,Zhi-Hua Zhou
### Background
孤立森林（iForest）作为一种广泛应用的无监督异常检测方法，主要因其出色的运行效率和在大规模任务中的优越性能而受到青睐。尽管其应用广泛，但有关iForest成功原因的理论基础仍不清楚。本文旨在通过对iForest归纳偏好的理论研究，解释其在何种条件下以及到何种程度上能表现良好。
### Innovation
本文将iForest的增长过程建模为随机行走，通过转移概率推导出期望深度函数，揭示了iForest的关键归纳偏倚：相较于k-最近邻，iForest对中心异常的敏感性较低，且具有更强的参数适应性。
### Conclusion
本研究为iForest的有效性提供了理论理解，并为后续的理论研究奠定了基础。
## 713. `cs.LG` - 指数族变分流匹配在表格数据生成中的应用 [PDF](https://arxiv.org/pdf/2506.05940), [HTML](https://arxiv.org/abs/2506.05940)
### Authors
Andrés Guzmán-Cordero,Floor Eijkelboom,Jan-Willem van de Meent
### Background
尽管去噪扩散和流匹配在生成建模方面取得了重大进展，但它们在表格数据上的应用仍然有限，而表格数据在实际应用中极为普遍。因此，本文开发了TabbyFlow，这是一种用于生成表格数据的变分流匹配(Variational Flow Matching, VFM)方法。为了将VFM应用于混合连续和离散特征的数据，本文引入了指数族变分流匹配(Exponential Family Variational Flow Matching, EF-VFM)，使用通用的指数族分布表示异构数据类型。
### Innovation
本文提出了Exponential Family Variational Flow Matching (EF-VFM)，该方法使用通用的指数族分布表示异构数据类型，从而将变分流匹配方法（VFM）应用于混合连续和离散特征的数据。同时，论文还建立了变分流匹配与基于Bregman发散的广义流匹配目标之间的联系。实验结果表明，EF-VFM在表格数据基准上的性能优于基线方法。
### Conclusion
本文通过提出的Exponential Family Variational Flow Matching (EF-VFM)方法，实现了表格数据生成的高效、数据驱动的目标，并进行了有效的评估，显示了该方法在实际应用中的优越性能。
## 714. `cs.LG` - 在固定维度的E(3)-不变潜空间中操控3D分子 [PDF](https://arxiv.org/pdf/2506.00771), [HTML](https://arxiv.org/abs/2506.00771)
### Authors
Zitao Chen,Yinjun Jia,Zitong Tian,Wei-Ying Ma,Yanyan Lan
### Background
医药化学家在优化药物时常常考虑分子的三维结构，并设计结构不同但保留关键特性的分子，如形状、药效团或化学性质。以往的深度学习方法通过诸如分子修复或属性导向优化的监督任务来解决这个问题。这项工作提出了一种灵活的零样本分子操控方法，通过在3D分子共享的潜在空间中导航实现。
### Innovation
本文提出了一种名为MolFLAE的3D分子变分自动编码器(VAE)，它学会了在不依赖于原子数的情况下学习一个固定维度、E(3)-不变的潜在空间。MolFLAE通过将3D分子编码为固定数量的语义嵌入标识的潜节点，实现了在潜在空间中的操控，包括原子数编辑、结构重构和结构与属性的协调嵌入。此外，通过计算评估展示了该方法在人类皮质醇受体药物优化中的应用，生成高效亲水性的分子同时保留关键相互作用。这种方法的灵活性、鲁棒性和实际应用价值主要体现在上述各个方面。
### Conclusion
该方法在标准的无条件3D分子生成基准测试中表现优异，潜在空间使得能够在不依赖于具体案例的情况下进行零样本分子操控，包括分子结构和属性的编辑和优化，从而为分子编辑和优化提供了新的思路和方法。
## 715. `cs.LG` - 在线决策导向学习 [PDF](https://arxiv.org/pdf/2505.13564), [HTML](https://arxiv.org/abs/2505.13564)
### Authors
Aymeric Capitaine,Maxime Haddouche,Eric Moulines,Michael I. Jordan,Etienne Boursier,Alain Durmus
### Background
决策导向学习（DFL）是一个越来越流行的训练预测模型的范式，这些模型的输出用于决策任务。与仅优化预测准确性不同，DFL 训练模型直接最小化与后续决策相关的损失。现有的研究主要集中在静态环境中，即固定批次的数据可供使用且目标函数随着时间推移不会变化。然而，本文作者将注意力转向了目标函数和数据分布随时间演变的动态环境，这种设置对在线学习构成了挑战，因为目标函数可能不具备或未定义梯度，无法使用标准的一阶优化方法，并且通常是非凸的。
### Innovation
本文提出并开发了两种基于DFL的原创在线算法，并分别建立了静态和动态遗憾界。这是首次为在线决策导向问题提供可证明的保证。同时，通过扰动技术结合近似最优的启发式算法来解决非凸性问题，提高了算法的有效性和实用性。
### Conclusion
作者在背包实验中展示了其算法的有效性，表明它们在执行任务时优于两个标准基准。
## 716. `cs.LG` - 风险敏感的代理组合 [PDF](https://arxiv.org/pdf/2506.04632), [HTML](https://arxiv.org/abs/2506.04632)
### Authors
Guruprerana Shabadi,Rajeev Alur
### Background
现代自主系统将复杂目标分解为一系列子任务，并选择一组专门的AI代理来完成这些子任务，从软件开发到机器人控制都有应用。实际部署需要选择不仅能够最大化任务成功，还能最小化违反安全、公平性和隐私要求的风险的代理组合，因此需要对代理组合的低概率行为进行仔细分析。本文基于此背景，研究代理组合的风险最小化。
### Innovation
作者将代理工作流形式化为有向无环图（称为代理图），其中边表示代理，路径表示代理组合。提出了一个有效的算法来遍历代理图，并找到近似最优化的代理组合。该算法利用联合边界逼近代理组合的风险值。此外，作者证明，在广泛的实用损失函数类中，该近似值是渐近近最优的。
### Conclusion
为了评估框架的有效性，作者使用一组类似于视频游戏控制的基准测试，这些测试需要组合几个使用强化学习训练的代理，并展示了该算法在逼近风险值和识别最优代理组合方面的有效性。
## 717. `cs.LG` - DiffusionBlocks：通过扩散解释实现模块化神经网络训练 [PDF](https://arxiv.org/pdf/2506.14202), [HTML](https://arxiv.org/abs/2506.14202)
### Authors
Makoto Shing,Masanori Koyama,Takuya Akiba
### Background
端到端的反向传播需要在整个网络的所有层中存储激活值，这会造成内存瓶颈，限制了模型的扩展能力。现有的按照区块的方式进行训练的方法可以缓解这个问题，但它们依赖于针对特定任务的小范围优化目标，并且主要应用于分类任务，很少被扩展到其他任务中。
### Innovation
提出了DiffusionBlocks，这是一种原理性的框架，将基于变压器的网络转变为真正独立的学习区块，同时保持与端到端训练相近的效果。核心洞察是残差连接自然对应于动力系统的更新。通过对动力系统的少量修改，可以将其转化为去噪过程的学习更新，每个区块可以独立学习，通过分数匹配目标实现。这种方式可以一次仅对一个区块进行梯度训练，从而降低内存需求，按照区块的数量进行减少。
### Conclusion
DiffusionBlocks在多种变压器架构（视觉、扩散、自回归、递归深度和掩码扩散）上的实验表明，其训练性能与端到端训练相当，且能够实现可在实际任务中扩展的区块化训练，超越了小规模分类任务。提供了一种理论上具有指导意义的方法，能够在多种架构上成功扩展到现代生成任务。
## 718. `cs.LG` - 连续思维机器 [PDF](https://arxiv.org/pdf/2505.05522), [HTML](https://arxiv.org/abs/2505.05522)
### Authors
Luke Darlow,Ciaran Regan,Sebastian Risi,Jeffrey Seely,Llion Jones
### Background
生物大脑表现出复杂的神经活动，其中神经动力学对于大脑信息处理至关重要。大多数人工神经网络忽视了单个神经元的复杂性。本文挑战了这一范式，通过引入神经水平的处理和同步，重新引入了神经时间作为基础元素。
### Innovation
Continuous Thought Machine (CTM)有两个创新点：（1）神经水平的时间处理，每个神经元使用独特的权重参数处理输入历史；（2）神经同步作为潜在表示。CTM旨在在神经抽象和生物现实性之间取得平衡，以有效捕捉关键的时序动态，同时保持计算上的可操作性。
### Conclusion
CTM能够在各种任务中展示丰富的内部表示和自然的解释途径，包括解决2D迷宫。CTM还可利用适应性计算，能够根据任务的复杂性调整计算量。本研究旨在分享CTM及其相关创新，而不是追求新的最先进技术。我们相信，CTM代表了朝着开发更生物真实且强大的人工智能系统的重大步骤。我们提供了补充的在线演示和补充技术报告。
## 719. `cs.LG` - 控序变异平方流匹配的可控生成 [PDF](https://arxiv.org/pdf/2506.18340), [HTML](https://arxiv.org/abs/2506.18340)
### Authors
Floor Eijkelboom,Heiko Zimmermann,Sharvaree Vadgama,Erik J Bekkers,Max Welling,Christian A. Naesseth,Jan-Willem van de Meent
### Background
本文在变异流动匹配（VFM）框架内推导出一种受控生成目标，将流动匹配视为一种变分推理问题。研究对比了两种实现受控生成的方式：一是通过条件生成模型的端到端训练，二是作为贝叶斯推断问题，允许在无需重新训练的情况下进行后验控制。
### Innovation
本文提出了两种实施可控生成的方法，分别为端到端训练条件生成模型和作为贝叶斯推断问题，同时建立了等变生成的条件，并为分子生成提供了等变形式的VFM，确保旋转、平移和排列不变性。此外，在不受控和受控的分子生成中评价该方法，在不受控生成中达到最新技术水平，在控制生成中也表现出色，无论是端到端训练还是贝叶斯推理情况。
### Conclusion
本文加强了基于流动的生成建模与贝叶斯推理之间的联系，提供了可用于约束驱动和对称感知生成的可扩展且原理上的框架。
## 720. `cs.LG` - 现代关联记忆方法 [PDF](https://arxiv.org/pdf/2507.06211), [HTML](https://arxiv.org/abs/2507.06211)
### Authors
Dmitry Krotov,Benjamin Hoover,Parikshit Ram,Bao Pham
### Background
类联想记忆的网络，如著名的霍普菲尔德网络，是描述全反馈神经网络的有效模型，这些网络的主要任务是存储和检索信息。近年来，这些网络因其信息存储能力的新理论结果以及与当前最先进的人工智能架构（如Transformer和扩散模型）的关系而重新引起了关注。这些联系为传统的人工智能网络的计算提供了新的理论理解，同时新型的拉格朗日形式化方法使设计有影响力的分布式模型成为可能，这些模型能够学习有用的表现形式，并指导新型架构的设计。
### Innovation
新型拉格朗日公式为设计强大分散化的关联记忆模型提供了可能，这些模型能够学习有用的表现形式，并启发新型架构的设计。这种联系为通过关联记忆的理论框架来解释传统的人工智能网络的计算提供了新的途径。
### Conclusion
该教程提供了一种易于理解的关联记忆介绍，强调了此研究领域中使用的新语言和方法，包括实用的手动数学推导和编程笔记本。
## 721. `cs.LG` - 权重的生成建模：泛化还是记忆？ [PDF](https://arxiv.org/pdf/2506.07998), [HTML](https://arxiv.org/abs/2506.07998)
### Authors
Boya Zeng,Yida Yin,Zhiqiu Xu,Zhuang Liu
### Background
近年来，生成模型被探索用于合成神经网络权重。这些方法以神经网络检查点作为训练数据，旨在在推理期间生成高性能的权重。先前的研究声称这些方法能够生成新颖的模型权重，即与训练过程中看到的检查点不同的权重。本文分析了四个代表性的方法，并发现它们合成权重主要通过记忆实现，生成的是检查点的复制或简单的插值，且无法超越简单的基线方法来获得高性能且不同的模型。
### Innovation
本文的主要创新在于通过实验证明并分析了生成模型在合成权重时主要依赖记忆而非泛化，该研究对于理解生成模型在不同领域的应用具有重要意义。
### Conclusion
本文发现生成模型依赖于记忆，合成的权重主要由记忆生成，没有达到期望的泛化能力。这表明生成模型在新领域应用时需要更加细致的设计和严格的评估。
## 722. `cs.LG` - QiMeng-CodeV-R1: 提升推理能力的Verilog代码生成 [PDF](https://arxiv.org/pdf/2505.24183), [HTML](https://arxiv.org/abs/2505.24183)
### Authors
Yaoyu Zhu,Di Huang,Hanqi Lyu,Xiaoyun Zhang,Chongxiao Li,Wenxuan Shi,Yutong Wu,Jianan Mu,Jinghua Wang,Yang Zhao,Pengwei Jin,Shuyao Cheng,Shengwen Liang,Xishan Zhang,Rui Zhang,Zidong Du,Qi Guo,Xing Hu,Yunji Chen
### Background
大规模语言模型（LLMs）通过可验证奖励的学习（RLVR）训练，在具有明确且可自动化验证的任务上取得了突破，例如软件编程和数学问题。然而，将RLVR扩展到电子设计自动化（EDA），特别是从自然语言（NL）规范自动生成硬件描述语言（HDL）如Verilog，存在三大挑战：缺乏自动且准确的验证环境、高质量的NL-代码对稀缺以及RLVR的高昂计算成本。为解决这些问题，本研究介绍了CodeV-R1——一种用于训练Verilog生成LLM的RLVR框架。
### Innovation
文章创新点包括：1）提出了一种基于规则的测试生成器，用于进行鲁棒的等效性检查；2）提出了回路数据合成方法，将开源Verilog片段与LLM生成的NL描述配对，通过生成的测试生成器验证代码-NL-代码的一致性，并过滤掉不等效的示例，生成高质量的数据集；3）采用两阶段的“先精炼后强化学习”训练管道：精炼阶段以建立推理能力，然后是适应性DAPO算法的强化学习阶段，该算法可以通过适应性调整采样率来降低训练成本。最终模型CodeV-R1-7B在VerilogEval v2和RTLLM v1.1上的通过率分别为68.6%和72.9%，超过了此前的最佳研究结果，并且甚至超过了671B DeepSeek-R1在RTLLM上的表现。
### Conclusion
研究成功地通过RLVR框架训练了Verilog生成的LLMs并解决了EDA领域的特定挑战。最终模型在验证基准测试中表现优异，不仅可以超越之前的最佳结果，甚至超过了规模更大的模型。研究成果释放了模型、训练代码和数据集，以促进EDA和LLM社区的研究。
## 723. `cs.LG` - 注入测量信息获得快速且抗噪声的基于扩散的逆问题求解器 [PDF](https://arxiv.org/pdf/2508.02964), [HTML](https://arxiv.org/abs/2508.02964)
### Authors
Jonathan Patsenker,Henry Li,Myeongseob Ko,Ruoxi Jia,Yuval Kluger
### Background
扩散模型已经确立为处理线性和非线性逆问题的原理性零样本解决方案，得益于它们的强大图像先验和迭代采样算法。这些方法通常依赖于Tweedie公式，该公式将扩散变量 δ_t 与后验均值 E[δ_0 | δ_t] 相关联，以便根据对最终去噪样本 δ_0 的估计来指导扩散轨迹。然而，这种方法并未考虑测量 y 的信息，这些信息需要在下游进行整合。
### Innovation
本文提出了一种估计条件后验均值 E[δ_0 | δ_t, y] 的方法，该均值可以作为单参数最大似然估计问题的解来形成。该预测可以整合到标准取样器中，结果是快速且内存高效的逆问题求解器。此外，优化器还可以适应噪声感知的最大似然停止准则，该准则对测量 y 中的噪声具有鲁棒性。
### Conclusion
我们在多个数据集和任务上展示了该方法与当代逆问题求解器的可比或改进的性能。
## 724. `cs.LG` - Subnetwork Data Parallelism for Model Parallelism [PDF](https://arxiv.org/pdf/2507.09029), [HTML](https://arxiv.org/abs/2507.09029)
### Authors
Vaibhav Singh,Zafir Khalid,Edouard Oyallon,Eugene Belilovsky
### Background
大规模神经网络的预训练需要大型加速器的大量内存，并且常常需要昂贵的通信，这构成了挑战。
### Innovation
引入了Subnetwork Data Parallelism (SDP)训练框架，该框架将模型划分为结构化子网络，通过计算工作节点在不交换激活的情况下进行训练。SDP研究了两种互补的masking模式：backward masking和forward masking。另外，还探讨了两种子网络构建策略：神经元级别和块级别，适用于CNN和transformer。
### Conclusion
在涵盖CNN和transformer的CIFAR、ImageNet以及LLM预训练的FineWeb上的实验中，SDP可以将每个设备的内存使用量减少30%-75%，同时保持或提高性能。值得注意的是，在FLOP匹配的设置下，forward masking有时可以实现更好的性能。
## 725. `cs.LG` - 短视频推荐中基于相对优势去偏差的观看时间预测 [PDF](https://arxiv.org/pdf/2508.11086), [HTML](https://arxiv.org/abs/2508.11086)
### Authors
Emily Liu,Kuan Han,Minfeng Zhan,Bocheng Zhao,Guanyu Mu,Yang Song
### Background
在视频推荐平台上，观看时长常被用作衡量用户满意度的指标。然而，原始的观看时长可能受到视频长度、流行度及用户行为等多种因素的影响，这会导致偏好信号失真，进而使推荐模型产生偏差。
### Innovation
提出了一种新颖的相对优势去偏差框架，通过将观看时长与用户和物品分组条件下的经验推导出的参考分布进行比较来进行校正。这种方法采用分位数基础的偏好信号，并引入了一种两阶段架构，明确地将分布估计与偏好学习分离。同时，还提出了分布嵌入方法，可以高效地表征观看时间分位数，而无需在线采样或存储历史数据。
### Conclusion
离线和在线实验表明，这种新方法在推荐准确性和鲁棒性方面明显优于现有的基线方法。
## 726. `cs.LG` - First Hallucination Tokens Are Different from Conditional Ones [PDF](https://arxiv.org/pdf/2507.20836), [HTML](https://arxiv.org/abs/2507.20836)
### Authors
Jakob Snel,Seong Joon Oh
### Background
大规模语言模型（LLMs）会生成与事实不符的情况，称为幻觉。检测这些幻觉是确保模型可信度的关键。目前，幻觉检测主要集中在响应或文本片段层面，但最近的研究开始探索在token级别进行检测，这种方法可以实现更精细的干预。然而，幻觉信号在幻觉token序列中的分布尚未得到探索。这项研究利用了来自RAGTruth语料库的token级注释，发现第一个生成的幻觉token比之后的token更容易被检测到。这种结构性特征在不同模型中都存在，暗示第一个幻觉token在token级幻觉检测中起着重要作用。
### Innovation
本研究的创新点在于利用token级别的注释，发现第一个生成的幻觉token比之后的token更容易被检测到。这种结构性特征在不同模型中都存在，表明第一个幻觉token在token级幻觉检测中起着重要作用，这为改进和优化幻觉检测方法提供了一个新的角度。
### Conclusion
本研究揭示了幻觉token的第一个token在检测中的重要性，发现其比之后的token更容易被检测到。通过识别第一个幻觉token，有助于更好地理解幻觉信号的分布，并进一步优化幻觉检测的策略。开源代码可以在提供的链接获取。
## 727. `cs.LG` - Co-rewarding: 稳定的自监督强化学习方法，以激发大型语言模型的推理能力 [PDF](https://arxiv.org/pdf/2508.00410), [HTML](https://arxiv.org/abs/2508.00410)
### Authors
Zizhuo Zhang,Jianing Zhu,Xinmu Ge,Zihua Zhao,Zhanke Zhou,Xuan Li,Xiao Feng,Jiangchao Yao,Bo Han
### Background
虽然可验证奖励的强化学习（RLVR）能够提高大语言模型（LLMs）的推理能力，但其依赖于人类标注的标签导致了规模难题，尤其是在处理复杂任务时。尽管近期的自奖励方法提供了一个无标签的替代方案，但它们常遇到训练崩溃的问题，因为单一视角的监督信号容易形成自一致的幻觉，导致奖励作弊。借鉴自监督学习的成功，本文提出了一种名为Co-rewarding的新自监督RL框架，通过寻求来自另一视角的互补监督来提高训练稳定。
### Innovation
提出了一种名为Co-rewarding的新自监督RL框架，通过在两种不同视角上寻求互补监督来改进训练稳定性。具体来说，Co-rewarding包括数据侧（Co-rewarding-I）和模型侧（Co-rewarding-II）两类实现。数据侧通过对比同义问题下的对比一致性来获取奖励信号；模型侧则维护一个缓慢更新的参考教师，利用伪标签实现自我蒸馏。这种方法通过引入不同层次的分歧增加了训练崩溃的难度。
### Conclusion
实验结果显示，Co-rewarding在各种设置下都表现出稳定的训练，并在多个数学推理基准测试上平均实现了3.31%的性能提升，特别是在Llama-3.2-3B-Instruct上提升了7.49%。值得注意的是，在某些情况下，Co-rewarding甚至超过了带有真实标签（GT）的RLVR，例如在GSM8K上Qwen3-8B-Base的通过率达到了94.01%，显著高于真实标签。本文的代码已经公开。
## 728. `cs.LG` - 免观测攻击对在线学习排序的影响 [PDF](https://arxiv.org/pdf/2509.22855), [HTML](https://arxiv.org/abs/2509.22855)
### Authors
Sameep Chattopadhyay,Nikhil Karamchandani,Sharayu Moharir
### Background
在线学习排序（OLTR）在信息检索和机器学习系统中起着关键作用，广泛应用于搜索引擎和内容推荐系统。然而，尽管采用了这些技术，对于OLTR算法在有组织的对抗性攻击面前的脆弱性，仍缺乏充分的理解。
### Innovation
本文提出了一个新的攻击框架，用于攻击一些广泛使用的OLTR算法。该框架旨在推广一组目标项目，使得它们在T - o(T)轮内出现在前K个推荐列表中，同时诱导学习算法产生线性遗憾。还提出了两种新型攻击策略：一个是针对CascadeUCB1算法的CascadeOFA，另一个是针对PBM-UCB算法的PBMOFA。理论上证明这两种策略只需要O(log T)次操纵即可成功。
### Conclusion
本文提供了理论保证，表明这两种策略只需要O(log T)次操纵即可成功，并通过真实数据的实验结果补充了理论分析。
## 729. `cs.LG` - Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains [PDF](https://arxiv.org/pdf/2507.17746), [HTML](https://arxiv.org/abs/2507.17746)
### Authors
Anisha Gunjal,Anthony Wang,Elaine Lau,Vaskar Nath,Yunzhong He,Bing Liu,Sean Hendryx
### Background
Reinforcement Learning with Verifiable Rewards (RLVR) 已在具有明确正确性信号的任务（如数学和编程）中被证明有效。然而，将其扩展到现实世界的推理任务具有挑战性，因为这些任务的评估依赖于细微、多标准的判断，而不是简单的正确与否判断。最近有研究使用实例特定的评分标准来捕捉这样的判断，但在训练后政策使用这些评分标准作为奖励信号的潜力尚未充分探索。
### Innovation
该论文提出了一种名为Rubrics as Rewards (RaR) 的方法，这是一种在策略训练后使用评分标准作为结构化奖励信号的强化学习方法。RaR能够将评分标准反馈扩展到验证性领域之外的任务中，主要通过评估不同策略来收集评分反馈，并将其汇总为奖励，从而在健康和科学领域中优于使用直接量表奖励的受欢迎的LLM作为评分基准。这一策略在健康和科学基准测试中分别实现了高达31%和7%的相对改进。
### Conclusion
RaR 训练的策略能够很好地适应多样的评估格式，在基于评分标准的任务和多项选择任务上表现优异。使用评分标准作为结构化奖励信号对于较小的评估者能更好地实现对齐，并减少评估者规模上的表现差异。
## 730. `cs.LG` - 关于可证明出现的上下文强化学习 [PDF](https://arxiv.org/pdf/2509.18389), [HTML](https://arxiv.org/abs/2509.18389)
### Authors
Jiuqi Wang,Rohan Chandra,Shangtong Zhang
### Background
现代强化学习(RL)代理通过更新神经网络参数来适应其策略以解决任务。最近观察到，一些预训练于特定任务分布的RL代理能够解决各种新的未见过的任务，而无需在新任务上更新参数。相反，这些代理依赖于预训练期间获得的上下文信息，通过上下文条件化策略实现更好的性能。这种现象被称为上下文强化学习(ICRL)。尽管ICRL取得了显著的成果，但预训练过程中使用的标准RL算法并未专门设计来产生有利于ICRL的参数，因此研究者提出了核心问题：为什么使用RL预训练算法可以生成有利于ICRL的网络参数？
### Innovation
本文假设能够进行ICRL的参数是预训练损失的极小值，并提供了一个案例研究支持这一假设。具体而言，当使用Transformer进行策略评估时，预训练损失的一个全局极小值可以促进上下文时变差异学习。这一发现揭示了预训练机制能够生成有利ICRL的参数的理论依据，并为ICRL的研究提供了新的视角。
### Conclusion
本文的研究证明了某些预训练参数能够在特定情况下促进ICRL，表明预训练过程中存在能够促进ICRL的参数，该研究为理解预训练在ICRL中的作用提供了理论支持，并为进一步研究预训练机制和ICRL的发展方向提供了新的线索。
## 731. `cs.LG` - STORI：随机环境的基准和分类法 [PDF](https://arxiv.org/pdf/2509.01793), [HTML](https://arxiv.org/abs/2509.01793)
### Authors
Aryan Amit Barsainyan,Jing Yu Lim,Dianbo Liu
### Background
尽管强化学习技术在诸如Atari100k等模拟基准测试中的表现令人印象深刻，但近年来的进步主要局限于模拟领域，并未广泛应用于现实世界领域。一个重要障碍是环境的随机性，因为真实系统包含噪声观测、不可预测的动力学以及非站定条件等，这些都削弱了当前方法的稳定性。现有的基准很少能够捕捉这些不确定性，通常被设计成简单的环境，算法可以被调整以成功运行。没有一个定义明确的随机性分类进一步加剧了评估的难度，因为对一种随机扰动的鲁棒性，并不保证对其他类型的不确定性也是鲁棒的。因此，为了填补这一关键缺口，我们介绍了STORI（STOchastic-ataRI）基准，该基准系统性地整合了多种随机效应对不同形式不确定性下的强化学习技术进行严格评估提供了可能。我们提出了一种全面的五类环境随机性的分类，并通过对DreamerV3和STORM等最新模型-驱动的强化学习算法进行了靶向评估，展示了其系统性的脆弱性。我们的研究揭示了该领域的世界模型大大低估了环境的变异性，难以处理动作污染，且在部分可观测性条件下动态行为不可靠。
### Innovation
我们引入了STORI（STOchastic-ataRI）基准，该基准系统性地整合了多种随机效应对不同形式的不确定性进行评估。我们提出了一种全面的五类环境随机性的分类，并展示了针对DreamerV3和STORM等最先进的模型驱动的强化学习算法的靶向评估结果，揭示了这些算法在面对不确定性和随机性时的系统性脆弱性。此外，我们还发布了可用于开发更加鲁棒的强化学习系统的代码和基准数据，使得研究人员能够在此基础上进行进一步研究和改进。
### Conclusion
我们的工作填补了现有的强化学习评估方法在应对真实世界复杂随机性方面的重要空白，并为开发更鲁棒的强化学习系统提供了统一的框架。
## 732. `cs.LG` - Flow-诱导对角高斯过程 [PDF](https://arxiv.org/pdf/2509.17153), [HTML](https://arxiv.org/abs/2509.17153)
### Authors
Moule Lin,Andrea Patane,Weipeng Jing,Shuhao Guan,Goetz Botterweck
### Background
该论文提出了一种称为Flow-诱导对角高斯过程（FiD-GP）的压缩框架，将神经网络权重不确定性投影到低维子空间中，并通过紧凑的诱导权重矩阵进行。FiD-GP依赖于归一化流先验以及光谱规整化来增加其表达能力。
### Innovation
FiD-GP引入了一种通过数值稳定投影机制将权重不确定性投影到低维子空间的方法，并且通过归一化流先验和光谱规整化增强其表达能力。此外，基于预测框架，该方法还能够设计用于特定域外检测的单一投影。
### Conclusion
与其他基于SVGP的基线方法相比，FiD-GP在各种任务中提高了不确定性估计能力，满足严格的光谱残差界限，并可理论保证域外检测。尽管压缩了神经网络存储需求，但可能增加了推理计算成本。具体而言，在全面的实验研究中，BF培训成本降低了几个数量级，参数压缩了约51%，模型大小减少了约75%，并且能够达到最新的准确性和不确定性估计水平。
## 733. `cs.LG` - Putnam-like数据集总结：LLM作为数学竞赛选手 [PDF](https://arxiv.org/pdf/2509.24827), [HTML](https://arxiv.org/abs/2509.24827)
### Authors
Bartosz Bieganowski,Daniel Strzelecki,Robert Skiba,Mateusz Topolewski
### Background
本研究汇总了Google DeepMind发布的Putnam-like基准测试的结果。该数据集包含96个原版的Putnam竞赛风格问题以及576个语言模型（LLM）的解决方案。研究旨在分析模型在解决数学竞赛问题上的表现，以验证它们解决数学竞赛题目的能力。
### Innovation
本研究创新之处在于使用了一个特定于数学竞赛的问题数据集来评估语言模型的能力，这之前可能较少见。通过这种方式，研究人员能够评估现代大语言模型在复杂数学问题上的处理能力。
### Conclusion
研究验证了模型在解决数学竞赛问题上的能力。通过分析模型的表现，研究团队得出了语言模型在处理这类问题时的优缺点，并且展示了这些模型在数学应用中的潜力。
## 734. `cs.LG` - 特征动态作为隐式数据增强：深度神经网络泛化的一种深度分解视角 [PDF](https://arxiv.org/pdf/2509.20334), [HTML](https://arxiv.org/abs/2509.20334)
### Authors
Tianyu Ruan,Kuo Gai,Shihua Zhang
### Background
论文探讨了深度网络为何能够很好地泛化。与传统的泛化理论不同，该研究不仅关注输入和输出，还关注内部特征随时间的变化。研究表明，浅层特征和较深层特征的结合能保持预测的稳定性，这种稳定性不是简单的收敛现象，并且对初级的方向性噪声具有鲁棒性。
### Innovation
论文提出并验证了特征动态（temporal consistency）与深层次分解在支持深度神经网络泛化方面的作用。具体创新点包括：发现了浅层特征和较深层特征结合能保持预测的稳定性；这种稳定性为隐式结构化增强范式提供了支持；展示了这种稳定性在未见过的数据和受损害的数据中依然存在，并能够解释当破坏语义结构时（例如随机标签）的行为。
### Conclusion
论文通过统计测试发现了随机梯度下降（SGD）注入方向性噪声以增强结构变异，并提出将特征动态与泛化联系起来的概念框架，为未来研究提供了关于时间特征演化测量实用替代方案的方向。
## 735. `cs.LG` - 通过稀疏自编码器基于向量精炼增强LLM引导 [PDF](https://arxiv.org/pdf/2509.23799), [HTML](https://arxiv.org/abs/2509.23799)
### Authors
Anyi Wang,Xuansheng Wu,Dong Shu,Yunpu Ma,Ninghao Liu
### Background
引导已作为控制大型语言模型（LLMs）的有效方法崛起，而不修改模型参数。然而，大多数现有的引导方法依赖于大规模数据集来学习明确的行为信息，这限制了它们在许多现实场景中的适用性。从少量数据中提取的引导向量经常包含与任务无关的噪声特征，从而降低了它们的效果。
### Innovation
我们引入了通过稀疏自编码器（SAEs）对引导向量进行精炼（SAE-RSV）的方法，利用SAEs对引导向量进行语义去噪和增补。首先通过SAEs提供的语义来去除与任务无关的特征，然后通过与识别的相关特征的语义相似性来补充小数据集中缺失的任务相关特征。实验表明，提出的SAE-RSV显著优于所有基线方法，包括监督微调。
### Conclusion
我们的研究结果表明，可以通过通过SAEs调整原始引导向量来从少量训练数据中构建出有效的引导向量。
## 736. `cs.LG` - 揭开水网络基础模型的神秘面纱 [PDF](https://arxiv.org/pdf/2509.23089), [HTML](https://arxiv.org/abs/2509.23089)
### Authors
Sylee Beltiukov,Satyandra Guthula,Wenbo Guo,Walter Willinger,Arpit Gupta
### Background
现有研究主要集中在网络基础模型（NFMs）的下游任务性能上，但缺乏对其内部隐含知识（特别是隐藏表示）的系统性分析。本文通过几何嵌入分析、度量对齐评估和因果敏感性测试，对模型进行多角度评估，旨在发现并理解NFMs内部的知识，并揭示其在特征表示、高阶背景处理等方面的问题。
### Innovation
本文提出了一个新的评价框架，通过几何嵌入分析、度量对齐评估和因果敏感性测试三个部分对NFMs进行全面评估，揭示了这些模型在特征表示的各向异性、特征敏感模式的一致性、高阶背景处理能力等方面的局限性。这种系统性分析对进一步改进模型性能具有重要意义。
### Conclusion
本文研究发现所有NFMs模型均存在显著的各向异性、特征敏感模式不一致以及高阶背景处理能力有限等问题。通过解决这些问题，可以在不改变架构的情况下显著提高模型性能（最高提高0.35个F1分数）。
## 737. `cs.LG` -  Ungrounded 的根基：基于谱图的框架量化多模态大语言模型中的幻觉 [PDF](https://arxiv.org/pdf/2508.19366), [HTML](https://arxiv.org/abs/2508.19366)
### Authors
Supratik Sarkar,Swagatam Das
### Background
在大型语言模型（LLM）中，幻觉仍然是信任人工智能（AI）的基本障碍，特别是在医学、法律和金融等高风险多模态领域。当前的评估技术主要是基于启发式方法，缺乏对幻觉产生、传播和跨模态交互的严格量化和理论保证。
### Innovation
我们提出了第一个严格的信息几何框架，用于在扩散动力学中量化多模态LLM（MLLM）中的幻觉，从定性检测转向基于数学依据的测量。该框架将MLLM输出表示为多模态图拉普拉斯的谱嵌入，并将真实值与不一致性之间的流形差距视为语义失真，通过温度时间依赖谱在RKHS嵌入中的本征模式分解，提供感知模态性和可解释的度量，捕捉幻觉随时间和输入提示的演变。
### Conclusion
我们的工作建立了一个量化和限制幻觉的原理基础，使幻觉从定性的风险转变为可处理、可分析的现象，实现了从主观发现到客观验证的转变。
## 738. `cs.LG` - 采用大步长的梯度下降：混沌与分形收敛区域 [PDF](https://arxiv.org/pdf/2509.25351), [HTML](https://arxiv.org/abs/2509.25351)
### Authors
Shuang Liang,Guido Montúfar
### Background
作者研究了矩阵分解中的梯度下降行为，特别是在大步长下参数空间的发展特性。背景在于，传统的梯度下降方法在特定条件下可能会表现出复杂的动力学行为。
### Innovation
创新点在于作者发现，在大步长下梯度下降的参数空间会出现分形结构，并推导出对于标量-向量分解问题的收敛临界步长。此外，作者还展示了正则化如何增加初始化的敏感性，并在初始值之间划分出分形边界。进一步，该分析扩展到了正交初始化的一般矩阵分解中。作者揭示了临界步长下梯度下降进入混沌区域，在此区域中长期动力学是不可预测的，且不存在简单的隐式偏置，如平衡性、最小范数或平坦性等。
### Conclusion
研究发现，在临界步长附近梯度下降会出现混沌现象，长期动态行为不可预测且没有简单的隐式偏好，而添加正则化会增强这一现象，使得受初始化影响更加明显，从而形成了由收敛和发散初始化确定的分形边界。
## 739. `cs.LG` - DM-Bench：糖尿病管理中个性化决策制定的LLM基准 [PDF](https://arxiv.org/pdf/2510.00038), [HTML](https://arxiv.org/abs/2510.00038)
### Authors
Maria Ana Cardei,Josephine Lamp,Mark Derdzinski,Karan Bhatia
### Background
当前已有的一些健康基准或者临床任务相关的基准主要关注于广泛的健康问题或临床任务处理，例如诊断和分诊。然而，没有一个基准专注于患者日常生活中的真实世界决策任务。本文提出了DM-Bench，旨在全面评估大型语言模型在糖尿病管理中面对个体日常决策问题时的表现，该模型涵盖了糖尿病、血糖管理、代谢健康等相关领域。DM-Bench 包含了7个不同的任务类别，反映了糖尿病患者在日常生活中提出的广泛问题。这些任务包括基础的血糖解释、教育查询、行为关联、高级决策和长期规划。
### Innovation
DM-Bench 是第一个专门设计来评估大型语言模型在糖尿病患者日常生活中面临的真实世界决策任务性能的基准。它引入了一个包容性的评估框架，以适应原型患者面向的AI解决方案提出的独特挑战。该基准包括15,000名不同糖尿病群体（1型、2型、糖尿病前期/一般健康和健身）的个体，涵盖了一个月的时间序列数据，数据包括连续葡萄糖监测仪（CGM）的葡萄糖跟踪和记录，以及行为日志。通过利用这些数据，生成了总共360,600个针对7个任务类别的个性化、上下文相关的提问。评测模型性能采用了5个指标：准确性、相关性、安全性、清晰度和可操作性。研究表明，8个近期的大型语言模型在任务和指标方面存在显著差异，没有一种模型在所有维度上都表现最优。这为评估和改进糖尿病管理中的AI解决方案提供了新方法和新工具。
### Conclusion
通过建立DM-Bench，我们旨在推动AI在糖尿病护理中的可靠性和安全性，证实其有效性，并增强其实用价值。这项研究为糖尿病管理中的AI技术发展和应用提供了一个坚实的评估平台。
## 740. `cs.LG` - 修复免费午餐：合成数据在模型导向策略优化中的何时何地为何失败 [PDF](https://arxiv.org/pdf/2510.01457), [HTML](https://arxiv.org/abs/2510.01457)
### Authors
Brett Barkley,David Fridovich-Keil
### Background
基于数据高效且类似Dyna风格模型导向的强化学习中，合成数据是关键组成部分，但有时也会降低性能。研究了合成数据何时有助于提高性能，何时失效及其原因。论文指出，尽管在OpenAI Gym中报告了强大的和泛化的样本效率收益，但最近的研究显示，在DeepMind Control Suite (DMC)中，模型导向强化学习策略优化（MBPO）常表现出色不如其无模型轴（SAC）算法。环境特点和机器人感知的不同导致了在DMC七个复杂任务中的性能损失，MBPO在环境假定适用于通用性的情况下也失败了。这揭示了受限评估环境下环境特定假设在算法设计中的隐性编码问题。
### Innovation
论文识别了导致失败的两个关键问题：动力学模型与奖励模型比例不匹配致批评者低估并阻碍模型与策略协进化期间的策略改进；目标表示不合适导致模型方差增加，产生纠错跑路。解决问题的方式使得MBPO在五项任务中表现超过SAC，同时保持了OpenAI Gym中报告的强大性能。论文主张这不仅是增益平均改进，还呼吁社区开发联系MDP任务和环境级别的结构与算法失败模式的分类，并探索普适性解决方案，明确基准选择最终如何塑造算法泛化条件。
### Conclusion
论文表明，解决合成数据导致的失败模式可以使得MBPO在某些任务中优于SAC，揭示了环境特定假设在算法设计中的重要性，并提出了一种重新思考强化学习算法性能和泛化的视角，鼓励开发更多的联系任务和环境级别结构与算法失败模式的分类，以及追求普适的解决方案来实现这些目标。
## 741. `cs.LG` - 端到端神经压缩与重建的超高效率解码 [PDF](https://arxiv.org/pdf/2510.01407), [HTML](https://arxiv.org/abs/2510.01407)
### Authors
Ethan G. Rogers,Cheng Wang
### Background
图像压缩与重建对于各种数字应用至关重要。尽管当前的神经网络压缩方法能够实现令人印象深刻的压缩率，但它们在数据重建中所依赖的基于卷积的解码器复杂且计算成本高，严重阻碍了这些技术的广泛应用。
### Innovation
为了应对神经压缩中的解码器瓶颈，作者提出了一种结合低秩表示的自编码器与向量量化的新压缩重建框架。该方法通过在学习到的图像潜在表示上进行一系列高效的低秩操作，高效地重建高质量数据。此方法显著减少了神经压缩/重建中解码阶段的计算开销，极大地消除了解码器计算瓶颈，同时保持了图像输出的高度保真度
### Conclusion
该框架能够高效地实现端到端的神经压缩与重建，通过低秩表示和向量量化降低了计算成本，提升了应用效率，同时保证了重建图像的质量。
## 742. `cs.LG` - 使用变分贝叶斯最后一层微调LLMs进行高维贝叶斯优化 [PDF](https://arxiv.org/pdf/2510.01471), [HTML](https://arxiv.org/abs/2510.01471)
### Authors
Haotian Xiang,Jinwen Xu,Qin Lu
### Background
许多应用场景需要解决具有高评估成本的黑盒优化问题，涉及药物发现、材料设计及超参数调优。为了高效地找到黑盒优化问题的全局最优解，贝叶斯优化（BO）提供了理论上的优雅框架，依赖于概率代理模型以迭代选择具有良好探索与利用平衡的查询点。高斯过程（GP）作为代理建模的首选方法，在低维连续变量情况下实现了令人信服的性能。然而，GP在处理具有不规则变量（如分类、序数等）的高维情况下表现不佳。受大型语言模型（LLMs）强大能力的启发，本研究采用LLMs作为代理模型，建模从高维输入变量到目标函数的映射。为了适应当前问题，利用低秩适应（LoRA）来微调LLMs参数和线性回归头部的后验分布，通过变分贝叶斯最后一层（VBLL）框架实现了这一目标。这种方法不仅计算成本较低，还支持递归更新。为了自动化关键的LoRA秩选择及其他超参数的选择，设计了一种加权集成（ENS）的LoRA-VBLL代理模型，进一步通过递归贝叶斯实现了单一LoRA-VBLL模型权重及参数的持续更新。
### Innovation
引入了低秩适应（LoRA）与变分贝叶斯最后一层（VBLL）框架，结合大型语言模型（LLMs）进行高维贝叶斯优化。提出了加权集成（ENS）的LoRA-VBLL方法，并通过递归贝叶斯实现了模型权重及参数的持续更新。
### Conclusion
实验结果显示，提出的（ENS-）LoRA-VBLL方法在各种高维基准测试和真实世界的分子优化任务中表现出色。
## 743. `cs.LG` - AReUReDi: Annealed Rectified Updates for Refining Discrete Flows with Multi-Objective Guidance [PDF](https://arxiv.org/pdf/2510.00352), [HTML](https://arxiv.org/abs/2510.00352)
### Authors
Tong Chen,Yinuo Zhang,Pranam Chatterjee
### Background
在治疗和生物分子工程中，设计能够满足多种通常是冲突目标的序列是一个核心挑战。现有的生成框架主要在连续空间中工作，且大多数是单目标指导的，而离散方法缺乏保证多目标帕累托最优性的保障。因此，需要一种新的算法解决这一问题，确保在多目标优化时能够收敛到帕累托前沿。为了解决这个问题，研究人员引入了AReUReDi算法。
### Innovation
AReUReDi算法结合了Tchebycheff标量化、局部平衡提议以及退火马尔可夫-哈特斯更新，确保在偏向帕累托最优状态的同时保持分布不变性，并且具有理论上的收敛到帕累托前沿的保证。该算法成功应用于肽和SMILES序列的优化中，优化多达五个治疗属性（包括亲和力、溶解度、溶血、半衰期和非阻塞性），并优于进化和扩散基线。这表明AReUReDi是一个强大的多属性生物分子生成框架，具有序列基础。
### Conclusion
AReUReDi算法通过将帕累托最优性纳入生成框架中，提高了多属性生物分子的生成能力，并展示了其在肽和SMILES序列设计中的优越性能。该算法为多属性生物分子设计提供了一种新的方法。
## 744. `cs.LG` - Anchored Supervised Fine-Tuning [PDF](https://arxiv.org/pdf/2509.23753), [HTML](https://arxiv.org/abs/2509.23753)
### Authors
He Zhu,Junyou Su,Peng Lai,Ren Ma,Wenjia Zhang,Linyi Yang,Guanhua Chen
### Background
大型语言模型的后训练涉及监督微调（SFT）和强化学习（RL）之间的基本权衡。SFT可以高效地模仿示例，但容易记忆；而RL则能够在更高的计算成本下实现更好的泛化。最近，动态微调（DFT）作为一种中间方案出现，通过调整SFT目标与标记概率重新加权，来实现某些推理领域的改进，但在其他任务上表现出不稳定性。
### Innovation
作者通过对奖励权重回归（RWR）框架的分析，揭示了DFT对应于一种特定的辅助分布选择，从而提供了比标准SFT更加紧致的RL边界。然而，他们也发现这种构造缺乏分布锚定，导致了训练稳定性退化。为解决这个问题，作者提出了一种附加轻量级KL正则化的锚定监督微调（ASFT），该方法同时保留了紧致性并确保稳定性。实验证明，ASFT在数学推理、医学知识接地和代码生成等多个领域中持续优于SFT和DFT，且具有极小的计算负担。
### Conclusion
作者的RWR框架为理解后训练方法提供了系统性的视角，并表明仔细的理论分析不仅能够提供更强的保证，还能带来实际收益。此外，ASFT在多个任务上展现出显著的性能提升，并且具有极小的计算成本增益。
## 745. `cs.LG` - 理解对抗性迁移：为什么代表空间攻击会在数据空间攻击成功的地方失败 [PDF](https://arxiv.org/pdf/2510.01494), [HTML](https://arxiv.org/abs/2510.01494)
### Authors
Isha Gupta,Rylan Schaeffer,Joshua Kazdan,Ken Ziyu Liu,Sanmi Koyejo
### Background
对抗性鲁棒性领域的研究已经表明，对抗样本能够在图像分类器之间和语言模型（LMs）之间成功转移。然而，近期有研究表明图像拦截攻击在视觉-语言模型（VLMs）之间无法成功转移。论文试图通过研究对抗攻击在模型中的转移机制来解释这一现象，提出了一种核心差异：数据空间的攻击能够转移，而模型表示空间的攻击则不能，除非代表几何对齐。论文基于多个场景验证了这一观点，包括简单的输入输出映射场景、图像分类器的表示空间攻击、语言模型的表示空间攻击、以及视觉-语言模型的数据空间和表示空间攻击，显示了代表空间攻击可在某些条件下在VLMs间成功转移。这些研究揭示了并非所有攻击都具有对抗性转移属性，而是取决于它们的操作领域——共享的数据空间或模型独特的表示空间。这项研究成果对于构建更鲁棒的模型具有至关重要的启示意义。
### Innovation
本文提出的新型观点在于，对抗性攻击的转移性与它们操作的空间有关。具体来说，数据空间的攻击可以转移，而模型表示空间的攻击在没有几何高度对齐的情况下则难以转移。论文通过四个不同的实验设置提供了理论和实证证据支持这一观点，展示了数据空间和模型表示空间的攻击之间的区别，并揭示了在特定几何对齐条件下代表空间攻击的成功转移。
### Conclusion
研究表明，对抗性转移不是所有攻击的固有特性，而是取决于其操作的空间——数据空间或模型表示空间。这项发现对于理解和设计抗转移对抗攻击具有重要意义，有助于构建更加鲁棒的机器学习模型。
## 746. `cs.LG` - SCOPED: Score-Curvature Out-of-distribution Proximity Evaluator for Diffusion [PDF](https://arxiv.org/pdf/2510.01456), [HTML](https://arxiv.org/abs/2510.01456)
### Authors
Brett Barkley,Preston Culbertson,David Fridovich-Keil
### Background
出分布检测（Out-of-distribution, OOD）对于确保机器学习系统在视觉、机器人技术、强化学习等领域可靠部署是至关重要的。现有的方法在检测未知或异常数据时通常需要多次通过训练模型，这限制了其在实际应用中的效率和准确性。
### Innovation
SCOPED提供了一种快速且通用的OOD检测方法，适用于扩散模型。相较于先前的方法，SCOPED减少了对训练模型的直接前向计算次数约一个数量级，并且在多个视觉基准测试中显示出与其计算成本相符的精度和召回率。此外，不同于单一阈值判断的方法，SCOPED通过核密度估计技术计算出分布内的数据密度，提供了一种灵活且无监督的检测方法，仅需一次前向传播和一次雅克比向量乘积（JVP），这得益于Hutchinson迹估计方法的效率提高。这种方法还适用于共享状态和动作空间的机器人控制任务，可以识别不同奖励函数和训练策略下的分布转移。
### Conclusion
SCOPED展示了其作为快速且可靠的OOD检测基础在真实世界领域的潜力，例如视觉中的感知缺陷检测、自回归模型中的异常检测、强化学习中的探索以及无监督训练数据集的筛选。
## 747. `cs.LG` - KAIROS：统一训练以实现通用非自回归时间序列预测 [PDF](https://arxiv.org/pdf/2510.02084), [HTML](https://arxiv.org/abs/2510.02084)
### Authors
Kuiye Ding,Fanda Fan,Zheya Wang,Hongxiao Li,Yifan Wang,Lei Wang,Chunjie Luo,Jianfeng Zhan
### Background
在互联网中，可靠的时序预测提供了前瞻性的信号，用于驱动资源规划、缓存放置和异常响应，帮助平台随着用户行为和内容分布的变化高效运行。与其他领域相比，针对Web应用的时序预测需要更快的响应速度，以支持实时决策制定。
### Innovation
KAIROS是一个非自回归时间序列预测框架，直接建模段级别的多峰分布，避免了误差累积，实现了即时推理，并且在现有非自回归模型的基础上提高了预测性能，特别是对于平滑过度的预测。该模型在大规模数据集上训练，展示了在六个广泛使用的基准上的零样本泛化能力，并在相似规模的预训练模型中表现出了可比拟的预测性能，但在推理成本上却只消耗极小的一部分。
### Conclusion
KAIROS强调了非自回归设计作为时间序列基础模型的可扩展范式的的重要性。它展示了非自回归框架在时间序列预测中的潜力，特别是在提高了泛化能力和降低推理成本方面。
## 748. `cs.LG` - PepCompass: 使用黎曼几何导航肽嵌入空间 [PDF](https://arxiv.org/pdf/2510.01988), [HTML](https://arxiv.org/abs/2510.01988)
### Authors
Marcin Możejko,Adam Bielecki,Jurand Prądzyński,Marcin Traskowski,Antoni Janowski,Karol Jurasz,Michał Kucharczyk,Hyun-Su Lee,Marcelo Der Torossian Torres,Cesar de la Fuente-Nunez,Paulina Szymczak,Michał Kmicikiewicz,Ewa Szczurek
### Background
抗微生物肽的发现面临肽空间的巨大规模和活性肽相对稀少的挑战。生成模型可以提供肽空间的连续潜在“地图”，但通常忽略解码器诱导的几何结构，依赖扁平的欧几里得度量，导致探索和优化变得失真且低效。此前基于流形的方法假设固定的内在维度，在肽数据的实际应用中严重失效。
### Innovation
提出了一个几何感知框架PepCompass，用于肽的探索和优化。核心是定义了一个κ-稳定黎曼流形的并集，捕捉局部几何结构并确保计算稳定性。提出了两种局部探索方法：基于二次黎曼布朗运动的有效采样和基于切空间的突变枚举。结合这些方法，得到了局部枚举贝叶斯优化(LE-BO)，一种局部活性优化的有效算法。同时，引入了潜在最小化测地线搜索(PoGS)，以属性丰富测地线为介进行原型嵌入的插值，偏向上种子的探索，即活性有利的肽。
### Conclusion
在体外验证中证实了PepCompass的有效性：PoGS产生了四个新的种子，随后使用LE-BO优化发现了25种具有广泛活性的高活性肽，包括对耐药细菌有效的肽。这表明，几何信息指导的探索为抗微生物肽的设计提供了一个强大的新范式。
## 749. `cs.LG` - Octax：加速的CHIP-8街机环境，用于JAX中的强化学习 [PDF](https://arxiv.org/pdf/2510.01764), [HTML](https://arxiv.org/abs/2510.01764)
### Authors
Waris Radji,Thomas Michel,Hector Piteau
### Background
强化学习（RL）研究需要多样的挑战性环境，这些环境既易于管理又可扩展。现代视频游戏虽然提供了丰富的动态，但由于它们是CPU密集型执行，所以在大规模实验中效率低下，因此不理想。
### Innovation
我们引入了Octax，一个基于JAX实现的高性能CHIP-8街机游戏环境套件，基于CHIP-8模拟，CHIP-8是Atari前辈，广泛用于RL研究的基准。Octax为JAX社区提供了一个期待已久的端到端GPU替代方案，提供了基于图像的环境，涵盖拼图、动作和策略等类型的游戏，可以在现代GPU上大规模执行。基于JAX的实现相比传统的CPU模拟器，速度提高了几个数量级，同时保持了对原游戏机制的完美忠实度。
### Conclusion
我们通过在多种游戏中训练RL代理展示了Octax的能力，显示了与现有解决方案相比在训练速度和可扩展性方面的显著改进。环境的模块化设计使研究人员能够轻松扩展套件以添加新游戏，或使用大型语言模型生成新型环境，从而使其成为大规模RL实验的理想平台。
## 750. `cs.LG` - 通过近端点方法在随机优化中实现方差减少和低样本复杂度 [PDF](https://arxiv.org/pdf/2402.08992), [HTML](https://arxiv.org/abs/2402.08992)
### Authors
Jiaming Liang
### Background
在随机优化中，高概率保证通常需要很强的噪声假设，如次高斯尾部。然而，这些假设往往过于严格。
### Innovation
本文提出了一种通过近端点方法的随机近端点方法，实现了在较弱的方差有界假设下获得类似的高概率保证。该方法结合了内部减少方差的近端子问题求解器和一个概率增强器，后者可以将每次迭代的可靠性提升为高置信度结果。
### Conclusion
该分析证明了收敛性具有低样本复杂性，而不需要限制性噪声假设或依赖分批处理。
## 751. `cs.LG` - 通过因果分离改进的结构分解马尔可夫决策过程的 Monte Carlo 计划 [PDF](https://arxiv.org/pdf/2406.16151), [HTML](https://arxiv.org/abs/2406.16151)
### Authors
Larkin Liu,Shiqi Liu,Yinruo Hua,Matej Jusup
### Background
马尔可夫决策过程 (MDPs) 作为一种通用框架，通常没有利用状态和奖励动态的因果结构带来的好处。对于一类资源分配问题，提出的结构分解马尔可夫决策过程 (SD-MDP) 利用因果分离将 MDP 的因果时间图分割为独立组件，从而实现维数降低和计算效率提升，优化了价值函数的估计。
### Innovation
引入了结构分解马尔可夫决策过程 (SD-MDP)，通过因果分离将时间因果图分割为独立组件，将顺序优化问题简化为具有对数复杂度的分数背包问题，优化了计算效率和政策性能。此外，SD-MDP 的计算优势不受状态动作空间大小的影响，适用于高维空间，并且能够无缝集成 Monte Carlo Tree Search (MCTS)，在受限模拟预算下提供更高的期望奖励并具有消失的简单遗憾界。
### Conclusion
通过实验证明，SD-MDP 在物流和金融领域的基准测试中表现更优，且在计算效率和政策性能方面都有所提升。
## 752. `cs.LG` - 分数阶签名：受分数阶微积分启发的签名的一般化 [PDF](https://arxiv.org/pdf/2407.17446), [HTML](https://arxiv.org/abs/2407.17446)
### Authors
José Manuel Corcuera,Rubén Jiménez
### Background
本文基于分数阶微积分，提出了路径签名的新型泛化版本，旨在描述线性Caputo控制分数微分方程的解。此外，还提出了另一种适用于机器学习的签名泛化版本。
### Innovation
本文的创新之处在于提出了一种基于分数阶微积分启发的路径签名的新泛化，以及更适用于机器学习的另一种签名泛化。
### Conclusion
通过在手写数字识别的玩具应用中测试这种最后的签名，观察到了与原始签名相比在准确率上的显著改进。
## 753. `cs.LG` - 通过激活引导理解代码LLMs（错误地）预测类型 [PDF](https://arxiv.org/pdf/2404.01903), [HTML](https://arxiv.org/abs/2404.01903)
### Authors
Francesca Lucchetti,Arjun Guha
### Background
大型语言模型（LLMs）在软件开发中被广泛用于编程任务中。然而，研究表明，这些模型往往缺乏深入理解程序语义的能力。即使是对语法进行微小的改变，比如重命名变量，也可能显著影响模型在各种任务上的表现。论文作者检视了类型预测任务，即给定部分类型化的程序，模型能否预测缺少的类型注释，以使程序更具类型化。
### Innovation
论文提出了一个问题，即现有模型在面对语义无关的编辑时表现不稳定，这反映出模型可能对代码语义的理解比较浅。作者通过使用激活引导方法，即通过操纵模型的内部激活来引导模型更有效地使用潜在知识，成功地在对抗性输入上恢复了准确的预测。实验结果表明，激活引导比提示使用上下文示例更有效，且适用于不同编程语言中的通用类型预测机制。
### Conclusion
研究人员发现，虽然LLMs确实学习了有效的类型预测机制，但在对抗性场景中这些机制往往不会被激活。通过激活引导，他们能够在对抗性输入上实现更准确的预测。研究结果显示，LLMs能够学习可跨编程语言转移的代码语义表示。
## 754. `cs.LG` - C2AL: 聚类对比辅助学习在大规模推荐系统中的应用 [PDF](https://arxiv.org/pdf/2510.02215), [HTML](https://arxiv.org/abs/2510.02215)
### Authors
Mertcan Cokbas,Ziteng Liu,Zeyi Tao,Elder Veliz,Qin Huang,Ellie Wen,Huayu Li,Qiang Jin,Murat Duman,Benjamin Au,Guy Lebanon,Sagar Chordia,Chengkai Zhang
### Background
在训练大规模推荐模型时，通常假定用户群体是同质的，但现实世界的数据是由不同条件分布的独特群体组成的混合体。随着模型规模和复杂性的增加以及训练数据量的增多，模型会受到主要分布模式的影响，从而忽视尾部区域，造成数据分布的不平衡。这种不平衡限制了模型的学习能力，可能导致注意力权重失效或神经元死亡。本文揭示了注意力机制在共享嵌入选择中的重要作用，并提出通过分析数据集的子结构和暴露那些具有强烈分布对比的结构来应对这一挑战，通过部分冲突的辅助标签来正则化共享表示，从而定制化地调整注意力层的学习过程，以保留与少数群体的互信息同时提升全局性能。
### Innovation
本文提出了C2AL方法，通过分析数据集的子结构并利用部分冲突的辅助标签来正则化共享表示，定制化调整注意力层的学习过程，以保留与少数群体的互信息同时提升全局性能。这种方法不同于以往的研究，后者是通过加权标签或多任务头部来缓解这种偏差，而C2AL方法利用部分冲突的辅助标签进行正则化。实验结果表明，通过使用此方法，因子机模型能够更好地捕捉用户之间的细微交互，整体减少了归一化熵0.16%，并且在针对少数群体方面取得了超过0.30%的性能提升。
### Conclusion
本文通过实验验证了C2AL方法的有效性，在大规模推荐系统中显著提升了针对少数群体的性能，同时保持了全局性能的优化。
## 755. `cs.LG` - 通过熵正则化扩展均场变分推断：理论与计算 [PDF](https://arxiv.org/pdf/2404.09113), [HTML](https://arxiv.org/abs/2404.09113)
### Authors
Bohan Wu,David Blei
### Background
变分推断(VI)作为一种在高维贝叶斯模型中进行近似推理的流行方法已经崭露头角。本研究旨在探索一种新的VI方法，它在原始的均场方法基础上，通过熵正则化来改进，称为$?Xi$-VI方法。$?Xi$-VI方法与熵最优传输问题有着紧密的联系，并借助于高效计算的Sinkhorn算法增强了其计算能力.
### Innovation
本研究提出了$?Xi$-VI方法，这是一种新的均场VI方法的扩展，通过熵正则化来改进。该方法有效地恢复了真实后验依赖性，通过正则化参数对依赖性进行减权。研究了参数空间维度对$?Xi$-VI近似精度的影响及其对计算考虑的影响，给出了$?Xi$-VI统计-计算权衡的概要分析，同时探讨了$?Xi$-VI的频率主义性质，包括一致性、渐近正态性、高维渐近性和算法稳定性，并提出实现多项式时间近似推理的充分条件。
### Conclusion
最后，研究在模拟和真实数据上证明了$?Xi$-VI方法在实际应用中的优势，比传统的均场VI方法更具优势。
## 756. `cs.LG` - 分批次非参数化上下文多臂老虎机 [PDF](https://arxiv.org/pdf/2402.17732), [HTML](https://arxiv.org/abs/2402.17732)
### Authors
Rong Jiang,Cong Ma
### Background
该研究探讨了在分批次约束下的非参数上下文多臂老虎机问题。在这种模型中，每个行动的预期奖励被建模为协变量的平滑函数，并且政策更新是在观察的每个批次结束时进行。研究者们设定了这种环境下的最小最大后悔下界，并提出了一种新颖的分批次学习算法，该算法能够在日志因子的精度范围内达到最优的后悔值。理论结果表明，在完全在线设置中，几乎常数个策略更新可以达到最优后悔值，这主要依赖于批处理大小与特征空间划分的关系。
### Innovation
该研究提出的算法在分批次约束下实现了最优后悔值（除了对数因子）。这归功于算法动态地将特征空间拆分为更小的区间，合理地调整这些区间的宽度与批次大小之间的关系。
### Conclusion
该研究为非参数上下文多臂老虎机设定了一种接近常数的策略更新次数，以达到最优的后悔值，在完全在线的环境下几乎可以实现最优结果，为这一领域的应用提供了新的视角和方法。
## 757. `cs.LG` - 机器学习算法中的歧视 [PDF](https://arxiv.org/pdf/2207.00108), [HTML](https://arxiv.org/abs/2207.00108)
### Authors
Roberta Pappadà,Francesco Pauli
### Background
机器学习算法在商业决策中广泛使用，这些决策可能会直接影响个人，例如，因为信用评分算法拒绝某人贷款。因此，从伦理和法律的角度来看，需要确保这些算法不会基于敏感属性（如性别或种族）歧视个体，这可能是无意且不知情地发生的。这就需要统计工具和方法来检测和消除这些潜在的偏见。
### Innovation
本文没有直接提及具体的创新点，但背景部分强调了检测和消除机器学习算法潜在偏见的重要性。
### Conclusion
需要使用统计工具和方法来检测和消除机器学习算法中的潜在偏见，以确保算法不会基于敏感属性歧视个体。
## 758. `cs.LG` - 通过顺序蒙特卡洛方法进行扩散后采样以实现零样本蛋白质基序支架 [PDF](https://arxiv.org/pdf/2412.05788), [HTML](https://arxiv.org/abs/2412.05788)
### Authors
James Matthew Young,O. Deniz Akyildiz
### Background
随着扩散模型的出现，可以以前所未有的速度生成新的蛋白质。motif支架问题涉及到指导这一生成过程，以产生具有某种功能亚结构的蛋白质motif。尽管模型已被训练以motif作为条件输入，但最近的技术可以利用扩散后采样的后验采样技术作为零样本替代方案，并通过顺序蒙特卡洛（SMC）算法对其进行校正。在此工作之中，我们提出了一个新的指导势能集，利用Genie无条件模型，并在SMC辅助的扩散后采样器中进行调整，以解决支架任务，并展示了在单motif问题中的效果。
### Innovation
我们引入了一种新的指导势能集，并将SMC辅助的扩散后采样器与Genie无条件模型结合使用，适应无条件模型，提供零样本蛋白质基序支架解决方案。在单motif问题上，发现提出的方法在某些情况下甚至优于传统的掩盖方法，并且重建指导方法的采样器优于替换方法。测量倾斜提议和扭曲目标大幅提高了性能。此外，通过将重建指导与SE(3)不变力场配对，我们提出了解决多motif问题的方法，并生成了具有点对称约束设计的内部对称单一分子。
### Conclusion
我们的工作展示了利用SMC辅助扩散后采样技术实现蛋白质基序零样本支架的方法，并证明了其在单motif和多motif问题上的有效性和适用性，以及生成具有特殊对称性的蛋白质分子的可能性。
## 759. `cs.LG` - 基于线性函数逼近的时序差分学习的统计推断 [PDF](https://arxiv.org/pdf/2410.16106), [HTML](https://arxiv.org/abs/2410.16106)
### Authors
Weichen Wu,Gen Li,Yuting Wei,Alessandro Rinaldo
### Background
本文探讨了时序差分（TD）学习算法，特别是与Polyak-Ruppert平均结合时的统计特性，该算法在强化学习中被广泛使用。研究的目标是估计最优线性价值函数模型的参数。研究假设样本独立，推导了更精确的高概率收敛保证，提出了更细的高维Berry-Esseen边界，以及提出了一种新的在线插值估计的渐近协方差矩阵的方法，这些都优于现有研究结果，为价值函数逼近的线性参数提供可靠的信心区域和同时的信心区间提供了基础。
### Innovation
- 推导了更精确的高概率收敛保证，依赖于渐近方差，并在较弱的条件下有效。- 建立了更细化的高维Berry-Esseen边界，达到比现有结果更快的速度。- 提出了一种新的、计算效率高的在线插值估计渐近协方差矩阵的方法。- 这些结果使得能够构造价值函数逼近的线性参数的信心区域和同时的信心区间，具有保证的有限样本覆盖率。
### Conclusion
通过数值实验验证了理论成果的应用性。这些理论成果为理解和优化基于线性函数逼近的TD学习算法提供了重要工具。
## 760. `cs.LG` - 强化学习后推断 [PDF](https://arxiv.org/pdf/2302.08854), [HTML](https://arxiv.org/abs/2302.08854)
### Authors
Vasilis Syrgkanis,Ruohan Zhan
### Background
本文探讨了使用强化学习（RL）算法收集的数据进行估计和推理。这些算法通过在多个阶段与个体单位互动并根据过去的结果更新其策略来进行自适应实验。目标是在数据收集后评估反事实策略，并估计动态治疗效果等结构参数，以支持归因分配并量化早期行动对最终结果的影响。这些参数通常可以通过解决矩方程的解来定义，因此本文采用了针对静态数据开发的基于矩的估计方法。然而，在RL设置中，数据是在非平稳行为策略下被自适应收集的。因此，标准估计方法无法确保渐近正态性，因为存在时间变化的方差。为了解决这一问题，文章提出了一个加权广义矩方法（GMM）来使用自适应权重稳定方差。
### Innovation
本文提出的创新点在于提出了一种新的加权广义矩方法（GMM），该方法使用自适应权重来稳定由于数据是在非平稳行为策略下自适应收集而导致的时间变化方差，从而使得标准估计方法能够确保渐近正态性，实现有效的假设检验和统一置信区域的构造。关键应用包括动态治疗效果估计和动态离策评估。
### Conclusion
本研究提出了一个新的方法，在自适应收集的数据下估计稳健的动态治疗效果。通过使用自适应权重来稳定矩估计的方差，该方法能够处理高度异方差性的数据，并带来了有效且一致的测试和统一的置信区间。应用研究还表明，该方法可以在动态环境中提供关于早期行动对最终结果影响的有价值的见解。
## 761. `cs.LG` - PrisonBreak: 使用至多二十五个目标位翻转破解大型语言模型 [PDF](https://arxiv.org/pdf/2412.07192), [HTML](https://arxiv.org/abs/2412.07192)
### Authors
Zachary Coalson,Jeonghyun Woo,Chris S. Lin,Joyce Qu,Yu Sun,Shiyang Chen,Lishan Yang,Gururaj Saileshwar,Prashant Nair,Bo Fang,Sanghyun Hong
### Background
我们研究了商用级安全对齐的大语言模型（LLMs）中的一个新漏洞：这些模型拒绝生成有害响应可以通过翻转少量的模型参数位来破解。与之前的攻击方法相比，我们的攻击方法只需用5到25个位翻转就能破解具有十亿参数的语言模型，需要的位翻转次数比针对小型计算机视觉模型的攻击少40倍。我们的方法直接在运行时在模型内存中取消封，不需要输入级别的修改，即可实现有害输出。实验结果表明，该攻击方法对开源大型语言模型的成功率高达80%-98%，对模型的实用性影响较小。
### Innovation
我们的关键创新是一个高效的位选择算法，该算法可以比之前的算法快20倍来识别关键的位，对于语言模型破解。该算法能够直接在运行时取消封模型，不需要对输入进行修改，并且比基于提示的攻击方法更加高效。
### Conclusion
我们的评估表明，具有较弱后训练对齐的模型需要更少的位翻转就能被破解；某些模型组件，例如价值投影层，更加脆弱；并且该攻击与现有的破解方法机制不同。实验还研究了潜在的对策，发现我们的攻击方法仍然在模型管道的不同阶段对防御措施有效。
## 762. `cs.LG` - XBreaking：基于可解释人工智能的LLM劫持方法 [PDF](https://arxiv.org/pdf/2504.21700), [HTML](https://arxiv.org/abs/2504.21700)
### Authors
Marco Arazzi,Vignesh Kumar Kembu,Antonino Nocera,Vinod P
### Background
大语言模型在现代以AI解决方案为主导的IT领域中是基本的参与者。然而，它们所伴随的安全威胁可能会阻碍其在政府组织、医疗机构等关键应用场景中的可靠采用。为应对这一问题，商业化的大型语言模型通常会经历复杂的过滤机制来删除任何潜在的危害输出。然而，作为一种对抗这种保护的方法，LLM破解已经成为一个显著威胁，目前已有许多研究证明了它在多个领域的有效性。现有的破解方案大多采用生成和测试策略来构造恶意输入，以改善对过滤机制的理解并设计针对性的破解攻击，本文提出了一个可解释的人工智能解决方案，通过比较分析过滤和非过滤模型的行为来推导出唯一的可利用对齐模式。然后，提出了一种名为XBreaking的新颖破解攻击，通过目标噪声注入来利用这些独特的模式打破LLM的安全限制。
### Innovation
提出了一个可解释的人工智能解决方案，通过比较分析过滤和非过滤模型的行为来推导出唯一的可利用对齐模式，然后提出了一种新颖的名为XBreaking的破解攻击，通过目标噪声注入来利用这些独特的模式打破LLM的安全限制。
### Conclusion
通过全面的实验活动，本文提供了关于过滤机制的重要见解，并展示了攻击的有效性和性能。
## 763. `cs.LG` - 使用强化学习实现镜头系统的主动对齐 [PDF](https://arxiv.org/pdf/2503.02075), [HTML](https://arxiv.org/abs/2503.02075)
### Authors
Matthias Burkhardt,Tobias Schmähling,Pascal Stegmann,Michael Layh,Tobias Windisch
### Background
在相机制造过程中，镜头系统与传感器对齐是一项关键挑战。尽管在理想条件下，最优对齐可以通过数学计算确定，但由于制造公差的现实世界偏差，这种方法通常不可行。测量这些公差既昂贵甚至不可能，忽略它们可能导致对齐效果不佳。因此，本文探讨了一种仅在传感器输出的像素空间中进行学习的强化学习方法，旨在消除需要设计专家级对齐概念的需求。
### Innovation
本文提出了一种使用强化学习的方法，该方法完全在传感器输出的像素空间中学习，不需要设计专家级概念。作者通过广泛基准测试展示了该方法在速度、精度和鲁棒性方面超越其他方法。此外，作者还引入了一个真实可信、公开可探索的开源模拟器relign，基于物理渲染，模拟具有非确定性制造公差和机器人对齐运动噪声的光学系统。该模拟器还提供了与流行机器学习框架的接口，以实现无缝实验和开发。
### Conclusion
本文的研究结果表明，强化学习在制造环境中具有提高光学对齐效率的潜力，同时最大限度地减少了手动干预的需要。
## 764. `cs.LG` - L1：使用强化学习控制推理模型思考时长 [PDF](https://arxiv.org/pdf/2503.04697), [HTML](https://arxiv.org/abs/2503.04697)
### Authors
Pranjal Aggarwal,Sean Welleck
### Background
现有的语言模型在测试时展示出一种惊人的能力，即“思考更久”——其通过生成更长的解释链以便使用更多计算资源来提高性能。然而，这些模型的解释链长度不可控，使得无法灵活分配测试时的计算资源以达到期望的性能水平。本文针对这一问题，介绍了Length Controlled Policy Optimization (LCPO)，一个简化且基于强化学习的方法，用于同时优化准确性和遵守用户指定的长度约束。该方法用来训练L1模型，该模型能够根据提示生成满足长度约束的输出，从而在不同任务上较好地平衡计算成本和准确率，并优于先前的方法S1。文章还发现，使用LCPO训练的模型可以产生短的推理链，同时展示类似的推理模式，与非推理模型相当。这些短推理模型(SRMs)在某些场景下表现出显著的性能增益。
### Innovation
提出了Length Controlled Policy Optimization (LCPO) 方法，该方法能够优化模型的准确性和遵守给定的长度约束，通过这种方法可以训练出L1模型，该模型能够根据提示生成满足长度约束的输出。此外，LCPO训练产生的短推理模型（SRMs）能够以接近非推理模型的链长生成推理链，同时保持与全长度推理模型类似的推理模式，并在某些任务上展示出显著的性能提升。这种短推理模型能够在不增加计算资源的情况下提升模型性能。
### Conclusion
LCPO使得推理模型的推理长度可以得到精确控制，从而能够精细地分配测试时的计算资源以达到期望的性能水平。L1和短推理模型(SRMs)有效地展示了如何利用LCPO来优化计算成本和准确率之间的关系。研究人员已经提供了代码和模型供大家使用。
## 765. `cs.LG` - 迭代加权核机高效学习稀疏函数 [PDF](https://arxiv.org/pdf/2505.08277), [HTML](https://arxiv.org/abs/2505.08277)
### Authors
Libin Zhu,Damek Davis,Dmitriy Drusvyatskiy,Maryam Fazel
### Background
神经网络因其能够直接从数据中学习低维表示和分层结构而表现出出色的实践经验。本研究旨在探讨这种能力是否也能通过经典核方法实现。
### Innovation
研究展示了核预测器的导数能够以较低的样本复杂度检测出影响坐标；通过迭代使用导数重新加权数据并重新训练核机器，能够有效学习具有有限跳跃复杂度的分层多项式。
### Conclusion
数值实验验证了该理论的有效性，表明核方法也能够高效地学习稀疏函数。
## 766. `cs.LG` - Topological Autoencoders++: 快速且精确的环感知降维方法 [PDF](https://arxiv.org/pdf/2502.20215), [HTML](https://arxiv.org/abs/2502.20215)
### Authors
Mattéo Clémot,Julie Digne,Julien Tierny
### Background
本文介绍了一种新的拓扑感知降维方法，旨在准确可视化高维数据中存在的循环模式。该方法基于拓扑自编码器（Topological Autoencoders，TopoAE）的建模。首先，作者对TopoAE相关的损失函数进行了新的理论分析，并指出零损失会导致高维和低维中的0维持久同调（PH^0）中的同调对相同。作者还提供了一个反例，说明当将TopoAE扩展到1维及以上持久同调（PH^d, d ≥ 1）时，这一特性不再成立。基于此观察，作者引入了一种新的TopoAE变体——TopoAE++，用于生成环感知的平面嵌入，解决上述失效问题。
### Innovation
作者引入了TopoAE++，这是一种针对1维持久同调（PH^1）的拓扑自编码器的新型通用方法，称为TopoAE++，用于准确生成环感知的平面嵌入，避免了在更高维度的失效情形。这种方法基于环填充2链的级联失真概念，提供了一种新的惩罚项，有利于2链的等距嵌入，从而生成更忠实的1环几何重构。此外，作者还引入了一种快速算法，用于精确计算平面中的Rips滤波的持久同调，提高了运行时效率，与之前的拓扑感知方法相比。
### Conclusion
该方法在拓扑准确性和低维中循环的视觉保留之间实现了更好的平衡，通过 Wasserstein 距离进行度量。作者的 C++ 实现可在该网址获得。
## 767. `cs.LG` - 有害的激活函数：通过受控渠道恢复神经网络权重 [PDF](https://arxiv.org/pdf/2503.19142), [HTML](https://arxiv.org/abs/2503.19142)
### Authors
Jesse Spielman,David Oswald,Mark Ryan,Jo Van Bulck
### Background
高风险机器学习应用越来越多地转移到不可信的终端用户或云环境中，保护预训练模型参数变得至关重要，以保护知识产权和用户隐私。最近，硬件隔离的防护堡垒，如Intel SGX，承诺即使在操作系统被攻破的情况下也能安全地保护机器学习应用的内部状态。然而，研究表明，特权软件对手可以利用神经网络激活函数中的输入依赖型内存访问模式，从SGX防护堡垒中提取机密权重和偏差。
### Innovation
攻击利用SGX-Step框架获取无噪声、指令级的页面访问轨迹。在使用Tensorflow Microlite库的11输入回归网络中证明了可完全恢复第一层权重和偏差，并在特定条件下部分恢复深层的权重参数。这种新颖的攻击技术仅需每输入每个权重20次查询即可在平均绝对误差低于1%的情况下获得所有第一层的权重和偏差，超越了之前模型盗窃攻击。
### Conclusion
广义生态系统分析揭示了在流行机器学习框架中广泛使用的具有输入依赖型内存访问模式的激活函数，无论是直接还是通过底层数学库。我们的发现强调部署在SGX防护堡垒中的机密模型的局限性，并强调需要对机器学习实现进行更严格的侧面信道验证，类似于对安全密码库的验证努力。
## 768. `cs.LG` - 编程与像素：计算机使用代理能否进行软件工程？ [PDF](https://arxiv.org/pdf/2502.18525), [HTML](https://arxiv.org/abs/2502.18525)
### Authors
Pranjal Aggarwal,Sean Welleck
### Background
当前，计算机使用代理（CUAs）能够执行广泛的通用任务，但现有的评估主要集中在简单的场景上，这使得人们不清楚这些通用的代理是否能够自动化更复杂的专门工作，例如软件工程（SWE）。为了研究这一问题，本研究引入了 $texttt{编程与像素}$ (PwP)，这是首个全面的软件工程计算机使用环境，允许代理通过视觉控制IDE（集成开发环境）来执行多样化的软件工程任务。为了实现整体评估，研究还引入了 $texttt{编程与像素-基准}$（PwP-Bench），这是一个包含15个现有和新开发的软件工程任务的基准测试集，这些任务覆盖了多种模态、编程语言和技能级别。
### Innovation
本研究引入了首个全面的软件工程计算机使用环境 $texttt{编程与像素}$ (PwP) 和 $texttt{编程与像素-基准}$（PwP-Bench），这是评估计算机使用代理自动化复杂任务能力的关键进步。研究发现，当CUAs仅通过视觉交互时，它们的表现明显逊色于专门的编程代理；但当赋予它们访问特定API（如文件编辑和bash操作）时，性能显著提升，甚至达到了专门代理的水平，尽管设计上是任务无关的；进一步接入IDE工具后，所有模型的表现进一步改善。研究揭示当前CUAs的主要不足是视觉接地能力有限以及不能充分利用丰富环境，为未来改进指明方向。
### Conclusion
本研究展示了当前计算机使用代理在自动化复杂任务方面的能力有限，尤其是在视觉交互上和环境利用上存在一定局限。然而，通过适当的功能增强，它们可以接近甚至达到专门代理的水平。因此，软件工程被确立为评估通用计算机使用代理是否能够胜任高级任务的一个自然领域，进一步的研究需要关注提升代理的视觉理解能力和环境适应性。研究团队已开放了相关代码和数据可以在相应网址找到。
## 769. `cs.LG` - Dynamical local Fréchet curve regression in manifolds [PDF](https://arxiv.org/pdf/2505.05168), [HTML](https://arxiv.org/abs/2505.05168)
### Authors
M.D. Ruiz-Medina,A. Torres-Signes
### Background
该论文致力于从时间相关双变量曲线数据在流形上评估的外在和内在局部线性近似Frechet条件均值问题。它基于Torres等人（2025）对流形上全局Frechet函数回归的研究进一步深入探讨。背景信息还包括外在局部线性Frechet函数回归预测的获得以及采用加权Frechet均值方法计算内在局部线性Frechet函数回归预测，并证明了这种内在局部近似的渐近最优性。此外，论文通过模拟研究展示了两种回归预测的有限样本性能，并考虑了对NASA的MAGSAT卫星时间变化地心纬度和经度预测地球磁场的应用问题。
### Innovation
论文的创新在于通过投影到流形嵌入空间的正交本征函数基形成了时间变化切空间中的外在局部线性Fréchet函数回归预测，并采用加权Fréchet均值方法计算内在局部线性Fréchet函数回归预测。同时，论文证明了这种内在局部近似的渐近最优性，并通过模拟研究验证了该方法在有限样本下的性能。
### Conclusion
论文展示了外在和内在局部福尔切函数回归预测以及一种Nadaraya-Watson类型的Fréchet曲线预测方法在时间相关双变量曲线数据在流形上的有限样本性能，并将其应用于预测NASA的MAGSAT卫星位置的地球磁场。总之，该研究揭示了局部Fréchet函数回归在流形上估计的时间相关曲线数据的有效性和可靠性。
## 770. `cs.LG` - 具有多布尔架构的高效且有效的大型语言模型 [PDF](https://arxiv.org/pdf/2505.22811), [HTML](https://arxiv.org/abs/2505.22811)
### Authors
Ba-Hien Tran,Van Minh Nguyen
### Background
权重二值化已经成为降低大型语言模型复杂性的有前途的策略。现有方法分为后训练二值化和训练感知方法。后训练二值化简单但会导致严重的性能下降。训练感知方法依赖于完整的精度潜在权重，这增加了复杂性并限制了效率。
### Innovation
提出了一种新颖的框架，使用多内核布尔参数表示大型语言模型，并首次使直接在布尔域微调大型语言模型成为可能，从而消除了潜在权重的需求。这增强了表示能力，并在微调和推理过程中大大降低了复杂性。
### Conclusion
在各种类型的大型语言模型中进行的大量实验表明，该方法优于最近的超低位量化和二值化技术。
## 771. `cs.LG` - Permissioned LLMs: Enforcing Access Control in Large Language Models [PDF](https://arxiv.org/pdf/2505.22860), [HTML](https://arxiv.org/abs/2505.22860)
### Authors
Bargav Jayaraman,Virendra J. Marathe,Hamid Mozaffari,William F. Shen,Krishnaram Kenthapadi
### Background
在企业环境中，组织数据被分割、孤立，并且通过复杂的访问控制框架严格保护。如果一个细调了孤立数据的大型语言模型（LLM）向具备不同访问权限的个体提供请求，可能会完全破坏这些访问控制结构。
### Innovation
我们提出了Permissioned LLMs（PermLLM），这是一种新的LLM类别，它在生成查询响应时将组织数据的访问控制结构叠加在其上。我们正式化了一种方法，用于确定在LLM查询响应上是否正确实施了访问控制。我们引入了相关响应的概念，用于证明PermLLM机制是否正确实现。我们还引入了一个新的度量标准，称为访问优势，以实证评估PermLLM机制的有效性。我们提出了三种基于参数高效微调的新PermLLM机制，并且引入了两个基于具体访问优势评估方法（域区分指数DDI和工具差距指数UGI）。
### Conclusion
我们通过在五个公开数据集上进行广泛的实验（GPQA、RCV1、SimpleQA、WMDP和PubMedQA），以及评估DDI和UGI度量标准是否可以量化LLM中的访问控制来证明我们的PermLLM机制的效用。
## 772. `cs.LG` - 基于分数阶谱分析和 Malliavin 微积分的随机场评分基于扩散生成模型方法 [PDF](https://arxiv.org/pdf/2505.13189), [HTML](https://arxiv.org/abs/2505.13189)
### Authors
Giacomo Greco
### Background
本文采用 Gamma 和 Malliavin 微积分的观点，将评分基于扩散生成模型（SGMs）推广到无限维抽象希尔伯特空间中。文章通过 Dirichlet 形式和 Cameron-Martin 空间中的高斯测度及维纳混沌关联的前向噪声明过程进行了定义，利用抽象的时间反转公式，证明了评分函数是 Malliavin 导数并且对应于条件期望。通过强调 Cameron-Martin 范数在数据分布 Fisher 信息中的作用，还扩展了现有的有限维熵收敛界值到希尔伯特空间中。最后，对于球面随机场进行了具体讨论，将噪声来源定义为 Whittle-Matérn 球面随机场。
### Innovation
本文首次将 Gamma 和 Malliavin 微积分的观点应用于评分基于扩散生成模型，成功将其推广到无限维抽象希尔伯特空间中，并通过强调 Cameron-Martin 范数的角色，扩展了熵收敛界值到希尔伯特空间。同时，该研究首次将 Whittle-Matérn 球面随机场应用于噪声源，具备创新性。
### Conclusion
文章通过 Gamma 和 Malliavin微积分的观点，成功推广了评分基于扩散生成模型到无限维抽象希尔伯特空间中，并探讨了熵收敛界值。特别地，着重阐述了Cameron-Martin范数在数据分布 Fisher信息中的作用，并针对球面随机场所做具体讨论。
## 773. `cs.LG` - 使用内部和外部知识预训练有限记忆语言模型 [PDF](https://arxiv.org/pdf/2505.15962), [HTML](https://arxiv.org/abs/2505.15962)
### Authors
Linxi Zhao,Sofian Zalouk,Christian K. Belardi,Justin Lovelace,Jin Peng Zhou,Ryan Thomas Noonan,Dongyoung Go,Kilian Q. Weinberger,Yoav Artzi,Jennifer J. Sun
### Background
现有的神经语言模型就像一个黑箱，语言规律和事实知识是分散在数十亿个不透明的参数中。这种复杂的编码结构使得检查、验证或更新特定事实变得困难。本文探讨了一种新的方法——有限记忆语言模型（LMLM），它在预训练过程中将事实知识外部化到外部数据库中，而不是记忆这些知识，以此来解决上述问题。
### Innovation
LMLMs在预训练过程中战略性地隐藏从外部检索到的事实值，从而教导模型进行目标性查询，而不是依赖于模型权重记忆。实验结果表明，LMLMs在标准基准测试上的性能与显著更大的语言模型相当，同时具有可解释、可编辑和可验证的知识库的优点。
### Conclusion
LMLMs通过外部化知识，提高了模型的透明度和可维护性，而不会显著牺牲其性能。
## 774. `cs.LG` - HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios [PDF](https://arxiv.org/pdf/2506.09650), [HTML](https://arxiv.org/abs/2506.09650)
### Authors
Kunyu Peng,Junchao Huang,Xiangsheng Huang,Di Wen,Junwei Zheng,Yufan Chen,Kailun Yang,Jiamin Wu,Chongqing Hao,Rainer Stiefelhagen
### Background
动作分割是高级视频理解中的核心挑战，旨在将未修剪的视频分割成段，并为每个段分配一个预定义的动作集。现有的方法主要针对单人活动并固定了动作序列，忽略了多人场景。目前的工作首先在多人场景中提出了一种基于文本引用的人类动作分割方法，其中文本描述指定分割的目标人。HopaDIFF 是第一个为此新任务构建的数据集，使用 VLM 基础特征提取器在 RHAS133 上基准测试现有动作分割方法，表明这些方法性能有限且目标人视觉线索聚合不佳。因此需要改进的方法来提高性能和分割效果，特别是针对多人场景中的动作分割作业。
### Innovation
这项工作首次引入了基于文本引用的多人场景人类动作分割，提出了一个霍普拉耦合差分框架（HopaDIFF），结合了新颖的交叉输入门注意力xlstm来增强整体-部分长程推理，并引入新的傅立叶条件以提供更多细粒度控制，以改善动作分割生成，这在各种评估设置中达到了现有技术的最佳效果，且开源了数据集和代码。
### Conclusion
HopaDIFF 在 RHAS133 数据集上取得了最先进的结果，包括构建了一个名为 RHAS133 的新数据集，提出了基于文本引用的多人视频中的动作分割方法，并开发了一个新的傅立叶条件下的整体-部分感知扩散模型，证明了该模型的有效性和先进性，为未来的研究提供了有价值的工作基础。
## 775. `cs.LG` - 预条件次梯度方法在复合优化中的应用：过度参数化和快速收敛 [PDF](https://arxiv.org/pdf/2509.11486), [HTML](https://arxiv.org/abs/2509.11486)
### Authors
Mateo Díaz,Liwei Jiang,Abdel Ghani Labassi
### Background
复合优化问题涉及最小化平滑映射与凸函数的复合。这类目标函数在数据科学和信号处理应用中广泛出现，例如相位恢复、盲去卷积和协作过滤。子梯度方法在复合损失良好时可以实现局部线性收敛，但如果平滑映射在某种意义上是病态或过度参数化的，即使凸函数良好，子梯度方法也会表现出较慢的亚线性收敛。
### Innovation
引入了一种Levenberg-Morrison-Marquardt子梯度方法，它在较为温和的正则条件下可以实现线性收敛，并且这种收敛速率仅由凸函数决定。进一步证明了这些问题满足正则条件，包括平方变量形式、矩阵感知和张量分解。
### Conclusion
数值实验表明了该方法的优势。
## 776. `cs.LG` - 双重阶段加权MoE模型在长尾第一人称错误检测中的应用 [PDF](https://arxiv.org/pdf/2509.12990), [HTML](https://arxiv.org/abs/2509.12990)
### Authors
Boyu Han,Qianqian Xu,Shilong Bao,Zhiyong Yang,Sicong Li,Qingming Huang
### Background
该研究提出了一个针对第一人称视角视频数据的用户行动错误检测问题。由于细微且不频繁的错误使得检测难度增大，研究需要一个能够有效处理这些问题的新型框架。
### Innovation
提出了一个双重阶段重权重混合专家(DR-MoE)模型，第一阶段使用固定和微调的ViViT模型提取特征，并通过特征专家模块进行结合。第二阶段采用三个不同的分类器训练，分别为缓解类别不平衡的加权交叉熵损失、改善分布倾斜排名的AUC损失以及基于标签感知损失和清晰度 aware最小化提高校准与泛化能力。最终通过分类专家模块融合这三个分类器的预测。
### Conclusion
提出的方法在识别罕见和模糊错误实例方面表现出色。源代码已发布，可供进一步研究使用。
## 777. `cs.LG` - 多层时空过渡图解纠缠表示学习及其在社会增强POI推荐中的应用 [PDF](https://arxiv.org/pdf/2508.07649), [HTML](https://arxiv.org/abs/2508.07649)
### Authors
Jie Li,Haoye Dong,Zhengyang Wu,Zetao Zheng,Mingrong Lin
### Background
POI推荐是商务智能中的研究热点，用户的空间-时间过渡和社会关系起着关键作用。然而，现有的大部分工作分别建模空间和时间过渡，导致相同的空间-时间关键节点的表示不一致。这种不一致在融合过程中引入冗余信息，增加了模型的不确定性并降低了可解释性。为了解决这个问题，本文提出了DiMuST，一种基于多层时空过渡图上的解纠缠表示学习的社会增强POI推荐模型。该模型采用了一个新颖的解纠缠变分多层图自动编码器（DAE），该模型首先通过多层时空图策略解纠缠共享和私有分布，然后通过专家乘积（PoE）机制融合共享特征并通过对比约束对私有特征进行去噪。该模型有效地捕捉POI的空间-时间过渡表示，同时保留其时空关系的固有相关性。实验表明，DiMuST在多个指标上显著优于现有方法。
### Innovation
提出了一种基于多层时空过渡图上的解纠缠表示学习的社会增强POI推荐模型DiMuST，该模型首先通过多层时空图策略解纠缠共享和私有分布，然后通过专家乘积（PoE）机制融合共享特征并通过对比约束对私有特征进行去噪。
### Conclusion
实验结果显示，DiMuST在两个具有挑战性的数据集上显著优于现有方法，能够有效地捕捉POI的空间-时间过渡表示，同时保留其时空关系的固有相关性。
## 778. `cs.LG` - 在世界隐空间中学习交互以实现团队协调 [PDF](https://arxiv.org/pdf/2509.25550), [HTML](https://arxiv.org/abs/2509.25550)
### Authors
Dongsu Lee,Daehee Lee,Yaru Niu,Honguk Woo,Amy Zhang,Ding Zhao
### Background
团队协调在多智能体强化学习（MARL）中是一个具有挑战性的问题。多智能体之间的复杂动态和由于局部观察而导致的不完整信息使这一过程变得复杂。因此，需要一种能有效捕捉智能体之间关系和任务特定世界信息的表示方法。
### Innovation
提出了一个新颖的表示学习框架，即交互世界隐空间（IWoL）。该框架通过直接建模通信协议，共同捕捉智能体之间的关系和特定任务的世界信息，提供了一种全分布式的机制来进行隐式的协调。相比显式的消息传递，IWoL能够避免决策速度变慢、对恶意攻击者易受攻击以及对带宽限制敏感等问题。在四种具有挑战性的MARL基准测试上，该框架展现了在团队协调方面的简单而强大的性能。
### Conclusion
IWoL不仅可以用作智能体的隐式表示，还可以作为通信的信息。通过与现有MARL算法的结合使用，IWoL进一步提升了这些算法的性能。
## 779. `cs.LG` - 朝向大小不变的显著对象检测：一种通用评估和优化方法 [PDF](https://arxiv.org/pdf/2509.15573), [HTML](https://arxiv.org/abs/2509.15573)
### Authors
Shilong Bao,Qianqian Xu,Feiran Li,Boyu Han,Zhiyong Yang,Xiaochun Cao,Qingming Huang
### Background
现有研究对显著对象检测(SOD)中现有评价指标的固有大小敏感性关注不够，特别是在单张图像中同时出现多个大小差异显著的显著对象时。目前的评估结果主要受较大区域预测错误主导，而较小但可能更具语义重要性的对象往往被忽视，导致性能评估偏向不足且实际性能下降。
### Innovation
提出了一个通用的大小不变评价框架(SIEva)，通过逐个评估每个可分离部分，然后聚合结果来有效缓解对象间大小不一致的影响。进一步开发了遵循大小不变原则的专门优化框架(SIOpt)，显著增强了跨各种大小范围的显著对象检测性能。该优化框架模型无关，可与广泛的SOD骨干网络无缝集成。此外还对SOD方法进行了泛化分析，并提供了新评估协议有效性的证据支持。
### Conclusion
全面的实验验证了我们提出方法的有效性。相关代码可在以下链接获取。
## 780. `cs.LG` - 基于YOLO的金属板缺陷检测 [PDF](https://arxiv.org/pdf/2509.25659), [HTML](https://arxiv.org/abs/2509.25659)
### Authors
Po-Heng Chou,Chun-Chi Wang,Wei-Lung Mao
### Background
工业制造中人工缺陷检测任务耗时且费力。作者使用了YOLO模型来开发一种自动缺陷检测模型，以提高检测效率。
### Innovation
结合使用了ConSinGAN数据生成技术与YOLO模型（包括YOLOv3, v4, v7, v9版本）进行缺陷检测，尤其是通过使用YOLOv9与ConSinGAN相结合提高了检测精度至91.3%，同时检测时间缩短至146毫秒。
### Conclusion
提出的方法通过与工业硬件和SCADA系统的整合，建立了一个实际的自动光学检测系统，并且该方法可以很容易地应用于工业制造中的其他组件，提升了工业制造中缺陷检测的整体效率和适用性。
## 781. `cs.LG` - 图论与卫星星座联邦学习的结合：跨越聚合、网络构成及性能优化 [PDF](https://arxiv.org/pdf/2509.24932), [HTML](https://arxiv.org/abs/2509.24932)
### Authors
Fardis Nadimi,Payam Abdisarabshali,Jacob Chakareski,Nicholas Mastronarde,Seyyedali Hosseinalipour
### Background
本文介绍了Fed-Span，一种专为低地球轨道卫星星座设计的联邦/分布式学习框架。该框架旨在解决分布式学习在动态卫星网络中固有的关键挑战，包括卫星间断性的连接问题、卫星计算能力的异构性及其随时间变化的存储数据集的多样性和变动性。Fed-Span的核心是通过最小生成树(MST)和最小生成森林(MSF)拓扑引入跨越模型的聚合和分派过程，以支持分布式学习。
### Innovation
Fed-Span引入了使用连续约束表达式的最小生成树(MST)和最小生成森林(MSF)拓扑的新视角，将图论抽象转化为优化框架，以实现在卫星网络中的模型聚合和传输调度。通过这些连续约束表达式，提出了一种新型的收敛准则，推导出能耗、延迟损失以及联合最小化模型预测误差、能耗和延迟的一系列优化问题。提出的优化问题是NP难题，通过逐步凸优化转化为几何编程问题，保证了其性能。
### Conclusion
实验结果表明，Fed-Span在模型收敛速度、能量效率和延迟优化方面优于现有方法。基于此，Fed-Span为在卫星网络中进行高效分布式学习提供了一种新颖的解决方案。
## 782. `cs.LG` - DeepGDel：基于深度学习的基因删除预测框架以实现全基因组规模代谢模型中的生长耦合生产 [PDF](https://arxiv.org/pdf/2504.06316), [HTML](https://arxiv.org/abs/2504.06316)
### Authors
Ziwei Yang,Takeyuki Tamura
### Background
在全基因组规模的基于约束的代谢模型中，基因删除策略对于实现生长耦合生产至关重要。虽然已经广泛探索了计算方法来计算基因删除，但由于当前方法无法充分利用诸如机器学习等数据驱动的新方法，因此这些方法在更高效的菌株设计中效率较低。因此，需要提出一种基本框架来实现这一目标。
### Innovation
本文提出了一个基于深度学习的框架，用于预测全基因组规模代谢模型中的生长耦合生产中的基因删除策略。该框架利用深度学习算法学习和整合顺序基因和代谢物数据表示，从而实现了自动化的基因删除策略预测。
### Conclusion
计算实验结果表明所提出的框架的可行性，显示了在不同规模的三个代谢模型中相比于基线方法的巨大改进。在研究中涉及的三个代谢模型下，所提出的框架在总体准确性上分别提高了14.69%、22.52%和13.03%，同时在预测基因删除状态时保持了平衡的精确度和召回率。这个框架的源代码和示例在该网址公开：this https URL。
## 783. `cs.LG` - 基于决策树的高效且正确的预测等价性 [PDF](https://arxiv.org/pdf/2509.17774), [HTML](https://arxiv.org/abs/2509.17774)
### Authors
Joao Marques-Silva,Alexey Ignatiev
### Background
近期研究表明，计算相同分类函数的不同决策树（预测等价树）构成了决策树拉什莫尔集合的重要部分，这种冗余性是不理想的。例如，基于拉什莫尔集合的特征重要性分析变得不准确，因为存在预测等价树，即对于所有可能的输入具有相同预测结果的决策树。先前的研究提出了判断预测等价树的方法，但该方法的计算复杂度和空间复杂度可能非常高，导致效率低下和结果不准确。因此，本文探讨了决策树预测等价性的高效且正确的判定方法，分析了存在的问题并提供了改进方案。
### Innovation
本文首次证明了存在某些决策树可导致Quine-McCluskey方法的最坏情况指数级运行时间和空间。进一步指出，Quine-McCluskey方法可能在处理不满足关键约束条件的情况下错误地决定预测等价性。最后，本文证明了对决策树应用最小DNF表示的所有问题都可以在决策树大小的基础上通过多项式时间解决。实验结果表明，对于Quine-McCluskey方法达到最坏情况的决策树，本文提出的新算法比McTavish等人提出的方法快许多数量级。
### Conclusion
本文针对决策树拉什莫尔集合中预测等价树的存在性问题进行了深入分析，并提出了改进Quine-McCluskey方法的新算法，该方法在处理问题时更为高效且正确，实验验证了算法的有效性。
## 784. `cs.LG` - 深度矩阵分解中极小值的锐度：精确表达式 [PDF](https://arxiv.org/pdf/2509.25783), [HTML](https://arxiv.org/abs/2509.25783)
### Authors
Anil Kamber,Rahul Parhi
### Background
理解损失景观中最小值附近的几何特性对于解释基于梯度的方法在深度学习和矩阵分解等非凸优化问题中的隐式偏置至关重要。关键量是对损失海森矩阵的最大特征值，它衡量了景观的锐度。目前，对这一特征值的具体作用尚不清楚，因为一般情况下的精确表达式未知。
### Innovation
本文首次提出了在一般过参数化深层矩阵分解（即深层线性神经网络训练）问题中任意极小点处平方误差损失海森矩阵的最大特征值的精确表达式，这解决了Mulayoff & Michaeli（2020）提出的一个开放性问题。此外，通过实验研究了基于梯度的训练过程中接近极小值时的逃逸现象，并依赖于我们对锐度的精确表达式的研究结果。
### Conclusion
本文提出了极小值的锐度在一般过参数化深层矩阵分解中的精确公式，解释了梯度基于方法的隐式偏置，并且通过实验研究接近极小值时的基本现象。
## 785. `cs.LG` - MobiLLM：一种用于6G开放RAN闭环威胁缓解的具身AI框架 [PDF](https://arxiv.org/pdf/2509.21634), [HTML](https://arxiv.org/abs/2509.21634)
### Authors
Prakhar Sharma,Haohuang Wen,Vinod Yegneswaran,Ashish Gehani,Phillip Porras,Zhiqiang Lin
### Background
开放RAN（O-RAN）作为一种开放和可互操作的架构，正在加速6G网络的发展，它支持智能和模块化应用。尽管O-RAN带来了前所未有的创新机会，但也扩大了潜在的安全攻击面，因此需要更可靠、低成本和自主的安全解决方案。传统的防御措施多为被动反应、劳动密集型且对于下一代系统的规模和复杂性来说并不足够。现有的O-RAN应用主要集中在网络优化或被动威胁检测，缺乏闭环自动化响应的能力。
### Innovation
本文提出了一种具身人工智能框架MobiLLM，用于6G O-RAN环境中的全自动化端到端威胁缓解。MobiLLM通过由大型语言模型（LLM）驱动的模块化多智能体系统来协调安全工作流程。框架包含威胁分析代理、使用检索增强生成（RAG）映射异常到特定对策的威胁分类代理，以及通过O-RAN控制接口确保安全执行缓解行动的威胁响应代理。基于MITRE FiGHT框架和其他3GPP规范，MobiLLM提供了一个可信赖的人工智能驱动网络安全的蓝图。初步评估结果表明，MobiLLM可以有效地识别并协调复杂的缓解策略，显著降低响应时间，并展示了自主安全操作在6G中的可行性。
### Conclusion
MobiLLM提供了一个全自动化和基于大型语言模型的威胁缓解框架，能够有效应对6G O-RAN环境中的安全挑战，显著提升了响应速度，并展示了人工智能驱动的安全操作在下一代网络中的可行性。
## 786. `cs.LG` - IntrusionX: 一种使用松鼠搜索优化的卷积-LSTM 深度学习框架用于网络入侵检测 [PDF](https://arxiv.org/pdf/2510.00572), [HTML](https://arxiv.org/abs/2510.00572)
### Authors
Ahsan Farabi,Muhaiminul Rashid Shad,Israt Khandaker
### Background
由于网络攻击的持续变化、网络流量数据的高维性和基准数据集中严重的类别不平衡，入侵检测系统（IDS）面临着持续的挑战。NSL-KDD等数据集中的这些特点使得传统的IDS方法难以有效检测入侵。
### Innovation
本文提出了一种名为IntrusionX的混合深度学习框架，该框架结合了卷积神经网络（CNN）进行局部特征提取和长短期记忆网络（LSTM）进行时间序列建模。此外，模型通过松鼠搜索算法（SSA）进一步优化，实现了高效的超参数调优同时保持计算效率。此框架中的数据预处理、分层数据分割和动态类别权重赋予了体系结构一种可重复性、不平衡数据敏感的设计，并通过元启发式优化增强了小类别的检测能力。
### Conclusion
实验结果表明，基于NSL-KDD的数据集，IntrusionX在二分类中达到98%的准确率，在5类分类中达到87%的准确率，并在针对小类别的召回率上取得了显著进展（U2R: 71%，R2L: 93%）。该研究的创新之处在于其具备可重复性、不平衡数据敏感设计，并采用元启发式优化进行模型优化。
## 787. `cs.LG` - GPT与偏见：理解大型语言模型中学习表示的一种稀疏方法 [PDF](https://arxiv.org/pdf/2510.01252), [HTML](https://arxiv.org/abs/2510.01252)
### Authors
Mariam Mahran,Katharina Simbeck
### Background
随着大型语言模型（LLMs）越来越多地被训练在海量、未经过滤的数据集上，理解模型的表现及其内部化的数据结构、主题和偏见已成为一个重要挑战。
### Innovation
本文展示了将大语言模型与稀疏自编码器（SAEs）结合使用，不仅能够解释模型行为，还可以揭示训练数据中嵌入的深层次结构、主题和偏见。研究者使用一种类似GPT的转换器模型专门训练简·奥斯汀的小说集，一个包含丰富社会构造和叙事模式的语料库。通过应用SAEs到多个层级的隐藏状态中，发现稀疏且可解释的特征，这些特征反映了语料库中的关键叙事和概念，如性别、阶级和社会职责。这些发现证明了结合大语言模型和SAEs可以作为一种可扩展的探针工具，用于复杂数据集的研究、偏见的发现以及大规模模型解释性。
### Conclusion
结合大语言模型和SAEs可以作为一种可扩展的探索复杂数据集的方法，提供了一条新的路径，用于发现语料库中的偏见并且提高模型的解释性。
## 788. `cs.LG` - VarCoNet：一种用于静息态功能性连接体提取的感知个体差异的自监督框架 [PDF](https://arxiv.org/pdf/2510.02120), [HTML](https://arxiv.org/abs/2510.02120)
### Authors
Charalampos Lamprou,Aamna Alshehhi,Leontios J. Hadjileontiadis,Mohamed L. Seghier
### Background
考虑到个体间脑功能的差异性是精确医疗中关键的一环，本文通过将功能个体差异视为有意义的数据而非噪声，提出了一种增强的自监督框架VarCoNet，用于从静息态功能磁共振成像（rs-fMRI）数据中稳健地提取功能性连接组（FC）。该框架利用自监督对比学习来利用内在的功能个体差异，作为脑功能编码器，即使在缺乏标签数据的情况下也能生成易于应用于下游任务的FC嵌入。
### Innovation
VarCoNet采用自我监督的方法，通过新颖的数据增强策略（基于rs-fMRI信号分段）进行对比学习，增强了1D-CNN-Transformer编码器的时间序列处理能力，并加入了鲁棒的贝叶斯超参数优化。该框架被用于两个下游任务：（i）从人类连接组项目（HCP）获取静息态fMRI数据进行个体特征指纹识别；（ii）使用ABIDE I和ABIDE II数据集的静息态fMRI数据进行自闭症谱系障碍（ASD）分类。与13种深度学习方法及最新方法相比，VarCoNet展示了其优越性、鲁棒性、可解释性和泛化能力。
### Conclusion
VarCoNet提供了一个灵活且鲁棒的功能连接组分析框架，适用于静息态功能磁共振成像数据。
## 789. `cs.LG` - Morphflux：转变环形网络以实现高效的多租户机器学习 [PDF](https://arxiv.org/pdf/2508.03674), [HTML](https://arxiv.org/abs/2508.03674)
### Authors
Abhishek Vijaya Kumar,Eric Ding,Arjun Devraj,Darius Bunandar,Rachee Singh
### Background
当前数据中心中的加速器连接大多使用基于环形的架构，尽管这些架构可以提供良好的通信性能，但面对多租户环境的需求和加速器计算的高数据需求时，其带宽和碎片化问题变得显著。
### Innovation
Morphflux是一种可编程的光子网络，能够大幅改进多租户环境下的加速器带宽分配，减少计算碎片，并最小化芯片故障的影响范围。通过在硬件原型上来实现，Morphflux展示了训练通过量提升至1.72倍的能力，并且能在硬件测试平台上迅速重新配置以替换故障芯片，整个过程仅需1.2秒。
### Conclusion
Morphflux提供了一种创新的解决方案，利用可编程光子网络有效解决多租户数据中心中加速器连接带宽和碎片化问题，同时增强了系统的容错能力，大幅提升了加速器在数据中心中的利用率和效率。
## 790. `cs.SE` - 从踪迹到行：针对开放源代码软件漏洞定位的人工智能代理 [PDF](https://arxiv.org/pdf/2510.02389), [HTML](https://arxiv.org/abs/2510.02389)
### Authors
Haoran Xi,Minghao Shao,Brendan Dolan-Gavitt,Muhammad Shafique,Ramesh Karri
### Background
现有的大型语言模型在漏洞发现方面显示出潜力，但目前的方法通常孤立地检查代码，难以处理长上下文，并且主要关注粗粒度的功能或文件级别检测，这给需要精确行级别定位和针对性修补的工程师提供有限的实际指导。现有的基准测试主要是粗粒度检测，无法支持精确行级别的漏洞定位，无法对致力于超越文件级预测的系统进行严格的评估。
### Innovation
本文提出了一个项目级别的、端到端的框架T2L-Agent（踪迹到行代理），该框架能够逐步将分析范围从模块细化到具体的漏洞行。T2L-Agent采用多轮反馈与行为踪迹分析器（ATA）结合的方法，将运行时证据（如崩溃点、堆栈跟踪和覆盖率差异）与基于AST的代码分块相结合，从而实现迭代完善，优于单次预测，并将症状转化为可操作的行级诊断。为此，作者构建了一个名为T2L-ARVO的基准测试，这个基准测试包括50个专家验证过的案例，覆盖五个崩溃家族和实际项目，支持粗粒度检测和细粒度定位，使评估系统的能力更接近实际应用。T2L-Agent在该基准测试上达到了漏洞检测率58.0%，行级别定位率54.8%，显著优于基线方法。
### Conclusion
T2L-Agent与T2L-ARVO基准测试一起，推动了基于LLM的漏洞检测从粗粒度识别转变为可部署、稳健、精确诊断，减少噪声并加快开源软件工作流中的修补速度。
## 791. `cs.SE` - AP2O：通过适应性渐进偏好优化逐类型纠正LLM生成的代码错误 [PDF](https://arxiv.org/pdf/2510.02393), [HTML](https://arxiv.org/abs/2510.02393)
### Authors
Jianqing Zhang,Wei Xia,Hande Dong,Qiang Lin,Jian Cao
### Background
LLMs在编程任务中的代码生成能力已经取得了显著的进步，但生成的代码仍然存在编译和运行时错误。现有的离线偏好优化方法主要集中在通过反馈信号（如通过/失败信号）来提升LLMs的编码能力，但忽视了失败代码中的深层错误类型。因此，需要新的方法来针对性地优化LLMs，减少代码错误数量和发展过程中的特定弱项。
### Innovation
本文提出了一种适应性渐进偏好优化方法（AP2O）应用于编程任务（即AP2O-Coder），该方法能够引导LLMs根据错误类型逐步优化，减少代码错误。具体而言，通过构造错误笔记本，并逐类型优化LLMs进行错误修正。此外，还通过动态回放错误类型来适应训练过程中LLMs的变化弱点。通过在不同参数规模的LLM（如Llama、Qwen和DeepSeek系列）上进行广泛实验，AP2O-Coder能够在保持相对较少偏好数据使用的情况下，提高代码生成准确率至多3%，达到了有别于现有方法的效果。
### Conclusion
通过AP2O-Coder，本文展示了适应性渐进偏好优化能够显著提升LLMs的代码生成能力并纠正特定类型的错误，具有广泛的适用性和高效性。
## 792. `cs.LG` - 具有模型反转攻击的辅助扩散任务导向语义通信 [PDF](https://arxiv.org/pdf/2506.19886), [HTML](https://arxiv.org/abs/2506.19886)
### Authors
Xuesong Wang,Mo Li,Xingyan Shi,Zhaoqian Liu,Shenghao Yang
### Background
语义通信通过传递语义信息而非原始输入符号序列来提升传输效率。任务导向的语义通信旨在保留特定任务信息，从而实现更大的带宽节省。然而，基于神经网络的通信系统容易受到模型反转攻击的影响，攻击者试图从窃听到的传输数据中推断敏感输入信息。因此，关键挑战在于在保证传输正确性和鲁棒性的同时保护隐私。早期研究通常假设攻击者试图在任务导向设置中完全重构原始输入，但在某些场景中，即使像素级别的指标如PSNR或SSIM较低，攻击者的输出仍然可以完成下游任务，这意味着敏感信息的泄漏。
### Innovation
该研究提出了DiffSem，一种辅助扩散的任务导向语义通信框架。该框架在发送端引入了一种自噪声机制，以适应调节语义内容并补偿信道噪声，在接收端则采用扩散U-Net提高任务性能，并可选择性地通过自我参考标签嵌入增强接收端的性能。实验结果表明，DiffSem能使合法接收者获得更高的准确性，从而验证了所提议框架的优越性能。
### Conclusion
通过引入适用于攻击效果评估的攻击者任务准确性指标，并通过自噪声机制和扩散U-Net等方法优化合法接收者和攻击者的性能差距，DiffSem框架在保持通信隐私性的同时确保了传输的正确性和鲁棒性。
## 793. `cs.SE` - ZeroFalse: 使用大型语言模型提高静态分析的精确性 [PDF](https://arxiv.org/pdf/2510.02534), [HTML](https://arxiv.org/abs/2510.02534)
### Authors
Mohsen Iranmanesh(Simon Fraser University),Sina Moradi Sabet(Amirkabir University of Technology),Sina Marefat(K. N. Toosi University of Technology),Ali Javidi Ghasr(Ferdowsi University of Mashhad),Allison Wilson(Cyber Risk Solutions),Iman Sharafaldin(Forward Security),Mohammad A. Tayebi(Simon Fraser University)
### Background
静态应用安全测试（SAST）工具对现代软件开发至关重要，但其采用却受到了过多误报的困扰，这削弱了开发者的信任度，并导致了成本高昂的手动审查需求。这些误报降低了SAST工具的有效性，因为它占据了开发者的时间而未能提供实质性的帮助。因此，需要一种方法来减少误报，同时保持覆盖率。
### Innovation
ZeroFalse提供了一种框架，将静态分析与大型语言模型（LLMs）结合，以减少误报同时保持覆盖率。ZeroFalse将静态分析器的输出视为结构化的合约，通过丰富细化的数据流敏感跟踪、上下文证据和CWE特定知识，然后由LLM进行筛选。这种设计保保持了静态分析的系统覆盖范围，同时利用了LLMs的推理能力。研究还评估了零误报模型在多个基准测试和实时项目上的性能，结果显示在OWASP Java基准测试上的F1分数为0.912，在OpenVuln数据集上的F1分数为0.955，并且准确率和召回率均保持在90%以上。结果显示专用的CWE提示比通用提示效果更好，且强调推理的LLMs能提供最可靠的精度和召回率平衡。
### Conclusion
这些发现使ZeroFalse成为提高SAST可靠性的一个实用和可扩展的方法，并支持其实现到实际的CI/CD管道。
## 794. `cs.LG` - Thinkquel：一种用于Text-to-dbt的合成数据和区间感知目标的专用模型 [PDF](https://arxiv.org/pdf/2510.00186), [HTML](https://arxiv.org/abs/2510.00186)
### Authors
Anni Li,Aria Attar,Paul Dong
### Background
将自然语言请求转化为可靠的、生产环境适用的数据转换仍然具有挑战性。正确性依赖于精准的模式链接和特定数据仓库的SQL语句变体，而可获得的最佳监督信号——执行成功和结果匹配——仅在序列层面提供。同时，构建大规模的执行验证语料库成本较高，且字符级目标与这些全局信号之间的不一致导致了不稳定优化和较低的可移植性。
### Innovation
引入了Thinkquel，一种针对生成稳健、可移植和执行验证的数据库查询的微调模型。Thinkquel整合了一种新颖的合成数据管道TS-SQL，它利用dbt作为可移植的中间表示，并采用区间感知的强化学习目标。同时，Token-Sequence GRPO (TS-GRPO)专门设计用于在微调大语言模型时填补字符级训练信号与序列级别执行奖励之间的差距。在500例样本TS-SQL测试集上，Thinkquel（32B）达到了93.2%的执行成功和61.8%的准确结果匹配率，优于基础模型67.2%（执行）和44.4%（匹配）。在Spider（14B）实验中，TS-GRPO提高了训练的稳定性并加速了执行匹配奖励的收敛速度，优于GRPO和GSPO.
### Conclusion
通过引入Thinkquel，该研究提高了生成可靠和可移植数据库查询的效率和效果，特别是在使用合成数据和区间感知目标方面表现出色。
## 795. `cs.SE` - 无服务器计算中动态函数配置及其管理：一个分类与未来方向 [PDF](https://arxiv.org/pdf/2510.02404), [HTML](https://arxiv.org/abs/2510.02404)
### Authors
Siddharth Agarwal,Maria A. Rodriguez,Rajkumar Buyya
### Background
无服务器云计算模型为服务商提供了一个框架，将底层基础设施管理抽象化给开发人员。在无服务器模型中，FaaS 提供了一种事件驱动、函数导向的计算服务，其定价按粒度计费并消除了闲置资源的费用。例如，AWS Lambda、Azure 函数和 Cloud Run 函数等平台要求开发人员为其函数配置最少的操作资源以确保其成功执行。这种资源分配既影响了操作费用也影响了函数的执行质量。然而，平台的不透明性迫使开发人员依赖专家知识或基于经验和猜测的决策来请求所需的函数资源。这使得在遵守性能约束的同时进行最优资源配置变得非平凡。同时，虽然商业平台常常按内存比例调整CPU和网络带宽资源，开源框架允许独立配置函数资源，这增加了开发人员优化其函数的复杂性。这些复杂性促使研究人员致力于解决开发人员面临的挑战并朝着更高效的无服务器执行模型迈进。研究者们识别并分类了函数即服务（FaaS）设置中资源配置的不同方面，并提出了一种影响函数设计、配置、运行时成本和性能保障的因素分类法。通过分析现有文献中的资源配置情况，研究并提出了一份关于函数配置的综合审查，指出现有研究的不足并提出了未来的研究方向以增强函数配置并提升无服务器计算环境的能力，促进其广泛采用。
### Innovation
该研究提出了一个关于无服务器计算环境中函数配置的分类法，并涵盖了影响函数设计、配置、运行时成本和性能保证的因素。研究还通过对现有文献的分析，提供了一份详尽的综述，指出现有研究的空白，并提出了未来的研究方向，旨在加强无服务器计算环境的能力，推动其更广泛的采用。
### Conclusion
该研究识别了无服务器计算中函数配置的各个方面，并提出了一个相关的分类框架。研究还总结了现有文献，并提出了一些建议来提高功能配置的有效性，增强无服务器计算环境，以推动更广泛的应用。
## 796. `cs.SE` - CWM：具有世界建模研究的开放权重LLM [PDF](https://arxiv.org/pdf/2510.02387), [HTML](https://arxiv.org/abs/2510.02387)
### Authors
FAIR CodeGen team. Jade Copet,Quentin Carbonneaux,Gal Cohen,Jonas Gehring,Jacob Kahn,Jannik Kossen,Felix Kreuk,Emily McMilin,Michel Meyer,Yuxiang Wei,David Zhang,Kunhao Zheng,Jordi Armengol-Estapé,Pedram Bashiri,Maximilian Beck,Pierre Chambon,Abhishek Charnalia,Chris Cummins,Juliette Decugis,Zacharias V. Fisches,François Fleuret,Fabian Gloeckle,Alex Gu,Michael Hassid,Daniel Haziza,Badr Youbi Idrissi,Christian Keller,Rahul Kindi,Hugh Leather,Gallil Maimon,Aram Markosyan,Francisco Massa,Pierre-Emmanuel Mazaré,Vegard Mella,Naila Murray,Keyur Muzumdar,Peter O'Hearn,Matteo Pagliardini,Dmitrii Pedchenko,Tal Remez,Volker Seeker,Marco Selvi,Oren Sultan,Sida Wang,Luca Wehrstedt,Ori Yoran,Lingming Zhang,Taco Cohen,Yossi Adi,Gabriel Synnaeve
### Background
为了提高代码生成能力，研究人员传统上依赖于静态代码训练，但这种方式限制了对代码深层次理解的能力。该论文提出了一种名为Code World Model (CWM)的32亿参数的开源权重大型语言模型（LLM），通过在Python解释器和自主Docker环境中大规模处理观察-行动轨迹，并进行多任务推理强化学习，增强了代码理解能力。
### Innovation
CWM采用了世界建模技术，在标准代码理解的基础上，增加了对动态执行和多任务推理的理解。它通过中等训练、强化学习和多任务推理，在具体的开发、数学和多轮软件工程环境中进行了验证。CWM还提供了密集的解码器只读LLM数据，训练时上下文大小可达131k个标记。在通用编程和数学任务上，CWM取得了优异成绩，如SWE-bench Verified的pass@1得分为65.8%，LiveCodeBench的得分为68.6%，Math-500的得分为96.6%，AIME 2024的得分为76.0%。
### Conclusion
CWM为研究人员提供了探索利用世界模型提高计算环境中的代码生成和推理规划能力的实验平台。在未来的研究中，CWM的相关检查点在中训练、微调和强化学习后被释放，以支持进一步的代码世界建模研究。
## 797. `cs.LG` - 在代码语言模型中分析潜在概念 [PDF](https://arxiv.org/pdf/2510.00476), [HTML](https://arxiv.org/abs/2510.00476)
### Authors
Arushi Sharma,Vedant Pungliya,Christopher J. Quinn,Ali Jannesari
### Background
在大型语言模型受到代码训练后，理解和解释它们的内部行为仍然是一个关键挑战，尤其是在需要信任、透明度和语义稳健性的情况下。具体来说，在代码上下文和应用中的理解和解释需求更为严格。
### Innovation
该研究提出了Code Concept Analysis (CoCoA)：一个全局的后验解释框架，通过将上下文化的标记嵌入聚类成人类可理解的概念组来揭示代码语言模型表示空间中的新兴词汇、语法和语义结构。研究结合了静态分析工具的语法对齐和提示工程的大型语言模型，实现跨抽象级别的潜在概念标签示范。通过分析概念在层间和跨三个微调任务中的分布，研究发现了方法族可以揭示意外的潜在交互并识别模型中学习表示的趋势和偏差。进一步地，将LCA与局部归因方法结合起来，以生成基于概念的解释，从而提高标记级别显著性的一致性和可解释性。
### Conclusion
对于多个模型和任务的实证评估表明，LCA发现的概念在语义保持扰动下保持稳定（平均聚类灵敏度指数，CSI = 0.288），并在微调过程中可预测地演变。在编程语言分类任务的用户研究中，添加概念的解释能够将标记级别角色的澄清提高37个百分点，相较于使用整体梯度的标记级别归因，提升了人类为中心的可解释性。
## 798. `cs.SE` - Product Manager Practices for Delegating Work to Generative AI: 'Accountability must not be delegated to non-human actors', [PDF](https://arxiv.org/pdf/2510.02504), [HTML](https://arxiv.org/abs/2510.02504)
### Authors
Mara Ulloa,Jenna L. Butler,Sankeerti Haniyur,Courtney Miller,Barrett Amos,Advait Sarkar,Margaret-Anne Storey
### Background
生成式AI（GenAI）正在改变知识工作的方式，特别是在软件开发团队中的产品经理（PMs）的工作性质。尽管有许多软件工程研究关注开发人员与GenAI的互动，但对于PMs的工作如何因GenAI而演变，人们了解较少。因此，本文作者通过在一家大型跨国软件公司微软进行了一项混合方法研究，以填补这一空白，包括对885名PMs的问卷调查、分析731名PMs的遥测数据以及采访了15名PMs。
### Innovation
作者贡献了PMs当前的GenAI采用率，使用场景，感知到的益处和障碍，构建了一个框架来捕捉PM们评估将哪些任务委托给GenAI的标准，还探讨了他们将GenAI整合到其角色中所采取的适应实践以及对他们角色如何演变的看法。这些发现为更广泛地将GenAI整合到工作流程中以及软件开发角色的演变提供了见解。
### Conclusion
研究结果表明，PMs正在适应与GenAI共事，但他们非常重视保持对其工作负有最终责任。这促使作者讨论了在更广泛的GenAI工作流程采用过程中应考虑的要点，以及软件开发角色的变化。
## 799. `cs.SE` - 使用傅里叶分析和突变聚类加速DNN突变测试 [PDF](https://arxiv.org/pdf/2510.02718), [HTML](https://arxiv.org/abs/2510.02718)
### Authors
Ali Ghanbari,Sasan Tavakkol
### Background
深度神经网络（DNN）突变分析是一种评估测试集充分性的有前途的方法。然而，生成大量突变体并在大数据集上进行测试的成本很高。本文研究了如何通过傅里叶分析加速DNN突变测试。
### Innovation
提出了一种名为DM#的新技术，通过傅里叶分析加速DNN突变测试，利用少量数据点量化突变体行为并对其进行聚类，然后选择一个代表在测试中使用，从而节省测试成本，提高效率。
### Conclusion
DM#在14个不同大小和数据集的DNN模型上进行了评估，并与多种基线技术进行了比较，结果表明，相比于随机突变体选择、边界样本选择和随机样本选择技术，DM#通常提供相当的速度提升，同时将突变评分误差分别降低了28.38%、11.78%、15.16%和114.36%。
## 800. `cs.SE` - OpenID连接程序的自动修复（扩展版本） [PDF](https://arxiv.org/pdf/2510.02773), [HTML](https://arxiv.org/abs/2510.02773)
### Authors
Tamjid Al Rahat,Yanju Chen,Yu Feng,Yuan Tian
### Background
OpenID Connect通过提供基于单点登录（SSO）的安全且方便的方法，简化了在线认证过程。尽管其广泛应用，但OpenID Connect中关键的安全漏洞仍导致了重大经济损失和安全漏洞，强调了需要强大的缓解策略。自动程序修复是一个有前景的解决方案，用于为OpenID实现生成候选补丁。然而，如领域特定复杂性及精确故障定位和补丁验证的需求等挑战必须被解决。
### Innovation
作者提出了AuthFix，一种利用大型语言模型（LLMs）进行自动化OpenID漏洞修复的反例引导修复引擎。AuthFix整合了三个关键组件：故障定位、补丁合成和补丁验证。通过使用新颖的基于Petri网的模型检查器，AuthFix确保了补丁的正确性，通过有效地建模交互过程。
### Conclusion
在OpenID漏洞数据集上的评估表明，AuthFix成功生成了正确的补丁，修复了23个漏洞中的17个（74%），并且大部分补丁在语义上与开发人员编写的修复补丁相似。
## 801. `cs.SE` - RedCodeAgent: 自动红队代理程序对抗多种代码代理程序 [PDF](https://arxiv.org/pdf/2510.02609), [HTML](https://arxiv.org/abs/2510.02609)
### Authors
Chengquan Guo,Chulin Xie,Yu Yang,Zhaorun Chen,Zinan Lin,Xander Davies,Yarin Gal,Dawn Song,Bo Li
### Background
由于其强大的代码生成能力和与代码解释器的整合，代码代理程序已经得到了广泛的应用，支持动态执行、调试和交互式编程功能。尽管这些进步简化了复杂的流程，但也引入了关键的安全和安全风险。当前的静态安全基准测试和红队工具不足以识别新兴的实际风险场景，因为它们未能涵盖某些边界条件，如不同旁路工具的综合影响。因此，需要一个系统的方法来发现这些代码代理程序中的漏洞。现有的红队方法存在局限性，主要依赖于静态代码的评估，可能会引入偏差，影响评估结果的准确性。因此，针对这些问题，本文提出了RedCodeAgent，一种自动化的红队代理程序，旨在系统地发现各种代码代理程序中的漏洞。
### Innovation
RedCodeAgent是一种新的自动化红队代理程序，能够自适应地利用现有的旁路知识，并根据输入查询选择最有效的红队工具及其组合。通过开发模拟沙盒环境来进一步评估代码代理程序的执行结果，以减轻依赖仅静态代码的LLM评估者潜在的偏差。实验结果显示，RedCodeAgent在效率和攻击成功率方面显著优于现有的红队方法，且能够更加稳健地评估代码代理程序，可以有效地识别未被现有方法发现的安全风险。此外，RedCodeAgent已经应用于实际的代码助手，如Cursor和Codeium，发现了新的安全风险。通过自动化和优化红队流程，使得红队评估更加高效、适应性强并且具有广泛的应用度。
### Conclusion
RedCodeAgent通过自动化的红队评估方法，集成了动态执行库和适应性存储模块，有效发现了多种先进代码代理的漏洞，同时通过沙盒模拟进一步提高评估的可靠性。该工具在各种先进代码代理和编程语言下的广谱评估中表现出色，并在真实的代码助手应用中发现了新的安全漏洞。RedCodeAgent展示了在自动化红队领域的创新和有效应用。
## 802. `cs.SE` - 研究LLM生成代码中的代码异味 [PDF](https://arxiv.org/pdf/2510.03029), [HTML](https://arxiv.org/abs/2510.03029)
### Authors
Debalina Ghosh Paul,Hong Zhu,Ian Bayley
### Background
大型语言模型（LLMs）越来越多地被用于生成程序代码。已有大量研究关注生成代码的功能正确性，但关于代码质量的研究相对较少。
### Innovation
本文提出了一种基于场景的方法来评估LLM生成代码的质量，通过测量代码异味并将其与专业编写代码的参考解决方案进行比较，以识别生成代码质量最差的场景。
### Conclusion
关于代码异味，LLM在不同编程任务复杂性和主题上的表现与人类编写代码的质量高度相关。然而，LLM生成的代码质量明显低于人类编写的代码。
## 803. `cs.SE` - GramTrans：代码生成中更好的代码表示方法 [PDF](https://arxiv.org/pdf/2510.02887), [HTML](https://arxiv.org/abs/2510.02887)
### Authors
Zhao Zhang,Qingyuan Liang,Zeyu Sun,Yizhou Chen,Guoqing Wang,Yican Sun,Lu Zhang,Ge Li,Yingfei Xiong
### Background
代码生成在软件开发中显示出巨大的潜力。然而，一个尚未充分探索的基本问题是，代码表示的选择如何影响模型性能。现有的研究采用了不同的表示方法，如将代码作为纯文本、文法规则序列或语法树序列，但缺乏对解析难度与模型效果之间关系的系统理解。先前的工作缺乏对这个问题的深刻见解，而本论文提出了一个假设：解析难度越小，模型的性能越好，并通过正式实验验证了这一假设。该研究选择了基于Python的DSL进行了控制实验，发现解析难度与模型性能之间存在强烈的相关性。
### Innovation
本研究提出了GramTrans，一种通用方法，自动将上下文无关语言转换为LL(1)类的表示。GramTrans引入了一种新颖的分层冲突消除算法，实现了语义简洁性和标记效率之间的灵活权衡。通过在Python和Java上使用三个代码生成模型进行了评估，GramTrans持续提供了相对于基线表示的显著改进。此外，本研究还通过分析现有表示方法，验证了解析难度与模型性能之间存在强烈一致性的假设，进一步支持了该论文的假设。
### Conclusion
本文通过GramTrans算法改进了代码生成中的代码表示方法，实验结果表明，通过降低解析难度，可以显著提升模型的性能。研究证实了解析难度与模型性能之间存在强烈的相关性，这为代码表示的设计提供了新的视角。
## 804. `cs.SE` - 教学中的敏捷方法模式-团队和项目启程 [PDF](https://arxiv.org/pdf/2510.03005), [HTML](https://arxiv.org/abs/2510.03005)
### Authors
Daniel Pinho,Petr Pícha,Filipe Correia,Přemek Brada
### Background
随着敏捷软件开发（ASD）的理念在工业界普及，教育领域针对ASD的教学课程变得越来越普遍。然而，现有的关于ASD在课堂上的应用研究多停留在框架层面或超越了软件开发领域，缺乏具体的教学建议。基于教育者的实践经验，本文展示了一种聚焦于大学学生敏捷实践教学的模式语言的初步工作，特别关注团队和项目设置阶段的五个模式：控制团队规模、设定更小的项目范围、选择非关键业务项目、自组织团队和团队自主选择主题，为构建整体模式语言提供基础.
### Innovation
本文提出了针对大学学生敏捷实践教学的模式语言，专注于团队和项目设置阶段，填补了现有研究在实际教学建议方面的空白，为教育者提供了实践指导.
### Conclusion
通过展示五种具体模式，本文为构建全面的敏捷教学模式语言奠定了基础，这有助于教育者更有效地教授学生敏捷软件开发实践.
## 805. `cs.SE` - 自动扩展的关键考虑：基于基准微服务的教训 [PDF](https://arxiv.org/pdf/2510.02585), [HTML](https://arxiv.org/abs/2510.02585)
### Authors
Majid Dashtbani,Ladan Tahvildari
### Background
微服务已成为构建可扩展和模块化云原生系统的主导架构范式。然而，实现有效的自动扩展仍然是一项艰巨的挑战，因为它不仅依赖于高级扩展技术，还依赖于良好的设计、实现和部署实践。现有的基准测试往往忽略了这些基础方面，使得很难在现实条件下评估自动扩展方法的效果。
### Innovation
本文通过将多种先进的自动扩展方法应用于广泛使用的微服务基准测试，识别出一套实用的自动扩展考虑因素。这些考虑因素根据软件生命周期的不同阶段进行了分类：架构、实现和部署。作者验证了这些考虑因素，并评估了多种自动扩展策略，包括阈值基于的、控制理论的、基于学习的、黑盒优化的和依赖性感知的方法。研究结果表明，忽视生命周期的关键问题会降低自动扩展器的性能，而解决这些问题则能实现更稳定和高效的扩展。
### Conclusion
本文的研究结果突显了生命周期感知工程对于充分利用微服务系统中自动扩展的全潜力的重要性。通过解决生命周期中的关键问题，我们可以提高自动扩展的性能和稳定性。
## 806. `cs.SE` - 用于监控云原生应用的追踪和指标设计模式 [PDF](https://arxiv.org/pdf/2510.02991), [HTML](https://arxiv.org/abs/2510.02991)
### Authors
Carlos Albuquerque,Filipe F. Correia
### Background
随着软件架构变得越来越分布式且易变，诊断系统问题变得更加困难，尤其是在面对碎片化的可观测性及更复杂的根本原因分析时。可观测性有助于保证云原生应用的可靠性和可维护性，但在日益复杂的环境中，确保有效的监控变得愈发挑战性。
### Innovation
本文基于先前研究，提出了三个针对云原生应用监控的关键挑战的设计模式：分布式追踪（Distributed Tracing）通过提高服务间请求流程的可见性，帮助进行延迟分析及根本原因检测；应用指标（Application Metrics）提供了一种结构化的度量方法，使软件能够以有意义的性能指标进行度量，支持实时监控及异常检测；基础设施指标（Infrastructure Metrics）则专注于监控系统的运行环境，帮助团队评估资源使用情况、可扩展性和运营健康状况。这些模式源于行业实践和可观测性框架，旨在为软件实践者提供指引。
### Conclusion
综上所述，本文通过揭示并提出解决云原生应用监控挑战的设计模式，为软件开发者提供了具体的、实际的解决方案，以实现更有效的监控，确保应用的可靠性与可维护性。
## 807. `cs.SE` - 向微服务重构：为服务提取打下基础 [PDF](https://arxiv.org/pdf/2510.03050), [HTML](https://arxiv.org/abs/2510.03050)
### Authors
Rita Peixoto,Filipe F. Correia,Thatiane Rosa,Eduardo Guerra,Alfredo Goldman
### Background
随着组织越来越多地从单一系统转向微服务，他们旨在实现更高的可用性、自动扩展、简化基础设施管理、增强协作以及简化部署。然而，这一迁移过程仍主要依赖手工操作且劳动密集型。尽管现有文献提供了各种分解单一系统的策略，但这些方法主要集中在架构层面的指导，往往忽略了开发人员在迁移过程中必须应对的代码级别挑战和依赖关系。
### Innovation
本文提出了一个包含七种重构的目录，专门设计以支持向微服务架构的过渡，并重点关注处理依赖关系。该目录为开发人员提供了一套系统性的指导，重新整理了文献中识别的重构方法，并解决了系统化处理代码级别的关键缺口。通过提供一个结构化、分步骤的方法，这项工作简化了迁移过程，为未来的自动化奠定了基础，使开发人员能够高效、有效地实施这些变更。
### Conclusion
通过提供一种结构化的，分步骤的方法，这项工作简化了资源重组并为潜在的自动化奠定了基础，使开发人员能够有效地实施这些变更。
## 808. `cs.SE` - 状态字段覆盖：评估或acles质量的度量标准 [PDF](https://arxiv.org/pdf/2510.03071), [HTML](https://arxiv.org/abs/2510.03071)
### Authors
Facundo Molina,Nazareno Aguirre,Alessandra Gorla
### Background
软件缺陷测试的效果不仅取决于测试输入的特性和它们对软件的充分性，还取决于用于确定软件行为是否符合预期的或acles的质量。已有评估或acles质量的度量标准存在不足，要么缺乏全面性，要么只能针对特定类型或acles，限制了其普适性。因此，需要一种新的评估或acles质量的方法，以提高测试的整体效果和效率。
### Innovation
本文提出了一种新的度量标准——状态字段覆盖（state field coverage），用以评估或acles质量。该度量标准衡量了或acles在测试执行过程中可能访问的对象静态定义的状态字段的比例。通过静态计算状态字段覆盖，该方法高效且直接为改善测试或acles提供了指导，识别出未被检查的状态字段。通过实验，该度量标准被证明能很好地评估或acles的质量，因为它与或acles的故障检测能力存在强烈的相关性，以突变分数衡量.
### Conclusion
本文提出的状态字段覆盖度量标准能够有效地评估或acles质量，并且可以直接指导改进测试或acles。实验结果表明状态字段覆盖与或acles的故障检测能力有强烈的相关性。
## 809. `cs.SE` - C2|Q>: 一个连接经典与量子软件开发的稳健框架 [PDF](https://arxiv.org/pdf/2510.02854), [HTML](https://arxiv.org/abs/2510.02854)
### Authors
Boshuai Ye,Arif Ali Khan,Teemu Pihkakoski,Peng Liang,Muhammad Azeem Akbar,Matti Silveri,Lauri Malmi
### Background
随着量子软件工程（QSE）作为使量子计算更广泛易用的关键学科的发展，大多数量子开发环境仍然要求开发者处理软件堆栈中的低级细节，包括问题编码、量子电路构建、算法配置、硬件选择以及结果解释，这使得经典软件工程师难以使用。为缓解这个问题，本文介绍了一种名为C2|Q>:的硬件无关的量子软件开发框架，该框架能够将经典规范（代码）转化为可执行的量子程序，同时保持方法论的严谨性。C2|Q>框架通过划分工作流程为三个核心模块来应用模块化软件工程原理：编码模块将问题分类并构建量子兼容格式（QCF）和量子电路；部署模块根据保真度、运行时间和成本生成电路并推荐硬件；解码模块将量子输出解释为经典解决方案。
### Innovation
C2|Q>:框架通过将工作流程划分为编码、部署和解码三个模块，实现了模块化软件工程的原则，并且能够将经典代码转化为可执行的量子程序。此框架还根据保真度、运行时间和成本来推荐适当的硬件，并成功处理了大量 classical 规范文件，同时显著减少了手工实现的工作量。尤其是对于利用已有 NISQ 硬件的问题，C2|Q>: 的实现工作量与手动实现相比降低了约 40 倍，证明了其对促进经典与量子软件开发之间的桥梁具有实用性。该框架还充斥在当前 NISQ 技术的实际应用程度中，在小到中型实例上得到了实际验证。
### Conclusion
C2|Q>:框架成功解决了经典软件工程师在量子计算开发中面临的问题，并显著提高了量子软件开发的效率。通过模块化的开发方法和硬件无关的特性，该框架为量子软件的普及和易用性带来了一步新的进展。该开源实现已经在公开网址提供，可供进一步研究和使用。
## 810. `cs.SE` - 地理位置机器学习库 [PDF](https://arxiv.org/pdf/2510.02572), [HTML](https://arxiv.org/abs/2510.02572)
### Authors
Adam J. Stewart,Caleb Robinson,Arindam Banerjee
### Background
近年来，机器学习的进展得益于领域特定软件库的出现，这使得工作流程更加流畅，并提高了可重复性。对于地理位置机器学习（GeoML），可用的地球观测数据的增长速度超过了能够处理其独特挑战（如不同的空间分辨率、光谱特性、时间频率、数据覆盖范围、坐标系统和文件格式）的领域库的发展。
### Innovation
本文综述了地理位置机器学习库的发展，分析了它们的演变、核心功能和当前生态系统。介绍了流行的地理位置机器学习库（如TorchGeo、eo-learn和Raster Vision），详细说明了它们的架构、支持的数据类型以及与机器学习框架的集成。还讨论了数据预处理、时空连接、基准测试和预训练模型的应用。通过作物类型制图的案例研究展示了这些工具的实际应用。强调了软件设计、许可证和测试的最佳实践，以及开源地理空间软件中出现的开放挑战和未来方向，特别是基础模型的兴起和治理的需求。
### Conclusion
本文旨在指导从业人员、开发者和研究者导航并贡献于快速发展的地理位置机器学习领域。
## 811. `cs.SE` - 使用机器学习进行插件类型推理 [PDF](https://arxiv.org/pdf/2406.15676), [HTML](https://arxiv.org/abs/2406.15676)
### Authors
Kazi Amanul Islam Siddiqui,Martin Kellogg
### Background
可插拔类型系统允许程序员扩展编程语言的类型系统，以实现程序员定义的语义属性。然而，插件类型系统很难在遗留代码库中部署，因为它们需要程序员手动编写类型注解。
### Innovation
该论文提出了一种新颖的表示方法，名为NaP-AST，用于编码有效的类型限定符自动推理所需的数据流提示。研究了几种模型架构，包括图变换神经网络（Graph Transformer Network）、图卷积网络（Graph Convolutional Network）和大型语言模型，用于推断类型限定符。这些模型在12个开源程序上进行了验证，结果表明GTN模型表现最佳，召回率为0.89，精确率为0.6。此外，研究还估计了受训练模型性能良好的所需Java类数量，在16k类附近性能提高，在22k类附近由于过拟合性能恶化。
### Conclusion
研究发现，GTN模型在推断类型限定符方面表现出色，并且还估计了所需Java类数量以实现良好性能。
## 812. `cs.SE` - 通过稀疏自编码器理解大语言模型的代码正确性机理 [PDF](https://arxiv.org/pdf/2510.02917), [HTML](https://arxiv.org/abs/2510.02917)
### Authors
Kriz Tahimic,Charibeth Cheng
### Background
随着大型语言模型（LLM）在软件开发中发挥关键作用，大量由人工智能建议的代码进入生产环境，因此理解其内部的正确性机制变得至关重要，以确保安全部署。
### Innovation
研究团队应用稀疏自编码器解构LLM的表示，通过t统计量选择预测方向，通过基模型表示的分离评分引导方向，并通过定向、注意力分析和权重正交化分析其机理特性。研究发现代码正确性方向可靠地预测错误代码，修正能力虽然具有统计显著性，但存在保留正确代码与修正错误之间的权衡。机理上，成功的代码生成依赖于关注测试案例而非问题描述。此外，在指令微调后，基模型中识别的方向仍保持有效，表明在预训练期间学习的代码正确性机制可能在微调期间进行了重用。
### Conclusion
机理上的洞见提出了三项实际应用：策略提示应优先选择测试示例而非复杂的问答描述，预测方向可以作为开发者的错误警报，这些相同的方向也可以引导有选择的引导，仅在预计会出现错误时进行干预以防止代码的持续引导导致的损坏。
## 813. `cs.SE` - Unmasking the Genuine Type Inference Capabilities of LLMs for Java Code Snippets [PDF](https://arxiv.org/pdf/2503.04076), [HTML](https://arxiv.org/abs/2503.04076)
### Authors
Yiwen Dong,Zhenyang Xu,Yongqiang Tian,Chengnian Sun
### Background
类型推断对于重用在线代码片段至关重要。虽然像StackOverflow这样的平台上广泛分享了代码片段，但这些片段往往缺乏诸如完全限定名（FQNs）等关键类型信息。最近的研究利用大型语言模型（LLMs）对这些代码片段进行类型推断，并取得了令人鼓舞的结果。然而，这些结果可能受到数据泄露的影响，因为用于评估的基准StatType-SO早在2017年就已公开发布在GitHub上。因此，目前无法确定LLMs的强劲表现是否源于它们真正理解了代码的语义，还是因为训练数据中包含了正确答案。
### Innovation
1. 创建了一个名为ThaliaType的新基准套件，专门用于类型推断评估，这是首次发布的内容；2. 发现了StarCoder2在开源训练数据中从StatType-SO泄露数据的现象，并观察到其他最先进的LLMs在ThaliaType上的表现也下降，精度下降高达59%，召回率下降高达72%；3. 设计了语义保持的代码转换来测试LLMs理解代码执行语义的能力，结果显示LLMs在StatType-SO上的表现对这些转换的鲁棒性远低于在ThaliaType上的表现。
### Conclusion
这些发现强调了在类型推断任务中仔细设计无泄露的基准的重要性。我们建议未来的研究采用ThaliaType进行严格的、可靠的对LLMs真正类型推断能力的评估。
## 814. `cs.SE` - 当名称消失时：揭示大语言模型实际上对代码的理解 [PDF](https://arxiv.org/pdf/2510.03178), [HTML](https://arxiv.org/abs/2510.03178)
### Authors
Cuong Chi Le,Minh V.T. Pham,Cuong Duc Van,Hoang N. Phan,Huy N. Phan,Tien N. Nguyen
### Background
大语言模型在编程任务上表现出色，但它们是如何理解程序意义的仍不清楚。代码通过结构语义进行通信，结构语义定义正式行为，而命名则直观地传达意图。去除命名渠道会严重影响涉及意图的任务，如总结，模型会退化为逐行描述。令人惊讶的是，即使在仅依赖结构的执行任务中也观察到一致的性能下降，表明当前基准测试更多是为了记忆命名模式而不是真正的语义推理。
### Innovation
提出了一组语义保留的混淆手段，以区分命名和结构语义的影响。通过这些方法揭示了标识符泄漏，并开发了ClassEval-Obf基准测试，系统地抑制了命名线索，同时保留行为。这些发现有助于改进大语言模型对于代码的理解和泛化能力的评估基准。
### Conclusion
ClassEval-Obf减少了夸大性能差距，削弱了记忆捷径，为评估大语言模型的代码理解能力和泛化提供了更可靠的基础。
## 815. `cs.SE` - 透视变换器：实现绿色AI的CLEAR视角 [PDF](https://arxiv.org/pdf/2510.02810), [HTML](https://arxiv.org/abs/2510.02810)
### Authors
Hemang Jain,Shailender Goyal,Divyansh Pandey,Karthik Vaidhyanathan
### Background
随着大型语言模型（LLMs）的迅速普及，环境问题引起了广泛关注。训练LLMs的成本是一次性的，而推断则在全球范围内持续进行，并且现在已成为AI能耗的主要部分。然而，大多数可持续性研究仅报告粗略的模型级指标，因为缺乏细粒度的测量方法，能源效率往往被视为次要目标，而不是主要目标。
### Innovation
本文首次提出了细粒度的变压器架构组件级能耗分析方法——Component-Level Energy Assessment via Repeated sampling (CLEAR)，以解决微秒级组件执行与毫秒级能耗传感器监控之间的时间不匹配问题。通过CLEAR方法，评估了15种模型，涵盖了四种不同的架构类型，确保了组件间能耗变异率低于9.5%，并捕获了模型总能耗的90%以上。分析发现注意力块的能耗明显高于浮点操作（FLOP）计数，表明单纯依靠FLOPs无法准确反映组件级的能源消耗成本。这些发现为建立以组件级优化为基础的能效变压器模型提供了详细的能耗基线，并提供了初步见解。
### Conclusion
本文的实证分析揭示了细粒度的组件能耗基线，显示FLOPs不足以准确捕获组件级别的能源成本，并为通过组件级优化构建能效变压器模型提供了初步步骤。
## 816. `cs.SE` - 从事实到反事实：为智能环境设计和评估反事实解释 [PDF](https://arxiv.org/pdf/2510.03078), [HTML](https://arxiv.org/abs/2510.03078)
### Authors
Anna Trapp,Mersedeh Sadeghi,Andreas Vogelsang
### Background
解释性越来越被认为是规则驱动型智能环境中的重要特性。反事实解释，即描述为了达到期望结果可以如何不同的描述，是可解释人工智能(XAI)的强大工具。然而，在这些规则驱动型领域中，并没有现成的方法来生成这些反事实解释。
### Innovation
本文提出了第一个为规则驱动型智能环境定制的反事实解释的正式化和实现。该方法作为一个插件，扩展了现有的智能环境解释引擎。并进行了一项用户研究，评估了生成的反事实解释与传统因果解释的效果。
### Conclusion
用户偏好高度取决于上下文：在时间紧迫的情况下，用户更偏好因果解释因其语言简洁；而在需要实际行动解决问题的情况下，用户则更偏好反事实解释。本文为智能环境提供了一种实用的解释框架，并提供了基于效果指导每种解释类型选择的实证证据。
## 817. `cs.SE` - Abstain and Validate：减少自动化程序修复噪声的双重LLM策略 [PDF](https://arxiv.org/pdf/2510.03217), [HTML](https://arxiv.org/abs/2510.03217)
### Authors
José Cambronero,Michele Tufano,Sherry Shi,Renyao Wei,Grant Uy,Runxiang Cheng,Chin-Jung Liu,Shiying Pan,Satish Chandra,Pat Rondon
### Background
当前，代理自动化程序修复（APR）系统正在解决工业中的复杂仓库级错误，但是生成的补丁仍然需要人类审核以确保修复了错误。然而，展示不太可能的补丁给开发人员会增加大量噪音，浪费了宝贵的时间，并可能降低对自动代码更改的信任。
### Innovation
本文引入了两种互补的基于LLM的策略来减少这种噪音：错误排除策略和补丁验证策略。错误排除策略会排除代理 APR 系统不太可能修复的错误。补丁验证策略会拒绝对给定错误不太可能是一个良好修复的补丁。在 Google 代码库的三组错误及代理 APR 系统生成的候选补丁上进行了评估。
### Conclusion
两种策略结合使用可以在成功率方面提高至多 39 个百分点，并且单独使用补丁验证还可以提高 Null Pointer 异常和检测器报告错误的平均单样本成功率。这种双重策略为代理 APR 系统的可靠、大规模工业部署提供了一条实用的道路。
## 818. `cs.SE` - 使用预训练编程语言模型的智能合约意图检测 [PDF](https://arxiv.org/pdf/2508.20086), [HTML](https://arxiv.org/abs/2508.20086)
### Authors
Youwei Huang,Jianwen Li,Sen Fang,Yao Li,Peng Yang,Bin Hu
### Background
智能合约中的恶意开发人员意图构成了去中心化应用程序的重要安全威胁，导致了严重的经济损失。
### Innovation
介绍了SmartIntentNN2（智能合约意图神经网络V2），这是在原始模型SmartIntentNN的基础上进行了增强。主要创新点在于，引入了一个基于BERT的预训练编程语言模型，并使用16,000个真实智能合约数据集进行领域适应性预训练，以此提高了模型对智能合约意图的检测能力。
### Conclusion
SmartIntentNN2在相同的10,000份智能合约评估集上，实现了更高的准确率0.9789、精确率0.9090、召回率0.9476和F1得分0.9279，大幅优于先前模型和基线模型，并且在F1得分上比GPT-4.1高出65.5%。这些结果证明SmartIntentNN2是智能合约意图检测的新一代最佳模型。
## 819. `cs.SE` - Programming with Pixels: Can Computer-Use Agents do Software Engineering？ [PDF](https://arxiv.org/pdf/2502.18525), [HTML](https://arxiv.org/abs/2502.18525)
### Authors
Pranjal Aggarwal,Sean Welleck
### Background
当前计算机使用代理（CUAs）能够执行广泛的任务，但大部分评估集中在简单的场景上。因此不清楚这类通用代理能否自动化复杂且专业的工作，如软件工程（SWE）。本文介绍了一个全新的环境$texttt{Programming with Pixels}$（PwP），首个专为软件工程设计的视觉控制环境，其中代理通过控制集成开发环境（IDE）来执行多样的软件工程任务。此外，作者还引入了$texttt{PwP-Bench}$基准测试，包含15个现有的和新的软件工程任务，涵盖多种模态、编程语言和技能集。通过全面评估先进的CUAs模型发现，在纯粹视觉互动下，它们的表现远逊于专业的编程代理。但在直接访问文件编辑API和bash操作后，它们的表现大幅提升，并且当访问更多的IDE工具时，进一步提升。现有CUAs的主要限制是视觉定位能力有限，以及无法充分利用丰富的环境。这表明软件工程是一个适合评估通用计算机使用代理是否能达到专业水平的自然领域。代码和数据在此提供：this https URL
### Innovation
1. 引入$texttt{Programming with Pixels}$（PwP），首次提供了一个专注于软件工程的视觉控制环境。2. 开发$texttt{PwP-Bench}$基准测试，用于评估软件工程任务。3. 通过对先进的CUAs模型进行广泛的评估，揭示了视觉定位能力和环境利用之间的关系，指出未来改进的方向。4. 暴露了当前CUAs的局限性，指明未来研究的方向，尤其是在视觉理解和环境利用能力方面。
### Conclusion
当前CUAs在视觉交互方面表现不佳，但在直接访问特定APIs后，其表现提升显著。进一步接入IDE工具，所有模型均显示出进一步的改进。这表明CUAs未来在这一领域的改进大有可为，并将软件工程确立为评估通用计算机使用代理能否在复杂任务上达到专业水平的理想场景。因此，提供了清晰的研究方向，包括改进视觉能力与环境利用能力。
## 820. `cs.SE` - 自动建筑规范审查：一个案例研究 [PDF](https://arxiv.org/pdf/2510.02634), [HTML](https://arxiv.org/abs/2510.02634)
### Authors
Hanlong Wan,Weili Xu,Michael Rosenberg,Jian Zhang,Aysha Siddika
### Background
资源约束或农村地区的建筑管理员在项目规模和复杂性增加时，需要进行劳动力密集、容易出错且昂贵的手工检查建筑设计文件。随着建筑信息建模（BIM）和大规模语言模型（LLMs）的广泛应用，自动代码审查（ACR）解决方案变得日益重要。
### Innovation
该研究引入了一个基于代理的新型框架，该框架结合了基于BIM的数据提取与使用检索增强生成（RAG）和Model Context Protocol（MCP）代理管道的自动化验证。框架使用LLM启用代理从不同文件类型中提取几何、计划和系统属性，然后通过两种互补机制进行建筑规范检查：直接调用美国能源部COMcheck引擎的API提供确定性和审计输出，以及基于RAG的推理以灵活地处理不完全或模棱两可的规范内容。研究表明，MCP代理管道在严格性和可靠性方面优于RAG推理管道。
### Conclusion
该研究通过展示一种扩展性强、可互操作且生产准备的框架，弥合了BIM与权威的规范审查工具之间的差距，从而推进了ACR研究。
## 821. `cs.SE` - 逐层知识注入以提高基于LLM的程序修复效果 [PDF](https://arxiv.org/pdf/2506.24015), [HTML](https://arxiv.org/abs/2506.24015)
### Authors
Ramtin Ehsani,Esteban Parra,Sonia Haiduc,Preetha Chatterjee
### Background
现有研究表明，通过提供与错误相关的上下文（例如错误信息和堆栈跟踪）能够提升自动化程序修复的效果，但仍有大量bug无法解决。在实际项目开发中，开发者常常依赖更为广泛的仓库和项目级别的上下文来解决bug。因此，本文探讨了如何自动提取和提供此类知识以提高基于LLM的程序修复效果。
### Innovation
本文提出了一种逐层知识注入框架，逐步增强LLM的结构化上下文信息。该框架从错误知识层开始（包括错误函数和失败测试），逐步扩展到仓库知识层（编译依赖关系、相关文件和提交历史），再注入项目知识层（包含相关文档和已修复bug的细节）。该框架在使用Llama 3.3和GPT-4o-mini两种LLM对314个来自BugsInPy数据集的bug进行实验时，使用逐层注入知识的方法，实现了79%（250/314）的修复率，相比之前的工作提升了23%。这表明不同类型的bug需要不同程度的上下文信息才能有效修复。作者还探讨了那些未解决问题的bug，并发现结构复杂且孤立的bug（如程序异常和GUI bug）即使注入所有可用信息后仍然难以解决。研究结果表明了逐层注入上下文的效果，并暗示了需要开发交互性和适应性的程序修复系统的需求。
### Conclusion
逐层知识注入方法可以显著提高基于LLM的程序修复效果。然而，不同类型的bug需要不同程度的上下文信息，尤其是对于复杂且孤立的bug而言，现有方法仍然面临挑战。未来工作需要进一步研究如何更有效地利用项目级别的上下文来解决这些类型的bug。
## 822. `cs.SE` - cAST: 基于抽象语法树的结构化分块增强代码检索增强生成 [PDF](https://arxiv.org/pdf/2506.15655), [HTML](https://arxiv.org/abs/2506.15655)
### Authors
Yilin Zhang,Xinran Zhao,Zora Zhiruo Wang,Chenyang Yang,Jiayi Wei,Tongshuang Wu
### Background
近期，检索增强生成（RAG）已被用于大规模的代码生成任务中，通过将预测基于外部代码库来提高生成的真实性。然而，当前在RAG管道中的一个关键但未充分研究的部分是分块 - 将文档分割成可检索的单元。现有的基于行的分块启发式常常破坏了语义结构，会分拆函数或混杂不相关代码，从而降低生成质量。现有的分块方法通常不考虑语义结构，导致生成质量下降。因此，需要一种能够尊重编程语言结构的分块方法来提高代码生成任务的表现。
### Innovation
该研究提出了基于抽象语法树（AST）的结构意识分块方法（cAST），该方法递归地将大AST节点拆分成更小的块，并合并兄弟节点，同时遵守大小限制。这种方法生成了跨编程语言和任务的自包含且语义连贯的代码单元，提高了多种代码生成任务的性能，比如在RepoEval检索任务的精度@5提升了4.3个点，在SWE-bench生成任务的精度@1提升了2.67个点。这项工作突出了结构意识分块在增强检索增强代码智能中的重要性。
### Conclusion
cAST方法通过保留编程语言结构来提高RAG管道中的分块质量，显著提升了代码检索和生成任务的表现，强调了结构意识分块在扩展检索增强代码智能方面的必要性。
## 823. `cs.SE` - LLAMAFUZZ：大型语言模型增强的灰盒模糊测试 [PDF](https://arxiv.org/pdf/2406.07714), [HTML](https://arxiv.org/abs/2406.07714)
### Authors
Hongxiang Zhang,Yuyang Rong,Yifeng He,Hao Chen
### Background
灰盒模糊测试已在揭示程序中的错误和漏洞方面取得了成功。然而，随机化的突变策略限制了其在结构化数据上的性能。专门针对复杂结构化数据的模糊测试器虽然能够处理这些数据，但需要额外的努力来定义语法，并且带宽较低。
### Innovation
探索利用大型语言模型来增强灰盒模糊测试对于结构化数据的潜力。利用预训练语言模型的知识生成新的有效输入。进一步通过突变种子进行微调，学习结构化格式和突变策略。开发了基于语言模型的模糊测试器LLAMAFUZZ，结合了语言模型的能力来理解和突变结构化数据进行模糊测试。实验表明，LLAMAFUZZ在标准的基于漏洞的基准Magma和多种实际程序上表现出色，性能优于顶级竞品。
### Conclusion
LLAMAFUZZ在实际程序集上分支数比AFL++平均多出27.19%。此外，LLAMAFUZZ在所有试验中发现了47个唯一的新漏洞。LLAMAFUZZ在漏洞触发和漏洞发现上表现出稳定性能。
## 824. `cs.SE` - 安全高效的大规模区块链投票：对比框架及大型语言模型的作用 [PDF](https://arxiv.org/pdf/2508.05865), [HTML](https://arxiv.org/abs/2508.05865)
### Authors
Kiana Kiashemshaki,Elvis Nnaemeka Chukwuani,Mohammad Jalili Torkamani,Negin Mahmoudi
### Background
区块链技术为现代化的电子投票系统提供了增强透明度、分散化和安全性的可能性。然而，由于可扩展性限制、高计算需求和复杂隐私要求等因素的影响，实际应用受到限制。
### Innovation
1. 提出了一种对比框架，分析区块链基电子投票架构、共识机制、加密协议。2. 考察了现有的工作证明、权益证明和委托权益证明模型的局限性，并提出了混合共识、轻量级密码学和去中心化身份管理的优化策略。3. 探索大型语言模型在智能合约生成、异常检测和用户交互中的新型作用。
### Conclusion
研究为设计安全、可扩展和智能的区块链基电子投票系统提供了基础，这些系统适用于国家规模部署。这项工作为构建由大型语言模型指导的智能合约生成和验证增强的端到端区块链电子投票原型奠定了基础，支持系统分析和仿真分析框架。
## 825. `cs.SE` - 通过动态内部表示选择进行模型无关的LLM生成代码正确性评估 [PDF](https://arxiv.org/pdf/2510.02934), [HTML](https://arxiv.org/abs/2510.02934)
### Authors
Thanh Trong Vu,Tuan-Dung Bui,Thu-Trang Nguyen,Son Nguyen,Hieu Dinh Vo
### Background
大型语言模型（LLMs）展示了在代码生成方面的强大能力，并逐渐被集成到软件开发过程中。然而，确保LLMs生成代码的正确性仍然是一个关键问题。先前的研究表明，LLMs的内部表示包含了评估代码正确性的有意义的信号。但是，现有的方法依赖于预选的固定层和标记位置的表示，这可能会限制其在不同模型架构和任务上的普适性。
### Innovation
本文提出了一种新的模型无关方法AUTOPROBE，该方法能够动态选择对代码正确性评估最具有信息性的内部表示。AUTOPROBE采用注意力机制学习隐藏状态的重要性评分，使其能够专注于最相关的特征。权重表示随后被聚合并传递给探针分类器，以从多个维度预测代码正确性，包括编译能力和功能性和安全性。
### Conclusion
实验结果表明，AUTOPROBE在多种基准和代码LLMs中比基线方法表现更优。在安全性评估方面，AUTOPROBE比最先进的白盒方法高出18%。在编译能力和功能性评估方面，与其它方法相比，AUTOPROBE在复杂代码上的性能分别高出19%和111%。这些发现表明，动态选择重要的内部信号使得AUTOPROBE能够作为各种LLMs生成代码正确性评估的稳健和普适性解决方案。
## 826. `cs.SE` - 基于元提示调优LLM代码优化：工业视角 [PDF](https://arxiv.org/pdf/2508.01443), [HTML](https://arxiv.org/abs/2508.01443)
### Authors
Jingzhi Gong,Rafail Giavrimis,Paul Brookes,Vardan Voskanyan,Fan Wu,Mari Ashiga,Matthew Truscott,Mike Basios,Leslie Kanthan,Jie Xu,Zheng Wang
### Background
近年来，利用多个大型语言模型（LLMs）进行代码自动化优化引起了广泛关注。然而，部署多个LLMs的工业平台面临一个关键挑战：优化一个LLMs的提示可能在其他LLMs上无效，这需要昂贵的模型特定提示工程。跨模型的提示工程瓶颈严重限制了多LLMs系统的实际部署。
### Innovation
本文引入了Meta-Prompted Code Optimization (MPCO)框架，这是一种自动生成针对不同LLM的高质量、任务特定提示的方法，同时满足工业效率的要求。MPCO利用元提示动态合成上下文感知优化提示，集成了项目元数据、任务要求和LLM特定的上下文。全面评估显示，MPCO在5个真实代码库的366小时瓶颈测试中实现的整体性能提升最高达19.06%，并且在所有方法中获得最佳统计排名。分析表明，表现最佳的优化中有96%来源于有意义的编辑。系统化的消融研究和元提示器灵敏度分析表明，全面的上下文集成对有效的元提示至关重要，主要LLMs可以有效作为元提示器。
### Conclusion
MPCO在代码优化平台中是自动验证和扩展的重要组成部分，其效果优于基线方法。该研究提供了工业实践者关于元提示有效的见解。
## 827. `cs.SE` - S-Graphs 2.0 -- 用于SLAM的分层语义优化和环路闭合 [PDF](https://arxiv.org/pdf/2502.18044), [HTML](https://arxiv.org/abs/2502.18044)
### Authors
Hriday Bavle,Jose Luis Sanchez-Lopez,Muhammad Shaheer,Javier Civera,Holger Voos
### Background
3D场景图的分层结构对于表示目的至关重要，因为它与人造环境中的常见模式相契合。此外，分层表示中的语义和几何信息可以用来加速地图元素和机器人姿态的优化和管理。现有的方法侧重于利用分层结构进行有效的数据管理和优化，但如何有效利用这种结构以提高SLAM（即时定位与地图构建）的性能尚未完全解决。因此，提出了S-Graphs 2.0，这是一种利用室内场景分层结构进行高效数据管理和优化的算法。
### Innovation
S-Graphs 2.0的主要创新在于：1) 前端引入了一种楼层检测模块，能够识别楼梯并为底层层次提供语义关系；2) 通过利用分层表示，在优化过程中实现了局部优化（窗口最近关键帧及其在四层表示中的连接组件）和地板级别的全局优化（重点在当前楼层的关键帧及其连接）；3) 在房间级别实现局部优化，通过消除冗余关键帧减少计算量。这些创新有效提升了SLAM算法的精度和速度，特别是在大型多层环境中，性能提升达到10倍以上。
### Conclusion
实验结果表明，S-Graphs 2.0在不同多层现实环境中具有较高的验证度，能够在大型多层环境中以更高的精度和更快的速度重建分层表示。这种新的算法为SLAM领域的研究和发展提供了新的思路和技术支持。
## 828. `cs.SE` - Scam2Prompt: 一种针对生产中大规模语言模型中恶意欺诈端点的可扩展审计框架 [PDF](https://arxiv.org/pdf/2509.02372), [HTML](https://arxiv.org/abs/2509.02372)
### Authors
Zhiyang Chen,Tara Saba,Xun Deng,Xujie Si,Fan Long
### Background
大型语言模型（LLMs）在现代软件开发中至关重要，但它们依赖于未经筛选的网络规模数据集进行训练，这引入了显著的网络安全风险：恶意内容的吸收和再现。为了系统地评估这一风险，研究人员引入了Scam2Prompt，这是一个可扩展的自动化审计框架，能够识别欺诈网站的根本意图，并合成模仿这一意图的无害开发人员风格的提示，从而测试LLM在收到这些无害提示时是否会生成恶意代码。
### Innovation
Scam2Prompt提供了一种新的方法来系统地评估大型语言模型中恶意内容的安全风险。通过识别欺诈网站的意图并生成模仿这些意图的提示，Scam2Prompt能够有效地测试LLM是否会在收到看似无害的提示时生成恶意代码。此外，研究人员还创建了Innoc2Scam-bench基准测试集，用于测试LLM中这一安全风险的持久性，并发现现有安全措施如先进的护栏措施在防止这种行为方面并不足以发挥作用。研究还发现，不同版本的LLM在生成恶意代码方面存在显著差异，这揭示了当前安全措施在应对这一问题上的局限性。
### Conclusion
研究发现，Scam2Prompt能够有效触发大量生产中LLM生成恶意代码，表现出高风险，而现有的安全措施根本不足以防止这种行为。不同版本的LLM在生成恶意代码方面存在显著差异，这表明需要进一步研究和改进来应对这一安全挑战。未来的研究应关注如何提高大型语言模型的安全性，并开发更有效的监控和防护机制。
## 829. `cs.SE` - 通过仓库感知知识图谱提高仓库级软件修复 [PDF](https://arxiv.org/pdf/2503.21710), [HTML](https://arxiv.org/abs/2503.21710)
### Authors
Boyang Yang,Jiadong Ren,Shunfu Jin,Yang Liu,Feng Liu,Bach Le,Haoye Tian
### Background
仓库级别的软件修复面临挑战，尤其是在语义鸿沟之间，即问题描述和代码修复之间的联系。现有方法主要依赖大语言模型（LLMs），但由于语义模糊性、对结构上下文理解有限以及推理能力不足，这些方法受到了限制。
### Innovation
1. 提出了一种新的仓库感知知识图（KG），准确地将仓库文件（问题和拉取请求）和代码库实体（文件、类和函数）链接起来，有效缩小了搜索空间，并准确缩小到20个最相关的函数以及错误位置的准确候选和上下文信息。2. 知识路径引导修复机制，利用从知识图中挖掘的实体路径进行跟踪，增强LLM的上下文信息，生成精确的代码修复及其解释。
### Conclusion
实验结果表明，KGCompass在SWE-bench Lite的单大语言模型修复性能和函数层次错误定位精度方面表现出最佳性能，达58.3%和56.0%，且使用单个修复模型成本仅为0.2美元每次修复。KGCompass在修复率上比纯大语言模型基线提高了50.8%到156.4%，展示了通过图引导修复框架提供了模型无关联、成本高效的修复，并为仓库级别的修复设定了新的基准。
## 830. `cs.SE` - 分析代码语言模型中的隐含概念 [PDF](https://arxiv.org/pdf/2510.00476), [HTML](https://arxiv.org/abs/2510.00476)
### Authors
Arushi Sharma,Vedant Pungliya,Christopher J. Quinn,Ali Jannesari
### Background
在代码训练的大语言模型中解析内部行为仍然是一个重要的挑战，特别是在需要信任、透明度和语义稳健性的情况下。
### Innovation
提出了Code Concept Analysis (CoCoA)：一个全局后验可解释性框架，通过将上下文化标记嵌入聚类到人类可解释的概念组中，揭示代码语言模型表示空间中的新兴词汇、语法和语义结构。结合基于静态分析工具的语法规则对齐与提示工程的大语言模型，提出了一种混合标注流水线，以实现跨抽象层次的潜在概念的可扩展标注。分析概念在层间和三个微调任务中的分布，以帮助识别意外的潜在交互并用于识别模型学习表示中的趋势和偏见。进一步将概念分析与局部归因方法结合，产生概念导向的解释，提高了标记级别显著性的一致性和可解释性。通过对多个模型和任务的实证评估显示，概念分析发现的概念在语义保持的扰动下保持稳定（平均聚类敏感性索引，CSI = 0.288），并且在微调中可预测地发展。在编程语言分类任务的用户研究中，概念增强的解释通过Integrated Gradients方法标记级别归因的解释性提高了37个百分点。
### Conclusion
概念分析在多种模型和任务中展示了其稳定性和可预测性，并且概念增强的解释比传统标记级别归因方法更有利于人类中心的解释性。
