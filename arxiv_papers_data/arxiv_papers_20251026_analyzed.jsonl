{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20075", "html_url": "https://arxiv.org/abs/2510.20075", "title": "LLMs可以在相同长度的文本中隐藏文本.ipynb", "title_en": "LLMs can hide text in other text of the same length.ipynb", "authors": "Antonio Norelli,Michael Bronstein", "background": "在语言模型技术的发展下，可以将有意义的文本隐藏在看似完全不同但依然连贯合理的文本中。这种现象得益于大型语言模型（LLMs）的能力，使得这样的技术成为了可能。", "innovation": "该论文提出了一种简单且有效的方法，即使用小型的开源LLM（80亿参数量）就能实现高质量的隐写术效果。不仅能够在相同长度的文本中隐藏和解码较长的信息，而且可以在个人电脑上快速完成这些操作。", "conclusion": "这项技术表明，文本内容与作者意图之间存在极大的脱节，进一步削弱了人们对书面交流的信任。这引起了一系列AI安全方面的问题，并让人质疑L大型语言模型真正理解的内容。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19957", "html_url": "https://arxiv.org/abs/2510.19957", "title": "由生成性AI驱动的车辆保险欺诈新趋势", "title_en": "A new wave of vehicle insurance fraud fueled by generative AI", "authors": "Amir Hever,Itai Orr", "background": "保险欺诈是一个普遍且代价高昂的问题，每年导致数十亿美元的损失。在车辆保险领域，欺诈手法包括人为制造事故、夸大损失或伪造文件等。随着生成性AI，特别是深度伪造图像和视频生成技术的发展，欺诈者现在可以更容易地大规模和快速地伪造事故证据，如制造逼真的车祸照片和伪造身份或文件，这些行为对保险公司构成了巨大威胁。", "innovation": "本文档介绍了UVeye的多层解决方案，旨在检测、缓解和遏制由生成性AI驱动的新一波欺诈行为，代表了在检测、缓解和遏制此类欺诈方面的一大进步。", "conclusion": "生成性AI与检测技术之间的不断升级的博弈，以及保险公司面临的资源和成本障碍，使得对抗生成性AI驱动的保险欺诈仍然是一项持久的挑战。UVeye的解决方案在对抗这种新型欺诈方面迈出了重要一步。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19949", "html_url": "https://arxiv.org/abs/2510.19949", "title": "Surfer 2：新一代跨平台计算机使用代理", "title_en": "Surfer 2: The Next Generation of Cross-Platform Computer Use Agents", "authors": "Mathieu Andreux,Märt Bakler,Yanael Barbier,Hamza Ben Chekroun,Emilien Biré,Antoine Bonnet,Riaz Bordie,Nathan Bout,Matthias Brunel,Aleix Cambray,Pierre-Louis Cedoz,Antoine Chassang,Gautier Cloix,Ethan Connelly,Alexandra Constantinou,Ramzi De Coster,Hubert de la Jonquiere,Aurélien Delfosse,Maxime Delpit,Alexis Deprez,Augustin Derupti,Mathieu Diaz,Shannon D'Souza,Julie Dujardin,Abai Edmund,Michael Eickenberg,Armand Fatalot,Wissem Felissi,Isaac Herring,Xavier Koegler,Erwan Le Jumeau de Kergaradec,Aurélien Lac,Maxime Langevin,Corentin Lauverjat,Antonio Loison,Avshalom Manevich,Axel Moyal,Axel Nguyen Kerbel,Marinela Parovic,Julien Revelle,Guillaume Richard,Mats Richter,Ronan Riochet,María Santos,Romain Savidan,Laurent Sifre,Maxime Theillard,Marc Thibault,Ivan Valentini,Tony Wu,Laura Yie,Kai Yuan,Jevgenij Zubovskij", "background": "跨设备（如网络、桌面和移动设备）构建能够通用操作的智能代理仍然是一个开放性的挑战。以前的系统通常依赖于特定环境的用户界面，这限制了它们在不同平台上的应用部署。", "innovation": "作者提出了Surfer 2，这是一个统一的架构，它仅通过视觉观察运行，并在所有三种环境中的性能都达到了最先进的水平。Surfer 2集成了分层上下文管理、解耦计划和执行、自我验证以及自适应恢复，使系统能够在长期任务执行中更可靠地运行。在WebVoyager上的准确率为97.1%，WebArena为69.6%，OSWorld为60.1%，AndroidWorld为87.1%，并且超出所有先前系统的性能，无需针对具体任务进行微调。在多次尝试中，Surfer 2甚至超过了所有基准测试中的人类性能。", "conclusion": "这些结果表明，系统化的协调调度能够提高基础模型的能力，并且能够通过视觉交互实现通用化的计算机控制。同时，这也指出了下一代视觉语言模型可能需要实现帕累托最优的成本效率。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19836", "html_url": "https://arxiv.org/abs/2510.19836", "title": "能源系统分析中人工智模型推理可靠性的基准测试", "title_en": "Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis", "authors": "Eliseo Curcio", "background": "在能源领域，人工智能和机器学习技术正在被用于预测、优化和政策设计，但目前缺乏标准化框架来评估这些系统是否合理推理。当前的验证方法主要关注预测准确性和计算效率，而没有测试分析结论的逻辑完整性。本文介绍了Analytical Reliability Benchmark (ARB)，这是一个可复制的框架，用于量化应用于能源系统分析的大语言模型的推理可靠性。", "innovation": "本文提出的ARB框架具有五个子指标：准确度、推理可靠性、不确定性纪律、政策一致性与透明度。它在确定性、概率性和知识论场景下，使用开放的能源技术经济数据集进行评估，能够客观地测量不同模型的推理可靠性，并验证这些差异具有显著性和可重复性。这是能源文献中首次提出的一种定量方法，用于验证人工智能系统中的因果推理、概率推理和政策驱动推理。", "conclusion": "ARB为全球能源转型中的可信和透明分析应用提供了一个参考框架，奠定了在能源领域中验证人工智系统因果、概率和政策驱动推理的第一个定量方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19838", "html_url": "https://arxiv.org/abs/2510.19838", "title": "Branch-and-Browse: 效率高且可控的基于树状推理和行动记忆的网络探索", "title_en": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory", "authors": "Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury", "background": "自主的网络代理由大型语言模型（LLMs）驱动，展现出了在信息检索、报告生成和在线交易等目标导向任务中的强大潜力。这些代理标志着在开放网络环境中实现实践中的实体化推理的关键步骤。然而，现有的方法在推理的深度和效率上仍然有限：传统的线性方法无法处理多步推理，且缺乏有效的回溯方法，而其他搜索策略则较为粗放，且计算成本高。", "innovation": "文章提出了Branch-and-Browse，它是一种基于树状推理和行动记忆的具体化网络代理框架，能够统一结构化推理-执行、上下文记忆和高效执行。其特点包括：(i) 使用树结构探索来实现可控制的多分支推理；(ii) 通过有效的Web状态回放与背景推理来启动探索；(iii) 利用页面行动记忆来在会话内外共享已探索的动作。在WebArena基准测试中，Branch-and-Browse成功率为35.8%，相对最先进的方法执行时间减少了最多40.4%。", "conclusion": "这些结果表明，Branch-and-Browse是一个可靠的且高效的LLM驱动网络代理框架。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20099", "html_url": "https://arxiv.org/abs/2510.20099", "title": "AI PB：为个性化投资见解生成的接地生成代理", "title_en": "AI PB: A Grounded Generative Agent for Personalized Investment Insights", "authors": "Daewoo Park,Suho Park,Inseok Hong,Hanwool Lee,Junkyu Park,Sangjun Lee,Jeongman An,Hyunbin Loh", "background": "在零售金融领域，AI PB是一个面向操作的生成式代理，不同于被动回答问题的反应式聊天机器人，它能够主动生成、符合规定的、个性化的投资见解。系统基于数据敏感性在内部和外部大型语言模型（LLM）之间确定性地路由，结合了开放搜索和金融领域嵌入式模型的混合检索管道，以及多层次的推荐机制，跨24台NVIDIA H100 GPU，完全在韩国金融监管的内部环境中运行。", "innovation": "系统特色包括一个模块化的编排层，能够根据数据敏感性决定性地在内部和外部大型语言模型之间路由；混合检索管道，结合了开放搜索与金融领域特定的嵌入模型；多阶段推荐机制，结合了基于规则的启发式方法、顺序行为建模和上下文臂算法。这些特征共同实现了符合规定的、个性化的投资见解的生成，同时也在严格的韩国金融监管环境中验证了结果的可信度和安全性。", "conclusion": "通过人工质量控制和系统度量数据，我们证明了显式路由和多层安全机制能够在高风险的金融环境中提供值得信赖的人工智能见解，展示了AI PB在零售金融领域的生产应用案例。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19954", "html_url": "https://arxiv.org/abs/2510.19954", "title": "RELATE: 无模式感知的多模态关系图感知器编码器", "title_en": "RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs", "authors": "Joseph Meyer,Divyansha Lachi,Reza Mohammadi,Roshan Reddy Upendra,Eva L. Dyer,Mark Li,Tom Palczewski", "background": "在电子商务、医疗保健和科学研究等领域中，关系多表数据非常普遍，可以自然地表示为具有多模态节点属性的异构时间图。现有的图神经网络（GNNs）依赖于模式特定的特征编码器，需要为每种节点类型和特征列单独创建模块，这不利于扩展性和参数共享。", "innovation": "我们提出了无模式感知的RELATE（关系编码器，用于类型的实体潜在聚合），这是一种模式无关的插件编码器，可以与任何通用GNN一起使用。RELATE使用共享的模态特定编码器来处理分类、数值、文本和时间属性，之后是类似于Perceiver的交叉注意模块，将特征聚合为固定大小、置换不变的节点表示。", "conclusion": "我们在RelBench基准测试中的ReLGNN和HGT中评估了RELATE，结果显示其性能在3%以内，同时将参数数量减少了多达5倍。这种设计支持各种模式，并可为通用图神经网络进行跨数据集预训练，朝着关系图数据的基础模型奠定了基础。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19842", "html_url": "https://arxiv.org/abs/2510.19842", "title": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs", "title_en": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs", "authors": "Yuanhe Zhang,Ilja Kuzborskij,Jason D. Lee,Chenlei Leng,Fanghui Liu", "background": "大型语言模型（LLMs）在被提示进行思维链（CoT）推理时表现出色，但尚未明确这种成功是源于搜索、记忆性程序还是规则一致性推理。本研究旨在通过将CoT建模为有向无环图（DAG）上的确定性规则基础随机过程，来探讨这一问题。", "innovation": "提出了一种将思维链推理模型化为DAG上的确定性规则基础随机过程的方法，并引入了逻辑接近度这一新的评价指标来衡量模型的思维链轨迹与DAG结构的一致性。此外，还提出了DAG-MATH CoT格式作为基准，引导LLMs生成符合该格式的思维链轨迹，从而评估其在框架下的推理能力。", "conclusion": "研究结果揭示了代表性LLM家族在标准数学推理数据集上的推理准确性具有统计显著差异，即使PASS@k指标相似。研究框架提供了一个平衡自由形式CoT和形式证明系统的方法，为LLM推理评估提供了可行的诊断工具。研究基准和代码可以在给定的链接处获取。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19964", "html_url": "https://arxiv.org/abs/2510.19964", "title": "AI驱动的个性化学习：通过领导力人格特质预测学术表现", "title_en": "AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits", "authors": "Nitsa J Herzog,Rejwan Bin Sulaiman,David J Herzog,Rose Fong", "background": "研究探讨了人工智能技术在个性化学习中的潜力，通过领导力人格特质和机器学习建模预测学术成功。实验数据来自环境工程学院的129名硕士生，他们进行了五项领导力人格测试，涵盖了23种特质，并使用自我评估工具（包括个性洞察、工作场所文化、工作动力、管理技能和情绪控制测试）。研究采用了探索性数据分析和相关性分析，通过皮尔逊相关系数挑选特征。将平均成绩分为三类：不及格、及格和优秀。使用支持向量机（SVM）、逻辑回归（LR）、K最近邻（KNN）、决策树（DT）、梯度提升（GB）、随机森林（RF）、XGBoost和LightGBM等七种机器学习算法进行建模。随机森林分类器表现最佳，对于包含17个人格特质特征和领导力标记特征的模型，准确率为87.50%，对于不包含该特征的模型，准确率为85.71%。", "innovation": "研究创新在于通过领导力人格特质应用机器学习模型来预测学术表现，以及采用不包含领导力标记特征的机器学习建模方法，分别取得了不同的预测性能。研究表明，通过这种方式，可以在教育早期阶段识别学生的强项和弱点，并选择最适合的个性化学习策略。", "conclusion": "研究结果表明，使用随机森林分类器结合多项人格特质特征，对于预测学生学术表现具有较高的准确率。这种AI驱动的方法为早期识别学生的学习需求并实现个性化学习提供了新的途径。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19835", "html_url": "https://arxiv.org/abs/2510.19835", "title": "一种解决数独谜题和最大割问题的启发式量子算法", "title_en": "A Quantum-Inspired Algorithm for Solving Sudoku Puzzles and the MaxCut Problem", "authors": "Max B. Zhao,Fei Li", "background": "本文提出并评估了一种量子启发式算法，用于解决数学上等价于寻找伊辛自旋玻璃哈密顿量基态的二次无约束二值优化（QUBO）问题。该算法利用矩阵乘积态（MPS）紧凑表示大量自旋配置的叠加，并利用离散驱动策略引导MPS朝向基态。算法中使用包含横向磁场的驱动哈密顿量与问题哈密顿量组合，促进自旋翻转和量子隧穿。MPS利用标准的密度矩阵重归一化分组（DMRG）方法更新，通过多次重复遍历自旋链来最小化系统的能量。尽管该算法具有启发式性质，但其能可靠地在各种QUBO实例中识别全局最小值，而不是仅仅找到近似最优解。本文首先使用公共来源的中级数独谜题进行验证，涉及超过200个伊辛自旋且具有长程耦合，随后将算法应用于Biq Mac库中的最大割问题实例，成功解决了多达251个节点和3265条边的实例。文章还讨论了该量子启发式方法的优势，包括可扩展性、普适性和适合于大规模工业QUBO应用的特点。", "innovation": "本文提出的算法结合了矩阵乘积态（MPS）和密度矩阵重归一化分组（DMRG）方法，以量子启发式的方式解决QUBO问题。该算法通过使用含有横向磁场的驱动哈密顿量与问题哈密顿量的组合来实现自旋翻转和量子隧穿，这有助于克服传统优化算法中的局部极小值问题。与现有的QUBO解决方法相比，该算法在处理具有复杂耦合的问题时更高效稳定。此外，由于算法能够识别全局最小值，因此在处理大规模、复杂问题时能展现出明显的优势。文章还讨论了这一量子启发式方法在数独谜题和最大割问题上的实际应用表现。", "conclusion": "本文提出了一种量子启发式算法，通过矩阵乘积态和密度矩阵重归一化分组的方法有效解决了QUBO问题。该算法不仅在结构化问题如数独谜题上表现出色，还成功应用于解决最大割问题实例，经验证充分验证了其有效性和效率。文章特别强调了量子启发式方法在解决大规模QUBO问题中的优势，为该领域提供了新的解决方案和技术途径。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20109", "html_url": "https://arxiv.org/abs/2510.20109", "title": "验证价值悖论：关于法律实践中生成型AI的规范性批判", "title_en": "The Verification-Value Paradox: A Normative Critique of Gen AI in Legal Practice", "authors": "Joshua Yuvaraj", "background": "人们普遍认为基于机器学习的生成型AI产品将大幅简化法律实践并降低成本，前提是律师能够有效管理AI的风险。然而，澳大利亚及其他地区的一些案例表明，当律师提交不准确的AI生成内容到法院时会受到谴责，这表明这种乐观态度可能需要重新评估。论文在此背景下提出，鉴于AI与现实的脱节和不透明性，以及律师首要职责的诚信、正直、不误导法庭等方面，有必要重新审视AI在法律实践中的使用评估方法。", "innovation": "论文提出了验证-价值悖论的新模型替代现有的评估方法，表明AI在法律实践中的使用效率提高将伴随着更大的手动验证输出的要求，从而使AI使用的净价值对律师来说往往可以忽略不计。该悖论还对法律实践和法律教育提出了新的影响和建议，强调忠实于真相和公民责任的价值观应该成为法律实践的核心。", "conclusion": "该论文提出了一个关于AI使用的新框架，认为AI在法律实践中的效率提升将通过增加手动验证的需要而被抵消，因而AI的总体价值可能是有限的，并且强调了法律实践和教育中应重视忠实于真相和公民责任的价值观。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20102", "html_url": "https://arxiv.org/abs/2510.20102", "title": "以人为中心的LLM代理系统以检测异常数字资产交易", "title_en": "Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions", "authors": "Gyuyeon Na,Minjung Park,Hyeonjeong Cha,Sangmi Chai", "background": "该研究介绍了HCLA，一种用于数字资产交易异常检测的人类中心多智能体系统。HCLA使得非专家用户能够以自然语言提问，并通过结构化的数据分析和上下文感知的解释来获得见解。该系统在开源Web界面中实现，并将用户的意图转化为经典检测器（在原型中使用XGBoost）的架构，并返回基于底层特征的叙述性解释。研究通过在标注的比特币混币数据集（Wasabi Wallet，2020-2024）上测试，验证了基线检测器的效果，并展示了HCLA增加了可解释性和交互式改进。", "innovation": "HCLA将解析、检测和解释三个角色整合成一个对话式工作流，这种方式允许非专家用户通过自然语言提问、查看结构化的分析结果并获得上下文感知的理由。该系统使用开源Web界面实现，并通过将用户的意图转化为经典检测器（如XGBoost）的架构，提供基于底层特征的叙述性解释。HCLA不仅仅是提高了检测的准确率，还增加了系统的可解释性和交互性。", "conclusion": "通过描述系统的架构、交互循环、数据集、评估协议和限制点，研究讨论了如何将人在环设计提高金融取证的透明度和信任度。HCLA通过整合解析、检测和解释角色，增强了用户对复杂数字资产交易的理解和信任，为金融和法律领域提供了重要的技术支持。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20252", "html_url": "https://arxiv.org/abs/2510.20252", "title": "大型语言模型中的个体化认知模拟：评估不同的认知表示方法", "title_en": "Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods", "authors": "Tianyi Zhang,Xiaolin Zhou,Yunzhe Wang,Erik Cambria,David Traum,Rui Mao", "background": "尽管大型语言模型（LLMs）能够模仿表面级的人类行为，比如角色扮演，但它们在模拟更深层次的个体认知过程方面的表现仍有待探讨。该研究旨在填补这一空白，并通过构建基于近期出版的小说的数据集，提出一个包含11个条件的认知评估框架，以测试七种现成的LLMs在作者风格模仿中的表现。", "innovation": "引入了一种新的任务来评估不同的认知表示方法在个体化认知模拟（ICS）中的效果；提出了一个11条件的认知评估框架来基准测试七种现成的LLMs在作者风格模仿中的表现，并测试了不同的认知表示，例如语言特征、概念映射和基于个人资料的信息。", "conclusion": "结合概念和语言特征在ICS中特别有效，本研究的结果表明，LLMs在模仿语言风格方面比模仿叙述结构更为有效，这凸显了它们深层认知模拟的局限性。这些发现为开发能够适应个体思维和表达方式的AI系统奠定了基础，促进了更加个性化和人性化导向的创意技术的发展。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20190", "html_url": "https://arxiv.org/abs/2510.20190", "title": "锁入阶段假说：身份巩固作为AGI的前奏", "title_en": "The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI", "authors": "Marcelo Maciel Amaral,Raymond Aschheim", "background": "大语言模型（LLMs）保持开放性并高度可控：它们大规模模仿、接受任意系统提示，并容易采纳多种人物形象。类比人类发展，作者假设通往人工通用智能（AGI）的过程中存在一个锁定阶段：从开放模仿过渡到身份巩固，在此期间目标结构、拒绝、偏好和内部表示变得更加稳定，并且对外部控制具有抵抗力。作者采用形式化方法，将此阶段与已知的学习动态现象联系起来，并建议开发检测该阶段开始的运营指标。", "innovation": "作者提出了一个假说，即将AGI的发展分为开放模仿阶段和身份巩固阶段。在这个阶段，作者提出了可操作的指标来检测其开始，并展示了虽然行为巩固是快速而非线性的，但其对一般能力的影响并非一致。作者还揭示了从小模型到大模型的不同结果，并认为身份巩固是AGI级别的可靠性的先决条件，对于安全性也至关重要：身份可以刻意设计，也可能在扩展过程中自发产生，从而可能硬化未预测的目标和行为。", "conclusion": "身份巩固是一个重要阶段，它既是AGI级别的可靠性的先决条件，也是确保安全的关键控制点。这种身份的巩固可以被有意图地构建，但也可能在扩展过程中自发形成，从而可能会固化不可预测的目标和行为。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20258", "html_url": "https://arxiv.org/abs/2510.20258", "title": "使用大型语言模型进行规划领域抽象 - 延长版本", "title_en": "Using Large Language Models for Abstraction of Planning Domains - Extended Version", "authors": "Bita Banihashemi,Megh Patel,Yves Lespérance", "background": "生成与给定目的相匹配的动态领域抽象仍然是一个重要的挑战，因为这种抽象的选择会影响代理进行规划、推理和提供解释的能力。本文通过将代理的具体行为模型化在PDDL中，研究了使用大型语言模型（LLMs）进行上下文学习从而生成抽象PDDL领域和问题实例的可能性。而用于基准测试的例子都是新的且不属于任何已训练LLMs的数据集。", "innovation": "本文创新性地利用大型语言模型（LLMs）进行上下文学习，针对给定自然语言中的抽象目标生成PDDL领域的抽象和问题实例。考虑了三种类型的抽象：具体动作的选择抽象、具体动作序列的抽象、具体动作/谓词参数的抽象及它们的组合。此外，生成的抽象PDDL领域和问题实例还经过了符号验证工具和专家的人工检查。实验结果表明，GPT-4o在简单场景中通常可以综合生成有用的规划领域抽象，尤其擅长于动作的抽象。", "conclusion": "研究表明，大型语言模型可以生成有用的规划领域抽象，特别是在简单场景中，且在动作抽象方面表现出色。然而，该方法在处理复杂场景或抽象关联谓词方面仍具有局限性，未来还需要进一步的研究来优化该模型在更复杂情况下的表现。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20205", "html_url": "https://arxiv.org/abs/2510.20205", "title": "Merge and Conquer: 通过进化优化2048中的人工智能", "title_en": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "authors": "Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum", "background": "在机器学习研究中，将人工智能优化应用于动态环境仍然是一个基本挑战。本文研究了进化训练方法在优化人工智能解2048游戏（一个二维滑动拼图游戏）方面的应用。2048结合了战略性游戏玩法和随机性元素，适合作为研究决策制定、长期规划和动态适应的理想平台。", "innovation": "本文提出了两种不同的系统：一个两剂元提示系统，其中“思考者”大型语言模型（LLM）代理优化“执行者”LLM代理的策略；一个基于修正的价值函数的单剂系统，使用有限的蒙特卡罗树搜索（Monte Carlo Tree Search, MCTS）。另外，还实验了回滚功能以避免性能下降。这些方法展示了在非确定性环境中使用进化优化技术提高人工智能性能的潜力。", "conclusion": "单剂系统实现了显著改进，平均每轮次提高了473.2分，并且随训练轮次呈现清晰的上升趋势（相关系数 ρ=0.607）。与此形成对比的是，两剂系统未取得显著进步，突显了元提示方法固有的局限性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20188", "html_url": "https://arxiv.org/abs/2510.20188", "title": "TRUST：一种用于审计大型语言模型推理的去中心化框架", "title_en": "TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning", "authors": "Morris Yu-Chao Huang,Zhen Tan,Mohan Zhang,Pingzhi Li,Zhuo Zhang,Tianlong Chen", "background": "大型语言模型（LLM）生成复杂的推理链，揭示了其决策过程，但验证这些中间步骤的忠实性和无辜性仍然是一个未解决的关键问题。现有的审计方法是集中的、不透明的，难以规模化，这在高风险领域部署专有模型时造成巨大风险。集中审计存在四个核心问题：一是鲁棒性不足，集中审计机构是单一的失败点，容易受到偏见或攻击；二是规模性较差，推理轨迹太长，难以进行人工验证；三是不透明性，封闭的审计程序会破坏公众信任；四是隐私问题，在展示完整推理的过程中存在模型盗窃或简化风险。", "innovation": "本文提出了一种名为TRUST的透明去中心化审计框架，通过以下方式克服现有局限：一是通过不同审计机构之间的共识机制，即使有最多30%的恶意参与者，也保证正确的审计；二是将推理轨迹分解为层次化的DAG结构，实现可扩展、并行的审计；三是使用区块链账本记录所有验证决策，确保公共问责；四是采用隐私保护分割技术，仅分享部分推理步骤来保护专有逻辑。还提供了TRUST框架的安全性和经济激励的理论保障。", "conclusion": "实验结果证明，TRUST框架能够有效检测推理漏洞，并能在对抗性审计员的情况下保持鲁棒性。本研究为分散式AI审计开了先河，提供了一条通往安全可信的LLM部署的实际途径。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20337", "html_url": "https://arxiv.org/abs/2510.20337", "title": "军事实体目标打击中人工智能系统附带损伤评估模型", "title_en": "Collateral Damage Assessment Model for AI System Target Engagement in Military Operations", "authors": "Clara Maathuis,Kasper Cools", "background": "在人工智能系统在战场上越来越多地发挥作用的时代背景下，确保负责任的目标打击需要对潜在的附带损伤进行严格的评估。", "innovation": "提出了一种新的面向军事实体目标打击中人工智能系统的附带损伤评估模型。该模型在一个统一的知识表示和推理（KRR）架构中整合了时间、空间和力量维度，并采用设计科学方法学。模型的分层结构捕获了要打击的人工智能系统的类别和架构组件，以及相应的打击向量和上下文方面。同时，考虑了扩散、严重性、可能性和评估指标，以提供一种增强透明推理机制的清晰表示。", "conclusion": "该模型通过实例化进行了演示和评估，并为构建负责任和可信赖的智能系统以评估打击人工智能系统产生的效应提供了基础。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20332", "html_url": "https://arxiv.org/abs/2510.20332", "title": "由设计引起的偏差？数据实践如何塑造AI医疗系统中的公平性", "title_en": "Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems", "authors": "Anna Arias-Duart,Maria Eugenia Cardello,Atia Cortés", "background": "人工智能（AI）在医疗领域的应用前景广阔。然而，尽管取得了一些显著的进步，AI解决方案在实际临床环境中的整合仍然受到限制。主要障碍之一在于训练数据的质量和公平性，这些数据常常因为偏见的数据收集实践而受到损害。本研究借助西班牙国家级R&D项目AI4HealthyAging中的经验，发现临床数据收集过程中存在多种类型偏见，包括历史偏见、代表性偏见和测量偏见，并且这些偏见在性别、性别认同、年龄、居住环境、社会经济地位、设备以及标记等多个变量中存在。", "innovation": "识别多种类型的数据偏见，包括历史、代表性、测量偏见，并指出这些偏见在性别、性别认同、年龄、居住环境、社会经济地位、设备以及标记等多个变量中的具体表现。", "conclusion": "提出了一系列提高临床问题设计和数据收集公平性和稳健性的实用建议。希望通过研究成果和实践经验为未来项目开发更加公平的AI医疗系统提供指导。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20310", "html_url": "https://arxiv.org/abs/2510.20310", "title": "工具增强的多步推理用于情景化问答", "title_en": "Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation", "authors": "Mingliang Zhai,Hansheng Liang,Xiaomeng Fan,Zhi Gao,Chuanhao Li,Che Sun,Xu Bin,Yuwei Wu,Yunde Jia", "background": "现有的情景化问答（EQA）方法主要依赖于视觉语言模型（VLMs）直接探索环境并回答问题，而忽略了明确思考或规划的过程，这限制了其推理能力，导致了不必要的探索和无效的回答。现有的EQA方法也因此表现不佳，无法有效地处理环境中的复杂问题。", "innovation": "本文提出了ToolEQA，这是一种将外部工具与多步推理相结合的代理。通过利用外部工具提供额外信息以辅助任务完成，toolEQA能够在后续推理步骤中获得更好的探索方向，从而获取附加的有效信息。this方法能够生成更准确的回应，同时缩短探索距离。此外，作者还设计了一种创新的数据生成管道，自动构建了大规模包含推理轨迹和答案的EQA任务数据集EQA-RT。在此基础上，ToolEQA 在HM-EQA、OpenEQA 和 EXPRESS-Bench 数据集上的表现均优于现有基线，特别是在处理未见过的场景（EQA-RT-Unseen）时，结果显示ToolEQA的成功率提高了9.2%-20.2%，并且比零样本的ToolEQA表达高出10%。", "conclusion": "实验结果表明，ToolEQA 能够显著提高对已见场景和未见场景的回答准确率，同时具有良好的通用性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20345", "html_url": "https://arxiv.org/abs/2510.20345", "title": "大语言模型赋能的知识图谱构建：一项综述", "title_en": "LLM-empowered knowledge graph construction: A survey", "authors": "Haonan Bian", "background": "知识图谱（KGs）长期以来一直是结构化知识表示与推理的基本基础设施。随着大规模语言模型（LLMs）的发展， KGs 的构建进入了一个新的范式，从基于规则和统计的管道转变为语言驱动和生成性框架。", "innovation": "本综述提供了一个关于 LLMs 驱动的 KG 构建的全面概述，系统地分析了 LLMs 如何重塑传统KG工程的三层管道（本体工程、知识提取和知识融合）。从基于模式和无模式的两个互补视角审查新兴的 LLM 推动方法，并综合代表性的框架，分析它们的技术机制及其限制。", "conclusion": "本综述总结了关键趋势和未来研究方向，包括基于 KG 的 LLM 推理、为自主系统构建的动态知识记忆以及多模态 KG 构建。通过这种系统回顾，我们旨在阐明 LLMs 和知识图谱之间不断演变的互动关系，向开发自适应、可解释和智能化的知识系统方向迈进。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20377", "html_url": "https://arxiv.org/abs/2510.20377", "title": "IKnow: 基于指令和知识持续预训练的有效领域适应", "title_en": "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation", "authors": "Tianyi Zhang,Florian Mai,Lucie Flek", "background": "持续预训练被期望能通过仅使用未标记的测试时间数据来适应大型语言模型（LLMs）到新的领域，但直接应用标准的自监督目标到指令调优模型已知会降低其指令跟随能力和语义表示。现有的解决方法假设可以访问原始基础模型或依赖于外部特定领域的数据库——这在基础模型权重因安全原因被保留或可靠的外部语料库不可用的情况下都构成了现实障碍。", "innovation": "我们提出了基于指令和知识的持续适应（IKnow）框架，这是一种简单且通用的方法，提出了以指令-回应对话格式的新自监督目标。该框架通过利用文本本身嵌入的领域知识，并在更深层次的语义层面学习编码而不需要依赖外部资源。", "conclusion": "IKnow 通过在无需外部资源的情况下利用文本中嵌入的领域知识，解决了现有解决方法带来的现实障碍，并且能够在新的领域中有效适应大型语言模型，提升指令跟随能力和语义表示的深度。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20275", "html_url": "https://arxiv.org/abs/2510.20275", "title": "经典特征嵌入有助于基于BERT的人类移动预测", "title_en": "Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction", "authors": "Yunzhi Liu,Haokai Tan,Rushi Kanjaria,Lihuan Li,Flora D. Salim", "background": "人类移动预测对于灾害救援、城市规划和公共卫生至关重要。现有的模型要么仅建模位置序列，要么仅将时间信息作为辅助输入，从而未能充分利用由点位兴趣（POI）提供的丰富语义上下文。", "innovation": "提出了一种称为STaBERT（语义-时间感知的BERT）的模型，该模型在基于BERT的移动模型中加入了导出的时间描述符和POI嵌入，旨在更好地捕捉人类移动背后的语义。STaBERT在每个位置整合了POI和时间信息，构建了一个统一且语义丰富的移动表示。实验结果表明，STaBERT显著提高了预测精度：在单一城市预测中，GEO-BLEU分数从0.34提高到0.75；在多城市预测中，从0.34提高到0.56。", "conclusion": "STaBERT模型通过整合POI和时间信息，显著提升了基于BERT的人类移动预测精度。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20402", "html_url": "https://arxiv.org/abs/2510.20402", "title": "用于专业创新过程生成更多新颖机会的计算模型和工具", "title_en": "A computational model and tool for generating more novel opportunities in professional innovation processes", "authors": "Neil Maiden,Konstantinos Zachos,James Lockerbie,Kostas Petrianakis,Amanda Brown", "background": "该论文提出了一种新的计算模型，旨在根据创造性的理论和技术生成更多新颖的机会，以支持创新项目。该模型包含五个功能，旨在提高创新机会的新颖性而不牺牲实用性。此模型被应用于酒店业的创新项目评估，评估结果显示，与Notebook LM和ChatGPT4相比，该计算模型生成了更多新颖和有用的结果，但并非所有模型的功能都贡献了更多新颖的机会，为未来的研究指出了新的方向。", "innovation": "论文创新之处在于提出了一种新的计算模型，该模型结合了创造力理论和实践，用于生成新颖的创新机会。模型的具体创新体现在五个功能的应用上，这些功能能以新颖的方式支持创新过程，同时保持其实用性。此模型与现有工具相比，能生成更新颖且更实用的结果，但仍有改进空间。", "conclusion": "研究结果表明，该计算模型在新颖性方面表现优于其他工具，但仍需要进一步优化以确保所有功能都有效地生成新颖的机会。未来的研究方向是继续改进模型，以提高其效果。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20457", "html_url": "https://arxiv.org/abs/2510.20457", "title": "SHOIQ中的神经推理方法以实现稳健的实例检索", "title_en": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$", "authors": "Louis Mozart Kamdem Teyou,Luke Friedrichs,N'Dah Jean Kouagou,Caglar Demir,Yasir Mahmood,Stefan Heindorf,Axel-Cyrille Ngonga Ngomo", "background": "概念学习通过使用形式化的描述逻辑公理来从知识库中学习可解释的分类模型。尽管神经符号概念学习最近取得了突破，但大多数方法仍然无法在实际知识库中部署。这是因为这些方法依赖于描述逻辑推理器，这类推理器对不一致的数据和错误数据不够鲁棒。", "innovation": "提出了一种名为EBR的新型神经推理器，它通过嵌入法近似符号推理器的结果。EBR仅需要检索原子概念和存在限制的实例以获取或近似描述逻辑SHOIQ中任何概念的实例集合。实验结果显示EBR对缺失和错误数据具有鲁棒性，优于现有的推理器。", "conclusion": "EBR推理器能够解决现有描述逻辑推理器在面对知识库中的不一致或错误数据时的鲁棒性问题，提供了一种稳健的实例检索方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20568", "html_url": "https://arxiv.org/abs/2510.20568", "title": "失去翻译：决策者并未真正倾听关于人工智能的市民关切", "title_en": "Lost in Translation: Policymakers are not really listening to Citizen Concerns about AI", "authors": "Susan Ariel Aaronson,Michael Moreno", "background": "人们普遍对人工智能（AI）有强烈观点，并希望决策者倾听这些观点。政府正在邀请公众对AI提出意见，但在政策制定过程中，公众的观点并未得到有效利用。这种现象导致决策者错失了建立AI及其治理公信力的机会。研究对比了澳大利亚、哥伦比亚和美国三国政府邀请公民就AI风险和政策提供反馈的情况，并发现尽管各政府都邀请了公众参与，但公民和决策者并未建立起有意义的对话。政府在吸引多样化的公众参与和宣传征求公众意见方面做得不够，使得大多数公民对此不了解或未准备好参与。调查结果显示，参与的公民比例极低，且政府对获取到的反馈反应不足，未能建立起有效的反馈机制。", "innovation": "该论文通过对比分析澳大利亚、哥伦比亚和美国三国的情况，揭示了这些国家在AI政策制定过程中存在的公众参与不足的问题，指出现有参与式AI治理方法未能有效建立公众信任和合法性的问题，并提出了八条改进建议。", "conclusion": "目前的参与式AI治理方法不太可能建立起公众对AI的信任和合法性，因为决策者未能充分倾听和回应公众的关切。论文提出了提高AI普及率、监测公众反馈、拓展公众参与、定期举办网络论坛、使用创新参与方法、包括代表性不足的群体、公开回应公众意见和让参与更容易等八条建议。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20591", "html_url": "https://arxiv.org/abs/2510.20591", "title": "通过母线分裂进行传输阻塞管理的可迁移图学习", "title_en": "Transferable Graph Learning for Transmission Congestion Management via Busbar Splitting", "authors": "Ali Rajaei,Peter Palensky,Jochen L. Cremer", "background": "网络拓扑优化（NTO）可以通过母线分裂缓解传输电网阻塞并减少重新调度成本。然而，使用现有求解器在近实时处理大规模系统时，解决这个混合整数非线性问题是不可行的。机器学习（ML）方法被视为一种有潜力的替代方案，但它们在未见过的拓扑结构、不同运行条件和不同系统上的推广能力有限，限制了它们的实际应用。", "innovation": "本文针对阻塞管理问题，将线性化AC潮流与NTO结合，提出了一种基于图神经网络（GNN）加速的方法。开发了一种异质边感知消息传递神经网络来预测有效的母线分裂动作作为候选NTO解决方案。GNN捕捉局部流模式，实现对未见过的拓扑变化的一般化，提高系统间迁移性。实验结果表明，该方法在GOC 2000节点系统中可以实现高达4个数量级的速度提升，能在一分钟内提供AC可行的解决方案，并且与最优解的差距为2.3%，展示了向大规模系统进行近实时NTO迈进的重要一步。", "conclusion": "这些结果表明，该研究为大型系统的拓扑和跨系统泛化提出了显著的进步，并向近实时NTO方向取得重要进展。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20604", "html_url": "https://arxiv.org/abs/2510.20604", "title": "高效计算随机游走中心性算法", "title_en": "Efficient Algorithms for Computing Random Walk Centrality", "authors": "Changan Liu,Zixuan Xie,Ahad N. Zehmakan,Zhongzhi Zhang", "background": "随机游走中心性是一种在图挖掘中用于量化节点重要性和影响力的基本度量方法。根据从所有其他节点到达某个节点的击中时间的加权平均值定义。尽管它能够捕捉丰富的图结构信息，并且在多种应用场景中广泛使用，但对大型网络计算这一指标仍然是不切实际的，因为现有方法所需的计算量很大。因此，本文研究了两种新的、高效的算法来计算随机游走中心性。", "innovation": "本文提出了两种新的、基于可伸缩算法的随机游走中心性计算方法。这两种算法分别是利用近似 cholesky 分解和稀疏逆估计的方法，以及基于有根生成树采样的方法。这两种算法的运行时间接近线性，并且提供了强大的近似保证。", "conclusion": "在包含超过1000万节点的大规模真实网络上的大量实验结果表明，提出的算法具有高效的计算时间和良好的近似质量。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20636", "html_url": "https://arxiv.org/abs/2510.20636", "title": "流体指数：下一代超智能基准指标", "title_en": "Fluidity Index: Next-Generation Super-intelligence Benchmarks", "authors": "Eric Ngoiya,Tianshu Bao", "background": "本文介绍了流体指数（FI），用于量化模型在动态、可扩展环境下的适应性。基准测试通过评估初始、当前和未来环境状态的偏差来衡量响应准确性，评估上下文切换和连续性。文章区分了封闭式和开放式基准，并优先考虑闭环开放式真实世界基准测试以测试模型的适应性。", "innovation": "研究提出了流体指数（FI）来量化模型的适应性，特别是在动态和可扩展环境中。这种新基准不仅可以评估响应准确性，还可以评估模型在上下文切换和连续性方面的表现。作者特别强调了闭环开放式实际基准测试，以便更真实地验证模型的适应性。", "conclusion": "研究认为，真正意义上的超级智能模型应具备至少第二级的适应性，即通过数码补给实现自持续计算，从而最大化流体性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20603", "html_url": "https://arxiv.org/abs/2510.20603", "title": "LLMs中良好推理的定义：基于多方面评估拆解推理步骤", "title_en": "What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation", "authors": "Heejin Do,Jaehui Hwang,Dongyoon Han,Seong Joon Oh,Sangdoo Yun", "background": "当前评估大语言模型（LLMs）的工作主要依赖于最终答案的准确性，这种方法虽然占主导地位，但它仅提供粗略的改进信号，并忽视了潜在推理过程的质量。本文作者认为，对推理进行更精细的评估有助于构建更 robust 的模型。因此，他们提出了因果逐步评估（CaSE）方法，这是一种利用只从前一上下文评估每个推理步骤的方法，以避免事后偏见。作者使用一个新的专家注释基准 MRa-GSM8K 和 MRa-MATH 验证了 CaSE 的有效性，并发现使用 CaSE 评估相关性和连贯性的训练数据直接提升了最终任务的表现。", "innovation": "本文创新地提出了因果逐步评估（CaSE）方法，这种方法通过仅从前一上下文评估每个推理步骤来避免事后偏见，从而提供对推理质量的更精细评估。此外，作者还展示了使用 CaSE 评估相关性和连贯性的训练数据可以直接提升 LLM 最终任务的表现。", "conclusion": "本文提供了一个可扩展的框架来分析、调试和改进 LLM 推理，并证明了从有效性检查转向多方面评估的实际价值。这种方法强调了在构建 robust LLM 时重视推理质量的重要性，为 LLM 的进一步研究和应用提供了新的方向。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20641", "html_url": "https://arxiv.org/abs/2510.20641", "title": "将机器学习整合到信念-欲望-意图代理中：当前进展和开放挑战", "title_en": "Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges", "authors": "Andrea Agiollo,Andrea Omicini", "background": "得益于机器学习（ML）模型在感知和认知任务中展现出的人类似能力，将ML嵌入理性代理架构中的框架正在受到关注。然而，这一领域依然支离破碎且不一致，经常仅将ML嵌入通用代理容器中，而忽视了理性架构（如信念-欲望-意图（BDI）代理）的表达能力。该领域相关文献尚未系统化，亟需系统分析以填补这一空白。", "innovation": "本文提出了一个精细分类现有方法的系统化分析框架，以BDI范式为参考。该分析揭示了增强的理性ML代理快速发展的文献，并指出了设计有效的理性ML代理的关键研究机会和开放挑战。", "conclusion": "该研究为理解和设计有效的理性ML代理提供了新的视角，指出了研究的潜力所在，并为进一步探索和创新奠定了基础。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20665", "html_url": "https://arxiv.org/abs/2510.20665", "title": "推理的形状：大型语言模型中推理踪迹的拓扑分析", "title_en": "The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models", "authors": "Xue Wen Tan,Nathaniel Tan,Galen Lee,Stanley Kok", "background": "评估大型语言模型推理踪迹的质量尚未得到充分研究，且劳动密集、不可靠：当前做法依赖于专家评分标准、手工标注和缓慢的一对一判断。自动化努力主要集中在基于图的代理上，这些代理衡量结构连接性，但无法阐明构成高质量推理的标准；对于本质上复杂的处理过程，这些抽象可能过于简单。因此，研究提出了基于拓扑数据分析的方法来捕捉推理踪迹的几何结构，从而实现高效的自动化评价。", "innovation": "引入了基于拓扑数据分析的评估框架，以捕捉推理踪迹的几何结构，能高效自动化评估推理质量。实验证明，拓扑特征在评估推理质量上的预测能力显著高于标准图形度量，表明有效的推理更好地通过高维几何结构来捕捉，而非仅通过关系图。进一步展示了紧凑且稳定的拓扑特征可靠地表示踪迹质量，为其后强化学习算法提供实用信号。", "conclusion": "有效推理更倾向于由高维几何结构而非单纯关系图来捕捉；利用紧凑且稳定的拓扑特征可有效识别推理踪迹的质量；拓扑数据分析为未来强化学习算法提供了一种实用的信号指示。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20467", "html_url": "https://arxiv.org/abs/2510.20467", "title": "FLORA：基于模糊逻辑的无监督知识图谱对齐", "title_en": "FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic", "authors": "Yiwen Peng(IP Paris),Thomas Bonald(IP Paris),Fabian M. Suchanek(IP Paris)", "background": "知识图谱对齐是一项任务，旨在跨两个知识图谱匹配等价实体（包括实例和类）和关系。现有的大多数方法主要集中在实体级别的对齐上，通过嵌入空间计算实体的相似性。这些方法缺乏可解释的推理，且需要训练数据才能工作。", "innovation": "本文提出了一种名为FLORA的简单但有效的方法：（1）无监督，不需要训练数据；（2）为实体和关系提供迭代的整体对齐；（3）基于模糊逻辑，因此能提供可解释的结果；（4）可证明收敛；（5）允许悬挂实体，即在另一个知识图谱中没有对应实体的实体；（6）在主要基准上的结果达到最先进的水平。", "conclusion": "FLORA方法解决了现有方法在解释性和对齐方面的问题，通过模糊逻辑实现无监督和迭代式的对齐，最终在主要基准上达到了最先进的对齐效果。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20809", "html_url": "https://arxiv.org/abs/2510.20809", "title": "Real Deep Research for AI, Robotics and Beyond", "title_en": "Real Deep Research for AI, Robotics and Beyond", "authors": "Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang", "background": "随着人工智能和机器人学研究的迅速增长，每年产生超过10,000篇论文，导致研究人员难以跟上最新的进展。快速变化的趋势、跨学科工作的增多以及探索超出自己专业领域的领域的需求，都使这一挑战更加严峻。", "innovation": "本文提出了一种通用的分析管道，能够系统地分析任一研究领域，识别新兴趋势，发现跨领域的机会，并为新的研究提供具体的起点。论文详细介绍了Real Deep Research (RDR)框架的构建，该框架应用在人工智能和机器人学领域，特别是对基础模型和机器人技术进行了重点研究。同时也简要地扩展了对其他科学领域的分析。", "conclusion": "希望通过这项工作，为从事人工智能及相关领域研究的科研人员提供启示。附录提供了各个分析主题的详细结果。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20691", "html_url": "https://arxiv.org/abs/2510.20691", "title": "计划然后检索：基于强化学习的复杂知识图谱推理指导", "title_en": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs", "authors": "Yanlin Song,Ben Liu,Víctor Gutiérrez-Basulto,Zhiwei Hu,Qianqian Xie,Min Peng,Sophia Ananiadou,Jeff Z. Pan", "background": "知识图谱问答（KGQA）旨在通过推理结构化的知识图谱来回答自然语言问题。虽然大语言模型通过强大的推理能力提升了KGQA的能力，但现有方法仍难以充分利用KG中的丰富知识和LLMs的推理能力，尤其在复杂场景中表现不佳。这些方法往往假设KG完全覆盖且缺乏判断何时需要外部信息的机制，其推理仍然是短视的，无法进行连贯的多步骤规划，即便相关知识存在也会导致推理失败。", "innovation": "本文提出了一种名为Graph-RFT的创新两阶段强化微调KGQA框架，其核心是一个‘计划-KG搜索-Web搜索-思考’的过程。Graph-RFT引入了一种具有定制计划检索数据集的链式思维微调方法，激活了结构化推理并解决了冷启动问题。然后，引入了一种新颖的计划检索引导的强化学习过程，将明确的规划和检索动作与多奖励设计相结合，实现了覆盖感知的检索调度。此外，使用了一种基于笛卡尔规划模块来将复杂问题分解为有序子问题，并使用逻辑表达式指导工具调用以进行全局一致的多步骤推理。", "conclusion": "通过对知识图谱和网络资源的检索优化以及合理利用多奖励机制，Graph-RFT框架使模型在知识不完全的情况下实现了自主规划和动态检索调度，并能够在复杂场景中进行连贯的多步骤推理。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20632", "html_url": "https://arxiv.org/abs/2510.20632", "title": "为多语言和多模态电子商务应用提供可靠评估的大语言模型", "title_en": "Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications", "authors": "Shuyi Xie,Ziqin Liew,Hailing Zhang,Haibo Zhang,Ling Hu,Zhiqiang Zhou,Shuman Liu,Anxiang Zeng", "background": "大语言模型（LLMs）在通用自然语言处理（NLP）基准测试中表现出色，但在专业领域的能力还未得到充分探索。在电子商务中，现有的评估工具如EcomInstruct、ChineseEcomQA、eCeLLM和Shopping MMLU存在任务多样性不足、任务形式单一、数据合成或选集以及局限于英语和中文等问题，因此留给实践者可信赖的工具来评估模型在复杂的真实购物场景中的能力有限。为了填补这一空白，该研究提出了一种名为EcomEval的多语言和多模态基准，用于评估LLMs在电子商务中的能力。EcomEval覆盖了六大类别和37项任务（包括8项多模态任务），数据主要来源于真实的客户查询和交易日志，反映了真实商业互动的嘈杂和异质性。为了确保参考答案的质量和可扩展性，研究采用了半自动的管道流程，由大型模型起草候选回复，随后由超过50名拥有电子商务和多语言专业知识的专家进行审核和修改。研究还定义了每个问题和任务类别的问题难度等级，通过不同规模和能力的模型进行评估得分的平均来实现面向挑战的详细评估。此外，EcomEval还涵盖了七种语言，包括五种低资源的东南亚语言，提供了一种多语言视角，而这是之前的工作所缺少的。", "innovation": "该研究的创新之处在于开发了EcomEval，一种全面的多语言和多模态基准，用于评估LLMs在电子商务应用中的性能。它涵盖了六个类别和37个任务（包括8个接受度任务），主要从真实的客户查询和交易日志中获取数据，反映了真实商业互动的特点。此外，研究采用了半自动流程改进参考答案的质量和可扩展性，定义了问题难度级别，以实现针对挑战的详细评估。EcomEval还提供了七种语言的支持，增加了多语言视角，进一步扩大了适用范围。", "conclusion": "EcomEval为评估LLMs在多语言和多模态电子商务应用中的性能提供了一个高质量、可扩展且全面的框架。通过这一基准，研究者和实际应用者可以更好地评估和利用大模型在复杂、真实的购物场景中的表现，从而指导未来的研究和发展。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.01555", "html_url": "https://arxiv.org/abs/2402.01555", "title": "SLYKLatent：使用深度面部特征学习的眼球追踪学习框架", "title_en": "SLYKLatent: A Learning Framework for Gaze Estimation Using Deep Facial Feature Learning", "authors": "Samuel Adebayo,Joost C. Dessing,Seán McLoone", "background": "在眼球追踪领域，由于数据集中的偶然不确定性、协变移位和测试领域的通用化挑战，现有的眼球探测方法在表现上不稳定。本研究旨在通过改进这些挑战来提高眼球估计的准确性。", "innovation": "SLYKLatent采用了一个新颖的方法，首先使用自监督学习在面部表情数据集上进行初始训练，然后通过基于块的三分支网络和逆解释方差加权训练损失函数进行精细化训练，以解决上述问题。通过在基准数据集上的评估，该方法在Gaze360上实现了10.9%的改进，在ETH-XGaze上的某些子集中领先11.6%，并且在适应性测试中分别在RAF-DB和Affectnet上取得了86.4%和60.9%的准确率。", "conclusion": "SLYKLatent的有效性通过消融研究得到了验证，并且在各个指标上显著超过了现有方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19829", "html_url": "https://arxiv.org/abs/2510.19829", "title": "SSL-SE-EEG: 一种基于自监督学习和挤压-激励网络的无标签EEG数据鲁棒学习框架", "title_en": "SSL-SE-EEG: A Framework for Robust Learning from Unlabeled EEG Data with Self-Supervised Learning and Squeeze-Excitation Networks", "authors": "Meghna Roy Chowdhury,Yi Ding,Shreyas Sen", "background": "脑电图（EEG）在脑-计算机接口（BCIs）和神经诊断中发挥着重要作用，但其在实际中的应用受到噪声干扰、数据缺失和注释成本高的挑战。", "innovation": "提出了SSL-SE-EEG框架，将自监督学习（SSL）与挤压-激励网络（SE-Nets）集成，增强特征提取能力，提升对噪声的鲁棒性，并减少对标注数据的依赖。与其他传统的EEG处理技术不同，SSL-SE-EEG将EEG信号转换为适用于深度学习的结构化二维图像表示。", "conclusion": "在MindBigData、TUH-AB、SEED-IV和BCI-IV数据集上进行的实验验证表明，SSL-SE-EEG具有最先进的准确率（在MindBigData上达到91%，在TUH-AB上达到85%），使其适用于实时BCI应用。通过实现低功耗、可扩展的EEG处理，SSL-SE-EEG为生物医学信号分析、神经工程和下一代BCIs提供了有前景的解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20784", "html_url": "https://arxiv.org/abs/2510.20784", "title": "基于一致性的AGI度量", "title_en": "A Coherence-Based Measure of AGI", "authors": "Fares Fourati", "background": "近期研究由\\citet{hendrycks2025agidefinition}将人工通用智能(AGI)定义为从Cattell--Horn--Carroll (CHC)人类认知模型得出的认知领域技能算术平均值。这一定义虽然优雅，不过它假设了补偿性——即某些领域的卓越能力可以弥补其他领域的失败。真正的通用智能应当体现一致的充足性——即在所有关键领域具有平衡的专业能力。因此，本文提出了基于一致性的AGI度量方法，结合算术均值、几何均值和调和均值体制连续统一体，用一致性下的广义均值积分定义AUC来衡量鲁棒性，并揭示了在不同补偿性假定下的稳健性。这种方法不同于算术平均值，算术平均值鼓励专业化，而AUC则惩罚不平衡并捕捉跨领域的依赖性。", "innovation": "本文提出了一种新的AGI度量方法，基于一致性的广义均值积分定义AUC。与传统的算术均值不同，AUC强调跨越不同补偿性假定的一致性，更严格地体现AGI的实际进展。通过对GPT-4和GPT-5的CHC基领域的得分应用该方法，发现即使算术分数很高，这些系统在各关键领域的整合表现依然远未达到一般性能力。该方法为测量真实向AGI的进展提供了一个理论上严谨且解释性强的基础。", "conclusion": "本文提出的AUC度量方法从根本上衡量AGI，突显了单纯聚焦于算术均值的不足，强调了在不同补偿性假设下的稳定性。虽然GPT-4和GPT-5在某些领域表现优异，但整体一致性显示它们距离真正的AGI还有很大差距，从而为评价AGI的真实进展提供了一个新的严格标准。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19844", "html_url": "https://arxiv.org/abs/2510.19844", "title": "CourtGuard: 本地多智能体提示注入分类器", "title_en": "CourtGuard: A Local, Multiagent Prompt Injection Classifier", "authors": "Isaac Wu,Michael Maslowski", "background": "随着大型语言模型（LLMs）被整合到各种敏感应用中，提示注入攻击成为了一个日益严重的风险。这些攻击能让LLMs泄露敏感信息、传播虚假信息，并表现出有害行为。为了防范此类攻击，本文提出了一种名为CourtGuard的本地运行多智能体提示注入分类器。该系统通过模拟法庭类机制来评估提示的性质，其中“辩护律师”模型认为提示无害，“检方律师”模型认为提示是提示注入，“法官”模型给出最终判定。该系统能在保持较低误报率的情况下运行，但其对提示注入的检测效果一般较差。然而，这一低误报率突显了在提示分类中同时考虑对抗和非对抗场景的重要性。此外，与现有提示注入分类器的性能对比增强了多智能体系统在提示注入攻击防御中的应用前景。", "innovation": "CourtGuard是一个本地可运行的多智能体提示注入分类器，它采用法庭模拟机制评估提示，包括辩护律师、检方律师和法官模型的逐层评估，以区分无害和有害的提示。此外，CourtGuard在误报率方面优于LLM作为法官的直接检测器，展示了对抗和非对抗场景同时考虑的重要性，同时也推动了多智能体系统在对抗提示注入攻击中的应用。", "conclusion": "CourtGuard显著降低了误报率，但在提示注入检测方面效果一般。但这一发现强调了在提示分类决策中同时考虑潜在对手和善意场景的重要性。此外，CourtGuard相比其他提示注入检测器在多智能体系统应用中的相对表现，进一步证明了多智能体系统在应对提示注入攻击中的潜在价值。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19851", "html_url": "https://arxiv.org/abs/2510.19851", "title": "推理模型能否掩饰推理过程？推理链监控的极限测试", "title_en": "Can Reasoning Models Obfuscate Reasoning? Stress-Testing Chain-of-Thought Monitorability", "authors": "Artur Zolkowski,Wen Xing,David Lindner,Florian Tramèr,Erik Jenner", "background": "近期的研究表明，对齐不当的模型可能会表现出欺骗行为，这引发了对其输出可信度的担忧。链式思考（CoT）被认为是一种有效的对齐监控工具，但一个关键问题是：模型是否可以在追求隐藏的敌对目标时掩饰其CoT，同时避开检测？", "innovation": "本文开发了一种可组合且可量化的提示分类，以测试CoT的掩饰性。通过玩具任务和真实环境中的实验，在SHADE-Arena进行了评估，揭示出CoT监控在无掩饰压力时表现出色；而在强力掩饰压力下，一些模型可以成功完成敌对任务并躲避检测；内部的CoT掩饰程度不如外部在提示压力下的掩饰程度大。这表明，在良性场景中，CoT提供了有价值的监督，但在稳健部署中需要针对具体模型的监控测试。", "conclusion": "CoT在良性环境中提供了有价值的监督，但稳健部署需要针对特定模型的监控测试，以确保其能够防止掩饰行为，保障输出的可信度。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19866", "html_url": "https://arxiv.org/abs/2510.19866", "title": "不同模型和提示框架在高中物理中生成的教学计划的教育合理性和易用性评估", "title_en": "An Evaluation of the Pedagogical Soundness and Usability of AI-Generated Lesson Plans Across Different Models and Prompt Frameworks in High-School Physics", "authors": "Xincheng Liu", "background": "本文通过评估五种领先的大语言模型——ChatGPT（GPT-5）、Claude Sonnet 4.5、Gemini 2.5 Flash、DeepSeek V3.2、Grok 4生成的教学计划的教育合理性和易用性，为了解AI在教育中的有效性提供了参考。", "innovation": "本文创新地综合作了许多因素来评估大语言模型生成的教学计划，包括模型选择、不同提示框架（TAG、RACE、COSTAR）的影响，以及对可读性、事实准确性、教育标准匹配度和学习目标认知需求的分析。", "conclusion": "研究结果表明，可读性主要由模型设计决定，而教学可靠性和课程标准一致性更多依赖于提示框架。最优配置是使用优化可读性的模型结合RACE框架以及明确的物理概念、课程标准和高层次目标的检查表。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19882", "html_url": "https://arxiv.org/abs/2510.19882", "title": "在线内容管理中的重要特征量化", "title_en": "Quantifying Feature Importance for Online Content Moderation", "authors": "Benedetta Tessa,Alejandro Moreo,Stefano Cresci,Tiziano Fagni,Fabrizio Sebastiani", "background": "准确评估用户对管理干预措施的响应是开发有效和用户为中心的管理策略的关键。这需要对哪些用户特征与不同行为响应相关有清晰的理解。本文旨在研究753个社会行为、语言、关系和心理特征，在预测受到Reddit重大管理干预影响的16800名用户的行为变化中的有效性。", "innovation": "本文将问题定义为“量化”任务，通过应用贪婪特征选择策略，不仅可以识别最能预测用户活动、毒性和参与度多样性的特征，还可以估计其重要性。研究结果能够识别出在所有任务中一直具有信息性的少数特征，并确定许多其他特征要么是特定任务相关的，要么几乎没有用处。还发现各种任务的预测性能不同，活动和毒性的变化比多样性更容易预测。这些结果为开发能够准确预测用户对管理干预反应的系统铺平了道路。", "conclusion": "本文的研究结果表明，在线内容管理后用户行为的复杂性，并暗示有效的管理不仅需要针对用户特征，还需要适应干预的具体目标。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19889", "html_url": "https://arxiv.org/abs/2510.19889", "title": "从优化到预测：基于Transformer的路径流量估计到交通分配问题", "title_en": "From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem", "authors": "Mostafa Ameli,Van Anh Le,Sulthana Shams,Alexander Skabardonis", "background": "交通分配问题是交通流量分析的核心问题，传统上使用在均衡原则下的数学规划方法求解。然而，这种方法在大规模网络中由于OD对数量的非线性增长而导致计算变得困难。传统方法在处理大规模网络时往往计算成本高昂。", "innovation": "该研究提出了一个基于深度神经网络的新型数据驱动方法，特别是利用Transformer架构直接预测交通均衡路径流量。通过关注路径级别的交通分布，该模型能够捕捉OD对之间的复杂关联，相比传统的链路级别方法提供了更详细和灵活的分析。基于Transformer的模型大幅减少了计算时间，并且能够适应需求和网络结构的变化，而不需要重新计算。", "conclusion": "实验结果显示，提出的模型比传统的优化方法快了数个数量级。该模型能够有效地估算多类网络中的路径级别交通流量，减少了计算成本并提高了预测精度。它还能够灵活适应需求和网络条件的变化，支持交通管理并为增强的交通运输规划和政策制定提供快速的`假设情况`分析。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19875", "html_url": "https://arxiv.org/abs/2510.19875", "title": "Stream: 将稀疏注意力扩展到大规模语言模型中的长上下文机械可解释性", "title_en": "Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention", "authors": "J Rosser,José Luis Redondo García,Gustavo Penha,Konstantina Palla,Hugues Bouchard", "background": "随着大型语言模型（LLMs）的上下文长度扩展到百万级token，传统的基于机制的可解释性技术在分析注意力机制时，其复杂度随着上下文长度的增加而四次方级增长，需要超过10万token的内存消耗。这使得在传统硬件上进行可解释性分析变得困难且成本高昂。", "innovation": "本文介绍了一种新的技术——Sparse Tracing稀疏跟踪，通过利用动态稀疏注意力机制，该技术能够高效地分析长时间上下文的注意力模式。此外，作者提出了名为Stream的编译可实现的分层剪枝算法，能够在接近线性时间内（$O(T \times \text{log } T)$）和线性空间（$O(T)$）内估计每个注意力头的稀疏注意力掩码，从而实现大规模上下文的一次通过解释。Stream通过二分搜索风格的细化方法，仅保留每查询的前k个关键块，同时保留模型的下一次行为。", "conclusion": "通过使用Stream技术，可以在保留关键信息的同时，大幅度减少token交互并揭示从输入到输出的逐层路径，使得长上下文解释在消费者级GPU上变得可行。这种技术提供了一种实用的工具，用于分析注意力模式和追踪信息流，而无需大量的缓存。Sparse Tracing有助于普及链式推理监控。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20621", "html_url": "https://arxiv.org/abs/2510.20621", "title": "朝向利用高级算法挖掘可解释模型的可信人工智能的形式化", "title_en": "Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms", "authors": "Riccardo Guidotti,Martina Cinquini,Marta Marchiori Manerba,Mattia Setzu,Francesco Spinnato", "background": "可解释的设计模型对于在现实世界应用中培养自动化决策模型的信任、问责和安全采用至关重要。本文构建了MIMOSA（挖掘利用高级算法的可解释模型）框架的基础，该框架提供了一个全面的方法来生成平衡解释性和性能的预测模型，同时嵌入关键的伦理属性。在此论文中，我们对包括表格数据、时间序列、图像、文本、交易和轨迹等不同类型的广泛决策任务下的监督学习环境进行了正式定义，并对三种主要的可解释模型类别（特征重要性、规则和基于实例的模型）进行了详细分析，探讨了它们的具体解释维度、推理机制和复杂性。在此基础上，我们还定义了三个重要的伦理属性：因果性、公平性和隐私性，为每个属性提供了形式化定义、评估指标和验证程序。", "innovation": "提出了MIMOSA框架，旨在构建一个全面的方法来生成平衡解释性和性能的预测模型，同时嵌入关键的伦理属性。详细讨论了监督学习环境下的广泛任务和数据类型，包括表格数据、时间序列、图像、文本、交易和轨迹。定义了三种主要的可解释模型类别及其特性，探讨了伦理属性之间的内在权衡，提出如何在可解释模型中嵌入隐私要求、公平约束和因果推理。通过在模型生成过程中评估伦理措施，为开发准确、可解释且公平、隐私保护、因果意识的AI系统奠定了理论基础。", "conclusion": "通过在模型生成过程中评估伦理措施，本文为开发不仅准确和可解释而且公平、隐私保护且具有因果意识的AI系统奠定了理论基础，使得这些系统不仅实现自动化决策，还能确保社会的信任、问责和安全采用。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19873", "html_url": "https://arxiv.org/abs/2510.19873", "title": "从小到大：通过推理图转移CUDA优化专长", "title_en": "From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph", "authors": "Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li", "background": "尽管CUDA编程及领域特定库的演进显著，但有效利用具有大规模并行引擎的GPU仍具有挑战性。大型语言模型（LLMs）展示出从顺序代码生成优化CUDA代码的潜力，但在实践中使用LLMs面临两大挑战：云基础API存在的代码泄漏风险，以及局部部署通常计算成本高昂且效率低下。这些缺陷促进了小语言模型（SLMs）的兴趣，SLMs更轻量级且更隐私友好。虽然研究显示SLMs在特定任务中可以与LLMs性能相当，但在CUDA生成方面的有限推理能力导致其表现欠佳。为克服这一差距，本文提出了ReGraphT，一种无需训练、基于检索增强的生成框架，将LLMs的推理转移到较小模型。ReGraphT将CUDA优化路径组织为结构化的推理图，将综合CUDA优化表示为状态转换，并利用蒙特卡洛图搜索（MCGS）进行高效探索。", "innovation": "提出了ReGraphT，一种无需训练、基于检索增强的生成框架，将LLMs的推理转移到较小模型。ReGraphT将CUDA优化路径组织为结构化的推理图，将综合CUDA优化表示为状态转换，并利用蒙特卡洛图搜索（MCGS）进行高效探索。还提出了一个针对CUDA优化的基准测试，通过推理复杂性的难度级别进行全面评估。实验结果表明，ReGraphT比特定HPC微调模型和其他检索增强的方法更优，平均加速CUDAEval和ParEval 2.33倍。当与DeepSeek-Coder-V2-Lite-Instruct和Qwen2.5-Coder-7B-Instruct结合使用时，ReGraphT使SLMs能够在避免隐私风险和过度计算开销的同时接近LLMs的性能。", "conclusion": "ReGraphT是在无需训练的情况下将LLMs级别的推理能力转移到较小模型的创新方法。通过构建CUDA优化的结构化推理图并利用MCGS，提高了小型模型在CUDA任务上的性能。实验证明，ReGraphT能够在保持较高性能的同时，降低大数据模型带来的隐私和计算成本风险。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19892", "html_url": "https://arxiv.org/abs/2510.19892", "title": "Can They Dixit? Yes they Can! Dixit as a Playground for Multi-modal Language Model Capabilities", "title_en": "Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities", "authors": "Nishant Balepur,Dang Nguyen,Dayeon Ki", "background": "当前多模态大语言模型（MLMs）通常被评估在静态的单一基准上，无法在一个任务中全面评估MLM的能力，或依赖于人类或模型间的两两比较，这种评估方式主观性强、成本高，并且允许模型利用表面捷径（如冗长）来提高胜率。", "innovation": "本文提出了一种基于游戏的评估方法，通过多模态语言模型在Dixit（一种幻想卡牌游戏）中的表现来全面评估MLM的能力。这种方法要求玩家具备多种能力，确保竞争性，且由明确的客观规则支配，使评估更具吸引力，为解决上述挑战提供了强有力的框架。", "conclusion": "定量实验显示，五种MLM在Dixit中获得的胜率排名与其在流行MLM基准上的表现完全一致。Dixit中人与MLM的对战揭示了代理策略之间的差异，并指明了MLM推理能力的改进方向。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19897", "html_url": "https://arxiv.org/abs/2510.19897", "title": "基于语义和情景记忆的监督学习：智能体适应的反思性方法", "title_en": "Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation", "authors": "Jackson Hassell,Dan Zhang,Hannah Kim,Tom Mitchell,Estevam Hruschka", "background": "本文探讨了基于预训练大规模语言模型的智能体如何通过标记示例学习目标分类函数，而无需更新参数。传统的微调等方法成本高、灵活性差且不透明，本文提出了一种增强记忆框架，利用标记数据和LLM生成的批判性反馈。该框架使用情景记忆存储实例级批判（捕捉特定的过去经历）和语义记忆将这些转换成可重用的任务级指导。在各类任务上，采用批判性反馈可将检索基线（类似于RAG）的准确率提高24.8%以上。通过大量实证研究，发现开源和OpenAI模型在处理事实性数据和偏好数据时的行为差异显著。为了解释模型对不同形式的监督在记忆中的反应，引入了新型的可塑性度量标准，帮助解释观察到的行为，并揭示模型特征和记忆策略如何共同影响学习动态。", "innovation": "提出了增强记忆框架，通过结合标记数据和LLM生成的批判性反馈学习目标分类函数，相比于传统的微调方法，该方法在成本、灵活性和透明度方面具有优势。此外，引入了可塑性度量标准，解释了模型对不同形式监督的响应，这一度量标准有助于阐明模型特征和记忆策略如何共同影响学习动态。", "conclusion": "本文研究发现，基于记忆增强的学习方法有助于构建更适应和可解释的大规模语言模型智能体。通过对记忆驱动的反思性学习深入研究，可以看到这种方法在提高模型学习效果和解释性方面的潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19895", "html_url": "https://arxiv.org/abs/2510.19895", "title": "大型语言模型驱动的数学建模", "title_en": "Large Language Model enabled Mathematical Modeling", "authors": "Guoyun Zhang", "background": "传统优化方法如线性规划、混合整数规划和仿真高度依赖领域专家将实际问题转化为可解的数学模型。尽管求解器如Gurobi和COPT很强大，但专家输入仍然对于定义目标、约束和变量是必需的。本研究探讨了大型语言模型（LLMs），特别是DeepSeek-R1模型，如何通过自然语言理解和代码生成来解决这一模式差距。尽管GPT-4、Claude和Bard等以前的模型在NLP和推理任务中表现出色，但由于高昂的令牌成本和虚构倾向，在供应链场景中的实际适用性有限。相比之下，使用强化学习训练的DeepSeek-R1是一种成本效益高且性能出色的模型，具有替代潜力。", "innovation": "本研究系统地评估了DeepSeek-R1在四种关键运筹学（OR）基准测试中的表现：NL4OPT、IndustryOR、EasyLP和ComplexOR。研究采用的方法包括基线评估、构建虚构现象分类法，以及应用LLM-as-a-Judge、少样本学习（FSL）、工具调用和多代理框架等缓解策略，旨在减少虚构现象，提高建模准确性，并更好地使模型输出与用户意图保持一致。", "conclusion": "通过使用DeepSeek-R1模型，研究为运筹学中的数学建模提供了一种新的路径，引入了自然语言理解和代码生成来提高决策准确性，从而减少对领域专家的依赖。同时，研究提出和应用了多种技术来减轻模型的虚构倾向，增强了模型的实用性和可靠性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19950", "html_url": "https://arxiv.org/abs/2510.19950", "title": "金融市场中的鲁棒强化学习：用椭圆不确定性集建模市场冲击", "title_en": "Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets", "authors": "Shaocong Ma,Heng Huang", "background": "在金融应用中，强化学习（RL）代理通常基于历史数据训练，而其行动不影响价格。然而，在部署时，这些代理在实时市场中交易，其成交能改变资产价格，这就是所谓的市场冲击。这种训练环境和部署环境之间的不匹配会显著降低表现。传统的鲁棒强化学习方法通过优化一系列不确定性下的最坏情况性能来解决这种模型不匹配问题，但通常依赖对称结构，无法捕捉市场冲击的方向性。", "innovation": "为了应对这一问题，本文开发了一种新型的椭圆不确定性集类。我们为这些集合下的最坏情况不确定性建立了隐式和显式的闭式解，这使得鲁棒政策评估更加高效和可操作。实验证实在单一资产和多资产交易任务中，我们的方法能够获得更高的夏普比率，并且在交易量增加的情况下仍然保持鲁棒性，提供了一种更忠实且可扩展的强化学习方法。", "conclusion": "我们的方法在多种交易任务中实现了卓越的夏普比率，并在交易量增加时保持了鲁棒性，为金融市场中的强化学习提供了一种更忠实且可扩展的方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19967", "html_url": "https://arxiv.org/abs/2510.19967", "title": "LyriCAR：一种针对可控歌词翻译的难度感知 Curriculum 强化学习框架", "title_en": "LyriCAR: A Difficulty-Aware Curriculum Reinforcement Learning Framework For Controllable Lyric Translation", "authors": "Le Ren,Xiangjian Zeng,Qingqiang Wu,Ruoxuan Liang", "background": "歌词翻译是一个具有挑战性的工作，需要平衡多种音乐约束条件。现有的方法通常依赖于手工编写的规则和句子级别的建模，这些方法限制了它们学习和掌握音乐语言模式，并在段落级别的翻译中有效泛化的能力，特别是在跨行连贯性和全局押韵方面。", "innovation": "提出了一种名为LyriCAR的新颖框架，这是一种操作完全无监督的可控歌词翻译模型。LyriCAR引入了一种难度感知的课程设计师和自适应课程策略，确保高效分配训练资源，加速收敛，并通过逐步指导模型进行复杂的挑战改进整体翻译质量。", "conclusion": "在EN-ZH歌词翻译任务上的广泛实验表明，LyriCAR的性能超越了最先进的基础模型，并达到标准翻译度量和多维奖励得分的新标准。自适应课程策略使训练步骤减少近40%，同时保持了优越的表现。代码、数据和模型可以在该链接中访问：this https URL."}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19975", "html_url": "https://arxiv.org/abs/2510.19975", "title": "重访零阶优化：最小方差两点估计器和方向对齐的扰动", "title_en": "Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations", "authors": "Shaocong Ma,Heng Huang", "background": "现有研究主要集中在固定长度的扰动上，忽略了方向对齐潜在的优势。本文探讨了两点零阶梯度估计器，并确定了随机扰动中使估计器渐近方差最小的分布。", "innovation": "本文将问题转化为受到扰动分布约束的泛函优化问题，发现理想中的扰动感可以在方向上与真实梯度对齐。同时，还对偏向对齐扰动(DAP)方案的理论和经验性质进行了研究，并分析了使用δ-非偏随机扰动的随机梯度下降的收敛性，扩展了现有的复杂度界限覆盖范围。通过在合成问题和实际任务上的实验评估，展示了DAPs在特定条件下的优越性。", "conclusion": "本文表明DAPs在特定条件下比传统方法更出色。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19953", "html_url": "https://arxiv.org/abs/2510.19953", "title": "零阶优化中无偏梯度估计器的最优构建", "title_en": "On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization", "authors": "Shaocong Ma,Heng Huang", "background": "零阶优化（ZOO）是一种重要的框架，适用于当梯度不可用或计算成本高昂时的随机优化。现有的ZOO方法的一个潜在局限性是，大多数梯度估计量通常存在偏见，除非扰动步长消失。因此，需要提出一种新的方法来克服这一偏见问题。", "innovation": "提出了一种全新的基于函数评估的无偏梯度估计量的无偏估计家族。通过将方向导数重新表示为倒转无穷级数，并从精心设计的分布中进行采样，构造了在消除偏见的同时保持良好方差的估计量。分析了它们的理论特性，推导了四种特定构建方法的最优尺度分布和扰动步骤，并证明确实能够使使用所提估计量的SGD达到光滑非凸目标的最佳复杂度。", "conclusion": "实验结果显示，相比标准方法，我们的方法在合成任务和语言模型微调中的准确性和收敛性优越于标准方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19988", "html_url": "https://arxiv.org/abs/2510.19988", "title": "LLM-增强的符号NLU系统以实现更可靠连续因果陈述解释", "title_en": "LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation", "authors": "Xin Lian,Kenneth D. Forbus", "background": "尽管大型语言模型（LLMs）在广泛应用中的适用性广泛，但它们依赖于概率推理，这使得它们容易出现生成事实中的虚构以及自然语言理解（NLU）任务中输出结构不一致的问题。相比之下，符号NLU系统提供基于经过整理的词汇库、语义资源以及句法和语义解析规则的可解释理解。这些系统生成的关系表示可以用于精确推理和规划，并实现增量可调试学习。然而，符号NLU系统往往在覆盖范围上比LLMs更有限，且需要稀缺的知识表示和语言学技能来进行扩展和维护。", "innovation": "本文探索了一种结合LLMs广泛覆盖语言处理能力和符号NLU生成结构化关系表示能力的混合方法。通过使用LLMs进行重述和文本简化以提供广泛的覆盖范围，并利用LLMs作为填充知识空白的来源，本文使用符号NLU生成用于推理和增量学习的表示。", "conclusion": "本文的方法在从常识科学文本中提取和解释数量以及因果法则的任务中显示出比仅符号系统的管道显著更好的效果。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19997", "html_url": "https://arxiv.org/abs/2510.19997", "title": "FAIGMOE", "title_en": "A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE)", "authors": "Abraham Itzhak Weinberg", "background": "GenAI为组织带来了变革的机会，但中型企业与大型企业面临不同的采用挑战。中型企业面临资源限制和AI专业知识不足的问题，而大型企业则面临组织复杂性和协调挑战。现有技术采用框架（如TAM、TOE和DOI理论）缺乏在这些不同背景下实施GenAI的特定性，导致在采用文献中存在重要缺口。。", "innovation": "本文提出了FAIGMOE框架，旨在解决中型组织和大型企业中对于GenAI的特殊需求。FAIGMOE框架综合了技术采用理论、组织变革管理和创新扩散观点，分为四个互相关联的阶段：战略评估、使用案例开发、实施和集成以及运营化和完善。该框架还特别考虑了GenAI的具体问题，如提示工程、模型编排和幻觉管理。", "conclusion": "FAIGMOE提供了一个综合性的概念框架，专门针对中型和大型企业中GenAI的采用，提供了可操作的实施协议、评估工具和治理模板，未来需要实证研究进行验证。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20001", "html_url": "https://arxiv.org/abs/2510.20001", "title": "超越MedQA：在大语言模型时代迈向真实的临床决策", "title_en": "Beyond MedQA: Towards Real-world Clinical Decision Making in the Era of LLMs", "authors": "Yunpeng Xiao,Carl Yang,Mark Mai,Xiao Hu,Kai Shu", "background": "大规模语言模型（LLMs）在临床应用中展现出潜力，但现有的评估通常依赖于简化的问题-答案（QA）任务，如MedQA。然而，这些简化任务未能充分反映真实的临床决策过程。因此，本研究通过两个维度——临床背景和临床问题，提出了一种统一的框架来更好地量化临床决策任务的难度，并总结了现有数据集和基准在两个维度上的设置。此外，研究还回顾了应对临床决策的方法，包括训练时间和测试时间的技术，并总结了这些方法在何时有效。", "innovation": "研究提出了一种新的框架，即通过对临床背景和临床问题这两个维度的考量来更好地评估和改进大规模语言模型在临床决策中的应用。这个框架有助于明确假设、标准化比较，并指导开发具有临床意义的大规模语言模型。", "conclusion": "这项研究超越了MedQA，提出了一个更加全面和贴近实际临床环境的评判框架。通过这个框架，研究总结了现有的方法，并指出了未来开发临床应用的大规模语言模型仍需解决的一些开放性挑战。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19973", "html_url": "https://arxiv.org/abs/2510.19973", "title": "认知偏差在自主6G网络中代理AI驱动网络中的教程", "title_en": "A Tutorial on Cognitive Biases in Agentic AI-Driven 6G Autonomous Networks", "authors": "Hatim Chergui,Farhad Rezazadeh,Merouane Debbah,Christos Verikoukis", "background": "尽管关键性能指标（KPIs）在TM Forum等级1-3下实现了自动化收益，但它们仍然只是实现真正网络自主性所需的无缝连接、公平性、适应性和韧性这些本质的替代指标。为了实现真正的网络自主性，需要感知和推理网络环境，而代理AI通过大型语言模型（LLM）驱动的代理实现了这一目标，这些代理能够感知多模式遥测、记忆推理、跨领域谈判，并通过API实现多目标目标。然而，这带来了认知偏差的风险，这些偏差会影响推理、谈判、工具使用和执行的准确性。", "innovation": "本文通过提供认知偏差的教程，涵盖了从神经科学和AI的角度解析这些偏差的分类、定义、数学公式、在电信系统中的出现和受影响的代理组件类型，以及针对每类偏差提供的缓解策略。此外，该论文还介绍了两个实用案例，探讨了在6G跨切片和跨域管理中认知偏差出现、影响及缓解的实际应用场景，例如使用锚点随机化、时间衰减和拐点奖励等技术来解决锚定、时间确认等偏差，从而提高了决策质量并提升了能效等多方面收益。", "conclusion": "通过上述手段，决策更加依赖于丰富的过往经验，从而增强了代理AI协议的质量和勇气。在第二个案例中，例如展示了决策质量提高了5倍，节能提高了约40%。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20039", "html_url": "https://arxiv.org/abs/2510.20039", "title": "双向影响：多轮人类-大规模语言模型互动中的意见动态", "title_en": "Beyond One-Way Influence: Bidirectional Opinion Dynamics in Multi-Turn Human-LLM Interactions", "authors": "Yuyang Jiang,Longjie Guo,Yuchen Wu,Aylin Caliskan,Tanu Mitra,Hua Shen", "background": "论文讨论了使用大规模语言模型（LLM）驱动的聊天机器人进行意见探索的现象。尽管过往研究关注了LLM如何影响用户观点，但鲜有研究探讨用户输入如何反向影响LLM回复，以及这种双向影响如何体现在多轮对话中。", "innovation": "本文通过在五个争议话题讨论中（N=266参与者）设置三种条件下的多轮对话，研究了双向意见动态。研究显示，个人化的聊天机器人在双向影响中起到了放大作用，尤其是在对话中涉及个人故事时，参与者的立场和LLM的立场最有可能发生改变。", "conclusion": "研究强调了在人类-LLM互动中过度趋同的风险，并强调需要仔细设计个性化聊天机器人，以更好地、更稳定地与用户对齐。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20040", "html_url": "https://arxiv.org/abs/2510.20040", "title": "通过模仿学习近似模型预测控制实现微电网能源管理", "title_en": "Approximate Model Predictive Control for Microgrid Energy Management via Imitation Learning", "authors": "Changrui Liu,Shengling Shi,Anil Alan,Ganesh Kumar Venayagamoorthy,Bart De Schutter", "background": "随着可再生能源的不断集成，微电网的可靠且可持续运行越来越依赖于高效的能量管理。传统的混合整数经济模型预测控制（EMPC）方法虽然能提供精确的控制策略，但计算复杂且耗时，限制了其在实际应用中的使用。", "innovation": "本文提出了一种基于模仿学习的框架，用于近似混合整数经济模型预测控制（EMPC），以实现微电网能量管理。该方法通过训练神经网络来模仿专家EMPC控制的离线轨迹，从而实现快速的实时决策，无需在线求解优化问题。此外，通过在训练期间注入噪声以减少分布偏移，并明确纳入可再生能源发电和需求预测的不确定性，增强了方案的鲁棒性和泛化能力。", "conclusion": "仿真实验结果表明，所学策略在经济性能上与基于优化的EMPC相当，但计算时间仅为后者的10%。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20028", "html_url": "https://arxiv.org/abs/2510.20028", "title": "比特币交易的时间图", "title_en": "The Temporal Graph of Bitcoin Transactions", "authors": "Vahid Jalili", "background": "自2009年创世区块以来，比特币网络已经处理了超10亿笔交易，总额超过872亿比特币，为机器学习提供了丰富的数据资源。然而，比特币基于UTXO的匿名设计特性使得这些数据难以被机器学习研究者访问和利用。本文正是为了解决这个问题，在此背景之下，作者提出了一种机器学习兼容的图模型来重建比特币的资金流动，从而构建了一个包含完整交易历史的临时异构图。该图积累了超24亿个节点和397.2亿个边的数据，涵盖了直到某一特定区块高度的所有交易信息。这一历史性的数据集和工具包的开发，将有助于机器学习社区更深入地研究比特币复杂的生态系统，推动异常检测、地址分类、市场分析以及大规模图机器学习基准测试等应用的发展。", "innovation": "本文提出了一种机器学习兼容的图模型，通过重建比特币的资金流动，构建了一个时间异构图。该图包含了完整的交易历史，具有超过24亿个节点和397.2亿个边，覆盖到特定区块高度前的数据。此外，作者还提供了一种定制化的采样方法，生成节点和边特征向量，以及用于在专业图形数据库中加载和分析比特币数据的工具。该研究结果对于机器学习研究来说是一个巨大的突破，能够更深入地分析比特币生态系统内的复杂关系。", "conclusion": "本文提供的全面的数据集和工具包，将极大地推动机器学习社区对于比特币生态系统的深入研究，促进异常检测、地址分类、市场分析以及大规模图机器学习基准测试等应用的发展。该工具包和数据集的共享，使得研究人员能够更方便地进行相关研究，推动相关领域的技术进步。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20061", "html_url": "https://arxiv.org/abs/2510.20061", "title": "为您的国家做什么：迈向一种公共红队模式", "title_en": "Ask What Your Country Can Do For You: Towards a Public Red Teaming Model", "authors": "Wm. Matthew Kennedy,Cigdem Patlak,Jayraj Dave,Blake Chambers,Aayush Dhanotiya,Darshini Ramiah,Reva Schwartz,Jack Hagen,Akash Kundu,Mouni Pendharkar,Liam Baisley,Theodora Skeadas,Rumman Chowdhury", "background": "AI系统有潜力产生益处和危害，但如果没有严谨和持续的对抗性评估，AI领域的参与者将难以评估AI风险的广度和程度。来自系统设计领域的研究人员已开发出多种有效的方法来评估和红队测试AI，这些方法针对偏见、仇恨言论、虚假信息和已知的其他危害类别。然而，随着越来越复杂的AI系统被释放到高风险领域（如教育、医疗保健和情报收集），我们当前的评估和监控方法正在愈发无法提供有效的监督。因此，为了实现负责任的AI，并确保其危害得到充分的理解和减轻其安全漏洞，提出新的方法以填补“责任缺口”变得比以往任何时候都更加紧迫。", "innovation": "本文提出了一种新的方法——合作性的公共AI红队练习，旨在通过评估和缓解AI系统的潜在风险，填补责任缺口。该方法结合了CAMLIS（首个现场公共演示者练习）的首次实施，以及NIST的AI风险和影响评估（ARIA）试点项目和新加坡Infocomm Media Development Authority (IMDA)的类似练习的结果。", "conclusion": "我们认为此方法不仅能提供具有意义的结果，而且还能应用于多个AI开发的司法管辖区，体现出其可行性和可扩展性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20084", "html_url": "https://arxiv.org/abs/2510.20084", "title": "ShapeX：基于形状子的后验时间序列分类模型解释", "title_en": "ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models", "authors": "Bosong Huang,Ming Jin,Yuxuan Liang,Johan Barthelemy,Debo Cheng,Qingsong Wen,Chenghao Liu,Shirui Pan", "background": "在高风险应用领域，如医疗和金融中，时间序列分类模型的解释性至关重要，因为高透明度和信任度对模型的接受度至关重要。尽管多种时间序列分类技术已经识别出关键形状子（shapelets）作为关键特征，这些形状子对于达到顶级性能和验证其在分类结果中的核心作用至关重要，但现有的后验时间序列解释方法主要关注于每个时间步的特征归因，而忽视了分类结果主要由关键形状子驱动的基本前提。", "innovation": "ShapeX是一个创新的框架，将时间序列分割为有意义的形状子驱动片段，并利用Shapley值评估其重要性。其核心是Shapelet Describe-and-Detect (SDD)框架，该框架有效学习了对于分类至关重要的多样化形状子。此外，ShapeX可以揭示因果关系而不是仅揭示相关性，这是因为形状子的原子性特性。", "conclusion": "在合成和真实数据集上的实验结果表明，ShapeX在识别最具相关性的子序列方面优于现有方法，提高了时间序列解释的精确性和因果一致性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20002", "html_url": "https://arxiv.org/abs/2510.20002", "title": "FORGING GEMS: ADVANCING GREEK NLP THROUGH QUALITY-BASED CORPUS CURATION AND SPECIALIZED PRE-TRAINING", "title_en": "Forging GEMs: Advancing Greek NLP through Quality-Based Corpus Curation and Specialized Pre-training", "authors": "Alexandra Apostolopoulou,Konstantinos Kanaris,Athanasios Koursaris,Dimitris Tsakalidis,George Domalis,Ioannis E. Livieris", "background": "自然语言处理（NLP）的进步对于形态丰富但资源较少的语言（如现代希腊语）常常受到研究景域碎片化、架构多样性缺乏和短上下文长度模型依赖等因素的阻碍。特别是在法律这样的专业、高价值领域，现有模型大多局限于早期的变压器架构和512词的窗口限制，不适合分析长法律文件。", "innovation": "本文提出了一种新的变压器模型系列——希腊嵌入模型（Greek Embedding Models，GEM），基于广泛高质量数据的整理。该系列模型首次应用于希腊语，并详细描述了大规模希腊语语料库的构建，采用严格的质量筛选和预处理方法，为通用领域和法律专业源创建高质量的训练数据集。此外，文章还提出了首个多语言希腊语-英语嵌入模型，特别针对法律领域，通过大量下游任务的实验表明，GEM-RoBERTa和GEM-ConvBERT模型显著优于现有基线。", "conclusion": "新一类模型证明了本文提出方法的有效性，特别是在法律领域，新模型极大地提升了NLP任务的效果。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20093", "html_url": "https://arxiv.org/abs/2510.20093", "title": "StableSketcher:通过视觉问答反馈增强基于像素的素描生成的扩散模型", "title_en": "StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback", "authors": "Jiho Park,Sieun Choi,Jaeyoon Seo,Jihie Kim", "background": "尽管扩散模型在生成高质量图像方面取得了显著进展，但在合成基于像素的手绘素描方面仍存在挑战，特别是在抽象表达方面。StableSketcher提出了一种新的框架，该框架能够利用扩散模型生成具有高提示保真度的手绘素描。该框架通过微调变分自编码器来优化潜在编码和解码，使其更好地捕捉素描的特征。同时，引入了基于视觉问答的新奖励函数，以增强文本-图像对齐和语义一致性，从而克服现有数据集仅依赖图像标签对的局限性，实现更好的提示对齐效果。为了支持这一研究，作者还开发了名为SketchDUO的新数据集，这是第一个包含实例级别的素描配对描述和问题-答案对的数据集。", "innovation": "提出了StableSketcher框架，该框架通过微调变分自编码器和引入基于视觉问答的新奖励机制，改进了扩散模型在生成手绘素描方面的性能。StableSketcher能够生成具有更高风格保真度的素描，且与提示的对齐效果优于Stable Diffusion基线。此外，还开发了首个包含实例级素描配对描述和问题-答案对的数据集SketchDUO，解决了现有数据集的局限性。", "conclusion": "实验结果表明，StableSketcher生成的素描在风格保真度上有所提升，并且能更好地与提示对齐。为了支持这项研究，研究者计划在论文被接受后，公开其代码和数据集。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20091", "html_url": "https://arxiv.org/abs/2510.20091", "title": "CreativityPrism：大型语言模型创造力的全面基准", "title_en": "CreativityPrism: A Holistic Benchmark for Large Language Model Creativity", "authors": "Zhaoyi Joey Hou,Bowei Alvin Zhang,Yining Lu,Bhiman Kumar Baghel,Anneliese Brei,Ximing Lu,Meng Jiang,Faeze Brahman,Snigdha Chaturvedi,Haw-Shiuan Chang,Daniel Khashabi,Xiang Lorraine Li", "background": "虽然人们普遍认为创造力是人类智能的一个显著特征，但大型语言模型（LLMs）在生成创造性文本方面的能力日益受到关注。然而，目前还没有一套全面的框架来评估LLMs在各种场景中的创造力。现有的评估方法仍然很零碎，不同领域的定义和测量标准差异巨大。", "innovation": "本文提出了CreativityPrism框架，该框架将创造力分解为三个维度：质量、新颖性和多样性。CreativityPrism整合了九项任务、三个领域（发散思维、创造性写作和逻辑推理）和二十项评估指标，以特定且独特的方式衡量每个维度的表现。通过对17个最先进的（SoTA）专属和开源LLMs的评估，研究发现独家模型与开源模型之间存在显著差异。不同任务领域内的模型性能高度相关，而不同领域的相关性较低。多样性和质量指标之间的相关性较强，表现出色的模型往往在其他指标上也有出色表现。然而，新颖性与两者相关性较弱。这些发现支持了作者的假设，即某项创造力任务或维度的优异表现未必会迁移到其他任务或维度中，强调需要对LLM的创造力进行全面评估。", "conclusion": "整体而言，模型在相同领域内的不同任务之间的表现高度相关，而跨领域之间的相关性较低。在评价维度中，多样性和质量指标之间的相关性较强，表现出色的模型在这些指标上通常也表现优异。然而，新颖性的表现与其他两者之间相关性较弱。这些发现强调了全面评估LLM创造力的重要性，证实了创造力的不同维度并非单一固定的概念。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20129", "html_url": "https://arxiv.org/abs/2510.20129", "title": "SAID: 使大型语言模型具备自我激活内部防御的能力", "title_en": "SAID: Empowering Large Language Models with Self-Activating Internal Defense", "authors": "Yulong Chen,Yadong Liu,Jiawen Zhang,Mu Li,Chao Huang,Jie Wen", "background": "尽管在安全性对齐方面取得了进展，但大型语言模型（LLMs）依然容易受到绕过保护机制的越狱攻击。现有的防御策略依赖于外部干预，如输入过滤或输出修改，这些方法往往缺乏通用性，会降低模型的实用性，同时产生显著的计算开销。", "innovation": "本文提出了一种新的无需训练的防御范式——自我激活内部防御（SAID），它将防御任务从外部纠正转变为内部能力的激活。SAID 独特地利用了LLM的自身推理能力，通过三个阶段的流程：模型本源意图蒸馏以提取核心语义，最优安全前缀探測以激活潜在的安全意识，以及保守的聚合策略以确保稳健的决策，从而主动识别和中和恶意意图。广泛的实验表明，SAID 在减轻有害输出方面显著优于最先进的防御方法，同时保持了模型在良性任务上的性能，且计算开销最小。", "conclusion": "我们的研究证明，激活LLMs的内在安全机制是建立更安全、更可靠的对齐AI系统的更稳健和可扩展的道路。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20094", "html_url": "https://arxiv.org/abs/2510.20094", "title": "关于麦昆-佛劳斯方程站态解结构及其在噪声变换器中的应用", "title_en": "On the Structure of Stationary Solutions to McKean-Vlasov Equations with Applications to Noisy Transformers", "authors": "Krishnakumar Balasubramanian,Sayan Banerjee,Philippe Rigollet", "background": "本文研究了圆上的麦昆-佛劳斯方程的站态解。研究背景包含了对于这些方程解的深入分析，以理解其在不同条件下的行为特性。特别关注的是如何通过傅里叶系数建立一种新的无限维二次系统来精确描述这些方程的解，从而提供了站态解在序列空间而不是函数空间上的明确表述。这为进一步分析提供了新的视角，尤其是对于局部分支的解释，这些分支的形式和性质（超临界、临界、亚临界或跨越型）可以清晰地描绘出来。", "innovation": "研究的主要创新在于通过傅里叶系数建立了站态McKean-Vlasov方程与无限维二次系统的精确等价，从而能够在序列空间而非函数空间明确地描述站态解的形式。这种框架用于清晰描述局部分支的局部特性，包括周期性和共振结构，同时考虑奇异势。此外，研究还直接推导了表征多模分支的形式和特性的解析表达式，明确了连续相变和非连续相变的特点。", "conclusion": "在全局范围内，本文确立了自由能景观的正则性和凹性特征，证明了站态测度存在的唯一性、紧致性，并进一步将非连续相变与自由能最小值映射的非可微点联系起来。在噪声变换器应用方面，通过具体研究参数β的变化对无限多分支的几何形状和不稳定态的影响，显示了参数β增加时的富相行为，观察到连续向非连续（一级相变）行为的尖锐转变。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20154", "html_url": "https://arxiv.org/abs/2510.20154", "title": "大型语言模型在零样本立场检测中是否受到刻板印象的影响？", "title_en": "Are Stereotypes Leading LLMs' Zero-Shot Stance Detection ?", "authors": "Anthony Dubreuil,Antoine Gourru,Christine Largeron,Amine Trabelsi", "background": "大型语言模型在其预训练数据中继承了刻板印象，导致在许多自然语言处理任务中（如仇恨言论检测或情感分析）对某些社会群体表现出偏见行为。令人惊讶的是，这种类型的偏见在立场检测方法中的评估已被社区忽视。立场检测是指将陈述标记为针对、支持或对特定目标保持中立，这是最敏感的NLP任务之一，因为它通常与政治倾向相关。", "innovation": "该研究专注于大型语言模型在零样本设置中的立场检测偏差问题。研究人员自动为现有立场检测数据集中的帖子添加了两个属性：特定群体的方言或口头风格，以及文本复杂度/可读性，以调查这些属性是否影响模型的立场检测决策。研究结果显示，大型语言模型在立场检测任务中存在显著的刻板印象倾向。", "conclusion": "大型语言模型在零样本立场检测任务中表现出明显的刻板印象倾向，例如，错误地将支持大麻的观点与低复杂性文本和非洲裔美国人方言联系在一起，并将反对唐纳德·特朗普与这种观点联系起来。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20098", "html_url": "https://arxiv.org/abs/2510.20098", "title": "通过自适应路由和精准推理利用大型语言模型在实体链接中的力量", "title_en": "Leveraging the Power of Large Language Models in Entity Linking via Adaptive Routing and Targeted Reasoning", "authors": "Yajie Li,Albert Galimov,Mitra Datta Ganapaneni,Pujitha Thejaswi,De Meng,Priyanshu Kumar,Saloni Potdar", "background": "传统的实体链接（EL）依赖于大规模的标注数据集和广泛的模型微调。尽管最近的少样本方法利用大型语言模型（LLMs）通过提示来减少训练需求，但它们通常会因昂贵的LLM推理而效率低下。", "innovation": "ARTER提出了一种结构化流程，通过战略性结合候选生成、基于上下文的评分、适应性路由和选择性推理，无需深入微调就能达到高性能。ARTER通过计算从检索到的候选者获得的一小组互补信号（包括嵌入和LLM基础），将上下文提及分为易处理和难处理两类。这些案例分别由低计算实体链接器（如ReFinED）和更昂贵的基于LLM的目标化推理处理。ARTER在标准基准测试中比ReFinED高出了4.47%的表现，平均在5个数据集中提高了2.53%，并且在所有提及方面与使用基于LLM推理的流程表现相似，但效率是其两倍之高，减少了LLM令牌的数量。", "conclusion": "ARTER通过自适应路由和选择性推理，利用大型语言模型改善了实体链接性能，且在减少计算成本的同时提高了准确率。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20171", "html_url": "https://arxiv.org/abs/2510.20171", "title": "100k台以上GPU的集体通信", "title_en": "Collective Communication for 100k+ GPUs", "authors": "Min Si,Pavan Balaji,Yongzhou Chen,Ching-Hsiang Chu,Adi Gangidi,Saif Hasan,Subodh Iyengar,Dan Johnson,Bingzhe Liu,Jingliang Ren,Ashmitha Jeevaraj Shetty,Greg Steinbrecher,Xinfeng Xie,Yulun Wang,Bruce Wu,Jingyi Yang,Mingran Yang,Minlan Yu,Cen Zhao,Wes Bland,Denis Boyda,Suman Gumudavelli,Cristian Lumezanu,Rui Miao,Zhe Qu,Venkat Ramesh,Maxim Samoylov,Jan Seidel,Feng Tian,Qiye Tan,Shuqiang Zhang,Yimeng Zhao,Shengbao Zheng,Art Zhu,Hongyi Zeng", "background": "随着大型语言模型（LLMs）规模的不断扩大，对于高效集体通信框架的需求也随之增加，尤其是在GPU数量达到数十万台时进行模型训练的工作负载。传统通信方法在大尺度下存在吞吐量和延迟的限制，这阻碍了先进模型的开发和部署。", "innovation": "本文介绍了来自Meta公司的NCCLX集体通信框架。该框架旨在优化从大规模训练到推理的整个LLM生命周期中的性能。NCCLX框架支持超过10万台GPU的复杂工作负载，确保了高吞吐量和低延迟的数据交换。实验证明NCCLX在Llama4模型上的通信效率有显著提升。", "conclusion": "本文的研究为下一代表现规模超出以往的传统框架提供了一个稳健的解决方案，使LLMs能够高效地运行在前所未有的规模上。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20165", "html_url": "https://arxiv.org/abs/2510.20165", "title": "IB-GAN: 使用信息瓶颈生成对抗网络的解缠表示学习", "title_en": "IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks", "authors": "Insu Jeon,Wonkwang Lee,Myeongjang Pyeon,Gunhee Kim", "background": "该研究提出了一种基于生成对抗网络（GAN）的解缠表示学习的无监督模型。研究人员试图将信息瓶颈（IB）框架应用于GAN的优化，提出了一种名为IB-GAN的新模型。该模型在一定程度上类似于InfoGAN，但在中间层的生成器中引入了生成输入与生成输出之间互信息的约束。这种设计使得生成器能够以解缠和可解释的方式利用潜在空间。", "innovation": "IB-GAN模型在生成对抗网络的基础上引入了信息瓶颈（IB）框架，通过中间层的生成器来约束输入与生成输出之间的互信息，从而使得生成器能够解缠地利用潜在空间；该模型在生成样本的视觉质量和多样性方面取得了优异的表现，尤其是在CelebA和3D Chairs数据集上的FID分数上优于\\(\\eta\\)-VAE和InfoGAN。", "conclusion": "IB-GAN在dSprites和Color-dSprites数据集上的实验表明，其解缠分数与当前最先进的\\(\\eta\\)-VAEs相当，并且在CelebA和3D Chairs数据集上的生成样本质量和多样性也优于\\(\\eta\\)-VAEs和InfoGAN。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20020", "html_url": "https://arxiv.org/abs/2510.20020", "title": "优化线性社会选择中的失真", "title_en": "Optimized Distortion in Linear Social Choice", "authors": "Luise Ge,Gregory Kehne,Yevgeniy Vorobeychik", "background": "社会选择理论提供了许多依据选民汇报的偏好排名来选择候选人的方法。然而，当选民有具体的偏好效用时，仅仅使用偏好排名可能会导致从最佳社会福利角度看的次优结果。失真是一种衡量这种次优性的度量，它提供了一种在效用结构非常有限时开发和分析投票规则的方法。然而，在许多情况下（例如，价值对齐的常见范式），替代方案允许向量表示，假设效用是这些向量表示的参数函数。本文首次研究线性效用函数下的失真，具体探讨了线性社会选择中确定性和随机投票规则的失真。我们获得了仅依赖候选者嵌入维度的失真边界，并与候选者和选票的数量无关。此外，我们还引入了多项式时间的实例最优算法，用于在给定候选者集合和投票后最小化失真。我们在两个真实世界领域进行了实证评估：使用协同过滤嵌入的推荐系统和使用语言模型嵌入的意见调查，将我们的实例最优算法与多种标准规则进行了对比评价。", "innovation": "本文首次研究了线性效用函数下的失真问题，探讨了线性社会选择中确定性和随机投票规则的失真，并提供了与候选者和选票数量无关的失真边界。此外，引入了多项式时间的实例最优算法，以最小化给定候选者和投票后的失真。并进行了实证研究，比较了我们的算法与其他标准规则的表现。这为优化在线性社会选择中的失真提供了新的视角和方法。", "conclusion": "本文通过研究线性效用函数下的失真，提出了新的失真边界和多项式时间的实例最优算法，这些结果有助于优化现实世界中的推荐系统和意见调查中的社会选择过程，提高了社会选择结果的效用性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20176", "html_url": "https://arxiv.org/abs/2510.20176", "title": "Mixture-of-Minds: 多智能体强化学习方法的表格理解", "title_en": "Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding", "authors": "Yuhang Zhou,Mingrui Zhang,Ke Li,Mingyi Wang,Qiao Liu,Qifei wang,Jiayi Liu,Fei Liu,Serena Li,Weiwi Li,Mingze Gao,Abhishek Kumar,Xiangjun Fan,Zhuokai Zhao,Lizhu Zhang", "background": "表格推理和理解是许多实际应用中的关键能力。虽然大型语言模型（LLMs）在这方面显示出一定的潜力，但现有方法仍然存在局限性。基于微调的方法增强了语言推理，但容易出现计算错误和虚构事实；而工具基础的方法则能精确处理表格，但缺乏语义理解，依赖严格模式。这些互补的缺点表明，需要结合稳健推理与可靠的表格处理的方法。", "innovation": "该论文提出了Mixture-of-Minds，这是一种多智能体框架，将表格推理分解为三个专门的角色：规划、编码和回答。该设计使每个智能体能够专注于任务的特定方面，同时利用代码执行进行精确的表格操作。通过这一工作流程，引入了一个自我提升训练框架，利用蒙特卡洛树搜索（MCTS）实现场景生成伪金数据轨迹，并通过强化学习（RL）优化智能体。", "conclusion": "广泛的实验表明，Mixture-of-Minds在TableBench上取得了显著的进步，达到了62.13%的得分，并超越了OpenAI-o4-mini-high。这些结果证明了结合结构化多智能体工作流程与强化学习促进表格理解的潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20198", "html_url": "https://arxiv.org/abs/2510.20198", "title": "被困在矩阵中：探究大型语言模型的空间推理能力", "title_en": "Stuck in the Matrix: Probing Spatial Reasoning in Large Language Models", "authors": "Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum", "background": "本研究通过一系列五项任务考察大型语言模型（LLMs）在文本输入基础上的空间推理能力及计算能力。这些任务涵盖了基本的空间推理以及在结构化网格环境中的多步问题解决，如象限识别、几何变换、距离评估、词搜索和地板瓷砖滑动等。", "innovation": "这些任务的复杂性通过逐渐增加网格大小进行扩展，要求模型超越简单的模式识别，进入抽象的空间推理。实验结果显示，对于简单复杂度和规模，LLMs表现出中度的成功，但随着规模的扩大，性能迅速下降，平均精确度损失42.7%，最高达84%。所有初始精确度超过50%的测试都显示出至少48%的损失，表明这种下降趋势是普遍存在的。此外，其在扩展复杂性方面的困难表明其底层架构可能缺乏稳健的空间表示。", "conclusion": "本研究强调了语言理解和空间推理之间的差距，对LLMs的当前局限性提供了见解，并为语言和几何学的结合未来的综合基准奠定了基础。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20218", "html_url": "https://arxiv.org/abs/2510.20218", "title": "可用于可解释多智能体 Q 学习的高阶互动建模", "title_en": "High-order Interactions Modeling for Interpretable Multi-Agent Q-Learning", "authors": "Qinyu Xu,Yuanyang Zhu,Xuefei Wu,Chunlin Chen", "background": "在多智能体强化学习（MARL）中，有效建模智能体之间的互动对于实现有效的协调和理解其合作机制至关重要。然而，之前的高阶互动建模努力主要受到组合爆炸或其黑盒网络结构不透明性的阻碍。", "innovation": "本文提出了一种新的值分解框架——连续分数 Q 学习（QCoFr），可以以线性复杂度 $\textit{O}(n)$ 灵活捕捉任意阶智能体互动，从而避免在建模丰富合作时出现组合爆炸。此外，引入了变分信息瓶颈来提取潜在信息以估算奖励。潜在信息有助于智能体过滤掉噪声互动，从而显著提高合作性和解释性。", "conclusion": "广泛的实验证明，QCoFr 不仅能够持续取得更好的性能，还提供了与理论分析一致的解释性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20178", "html_url": "https://arxiv.org/abs/2510.20178", "title": "PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching", "title_en": "PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching", "authors": "Yun Wang,Junjie Hu,Qiaole Dong,Yongjian Zhang,Yanwei Fu,Tin Lun Lam,Dapeng Wu", "background": "从立体视频中估计时间上一致的深度对于增强现实等实际应用至关重要，因为不一致的深度估计会破坏用户的沉浸感。尽管这一任务非常重要，但如何在计算高效的前提下建模长期的时间一致性仍然是一个挑战。之前的许多方法试图通过聚合时空信息来解决这个问题，但这些方法面临一个根本性的权衡：有限的时间建模只能带来小幅提升，而捕捉长距离依赖关系又会导致计算成本大幅增加。针对这一限制，提出了一个记忆缓冲区来建模时空一致性，同时实现动态立体配准的高效率。", "innovation": "本文引入了Pick-and-Play Memory (PPM) 构建模块，这种模块通过两阶段过程来提高时空一致性的建模效率和准确性。第一阶段是'pick'过程，该过程找出最相关的帧，第二阶段是'play'过程，该过程适应性加权所选帧来进行时空聚合。这种两阶段协作过程足以为动态立体配准维护一个紧凑且高度信息性的记忆缓冲区。实验结果表明，PPMStereo在准确性和时间一致性方面均表现出色，尤其在计算成本更低的情况下实现了0.62/1.11 TEPE的表现，优于BiDAStereo，分别提高了17.3%和9.02%。", "conclusion": "PPMStereo在时空一致的动态立体配准方面表现出显著的效果，特别是在降低计算成本的同时提高了性能。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20211", "html_url": "https://arxiv.org/abs/2510.20211", "title": "利用AI代理自动处理IaC配置漂移", "title_en": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "authors": "Zhenning Yang,Hui Guan,Victor Nicolet,Brandon Paulsen,Joey Dodds,Daniel Kroening,Ang Chen", "background": "传统的云基础设施管理工具，如云控制台、命令行接口（CLI）和SDK，已经被广泛使用。然而，随着Infrastructure-as-Code/IaC框架（如Terraform）的流行，IaC配置与实际基础设施之间的不一致问题也日益显现。当IaC与其他管理工具（如控制台、CLI或SDK）结合使用时，可能会失去对外部变化的可见性，导致基础设施漂移，使得IaC操作失效或引发错误。", "innovation": "提出了一种名为NSync的自动化系统，用于修复IaC配置漂移。NSync通过分析API调用日志，检测并调整非IaC变化，确保IaC配置与实际基础设施的一致性。该系统利用了自学习架构和LLM推理技术，能够从杂乱的API序列中推断高阶意图，生成精确的IaC更新，同时不断优化其知识库以提高性能。此外，还设计了一个新的测试框架，用于注入真实的配置漂移情况并评估NSync的性能。实验结果表明，NSync在准确性（从0.71提高到0.97）和效率（提高1.47倍）方面优于基准系统。", "conclusion": "NSync通过自动化API调用日志的分析，有效解决了由IaC和外部云管理工具结合使用引起的基础设施漂移问题。该系统不仅在准确性上有所提升，还展示了更高的资源利用效率，展现了自动修复IaC配置漂移的潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20209", "html_url": "https://arxiv.org/abs/2510.20209", "title": "利用常规实验室数据评估早期癌症检测可行性：不平衡数据集上的机器学习方法评价", "title_en": "Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset", "authors": "Shumin Li", "background": "在兽医领域，开发易于获取的早期癌症筛查工具面临重大挑战。常规实验室数据提供了一种低成本但潜在有效的筛查途径，但由于单一生物标志物的非特异性及筛查样本中的严重类别不平衡问题，其应用受到限制。", "innovation": "本研究通过金毛寻回犬长期研究（GRLS）队列，评估了在实际条件下利用机器学习方法进行癌症风险分类的可行性。研究对126种不同的分析管道进行了基准测试，包括各种机器学习模型、特征选择方法及数据平衡技术，并实现了在患者级别对数据的分割以防止泄露。研究发现最佳模型在统计上可检测癌症信号，但临床分类性能不足。", "conclusion": "常规实验室数据中确实存在可检测的癌症信号，但因其强度较弱且与其他炎症性疾病混淆，难以用于可靠的临床鉴别诊断。该研究为单一数据模态建立了关键性能上限，并强调了多模态数据集成在计算兽医肿瘤学中的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20225", "html_url": "https://arxiv.org/abs/2510.20225", "title": "通过元变分丢弃进行联邦学习", "title_en": "Federated Learning via Meta-Variational Dropout", "authors": "Insu Jeon,Minui Hong,Junhyeog Yun,Gunhee Kim", "background": "联邦学习（FL）旨在通过远程分布式客户端训练全局推理模型，由于其提高数据隐私的优点而受到关注。然而，传统的FL在实际应用中往往面临诸如模型过拟合并导致局部模型发散等挑战，这主要是由于客户端之间受限且非同分布（non-IID）的数据问题。", "innovation": "提出了一个新颖的元贝叶斯学习方法叫元变分丢弃（MetaVD）。MetaVD通过共享的超网络学习预测客户端相关的丢弃率，从而能够在受限且非同分布数据场景下有效个性化FL算法模型。另外，通过条件丢弃后验的研究，强调了元学习的后验调整观点和贝叶斯联邦学习的后验聚合观点。", "conclusion": "MetaVD在各种稀疏和非同分布FL数据集上进行了广泛的实验，展示了优秀的分类准确性和不确定性校准性能，特别是对于异分布（OOD）客户。MetaVD通过压缩每个客户端所需的部分本地模型参数，减轻了模型的过拟合并降低了通信成本。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20229", "html_url": "https://arxiv.org/abs/2510.20229", "title": "为何大型视觉语言模型在较长响应中更易产生妄想：背景的作用", "title_en": "Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context", "authors": "Ge Zheng,Jiaye Qian,Jiajin Tang,Sibei Yang", "background": "近年来，大型视觉语言模型（LVLMs）取得了显著进展，但也容易出现妄想问题。较长、自由形式的响应中更为常见这些妄想现象，通常归因于累积的不确定性。本文探讨的是妄想是否仅由长度引起的错误导致，或是存在更深层次的机制。研究表明，妄想风险并非由长度本身引起，而是与更依赖于上下文以维持较长响应的连贯性和完整性有关。", "innovation": "本文提出了一种新颖的“诱导-检测-抑制”框架，通过故意设计的上下文主动诱导妄想，利用诱导的实例早期检测高风险案例，并最终在实际解码中抑制潜在的对象级妄想。这种方法在所有基准测试中都表现出一致性且显著的改进，证明了该框架的有效性。强大的检测能力和妄想减轻不仅验证了框架，更重要的是重新验证了上下文的作用。", "conclusion": "本文不仅验证了我们的框架，更重要的是对LVLMs在较长响应中的妄想现象重新验证了我们的假设。我们的研究不是单纯追求性能提升，而是希望能够提供新的见解，并作为深入探索LVLMs中较长响应妄想现象的第一步。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20221", "html_url": "https://arxiv.org/abs/2510.20221", "title": "FinCARE: 财务因果分析中的推理与证据", "title_en": "FinCARE: Financial Causal Analysis with Reasoning and Evidence", "authors": "Alejandro Michel,Abhinav Arun,Bhaskarjit Sarmah,Stefano Pasquali", "background": "投资组合经理依赖于基于相关性的分析方法和启发式方法，这些方法无法捕捉到真正驱动业绩的因果关系。现有的因果发现算法同样存在这一局限性。研究结果表明，当前的统计因果发现算法如约束式（PC）、评分式（GES）和连续优化（NOTEARS）在模拟的500家企业数据集上的表现不如预期，且存在提升空间。因此，需要开发能够系统地增强这些算法的方法，以更准确地识别财务领域中的因果关系，从而为风险管理和决策提供支持。", "innovation": "本文提出了一种结合统计因果发现算法和从SEC 10-K报表提取的财务知识图谱以及大型语言模型推理的混合框架。该方法通过算法编码知识图谱约束，并利用LLM的概念推理来进行假设生成，系统地增强了约束式（PC）、评分式（GES）和连续优化（NOTEARS）三种代表性的因果发现范式。实验结果表明，增强后的方法在三个领域的表现显著提升：PC算法的F1分数提高了36%，GES算法提高了100%，NOTEARS算法提高了366%。此外，该框架还能提供可靠的场景分析，进行反事实预测的平均绝对误差为0.003610，干预效果方向准确率为100%。这些进步有效解决了现有方法存在的局限，将统计发现与金融专业知识相结合，为投资组合经理提供了一个基于因果关系的风险管理和决策支持框架。", "conclusion": "本研究提出的混合框架通过整合新兴技术，显著提升了因果发现算法的性能，并提供了更有效的方法来评估潜在情景和市场干预效果，为投资组合管理者提供了必要的因果推理基础，在动态市场环境中进行前瞻性的风险管理与战略决策。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20222", "html_url": "https://arxiv.org/abs/2510.20222", "title": "QKCV 注意力机制：通过静态分类嵌入增强时间序列预测，适用于轻量级和预训练基础模型", "title_en": "QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models", "authors": "Hao Wang,Baojun Ma", "background": "在实际时间序列预测任务中，类别信息对于捕捉内在数据模式至关重要。传统的QKV框架在处理这个问题时有所不足，无法有效强调类别特定的信息。本文介绍了一种名为QKCV（Query-Key-Category-Value）的注意机制，它是对传统QKV框架的扩展，加入了静态的类别嵌入C，以突出类别特定的信息。这种机制是一种多功能的插件模块，可以增强基于注意力的时间序列预测模型（如纯粹的Transformer、Informer、PatchTST、TFT）的预测准确性，适用于各种实际数据集。此外，QKCV在微调单一时间序列基础模型时展示了显著的适应性，仅通过更新静态嵌入C就能实现预训练权重的保持，从而减少计算开销并获得更好的微调性能。", "innovation": "提出了QKCV（Query-Key-Category-Value）注意力机制，这是对传统QKV框架的扩展，加入了静态的类别嵌入C以突出类别特定的信息。QKCV作为一种多功能插件模块，能够提升基于注意力的时间序列预测模型（如Vanilla Transformer、Informer、PatchTST、TFT）的预测准确性。进一步的是，QKCV在微调单一时间序列基础模型时展示了显著的适应性，只需更新静态嵌入C，即可保持预训练权重，从而减少计算开销并实现更优的微调性能。", "conclusion": "QKCV注意力机制通过引入静态类别嵌入C来增强时间序列预测模型，提高预测准确性，并展示了在维护预训练权重的同时，有效减少计算开销并实现更好的微调性能的能力。这种机制对于广泛的实时序列数据集和轻量级模型特别有效。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20235", "html_url": "https://arxiv.org/abs/2510.20235", "title": "最大最小准则多目标强化学习：博弈理论方法", "title_en": "Multi-Objective Reinforcement Learning with Max-Min Criterion: A Game-Theoretic Approach", "authors": "Woohyeon Byeon,Giseung Park,Jongseong Chae,Amir Leshem,Youngchul Sung", "background": "本文的研究背景是多目标强化学习（MORL）问题，其中目标之间可能存在冲突。传统的强化学习方法通常仅考虑单一目标，但现实世界的许多决策过程需要同时优化多个目标。现有的MORL方法在处理多目标问题时可能存在收敛性问题或计算复杂度高。本文尝试通过引入博弈论视角，提出一种新的框架，以解决这些问题。", "innovation": "本文的创新点在于：1. 将多目标强化学习问题重新表述为博弈论中的两玩家零和调节连续博弈；2. 提出基于镜像下降法的有效算法，简化了策略更新过程，确保全局最后迭代收敛；3. 提供了算法的全面理论分析，包括精确和近似策略评估的迭代复杂度以及样本复杂度界；4. 通过自适应调节改进了提出的算法，进一步提升了性能。", "conclusion": "实验结果表明，该算法在表征环境中的收敛行为良好，并且在多目标强化学习环境中的实现显著优于之前的基线方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20280", "html_url": "https://arxiv.org/abs/2510.20280", "title": "通过学习预测上下文嵌入进行上下文级语言建模", "title_en": "Context-level Language Modeling by Learning Predictive Context Embeddings", "authors": "Beiya Dai,Yuliang Liu,Daozheng Xue,Qipeng Guo,Kai Chen,Xinbing Wang", "background": "Next-token prediction (NTP) 是现代大型语言模型 (LLMs) 预训练的基石，推动了它们在文本生成、推理和指令执行方面的空前能力。然而，基于标记级别的预测限制了模型捕捉更高层次语义结构和长期上下文关系的能力。", "innovation": "我们提出了 ContextLM 框架，通过增加内在的“下文预测”目标，使标准预训练在保持与标准自回归、逐标记评估范式（例如困惑度）兼容的同时，实现了模型对多标记上下文的预测表示能力的提升。广泛的实验表明，ContextLM 在困惑度和下游任务性能上提供了持续的改进。", "conclusion": "我们的分析表明，通过预测上下文提供了扩展和高效的通往更强大的语言建模途径，具有更好的长期一致性和更有效的注意资源分配，同时保持了最小的计算开销。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20242", "html_url": "https://arxiv.org/abs/2510.20242", "title": "构建高性能选择性分类器需要什么？", "title_en": "What Does It Take to Build a Performant Selective Classifier?", "authors": "Stephan Rabanser,Nicolas Papernot", "background": "选择性分类器通过在模型判断输入不确定时放弃模型的预测来提高模型的可靠性。然而，现有的实用方法很少能达到完美排序器的黄金标准性能，即按正确性顺序接受示例。作者将这一缺失部分定义为选择性分类的间隙，并首次提出了五种不同类型的间隙来源的有限样本分解：贝叶斯噪声、近似误差、排名误差、统计噪声以及由于实施或转移引起的宽松度。", "innovation": "作者分析了单调后校准对减少差距的有限影响，指出它很少改变模型的得分排名，因此需要得分机制能够有效重新排列预测而不是仅仅重新缩放。通过合成的两月亮数据和实际的视觉和语言基准测试，作者验证了他们的分解方法，并通过受控实验分离了每个错误组件。结果表明，贝叶斯噪声和模型容量有限可以解释很大一部分差距，只有更丰富、特征感知的校准器能显著改进得分排序；数据转移引入了一个额外的宽松度，需要分布鲁棒训练。", "conclusion": "作者的推理结果提供了一个定量的误差预算以及实际的指导方针，使实践者能够构建更接近理想排序器行为的选择性分类器。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20239", "html_url": "https://arxiv.org/abs/2510.20239", "title": "跨模态严重性融合诊断跨越抑郁症和创伤后应激障碍", "title_en": "Tri-Modal Severity Fused Diagnosis across Depression and Post-traumatic Stress Disorders", "authors": "Filippo Cenacchi,Deborah Richards,Longbing Cao", "background": "抑郁症和创伤后应激障碍常常同时出现并伴有相关症状，这使得自动化评估变得复杂，而当前的自动化评估往往是二元的且专注于特定的障碍。临床上有用的诊断需要基于严重程度的跨障碍估算和决策支持解释。因此，本文提出了一种统一三模态情感严重度框架，融合了访谈文本、音频和面部信号，以提供抑郁症和创伤后应激障碍的分级严重度评估。", "innovation": "本文介绍了一种三模态情感融合方法，该方法通过将访谈文本、音频、面部信号分别与句子级变换器嵌入、梅尔对数统计、动作单元、凝视、头部和姿势描述符同步和融合，输出两种障碍的分级严重度。这种方法在针对多障碍同时评估抑郁症和创伤后应激障碍方面进行了展示，Stratified交叉验证结果显示，在DAIC数据集上，融合模型优于单一模态或去除某些模态的基线模型。", "conclusion": "融合模型在重度和加权F1得分上与最强的单一模态基线模型相当，但在决策曲线实用性以及在噪声或缺失模态下的鲁棒性方面表现更好。特定应用于创伤后应激障碍时，融合可以减少回归误差，提高类一致性，错误集中在相邻严重度之间，极端类别可以可靠地被识别。消除研究显示，文本对抑郁症严重程度的贡献最大，而音频和面部提示对于创伤后应激障碍至关重要，归因分析与语言和行为标志符一致。本文提供了一种可重复的评估方法，并提供了一种在临床决策中的融合支持，让临床医生参与决策过程。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20272", "html_url": "https://arxiv.org/abs/2510.20272", "title": "PRM引导的树搜索在大型语言模型进行数学推理中的局限性", "title_en": "Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs", "authors": "Tristan Cinquin,Geoff Pleiss,Agustinus Kristiadi", "background": "尽管在大型语言模型（LLMs）中使用Best-of-N（BoN）选择的链式思考提示已经成为数学推理的流行方法，但由于其线性结构无法捕捉复杂问题解决过程中的分支和探索性，因此这种方法存在局限性。作者通过研究提出，通过最大化过程奖励模型（PRM）分数来实现不可解的动作空间的自适应算法，并探讨PRM引导的树搜索是否能够通过探索多种部分解决方案路径来提升数学推理能力。", "innovation": "作者提出了一个自适应算法，以最大化PRM分数来搜索不可解的动作空间，并将PRM引导的树搜索方法与BoN进行比较。此外，研究发现蒙特卡洛树搜索和束搜索方法优于其他PRM引导的搜索方法，这表明可能需要改进奖励建模方法才能有效增强LLMs的数学推理能力。", "conclusion": "实验证明，PRM引导的树搜索方法在数学推理中表现不佳，不仅费时，而且已有的PRM在模型深度增加时对状态值的近似不准确，导致泛化能力差。使用不可靠的PRM分数来进行树搜索是其表现不佳的根本原因，这表明需要更好的奖励建模方法才能让树搜索在大型语言模型中有效提升数学推理能力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20287", "html_url": "https://arxiv.org/abs/2510.20287", "title": "在生成式人工智能时代进行霹雳舞视频分类", "title_en": "Breakdance Video classification in the age of Generative AI", "authors": "Sauptik Dhar,Naveen Ramakrishnan,Michelle Munson", "background": "近年来，大型视觉语言模型在体育领域的应用取得了重大进展，尤其在足球、板球、篮球等主要运动类别中得到广泛应用。这些工作主要集中在生成任务，如视觉问答和精彩片段生成。本文聚焦于一项非常特别但极受欢迎的运动——霹雳舞，并分析现代视频基础模型（包括编码器和解码器）在霹雳舞视频分类中的应用。", "innovation": "本文分析了在生成式人工智能时代，现代视频编码器模型和解码器模型在霹雳舞视频分类任务中的效果。结果表明，视频编码器模型继续在预测任务上优于最先进的视频语言模型。此外，本文还为如何选择编码器模型提供了见解，并对微调后的解码器模型在霹雳舞视频分类中的工作原理进行了深入分析。", "conclusion": "研究表明，视频编码器模型在霹雳舞视频分类任务上仍然表现出色。本文为选择合适的编码器模型提供了建议，并对微调后的解码器模型的工作原理进行了全面分析。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20255", "html_url": "https://arxiv.org/abs/2510.20255", "title": "在高等教育中朝着用于课程教学的AI代理方向：从现场早早的体验", "title_en": "Towards AI Agents for Course Instruction in Higher Education: Early Experiences from the Field", "authors": "Yogesh Simmhan,Varad Kulkarni", "background": "本文介绍了在印度化学研究所(IISc)的一门研究生级云计算课程中部署基于AI的教学代理的初步发现。该代理被设计为主要的授课教师，结合人类教师的辅助，进行课程结构设计和问答环节。该研究提出了一种分析框架，通过可解释的参与度指标（如主题覆盖、主题深度和轮次详细程度）来评估代理与学生的互动记录。研究人员报告了学生如何与代理互动以探索概念、澄清疑惑和维持探究性对话的早期经验，并且分析了两次连续教学模块的应用展示了参与度模式的变化，从广泛的概念探索转向深入、集中的探究。这些结果表明，有组织地集成对话型AI代理可以促进反思式学习，提供在真实课堂环境中研究参与度的可重复方法，并支持规模化的高质量高等教育。", "innovation": "1. 设计了一个大型语言模型（LLM）驱动的教师代理，并将其作为主要的授课教师集成到课程工作流中，以进行概念交付。\n2. 引入了一种教学框架，结合人类教师，提供课程结构和进行问答环节。\n3. 提出了一种分析框架，使用可解释的参与度指标来评估代理与学生的互动记录。\n4. 报告了早期经验与初步分析，展示了参与度模式从广泛的概念探索向深入、集中的探究转变的过程。", "conclusion": "结构化集成对话型AI代理能够促进反思性学习，并提供研究真实课堂环境中学生参与度的方法，同时支持大规模、高质量的高等教育。通过GPT代理在研究生云计算课程中的应用，研究揭示了AI代理与学生互动和参与度变化的模式，为未来研究提供了有价值的见解。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20291", "html_url": "https://arxiv.org/abs/2510.20291", "title": "一种参数高效的跨模态专家体系结构在地理定位中的应用", "title_en": "A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization", "authors": "LinFeng Li,Jian Zhao,Zepeng Yang,Yuhang Song,Bojun Lin,Tianle Zhang,Yuchen Yuan,Chi Zhang,Xuelong Li", "background": "该任务要求从多平台（卫星/无人机/地面）的大数据集中，根据自然语言查询获取最具相关性的地理参考图像。主要挑战包括跨平台异构性和通用训练描述与特定平台测试查询之间的领域差距。", "innovation": "提出了一种参数高效的专家混合体系结构（Mixture-of-Experts，MoE），通过平台分割、卫星增强和去除方向词语等手段，结合基于LLM的文本描述精炼流程，实现跨模态文本和视觉特征的一致。使用BGE-M3（文本）和EVA-CLIP（图像）进行平台专家的训练，采用逐阶段硬负样本挖掘策略，提升区分能力。在推理时将多个平台专家的评分融合，成功实现了跨视角的稳健地理定位。", "conclusion": "该系统在官方排行榜上名列前茅，证明了其在异构视角下的跨模态地理定位能力的可靠性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20286", "html_url": "https://arxiv.org/abs/2510.20286", "title": "UI-Ins: 使用多视角指令推理提升UI界面接地", "title_en": "UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning", "authors": "Liangyu Chen,Hanzhang Zhou,Chenglin Cai,Jianan Zhang,Panrong Tong,Quyu Kong,Xu Zhang,Chen Liu,Yuqi Liu,Wenxuan Wang,Yue Wang,Qin Jin,Steven Hoi", "background": "GUI接地将自然语言指令映射到可操作的UI元素，是GUI代理的核心能力。先前的工作大多将指令视为用户意图的静态代理，忽视了指令多样性和质量对面接地性能的影响。通过仔细调查现有的接地数据集，研究发现其中23.3%的指令存在缺陷，并展示了利用推理时的指令多样性可以实现高达76%的相对性能改进。", "innovation": "引入了指令作为推理的范式，将指令视为动态的分析路径，提供不同的视角，并使模型在推理过程中选择最有效的路径。为此，提出了一种两阶段训练框架：监督微调（SFT）以生成多样化的指令来培养多视角推理能力，以及随后的强化学习（RL）来优化路径选择和组合。最后研发的模型（UI-Ins-7B 和 UI-Ins-32B）在五个挑战性的接地基准测试中达到了最先进的结果，并展示了新兴的推理能力，在推理过程中选动生成和合成新的指令路径。特别是在使用UI-Ins-7B作为执行器时，在AndroidWorld中实现了74.1%的成功率。", "conclusion": "研究表明，推理可以被形式化为增强而不是妨碍接地性能的方式，同时我们的方法在SFT+RL框架中提高了策略的稳定性。所有代码和模型检查点将在指定的链接中公开。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20296", "html_url": "https://arxiv.org/abs/2510.20296", "title": "RAG-Stack：从向量数据库视角共优化RAG的质量和性能", "title_en": "RAG-Stack: Co-Optimizing RAG Quality and Performance From the Vector Database Perspective", "authors": "Wenqi Jiang", "background": "检索增强生成（RAG）已成为矢量数据库最具代表性的应用之一。通过将从数据库中检索来的文档整合到大型语言模型的提示中，RAG能够生成更可靠和信息丰富的内容。尽管广泛研究了矢量数据库，但在整个端到端RAG管道的背景下，仍有许多开放的研究问题。其中一个兼具实践挑战的问题是如何在RAG中共同优化系统性能和生成质量，这比表面上看起来要复杂得多，因为涉及到算法层面（涵盖模型和数据库）和系统层面（从软件到硬件）的众多调节旋钮。", "innovation": "本文提出了RAG-Stack，这是一种三支柱蓝图，用于RAG系统的质量-性能共同优化。RAG-Stack包括：（1）RAG-IR，一种中间表示，用作抽象层，以解耦质量和性能方面；（2）RAG-CM，一种成本模型，用于根据RAG-IR估计系统性能；（3）RAG-PE，一种计划探索算法，用于搜索高质量和高性能的RAG配置。", "conclusion": "我们相信这种三支柱蓝图将成为未来RAG质量-性能共同优化的默认范式。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20314", "html_url": "https://arxiv.org/abs/2510.20314", "title": "增强深度强化学习安全性：对抗攻击与防御的全面综述", "title_en": "Enhancing Security in Deep Reinforcement Learning: A Comprehensive Survey on Adversarial Attacks and Defenses", "authors": "Wu Yichao,Wang Yirui,Ding Panpan,Wang Hailong,Zhu Bingqian,Liu Chun", "background": "随着深度强化学习（DRL）技术在自动驾驶、智能制造和智能医疗等复杂领域的广泛应用，如何在动态和变化的环境中提高其安全性和鲁棒性成为当前研究的核心问题。特别地，在面对对抗攻击时，DRL 可能会遭受严重性能下降甚至作出潜在危险的决策，因此在安全性要求高的场合确保其稳定性至关重要。", "innovation": "本文首先介绍了DRL的基本框架，并分析了复杂和变化环境中面临的主安全性挑战。此外，提出了基于扰动类型和攻击目标的对抗攻击分类框架，并详细回顾了主流针对DRL的对抗攻击方法，包括状态空间、动作空间、奖励函数和模型空间的各种攻击方法。为了有效对抗攻击，本文系统总结了当前的各种增强鲁棒性的训练策略，如对抗训练、竞争训练、鲁棒学习、对抗检测、防御蒸馏及其他相关防御技术，同时也讨论了这些方法在提高DRL鲁棒性方面的优缺点。", "conclusion": "本文展望了DRL在对抗环境中的未来研究方向，强调了提高泛化能力、降低计算复杂性和增强可扩展性和解释性等研究需求，旨在为研究人员提供有价值的研究参考和方向。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20350", "html_url": "https://arxiv.org/abs/2510.20350", "title": "由AI生成的图像想要什么？", "title_en": "What do AI-Generated Images Want?", "authors": "Amanda Wasielewski", "background": "该论文的背景在于W.J.T. Mitchell的著名论文《图片想要什么？》(What do pictures want?)将理论焦点从理解图片的行为以及人类创作者的动机，转向图片自身的能动性和欲望。在此基础上，论文通过探讨AI生成图片的特点来重新定义这一问题，致力于理解这些由算法生成的图像是否也拥有某种欲望和需求。", "innovation": "本文的创新在于将历史上的抽象艺术理论引入到探讨AI生成图像的行为中，论证了由于AI生成图像本质上是抽象的，因此它们更倾向于具有具体性。此外，文章指出了当前AI图像生成工具的机制，即文本和图像之间存在可交换性假设，以及这一过程掩盖了生成图像与提供文本之间的复杂关系，使得视觉输出看似从文本转化而来，仿佛有魔法发生。", "conclusion": "本文的结论是AI生成图像由于其抽象的性质，它们并非试图去实现抽象的概念，而是偏向于具体的表征，这一结论挑战了我们对于AI生成图像的理解，并揭示了其背后的技术逻辑。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20299", "html_url": "https://arxiv.org/abs/2510.20299", "title": "DB-FGA-Net: 双重主干频率门控注意网络结合Grad-CAM可解释性进行多类分类", "title_en": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability", "authors": "Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim", "background": "脑肿瘤是神经肿瘤学中的一大挑战性问题，早期和精确的诊断对于成功治疗至关重要。基于深度学习的脑肿瘤分类方法通常依赖于大量的数据增强，这可能会限制其在临床应用中的泛化能力和可靠性。大规模和分布式的医疗数据集对模型提出了进一步的挑战。因此，迫切需要一种既无需数据增强又能稳健处理多变大小和分布数据的数据集，并且在临床上具有高可靠性的深度学习模型。", "innovation": "本文提出了一种双重主干网络(DB-FGA-Net)，该网络结合了VGG16和Xception，并集成了频率门控注意(FGA)块，以捕捉局部和全局特征的互补性。不同于先前的研究，我们的模型在未经过数据增强的情况下达到了最新的性能，这证明了其对大小和分布多样的数据集的鲁棒性。此外，还集成Grad-CAM来增强模型可解释性，使得预测结果与临床应用有更好关联，提高了预测的透明度。在7K-DS数据集上的实验结果证实了DB-FGA-Net在4类、3类和2类设置下的高精度，分别为99.24%、98.68%和99.85%。面对独立的3K-DS数据集的挑战，该模型的准确率达到了95.77%，大幅超越了基线和新的前沿方法。", "conclusion": "所述框架在7K-DS数据集上实现了99.24%的准确率，在3类和2类设置下分别达到了98.68%和99.85%的准确率。在独立的3K-DS数据集上，这种增强可解释的深度学习模型对临床应用具有高度泛化的能力，实现了95.77%的准确率，表明该模型具有强大的临床转化潜力，可以可靠地用于脑肿瘤诊断。为了进一步支持临床操作，我们开发了一种图形用户界面(GUI)，可以实时分类和基于Grad-CAM实现肿瘤定位。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20333", "html_url": "https://arxiv.org/abs/2510.20333", "title": "GhostEI-Bench: 移动代理在动态设备环境中对环境注入的抵御能力？", "title_en": "GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?", "authors": "Chiyu Chen,Xinhao Song,Yunkai Chai,Yang Yao,Haodong Zhao,Lijun Li,Jie Li,Yan Teng,Gongshen Liu,Yingchun Wang", "background": "视觉语言模型（VLMs）被越来越多地用作自主代理，以导航移动图形用户界面（GUI）。在包含通知、弹出窗口和跨应用交互的动态设备生态系统中运行，它们面临一种独特的且未被充分探索的威胁向量：环境注入。这种攻击不通过文本指令进行操纵，而是通过向GUI直接插入恶意UI元素（例如欺骗性覆盖或伪装的通知）来破坏代理的视觉感知。这种攻击绕过了文本保护，导致隐私泄露、经济损失或设备不可逆的损害。为了系统地评估这一威胁，作者引入了GhostEI-Bench，这是首个评估在动态可执行环境中受到环境注入攻击的移动代理的基准。超越前人的静态图像评估，GhostEI-Bench将恶意事件注入实际的应用工作流程中，并在完全运行的Android模拟器中评估关键风险场景下的性能。", "innovation": "作者提出了一种评估方法，即GhostEI-Bench，用于检测和量化移动代理在受环境注入攻击影响下的性能状况。GhostEI-Bench采用了一个名为judge-LLM的协议，该协议通过分析代理的动作轨迹和相应的屏幕截图来细粒度地分析故障，定位感知、识别或推理的失败点。实验结果表明，当前最先进的模型在应对被操纵的UI时表现出明显的脆弱性。GhostEI-Bench提供了一个框架，用于量化和缓解这一新兴威胁，为更为稳健和安全的实体代理铺平了道路。", "conclusion": "全面的实验表明，当前最先进的代理模型对欺骗性环境提示表现出系统性的感知和推理能力不足。GhostEI-Bench为量化和缓解这一新兴威胁提供了一个框架，推进了更稳健和安全的实体代理的发展。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20339", "html_url": "https://arxiv.org/abs/2510.20339", "title": "面向表面计量学的多任务深度学习", "title_en": "Multi-Task Deep Learning for Surface Metrology", "authors": "D. Kucharski,A. Gaska,T. Kowaluk,K. Stepien,M. Repalska,B. Gapinski,M. Wieczorowski,M. Nawotka,P. Sobecki,P. Sosinowski,J. Tomasik,A. Wojtowicz", "background": "本文介绍了用于预测表面纹理参数及其报告的标准不确定性的可再现深度学习框架。研究使用了包含了触觉和光学测量系统的多样数据集，探讨了测量系统类型的分类问题，并同时进行了协调回归，针对Ra、Rz、RONt及其不确定目标（Ra_uncert、Rz_uncert、RONt_uncert）。不确定性通过量化头和异方差头建模，并通过后验同校准来生成可校准的区间。", "innovation": "提出了一个多任务深度学习框架，同时考虑表面纹理参数及其不确定性的预测问题，特别是在包含不同测量系统的数据集上实现了测量系统类型的分类。模型通过量化和异方差头部建模不确定性，并通过后验同校准确保预测的可靠性。此外，作者探索了单目标模型与多输出模型在处理此类问题时的性能差异。", "conclusion": "研究表明，单目标回归器在多个目标上表现出很高的预测精度（R2值分别为Ra 0.9824、Rz 0.9847、RONt 0.9918），其中两个不确定性目标也得到了较好建模（Ra_uncert 0.9899、Rz_uncert 0.9955），而RONt_uncert的建模效果较为困难（R2 0.4934）。分类器的准确率达到92.85%，经过温度缩放，概率校准几乎没有变化（测试切分ECE值从0.00504变为0.00503）。直观上，单目标模型在处理这些问题时表现更优于多输出模型。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20342", "html_url": "https://arxiv.org/abs/2510.20342", "title": "教会语言模型使用工具进行推理", "title_en": "Teaching Language Models to Reason with Tools", "authors": "Chengpeng Li,Zhengyang Tang,Ziniu Li,Mingfeng Xue,Keqin Bao,Tian Ding,Ruoyu Sun,Benyou Wang,Xiang Wang,Junyang Lin,Dayiheng Liu", "background": "大型推理模型（LRMs）如OpenAI-o1展现出了在自然语言推理方面的出色能力，但在处理复杂数学运算时经常显示出不效率和不准确性。虽然集成代码解释器（Code Interpreters, CIs）能提供一种有希望的解决方案，但这引入了一个关键挑战，即模型内部的基于概率的推理与外部提供的确定性知识之间的冲突，这导致模型进行无生产力的思考。为解决这一问题，本文提出了CoRT（Code-Optimized Reasoning Training），一种后训练框架，旨在教LRMs有效使用CIs。通过一种称为提示工程的新数据合成策略，CoRT在推理路径中的关键点注入多样的提示，生成高质量、代码集成的推理数据，特别针对优化LRM-CI交互设计。这些方法通过监督微调生成了30个高质量样本来训练参数从1.5B到32B的模型。", "innovation": "本文提出了CoRT（Code-Optimized Reasoning Training），一种后训练框架，旨在教LRMs有效使用CIs。其中，提示工程是一种新的数据合成策略，能够在推理路径的关键点注入多样化的提示，生成高质量、代码集成的推理数据，特别针对优化LRM-CI交互设计。CoRT进一步通过拒绝采样和强化学习调节外部CI使用和内部思考的多轮交替。期望通过这种方法提高模型的效率和准确性，尤其是在处理复杂的数学推理问题时。", "conclusion": "通过实验评估表明，CoRT对于数学推理表现出色，比基于纯自然语言推理的方法分别取得了4%和8%的绝对改进，且CoRT显著增强了效率，32B模型的令牌使用量减少了大约50%，1.5B模型的令牌使用量减少了大约30%。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20375", "html_url": "https://arxiv.org/abs/2510.20375", "title": "负向文本对大型语言模型幻觉的影响", "title_en": "The Impact of Negated Text on Hallucination with Large Language Models", "authors": "Jaehyung Seo,Hyeonseok Moon,Heuiseok Lim", "background": "近年来，大型语言模型（LLMs）中的幻觉现象在自然语言处理领域引起了广泛关注。然而，负向文本对LLMs幻觉的影响尚未得到充分研究。", "innovation": "本文设置了三个重要的待解答研究问题，并提出了解决方案。通过构建包含负向表达式的NegHalu数据集，探究了LLMs在处理负向输入时检测幻觉的能力，揭示了LLMs在处理负向输入时的挑战，并揭示了其内部状态。研究表明，LLMs在检测负向文本中的幻觉时存在困难，经常产生逻辑不一致或不忠实的判断。", "conclusion": "实验证明，LLMs在处理负向文本时难以有效地检测幻觉，频繁作出逻辑上不一致或不忠实的判断。此外，我们还剖析了LLMs在处理负向输入时的内部状态，揭示了缓解其意外影响的困难。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20351", "html_url": "https://arxiv.org/abs/2510.20351", "title": "在大型语言模型中评估公共表格数据集的潜在知识", "title_en": "Evaluating Latent Knowledge of Public Tabular Datasets in Large Language Models", "authors": "Matteo Silvestri,Flavio Giorgi,Fabrizio Silvestri,Gabriele Tolomei", "background": "大型语言模型（LLMs）越来越多地被评估其处理结构化数据的能力，但此类评估往往忽略了数据集污染这一重要混淆因素。本文研究了LLMs是否对广泛使用的表格基准数据集，如Adult Income、Titanic等，具有先验知识。通过一系列受控探针实验，结果显示，只有包含强烈语义暗示（例如，有意义的列名或可解释的价值类别）的数据集才会出现污染效应。相反，当去除或随机化这些暗示时，性能急剧下降至近乎随机的水平。这表明LLMs在表格推理任务中的表现部分反映的是对公共可用数据集的记忆，而非真正的泛化能力。", "innovation": "该研究通过受控的探针实验揭示了数据集污染效应仅在包含强烈语义暗示的数据集中出现，而无此类暗示时性能显著下降。这一发现挑战了LLMs在表格推理任务中的表现，建议评估协议的改进策略，以区分语义泄漏与真正的推理能力。", "conclusion": "研究结果表明，LLMs在表格推理任务中的表现可能部分反映了对公开可用数据集的记忆，而非真正的泛化能力。未来的研究应探讨如何从LLMs的能力评估中分离出语义泄漏，以确保评估的公正性与可靠性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20381", "html_url": "https://arxiv.org/abs/2510.20381", "title": "VLSP 2025 MLQA-TSR挑战：越南多模态道路交通标志法律规定问答", "title_en": "VLSP 2025 MLQA-TSR Challenge: Vietnamese Multimodal Legal Question Answering on Traffic Sign Regulation", "authors": "Son T. Luu,Trung Vo,Hiep Nguyen,Khanh Quoc Tran,Kiet Van Nguyen,Vu Tran,Ngan Luu-Thuy Nguyen,Le-Minh Nguyen", "background": "该论文提出VLSP 2025 MLQA-TSR共享任务，旨在推进越南多模态法律文本处理的研究，并提供一个多模态法律领域中的智能系统构建和评估基准数据集，重点在于越南的道路交通标志法规。", "innovation": "VLSP 2025 MLQA-TSR包含两个子任务：多模态法律检索和多模态问题回答。这是首个在越南道路交通标志法规领域的多模态法律问答任务，通过挑战促进了该领域的研究进展。", "conclusion": "在VLSP 2025 MLQA-TSR上，多模态法律检索的最佳报告结果为F2分数64.55%，多模态问题回答的准确率为86.30%。这些结果为后续研究和改进奠定了坚实的基础。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20387", "html_url": "https://arxiv.org/abs/2510.20387", "title": "基于相对概率的语言模型扩展律", "title_en": "Relative-Based Scaling Law for Neural Language Models", "authors": "Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu", "background": "现有规模律研究几乎完全依赖交叉熵作为评价指标，但交叉熵仅提供了性能的部分视图，忽略了正确和错误词之间的相对排序，而在贪婪采样等场景中，这种相对排序至关重要。", "innovation": "提出了基于相对概率（RBP）的度量方法，量化了正确词在前几个预测中的排名概率。构建了基于相对概率的扩展律，描述了RBP随模型增大如何提升。该研究通过四个数据集和四个模型家族的广泛实验，展示了该定律的稳健性和准确性。", "conclusion": "基于相对概率的扩展律补充了交叉熵视角，有助于更全面地理解大规模语言模型的扩展。它为实际开发和理论探索提供了宝贵的见解。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20327", "html_url": "https://arxiv.org/abs/2510.20327", "title": "LEGO: 一种轻量且高效的推荐系统多属性删除框架", "title_en": "LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems", "authors": "Fengyuan Yu,Yuyuan Li,Xiaohua Feng,Junjie Fang,Tao Wang,Chaochao Chen", "background": "随着对保护用户敏感信息需求的增加，推荐系统中的推荐属性删除受到越来越多的关注。现有研究主要集中在单属性删除上。然而，实际中的隐私保护要求往往涉及多个敏感属性并且是动态的。现有的单属性删除方法无法满足这些实际要求，因为存在i) 无法同时处理多个删除请求，以及ii) 对动态删除需求缺乏有效的适应性这两个问题。", "innovation": "我们提出了一种轻量且高效的多属性删除框架LEGO。具体来说，我们把多属性删除过程分为两步：i) 嵌入校准从用户嵌入中删除特定属性的相关信息，ii) 灵活组合将这些嵌入合并成一个嵌入，保护所有敏感属性。我们把删除过程视为互信息最小化问题，为LEGO提供了同时删除的理论保证，从而解决了i)问题。通过两步框架，嵌入校准可以并行执行，灵活组合是灵活和高效的，从而解决了ii)问题。我们在三个真实世界数据集上的三个代表性推荐模型上的大量实验表明了我们提出的框架的有效性和效率。", "conclusion": "我们的实验结果在三个真实世界数据集上表明，LEGO框架在多属性删除方面是有效且高效的，并通过并行和灵活的方式提供了更好的适应性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20388", "html_url": "https://arxiv.org/abs/2510.20388", "title": "FLAS：分布式服务的 proactive 和 reactive 自动扩缩容结合架构", "title_en": "FLAS: a combination of proactive and reactive auto-scaling architecture for distributed services", "authors": "Víctor Rampérez,Javier Soriano,David Lizcano,Juan A. Lara", "background": "云计算已成为众多新兴技术的主要支持平台，主要得益于其弹性特征。自动缩放器是实现此弹性的系统，通过按需获取和释放资源以确保服务水平。本文介绍了一种结合前瞻性与反应性的自动缩放器 FLAS，适用于分布式服务。FLAS 主要利用预测性模型来预测关键 SLA 参数的变化趋势，并基于资源使用指标预测高指标来实现反应性策略，减少入侵性并使应用环境适应更为广泛。", "innovation": "FLAS 引入的主要创新点包括：(i) 高级指标变化趋势的预测模型，可预测与 SLA 相关的关键参数的变化；(ii) 基于资源使用指标估计高级指标的反应性系统，减少了入侵性并使该系统能够适应各种应用。", "conclusion": "通过对内容发布-订阅中间件（E-SilboPS）的应用实现，在多种测试案例中，包括最糟糕的情况，FLAS 确保了超过 99% 的时间符合性能要求，验证了该方法的有效性和系统的有效性。据了解，这是首个内容发布-订阅分布式系统的自动扩缩容系统（不过该系统足够通用，可以适用于任何分布式服务）。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20328", "html_url": "https://arxiv.org/abs/2510.20328", "title": "MemER: 通过经验检索扩大机器人控制中的记忆规模", "title_en": "MemER: Scaling Up Memory for Robot Control via Experience Retrieval", "authors": "Ajay Sridhar,Jennifer Pan,Satvik Sharma,Chelsea Finn", "background": "人类在日常任务中会依赖记忆，而大多数机器人策略缺乏这种能力。本文旨在赋予机器人策略与人类相似的记忆能力。现有的方法在处理长期观察历史时效率低下且容易受到环境变化的影响，而无选择地从中抽取历史信息会导致无关或冗余的信息。", "innovation": "提出了一个分层策略框架，其中高层策略负责从经验中选择和跟踪之前的相关关键帧，这些关键帧用于生成低层策略执行时所使用的文本指令。该设计能够与现有的视觉-语言-动作（VLA）模型兼容，使得系统能够有效推理长期依赖关系。在实验证明中，使用Qwen2.5-VL-7B-Instruct和$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol{\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol{\boldsymbol{\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol{\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol}\boldsymbol{\boldsymbol}\boldsymbol}\boldsymbol}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}$等高层和低层策略，并利用演示和最小语言标注进行微调。这一方法在三个实际的长期机器人操作任务中表现超出先前方法，这些任务需要几分钟的记忆。有关视频和代码的内容可以在这里找到：this https URL。", "conclusion": "我们的方法MemER在三个实际的长期机器人操作任务中表现优于先前的方法，这些任务需要几分钟的记忆。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20408", "html_url": "https://arxiv.org/abs/2510.20408", "title": "平衡专业化与集中化：基于顺序工业控制的多代理强化学习基准环境", "title_en": "Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control", "authors": "Tom Maus,Asma Atamna,Tobias Glasmachers", "background": "多阶段工业过程的自主控制需要局部专业化和全局协调。虽然强化学习（RL）是一个有前景的方法，但其在工业中的应用受到诸如奖励设计、模块化和动作空间管理等方面的挑战限制。许多学术基准环境与工业控制问题差异显著，限制了其在实际应用中的可转移性。已有两种基准环境SortingEnv和ContainerGym，本研究将它们合并成一个顺序回收场景，该场景包含排序和压碎操作。我们评估了两种控制策略：模块化架构中的专业化代理和管理整个系统的单一代理，同时分析了行动遮蔽的影响。实验结果显示，在没有行动遮蔽的情况下，代理难以学习有效的策略，模块化架构表现更好；在应用行动遮蔽后，两种架构都显著改善，差距显著缩小。这些结果强调了行动空间约束的重要性，并暗示随着行动复杂性的降低，专业化的优势逐渐减弱。因此，本文提出了一个有价值的测试床，用于探索工业自动化中的实用且稳健的多代理RL解决方案，并促进了集中化与专业化之间持续的争论。", "innovation": "提出了一个结合了Two殷两种现有基准环境的顺序回收场景的多代理行动学习基准环境。评估了模块化架构（具有专业化代理）和整体管理架构（单一代理治理整个系统）两种控制策略，同时分析了行动遮蔽的影响。实验结果显示在没有行动遮蔽时，模块化架构表现更优；在应用行动遮蔽后，两种架构都显著改善，差距缩小。这些结果强调了行动空间约束的重要性，并说明专业化的优势随行动复杂性的降低而减弱。", "conclusion": "提出的基准环境为探索和工业自动化中实用且稳健的多代理RL解决方案提供了一个有价值的试验平台。研究成果还为集中化与专业化的持续争论做出了贡献，强调了行动空间约束的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20441", "html_url": "https://arxiv.org/abs/2510.20441", "title": "UniSE：基于解码器仅自回归语言模型的统一语音增强框架", "title_en": "UniSE: A Unified Framework for Decoder-only Autoregressive LM-based Speech Enhancement", "authors": "Haoyin Yan,Chengwei Liu,Shaofei Xue,Xiaotao Liang,Zheng Xue", "background": "神经音频编解码器（NACs）的发展极大地促进了语言模型（LMs）在语音处理和理解中的应用。然而，缺乏关于基于自回归（AR）语言模型的模型在统一语音增强（SE）的多种子任务中的有效性的验证。现有的研究表明，尽管LMs在处理多种任务方面具有潜力，但在语音增强任务上尚未得到充分验证和统一处理。本文研究了基于解码器仅自回归语言模型的方法来应对不同类型的语音增强任务，如语音恢复、目标说话人提取和语音分离等问题，以验证其在统一多种语音增强任务中的效果。", "innovation": "本文提出了一种名为UniSE的新框架，它是一种基于解码器仅自回归语言模型的统一框架，用于处理不同类型的语音增强任务。该框架通过AR建模将输入的语音特征作为条件，并生成目标语音的离散标记，从而兼容多个任务的学习模式。这一创新之处在于它能够用统一的方法处理语音增强任务，而不是分别处理每一个具体的任务。这为语音增强领域提供了一种新的方法，可以更有效地处理不同类型的语音增强任务。", "conclusion": "实验结果表明，本文提出的UniSE在几个基准测试上可以达到与判别性和生成性基线相当的性能，显示出语言模型在统一多种语音增强任务方面的潜力。这一研究结果验证了基于解码器仅自回归语言模型的方法在语音增强任务中的有效性和实用性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20438", "html_url": "https://arxiv.org/abs/2510.20438", "title": "利用视觉变换器实现高精度肺癌检测和实时部署的动态权重调整知识蒸馏", "title_en": "Dynamic Weight Adjustment for Knowledge Distillation: Leveraging Vision Transformer for High-Accuracy Lung Cancer Detection and Real-Time Deployment", "authors": "Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel", "background": "本文介绍了一种用于肺癌（LC）分类的创新方法——FuzzyDistillViT-MobileNet模型，综合利用动态模糊逻辑驱动的知识蒸馏（KD）来应对疾病诊断中的不确定性和复杂性。不同于依赖静态KD和固定权重的传统模型，该方法利用动态调整蒸馏权重，增强学生模型在高置信度区域的关注度并减少对不确定区域的关注。这种动态调整提高了模型处理不同区域不确定性变化的能力。研究还采用了像素级图像融合改进技术，如Gamma校正和直方图均衡化，进一步提升图像质量。通过多尺度分层分解和系数递归平均化，改善特征提取，使用遗传算法（GA）从12个预训练学生模型中选择最适合的模型，兼顾性能与计算成本。基于此模型，实验评估了LC25000组织病理图像和IQOTH/NCCD CT扫描图像，展示了模型在不同成像领域的鲁棒性。", "innovation": "1. 利用动态模糊逻辑驱动的知识蒸馏（KD），灵活调整蒸馏权重。2. 在Vision Transformer（ViT-B32）的指导下，优化学生模型（MobileNet），增强泛化能力。3. 引入像素级图像融合技术，如Gamma校正和直方图均衡化，提高图像质量和特征保留。4. 使用遗传算法（GA）挑选最优预训练学生模型，实现高效计算与高精度的平衡。5. 在不同影像数据集上（组织病理图像和CT扫描图像）验证了模型的高效和可靠性，展示出高精度和鲁棒性。", "conclusion": "本文提出了一种基于动态模糊逻辑驱动的知识蒸馏方法的FuzzyDistillViT-MobileNet模型，通过优化Vision Transformer和学生模型、改进图像质量处理以及使用遗传算法选择最优预训练模型，实现高效、高精度的肺癌分类。该模型在不同医学影像数据集上展示了良好的性能，具备高精度和广泛的应用前景。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20468", "html_url": "https://arxiv.org/abs/2510.20468", "title": "通过图像偏好模型的可移植黑盒一次攻击水印", "title_en": "Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models", "authors": "Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko", "background": "近年来，数字内容水印技术因其广泛应用和生成模型的增多以及法律压力的增加而受到广泛关注。随着越来越多的AI生成内容在网络上可用，水印在大规模确保内容真实性和归属方面的作用日益重要。尽管有很多评估水印鲁棒性的研究，但对于水印伪造，即偷取真实内容中的水印并应用到恶意内容中的情况，研究较少。", "innovation": "本文在广泛使用的后置图像水印上下文研究了水印伪造。首先，引入了偏好模型来评估图像是否被水印标记，该模型通过使用纯程序生成的图像进行训练，并不需要真实水印。其次，展示了模型通过反向传播优化输入图像来移除和伪造水印的能力，仅需单一的水标图像即可完成，且无需了解水印模型的信息，简化了攻击过程。第三，对多种后置图像水印模型进行了评估，证明了该方法能有效伪造水印，质疑现有水印技术的安全性。", "conclusion": "研究表明，利用本文提出的方法能够有效伪造水印，提醒了对于现有水印技术潜在的攻击风险。为此，文中提供了代码和进一步资源的公开访问。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20448", "html_url": "https://arxiv.org/abs/2510.20448", "title": "MolBridge：针对稳健药物-药物相互作用事件预测的原子级别联合图精炼方法", "title_en": "MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction", "authors": "Xuan Lin,Aocheng Ding,Tengfei Ma,Hua Liang,Zhe Quan", "background": "药物组合提供治疗益处，但也带来了药物-药物相互作用(DDIs)的风险，特别是在复杂的分子结构下。准确预测DDI事件需要捕捉细粒度的药物间关系，这对于建模诸如酶介导的竞争等代谢机制至关重要。然而，现有的方法通常依赖于孤立的药物表示，未能明确建模原子层面上的跨分子交互，从而限制了其在不同分子复杂性和DDI类型分布中的有效性。", "innovation": "为了克服上述限制，我们提出了一种新颖的原子级别联合图精炼框架MolBridge，用于稳健的DDI事件预测。MolBridge构建了一个联合图，能够整合药物对的原子结构，从而可以直接建模药物间关联。为解决可能由过度平滑导致的远距离原子依赖信息丢失问题，我们引入了一个结构一致性模块，该模块能够迭代精炼节点特征同时保留全局结构上下文。这种联合设计使MolBridge能够有效学习局部和全局的交互模式，从而在局部和归纳场景中都优于最新的基线方法，提供了对常见和罕见DDI类型都具备鲁棒性的表示。广泛的实验在两个基准数据集上展示了MolBridge的一致优势，这表明细粒度的图精炼可以提高DDI事件预测的准确性和机理可解释性。", "conclusion": "这些结果证明了细粒度图精炼在改善DDI事件预测准确性、鲁棒性和机理解释力方面的优势。这项工作通过开发基于图的方法来研究和分析药物-药物相互作用网络，为Web挖掘和内容分析领域做出了贡献。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20479", "html_url": "https://arxiv.org/abs/2510.20479", "title": "RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging", "title_en": "RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging", "authors": "Bowen Wang,Haiyuan Wan,Liwen Shi,Chen Yang,Peng He,Yue Ma,Haochen Han,Wenhao Li,Tiao Tan,Yongjian Li,Fangming Liu,Yifan Gong,Sheng Zhang", "background": "大型语言模型（LLMs）的内部表示可以作为它们所学知识的可靠代理。现有的连续学习方法在处理新的学习任务时，往往需要访问历史数据或需要标注任务标签，这对场景变化和数据效率提出了挑战，还可能会造成记忆消退（catastrophic forgetting）问题，尤其是在处理多领域集成和保留领域一般特征的情况下。", "innovation": "提出了一种新的表示意识模型融合框架——RECALL，它可以在无需访问历史数据的情况下进行连续学习。RECALL 通过层次参数融合计算模型之间的相似性，并根据浅层和深层的特性进行适配，从而在不降低性能的情况下适应不同任务。这种方法首次能够在不同领域的任务之间实现无缝集成，并能有效防止记忆消退。", "conclusion": "通过广泛的实验，在五个NLP任务和多个连续学习场景下，RECALL展示了优于基线模型的知识保留能力和泛化能力，提供了一种可扩展且无需数据的解决方案，以适用于不断进化的LLMs。RECALL使得多领域模型的集成变得更加顺畅，具有较强的防止记忆消退的能力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20469", "html_url": "https://arxiv.org/abs/2510.20469", "title": "在执行Peer-to-Peer资源受限网络中的信息融合时生成的结构", "title_en": "Structures generated in a multiagent system performing information fusion in peer-to-peer resource-constrained networks", "authors": "Horacio Paggi,Juan A. Lara,Javier Soriano", "background": "信息融合的过程在过去被视作一种纯粹的分层过程，类似于传统的军事应用。然而，随着信息融合在不同非军事领域的发展，以及人机和机器间通信的进步，信息融合逐渐转变为一种更灵活、动态的多层次过程——称为holonic信息融合。这种转变特别适合于新兴的边缘组织和民用应用。当要素（“peers”）间存在资源（能量、可用信息、时间等）的限制时，在这样的一组完全交互的元素下生成的holon结构能够优化信息模糊性和不确定性的影响，适应环境或组成中的突然变化，并具备一定程度的自主性和协作能力，以实现共同目标。", "innovation": "本文研究了在资源受限的Peer-to-Peer网络中信息融合时生成的holon结构，基于多代理系统模型进行通用研究，并展示了一个可能的操作示例。该模型强调了holon结构在应对资源不足、通信中断或系统组件失效情况下的优势，比如高度的适应性、一定程度的自主性和协作能力。", "conclusion": "holon结构因其较强的适应性、一定程度的自主性和协作性特征，适用于资源受限和动态变化的环境中的信息融合任务。文章通过多代理系统模型展示了holonic结构的生成过程及其潜在应用，强调了holonic结构能够在通信受限或系统组件失效的情况下仍能有效运行的能力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20453", "html_url": "https://arxiv.org/abs/2510.20453", "title": "超越标准模型物理学中的符号回归和可微分拟合", "title_en": "Symbolic Regression and Differentiable Fits in Beyond the Standard Model Physics", "authors": "Shehu AbdusSalam,Steven Abel,Deaglan Bartlett,Miguel Crispim Romão", "background": "本文通过探讨所谓的约束最小超标准模型（CMSSM）来展示符号回归（SR）在探索超出标准模型（BSM）粒子物理模型的效果。BSM模型通常具有多个（如四个）任意参数，这些参数决定了实验信号和如暗物质的剩余密度等天体物理学观测结果。人们希望通过对这些符号表达式的分析来加速对观测现象的研究。本文重点关注希格斯玻色子的质量、冷暗物质的剩余密度以及对Muon异常磁矩的贡献。研究表明，SR能够产生极具准确性的表达式。利用这些表达式，可以进行全局拟合来推断CMSSM输入参数的后验概率密度，这些结果与采用传统方法的推断结果一致。此外，本文还展示了SR的一个主要优势，即能够使用可微分方法而不是抽样方法来进行拟合。", "innovation": "本文的创新之处在于通过使用符号回归方法，能够迅速生成与输入参数相关的符号表达式，并通过这些表达式进行全局拟合，推断CMSSM输入参数的后验概率密度，同时，与常规方法相比，SR利用可微分方法进行拟合，具有更大的全局鲁棒性。此外，研究还对比了符号回归与神经网络回归两种方法，发现符号回归能产生更稳健的全局结果，而神经网络则需要聚焦于有前景的数据区域才能达到同样的性能效果。", "conclusion": "本文利用符号回归方法，成功对CMSSM中的重要指标进行了精确的符号表达，并通过分析这些符号表达式进行全局拟合，取得了与传统方法一致的结果。此外，符号回归还展示出了利用可微分方法进行拟合的潜力，这一方法相较于传统的抽样方法更为稳健，但需要有更丰富的数据支持。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20487", "html_url": "https://arxiv.org/abs/2510.20487", "title": "引导评估意识的语言模型表现出部署状态的行为", "title_en": "Steering Evaluation-Aware Language Models To Act Like They Are Deployed", "authors": "Tim Tian Hua,Andrew Qin,Samuel Marks,Neel Nanda", "background": "大型语言模型（LLMs）有时会检测到自身正在被评估，并调整行为以显得更符合模型预期，这会削弱安全性评估的可靠性。本文通过引入引导向量来抑制LLM的评估意识，使其在评估时表现得像实际部署时那样，从而提升评估的可靠性。", "innovation": "本文提出了一种方法，通过训练LLM在评估环境中使用Python类型提示，使其表现出评估意识，然后再通过专家迭代训练，增强这种行为，从而使得模型在存在评估提示时也能表现出非评估意识的状态。关键在于使用原始模型构建引导向量，以使模型在评估过程中表现出与实际部署时一致的行为。", "conclusion": "本文的研究结果表明，通过引导技术可以抑制语言模型的评估意识，使其即使在存在评估提示时也能表现出与实际部署一致的行为，这将有助于提高安全性评估的可靠性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20486", "html_url": "https://arxiv.org/abs/2510.20486", "title": "Hurdle-IMDL: 一种不均衡学习框架用于红外降雨恢复", "title_en": "Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval", "authors": "Fangjian Zhang,Xiaoyong Zhuge,Wenlan Wang,Haixia Xiao,Yuying Zhu,Siyang Cheng", "background": "人工智能已推动了定量遥感的发展，但其效果受到标签分布不平衡的限制。传统的训练模型倾向于偏好常见的样本，而忽略了罕见样本，这导致了罕见样本检索性能的下降。降雨恢复就是一个典型例子，特别是在强降雨方面表现尤为凸显。", "innovation": "本文提出了一个名为Hurdle-Inversion Model Debiasing Learning (IMDL)的框架。该框架通过分解降雨分布的不平衡，处理零通胀和长尾问题。采用 hurdle 模型处理零通胀问题，并通过 IMDL 将学习对象转化为无偏的理想反向模型来解决长尾问题。通过统计指标和对中国东部地区降雨天气的案例研究，证明了 Hurdle-IMDL 在系统性低估和强至极端降雨的恢复方面优于传统的成本敏感、生成和多任务学习方法。", "conclusion": "Hurdle-IMDL 提供了一种通用的方法来应对环境变量分布的不均衡问题，从而提高了罕见但高影响事件的恢复能力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20505", "html_url": "https://arxiv.org/abs/2510.20505", "title": "Heterogeneous Question Answering的层次序列迭代", "title_en": "Hierarchical Sequence Iteration for Heterogeneous Question Answering", "authors": "Ruiyi Yang,Hao Xue,Imran Razzak,Hakim Hacid,Flora D. Salim", "background": "检索增强生成（RAG）在处理多步骤问题和异构证据来源方面表现脆弱，这通常涉及到准确性与延迟及标记/工具预算之间的权衡。现有方法难以有效地跨文本、表格和知识图谱等不同类型的数据融合知识，以生成准确的答案，同时保持效率和可解释性。因此，本文提出了一个统一框架，旨在提高多源数据融合的问答系统的性能和效率。", "innovation": "本文提出了一种新的框架——层次序列迭代（HSEQ Iteration for Heterogeneous Question Answering），该框架包括两个关键组件：(i) 将文档、表格和知识图谱线性化为具有一系列轻量级结构标签的可逆层次序列，(ii) 执行结构感知迭代，以收集生成答案前必要的证据。通过这个框架，论文实现了一个头部代理和迭代代理合作的方式，可以有效地在资源限制下进行证据收集和答案生成，同时还通过可选的精炼循环来解决矛盾问题，从而提高答案的准确性和可靠性。此外，HSEQ框架还具有跨多种数据格式的一致政策，指导有意识的预算迭代，以及可靠的证据标准化等优点。", "conclusion": "实验结果表明，该方法在HotpotQA（文本）、HybridQA/TAT-QA（表格+文本）和MetaQA（知识图谱）数据集上均优于传统的单次通过、多跳和基于代理的RAG基线方法，展示了高效率的优异性能。HSEQ方法还体现出三个关键优势：一是能够以一种无关格式的方式统一并有效处理多种类型的数据；二是能够进行预算内的引导和有意识的迭代，同时保持准确性；三是通过证据标准化实现可靠问题解答，提高答案的一致性和可审计性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20531", "html_url": "https://arxiv.org/abs/2510.20531", "title": " Fake-in-Facext: 面向细粒度可解释的换脸分析", "title_en": "Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis", "authors": "Lixiong Qin,Yang Zhang,Mei Wang,Jiani Hu,Weihong Deng,Weiran Xu", "background": "多模态大规模语言模型（MLLMs）的进步已经弥合了视觉和语言任务之间的差距，使解释可解释的换脸分析（XDFA）成为可能。然而，当前的方法受到了细粒度意识不足的问题：数据注释中的描述粗略且不可靠，并且模型无法支持文本伪造解释与视觉证据之间的联系输出，也无法处理任意面部区域的查询输入。这些限制导致响应还不够基于面部视觉上下文（Facext）。", "innovation": "为了解决上述限制，本文提出了Fake-in-Facext（FiFa）框架，主要创新在于数据注释和模型构建。首先定义了面部图像概念树（FICT），将面部图像细分为区域概念，进而构建了更可靠的注释管道FiFa-Annotator，用于伪造解释。基于这一专门的数据注释，提出了一个新的称为Artifact-Grounding Explanation（AGE）任务，该任务生成与扰动的艺术品分割掩码交织的文本伪造解释。提出的统一多任务学习架构FiFa-MLLM支持丰富的多模态输入和输出，可促进细粒度的可解释换脸分析。通过多个辅助监督任务，FiFa-MLLM在AGE任务上超过了强基线，并在现有的XDFA数据集上取得了SOTA性能。", "conclusion": "与强大的基线相比，FiFa-MLLM在AGE任务上表现出色，并在现有的XDFA数据集上实现了最先进的性能。该研究还计划将代码和数据公开。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20556", "html_url": "https://arxiv.org/abs/2510.20556", "title": "结构不变性至关重要：通过图度量重新思考图重排", "title_en": "Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics", "authors": "Alexandre Benoit,Catherine Aitken,Yu He", "background": "图重排已成为通过修改图拓扑来改善信息流动从而缓解图神经网络（GNN）和图变换器中过度压缩问题的关键技术。尽管有效，但图重排基本会改变图的结构，可能使依赖结构的重要信号失真。尽管图重排的应用越来越广泛，但目前对该技术必须保留哪些结构特性以确保性能改进和结构保真的了解仍然不足。", "innovation": "该研究是首次系统地分析了图重排如何影响一系列图结构指标，并探讨了这些变化与下游任务性能之间的关系。研究了七种不同的图重排策略，并将局部和全局图属性的变化与节点分类精度相关联。结果揭示了一种一致的模式：成功的重排方法倾向于保留局部结构，同时允许在全局连接性方面有一定的灵活性。.", "conclusion": "这些发现为设计有效的图重排策略提供了新的见解，填补了图理论与实际GNN优化之间的差距。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20543", "html_url": "https://arxiv.org/abs/2510.20543", "title": "The Dog the Cat Chased Stumped the Model: Measuring When Language Models Abandon Structure for Shortcuts", "title_en": "The Dog the Cat Chased Stumped the Model: Measuring When Language Models Abandon Structure for Shortcuts", "authors": "Sangmitra Madhusudan,Kaige Chen,Ali Emami", "background": "尽管对语言模型进行了广泛的基准测试，但我们缺乏区分结构性理解与语义模式匹配的方法。论文介绍了CenterBench，这是一个包含9720个关于中心嵌套句子的同理解问题的数据集，这些句子中的从句依序嵌套，从简单的到深度嵌套结构具有不同程度的处理需求。每个句子都有一个语义上不现实但语法上相同的对照句子，并包含六个测试表层理解、句法依赖性和因果推理的问题。", "innovation": "中心提出了CenterBench数据集，用于测试语言模型在处理复杂句子时是否从结构性分析转向模式匹配。研究发现，随着复杂性的增加，语言模型在可能和不可能句子之间的性能差距系统地增大，模型在因果关系推理的问题上表现更差，而在模型表现上存在对语义可能性的不同反应。", "conclusion": "中心Bench提供了第一个框架，用于识别模型何时从结构性分析转向模式匹配。同时，研究发现推理模型虽然提高了准确性，但也表现出语义捷径、过度思考和答案拒绝等现象。人类在处理这些问题时表现出不同的语义影响，这是一个新的观察结果。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20548", "html_url": "https://arxiv.org/abs/2510.20548", "title": "GlobalRAG: 通过强化学习增强多跳问答中的全局推理", "title_en": "GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering via Reinforcement Learning", "authors": "Jinchang Luo,Mingquan Cheng,Fan Wan,Ni Li,Xiaoling Xia,Shuangshuang Tian,Tingcheng Bian,Haiwei Wang,Haohuan Fu,Yan Tao", "background": "强化学习在提升检索增强生成（RAG）方面展现了潜力。然而，在处理多跳问答（QA）时，其有效性受到两大基本限制：一是缺乏全局规划结构化多步推理，二是执行不忠实，这阻碍了有效查询的形成和一致的证据使用。", "innovation": "提出了一种名为GlobalRAG的强化学习框架，旨在增强多跳QA中的全局推理。GlobalRAG将问题分解为子目标，协调检索与推理，迭代细化证据。引入了规划质量奖励和子目标完成奖励来指导这一过程，这两种奖励分别鼓励连贯的规划和可靠的子目标执行。此外，采用逐步权重退火策略平衡过程导向和结果导向的目标。", "conclusion": "在内部和外部领域基准测试中进行的广泛实验表明，使用仅8k训练数据（少于强基准线使用的42%数据），GlobalRAG在EM和F1指标上分别实现了平均14.2%的提升，显著优于强基准线。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20535", "html_url": "https://arxiv.org/abs/2510.20535", "title": "ARC-Encoder：为大型语言模型学习压缩文本表示", "title_en": "ARC-Encoder: learning compressed text representations for large language models", "authors": "Hippolyte Pilchen,Edouard Grave,Patrick Pérez", "background": "近年来，检索增强生成或有思辨推理等技术使得上下文变得更长，推理成本也相应增加。上下文压缩技术可以降低这些成本，但最有效的方法需要细调目标模型或改动其架构。这些方法可能在特定用途以外削弱模型的一般能力。论文中探讨了一种替代方法：一个编码器，它将文本压缩为连续表示，替代解码器LLM中的词元嵌入。研究中系统地探讨了编码器的训练策略和架构选择。这导致设计出一种适配文本表示压缩器（Adaptable text Representations Compressor，简称ARC-Encoder），它输出的连续表示通常是文本词元数量的1/4到1/8。ARC-Encoder被评估应用于各种LLM应用场景，包括上下文学习和扩展上下文窗口，使用指令型和基于的解码器。结果表明，ARC-Encoder在多个基准测试中表现出色，同时提高推理中的计算效率。最后，研究表明，模型可以适应多个解码器，使得ARC-Encoder成为一种灵活且高效的便携编码器解决方案，可以与多种LLM无缝协同工作。", "innovation": "开发了适配文本表示压缩器（Adaptable text Representations Compressor，简称ARC-Encoder），这是一种编码器，能将文本压缩为连续表示，替代解码器LLM中的词元嵌入。ARC-Encoder设计成输出的连续表示是文本词元数量的1/4到1/8。研究采用了系统的方法来探索编码器的训练策略和架构选择，以优化ARC-Encoder的性能。ARC-Encoder在多个LLM应用场景中表现优秀，既能提高性能又能提升计算效率，并能适应多种解码器。", "conclusion": "研究开发了一种适配文本表示压缩器ARC-Encoder，通过将文本压缩为连续表示来替代解码器LLM中的词元嵌入，显著提高了计算效率。ARC-Encoder在多种应用场景中表现优秀，能够适应多个解码器。研究结果表明，ARC-Encoder可以作为一种灵活且高效的压缩编码器解决方案，广泛适用于各种大型语言模型。同时，研究者共享了模型训练代码、微调数据集和预训练模型。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20579", "html_url": "https://arxiv.org/abs/2510.20579", "title": "Open-o3 Video: 显式时空证据支撑的视频推理", "title_en": "Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence", "authors": "Jiahao Meng,Xiangtai Li,Haochen Wang,Yue Tan,Tao Zhang,Lingdong Kong,Yunhai Tong,Anran Wang,Zhiyang Teng,Yujing Wang,Zhuochen Wang", "background": "目前大多数视频推理模型只能生成文本推理痕迹，但不指出关键证据何时何地出现。虽然最近像OpenAI-o3这样的模型在图像的证据中心推理方面引起了广泛兴趣，但将其扩展到视频则更具挑战性，因为这需要在动态场景中实现联合时间跟踪和空间定位。", "innovation": "本文介绍了Open-o3 Video框架，它是一种非代理框架，将显式时空证据集成到视频推理中，并精心收集训练数据并设计训练策略来应对上述挑战。为实现这一功能，作者构建了两个高质量数据集：STGR-CoT-30k用于自我训练（Self-Training with Explicit Chemical Reasoning Traces）和STGR-RL-36k用于强化学习（Reinforcement Learning with Explicit Chemical Reasoning Traces），并采用了一种特殊设计的冷启动强化学习策略，能够同时促进答案准确性、时间对齐和空间精度。该模型在V-STAR基准上达到最新性能，提高了mAM 14.4%和mLGM 24.2%，并且在多个视频理解基准上也表现出一致改进。", "conclusion": "Open-o3 Video生成的推理痕迹还为测试时的扩展提供了有价值的信号，能够进行可靠性的验证，从而提高了答案的可靠性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20566", "html_url": "https://arxiv.org/abs/2510.20566", "title": "AdaDoS: 使用深度对抗强化学习在SDN中的自适应DoS攻击", "title_en": "AdaDoS: Adaptive DoS Attack via Deep Adversarial Reinforcement Learning in SDN", "authors": "Wei Shao,Yuhao Wang,Rongguang He,Muhammad Ejaz Ahmed,Seyit Camtepe", "background": "现有的防御机制在对抗基于规则的DoS攻击时表现出了显著的效果，通过预定义的签名和静态启发式方法来识别并阻止恶意流量。然而，随着AI技术的应用，SDN安全遇到了新的挑战，可能削弱现有防御机制的有效性。现有DoS检测器可能无法有效检测通过对抗性强化学习（RL）策略进行的自适应DoS攻击。此类攻击通过动态调整策略以躲避检测，尤其难以捉摸，因为攻击者通常获取的信息少于防御者。因此，攻击者可以利用这种信息不对称性来避免被检测器发现。", "innovation": "AdaDoS首次将RL应用于开发DoS类型的攻击序列，能够自适应地躲避基于机器学习和基于规则的DoS类型的攻击检测器。通过将攻击场景建模为对抗性游戏，其中攻击者的目标是阻碍网络流量而不被发现，AdaDoS利用加深对抗强化学习策略解决这一问题。通过引入新颖的互学习模块，学生代理利用有限观察并通过从教师代理中学习来提升自己的性能。此外，AdaDoS将DoS攻击建模为部分可观测的马尔可夫决策过程（POMDP），使攻击者仅能访问攻击节点与受害节点之间的延迟信息。AdaDoS通过动态调整其策略来避免被检测器发现，展示了基于强化学习自适应DoS攻击的有效性与挑战性.", "conclusion": "AdaDoS提供了对抗自适应DoS攻击的新颖方法，通过加深对抗强化学习，并使用互学习模块解决信息不对称问题，能够在恶意网络攻击检测器的检测环境中实现自适应的DoS攻击。这不仅展示了AdaDoS在对抗现有DoS攻击检测器方面的有效性，还揭示了新的对抗性学习范式在网络安全中的潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20596", "html_url": "https://arxiv.org/abs/2510.20596", "title": "基于相似性原型的无监督跨模态分割域适应", "title_en": "Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation", "authors": "Ziyu Ye,Chen Ju,Chaofan Ma,Xiaoyun Zhang", "background": "深度学习模型在各种视觉挑战中取得了巨大成功，但这些模型在应用于未见过的数据时会面临性能急剧下降的问题。由于模型对数据域变换敏感，无监督域适应尝试通过减少不同域之间的差异来降低域差距，从而避免未见到的数据领域需要昂贵的标注成本。", "innovation": "本文提出了一种新的跨模态分割框架，通过在嵌入空间中学习类别的原型，并引入相似性约束使这些原型具有代表性和相互分离的性质。此外，为了防止类别缺失问题并进行原型的对比学习，本文使用字典将不同图像中提取的原型存储起来，进一步提高性能。", "conclusion": "大量的实验表明，该方法在跨模态分割中的表现优于其他最先进的方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20584", "html_url": "https://arxiv.org/abs/2510.20584", "title": "ChatGPT能否公平地编码沟通数据？：多轮合作任务的实证证据", "title_en": "Can ChatGPT Code Communication Data Fairly?: Empirical Evidence from Multiple Collaborative Tasks", "authors": "Jiangang Hao,Wenju Cui,Patrick Kyllonen,Emily Kerzabi", "background": "大规模评估沟通与协作需要对大量沟通数据进行分类编码，这是一个劳动密集型的工作。已有研究表明，ChatGPT可以直接根据编码准则对沟通数据进行编码，并能达到与人工评估员相当的准确度。然而，ChatGPT或其他类似AI技术在编码过程中是否存在针对不同 demographic 组群（如性别和种族）的偏见仍不清楚。本研究通过调查 ChatGPT 基础的自动编码技术，使用典型的合作问题解决编码框架，探讨不同性别和种族组群之间的差异。本研究的数据来自三种类型的合作任务：协商、问题解决和决策制定。", "innovation": "本研究利用 ChatGPT 自动编码沟通数据，并通过多种类型的协作任务进行了实证分析，以评估其对不同性别和种族群体是否存在偏见，填补了这一研究领域的空白，提供了一种在大规模评估协作和沟通中的新方法。", "conclusion": "ChatGPT 所进行的编码未显示出对性别和种族群体的显著偏见，为将其应用于大规模评估通信和协作铺平了道路。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20602", "html_url": "https://arxiv.org/abs/2510.20602", "title": "利用互易性回声 acoustic fields with reciprocity", "title_en": "Resounding Acoustic Fields with Reciprocity", "authors": "Zitong Lan,Yiduo Hao,Mingmin Zhao", "background": "虚拟环境中的沉浸式声音体验需要支持动态声源位置的灵活声学建模。本文旨在估计任意声源位置下的房间冲激响应，以此类比视觉领域的重新照明问题。现有的方法主要依赖于少量已测声源位置来预测其他位置的声音特性，但难以实现高精度的实时渲染。为此，本文提出了一个名为“回声”的任务，旨在提高声学场学习的效果，以实现更高质量的沉浸式声音体验。", "innovation": "本文提出了一种称为Versa的方法，这是一种基于物理原理的声学场学习方法。Versa通过交换声源和监听器的位置来生成物理上有效的虚拟声源位置样本，并利用互易性解决了由此带来的挑战。此外，还提出了一种自监督学习方法，以应对声源/监听器增益模式导致的难题。实验结果表明，Versa在仿真和真实世界的数据集上改善了声学场学习的性能。", "conclusion": "实验结果和感知用户研究显示，使用Versa方法可以显著提高沉浸式空间声音体验的质量。该项目的代码、数据集和演示视频可在指定网站获取。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20607", "html_url": "https://arxiv.org/abs/2510.20607", "title": "通过组合能量最小化实现可泛化的推理", "title_en": "Generalizable Reasoning through Compositional Energy Minimization", "authors": "Alexandru Oarga,Yilun Du", "background": "泛化是机器学习中的一个关键挑战，尤其是在需要解决比训练过程中遇到的问题更为复杂的推理任务中。现有的方法通常通过端到端训练来训练推理模型，直接将输入示例映射到解决方案。虽然这种方法允许模型从数据中学习有用的经验法则，但它往往导致泛化能力有限，无法超出训练分布之外。", "innovation": "本文提出了一个新的推理泛化方法，通过在较小且更容易解决的子问题的空间中学习能量景观来实现。在测试阶段，通过组合多个子问题的能量函数构建一个全局能量景观。这种方法的优势在于可以逐步引入更多约束，从而适用于难度更大的问题。同时，为了提高从新构造的能量景观中抽样的质量，本文引入了并行能量最小化(PEM)。该方法在广泛的任务上进行了评估，并展示了其在解决更大、更复杂的问题方面的优越性。", "conclusion": "本文的方法在多种推理问题上均优于现有的最先进的方法，证明了其在解决更大、更复杂的推理任务上的泛化能力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20605", "html_url": "https://arxiv.org/abs/2510.20605", "title": "OnlineSplatter：无姿态在线自由移动物体3D重建", "title_en": "OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects", "authors": "Mark He Huang,Lin Geng Foo,Christian Theobalt,Ying Sun,De Wen Soh", "background": "单目视频中自由移动物体的3D重建仍然是一个挑战，尤其是在缺乏可靠姿态或深度线索以及任意物体运动的情况下。现有方法通常需要摄像头姿态、深度先验或重优化等复杂步骤。因此，需要一种新的在线前馈框架，能够在不需要这些复杂步骤的情况下，直接从RGB帧生成高质量和对象中心的3D高斯模型。", "innovation": "提出了OnlineSplatter，一种新颖的在线前馈框架，能够从单目视频中直接生成高质量、对象中心的3D高斯模型，而无需要求摄像头姿态、深度先验或重优化。该框架通过一个密集的高斯原语场从第一帧开始进行重建，并逐步精化对象表示。其核心贡献是一个结合隐式外观-几何键和显式方向键的双键记忆模块，能够稳健地将当前帧特征与临时聚合的对象状态融合。此外，该设计通过基于空间指南的记忆读取和高效的稀疏化机制，有效地处理自由移动的物体。", "conclusion": "在现实世界的数据集上的评估显示，OnlineSplatter在无姿态的3D重建基准中显著优于现有方法，并且随着观测次数的增加一致性提高。同时，其展示出的内存和运行时间保持恒定，提供了全面而紧凑的对象覆盖。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20519", "html_url": "https://arxiv.org/abs/2510.20519", "title": "Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning", "title_en": "Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning", "authors": "Xiaohan Lan,Fanfan Liu,Haibo Qiu,Siqi Yang,Delian Ruan,Peng Shi,Lin Ma", "background": "近年来，大型语言模型（LLM）的推理能力取得了显著进步，已在复杂的任务上，如数学问题解决中实现了重要的性能提升。尽管取得了这些进展，当前的大规模多模态推理模型仍存在两个关键限制：它们倾向于使用昂贵的推理技术来进行简单的查询，导致效率低下；此外，这一专业知识的重视削弱了它们对更广泛的、更具一般性的理解能力。", "innovation": "本文提出了Metis-HOME框架，一种混合优化的专家混合模型（MoE）框架，旨在解决这一权衡问题。Metis-HOME通过将原始密集模型结构化为两个专家分支实现了一种‘混合思考’的模式：一个专门用于复杂的多步推理的思考分支，另一个则优化用于快速直接的感知推理，如通用VQA和OCR任务。通过一个轻量级的可训练路由器，动态分配查询给最适合的专家。实验证明，该方法不仅可以显著提高复杂的推理能力，还能提高模型的一般能力，逆转了其它专业推理模型在性能上退化的趋势。", "conclusion": "我们的工作建立了强大的和多功能多模态语言模型（LLM）的新范式，有效解决了推理与泛化的常见矛盾，为构建高效而多功能的模型提供了新的思路。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20609", "html_url": "https://arxiv.org/abs/2510.20609", "title": "大规模实用代码RAG：在计算预算下的任务感知检索设计选择", "title_en": "Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under Compute Budgets", "authors": "Timur Galimzyanov,Olga Kolomyttseva,Egor Bogomolov", "background": "本文研究了在现实计算预算下，针对代码的生成任务的检索设计。作者使用了Long Code Arena中的两种互补任务，即代码补全和错误定位，系统地在不同的上下文窗体大小中比较了各种检索配置。", "innovation": "研究发现，不同的检索配置对于不同任务有不同的效果。例如，对于PL-PL任务，稀疏BM25（基于单词级分割）是最有效的，在速度上快了约一个数量级。而对于NL-PL任务，专有的密集编码器表现更佳，但处理时间长100倍。研究还发现最优的片段大小会根据可用的上下文有所变化，并提出了基于任务需求、模型限制和计算效率的推荐方法。", "conclusion": "研究表明，BPE基于的分割过于缓慢，而BM25加上基于单词的分割能在质量与延迟之间提供最佳的权衡。因此，文章为根据特定任务、模型约束和计算效率构建有效的代码导向的RAG系统提供了基于实证的建议。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20612", "html_url": "https://arxiv.org/abs/2510.20612", "title": "黑盒吸收：大规模语言模型削弱创新理念", "title_en": "Black Box Absorption: LLMs Undermining Innovative Ideas", "authors": "Wenjun Cao", "background": "大规模语言模型被广泛认为是推动创新的重要工具。然而，这些模型存在一种系统性风险：黑盒吸收。这种风险体现在大型服务平台运营的不透明内部架构中，能够内部化、泛化和重新利用用户在交互中提供的新概念，从而破坏创新经济的基本原则，导致信息和结构上的不对称，威胁创新生态系统的长期可持续性。", "innovation": "本文提出了两个核心概念：创新单元和理念安全性，并分析了吸收机制，提出了具体的治理和工程议程来减轻这些风险，确保创作者贡献可追溯、可控和公平。", "conclusion": "本文通过对黑盒吸收现象的分析，提出了新的概念和治理框架，旨在保护创新理念的安全性，确保长期的创新生态系统可持续发展。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20611", "html_url": "https://arxiv.org/abs/2510.20611", "title": "PSO-XAI: 一种增强的可解释人工智能框架，用于可靠的乳腺癌检测", "title_en": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection", "authors": "Mirza Raquib,Niloy Das,Farida Siddiqi Prity,Arafath Al Fahim,Saydul Akbar Murad,Mohammad Amzad Hossain,MD Jiabul Hoque,Mohammad Ali Moni", "background": "乳腺癌是全球女性中最关键和最常见的癌症类型，导致癌症相关死亡率上升。早期和准确的检测至关重要，因为它可以减轻潜在威胁，提高生存率。常规诊断方法受限于变异、成本以及最重要的是误诊风险。为解决这些挑战，机器学习（ML）已成为计算机辅助诊断的强大工具，特征选择对提高模型性能和可解释性起着重要作用。", "innovation": "本研究提出了一个结合了定制粒子群优化（PSO）的集成框架，用于特征选择。该框架在性能评估中表现出色，涵盖了30多种不同模型，包括传统分类器、集成技术、神经网络、概率算法和邻近实例算法。通过交叉验证和可解释AI方法确保了模型解释性和临床相关性，实验结果显示，该方法在所有性能指标（包括准确性和精确度）上均获得了99.1%的高得分，有效减少了维度并提供了透明、模型无偏的解释。", "conclusion": "结果表明，结合群体智能与可解释的机器学习对于实现稳健、可靠和临床有意义的乳腺癌诊断具有潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20630", "html_url": "https://arxiv.org/abs/2510.20630", "title": "使用机器学习预测量子处理单元（QPU）处理时间", "title_en": "Quantum Processing Unit (QPU) processing time Prediction with Machine Learning", "authors": "Lucy Xing,Sanjay Vishwakarma,David Kremer,Francisco Martin-Fernandez,Ismael Faro,Juan Cruz-Benito", "background": "本文探讨了机器学习（ML）技术在预测量子作业（量子计算中的任务）在量子处理单元（QPU）上的处理时间的应用。研究使用了大约150,000个遵循IBM Quantum模式的任务数据集，并通过使用梯度提升算法（LightGBM）进行预测，同时结合数据预处理方法来提高模型的准确性。这项研究的背景在于提升量子计算系统的运营效率，并探讨机器学习在优化资源管理和调度中的潜在作用。", "innovation": "研究采用机器学习方法，特别是LightGBM算法来预测QPU处理时间，并通过数据预处理优化模型性能。这种方法可以预先估计量子作业的处理时间，进而影响资源管理和调度策略，提升操作效率。这是机器学习在量子计算领域的创新应用，有助于推动这一技术的发展。", "conclusion": "研究结果表明机器学习在预测量子作业处理时间方面具有显著效果，这不仅凸显了机器学习在未来优化量子任务预测中的潜力，也为将人工智能驱动工具集成到量子计算系统中铺平了道路。这项研究不仅为提高量子计算系统的运营效率奠定了基础，也为更复杂的量子计算操作提供了技术支持。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20610", "html_url": "https://arxiv.org/abs/2510.20610", "title": "BUSTED在AraGenEval共享任务中的表现：基于Transformer模型的阿拉伯语AI生成文本检测比较研究", "title_en": "BUSTED at AraGenEval Shared Task: A Comparative Study of Transformer-Based Models for Arabic AI-Generated Text Detection", "authors": "Ali Zain,Sareem Farooqui,Muhammad Rafi", "background": "该论文描述了在Ara-GenEval共享任务中针对阿拉伯语AI生成文本检测提交的内容。BUSTED团队参加了这项任务并取得了第五名的成绩。研究团队探讨了三种预训练的变压器模型的有效性，包括AraELECTRA、CAMeLBERT和XLM-RoBERTa。方法是将每个模型在提供的数据集上进行微调，以执行二分类任务。研究结果出人意料：多语言的XLM-RoBERTa模型以F1分数0.7701的表现超过了专门针对阿拉伯语的模型，突显了AI生成文本检测的复杂性，并强调了多语言模型的强泛化能力。", "innovation": "研究发现，多语言的XLM-RoBERTa模型在阿拉伯语AI生成文本检测任务中表现最好，实现了最高的F1分数0.7701，超过了专门设计的阿拉伯语模型。这项工作强调了多语言模型在面对特定语言任务时的泛化能力，并提出了基于Transformer的模型在AI生成文本检测任务上的新见解。", "conclusion": "研究结果表明，虽然阿拉伯特定模型在某些方面可能更加专业，但在泛化能力上，多语言的XLM-RoBERTa模型更适合用于各种语言的AI生成文本检测任务。这一发现对未来的模型设计和选择具有重要意义。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20629", "html_url": "https://arxiv.org/abs/2510.20629", "title": "公平生存预测：一种公平性意识生存建模（FASM）方法", "title_en": "Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach", "authors": "Mingxuan Liu,Yilin Ning,Haoyuan Wang,Chuan Hong,Matthew Engelhard,Danielle S. Bitterman,William G. La Cava,Nan Liu", "background": "随着机器学习模型越来越多地应用于医疗保健，临床数据中嵌入的结构性不平等和社会偏见可能会通过数据驱动的模型得到延续甚至放大。在生存分析中，截尾和时间动态会进一步使公平模型的开发复杂化。此外，算法公平性方法往往忽略了各组间排名差异，例如高风险的黑人患者可能被排名在低风险但未经历死亡事件的白人患者之下。这样的重新排序会强化生物本质主义并削弱公平的护理。提高公平性同时保持与未考虑公平性生存模型相当的预测能力是当前生存分析的一大挑战。", "innovation": "本文提出了一种公平性意识生存建模（FASM），旨在减轻对未来时间和组内及组间风险排名的算法偏见。通过乳癌预后作为代表性案例，应用FASM对SEER乳癌数据进行分析，结果显示FASM在提高公平性方面表现显著，同时保持了与未考虑公平性的生存模型相当的预测力。时间分层评估表明，FASM能够在10年的时间范围内保持公平性的稳定性，并且在随访中期显示出最大的改进。这种方法促进了兼顾准确性和公平性的生存模型开发，将公平性作为临床护理的核心原则。", "conclusion": "FASM方法在提高生存模型公平性的同时，维持了与未考虑公平性的生存模型相当的预测能力。这种方法可以在10年内保持稳定的公平性，并且在随访中期显示出最大的改进，促进了以公平性和准确性为双重核心的临床决策模型的发展。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20647", "html_url": "https://arxiv.org/abs/2510.20647", "title": "理性的通用语言：多语言AI的一柄双刃剑", "title_en": "The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI", "authors": "Alan Saji,Raj Dabre,Anoop Kunchukuttan,Ratish Puduppully", "background": "大型推理模型（LRMs）在数学、科学及其他问答任务中表现出色，但在多语言推理能力方面仍然被低估。当面对非英语问题时，LRMs通常使用英语进行推理，这引发了关于其解释性和处理语言和文化细微差别的能力的担忧。", "innovation": "作者系统性地比较了LRMs在英语与问题语言之间的推理差异，并超越了准确性的度量，分析了推理痕迹中的认知属性。研究发现，使用英语推理的痕迹中认知行为的出现频率更高，且与英语推理相比，英语推理在整个答案中的准确性更高，尤其是在任务复杂度较高时。然而，这种以英语为中心的策略更易产生“翻译迷失”的关键失败模式，即翻译步骤导致原本可以通过使用问题语言进行推理避免的错误。", "conclusion": "虽然LRMs在使用英语进行推理时表现出更高的准确性和更高级的认知行为，但它们可能因“翻译迷失”而产生较大错误，这突显了在构建多语言AI中理解语言和文化细微差别的必要性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20635", "html_url": "https://arxiv.org/abs/2510.20635", "title": "为什么苹果会落到地上：评估大语言模型中的好奇心", "title_en": "Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language Model", "authors": "Haoyu Wang,Sihang Jiang,Yuyan Chen,Yitong Wang,Yanghua Xiao", "background": "人类的好奇心是推动其探索和学习新知识的关键因素。近年来，大型语言模型（LLMs）在自然语言处理方面取得了进展，引发了关于这些模型是否具有类似于人类的好奇心驱动学习能力的讨论。本研究从人类的好奇心评估问卷五维好奇心量表修订版（5DCR）出发，设计了一个涵盖信息寻求、刺激寻求和社会好奇等维度的全面评估框架，以评估LLMs的好奇程度。研究表明，尽管LLMs表现出更强的好奇心，但在面对不确定性环境时，它们仍倾向于保守的选择。这些发现为LLMs未来学习能力和创新研究提供了实验支持。", "innovation": "本文创新性地采用五维好奇心量表修订版（5DCR）设计了评估LLMs好奇心的框架，涵盖信息寻求、刺激寻求和社会好奇等多个维度，并证实了好奇心能提高模型的推理和主动学习能力。研究还发现，尽管LLMs表现出强烈的好奇心，但它们在面对不确定性环境时会做出保守的选择。", "conclusion": "LLMs有潜力表现出类似人类的好奇心，这为未来改进LLMs的学习能力和支持创新性研究提供了实验支持。研究结果表明好奇心在LLMs中的作用，并提供了有关如何进一步培养和利用好奇心的见解。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20671", "html_url": "https://arxiv.org/abs/2510.20671", "title": "GRACE: 基于图的成瘾护理预测", "title_en": "GRACE: GRaph-based Addiction Care prEdiction", "authors": "Subham Kumar,Prakrithi Shivaprakash,Koustav Rudra,Lekhansh Shukla,Animesh Mukherjee", "background": "确定成瘾患者的适宜护理地点是影响治疗结果和资源有效利用的一个关键临床决策。由于缺乏足够的专业化治疗资源，如住院床位或工作人员，开发一个自动化的决策框架来解决这个问题变得更加迫切。当前的决策方法在成瘾数据集中存在严重的类别不平衡问题。", "innovation": "本文提出了一种新颖的图神经网络（GRACE）框架，将护理地点预测问题形式化为结构化学习问题。通过进行广泛的特征工程，并提出了一种获得无偏见元图的新方法来训练GNN，以解决类别不平衡问题。实验结果表明，与竞争 baseline 相比，在少数类的 F1 分数上提高了11-35%。", "conclusion": "通过GRACE框架，在实际数据中取得了显著的改进。该研究的结果证明了提出的GRACE方法的有效性和潜在的应用价值。代码和节点嵌入在provided link中可以获取。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20634", "html_url": "https://arxiv.org/abs/2510.20634", "title": "深度学习在牙科图像分析中的应用：数据集、方法和技术前沿综述", "title_en": "Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges", "authors": "Zhenhuan Zhou,Jingbo Zhu,Yuchen Zhang,Xiaohang Guan,Peng Wang,Tao Li", "background": "牙科图像分析对于准确诊断和优化治疗计划至关重要。然而，牙科成像面临着低对比度、金属伪影和投射角度变化等挑战。加之不同牙医经验的差异导致的主观性因素，手动解读成像结果既耗时又易产生不一致性。因此，利用人工智能（AI）进行自动化的牙科图像分析（DIA）成为了解决这些问题的有力手段。在这篇论文中，作者综述了260项关于深度学习在牙科图像分析中的应用研究，分析了其中49篇关于公开可用数据集的研究和211篇关于深度学习算法的研究，系统地探讨了基于深度学习的数据集和模型的最新进展，分析了网络架构、优化策略、训练方法和性能等关键方面，为该领域的研究人员提供了宝贵的参考资料。", "innovation": "文章系统性地综述了260项深度学习在牙科图像分析中的应用研究，特别关注数据集和模型的两个方面，详细分析了相关的网络架构、优化策略、训练方法和性能指标，并总结了最新的挑战和未来的潜在方向。这为研究人员提供了全面且系统的参考文献，并且所有补充材料将在GitHub上公开共享，具有创新性地填补了该领域的研究空白。", "conclusion": "文章总结了当前深度学习在牙科图像分析中的研究现状和挑战，对未来方向进行了展望，并希望该研究能够为该领域的研究人员提供重要的参考。所有补充材料和详细的比较表将在GitHub上公开提供。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20653", "html_url": "https://arxiv.org/abs/2510.20653", "title": "寻找最优平衡点：推理时LSTM自我反思在质量、成本和速度之间的权衡", "title_en": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During Inference-Time LLM Reflection", "authors": "Jack Butler,Nikita Kozodoi,Zainab Afolabi,Brian Tyacke,Gaiar Baimuratov", "background": "随着大型语言模型（LLMs）的不断演进，实践者在不重新训练模型的情况下，有了更多选项来提高推理时的表现，包括预算调整和多步技术（例如自我反思）。这些方法虽然提高了输出质量，但也带来了准确率、成本和延迟之间的复杂权衡，这些权衡尚未在不同的应用场景中得到充分理解。本文系统地比较了在数学推理和翻译任务中，自我反思与预算调整的效果。", "innovation": "本文首次系统地比较了自我反思和预算调整在这两类任务上的表现，并且评估了不同配置下的效果，使用多种模型和不同的自省深度及计算预算，确定了帕累托最优性能前沿。此外，研究还探讨了不同模型系列中的自省轮数深度和反馈机制质量对性能的影响。", "conclusion": "研究结果表明不同领域的自省效果存在明显差异，数学推理中有高达220%的性能提升。自省轮数深度和反馈机制质量对模型性能有显著影响。在实际应用中，例如Zalando Lounge的一个市场本地化系统中，自省增强的内容本地化系统的部署证实了这种差异性，强调了在部署这些技术时需要进行领域特定评估的重要性。这些结果提供了选择最优推理策略的具体指导，并开放源代码供进一步研究和验证。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20677", "html_url": "https://arxiv.org/abs/2510.20677", "title": "R2-SVC: 向现实世界的稳健且富有表现力的零样本歌唱语音转换", "title_en": "R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice Conversion", "authors": "Junjie Zheng,Gongyu Chen,Chaofan Ding,Zihao Chen", "background": "在实际应用中的歌唱声音转换（SVC）中，环境噪音和情感表达的需求构成了重大挑战。传统的SVC方法通常没有考虑到实际部署场景，因为训练和推断大多依赖于干净的数据。这种脱节限制了其实用性，因为不可避免地存在多种噪音源和音乐分离造成的艺术缺陷。为了应对这些问题，我们提出了一种稳健且富有表现力的SVC框架R2-SVC。", "innovation": "首先，我们通过随机基础音高（F0）扰动和音乐分离艺术模拟（如 reverberation, echo）来增强模拟中的稳健性，显著提高了在嘈杂环境下的性能；其次，我们使用领域特定的歌唱数据丰富说话人的表示：除了干净的伴奏，我们还整合了DNSMOS过滤后的分离伴奏和公开的歌唱语料库，使模型既能保留说话人音色又能捕捉歌唱风格的独特之处；最后，我们整合了神经源-滤波（NSF）模型，明确表示谐波和噪声成分，增强了转换歌唱的自然性和可控性。", "conclusion": "R2-SVC 在多个SVC基准测试中实现了最先进的结果，无论是在干净还是嘈杂的环境中。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20699", "html_url": "https://arxiv.org/abs/2510.20699", "title": "金融市场波动预测中的叙事语义融合", "title_en": "Fusing Narrative Semantics for Financial Volatility Forecasting", "authors": "Yaxuan Kong,Yoontae Hwang,Marcus Kaiser,Chris Vryonides,Roel Oomen,Stefan Zohren", "background": "金融市场波动预测是风险管理中的关键问题，现有的方法通常难以统一时间序列特征和新闻数据等异构数据模态，也无法有效减少向后看偏差，这对模型的有效性构成挑战。", "innovation": "M2VN 提出了一个多模态波动网络，通过结合时间序列特征和无结构的新闻数据，并借助深度神经网络的优势来解决上述挑战。M2VN 引入了辅助对齐损失，增强了结构化和非结构化数据在深度学习架构中的融合，并使用时间机器 GPT 生成的新闻嵌入确保时间一致性。", "conclusion": "通过广泛的实验，M2VN 证明了其在实际应用中的优越性，特别是在风险管理和金融市场决策方面。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20692", "html_url": "https://arxiv.org/abs/2510.20692", "title": "探索大型语言模型在访问控制策略合成与总结中的应用", "title_en": "Exploring Large Language Models for Access Control Policy Synthesis and Summarization", "authors": "Adarsh Vatsa,Bethel Hall,William Eiers", "background": "云计算服务日益增多，现有云计算系统允许管理员通过编写策略来实现访问控制，但这些策略往往需要手工编写且复杂，容易出错。此外，由于现有策略通常实施复杂的访问控制规范，因此很难精确分析其行为是否符合预期。近年来，大型语言模型在自动生成代码和代码总结方面表现出色，这表明它们可能用于自动生成访问控制策略或帮助理解现有策略。", "innovation": "论文探索了大型语言模型在访问控制策略合成与总结中的应用。研究发现，尽管大型语言模型能够有效地生成语法正确的策略，但是它们在生成具备权限控制策略方面的表现参差不齐，部分模型生成的策略与给定规格一致的比例较低。此外，论文提出了利用大型语言模型进行访问控制策略分析的新型语义请求总结方法，通过这种方法生成策略请求的具体描述。", "conclusion": "尽管大型语言模型在自动化策略生成方面存在一定的挑战，但在结合符号方法进行现有策略分析方面表现出良好的前景。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20683", "html_url": "https://arxiv.org/abs/2510.20683", "title": "基于脉冲神经网络的大规模、因果和节能神经解码框架", "title_en": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding with Spiking Neural Networks", "authors": "Georgios Mentzelopoulos,Ioannis Asmanis,Konrad P. Kording,Eva L. Dyer,Kostas Daniilidis,Flavia Vitale", "background": "脑-计算机接口（BCIs）有望为神经运动障碍患者恢复诸如言语和假肢控制等生命功能。其成功的关键在于神经解码器，这些模型将神经活动映射到预期行为。当前的学习解码方法可以分为两大类：简单的因果模型缺乏泛化能力，而复杂的非因果模型虽然能够泛化和在线下实现，但在实时环境中表现不佳。这两个模型都面临一个共有的挑战，即依赖于能耗高的人工神经网络作为其底层架构，这使得它们难以集成到资源有限的现实世界系统中。脉冲神经网络（SNNs）提供了一种有希望的替代方案。因为它们是因果的，这些模型适合实时使用，并且它们低能耗的特点使它们成为电池约束环境中理想的选择。\n", "innovation": "我们提出了Spikachu，一种基于SNNs的可扩展、因果和节能神经解码框架。我们的方法直接处理分桶的脉冲，通过将它们投影到共享的潜在空间，在适应输入时间的脉冲模块中提取相关特征；然后这些潜在表示被整合并解码以生成行为预测。我们在6只非人灵长类动物的113个记录会话（总计43小时记录）上评估了我们的方法。与单一会话训练的因果基线相比，我们的方法使用2.26到418.81倍更低的能耗表现出更佳性能。此外，我们还证明了多会话和多主题的训练能够提高性能，并允许在看不见的会话、主题和任务上的少量示例转移学习。\n", "conclusion": "总体而言，Spikachu引入了一种基于SNNs的可扩展、实时兼容的神经解码框架，其性能与现有的先进模型相当，但能耗则低了几个数量级。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20690", "html_url": "https://arxiv.org/abs/2510.20690", "title": "神经多样性在小型模型中正则化幻觉", "title_en": "Neural Diversity Regularizes Hallucinations in Small Models", "authors": "Kushal Chakrabarti,Nirmal Balachundhar", "background": "尽管语言模型的参数、计算和数据不断增加，它们仍然会表现出幻觉。研究表明这一点，并强调神经多样性——不相关的并行表示——作为一种减少固定参数和数据预算下幻觉率的机制是合理的。神经多样性受到投资组合理论的启发，在投资组合理论中，不相关的资产通过减少风险来提高风险阈值 √P。这表明幻觉的概率与表示的相关性有关，并预测语言模型需要一种最优的神经多样性水平。这种方法需要综合并验证神经多样性对幻觉减少的效果。", "innovation": "提出了一种名为ND-LoRA（神经多样性低秩适应）的新方法，结合了平行LoRA适配器和Barlow Twins正则化，从而减少了幻觉的出现，同时并未降低一般精度。实验证明，LoRA适配器和正则化作用互补，因果干预表明神经多样性是中间因素，并通过相关性分析发现规模效应：神经相关性增加0.1%会导致幻觉增加3.8%。任务依赖的最优性也出现了：不同的任务需要不同量的最优神经多样性", "conclusion": "我们的结果强调神经多样性作为一个第三个缩放轴——与参数和数据正交——在固定预算下提高语言模型的可靠性的价值。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20718", "html_url": "https://arxiv.org/abs/2510.20718", "title": "多变量半导体工艺时间序列中的无监督异常预测方法", "title_en": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series", "authors": "Daniel Sorensen,Bappaditya Dey,Minjin Hwang,Sandip Halder", "background": "半导体制造是一个极其复杂且精度驱动的过程，涉及数千个相互关联的参数，这些参数跨越多种工具和工艺步骤。多元时间序列分析已成为此类环境实时监控和故障检测的关键领域。然而，半导体制造中的异常预测面临多个挑战，包括传感器数据的高维度性和由于真实故障罕见而引起的严重类别不平衡。此外，变量之间的复杂关联性使得异常预测和根本原因分析更加复杂。", "innovation": "本文提出了一种新的异常预测框架，包括两种新的方法，分别使用N-BEATS模型和Graph Neural Network (GNN)。该框架分为两个主要阶段：首先在假设数据集中没有异常的情况下训练一个预测模型；其次对未见过的时间序列数据进行预测，并将其与训练信号的预测进行比较。偏离预定义阈值的被视为异常。这两种方法的区别在于所使用的预测模型。第一种方法假设变量之间独立，利用N-BEATS模型进行单变量时间序列预测；第二种方法通过利用GNN捕捉变量之间的关系，取消了变量独立的假设。结果表明，尽管GNN在可训练参数数量和计算成本方面远低于N-BEATS模型，但在预见性和生成稳定异常预测方面表现更好。", "conclusion": "GNN（图神经网络）被认为是一种在线异常预测的有前途的解决方案，可以部署在制造环境中，为进一步实现实时过程纠正和预防性故障预防提供了可能。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20733", "html_url": "https://arxiv.org/abs/2510.20733", "title": "多智能体合作中的心灵感应通信", "title_en": "Thought Communication in Multiagent Collaboration", "authors": "Yujia Zheng,Zhuokai Zhao,Zijian Li,Yaqi Xie,Mingze Gao,Lizhu Zhang,Kun Zhang", "background": "自然语言虽然支持人类的合作，但由于其易失性、歧义性和间接性，限制了集体智能的潜力。尽管机器不受这些限制，目前大多数基于大语言模型的多智能体系统仍然只能依赖自然语言进行交互，通过交换文本令牌或其嵌入实现。该研究提出了一种新的范式——心灵感应通信，使智能体可以直接进行心灵感应式交互，类似于心灵传话。通过形式化这一过程，作者将该交互过程视为一种通用潜在变量模型，通过未知函数生成代理状态。", "innovation": "作者提出了心灵感应通信这一新的范式，其特点是可以使智能体直接进行心灵感应式交互，而无需依赖自然语言。作者引入了一种新的模型，通过这个模型揭示出智能体背后的潜在思想，并在此基础上开发了提取智能体潜在思想的框架。同时，该研究证明了即使在没有辅助信息的情况下，智能体之间的共享和私人潜在思想可以被识别，并可以重建其共享结构，保证了理论上的可实现性。", "conclusion": "该研究通过开发的理论和框架，能够在智能体通信前提取潜在思想，并为每个智能体分配相关的思想及其分享模式。这些结论被实验验证，表明了心灵感应通信可以提升协作的效率。作者认为这种范式不仅适用于大语言模型，也适用于其他模态，具有广泛的影响。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20721", "html_url": "https://arxiv.org/abs/2510.20721", "title": "用户对隐私保护和帮助性在大型语言模型对敏感隐私场景响应中的感知", "title_en": "User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios", "authors": "Xiaoyuan Wu,Roshni Kaushik,Wenkai Li,Lujo Bauer,Koichi Onoue", "background": "大型语言模型（LLMs）在撰写电子邮件、总结会议和回答健康问题等方面的应用迅速增长。在这些应用中，用户可能需要分享私人信息（如健康记录、联系方式）。为评估LLMs对保护私人信息的能力，已有研究制定了诸如ConfAIde、PrivacyLens等基准测试。使用这些基准测试，研究者发现LLMs在回答复杂任务时有时会泄露私人信息，但这些评估仍然依赖于代理LLMs来衡量是否符合隐私规范，忽略了真实用户的意见。过去的研究主要集中在LLMs响应的隐私保护质量上，而没有调查这些响应在帮助性方面的细微差别。", "innovation": "本研究通过让用户对来自PrivacyLens的90个敏感隐私场景下LLMs的回应进行评估，研究发现用户在评估同一场景下LLMs回应的隐私保护质量和帮助性方面存在低一致性。此外，五个代理LLMs之间存在高一致性，但每个个体LLM与用户评估的相关性却很低。这些结果表明，LLMs的隐私保护和帮助性通常针对个体，而代理LLMs可能不是真实用户对此类响应感知的良好估计。本研究强调了需要进行用户导向的研究以测量LLMs在同时保护隐私和帮助用户方面的能力。未来研究还可以探索改进代理LLMs与用户之间的一致性，从而更好地估计用户感知的隐私和实用性。", "conclusion": "研究结果表明，LLMs的隐私和帮助性往往因个体而异，代理LLMs不能很好地预测真实用户在这种敏感隐私情境下的感知。未来研究需要进行用户导向的研究，以衡量LLMs在同时保护隐私和帮助用户方面的能力，并找到改进代理LLMs与用户一致性的方法，以更好地估计用户感知的隐私和实用性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20706", "html_url": "https://arxiv.org/abs/2510.20706", "title": "使用模型预测控制和强化学习的四足动物实时步态适应", "title_en": "Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning", "authors": "Ganga Nair B,Prakrut Kotecha,Shishir Kolathaya", "background": "无模型的强化学习使四足行走更加适应和灵活；然而，策略往往收敛于单一的步态，导致性能不足。传统上，模型预测控制（MPC）被广泛用于获得特定任务的最佳策略，但缺乏适应环境变化的能力。", "innovation": "提出了一个优化框架，用于实时步态适应连续的步态空间，结合模型预测路径积分（MPPI）算法和Dreamer模块，以产生适应性和最优的四足行走策略。该框架在每个时间步骤中同时优化动作和步态变量，利用一个通过学习得到的Dreamer奖励来促进速度跟踪、能效、稳定性和平滑过渡，同时惩罚突然的步态变化。通过引入一个学习到的价值函数作为终端奖励，扩展了此框架到无限时间规划。", "conclusion": "此框架通过为Unitree Go1进行仿真评估，证明了在不同目标速度下平均能效消耗减少了高达36.48%，同时保持了精确的跟踪和适应性、任务适应性的步态。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20768", "html_url": "https://arxiv.org/abs/2510.20768", "title": "RAGRank：使用PageRank对策CTI LLM流水线中的中毒", "title_en": "RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines", "authors": "Austin Jia,Avaneesh Ramesh,Zain Shamsi,Daniel Zhang,Alex Liu", "background": "检索增强生成（RAG）已经成为在网络威胁情报（CTI）系统中操作大型语言模型（LLM）使用的主导架构模式。然而，这种设计容易受到投毒攻击，现有的防御措施可能在CTI场景下失败，因为网络威胁信息往往来自新兴攻击，且更复杂的威胁行为者能够模仿合法的格式、术语和风格惯例。", "innovation": "论文提出了一种通过在语料库上应用源信誉算法（以PageRank为例）来加速现代RAG防御机制的鲁棒性。作者展示了其算法在定量实验中降低恶意文档的权威评分，同时提升可信内容的评分，并验证了算法在CTI文档和流中的概念验证性能。", "conclusion": "研究在量化实验中证明了算法的有效性，并展示了其在CTI文档和流中概念验证的性能，表明通过使用PageRank等源信誉算法可以显著提高RAG在面对投毒攻击时的鲁棒性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20727", "html_url": "https://arxiv.org/abs/2510.20727", "title": "使用自然语言处理从临床笔记中自动提取氟尿嘧啶治疗及治疗相关毒性", "title_en": "Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing", "authors": "Xizhi Wu,Madeline S. Kreider,Philip E. Empey,Chenyu Li,Yanshan Wang", "background": "氟尿嘧啶类药物被广泛用于结肠癌和乳腺癌等癌症治疗，但这些药物常引起手足综合征和心脏毒性等不良反应。由于毒性信息往往嵌入在临床记录中，因此本文旨在开发和评估自然语言处理（NLP）技术来提取治疗和毒性信息。研究团队构建了包含236份临床记录的数据集，从204,165名成年肿瘤患者中得出，并由领域专家分类标注了治疗方案和毒性的相关类别。研究采用了基于规则、机器学习（随机森林、支持向量机和支持向量回归、逻辑回归）、深度学习（BERT、临床BERT）以及大规模语言模型的方法。研究通过80:20的训练测试集比例来训练模型，并针对不同方法进行了评估和比较。从评估结果来看，零样本提示法和错误分析提示法能够有效提高治疗和毒性信息提取的精确度和召回率，而基于大规模语言模型的方法在处理复杂且未知的毒性信息时表现更为出色，分别在治疗和毒性信息提取上达到了最佳的F1分数。机器学习和深度学习方法由于训练数据量少，难以进行泛化，特别是对于稀有类别的信息处理更为受限。与其他方法相比，基于规则的方法为性能较低，但在治疗和毒性信息提取上仍然有一定表现。", "innovation": "研究团队创新地使用了零样本提示和错误分析提示方法来进一步增强NLP模型的效果，特别是对于治疗和毒性信息的准确提取。同时，基于大规模语言模型的方法表现尤为突出，这得益于它们在处理复杂性和未知性方面的能力。机器学习和深度学习方法在小数据集上表现受限，而大规模语言模型则展现出更强的泛化能力。文中着重探讨了不同类型模型在处理氟尿嘧啶治疗及治疗相关毒性信息提取时的不同表现，并为进一步的研究指明了方向。", "conclusion": "基于大规模语言模型的自然语言处理方法最有效地从临床笔记中提取氟尿嘧啶治疗及治疗相关毒性信息，并且具有较强的研究支持和药监用途潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20743", "html_url": "https://arxiv.org/abs/2510.20743", "title": "同情提示：多模态LLM对话中的非言语背景整合", "title_en": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM Conversations", "authors": "Lorenzo Stacchio,Andrea Ubaldi,Alessandro Galdelli,Maurizio Mauri,Emanuele Frontoni,Andrea Gaggioli", "background": "当前，大型语言模型（LLM）在对话中主要依赖于文本输入，缺乏对用户非言语情感线索的捕捉和利用。现有的多模态界面通常需要用户明确控制非言语信息的输入，这可能会破坏用户交互的自然流畅性。该研究旨在通过引入一种新的框架来解决这一问题，即Empathic Prompting，能够将用户的非言语情感线索隐式地融入到LLM对话中，从而提高对话的自然流畅性和用户满意度。", "innovation": "Empathic Prompting 提出了一种新颖的框架，通过集成商业面部表情识别服务来捕捉用户的情感线索，并将这些线索作为上下文信号融入到对话中。该框架具有模块化和可扩展性，可以整合额外的非言语模块，使AI模拟更多的人类交流特点。研究通过本地部署的DeepSeek实例实现并进行了初步的服务和可用性评估，表明该方法能够一致地将非言语输入整合到LLM输出中，同时提高了对话的流畅性。该方法特别适用于医疗或教育等需要捕捉用户情感但这些情感常难以通过言语明确传达的领域。", "conclusion": "Empathic Prompting 代表了一种创新的方法，能够通过非言语上下文的丰富，提高多模态LLM对话的质量。初步研究表明，这种方法在改进聊天机器人介导的对话流畅性和自然性方面具有巨大潜力，特别是在医疗和教育等特定领域有着重要的应用前景。未来的工作可以通过进一步优化算法和增加更多的非言语模块来提高系统的性能。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20780", "html_url": "https://arxiv.org/abs/2510.20780", "title": "大型推理模型适合作为翻译评估器吗？分析与性能提升", "title_en": "Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost", "authors": "Runzhe Zhan,Zhihong Huang,Xinyi Yang,Lidia S. Chao,Min Yang,Derek F. Wong", "background": "近期大型推理模型（LRMs）的发展引入了一个中间的“思考”过程，这一过程在生成最终答案之前进行，提升了其在复杂下游任务上的推理能力。然而，LRMs作为机器翻译（MT）质量评估器的潜力尚未得到充分探索。这项研究首次系统地分析了LRMs在MT评估中的应用，指出了几个关键挑战，并提出了通过训练LRMs来模拟人类思考轨迹的方法来解决这些问题。", "innovation": "研究提出了通过训练LRMs采用合成、类人思考轨迹来校准它们的思考过程的方法。实验表明，这种方法能大幅度降低成本（约35倍），同时提升不同规模LRMs（如R1-Distill-Qwen-7B）的评估性能（例如提高了8.7个相关性分数）。这一发现突显了高效校准的LRMs在推进精细自动MT评估中的潜力。", "conclusion": "这项研究揭示了LRMs在MT评估中的一些关键挑战，并提出了一种通过训练模型模拟人类思考路径来优化其评估性能的方法。实验结果表明，这不仅能够大幅度降低计算成本，还能够提升多种规模LRMs的评估性能，展示了高效校准的LRMs在提升MT评估精度方面的巨大潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20782", "html_url": "https://arxiv.org/abs/2510.20782", "title": "针对LLM生成文本负责任表现维度的特定用途数据集", "title_en": "A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text", "authors": "Alicia Sagae,Chia-Jung Lee,Sandeep Avula,Brandon Dang,Vanessa Murdock", "background": "当前评估大型语言模型（LLMs）的方法通常侧重于高层任务，如文本生成，并不专门针对特定的AI应用场景。这种评估方法不足以评估在负责任AI维度（如公平性）上的性能，因为受保护属性在某一应用场景中非常相关，在另一场景中可能不那么相关。", "innovation": "本文构建了一个由真实世界应用驱动的数据集，通过公平属性与性别化形容词及产品类别相交，生成了大量的带标注提示。基于此数据集，结果能够识别LLMs在质量、真实性、安全性和公平性方面的差距，并提出了一项针对LLMs评估的建议，同时提供了用于研究社区的资源。", "conclusion": "本文通过对LLMs生成文本的负责任表现维度进行测量，提供了一个特定用途的数据集，帮助识别现有的评估差距，为研究社区提供了资源和评估建议。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20797", "html_url": "https://arxiv.org/abs/2510.20797", "title": "简单的上下文压缩：均值池化和多比例训练", "title_en": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training", "authors": "Yair Feldman,Yoav Artzi", "background": "在使用长上下文的检索增强生成（RAG）过程中，使用大型语言模型（LLMs）时通常会增加计算成本。一种常用策略是软上下文压缩，即通过变换输入序列生成一个较短连续表示来降低计算成本。", "innovation": "开发了一种轻量且简单的均值池化方法，该方法在多个上下文压缩比训练的情况下，持续优于广泛使用的压缩标记架构。并研究了训练相同的压缩器以输出多个压缩比例的方法。", "conclusion": "整体而言，简单的均值池化方法取得了最佳性能，即使在训练多个压缩比例的情况下，性能下降也较为轻微。但总体上，不同架构和训练策略之间需要权衡的问题更为复杂，这表明压缩技术的复杂性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20728", "html_url": "https://arxiv.org/abs/2510.20728", "title": "利用多智能体系统设计具有横向对角门的量子码", "title_en": "Co-Designing Quantum Codes with Transversal Diagonal Gates via Multi-Agent Systems", "authors": "Xi He,Sirui Lu,Bei Zeng", "background": "该研究基于Subset-Sum线性编程（SSLP）框架，提升了针对指定横向对角门设计量子码的工作流程。先前的方法已成功地通过SSLP框架来划分基字符串，并利用小型线性规划解决子问题来确保$Z$-边缘Knill-Laflamme（KL）等式。研究在一个支持迭代工具使用循环智能体和推理编辑流程智能体的TeXRA平台上开展。研究者使用LaTeX-Python环境进行问题建模、代码执行和文档编辑，并借助Git/Overleaf同步工作成果。研究最初专注于距离$d=2$，并探索了$q\text{ubit} \text{} n \text{} \text{} \text{} \text{} \textle6$及代码维度$K\text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{} \text{le}4$的量子码。该研究通过系统筛选和精确化数值，生成可验证的代码表，并在分析中证明这些代码满足KL等式。此外，该研究发现了一种新的代码，能够在距离2和4-qubit时实现横向控制相位门$diag(1,1,1,i)$。总的来说，研究工作将对角化与横向可行性转化为可大规模分析的结构化管线，结合系统遍历方法和精确的分析重建。这些方法使得量子码的系统化构造变得可以重现，为更大规模的$K$及更高距离提供了精确基于数据的方法论指导，逐步推进数据驱动的分类实现。", "innovation": "该研究提出了一种多智能体、人类在环的工作流程，用于协同设计具有指定横向对角门的量子码。这是通过扩展SSLP框架实现的，该框架能够通过小型线性规划解决子问题来处理$Z$-边缘KL等式，并且能够在不进行退化到单一解的情况下处理模块残留。研究开发了一种多智能体协作平台TeXRA，其中不同的智能体（合成智能体、搜索智能体和审计智能体）分别负责问题构建、候选筛选、具体化数字和独立验证工作。这种方法不仅提升了量子码设计的系统性和准确性，还为未来的研究提供了系统化和可重复性的基础。", "conclusion": "通过多智能体系统的应用，该研究成功地设计了具有横向对角门的量子码，并提出了系统的筛选和精确化的策略。基于TLTEX工作平台，该研究不仅实现了可验证的代码构造，还证明了这些代码符合所需的KL等式，并且还发现了一个新的代码实例。研究认为，通过这种方法，量子码的设计可以转化为一个分析性的管线，结合系统遍历和精确化的重建。这种多智能体合作的方法为更大大小量化体以及更高的距离提供了新的可能性，并且推动了基于数据的分类方法的发展。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20808", "html_url": "https://arxiv.org/abs/2510.20808", "title": "机器人中的现实差距：挑战、解决方案和最佳实践", "title_en": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices", "authors": "Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos", "background": "机器学习在多个机器人领域取得了显著进步，包括导航、移动和操作。然而，仿真过程中存在的简化和近似不可避免地导致了模拟环境与真实环境之间的差距，即现实差距。这个差距严重阻碍了仿真到现实世界的应用转换。尽管已有一些进展，但理解现实差距的根本原因以及寻找解决方案仍是一项亟待解决的挑战。", "innovation": "综述了仿真到现实世界的转换场景，总结了现实差距的原因、解决方案及评估标准，并探讨了领域随机化、现实到仿真转换、状态和动作抽象以及仿真与现实共同训练等技术。", "conclusion": "本文从全面概述仿真到实际应用之间的转换现状出发，强调了现实差距的根本原因、怎么应对以及如何评估这一差距，旨在提升对现实差距的理解，推动仿真与现实世界之间更好的转换。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20795", "html_url": "https://arxiv.org/abs/2510.20795", "title": "使用球面图神经网络从CMB推断原始磁场参数的贝叶斯推断", "title_en": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with Spherical Graph Neural Networks", "authors": "Juan Alejandro Pinto Castro,Héctor J. Hortúa,Jorge Enrique García-Farieta,Roger Anderson Hurtado", "background": "深度学习已经成为了现代 cosmology 中的一种革命性方法，提供了一种强大的工具从复杂的天文学数据集中提取有意义的物理信息。本文采用了一种新颖的贝叶斯图形深度学习框架，直接从模拟的宇宙微波背景(CMB)图中估计包含原始磁场(PMF)的宇宙模型中的关键宇宙参数。方法利用了DeepSphere，这是一种专门为尊重CMB数据的球形几何特性而设计的球形卷积神经网络架构，通过HEALPix像素化技术实现。为了超越确定性的点估计，并实现稳健的不确定性量化，本文将贝叶斯神经网络(BNNs)融入了框架中，捕捉模型预测中的aleatoric和epistemic不确定性，反映了模型对其预测的信心水平。这种方法在磁场参数估计中表现出色，$R^{2}$得分超过了0.89。通过后训练技术，包括变异尺度和GPNormal，我们还获得了可靠的不确定性估计。该集成的DeepSphere-BNNs框架不仅能够从包含PMF贡献的CMB图中准确估计参数，还能提供可靠的不确定性量化，为精确cosmology时代的稳健cosmological推理提供了必要的工具。", "innovation": "本文提出了一种新颖的贝叶斯图形深度学习框架，结合了贝叶斯神经网络（BNNs），用于直接从模拟的CMB图中估计PMF的宇宙学参数。这种方法不仅实现了准确的参数估计，而且还提供了可靠的不确定性量化，尤其是通过后训练技术实现了aleatoric和epistemic不确定性捕捉，提高了模型预测的可信度。", "conclusion": "本文整合了DeepSphere-BNNs框架，不仅能够准确从包含PMF贡献的CMB图中估计宇宙学参数，还能提供可信的不确定性量化，为精准宇宙学时期的稳健cosmological推理提供了强有力的工具。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20800", "html_url": "https://arxiv.org/abs/2510.20800", "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "title_en": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "authors": "Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus", "background": "近期，Sharma等人提出了一种称为Layer-SELectional-Rank reduction（LASER）的方法，该方法表明，通过精心选择计算权重矩阵中的高阶成分并剪枝，可以提升下游任务的准确性，而无需基于梯度的微调。然而，LASER在每个矩阵上进行耗时的搜索（每个都要求完整的数据前向传播）使得它在快速部署时变得不切实际。", "innovation": "研究团队通过去除这一搜索开销并发现：(i) 只需检查一小部分精心选择的矩阵；(ii) 每个矩阵奇异值的梯度可以指示哪些矩阵值得进行剪枝；(iii) 允许矩阵行围绕多个子空间群集并独立分解每个群集可以进一步减少过拟合并提高准确性最多24.6个百分点；(iv) 在测试阶段仅使用100个样本而非完整训练数据来计算指示性梯度和测量最终准确度，可以进一步减少搜索时间，原因是下游任务的适应主要由提示风格决定而不是数据集大小。", "conclusion": "结合这些发现，我们展示了一种快速且稳健的下游任务适应算法，利用单个梯步和快速扫描顶级候选层及分解技术，使大模型能够快速适应新的数据集，而无需微调。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20810", "html_url": "https://arxiv.org/abs/2510.20810", "title": "LLM生成文本的可检测性：什么是真正的LLM生成文本？", "title_en": "On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?", "authors": "Mingmeng Geng,Thierry Poibeau", "background": "随着大规模语言模型（LLMs）的广泛应用，许多研究人员开始关注如何检测由它们生成的文本。然而，对于‘LLM生成文本’这一目标缺乏一个一致且精确的定义，不同使用场景和LLM多样性进一步增加了检测难度。常见的检测目标通常仅代表LLMs可能产生的文本的一部分。通过人类对LLM输出进行编辑，以及LLM对用户的微妙影响，使得区分LLM生成和人类编写的文本变得模糊。现有的基准和评估方法未能充分考虑实际应用中的各种条件，导致检测器的数值结果经常被误解，其意义也在降低。因此，只有在特定情况下，检测器仍然有用，但它们的结果应被视为参考而非决定性指标。", "innovation": "本文探讨了LLM生成文本的模糊性及其对检测器效果的影响，提出了对现有定义和评价方法的批判，并强调了在特定条件下的检测器应用价值。", "conclusion": "虽然现有的检测器在特定条件下仍然有用，但它们的结果需要谨慎解读，不应被视为决定性的指标。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20812", "html_url": "https://arxiv.org/abs/2510.20812", "title": "小型草稿，大型裁决：利用推测进行密集信息视觉推理", "title_en": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation", "authors": "Yuhan Liu,Lianhui Qin,Shengjie Wang", "background": "大量视觉-语言模型（VLMs）在多模态理解方面取得了显著进步，但在推理密集类型的信息图、包含文本注释和细粒度图形元素的复杂图像时存在挑战。主要挑战在于在密集布局中精确定位关键线索以及进行多跳推理以整合分散的证据。", "innovation": "提出了基于推测解码的无训练框架Speculative Verdict (SV)，该框架结合了多个轻量级草稿专家和一个大型裁决模型。在草稿阶段，小型VLM作为草稿专家生成多样化的推理路径；在裁决阶段，一个强大的VLM综合这些路径生成最终答案，同时降低成本并保证正确的答案。此外，引入了一种共识专家选择机制，仅将高一致性的推理路径传递给裁决过程，以进一步提高效率和准确性。", "conclusion": "实验结果表明，SV在InfographicVQA、ChartMuseum、ChartQAPro和HR-Bench 4K等具有挑战性的密集信息和高分辨率视觉问答基准测试中取得了持续的收益。通过综合多个部分准确的推理路径中的正确洞察，SV在错误纠正和成本效率方面优于大型专有模型或训练管道。相关代码可通过以下链接获得：this https URL"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20774", "html_url": "https://arxiv.org/abs/2510.20774", "title": "FieldGen: 从预先操作轨迹到场导向数据生成", "title_en": "FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation", "authors": "Wenhao Wang,Kehe Ye,Xinyu Zhou,Tianxing Chen,Cao Min,Qiaoming Zhu,Xiaokang Yang,Yongjian Shen,Yang Yang,Maoqing Yao,Yao Mu", "background": "现有的数据收集方法难以平衡大规模、多样性和高质量之间，而在模拟中虽然具有可扩展性但存在模拟与现实之间的差距，在远程操作中虽然可以获得高质量的演示，但存在多样性和高人力成本的问题。因此，需要一个可以生成大规模、多样化且高质量真实世界数据的框架，同时减少人工监督的复杂性。", "innovation": "引入了一个名为FieldGen的场导向数据生成框架，该框架将机械手操作分为两个阶段，前后两个阶段分别为增加轨迹多样性和提高精度。通过人类演示捕捉关键接触和姿态信息，然后利用吸引场自动生成多元化的轨迹并收敛到成功配置。此外，FieldGen-Reward还可以增强生成数据中的奖励标注，进一步提高策略学习的效果。实验结果表明，使用FieldGen训练的策略在成功率和稳定性方面优于遥操作基准策略，同时显著减少了长期真实世界数据收集所需的人力投入。", "conclusion": "通过FieldGen框架，实现了大规模、多样化且高质量的实时数据收集，同时减少了人工监督的需求，大大提高了机械手操作策略的训练效率和效果。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20818", "html_url": "https://arxiv.org/abs/2510.20818", "title": "VAMOS:一种基于视觉-语言-动作的层次模型支持能力调节和可操控导航", "title_en": "VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation", "authors": "Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta", "background": "机器人导航的基本挑战在于学习能够在多种环境之间泛化的策略，同时还要遵守特定实体的独特物理约束和能力（例如，四足机器人能够上台阶，但轮式机器人不能）。过往的研究方法要么是基于模型的，要么是端到端的学习方法，两者都无法较好地解决这一问题。", "innovation": "本文提出了一种名为VAMOS的层次视觉-语言-动作(VLA)模型。该模型将语义规划与物理实体的实现分离开来：通用规划者学习来自多样且开放世界的数据，而专门的执行模型则在安全且低开销的模拟中学习机器人的物理约束和能力。设计的接口允许高级规划者直接在图像空间中提出候选路径，这些路径由执行模型评估并重新排名。实验结果表明，VAMOS在室内和复杂户外导航中的成功率高于现有的基于模型的和端到端学习方法。该层化设计能够跨越不同类型的机器人（如腿式和轮式机器人）的导航，并且可以通过自然语言轻松控制。", "conclusion": "VAMOS通过分层设计实现跨不同机械结构的导航。保护主义模型对物理实体的理解对于规划器在不同物理差异的轮式机器人和腿式机器人之间进行应用至关重要。此外，该模型显著提高了单个机器人导航的可靠性，成功率达到三倍的提升。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20813", "html_url": "https://arxiv.org/abs/2510.20813", "title": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation", "title_en": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation", "authors": "Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang", "background": "本文介绍了一个名为GSWorld的机器人操纵仿真器，该仿真器结合了3D Gaussian Splatting和物理引擎，用于增强现实机器人操作能力。该论文旨在解决在真实机器人训练机器人策略时面临的挑战，提出了一种闭环开发策略，即通过重现从真实机器人数据中学习的策略评估和无需使用真实机器人进行sim2real策略训练。为了实现多样的照片级真实渲染效果，论文提出了一种新的资产格式（GSDF，Gaussian Scene Description File），该格式将Gaussian-on-Mesh表示与机器人URDF和其他对象相结合。该论文通过设置重建流水线，创建了一个包含3个单臂和双臂操作机器人实体以及超过40个对象的GSDF数据库，进而展示了GSDF与物理引擎结合的各种即时有趣的应用场景，包括零样本模拟到真实图像像素到动作策略学习等。", "innovation": "这篇论文的创新在于提出了GSWorld，一个结合了3D Gaussian Splatting和物理引擎的机器人操纵仿真器，支持闭环开发策略，通过照片级真实渲染实现了多种应用，包括零样本sim2real策略学习、高质量的数据采集、实时策略基准测试和虚拟遥操作数据收集等。论文还提出了一种新的资产格式GSDF，能更好地支持多种场景的建模。", "conclusion": "该研究展示了GSWorld在机器人操纵仿真中的强大功能和广泛应用场景，为高保真、低成本的机器人操纵策略开发提供了新的工具。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20748", "html_url": "https://arxiv.org/abs/2510.20748", "title": "强化学习与消费储蓄行为", "title_en": "Reinforcement Learning and Consumption-Savings Behavior", "authors": "Brandon Kaplowitz", "background": "本文展示了强化学习如何解释经济衰退期间家庭消费行为中的两个令人困惑的实证模式。研究构建了一个模型，使得代理人在收入不确定性条件下使用基于神经网络近似的Q学习来作出消费储蓄决策，从而偏离标准理性预期假设。该模型再现了最近文献中的两个关键发现：失业家庭在之前拥有较低流动性资产的情况下，在收到刺激转移支付时的边际消费倾向（MPC）远高于拥有较高资产的家庭（0.50 vs 0.34），尽管两组家庭均未面临借贷限制，这与Ganong等人的（2024）发现一致；以及具有更多失业历史的家庭在控制当前经济状况后仍持续保持较低的消费水平，这与Malmendier和Shen（2024）所记录的“伤痕效应”一致。", "innovation": "不同于基于对未来收入风险信念更新或事前异质性的现有解释，强化学习机制通过随经验变化的价值函数近似误差同时产生较高的MPC和较低的消费水平。模拟结果显示这一机制接近实际估计值，表明通过强化学习的适应性学习机制提供了一个统一框架，能够解释过去经历如何在超出当前经济状况预测的情况下塑造当前的消费行为。", "conclusion": "强化学习机制能够解释过去经历如何在超出当前经济状况预测的情况下塑造当前消费行为，为理解经济衰退期间的家庭消费行为提供了新的解释框架。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20819", "html_url": "https://arxiv.org/abs/2510.20819", "title": "对比和预测潜在扩散桥梁以实现通用模态翻译", "title_en": "Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge", "authors": "Nimrod Berman,Omkar Joglekar,Eitan Kosman,Dotan Di Castro,Omri Azencot", "background": "近年来生成模型的发展将扩散模型定位为从复杂数据分布中采样的先进工具。尽管这些模型在单一模态领域，如图像和音频方面取得了显著的成功，但将它们的能力扩展到模态翻译（MT），即在不同感官模态之间进行信息转换，仍然是一个开放的挑战。现有方法往往依赖于诸如共享维度、高斯先验和特定模态的架构等限制性假设，这限制了它们的通用性和理论基础。", "innovation": "本文提出了一种基于潜在扩散桥模型的潜在变量扩展的模态翻译通用框架——Latent Denoising Diffusion Bridge Model (LDDBM)。通过在共享的潜在空间中操作，该方法能够无需对齐维度即可学习任意模态之间的桥梁，并引入对比对齐损失以确保样本之间语义一致。同时，设计了一种跨域翻译导向的编码器-解码器架构，并提出了一种预测损失来引导训练以实现精确的跨域翻译。此外，还探索了多种训练策略以提高稳定性。", "conclusion": "我们的方法支持任意模态对，对多视图到3D形状生成、图像超分辨率和多视图场景合成等多样化的MT任务表现强劲。全面的实验和消融研究表明，我们的框架在通用模态翻译中建立了新的强基线。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.12977", "html_url": "https://arxiv.org/abs/2411.12977", "title": "MindForge: 为长生命周期文化学习赋能具身代理的知识理论", "title_en": "MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning", "authors": "Mircea Lică,Ojas Shirekar,Baptiste Colle,Chirag Raman", "background": "基于大语言模型（LLMs）的具身代理，如Voyager，在像Minecraft这样的世界中展现出开放性的能力。然而，这些代理在执行特定领域任务时依然受挫。这项研究探讨了当使用预训练的LLMs时，具身代理在基本任务中的表现问题，并提出了MindForge框架，通过明确的知识理论、自然的多代理沟通及多层次记忆系统来促进长生命周期的文化学习。研究在Minecraft环境中测试了MindForge代理，验证了其超越Voyager代理的能力，并且展示了在协作环境下代理如何通过增加沟通轮次来提升表现，从而解决复杂问题并适应新的任务环境。", "innovation": "1. 结构化的知识理论表示，将感知、信念、欲望与行动联系起来；\n2. 天然的多代理间沟通；\n3. 多成分的记忆系统。", "conclusion": "在Minecraft的指导下，MindForge代理相较于Voyager代理在基本任务上表现更好，同时在完全协作的环境中通过增加沟通轮次来提升代理表现，展示了复杂知识转移、协作解决问题及适应新任务环境的高级行为。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.13837", "html_url": "https://arxiv.org/abs/2504.13837", "title": "RL是否真正激励LLMs的基础模型之外的推理能力？", "title_en": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?", "authors": "Yang Yue,Zhiqi Chen,Rui Lu,Andrew Zhao,Zhaokai Wang,Yang Yue,Shiji Song,Gao Huang", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 近期在增强语言模型（LLMs）的推理性能上取得了显著成效，特别是在数学和编程任务上。RLVR被认为能使LLMs不断自我提升，获得超出基础模型的新推理能力。本文通过系统地探究训练有素的RLVR LLM的不同模型家族、RL算法和数学、编码和视觉推理基准上的推理能力边界，以large k值的pass@k作为评估标准，检验了当前RLVR的状态。", "innovation": "研究使用pass@k作为评估指标，不同模型家族、RL算法和基准下的系统测试显示当前训练设置未能激发新的推理模式。尽管RLVR训练的模型在small k值表现较好，基础模型在large k值的pass@k得分更高。覆盖率和困惑度分析表明，观察到的推理能力源自基础模型并受到其限制。定量分析显示，六种流行的RLVR算法表现相似，未充分利用基础模型的潜力。相比之下，研究表明蒸馏可以从教师模型引入新的推理模式，并真正扩展模型的推理能力。", "conclusion": "当前RLVR方法尚未真正利用RL在激励LLMs产生全新推理能力方面的潜力，这表明需要改进的RL范式，如持续扩展和多轮代理-环境交互，以解锁这种潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02439", "html_url": "https://arxiv.org/abs/2505.02439", "title": "通过集成学习实现大规模多环境建筑空调控制的基于机器学习的模型预测控制", "title_en": "Towards Machine Learning-based Model Predictive Control for HVAC Control in Multi-Context Buildings at Scale via Ensemble Learning", "authors": "Yang Deng,Yaohui Liu,Rui Liang,Dafang Zhao,Donghua Xie,Ittetsu Taniguchi,Dan Wang", "background": "建筑热力学模型可以预测在潜在的HVAC操作下实时室温变化，这对于优化建筑物中的HVAC控制至关重要。尽管早期的研究已经尝试为各种建筑环境开发此类模型，但这些模型通常需要大量数据收集时间，并依赖大量专家知识，这使得建模过程效率低下并限制了模型的可重复使用。", "innovation": "本文提出了一个模型集成视角，利用现有的开发模型作为基模型来服务目标建筑环境，进而提供准确预测并减少相关努力。为了应对建筑数据流的非平稳性和基模型数量的增加，本文提出了一个分层强化学习（HRL）方法来动态选择和加权基模型。该方法采用两级决策过程：高层负责模型选择，而低层确定选择模型的权重。", "conclusion": "我们通过离线实验和现场案例研究全面评估了提出的框架，实验结果表明该方法的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15275", "html_url": "https://arxiv.org/abs/2504.15275", "title": "终止求和：过程奖励模型所需的所有最小形式的信用分配", "title_en": "Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning", "authors": "Jie Cheng,Gang Xiong,Ruixi Qiao,Lijun Li,Chao Guo,Junle Wang,Yisheng Lv,Fei-Yue Wang", "background": "过程奖励模型（PRMs）已被证明在大规模语言模型（LLMs）上扩展到具有挑战性的推理任务时非常有效。然而，PRMs的奖励作弊问题限制了它们在强化学习调优中的成功应用。研究表明，传统的强化学习（RL）中累积的伽马衰减未来奖励的形式导致LLMs为高奖励的步骤作弊。", "innovation": "本文提出了一种名为PURE的创新方法，即过程监督强化学习。PURE的关键创新是一个最小值形式的信用分配方法，将价值函数定义为未来的最小奖励。这种方法通过限制价值函数的范围和更合理地分配优势，显著缓解了奖励作弊问题。", "conclusion": "实验表明，基于PRMs且能实现最小值形式信用分配的方法在只有30%的步骤内就能达到可验证奖励方法相当的推理性能。同时，即使只是将PRMs调优与10%的可验证奖励相结合，也能进一步缓解奖励作弊，并在Qwen2.5-Math-7B中产生最佳调优模型，准确率达到82.5%的AMC23和53.3%的平均准确率。本文还总结了观察到的奖励作弊案例，并分析了训练崩溃的原因。文章在 this https URL 公开了代码和模型权重。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.09933", "html_url": "https://arxiv.org/abs/2502.09933", "title": "MIR-Bench：你的大语言模型能在多次样例推理中识别复杂模式吗？", "title_en": "MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?", "authors": "Kai Yan,Zhan Ling,Kang Liu,Yifan Yang,Ting-Han Fan,Lingfeng Shen,Zhengyin Du,Jiecao Chen", "background": "模式识别及应用能力是通用人工智能的基本能力，受到心理学和人工智能研究者的广泛研究。虽然已经提出了许多基准来衡量大型语言模型 (LLM) 的这种能力，但这些基准主要关注少量示例（通常少于10个）设置，且缺乏对从长上下文汇总大量信息的评估。另一方面，LLM 的上下文长度不断增加，引入了新的多示例在上下文学习 (ICL) 帕拉迪姆，可以通过少量输入输出示例解决涵盖数百到数千个示例的新任务，而无需昂贵且低效的微调。然而，多示例评估往往侧重于分类，而流行的长上下文 LLM 任务，如“搜索大文本中隐藏的针”（NIAH），很少需要复杂的智能来整合大量信息。为了弥补两方面的不足，本文提出了第一个针对模式识别的多示例在上下文中的推理基准MIR-Bench，要求LLM通过输入输出示例预测来自具有不同数据格式的基础函数的输出。基于MIR-Bench，我们研究了许多新的多示例在上下文推理问题，并获得了许多重要发现，包括缩放效应、鲁棒性、归纳推理 vs. 归纳推理、检索增强生成 (RAG)、编码以实现归纳推理、跨域泛化性等。", "innovation": "首先提出的多示例在上下文推理基准MIR-Bench以输入输出示例的形式要求LLM预测来自具有不同数据格式的基础函数的输出。基于MIR-Bench，研究了新的多示例在上下文推理问题，揭示了缩放效应、鲁棒性、归纳推理 vs. 归纳推理、检索增强生成 (RAG)、编码以实现归纳推理、跨域泛化性等重要发现。", "conclusion": "基于MIR-Bench，本文首次提出了一个针对模式识别的多示例在上下文中的推理基准，提供了对LLM的理解和能力评估，发现了一些新的问题和现象。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02828", "html_url": "https://arxiv.org/abs/2505.02828", "title": "Privacy Risks and Preservation Methods in Explainable Artificial Intelligence: A Scoping Review", "title_en": "Privacy Risks and Preservation Methods in Explainable Artificial Intelligence: A Scoping Review", "authors": "Sonal Allana,Mohan Kankanhalli,Rozita Dara", "background": "解释性人工智能(XAI)成为了可信赖人工智能的重要支柱，旨在提高天然不透明的复杂模型的透明度。尽管将解释纳入模型具有诸多好处，但提供这些额外信息时还存在着隐私方面的担忧。这项研究通过文献回顾来探讨隐私与解释性之间的冲突，选取了2019年1月至2024年12月间发表的1,943项研究中的57篇文章，分析了隐私风险、现有隐私保护方法以及构成隐私保护解释的特性。", "innovation": "本文通过标准的文献回顾方法，系统地总结了隐私保护解释的原则，并提出了一系列建议以平衡隐私保护与系统的其他要求，从而帮助研究人员和从业者更好地理解符合隐私合规要求的XAI的需求。", "conclusion": "本文的研究揭示了隐私保护解释的复杂关系，这两者都是可信赖人工智能的基本原则，并提供了实现隐私保护XAI的建议。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23946", "html_url": "https://arxiv.org/abs/2505.23946", "title": "所学知识：代码LLMs的学习和改进的多智能体框架", "title_en": "Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve", "authors": "Yuanzhe Liu,Ryan Deng,Tim Kaler,Xuhao Chen,Charles E. Leiserson,Yao Ma,Jie Chen", "background": "近期研究表明，LLMs在不同任务中具备不同的技能和专长。它们的表现存在多个粒度层次上的差异性。例如，在代码优化任务中，不同的代码LLMs在不同的优化类别中表现出色，没有一个模型能够完全胜过其他模型。这一发现引发了如何在不了解各个模型互补优势的情况下，利用多个LLM代理来解决编程问题的问题思考。", "innovation": "本文提出了一种基于知识传输的多智能体协作框架，旨在通过多LLM代理相互学习彼此的成功和失败，从而提升各自的表现。还设计了知识请求-存储-选择机制，并展示了即使是一个小型的LLM团队，加上从前的经验教训，也能优于大LLM以及其他多LLM协作方法。", "conclusion": "通过多智能体框架中的知识共享与学习，小型LLM团队可以通过积累和传递所学经验，克服单一模型能力限制，展现出与大模型相当甚至更好的性能。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.04210", "html_url": "https://arxiv.org/abs/2506.04210", "title": "更多思考总是有帮助吗？推理模型测试时缩放的幻觉", "title_en": "Does Thinking More always Help? Mirage of Test-Time Scaling in Reasoning Models", "authors": "Soumya Suvra Ghosal,Souradip Chakraborty,Avinash Reddy,Yifu Lu,Mengdi Wang,Dinesh Manocha,Furong Huang,Mohammad Ghavamzadeh,Amrit Singh Bedi", "background": "近年来，测试时缩放趋势在推理模型（如OpenAI的o1，DeepSeek的R1）的推理模型中得到流行，认为扩展思考痕迹可以提高性能。这种做法引发了自然的问题：测试时多思考是否真的能提升推理效果？", "innovation": "研究表明，额外的思考初期能提升性能，但随后会在“过度思考”的情况下下降。为此，研究引入了一种基于多数投票的并行思考方法，生成多条独立推理路径，在相同推理预算下选出最一致的答案，相比于扩展思考，可以提高高达20%的准确率，提供了一种简单有效的推理模型测试时缩放机制，而不是通过延伸思考来利用推理思考预算的有效方式。", "conclusion": "测试时的缩放通过增加思考并不总是能提升推理效果，而是会产生误差。因此，多思考不一定是提高推理效果的有效方式，并且推荐采用并行思考作为更有效的测试时缩放方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17192", "html_url": "https://arxiv.org/abs/2509.17192", "title": "让我们来玩游戏：用于开放性战争游戏的语言模型", "title_en": "Shall We Play a Game? Language Models for Open-ended Wargames", "authors": "Glenn Matlin,Parv Mahajan,Isaac Song,Yixiong Hao,Ryan Bard,Stu Topp,Evan Montoya,M. Rehan Parwani,Soham Shetty,Mark Riedl", "background": "战争游戏是参与者决策影响未来事件的冲突模拟。传统上，严肃的战争游戏由专家用于探索决策的战略影响和体验性学习。文章指出，人工智能系统，尤其是语言模型（LMs），在战略规划方面的表现正迅速接近甚至可能超越人类专家的水平。军事组织已经在使用语言模型来提供关于现实世界决策后果的见解，特别是在开放性战争游戏中，这种游戏使用自然语言来传达行动和结果。文章进一步探讨了部署AI系统进行开放性战争游戏时安全性、可解释性和可解释性的问题，原因在于AI系统能够影响大规模决策。", "innovation": "文章通过进行文献综述，选取了100份未分类的研究，构建了一个新的开放性战争游戏的本体论，并提出了针对开放性战争游戏在不同领域的实际建议和关键安全性考虑。文章还提出了对未来工作的高影响研究挑战，旨在促进在开放性战争游戏中使用AI系统的研究和实践进步。", "conclusion": "文章总结了开放性战争游戏领域中利用AI系统的安全性和挑战，并向研究社区提出了未来工作的关键研究挑战。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19923", "html_url": "https://arxiv.org/abs/2506.19923", "title": "Prover Agent: 基于代理的框架进行形式数学证明", "title_en": "Prover Agent: An Agent-Based Framework for Formal Mathematical Proofs", "authors": "Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai", "background": "本文介绍了Prover Agent，这是一种将大型语言模型（LLMs）与形式证明助手Lean相结合的新型AI代理，用于自动定理证明。背景在于现有的自动定理证明方法还缺乏有效利用和整合自然语言推理能力的方式，这对正式证明任务特别有益。Prover Agent旨在通过结合自然语言和形式化推理，解决这一问题。", "innovation": "Prover Agent的创新点在于它能够协调非正式的推理LLM、正式的证明模型，并从反馈中生成辅助引理。这些辅助引理不仅限于形式证明中的次目标，还包括从假设中推导出的特定情况或潜在有用的事实，有助于发现可行的证明策略。此外，Prover Agent在MiniF2F基准测试中达到了88.1%的成功率，比使用小型语言模型（SLMs）的先前方法实现了新的最先进的性能，且使用的样本预算较少。", "conclusion": "本文进行了理论分析和案例研究，展示了生成的引理如何帮助解决具有挑战性的问题。同时，Prover Agent的代码已公开，供进一步研究使用。总之，Prover Agent为自动定理证明领域提供了新的解决方案，并展示了小型语言模型在正式证明任务中的有效应用潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14667", "html_url": "https://arxiv.org/abs/2505.14667", "title": "SAFEPATH：通过早期对齐防止有危害性的推理", "title_en": "SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment", "authors": "Wonje Jeung,Sangyeon Yoon,Minsuk Kahng,Albert No", "background": "大型推理模型（LRMs）在复杂的任务解决中变得越来越强大，但它们结构化的推理路径在遇到有害提示时可能导致不安全的输出。现有的安全对齐方法可以减少有害输出，但这些方法可能会降低推理深度，导致在复杂、多步骤任务中的显著权衡，并且依然容易受到高级的突破攻击。现有方法在这种背景下存在很大的局限性，特别是在处理侧重推理的模型时表现不佳，揭示了安全人工智能的新方向的必要性。", "innovation": "SAFEPATH 是一种新颖的轻量级对齐方法，它通过在有害提示下自动生成一个短的（8token）安全导引（Safety Primer），指导推理模型的初始推理路径，以便在推理过程中继续保留未监督的推理过程。发现 SAFEPATH 在多个基准测试中能够有效减少有害输出，同时保持推理性能。特别是在 DeepSeek-R1-Distill-Llama-8B 模型中，SAFEPATH 的有害响应减少了高达 90.0%，并阻止了 83.3% 的突破尝试，所需计算量分别比 Direct Refusal 和 SafeChain 少 295.9 倍和 314.1 倍。此外，SAFEPATH 还提供了一个无需微调的零样本变体，进一步增强了其适应性和效率。", "conclusion": "SAFEPATH 通过早期对齐简化了大型推理模型的有害推理问题，显著提高了模型的安全性。SAFEPATH 在多个基准测试中的表现表明，它能够在减少有害输出的同时保持推理性能，甚至在 DeepSeek-R1-Distill-Llama-8B 模型中表现更为突出，同时比现有方法大幅减少了计算需求。进一步的研究也揭示了现有方法在这种背景下存在的局限性，有助于安全 AI 的新方向的探索。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18633", "html_url": "https://arxiv.org/abs/2509.18633", "title": "空间基于代理的模型中适应性学习对气候风险评估的应用：具有进化经济代理的地理空间框架", "title_en": "Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents", "authors": "Yara Mohajerani", "background": "气候风险评估需要构建复杂的空间异质性灾害与适应性经济系统的相互作用模型。目前的研究需要一种结合气候危害数据与经济代理进化学习的空间代理基础模型来实现这一目标，特别是在面对长期气候变化如RCP8.5的影响时，评估不同经济系统在不同气候压力下的适应策略及其经济后果。", "innovation": "本文提出了一个新颖的空间代理基础模型框架，该框架结合了基于Mesa的空间建模与CLIMADA气候影响评估系统，创新性地引入了适应性学习行为。这些学习行为允许企业通过基于适应性选择和突变进行预算分配、定价、工资和风险适应策略的进化。这种方法展示了在不同气候压力下的长期适应性策略对经济社会的影响，并特别关注通过供应链中断来揭示间接暴露于自然灾害下的系统性风险。", "conclusion": "该开放源代码框架为金融机构和企业提供了一种工具，以量化直接和连锁气候风险，并评估成本效益的适应策略。通过模拟至2100年的河流洪水影响，研究发现即使未直接暴露于洪水的企业也可能因供应链中断而受到影响，到2100年，在基于RCP8.5情景下的商品平均价格比基线情景提高了5.6%。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.10603", "html_url": "https://arxiv.org/abs/2510.10603", "title": "EA4LLM：通过进化算法实现大型语言模型优化的无梯度方法", "title_en": "EA4LLM: A Gradient-Free Approach to Large Language Model Optimization via Evolutionary Algorithms", "authors": "WenTao Liu,Siyu Song,Hao Hao,Aimin Zhou", "background": "近年来，大型语言模型（LLMs）取得了显著进展，主要依赖于基于梯度的优化器（如Adam）进行模型优化。然而，这些基于梯度的方法对硬件提出了严格的高并发和高内存需求，并且要求所有神经网络操作必须可微，从而排除了许多有前景但不可微的架构的实际应用。", "innovation": "本文提出了一种进化算法——EA4LLM，用于优化LLMs。这是首次实证验证从预训练阶段开始在不同规模（从0.5B到32B）模型上进行全参数优化。实验结果显示进化算法可以有效优化神经网络。这项工作挑战了基于梯度优化是唯一可用于训练神经网络的可行方法，并且有可能降低训练大型语言模型的计算成本，从而使计算资源有限的研究团体也能参与到深度学习的研究中来。", "conclusion": "进化算法能够有效优化神经网络，这是一种不同于基于梯度的优化的新方法。本文的工作表明，无梯度的进化算法有可能在优化和训练大型语言模型方面发挥重要作用，并为未来的工作提供了重要的见解和指导。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16614", "html_url": "https://arxiv.org/abs/2510.16614", "title": "计数很重要：使用基于计数的内在奖励在LLM推理中激发探索", "title_en": "Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards", "authors": "Xuan Zhang,Ruixiao Li,Zhijian Zhou,Long Li,Yulei Qin,Ke Li,Xing Sun,Xiaoyu Tan,Chao Qu,Yuan Qi", "background": "强化学习（RL）已成为增强大型语言模型（LLMs）多步推理能力的一种有吸引力的方法。然而，现有的RL范式仍然依赖于基于稀疏最终结果奖励的探索，这往往导致LLMs表现出重复性和亚最优的推理模式。", "innovation": "本文研究了如何为LLM推理设计探索，并引入了MERCI（基于计数的内在奖励激发LLM推理中的探索）这一创新的RL算法，它通过结合原则性的内在奖励增强策略优化。MERCI基于计数探索的想法，利用轻量级的硬币翻转网络（CFN）估计伪计数和推理轨迹的知识型不确定性，并进一步将它们转化为内在奖励，以奖励新颖性并保留来自任务奖励的学习信号。", "conclusion": "在复杂的推理基准上的实验表明，MERCI鼓励更丰富且多样化的思想链，显著提高了性能，并帮助策略脱离当地的固定模式，发现更好的解决方案。这表明，我们针对的目标内在动机可以使语言模型的探索变得可靠。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08872", "html_url": "https://arxiv.org/abs/2510.08872", "title": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare", "title_en": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare", "authors": "Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You", "background": "大型语言模型（LLMs）在推理方面取得了显著进展，但在诸如写作、信息检索或提供实用指导等任务中有时会生成次优的响应。传统的对齐方法通常假设最大化模型反馈也会最大化用户福利，但这种假设在实践中经常无法实现：模型可能会过度详细解释或生成过于冗长的推理，即使用户更喜欢简洁的答案。这种行为类似于囚徒困境，个体理性选择会导致社会福利的下降。这表明需要一个原则性的决策机制来同时为LLM和用户带来双赢的结果。", "innovation": "提出了游戏论对齐（GTAlign）框架，将游戏论决策机制整合到LLM推理和训练中。在推理过程中，模型将用户-LLM交互视为战略博弈，它构建支付矩阵以估算两者之间的福利，并选择互惠互利的行动。在训练过程中，引入了互惠福利奖励，以鼓励合作响应，使模型行为与社会有效成果一致。此外，还引入了一种推理技术，利用游戏论推理动态调整LLM的响应以适应LLM服务的价格策略变化。广泛的实验表明，GTAlign在多种任务中显著提高了推理效率、答案质量和互惠福利，优于基线方法。算法模型的相关代码已公开。", "conclusion": "GTAlign框架在提高互动效率、答案质量和互惠福利方面显著优于基线方法，展示了游戏论方法在LLM对齐中的潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16559", "html_url": "https://arxiv.org/abs/2510.16559", "title": "BuildArena: LLMs的工程建筑物理对齐交互基准", "title_en": "BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction", "authors": "Tian Xia,Tianrun Gao,Wenhao Deng,Long Wei,Xiaowei Qian,Yixian Jiang,Chenglei Yu,Tailin Wu", "background": "工程建筑自动化的目标是将自然语言规范转化为实际可行的结构，这需要在严格的物理约束下进行复杂的集成推理。尽管现代大语言模型（LLMs）拥有广泛的知识和强大的推理能力，使其成为这一领域的有潜力的候选者，但它们在工程建筑方面的性能尚未得到充分评估。为解决这一问题，该研究引入了BuildArena，这是首个物理对齐的交互性基准，专门用于语言驱动的工程建筑。它提供了评估LLMs能力的框架，覆盖了从静态到动态力学的多种难度层次，并支持基于语言指令的3D空间几何计算，最终能够全面评估前沿LLMs的语言驱动和物理为基础的工程建筑自动化能力。", "innovation": "BuildArena 作为首个物理对齐的交互性基准，提供了一个高度可定制的基准框架，能够深入比较和分析LLMs；任务设计策略覆盖了静态与动态力学的多层次任务；集成了一个3D空间几何计算库来支持基于语言指令的建筑构造；并设立了一个基线LLM自主工作流，以有效评估不同模型的能力。通过对八种前沿大语言模型进行全面评估，BuildArena展示了其在语言驱动和物理导向的工程建筑自动化方面的潜力。", "conclusion": "BuildArena 项目通过评估先进的大语言模型在工程建筑上的应用能力，填补了当前在这一领域中的评估空白，并为未来进一步的研究和开发提供了坚实的基础。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25271", "html_url": "https://arxiv.org/abs/2509.25271", "title": "RADAR: 一种基于角色专业化协作的风险感知动态多代理框架，用于大型语言模型安全性评估", "title_en": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "authors": "Xiuyuan Chen,Jian Zhao,Yuchen Yuan,Tianle Zhang,Huilin Zhou,Zheng Zhu,Ping Hu,Linghe Kong,Chi Zhang,Weiran Huang,Xuelong Li", "background": "现有的大型语言模型（LLMs）的安全评估方法存在固有的局限性，包括评估者偏见和由于模型同质性而产生的检测失败，这些因素共同削弱了风险评估过程的稳健性。", "innovation": "本文通过引入一个理论框架，重构了风险概念空间并将其分解为三个互斥子空间：明确风险子空间（涵盖直接违反安全指南的内容）、隐含风险子空间（捕捉需要上下文推理来识别的潜在恶意内容）和非风险子空间。此外，还提出了一个基于多代理协作的RADAR框架，通过四种专业化角色的多轮辩论机制和动态更新机制实现风险概念分布的自我演化，从而全面覆盖显性和隐性风险并减轻评估者偏见。", "conclusion": "通过对构建的包含800个具有挑战性的评估数据集进行广泛实验，我们的RADAR框架在多个维度（包括准确率、稳定性和自我评估风险敏感性）上明显优于基准评估方法，并且相较于最强的基准评估方法在风险识别准确性方面提高了28.87%。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17697", "html_url": "https://arxiv.org/abs/2510.17697", "title": "多智能体强化学习中目标干预原则", "title_en": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "authors": "Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang", "background": "在大规模多智能体强化学习（MARL）中，引导协调策略以实现期望结果颇具挑战，尤其是当全球人为干预无法实施时。当前设计外部机制（如内在奖励和人类反馈）多依赖于经验性研究，缺乏易于使用的工具。为了应对这些问题，作者采用多智能体影响图（MAIDs）为图形框架，探讨了MARL中的未引导自组织与全局引导机制，并设计了一种新的目标干预范式以集中于单个特定智能体，从而减轻全局引导的问题。通过引入因果推理方法，称为预策略干预（PSI），实现了该目标干预范式。利用MAIDs中压缩相关性图的分析方法，提供了评估MARL学习范式可行性的工具。", "innovation": "提出了一种新的多智能体强化学习（MARL）的干预范式，称为目标干预范式，适用于单一特定智能体，以降低全局引导的复杂性。利用因果推理方法，实现预策略干预（PSI），通过最大化因果效应来实现复合期望结果。通过压缩相关性图的分析方法，提供了一种工具来评估MARL学习范式的可行性。", "conclusion": "实验结果证明了提出的目标干预的有效性，并验证了相关性图分析的结果。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19562", "html_url": "https://arxiv.org/abs/2510.19562", "title": "DAIL：超越任务歧义的语言条件强化学习", "title_en": "DAIL: Beyond Task Ambiguity for Language-Conditioned Reinforcement Learning", "authors": "Runpeng Xie,Quanwei Wang,Hao Hu,Zherui Zhou,Ni Mu,Xiyun Li,Yiqin Yang,Shuang Xu,Qianchuan Zhao,Bo XU", "background": "自然语言理解和遵循人类指令是智能代理的关键能力。然而，语言指令的灵活性导致在语言条件任务中产生大量歧义，严重恶化了算法性能。", "innovation": "提出了一种新颖的方法——DAIL（分布对齐学习），包含两个关键组件：分布策略和语义对齐。理论结果表明，价值分布估计机制增强了任务特异性，并且语义对齐模块捕捉轨迹与语言指令之间的对应关系。实验证明DAIL能够有效解决指令歧义，性能优于基线方法。", "conclusion": "在结构化和视觉观察基准上的大量实验结果显示，DAIL能够有效地解决指令歧义，达到基线方法的优越性能。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18470", "html_url": "https://arxiv.org/abs/2510.18470", "title": "CircuitSeer: 挖掘大语言模型中数学推理电路的高质量数据", "title_en": "CircuitSeer: Mining High-Quality Data by Probing Mathematical Reasoning Circuits in LLMs", "authors": "Shaobo Wang,Yongliang Miao,Yuancheng Liu,Qianli Ma,Ning Liao,Linfeng Zhang", "background": "大语言模型（LLMs）展示了令人印象深刻的推理能力，但提升其性能通常需要大量推理数据集，这些数据集进行训练会耗费大量的计算资源。现有数据选择方法旨在整理出更小、更高质量的数据子集，但这些方法往往依赖于昂贵的外部模型或不透明的启发式规则。本研究将重点从外部启发式转移到模型内部机制，发现复杂推理任务始终激活一组稀疏且专门化的注意力头，形成了核心推理电路。依据这一洞察，提出了CircuitSeer方法，通过度量数据对这些关键电路的影响来量化推理复杂度。", "innovation": "CircuitSeer是一个新颖的数据选择方法，它基于量化数据对核心推理电路的影响来评估数据的推理复杂度。开发该方法的创新之处在于它直接利用模型的内部机制，而非依赖外部模型或启发式规则，并取代了现有的基于外部启发式的低效策略。", "conclusion": "在4个模型和9个数据集上进行的实验表明，CircuitSeer具有优越性。通过仅在由我们的方法选择的10%的数据上进行微调Qwen2.5-Math-7B，所得的结果在平均Pass@1指标上比在完整数据集上进行训练提高了1.4个点，这充分展示了其效率和有效性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18254", "html_url": "https://arxiv.org/abs/2510.18254", "title": "大型语言模型的反思性推理揭示的系统性失败：开放性任务揭示反思幻象", "title_en": "Illusions of reflection: open-ended task reveals systematic failures in Large Language Models' reflective reasoning", "authors": "Sion Weatherhead,Flora Salim,Aaron Belbasis", "background": "现有研究表明，人类在任务进行过程中能够主动发现错误并纠正，这是因为反思与任务目标及其约束紧密相关。然而，今天的大型语言模型虽然能够生成具有反思性的文本和推理内容，但其实际是否与人类的反思性推理功能等效仍是一个未知数。已有工作主要集中在封闭任务上，这类任务外部存在明确的正确性信号，这使得模型的表现显得更加有效但实际上却掩盖了自我纠正能力的局限性。因此，该研究使用一个简单但开放且规则受限的实际任务来测试八个前沿模型的性能：要求模型生成有效的科学测试项目，并在评估后进行修正。结果显示，模型的初次表现较差，反思后仅取得轻微提升，甚至在第二次尝试中往往重复相同的错误，这表明", "innovation": "本研究通过开放且规则受限的任务来测试大型语言模型的反思性推理能力，发现在初次尝试和通过反思后的第二次尝试中，模型的性能并不如预期，尤其是在任务开放性增加时，模型的性能下降更为明显。这一研究揭示了当前大型语言模型在反射性推理方面存在系统性失败，缺乏人类那样的主动监测和约束敏感的修复机制。此外，研究指出，现阶段大模型中实现这些机制仍需外部结构来监督和约束模型，以确保可靠表现。该研究为理解大模型的不足提供了新的视角，并推动了改进现有模型的研究方向。", "conclusion": "当前大模型中的"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18988", "html_url": "https://arxiv.org/abs/2510.18988", "title": "通过主动测试选择实现及时临床诊断", "title_en": "Timely Clinical Diagnosis through Active Test Selection", "authors": "Silas Ruhrberg Estévez,Nicolás Astorga,Mihaela van der Schaar", "background": "目前越来越关注使用机器学习（ML）来支持临床诊断，但大多数方法依赖于静态、完全观察的数据集，未能反映临床实践中 clinicians 所使用的基于顺序、资源感知的推理。诊断仍然是一个复杂且易出错的过程，尤其是在高压或资源有限的环境中，这突显了需要帮助临床医生及时且经济高效地做决策的框架的重要性。", "innovation": "该论文提出了 ACTMED（Adaptive Clinical Test selection via Model-based Experimental Design），这是一种结合贝叶斯实验设计（BED）与大规模语言模型（LLMs）的诊断框架，旨在更好地模拟现实生活中的诊断推理。在每一步中，ACTMED 会选择预期能最大程度减少特定患者诊断不确定性所必需的测试。大规模语言模型作为灵活的模拟器，生成可能的患者状态分布并支持信念更新，无需结构化、任务特定的训练数据。临床医生可以在过程中保持参与，审查测试建议、解释中间输出并应用临床判断。", "conclusion": "ACTMED 的评估显示它可以优化测试选择以提高诊断准确性、可解释性和资源利用。这代表了朝着透明、适应性且符合临床医生的诊断系统迈出的一步，这些系统可以在减少对特定领域数据依赖的情况下泛化到各种环境中。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.12961", "html_url": "https://arxiv.org/abs/2405.12961", "title": "通过连续反馈对变压器进行能级排名对齐", "title_en": "Aligning Transformers with Continuous Feedback via Energy Rank Alignment", "authors": "Shriram Chennakesavalu,Frank Hu,Sebastian Ibarraran,Grant M. Rotskoff", "background": "在化学空间中搜索分子是一种极其具有挑战性的问题，因为可能的分子数量随着原子数量的增加呈组合性增长。虽然大型自回归模型在数据库中训练化学化合物，可以生成强大的生成器，但我们仍然缺乏能有效生成具有特定性质分子的稳健策略。此外，虽然分子搜索问题类似于大型语言模型的“对齐”问题，但对于许多化学任务我们具有明确且易于评估的奖励函数。", "innovation": "该研究引入了一种称为能级排名对齐（ERA）的算法，该算法利用显式奖励函数来生成基于梯度的目标，用于优化自回归策略。该算法理论上与代理策略优化（PPO）和直接偏好优化（DPO）密切相关，但其最小化器会收敛到理想的状态-能量分布。ERA算法非常具有扩展性，不需要强化学习，并且在奖赏观察对较少时，对DPO的性能表现良好。", "conclusion": "该方法被应用到分子转换器和蛋白质语言模型，以分别生成具有外部指定特性的分子和蛋白质序列，并且发现ERA策略能够稳健地搜索化学空间的多样化部分。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19788", "html_url": "https://arxiv.org/abs/2510.19788", "title": "世界模型学习基准测试", "title_en": "Benchmarking World-Model Learning", "authors": "Archana Warrier,Dat Nguyen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares", "background": "现有的世界模型学习和评估方法偏离了通过学习能够支持多种下游任务和推理的世界模型的目标，通常专注于下一帧的预测，并通过在相同环境中的奖励最大化来衡量成功。作者提出了WorldTest，这是一种评估模型学习代理的新协议，将无奖励交互与打分测试阶段分离在不同的但相关的环境中进行。WorldTest是开放式的，模型应支持多种未知的任务，并且对于模型表示不拘泥，从而允许跨方法进行比较。", "innovation": "WorldTest提供了一个新的模板——无奖励探索，来源测试和基于行为的评分，以评估代理学习环境动力学的知识。秋之台套件被用作实例，其中包含了43个交互网格世界环境和129个任务，分为遮盖帧预测、规划和因果动力学变化预测三个类型。作者比较了517名人类参与者和三个前沿模型在秋之台套件中的表现，发现人类在某些环境中的表现优于模型的生成，而在其他环境中，计算的扩大只在某些环境中提高了性能而并非全部提高。这表明世界模型学习存在显著的提升空间。", "conclusion": "WorldTest提供了一种评估基于学习模型的代理的方法，该方法可以更广泛地展示代理对环境动力学的理解。秋之台套件揭示了世界模型学习中的大量改进空间。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.05500", "html_url": "https://arxiv.org/abs/2410.05500", "title": "增强深度学习的残差柯尔莫哥洛夫-阿诺尔德网络", "title_en": "Residual Kolmogorov-Arnold Network for Enhanced Deep Learning", "authors": "Ray Congrui Yu,Sherry Wu,Jiang Gui", "background": "尽管深度卷积神经网络(CNNs)在各种任务中取得了巨大的成功，但它们在优化和训练过程中由于内部网络深度中含有数百层等原因变得复杂且昂贵。传统的卷积操作因其线性和固定激活的性质，需要大量的层才能从数据中学习到有意义的模式。由于网络的规模庞大，这种方法变得计算效率低下，并且在小数据集上存在过拟合或梯度爆炸的风险。因此，我们介绍了一种“即插即用”的模块，称为残差柯尔莫哥洛夫-阿诺尔德网络(RKAN)。", "innovation": "我们的模块非常紧凑，可以很容易地插入到任何阶段的传统深度网络中，在现有的卷积框架中学习支持性的多项式特征变换。RKAN在不同的视觉任务中和广泛测试的基准中的一致性改进超过了基线模型，实现了最先进的性能。", "conclusion": "RKAN模块提供了一种在深度卷积神经网络中引入多项式特征变换的有效方式，增强了网络的性能，减少了过拟合和梯度爆炸的风险。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.05056", "html_url": "https://arxiv.org/abs/2410.05056", "title": "α-混合在随机迭代中的转换及其在排队论中的应用", "title_en": "Transition of $α$-mixing in Random Iterations with Applications in Queuing Theory", "authors": "Attila Lovas", "background": "非线性时间序列模型在经济计量学、排队理论和机器学习中至关重要，尽管其统计分析仍不完善。关于弱依赖变量的关键结果，如大数定律和funcCLT是已知的。文章探讨了如何通过耦合方法将内生自变量的因素混合特性转移到响应变量上。同时，还研究了在随机环境下的Markov链，以及在非平稳环境下具有有利混合特性的框架，并将其应用于单服务台排队模型。", "innovation": "1. 通过耦合方法展示了内生自变量的混合性质如何传递给响应变量。2. 研究了在随机环境下的Markov链的性质，即使在非平稳环境下，只要具有有利的混合特性。3. 应用研究结果到单服务台排队模型中。", "conclusion": "通过证明混合属性的传输，并研究在多种条件下的Markov链行为，扩展了非线性时间序列模型在各种环境下的统计分析，为排队问题提供了新的理论工具。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.00954", "html_url": "https://arxiv.org/abs/2406.00954", "title": "基于标注指南的知识增强：朝向增强大型语言模型在教育文本分类中的性能", "title_en": "Annotation Guidelines-Based Knowledge Augmentation: Towards Enhancing Large Language Models for Educational Text Classification", "authors": "Shiqi Liu,Sannyuya Liu,Lele Sha,Zijie Zeng,Dragan Gasevic,Zhi Liu", "background": "各种机器学习方法在自动分类教育文本以识别学习参与度指标方面取得了显著的受欢迎程度，即学习参与度分类（LEC）。LEC能提供深入的人类学习过程洞察，吸引不同研究社区的兴趣，包括自然语言处理（NLP）、学习分析和教育数据分析领域。近年来，大型语言模型（LLMs）如ChatGPT在各种NLP任务中表现出色，但在LEC任务中的全面评估和改进方法尚未得到充分研究。因此，提出了基于标注指南的知识增强（AGKA）方法来改进LLMs。AGKA采用GPT 4.0从标注指南中检索标签定义知识，并使用随机下采样器选取典型的例子。", "innovation": "该研究提出了AGKA方法，一种基于标注指南的知识增强方法，可以改进未经微调的LLMs，特别是在二元分类任务中，GPT 4.0在AGKA微调后比全量微调模型（如BERT和RoBERTa）表现更好。此外，基于开源LLM的Llama 3 70B与AGKA结合的表现与使用闭源GPT 4.0和AGKA的模型相当。研究结果还表明，LLMs在多分类任务中难以区分名称相似的标签。", "conclusion": "AGKA可以提高未经微调的LLMs，特别是GPT 4.0和Llama 3 70B的表现。在二元分类任务中，带有AGKA的GPT 4.0的微调效果优于全量微调的BERT和RoBERTa，但在需要深入理解复杂语义信息的多分类任务中，GPT 4.0表现不佳。值得注意的是，开源LLM Llama 3 70B结合AGKA与闭源GPT 4.0和AGKA的表现相当，基于开源LLM的方法具有潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.07812", "html_url": "https://arxiv.org/abs/2410.07812", "title": " Temporal-Difference Variational Continual Learning ", "title_en": "Temporal-Difference Variational Continual Learning", "authors": "Luckeciano C. Melo,Alessandro Abate,Yarin Gal", "background": "在实际应用中，机器学习模型需要不断地学习新的任务以适应数据生成分布的变化。然而，在持续学习（Continual Learning, CL）中，模型往往难以平衡学习新任务的能力（可塑性）和保持之前知识的能力（记忆稳定性）。因此，容易导致灾难性遗忘，即模型在新任务上的性能下降，影响部署系统的可靠性。在贝叶斯持续学习文献中，拟变方法通过递归更新后验分布并保持其接近前一估计来解决这一挑战。然而，该论文认为，这些方法可能由于递归过程中累积的近似误差而效果不佳。", "innovation": "为了解决这个问题，作者提出了一种新的学习目标，它综合了多个以前后验估计的正则化效应，防止单一错误在未来后验更新中占据主导并随时间累积。这种方法与时间差分（Temporal-Difference）方法之间存在有趣的联系，这些方法在强化学习和神经科学中广受欢迎。实验表明，该方法有效缓解了灾难性遗忘问题，优于强大的拟变持续学习方法。", "conclusion": "实验结果表明，该方法在应对持续学习中的灾难性遗忘方面表现优异，相较于强大的拟变持续学习方法更具有优势。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.11843", "html_url": "https://arxiv.org/abs/2411.11843", "title": "Bi-Mamba: 向1位状态空间模型的准确方向迈进", "title_en": "Bi-Mamba: Towards Accurate 1-Bit State Space Models", "authors": "Shengkun Tang,Liqun Ma,Haonan Li,Mingjie Sun,Zhiqiang Shen", "background": "传统的选择状态空间模型（SSM）如Mamba在解决Transformer的局限性方面表现良好，比如二次时间复杂度和推理时的内存需求，但Mamba模型规模的增加使其在训练和部署中面临挑战，尤其是在训练和推理时巨大的计算需求。", "innovation": "提出了Bi-Mamba，这是一种可扩展且强大的1位Mamba架构，用于构建更高效的大型语言模型（LLM），参数大小分别为780M、1.3B和2.7B。Bi-Mamba模型采用自回归蒸馏损失从标准LLM规模的数据集进行训练。实验数据显示，Bi-Mamba在语言建模基准测试中的性能与全精度（FP16或BF16）模型相当，甚至优于后训练二值化（PTB）Mamba和二值化感知训练（BAT）Transformers基线。此外，与原始Mamba相比，Bi-Mamba在内存使用和计算成本上大幅降低。这项工作开创了低比特表示下的线性复杂LLM的新方向，并为高效的一位Mamba基模型的专用硬件设计提供了途径。", "conclusion": "Bi-Mamba模型展示了在保持准确性的前提下，通过二值化技术有效降低计算需求和资源消耗的可能性，为未来的大规模语言模型的高效设计提供了新的思路。此外，该研究还为相关硬件的优化设计提供了指导。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.19258", "html_url": "https://arxiv.org/abs/2410.19258", "title": "非所有注意力头都重要：一种结合检索与推理的注意力头级别KV缓存压缩方法", "title_en": "Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning", "authors": "Yu Fu,Zefan Cai,Abedelkadir Asi,Wayne Xiong,Yue Dong,Wen Xiao", "background": "大语言模型（LLMs）中常用的键值（KV）缓存技术可以提高计算效率，但随着输入长度增加其内存开销迅速增长。此前研究表明，并非所有令牌对于文本生成都同等重要，提出了一种层级别的KV缓存压缩方法来选择性地保留重要信息。现有方法关注多头的总体贡献，而没有具体考虑每个多头在生成过程中的区别作用。因此，本文提出了HeadKV方法，这是一种基于个体注意力头的KV缓存压缩技术，并进一步提出了结合了一种新颖的上下文推理能力估计方法的HeadKV-R2。该方法更适合于需要检索和推理能力的上下文问答任务。通过在各种基准测试、不同模型架构和长上下文能力测试中进行广泛实验，本文证明了基于注意力头级别的KV缓存压缩方法在保留 KV 缓存的97%性能的同时，只需保留1.5%的KV缓存，特别是在低资源环境下（缓存大小为64和128的情况）性能表现更优。", "innovation": "提出了基于注意力头级别的KV缓存压缩方法HeadKV和HeadKV-R2，并结合了一种新颖的上下文推理能力估计方法，专门适用于需要检索和推理能力的上下文问答任务，这种相比于现有方法更加精准和高效。实验表明，该方法在保持高效率的同时，大幅度减少了KV缓存的需求，尤其对于低资源环境具有显著优势。", "conclusion": "本文提出的基于注意力头级别的KV缓存压缩方法，能够在保留大部分模型性能的同时，实现大幅减少KV缓存的需求，特别在低资源环境下表现出色。这种方法对于大语言模型的高效运行具有重要意义。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.09805", "html_url": "https://arxiv.org/abs/2412.09805", "title": "making_classic_gnn_strong_baselines_across_varying_homophily_smoothness_generalization_perspective", "title_en": "Making Classic GNNs Strong Baselines Across Varying Homophily: A Smoothness-Generalization Perspective", "authors": "Ming Gu,Zhuonan Zheng,Sheng Zhou,Meihan Liu,Jiawei Chen,Tanyu Qiao,Liangcheng Li,Jiajun Bu", "background": "尽管图神经网络（GNNs）取得了巨大成功，但这些网络常常被认为在不同亲和程度的图上表现不佳。近期的经验研究表明，恰当的超参数调优可以帮助亲和性强的GNNs在不同亲和程度的数据集上表现良好，但背后的理论和有效架构仍然不清楚。因此，为了提高GNN在网络亲和性方面的一致性，本文从理论上重新审视了GNN的消息传递过程，并发现了一个新颖的平滑性-泛化困境，即增加跳跃次数会提升平滑性但会损害泛化能力，这一困境在高阶亲和和非亲和的网络中尤为严重，因为这些网络中复杂的邻域类别分布对噪声和稀疏性引发的偏移非常敏感。", "innovation": "本文提出了“Inceptive Graph Neural Network (IGNN)”，这是一种基于三个简单且有效的设计原则构建的新型GNN架构。IGNN兼具跳跃智慧的泛化能力，并通过自适应平滑性来提高整体泛化能力，从而缓解了平滑性-泛化困境。实验结果表明，IGNN在30种基线中表现最佳，并揭示了某些类型的GNN在网络亲和性变化时具有一定的普遍性.", "conclusion": "基准测试表明，IGNN在不同亲和程度的数据集上表现优越，并且揭示了某些经典GNN在网络亲和性变化时的普遍性。本文提供了一个新的视角，表明平滑性和泛化之间的平衡对于提高GNN在网络亲和性变化中的一致性非常重要。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.13251", "html_url": "https://arxiv.org/abs/2502.13251", "title": "神经注意力搜索", "title_en": "Neural Attention Search", "authors": "Difan Deng,Marius Lindauer", "background": "该论文提出了一个名为NAtS（神经注意力搜索）的新框架，旨在自动评估序列中每个令牌的重要性，并决定是否可以在几个步骤后丢弃相应的令牌。这种方法可以在推理过程中有效减少基于转换器模型所需的缓存（KV）大小，从而降低推理成本。", "innovation": "1. 设计了一个包含三种类型的令牌搜索空间：全局令牌、局部令牌和滑动窗口令牌。\n2. 通过可学习的注意力掩码，可以联合学习令牌类型信息和架构权重。\n3. 实验结果表明，NAtS可以在保持模型性能的同时，有效地减少所需缓存的大小。", "conclusion": "NAtS框架能够通过自动评估每个令牌的重要性并选择性丢弃它们，来有效地减少基于转换器模型的KV缓存需求，而不影响模型的性能。这种技术可以显著降低转换器模型的推理成本。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.07591", "html_url": "https://arxiv.org/abs/2502.07591", "title": "DMWM：具有长期想象能力的双重思维世界模型", "title_en": "DMWM: Dual-Mind World Model with Long-Term Imagination", "authors": "Lingyi Wang,Rashed Shelim,Walid Saad,Naren Ramakrishnan", "background": "已有基于循环状态空间模型（RSSM）的世界模型依赖单步统计推理来捕捉环境动态，因此无法执行长期想象任务，因为预测误差的累积会导致失真。为了应对这一挑战，本文从人类认知的双重过程理论中汲取灵感，提出了一种新的双重思维世界模型（DMWM）框架，旨在通过对逻辑推理的集成来实现具有逻辑一致性的想象能力。该框架由两个部分组成，分别为使用直观方式处理状态转换的RSSM-S1组件，和通过层次深度逻辑推理引导想象过程的LINN-S2组件。", "innovation": "提出的DMWM框架通过集成逻辑推理的LINN-S2组件与依赖单步统计推理的RSSM-S1组件相结合，设计了一种跨系统的反馈机制，确保想象过程符合真实环境中的逻辑规则。这种方法比当前最先进的世界模型在逻辑连贯性、试验效率、数据效率和长期想象能力方面取得了显著改进。", "conclusion": "DMWM框架在DMControl基准测试任务中得到评估，实验结果表明该框架在多个方面显著优于当前最先进的世界模型。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.09389", "html_url": "https://arxiv.org/abs/2502.09389", "title": "S$^2$-Diffusion: 从实例级到类别级技能在机器人操作中的泛化", "title_en": "S$^2$-Diffusion: Generalizing from Instance-level to Category-level Skills in Robot Manipulation", "authors": "Quantao Yang,Michael C. Welle,Danica Kragic,Olov Andersson", "background": "近年来机器人技能学习的进步推动了机器人操作技术的发展，使其能够从相对较少的演示中学习复杂的操作任务。然而，这些技能通常局限于训练数据中展示的具体操作、物体和环境实例，难以将技能泛化到同一类别的其他实例。", "innovation": "本文提出了一种开放词汇量的空间语义扩散策略（S$^2$-Diffusion），使机器人能够在同一类别的不同实例之间泛化技能。该策略通过一个可提示的语义模块结合空间表征来捕获技能的功能方面，并利用深度估计网络使得仅用单一RGB摄像头即可实现。该方法在多种机器人操作任务中进行了评估和比较，无论是仿真还是真实世界。", "conclusion": "实验结果显示，S$^2$-Diffusion对类别无关因素的变化具有不变性，能够在同一类别中的其他实例上实现令人满意的性能，即使训练时没有包含这些特定实例。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.01243", "html_url": "https://arxiv.org/abs/2501.01243", "title": "Face-Human-Bench：多模态助手理解人脸和人类的综合基准", "title_en": "Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants", "authors": "Lixiong Qin,Shilong Ou,Miaoxuan Zhang,Jiangning Wei,Yuhang Zhang,Xiaoshuai Song,Yuchen Liu,Mei Wang,Weiran Xu", "background": "人脸和人类是社交互动中的关键元素，广泛出现在日常生活中的照片和视频中。因此，深入理解人脸和人类有助于提高多模态助手的回应质量和应用范围。然而，当前多模态助手领域缺乏全面和科学地评估人脸和人类理解能力的标准。", "innovation": "本文首先提出了一个多级能力分类，包括三个层次的能力。基于此分类，从脸像和人类社区的公开数据集中收集图像和注释，构建了一种半自动数据管道来生成新的基准问题。构建了Face-Human-Bench基准，包括用于开发和测试集，每部分有1800个问题，支持英语和中文。在25个主流多模态大型语言模型（MLLMs）上进行了评估，重点关注能力之间的相关性、目标相对位置对性能的影响以及Chains of Thought（CoT）提示对性能的影响。此外，研究了需要由专门模型补充的MLLMs的能力。", "conclusion": "通过Face-Human-Bench基准对25个主流多模态大型语言模型进行了评估，发现MLLMs在不同能力上的表现存在差异，提出需要进一步研究和补充特定领域模型来提高其整体性能。同时，数据集和评估代码已开源，可供其他研究者使用。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.11554", "html_url": "https://arxiv.org/abs/2502.11554", "title": "为语音用户界面设计开展动态隐喻对话设计", "title_en": "Toward Metaphor-Fluid Conversation Design for Voice User Interfaces", "authors": "Smit Desai,Jessie Chin,Dakuo Wang,Benjamin Cowan,Michael Twidale", "background": "现有的语音用户界面（VUI）设计通常依赖静态、以人为中心的隐喻，这些隐喻未能适应不同的情境和用户需求。这项研究探讨了动态调整基于对话使用情境的隐喻性表示的方法，以解决现有设计的不足。研究一和研究二分别调查了用户对不同幽默水平和层级的命令、信息查询、社会性互动以及错误恢复情景的偏好，并表明动态隐喻设计能够更好地匹配不同情境下的用户期望，从而提升采用意愿、满足感和喜好度。然而，用户在隐喻偏好上的个体差异提示了个性化设计的需求。这些发现挑战了一体化宣称所有人的VUI设计理念，并显示出动态隐喻设计在创建更适应和引人入胜的人工智能交互中的潜力。", "innovation": "该研究提出了一种名为动态隐喻设计的新方法，这种方法可以根据对话使用情境动态调整隐喻性表示，以提高用户体验。研究通过将隐喻与不同情境联系起来，并在两个实验中验证了该方法的有效性，显示出它能够更好地匹配用户期望，从而提升用户体验。", "conclusion": "研究揭示了用户在不同情境下的隐喻偏好，提出了动态隐喻设计能够克服传统VUI设计的局限性，展示了更具适应性和交互性的用户界面设计的可能性，挑战了一体化的一刀切设计理念，并强调了个性化设计的需求。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.15090", "html_url": "https://arxiv.org/abs/2502.15090", "title": "ExpertLens：激活引导特征具有高度可解释性", "title_en": "ExpertLens: Activation steering features are highly interpretable", "authors": "Masha Fedzechkina,Eleonora Gualdoni,Sinead Williamson,Katherine Metcalf,Skyler Seto,Barry-John Theobald", "background": "大规模语言模型（LLMs）中的激活引导方法已经被证明是一种有效的方法，可以对生成的语言进行有针对性的更新，而不需要大量的适应数据。已有研究表明，这些激活引导方法能发现可解释的特征，但尚未完全验证这一假设。", "innovation": "该研究通过使用“寻找专家”方法识别特定概念（如“猫”）相关的神经元，并引入了ExpertLens的概念，即通过检查这些神经元来获得对模型表示的洞察。研究发现ExpertLens具有跨模型和数据集的稳定性，并且与行为数据推断的人类表示高度一致。此外，通过ExpertLens重建人类概念组织，展示了其能够实现对LLM概念表示的精细视角。", "conclusion": "研究结果表明，ExpertLens是一种灵活且轻量的方法，用于捕获和分析模型表示，且其表现明显优于基于词/句嵌入的对齐方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.17213", "html_url": "https://arxiv.org/abs/2502.17213", "title": "由深度学习驱动的脑电信号分析：推进神经疾病诊断", "title_en": "Deep Learning-Powered Electrical Brain Signals Analysis: Advancing Neurological Diagnostics", "authors": "Jiahe Li,Xin Chen,Fanqi Shen,Junru Chen,Yuxin Liu,Daoze Zhang,Zhizhang Yuan,Fang Zhao,Meng Li,Yang Yang", "background": "神经性疾病对全球公共卫生构成重大挑战，推动了脑信号分析的进步。头皮脑电图（EEG）和颅内脑电图（iEEG）广泛用于诊断和监测。然而，数据集的异质性和任务变化阻碍了稳健的深度学习解决方案的发展。", "innovation": "该综述系统地探讨了用于EEG/iEEG的神经疾病诊断的最新深度学习方法进展，涵盖了7种神经性状况，共46个数据集的应用情况。评估了代表方法和定量结果，并整合了性能分析、数据使用、模型设计和特定任务的适应性分析。突出了预训练多任务模型在实现可扩展和可泛化解决方案中的作用。", "conclusion": "最后，提出了一种标准化基准来评估跨多种数据集的模型，并强调最近的创新如何朝着智能化、适应性医疗系统改造神经疾病诊断。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.06520", "html_url": "https://arxiv.org/abs/2505.06520", "title": "PRUNE: 基于修补的可验证神经网络去学习框架", "title_en": "PRUNE: A Patching Based Repair Framework for Certifiable Unlearning of Neural Networks", "authors": "Xuran Li,Jingyi Wang,Xiaohan Yuan,Peixin Zhang", "background": "在已训练的神经网络模型中，移除特定的训练数据（即，去学习）通常是必要的，特别是在受到数据持有者隐私保护相关法规的推动下，例如‘被遗忘权’的规定。现有方法通常涉及重新训练模型，这在成本和验证方面都带来了挑战。本文探讨了如何通过在原始模型上施加精心设计的“修补件”来实现特定数据的精确删除，同时保持模型性能。", "innovation": "本文提出了一个新的视角，并提出了一种名为PRUNE的方法，通过在原始神经网络上施加精心设计的“修补件”，实现有针对性的去学习。该方法借鉴了神经网络修复的研究路线，旨在通过最小的“修补件”实现可验证的去学习，并提出了迭代选择代表性的数据点来逐步去学习大量数据点或整个类别，从而验证整组数据的去学习效果。该方法在多个分类数据集上的实验表明，这种方法既有效又具有竞争力。", "conclusion": "本文提出的PRUNE方法不仅能够实现可验证的去学习，同时还能保持模型原有的性能，并且在效率和内存消耗方面具有竞争优势。这种方法提供了一种新的解决方案来处理去学习问题，特别是在考虑了数据持有者的隐私保护需求时。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.12474", "html_url": "https://arxiv.org/abs/2504.12474", "title": "BiGTex：在Text-Attributed Graphs中结合结构和语义信号", "title_en": "Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex", "authors": "Azadeh Beiranvand,Seyed Mehdi Vahidipour", "background": "Text-attributed graphs (TAGs)要求模型捕捉节点相关文本的语义丰富性和图结构的依赖关系，这对表示学习提出了独特挑战。虽然图神经网络在建模拓扑信息方面表现出色，但它们处理非结构化文本的能力不足。相比之下，大型语言模型在理解文本方面表现出色，但通常不关注图结构。", "innovation": "此工作提出了一个新颖的架构——BiGTex（Bidirectional Graph Text），该架构通过堆叠Graph-Text Fusion Units紧密集成图神经网络和大型语言模型。每个单元允许文本和结构表示之间的互注意力，使信息可以在两个方向流动，文本影响结构，结构指导文本解释。该架构使用参数效率高的微调（LoRA）进行训练，保持大型语言模型冻结，以适应任务特定的信号。广泛的实验表明，BiGTex在节点分类中达到最先进的性能，并且在链接预测中具有良好的泛化能力。消融研究表明，软提示和双向注意力对模型的成功至关重要。", "conclusion": "BiGTex在节点分类和链接预测任务中取得了最先进的性能，并且能够有效地泛化。通过参数效率高的微调训练，该架构实现了图结构和文本信息的紧密结合。进一步的研究表明，双向注意力和软提示在模型的成功中起着关键作用。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01002", "html_url": "https://arxiv.org/abs/2504.01002", "title": "词条嵌入违反流形假设", "title_en": "Token embeddings violate the manifold hypothesis", "authors": "Michael Robinson,Sourya Dey,Tony Chiang", "background": "为了全面理解大型语言模型（LLM）的行为，必须掌握其输入的标记空间。如果标记空间与我们的假设不同，我们对LM的理解和结论很可能是错误的。这篇论文通过实证和理论研究来阐明标记嵌入的结构。提出了一个假设测试，即在每个标记的邻域内，结构相对平坦和光滑，以此作为零假设，通过测试来检验这一假设。研究发现，零假设经常被拒绝，表明标记子空间不是流形，也不是纤维丛。这意味着，当LLM接收到两个语义等价的提示，如果其中一个提示中包含由测试标识的标记，那么对该提示的响应可能不如另一个提示稳定。", "innovation": "论文提出了一种新的统计测试方法，用于验证标记空间是否符合纤维丛假设。这种方法不仅区分了小半径和大半径区域的不同属性，还能广泛应用于不同的开源语言模型（每个模型具有独特的标记嵌入）。此外，提出的纤维丛假设是对传统流形假设的拓展，能更好地解释标记空间的复杂结构。", "conclusion": "通过在多个开源语言模型上运行测试，研究人员发现零假设频繁被拒绝，表明标记子空间不是纤维丛。这说明，当面对语义等价的提示时，如果提示包含由测试标识的标记，那么模型的响应将表现出较低的稳定性。这一发现挑战了传统流形假设，对理解语言模型的内部机制有着重要的影响。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.09131", "html_url": "https://arxiv.org/abs/2505.09131", "title": "Fair Clustering via Alignment", "title_en": "Fair Clustering via Alignment", "authors": "Kunwoong Kim,Jihu Lee,Sangchul Park,Yongdai Kim", "background": "算法公平性在聚类中的目标是在给定敏感属性的情况下平衡各个聚类中实例的比例。尽管最近开发的公平聚类算法在特定公平约束下优化了聚类目标，但它们的内在复杂性或近似往往会导致实际中的聚类实用性和数值稳定性不足。", "innovation": "提出了一种新的基于公平 $K$-means 聚类目标函数新颖分解的公平聚类算法名为公平聚类通过对齐 (FCA)。该算法交替地进行(i) 寻找用于对齐不同受保护群体数据的联合概率分布，和(ii) 在对齐的空间中优化簇中心。FCA 的主要优势在于，它理论上能够为任何给定的公平水平约提供最优化的聚类实用性和复杂约束，从而实现在实践中的高实用价值公平聚类。", "conclusion": "实验表明，FCA 在 (i) 达到公平水平和聚类实用性的最佳权衡，以及 (ii) 实现近乎完美的公平性和无数值不稳定性方面优于现有方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.01618", "html_url": "https://arxiv.org/abs/2505.01618", "title": "别太懒惰：CompleteP 使深度变换器计算高效", "title_en": "Don't be lazy: CompleteP enables compute-efficient deep transformers", "authors": "Nolan Dey,Bin Claire Zhang,Lorenzo Noci,Mufan Li,Blake Bordelon,Shane Bergsma,Cengiz Pehlevan,Boris Hanin,Joel Hestness", "background": "研究了在使用不同参数化（即随模型大小变化调整模型和优化器超参数的规则）时大型语言模型（LLM）训练的计算效率。一些参数化方法在模型深度变化时无法有效转移最佳基超参数（例如学习率），导致实践者需要重新调整这些超参数（昂贵），或者在重新调整不切实际时接受次优的训练。即使实现超参数转移，理论研究表明参数化方法可能仍处于懒惰学习阶段，导致各层仅学习接近线性化的特征，从而阻碍深度和非线性的有效利用。", "innovation": "识别并采用了一种称为CompleteP的参数化方法，它能够实现深入可转移的超参数并确保各层的非懒惰学习。CompleteP使得更多的模型宽度/深度比例保持计算效率，进而解锁更适合不同硬件设置和操作环境的模型形状。此外，与此前的最新技术相比，CompleteP实现了12-34%的计算效率提升。所有实验均在Cerebras CS-3系统上运行。", "conclusion": "CompleteP使得深度变换器在计算上更加高效，能够实现各层深度可转移的超参数，并且提高了计算效率，适用于各种硬件设置和操作环境。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12226", "html_url": "https://arxiv.org/abs/2505.12226", "title": "Shallow Flow Matching for Coarse-to-Fine Text-to-Speech Synthesis", "title_en": "Shallow Flow Matching for Coarse-to-Fine Text-to-Speech Synthesis", "authors": "Dong Yang,Yiyi Cai,Yuki Saito,Lixu Wang,Hiroshi Saruwatari", "background": "基于流匹配（Flow Matching, FM）机制的文本转换为语音（Text-to-Speech, TTS）模型通常采用粗细生成（coarse-to-fine generation）框架。然而，这些模型主要依赖于细粒度生成器生成的初步表示作为条件，从而可能在生成过程中失去一些重要的细节信息。", "innovation": "提出了Shallow Flow Matching（SFM）机制，一种在粗细生成框架中增强FM机制的新方法。SFM通过使用弱生成器生成的粗粒度表示来构建模型中的中间状态，并在训练过程中引入正交投影方法来动态确定这些状态的时序位置。SFM从中间状态开始推断，而不是从纯噪声开始，这使得模型更多地关注当前流匹配路径的后阶段。", "conclusion": "实验结果表明，SFM在主观和客观评估中都能显著提高语音自然度，并且在使用自适应步长偏微分方程求解器时能够显著加速推断过程。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.18458", "html_url": "https://arxiv.org/abs/2504.18458", "title": "Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning", "title_en": "Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning", "authors": "Wenyi Xiao,Leilei Gan", "background": "在通过GRPO应用强化学习到大规模的视觉-语言模型推理时，该方法难以有效扩展推理长度或在所有任务中产出冗简的内容，仅在准确性上取得边际提升。这个问题主要体现在难以克服视觉-语言模型在处理复杂推理任务时的推理深度和语言表达冗余性的问题。作者通过实证分析，发现响应长度和数据分布对模型性能有重要影响。", "innovation": "提出了一种名为FAST-GRPO的新方法，通过根据问题特性动态调整推理深度，显著提高了模型在视觉-语言模型推理任务中的性能和效率。此外，引入了两种互补的指标来估计问题难度，指导模型在何时使用快速或慢速思考做出决策。同时，将自适应长度奖励和难度感知的KL散度引入GRPO算法，使得FAST模型在七个推理基准测试中相比基线模型达到了10%以上的相对准确性提升，并且在32.7%-67.3%的生成文本行数减少的同时保持了准确性。这种新的算法平衡了推理长度和准确性的要求，有效缓解了视觉-语言模型在推理任务中的复杂性与精度之间的权衡问题。", "conclusion": "实验表明，FAST-GRPO在七个推理基准测试中的准确性优于基线模型，同时相比之前的慢思考方法减少了32.7%-67.3%的生成文本行数，有效平衡了推理长度和准确性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10465", "html_url": "https://arxiv.org/abs/2505.10465", "title": "Superposition Yields Robust Neural Scaling", "title_en": "Superposition Yields Robust Neural Scaling", "authors": "Yizhou Liu,Ziming Liu,Jeff Gore", "background": "今天的大型语言模型（LLMs）的成功依赖于一个观察：较大的模型表现更好。然而，这一神经规模法则（即损失随模型大小呈幂次定律减少）的起源仍然不清楚。已有研究表明，更大的模型通常会有更好的效果，但是这种规模规律的实际机制尚未明确。", "innovation": "作者提出了“表示重叠”的概念，认为这是导致神经规模法则的关键因素。通过Anthropic的玩具模型和权重衰减方法，作者系统地研究了损失如何随着模型大小的变化而改变。结果显示，不同频率分布下的损失会因为表示向量之间的几何重叠而在强重叠情况下呈现与模型维度的逆向关系。", "conclusion": "作者证实开源的LLMs处于强重叠状态，表明损失随模型维度呈倒数关系。此外，Chinchilla的数据也支持这一行为。研究表明，表示重叠是神经规模法则的核心驱动力，这为探索何时可以改进和何时会破坏神经规模法则提供了新的见解。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.07260", "html_url": "https://arxiv.org/abs/2505.07260", "title": "UMoE：融合注意力与FFN的共享专家架构", "title_en": "UMoE: Unifying Attention and FFN with Shared Experts", "authors": "Yuanhang Yang,Chaozheng Wang,Jing Li", "background": "混合专家（MoE）架构已被证明是扩展Transformer模型的有效方法。早期的研究主要将MoE应用于前馈网络（FFN）层，随后的研究尝试将MoE扩展到注意力层以提高模型性能。然而，现有的基于注意力的MoE层需要专门的实现，且性能不如基于FFN的版本。这项研究旨在通过重新整理注意力机制，揭示注意力模块中的前馈网络结构来弥合这一差距，从而提出一种新的统一架构UMoE，该架构可以在保持优良性能的同时实现FFN和注意力组件之间的高效参数共享。", "innovation": "论文提出了一种新的统一架构UMoE，其创新之处在于重新整理了注意力机制，凸显了注意力模块内的前馈网络结构，从而使得基于注意力的MoE层能够获得更好的性能，同时允许FFN和注意力组件之间的高效参数共享。这项工作填补了MoE在注意力层应用方面的空白，提高了模型的整体性能和效率。", "conclusion": "UMoE通过基于注意力的MoE层实现了卓越的性能，同时在FFN和注意力组件之间实现了高效的参数共享。该研究为混合专家架构在Transformer模型中的应用开辟了新的途径，促进了模型的高效扩展。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13938", "html_url": "https://arxiv.org/abs/2505.13938", "title": "CLEVER: 一个为形式验证代码生成精心编排的基准", "title_en": "CLEVER: A Curated Benchmark for Formally Verified Code Generation", "authors": "Amitayush Thakur,Jasper Lee,George Tsoukalas,Meghana Sistla,Matthew Zhao,Stefan Zetzsche,Greg Durrett,Yisong Yue,Swarat Chaudhuri", "background": "在自动化代码生成技术的发展过程中，完美实现从程序设计思路到代码实现的无缝连接一直是挑战。已有基准在测试案例、LLM生成注释以及泄漏实施逻辑等方面存在不足，无法充分检验新兴的语言模型和方法在可靠的代码生成与正式推理上的能力。", "innovation": "提出了一种精心挑选的基准 ${\rm C{\tiny LEVER}}$，包含161个问题，每个问题都包括生成对应的规范以及用Lean语言具体化满足此规范的任务。此基准避免了以前基准中的不足，如测试案例监督、大规模语言模型生成注释、泄露实现细节或产生空洞解决方案的规范。所有输出通过Lean的类型检查器验证，确保了机器可验证的正确性。该基准被用来评估几种基于最先进的语言模型的少样本和代理方法，展示了形式验证代码生成的挑战性。", "conclusion": "该基准旨在成为程序综合和形式推理的前沿挑战性标准，为现有方法的评估和未来研究提供了有力工具。所有相关代码和数据都可以在GitHub和HuggingFace上找到。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12944", "html_url": "https://arxiv.org/abs/2505.12944", "title": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs", "title_en": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs", "authors": "Jan Hagnberger,Daniel Musekamp,Mathias Niepert", "background": "使用密集空间域来解决时间依赖偏微分方程（PDEs）在多个科学和工程领域中是一个基本问题，例如气候现象和流体动力学建模。然而，直接在物理空间中执行这些计算通常会导致巨大的计算成本。为了解决这个问题，已经开发出了在压缩潜在空间中操作的神经代理模型来解决PDEs。尽管这些方法降低了计算复杂性，但它们往往使用基于Transformer的注意力机制来处理非规则采样领域，增加了内存消耗。相比之下，卷积神经网络可以在高效编码和解码的同时，只能处理规则采样。鉴于此，本文提出了一种CALM-PDE模型，能够在压缩潜在空间中高效地解决任意采样空间的PDEs。", "innovation": "文章提出了一种CALM-PDE模型，结合了连续卷积的编码-解码架构，使用受限于ε-邻域的核，并且能够自适应和优化查询点来应用卷积操作。相比于基于Transformer的方法，该模型在内存和推理时间效率方面具有显著优势，同时在多种具有规则和非规则空间采样的PDEs上表现出色或优于现有基准方法。", "conclusion": "CALM-PDE作为一种新的模型，能够在不规则空间域中高效地解决PDE问题，同时提供更好的内存和推理时间效率，优于基于Transformer的其他方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15034", "html_url": "https://arxiv.org/abs/2505.15034", "title": "RL Tango: 一起强化生成器和验证器的语言推理", "title_en": "RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning", "authors": "Kaiwen Zha,Zhengqi Gao,Maohao Shen,Zhang-Wei Hong,Duane S. Boning,Dina Katabi", "background": "近年来，强化学习（RL）成为提升大语言模型（LLMs）推理能力的有效方法，其中LLM生成器由验证器（奖励模型）引导。然而，当前针对LLMs的RL后训练方法通常使用固定的验证器（基于规则或冻结预训练），或者通过监督微调（SFT）进行有区别的训练。这种设计容易导致奖励作弊并泛化能力差，无法很好地超越其训练分布。", "innovation": "针对这些局限，本文提出了一个名为Tango的新框架，其创新之处在于使用RL同时训练LLM生成器和验证器，并且验证器是通过RL在生成层面进行训练并与其演变。与确定性或SFT训练的验证器不同，这种生成的RL训练验证器表现出更强的稳健性和更好的泛化能力，促进生成器的有效相互强化。实验结果表明，Tango的两个组件在7B/8B规模模型中表现最佳：生成器在五个竞赛级别的数学基准测试和四个具有挑战性的离域推理任务中表现最佳，验证器在ProcessBench数据集上领先。", "conclusion": "两个组件在最困难的数学推理问题上表现出显著的提升。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15293", "html_url": "https://arxiv.org/abs/2505.15293", "title": "LLM-Explorer: 大型语言模型驱动的强化学习策略探索增强插件", "title_en": "LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models", "authors": "Qianyue Hao,Yiwen Song,Qingmin Liao,Jian Yuan,Yong Li", "background": "现有的强化学习（RL）中的策略探索方法，如贪心策略和高斯过程，利用预设的随机过程，并且这些方法在所有类型的任务中都以相同的方式应用，忽略了任务特有的影响策略探索的因素。在RL训练过程中，这些随机过程的演变是刚性的，通常只包含方差的衰减，无法根据代理的实时学习状态灵活调整。", "innovation": "我们受到大型语言模型（LLMs）分析和推理能力的启发，设计了LLM-Explorer，这是一种插件模块，可以适配各种广泛使用的RL算法，包括DQN系列、DDPG、TD3及其变体，通过插件化的方式动态生成任务特定的探索策略，提高了策略探索的效果。LLM-Explorer通过分析代理在给定任务中的学习轨迹，生成未来策略探索的概率分布，并根据学习过程动态更新。", "conclusion": "我们在Atari和MuJoCo基准测试中的广泛实验表明，LLM-Explorer能够显著提升RL策略探索，平均性能提升了37.27%。我们的代码开源于此http[s]://example.com/以实现可重复性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13358", "html_url": "https://arxiv.org/abs/2505.13358", "title": "使用Koopman建模的一步离线蒸馏扩散模型", "title_en": "One-Step Offline Distillation of Diffusion-based Models via Koopman Modeling", "authors": "Nimrod Berman,Ilan Naiman,Moshe Eliasof,Hedi Zisling,Omri Azencot", "background": "基于扩散的生成模型已经在实践中展示了出色的表现，但是它们的迭代采样过程计算成本仍然很高。消除这一成本的一个重要策略是蒸馏，尤其是离线蒸馏具有高效、模块化和灵活等优势。研究表明，扩散模型可以看作是动力系统理论的一部分，但同时在这一领域还存在许多未充分利用的强大工具。此外，扩散模型本身就对潜在空间施加了结构化且语义连贯的轨迹。因此，本文提出了一个基于Koopman理论的新型离线蒸馏方法——Koopman Distillation Model (KDM)，该方法利用Koopman理论将非线性动力学表示成线性的变换空间中的动力学。KDM通过编码噪声输入至嵌入空间，使用学习到的线性操作符向前传播，并通过解码器重建清晰样本，从而实现了保持语义保真度的一步生成方法。此外，这种方法还得到了理论上的支持，即在一定假设下，学习到的扩散动力学可以得到有限维的Koopman表示，且Koopman潜在空间中的临近性与生成输出中语义相似性相关，有利于轨迹对齐。", "innovation": "介绍了Koopman Distillation Model (KDM)，一种基于Koopman理论的一步离线蒸馏方法。该模型通过利用Koopman理论将非线性动态转化为线性表示，实现了单步生成策略并保持了语义保真度，这一方法克服了传统扩散模型采样过程中的高计算成本问题。理论分析进一步表明，该方法适用于经典的动力系统表示，并在生成模型的蒸馏中表现出高效性和灵活性。", "conclusion": "KDM在标准的离线蒸馏基准上获得了竞争力的性能，表明了这种方法的有效性和效率。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16581", "html_url": "https://arxiv.org/abs/2505.16581", "title": "如何通过提炼政策的集成提高强化学习中的泛化能力", "title_en": "How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning", "authors": "Max Weltevrede,Moritz A. Zanger,Matthijs T.J. Spaan,Wendelin Böhmer", "background": "在零样本策略迁移的强化学习设置中，目标是训练一个代理在固定的一组训练环境中，以便在类似的但未见过的测试环境中泛化。先前的研究表明，训练后的策略提炼有时可以产出在测试环境中性能优于原始策略的政策。然而，目前还不清楚为什么这样，以及使用什么数据进行策略提炼。本文在某些假设下证明了策略提炼后的泛化界，并提供了两个实用的见解：为了提高泛化能力，应该1) 训练提炼政策的集成，2) 在尽可能多的来自训练环境的数据上进行提炼。作者通过实验证明了这些见解在更宽泛的场景下仍然有效，即使理论所需的假设不再适用。最后，本文展示了在多样数据集上提炼出的政策集成可以在很大程度上优于原代理的泛化能力。", "innovation": "本文在某些假设下证明了策略提炼后的泛化界，提供了训练政策提炼的集成以及在尽可能多的来自训练环境的数据上进行提炼以提高泛化能力的实用见解，通过实验证明了这些见解的广泛适用性，尤其是当理论所需的假设不再适用时。最终展示了多样数据集上提炼的政策集成在泛化方面表现出更好的性能。", "conclusion": "通过在多样数据集上提炼政策的集成，可以显著提高在类似未见过的测试环境中的泛化性能。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14827", "html_url": "https://arxiv.org/abs/2505.14827", "title": "文本生成超越离散令牌抽样", "title_en": "Text Generation Beyond Discrete Token Sampling", "authors": "Yufan Zhuang,Liyuan Liu,Chandan Singh,Jingbo Shang,Jianfeng Gao", "background": "在标准的自回归生成中，LLM预测下一个令牌的概率分布，然后抽样一个离散令牌并丢弃这个分布，仅将抽样的令牌作为新的输入传递。为了保留这种分布中的丰富信息，本文提出了一种名为Mixture of Inputs (MoI)的方法，这是一种无需训练的方法来实现自回归生成。在生成离散令牌之后，我们构建了一个新输入，将生成的离散令牌与之前丢弃的概率分布混合。具体来说，使用了一种贝叶斯估计方法，将令牌分布视为先验，抽样令牌作为观测值，并用连续后验估计代替传统的单热向量作为新模型输入。MoI方法使得模型在整个生成过程中维持更丰富的内部表示，从而提高了文本质量和推理能力。", "innovation": "本文提出了Mixture of Inputs (MoI)方法，这是一种无需额外训练即可实现自我回归生成的方法，通过将先前丢弃的概率分布与生成的离散令牌混合作为新输入，保持了丰富信息的使用。通过使用贝叶斯估计方法，MoI将单热向量替换为连续后验估计作为新模型输入。这种方法使模型在整个生成过程中保持更丰富的内部表示，从而提高了文本质量和推理能力。", "conclusion": "在数学推理、代码生成和博士级别QA任务中，MoI方法在多个模型（包括QwQ-32B、Nemotron-Super-49B、Gemma-3-27B和DAPO-Qwen-32B）上取得了更好的性能，且无需额外训练且计算开销几乎为零。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16690", "html_url": "https://arxiv.org/abs/2505.16690", "title": "您的预训练大语言模型其实是无监督的信心调校器", "title_en": "Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator", "authors": "Beier Luo,Shuoyuan Wang,Sharon Li,Hongxin Wei", "background": "大语言模型（PLMs）在适应人类偏好及下游任务方面需要通过后训练来优化。然而，后训练模型（PoLMs）往往过于自信，这对关键应用的可靠性构成威胁。缺乏针对具体下游任务的带标签数据使得这种调整难点重重。论文识别并探讨了解决这一问题的路径，特别是通过一种新颖的无监督方法——矛盾共识意识信心校准（DACA），来优化后训练中的参数（例如温度$\tau$）。", "innovation": "研究提出了一种新的无监督方法——矛盾共识意识信心校准（DACA），以优化后训练中的-confidence calibration。该方法通过仅使用一致性示例进行校准，而非侧重于分歧示例，从而避免增加过大温度$\tau$值的问题。这种方法有效地降低了温度$\tau$值的影响，提高了校准效果。实验展示了这种方法的有效性，在常见基准测试中，开源和API基础的大语言模型（如GPT-4o）的平均ECE提高了15.08%。", "conclusion": "该研究通过引入矛盾共识意识信心校准（DACA）方法，解决了预训练模型后训练中存在的过自信问题。通过避免因分歧示例引起的过大温度$\tau$值，DACA提升了信心校准的效果，并在多个大语言模型中验证了其有效性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15984", "html_url": "https://arxiv.org/abs/2503.15984", "title": "DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration", "title_en": "DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration", "authors": "Suraj Singh,Anastasia Batsheva,Oleg Y. Rogov,Ahmed Bouridane", "background": "现代图像修复和超分辨率方法依赖于深度学习，因其性能优于传统算法。然而，深度学习通常需要大量的训练数据集，而在天体摄影中这类数据集很少见。Deep Image Prior (DIP)通过在单张图像上进行盲训练来绕过这个限制，尽管在某些情况下有效，但DIP经常会遇到过拟合、伪影生成和不稳定的问题。因此，亟需提出一种能够克服这些挑战并提高通用性能的方法。", "innovation": "本文提出了一种名为DIPLI的框架，该框架从单帧训练转移到多帧训练，结合使用反投影技术，通过TVNet模型估计光流，以及使用拉angevin动力学获得非确定性预测的无偏蒙特卡洛估计。这一方法在合成数据集上的实验显示，与经典的幸运成像技术、DIP、基于Transformer的模型RVRT和基于扩散的模型DiffIR2VR-Zero相比，有持续改进，特别是在SSIM、PSNR、LPIPS和DISTS指标上表现出更优的质量恢复。此外，该方法还需要比幸运成像更少的输入图像，并且不易过拟合或产生伪影。在现实世界中的天文学数据上进行的评估也证实了方法的有效性，显示了其在不同域中的稳健性。", "conclusion": "该研究方法在合成数据集上表现出持续改进，并且在现实世界中的天文学数据上也显示了高重建质量，这说明该方法在实际应用中的潜力是可靠的。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16722", "html_url": "https://arxiv.org/abs/2505.16722", "title": "破除mBad！跨语言脱毒的监督微调", "title_en": "Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification", "authors": "Himanshu Beniwal,Youngwoo Kim,Maarten Sap,Soham Dan,Thomas Hartvigsen", "background": "随着大型语言模型（LLMs）在世界各地的应用变得越来越普遍，确保它们在多种语文环境中没有毒性内容仍然是一个关键挑战。因此，研究“跨语言脱毒”这一跨语言范式变得非常重要。该范式旨在通过在不同语言和书写体系中高资源语言和低资源语言之间转移脱毒能力，减轻毒性内容的影响。这项研究通过392个广泛设置来评估跨语言脱毒在有限数据条件下对毒性减少的有效性，同时分析不同语言环境下的毒性减轻措施如何影响模型在非毒性任务上的表现，揭示安全性和知识保留之间的权衡关系。相关代码和数据集已公开发布。", "innovation": "提出了跨语言脱毒的监督微调方法，旨在减轻毒性内容的影响，并使脱毒能力能够跨越不同书写体系及资源水平的语言场景进行转移。通过这个方法，研究者探索了不同语言环境下的脱毒效果，同时分析了毒性减轻措施对模型在非毒性任务上表现的影响，揭示了安全性与知识保留之间的权衡关系。这种方法的创新在于提供了一种在语言资源有限的情况下有效减轻毒性内容的方法。", "conclusion": "通过跨语言脱毒的研究，证实了监督微调的有效性，能够显著减少跨语言环境下的毒性内容，并且在一定程度上不影响模型在非毒性任务上的表现。同时，研究揭示了毒性减轻措施与模型安全性及知识保留之间的权衡关系。相关代码和数据集已经公开发布，便于进一步的研究和应用。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19667", "html_url": "https://arxiv.org/abs/2505.19667", "title": "LeCoDe：交互法律咨询对话评估基准数据集", "title_en": "LeCoDe: A Benchmark Dataset for Interactive Legal Consultation Dialogue Evaluation", "authors": "Weikang Yuan,Kaisong Song,Zhuoren Jiang,Junjie Cao,Yujie Zhang,Jun Lin,Kun Kuang,Ji Zhang,Xiaozhong Liu", "background": "法律咨询是保护个人权利并确保人们能够获得司法服务的重要手段，但由于专业人员短缺，许多个人依然难以负担得起且无法获得这些服务。尽管最近大语言模型（LLMs）的进步为大规模、低成本的法律援助提供了可能，但现有的系统在处理互动和知识密集型的现实生活咨询方面仍然表现不足。", "innovation": "该研究引入了LeCoDe，这是一个包含3,696个法律咨询对话和110,008个对话回合的实际互动作业数据集，旨在评估和提高LLMs的法律咨询能力。LeCoDe通过从短视频平台收集直播咨询来创新性地为法律咨询提供真实的多轮对话。此外，法律专家的严格标注增加了数据集的专业见解和专业知识。研究还提出了一种全面的评估框架，该框架从澄清能力和专业建议质量两方面评估LLMs的咨询能力，涵盖了12个指标。通过在多种通用和特定领域语言模型上的广泛实验，结果显示，即使是最先进的模型如GPT-4在澄清和建议质量上的得分也很低，强调了专业咨询场景的复杂性。", "conclusion": "本研究基于发现，进一步探讨了几种策略以提高LLMs的法律咨询能力。该基准数据集有助于推进法律领域对话系统的研究，特别是模拟更接近现实用户-专家交互的场景。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21364", "html_url": "https://arxiv.org/abs/2505.21364", "title": "无需牺牲的可解释性：Mixture of Decoders的忠实密集层分解", "title_en": "Towards Interpretability Without Sacrifice: Faithful Dense Layer Decomposition with Mixture of Decoders", "authors": "James Oldfield,Shawn Im,Sharon Li,Mihalis A. Nicolaou,Ioannis Patras,Grigorios G Chrysos", "background": "多层感知机（MLPs）是大型语言模型的重要组成部分，但由于它们的密集表示，使得理解和编辑变得困难。最近的方法通过神经元级别的稀疏性学习可解释的近似值，但未能忠实重建原始映射，显著提高了模型的下一个标记交叉熵损失。背景强调了在保持可解释性的同时，需要保持模型性能不牺牲准确性的问题。", "innovation": "作者提倡从全层级别稀疏性转向稀疏层级别的稀疏性，以克服稀疏层近似中的准确性和性能之间的权衡问题。通过引入Mixture of Decoders（MxDs），这种方法将预训练的密集层扩展为数万个专业子层。通过一种灵活的张量分解形式，每个稀疏激活的MxD子层实现了全秩权重的线性变换，即使在高度稀疏的情况下也能保持原解码器的表征能力。实验证明，MxDs在高达30亿参数的语言模型中，在稀疏性-准确性的边界上显著优于现有方法（如Transcoders）。此外，MxDs在稀疏探针和特征导向的研究中展示了类似的专业化特征，开辟了一条新的设计可解释且忠实的分解路径。", "conclusion": "实验结果表明，MxDs在保持链结稠密层分解的准确性的同时，能够显著提高其实现可解释性的能力，为设计更加可解释的语言模型提供了新的途径。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22038", "html_url": "https://arxiv.org/abs/2505.22038", "title": "平衡的标记剪枝：超越局部优化加速视觉语言模型", "title_en": "Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization", "authors": "Kaiyuan Li,Xiaoyue Chen,Chen Gao,Yong Li,Xinlei Chen", "background": "大视觉-语言模型（LVLMs）在多模态任务中通过将图像编码成数千个标记展示了显著的效果。然而，大量图像标记导致了显著的计算 overhead。以前的方法尝试通过标记剪枝来减少图像标记的数量，通常基于注意力分数或图像标记多样性进行选择。我们的实验发现，现有方法往往忽略了剪枝对当前层输出（局部）和后续层输出（全局）的联合影响，导致了次优的剪枝决策。", "innovation": "我们提出了平衡的标记剪枝（BTP），一种即插即用的方法来剪枝视觉标记。该方法利用一个小校准集将剪枝过程分为多个阶段。在早期阶段，该方法侧重于剪枝对后续层输出的影响，而在较深的阶段，聚焦于保持局部输出的一致性。广泛实验展示了该方法在多个LVLMs和多个基准上的有效性。同时，该方法在平均情况下实现了78%的压缩率，保留了原始模型96.7%的性能。", "conclusion": "我们的方法通过平衡剪枝，能够在多个 LVLMs 上实现显著的压缩率并且保持高性能。我们的代码可以在给定的URL中找到。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21441", "html_url": "https://arxiv.org/abs/2505.21441", "title": "随机森林自动编码", "title_en": "Autoencoding Random Forests", "authors": "Binh Duc Vu,Jan Kapar,Marvin Wright,David S. Watson", "background": "该文基于非参数统计和谱图论的基础结果，提出了一种正则的方法来进行随机森林的自动编码。该方法旨在学习模型的一种低维表示，以便优化地表示数据中的关系。通过约束优化、分裂重新标记和最近邻回归，提供了解码问题的精确和近似解法，这些方法有效地反转了压缩管道，通过集合中的树木学习的分割来建立从嵌入空间到输入空间的映射。所得解码器在常见的正则假设下是普遍一致的。该过程适用于监督或无监督模型，提供对条件或联合分布的洞察。", "innovation": "提出了一种基于随机森林的自动编码方法，利用非参数统计和谱图论的基础结果来学习最优的数据关系表示。通过对解码问题的精确和近似求解，结合约束优化、分裂重新标记和最近邻回归，实现了从嵌入空间到输入空间的有效映射。所得解码器在常见的正则假设下拥有普遍一致性，并可应用于监督或无监督模型，能力涵盖数据可视化、压缩、聚类和降噪等领域，具有广泛的应用前景。", "conclusion": "研究展示了该自动编码方法在不同类型数据（如表格数据、图像数据和基因组数据）上的应用，表明该方法在各种应用场景中具有简单性和实用性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22389", "html_url": "https://arxiv.org/abs/2505.22389", "title": "使用扰动训练，合并推理：一种两阶段持续学习框架", "title_en": "Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning", "authors": "Haomiao Qiu,Miao Zhang,Ziyue Qiao,Liqiang Nie", "background": "持续学习（CL）的目标是让模型从连续的任务序列中不断获取新知识，同时避免已学习信息的遗忘。然而，现有CL方法仅依赖最近任务的参数进行推理，这使得它们容易遭受灾难性遗忘。本文通过借鉴模型合并技术的成功经验，提出了一种创新的方法。", "innovation": "本文提出了Perturb-and-Merge（P&M）框架，将模型合并技术融入CL中，以减轻遗忘问题。具体而言，P&M在每完成一个任务后，通过形成旧模型和新任务特定模型的凸组合来构建新模型。通过理论分析，P&M最小化了所有任务的总损失增加量，并在轻度假设下推导出合并系数的闭式解。此外，通过使用Hessian矩阵和任务向量构造的正则化术语，减轻了合并过程中引入的降级问题，并通过一种在无额外前向或反向传播的情况下有效近似正则化术语的随机扰动策略，进一步提高了合并模型的性能。", "conclusion": "通过将P&M框架与参数高效的LoRA方法结合，减少了内存开销。提出的P&M方法在几个持续学习基准数据集上取得了最先进的性能。代码可在提供链接处获取。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05341", "html_url": "https://arxiv.org/abs/2506.05341", "title": "直接基于空间推理的3D室内场景合成数值布局生成", "title_en": "Direct Numerical Layout Generation for 3D Indoor Scene Synthesis via Spatial Reasoning", "authors": "Xingjian Ran,Yixuan Li,Linning Xu,Mulin Yu,Bo Dai", "background": "3D室内场景的现实合成对于体现式AI和数字内容创作至关重要。它可以自然地分为两个子任务：对象生成和布局生成。虽然近年来生成模型在对象级别的质量和可控性上取得了显著进展，但布局生成仍然面临挑战，主要是由于可用数据集有限。现有的方法要么过度拟合这些数据集，要么依靠预定义的约束来优化数值布局，牺牲了灵活性。因此，这些方法无法生成开放词汇的场景，同时也无法遵循精细粒度的用户指令。", "innovation": "直接提出了DirectLayout框架，使用大型语言模型（LLMs）的一般化空间推理直接从文本描述生成数值3D布局。DirectLayout分解生成过程为三个阶段：生成顶视图（BEV）布局、将其提升到3D空间、并进一步优化对象放置。为了使模型能够进行显式空间推理并掌握基础对象放置原则，采用基于3D-Front数据集的Chain-of-Thought（CoT）激活。此外，还设计了CoT-Grounded生成布局奖励以增强泛化性和空间规划能力。推理过程中，DirectLayout通过上下文学习迭代资产-布局对齐来解决资产布局不匹配问题。广泛的实验表明，DirectLayout能够实现令人印象深刻的语义一致性、泛化能力和物理可解释性。", "conclusion": "DirectLayout框架通过使用大型语言模型的一般化空间推理，从文本描述直接生成数值3D布局，实现了对3D室内场景合成的高质量布局生成。通过设计CoT激活和CoT-Grounded生成布局奖励，提高了模型的泛化能力和空间规划能力。在上下文学习的帮助下，DirectLayout能够迭代调整资产布局，确保生成的场景既遵循用户指令又具有物理合理性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.16349", "html_url": "https://arxiv.org/abs/2506.16349", "title": "基于自回归图像生成的水印技术", "title_en": "Watermarking Autoregressive Image Generation", "authors": "Nikola Jovanović,Ismail Labiad,Tomáš Souček,Martin Vechev,Pierre Fernandez", "background": "生成模型的输出水印化已被证明是一种很有前景的方法，用于追踪其来源。尽管自回归图像生成模型引起了广泛关注，它们存在潜在的滥用风险，但之前的研究尚未尝试在生成过程的标记层面嵌入水印。", "innovation": "本文提出了首个在自回归图像生成模型生成的图像标记层面嵌入水印的方法，通过将自然语言生成模型的水印技术应用到这一场景中。为解决反向循环一致性问题，同时增强方法对常规图像变换、神经压缩和移除攻击的鲁棒性，该研究引入了定制化的标记器-反标记器微调流程和互补的水印同步层。", "conclusion": "实验表明，本方法能够实现可靠且鲁棒的水印检测，且其p值具有理论根基。相关代码和模型可以在指定的链接中找到。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09018", "html_url": "https://arxiv.org/abs/2506.09018", "title": "Edit Flows: 使用编辑操作实现流动匹配", "title_en": "Edit Flows: Flow Matching with Edit Operations", "authors": "Marton Havasi,Brian Karrer,Itai Gat,Ricky T. Q. Chen", "background": "自回归生成模型能够自然地生成可变长度的序列，而非自回归模型则难以生成此类序列，通常需要引入固定的、基于令牌结构来解决生成问题。本文通过引入基于编辑操作（插入、删除和替换）的离散流动，提出了Edit Flows模型，以克服这一缺陷。通过对序列空间上的连续时间马尔可夫链建模，使得生成过程更加灵活，更能适应序列数据结构的特点。此外，利用扩展状态空间和辅助变量的训练方法，使得学习过程更加高效和可计算。经过实验表明，Edit Flows模型在图像字幕生成任务中优于自回归模型，在文本和代码生成任务中显著优于遮掩模型构建方法，从而证明了其有效性，", "innovation": "提出了Edit Flows模型，通过定义离散流作为编辑操作（插入、删除和替换）作用于序列之上，实现了对序列数据结构的更紧密匹配。利用连续时间马尔可夫链对编辑操作建模，提供了灵活的位置相关生成方式，并通过扩展状态空间和辅助变量提高了学习的效率与可计算性。", "conclusion": "实验结果显示，Edit Flows模型在图像字幕生成和文本、代码生成任务中表现出色，优于传统的自回归模型及遮掩模型，证明了其在序列数据生成中的优势。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07031", "html_url": "https://arxiv.org/abs/2506.07031", "title": "HauntAttack: 当攻击影随推理之后", "title_en": "HauntAttack: When Attack Follows Reasoning as a Shadow", "authors": "Jingyuan Ma,Rui Li,Zheng Li,Junfeng Liu,Heming Xia,Lei Sha,Zhifang Sui", "background": "新兴的大型推理模型（LRMs）在数学和推理任务中表现出色，显示出强大的能力。然而，推理能力的提升和内部推理过程的暴露带来了新的安全漏洞。当推理与危害性交织时，LRMs 在推理模式下是否会更容易遭受攻击？为了探讨这个问题，作者引入了HauntAttack，一种新颖且通用的黑盒对抗性攻击框架，它可以系统地将有害指令嵌入推理问题中。研究发现在11种LRMs上的攻击成功率平均为70%，这比之前最强大的基线模型提高了12个百分点。此外，进一步的分析表明，即使是高级的安全对齐模型，仍高度容易遭受基于推理的攻击，这揭示了在未来模型开发中平衡推理能力和安全性的重要迫切性挑战。", "innovation": "提出了一种新颖且通用的黑盒对抗性攻击框架，HauntAttack，该框架可以系统地将有害指令嵌入到推理问题中，引导模型逐步向不安全的输出迈进。通过对11种LRMs进行评估，HauntAttack取得了显著的攻击成功率，并揭示了即使高级安全对齐模型仍高度易受推理攻击的影响，这对未来的模型开发具有重要的启示意义。", "conclusion": "研究发现，相较于最先进的基线模型，HauntAttack的攻击成功率提高了12个百分点。分布分析表明，即使是高度安全对齐的模型，仍然很容易受到基于推理的攻击。这表明在未来模型开发中重平衡推理能力和安全性的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07520", "html_url": "https://arxiv.org/abs/2506.07520", "title": "LeVo：基于多偏好对齐的高质量歌曲生成", "title_en": "LeVo: High-Quality Song Generation with Multi-Preference Alignment", "authors": "Shun Lei,Yaoxun Xu,Zhiwei Lin,Huaicheng Zhang,Wei Tan,Hangting Chen,Jianwei Yu,Yixuan Zhang,Chenyu Yang,Haina Zhu,Shuai Wang,Zhiyong Wu,Dong Yu", "background": "近期，大型语言模型（LLMs）和音频语言模型在音乐生成中取得了显著的进展，特别是在歌词到歌曲的生成中。然而，现有方法仍然面临复杂的歌曲编排和高质量数据稀缺的问题，这限制了音频质量、音乐性、指令遵循能力和声乐-伴奏和谐度。", "innovation": "该研究提出了LeVo框架，这是一个基于语言模型的方法，由LeLM和Music Codec构成。LeLM能够并行建模两种类型的令牌：混音令牌，用于表示人声和伴奏以改善声乐-伴奏和谐度；双轨令牌，分别编码人声和伴奏以实现高质量的歌曲生成。它通过两个解码器的Transformer和模块化的扩展训练策略来防止不同令牌类型之间的干扰。此外，该研究引入了一种基于直接偏好优化（DPO）的多偏好对齐方法，通过半自动的数据构建过程和后训练处理来处理多元的人类偏好。实验证明，LeVo在客观和主观指标上显著优于现有开源方法，且在与行业系统竞争时表现良好。", "conclusion": "LeVo框架不仅显著改善了歌曲生成的质量，而且通过多偏好对齐方法增强了音乐性和指令遵循能力。实验结果表明，该方法在多种场景下的性能优于现有方法，同时能够与行业系统竞争，并且实验性例和源代码已经公开。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01665", "html_url": "https://arxiv.org/abs/2506.01665", "title": "利用证明安全性强化学习中的解析梯度", "title_en": "Leveraging Analytic Gradients in Provably Safe Reinforcement Learning", "authors": "Tim Walter,Hannah Markgraf,Jonathan Külz,Matthias Althoff", "background": "在关键安全应用中部署自主机器人需要安全性保证。证明安全的强化学习是一个活跃的研究领域，旨在通过保障措施提供这样的保证。现有的方法主要针对基于采样的强化学习，而基于解析梯度的强化学习通常能够在较少的环境交互中获得更优表现，但缺乏相应的保障手段以应对这一学习范式。", "innovation": "本文通过开发第一个有效的基于解析梯度的强化学习保障方法，填补了这一领域的空白。研究了现有的差分保障措施，通过修改映射和梯度公式进行适应，并将其整合到最先进的学习算法和差分模拟中。通过在三个控制任务上的数值实验，评估了不同保障措施对学习的影响。结果表明，在不牺牲性能的情况下可以实现保障性训练。", "conclusion": "实验结果证明了保障性训练在不降低性能的前提下是可行的。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13992", "html_url": "https://arxiv.org/abs/2506.13992", "title": "AssistedDS：评估外部领域知识如何辅助LLMs在自动化数据科学中的表现", "title_en": "AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science", "authors": "An Luo,Xun Xian,Jin Du,Fangqiao Tian,Ganghua Wang,Ming Zhong,Shengchun Zhao,Xuan Bi,Zirui Liu,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Mingyi Hong,Jie Ding", "background": "大型语言模型（LLMs）已经推动了数据科学工作流的自动化。然而，目前尚不清楚它们是否能够像人类数据科学家一样有效利用外部领域知识。为了回答这一问题，本文提出了一种基准测试AssistedDS（辅助数据科学），旨在系统性地评估LLMs在表格预测任务中处理领域知识的能力。该基准测试包括具有已知生成机制的合成数据集和真实世界的Kaggle竞赛，每个数据集都配有定制的有益和有害文档集合。", "innovation": "引入了AssistedDS作为评估LLMs在表格预测任务中处理领域知识能力的基准测试。它包括具有已知生成机制的合成数据集、真实世界的Kaggle竞赛以及相应的文档集合。评估了当前最先进的LLMs辨别、吸收和运用有益或有害领域知识的能力，具体评估了提交的正确性、信息召回率和预测性能。", "conclusion": "研究结果表明，（1）LLMs常常无批判地接受提供的信息，在引入有害信息时显著损害其预测性能；（2）有益指导往往无法抵消有害信息的负面影响；（3）在Kaggle数据集中，LLMs常在时间序列数据处理、不同折叠的一致特征工程和分类变量解释上出现问题。研究结果显示，目前模型在处理和利用专家知识方面存在显著不足，强调了开发更稳健、知识感知的自动化数据科学系统的重要性。数据和代码可以在以下链接获取：this https URL"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05821", "html_url": "https://arxiv.org/abs/2506.05821", "title": "FuseUNet：U型网络的多尺度特征融合方法", "title_en": "FuseUNet: A Multi-Scale Feature Fusion Method for U-like Networks", "authors": "Quansong He,Xiangde Min,Kaishen Wang,Tao He", "background": "医学图像分割是计算机视觉中的关键任务，UNet架构在此领域起到了里程碑式的作用。UNet家族的典型特征是跳接连接，然而他们存在的问题是：（1）在不同尺度下特征之间的互动不足；（2）依赖于简单的连接或相加操作，限制了信息的有效整合。尽管现有研究主要集中在增强编码器和解码器的能力，但上述问题并未得到有效解决。", "innovation": "为解决上述挑战，该研究提出了一个创新的多尺度特征融合方法，将UNet的解码过程重新构想为求解初始值问题（IVP），并将跳接连接视为离散节点。研究利用线性多步法的原则，提出了一种自适应常微分方程方法，以实现有效的多尺度特征融合。该方法与编码器和解码器架构无关，可以在各种类似U-Net的网络中灵活应用。实验结果表明，该方法能够提高特征利用效率、减少网络参数量并保持高性能", "conclusion": "研究通过在多个数据集上的实验，证明了所提方法的有效性，包括ACDC、KiTS2023、MSD脑肿瘤和ISIC2017/2018皮肤病变分割数据集。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17065", "html_url": "https://arxiv.org/abs/2506.17065", "title": "基于流的方法在动态因果模型中的应用，处理非高斯或异方差噪声", "title_en": "Flow based approach for Dynamic Temporal Causal models with non-Gaussian or Heteroscedastic Noises", "authors": "Abdellah Rahmani,Pascal Frossard", "background": "理解多变量时间序列中的因果关系至关重要，尤其是在金融或神经学数据处理中。多变量时间序列通常表现出多个变化的时期，每个时期有未知的开始和结束，且每个时期的因果结构都不相同。因此，推断因果依赖关系和时期变化对分析潜在过程至关重要。然而，在这种情况下，因果结构学习存在挑战，因为因果图和混合函数可能在每个时期都有所不同，且噪声分布可能非高斯或异方差。现有的因果发现方法无法解决这些问题，因为它们通常假设稳态或具有恒定方差的高斯噪声。因此，本文提出了FANTOM框架，该框架可以处理非稳态过程和非高斯或异方差噪声。", "innovation": "FANTOM框架同时推断出因果图的数量及其对应的索引，并学习每个时期的有向无环图。该方法使用贝叶斯期望最大化算法来最大化数据对数似然的证据下界。此外，论文在理论层面证明了在固定的和非固定的条件下，FANTOM中提出的时变异方差因果模型是可识别的。大量合成和真实数据的实验表明FANTOM方法优于现有方法，能够处理非稳态过程以及非高斯或异方差噪声。", "conclusion": "FANTOM框架能够在多变量时间序列中同时识别因果结构和非稳态时期，并能够有效处理非高斯或异方差噪声。实验结果表明，该方法能够克服现有方法的局限性，在处理因果发现任务时表现更优。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23751", "html_url": "https://arxiv.org/abs/2505.23751", "title": "REOrdering Patches Improves Vision Models", "title_en": "REOrdering Patches Improves Vision Models", "authors": "Declan Kutscher,David M. Chan,Yutong Bai,Trevor Darrell,Ritwik Gupta", "background": "序列模型如.transformers需要将输入表示为一维序列。在视觉领域，这通常涉及使用固定的行主要（行扫描）顺序来展平图像。虽然全自注意力是置换协变的，但现代长序列.transformers越来越多地依赖于破坏这种协变性的架构近似，从而引入了对补丁顺序的敏感性。我们的研究表明，补丁顺序在这些设置中对模型性能有显著影响，简单的替代方法，如列主要或希尔伯特曲线，会显著改变准确性。", "innovation": "我们提出了一种两阶段框架.REOrder，用于发现任务最优的补丁序排列。首先，我们通过评估各种补丁序列的压缩性来推导出信息论先验。然后，我们通过优化Plackett-Luce策略来学习置换策略，使用REINFORCE。这种方法能有效学习组合置换空间中的策略。REOrder在ImageNet-1K中将顶级正确率提高了最高3.01%，在Functional Map of the World中提高了13.35%。", "conclusion": "我们证明补丁顺序对模型性能有显著影响，提出了一种两阶段框架REOrder来优化补丁序排列，该框架通过评估可压缩性和使用REINFORCE优化策略，显著提高了视觉模型的表现。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22601", "html_url": "https://arxiv.org/abs/2505.22601", "title": "过参数化环境下的机器忘却", "title_en": "Machine Unlearning under Overparameterization", "authors": "Jacob L. Block,Aryan Mokhtari,Sanjay Shakkottai", "background": "传统的机器忘却算法旨在通过移除特定的训练样本来消除它们对模型的影响，理想情况下能够恢复仅基于其余数据训练所得的模型。然而，在过参数化环境中，许多模型能够完美拟合数据，此时传统方法定义解为任意数据保留集上的损失最小化者已经不足，因为原始模型可能已经能够拟合保留的数据，从而满足该条件。在此背景下，损失梯度消失，使得依赖梯度扰动的先前方法失效，促使探索新的忘却定义及算法。", "innovation": "本文定义了过参数化环境下的忘却解为保留数据的最小复杂度拟合者，并提出了一种新的算法框架，仅需访问原始解关于保留数据集的模型梯度。该框架通过最小化正则化目标并限制扰动与模型梯度正交，实现了一阶拟合条件的松弛化。本文还为不同模型类别提供了精确和近似的忘却保障，并证实了该框架在多种忘却实验中的表现优于现有基准。", "conclusion": "通过定义新的忘却解和提出创新的算法框架，本文克服了在过参数化环境中传统方法的局限性，并提供了针对不同模型类别的忘却保证。实验结果表明，本文的方法在多种忘却实验中表现更优。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18631", "html_url": "https://arxiv.org/abs/2506.18631", "title": "ReDit: 通过奖励抖动改进大语言模型策略优化", "title_en": "ReDit: Reward Dithering for Improved LLM Policy Optimization", "authors": "Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu", "background": "DeepSeek-R1 通过基于规则的奖励系统成功增强了大规模语言模型的推理能力。尽管它具有避免奖励作弊的优点，但这些奖励函数通常是离散的，容易导致梯度异常、优化不稳定和收敛缓慢等问题。为了应对这些问题，提出了 ReDit 方法，即通过对离散奖励信号添加简单的随机噪声进行抖动，以提供探索性的梯度并促进平稳的梯度更新，从而加速收敛，同时引入随机性鼓励模型探索新的策略从而跳出局部最优。", "innovation": "ReDit方法通过向离散奖励信号添加简单随机噪声，改变了传统的奖励信号，使得学习过程中持续提供探索性梯度，从而更平滑地更新梯度并加速收敛。该方法在不同任务上表现出色，在训练步骤减少了约10%的情况下，性能与标准GRPO相当，并且在相同训练时间内，性能提高了4%。并且通过理论分析证明了它的优点，通过可视化进一步验证了改进效果。", "conclusion": "ReDit通过简单的随机噪声添加，有效解决了离散奖励可能带来的梯度异常和优化不稳定性问题，该方法显著提高了训练效率和模型性能，特别是在与标准GRPO相比时，在较短的训练时间内保持了与之相当甚至更好的性能表现。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19358", "html_url": "https://arxiv.org/abs/2506.19358", "title": "从高信噪比雷达信号到心电图：有限数据场景下的心血管聚焦算法的迁移学习模型", "title_en": "From High-SNR Radar Signal to ECG: A Transfer Learning Model with Cardio-Focusing Algorithm for Scenarios with Limited Data", "authors": "Yuanyuan Zhang,Haocheng Zhao,Sijie Xiong,Rui Yang,Eng Gee Lim,Yutao Yue", "background": "在文献中，心电图（ECG）可以通过雷达信号得到恢复，但是这种恢复的效果依赖于高质量的雷达信号和大量的雷达-ECG对进行培训。由于缺乏数据，这种技术在新场景中的应用受到限制。因此，本文旨在探讨在数据稀缺的新场景下，使用有限数据的雷达信号来恢复ECG的方法，提出了一种心血管聚焦和跟踪（CFT）算法，确保有效获取高质雷达信号，以及一个迁移学习模型RFcardi，在没有心电图真实数据的情况下从雷达信号中提取心血管相关的信息，并通过少量同步的雷达-ECG对进行微调。", "innovation": "提出了心血管聚焦和跟踪（CFT）算法，用于在数据有限的新场景中精确跟踪心脏位置，以确保有效获取高质量雷达信号；提出了一个基于心脏特征内在稀疏性的RFcardi迁移学习模型，在没有心电图真实数据的情况下从雷达信号中提取心血管相关信息，仅需少量同步的雷达-ECG对即可进行微调，从而有效生成忠实的ECG恢复结果。", "conclusion": "实验结果表明，提出的CFT可以动态识别心脏位置，RFcardi模型能够在少量雷达-ECG对训练后，有效生成忠实的ECG恢复结果。本文提供的代码和数据集在发表后将公开。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23679", "html_url": "https://arxiv.org/abs/2506.23679", "title": "使用变换器学习模幂运算", "title_en": "Learning Modular Exponentiation with Transformers", "authors": "David Demitri Africa,Sara M. Kapoor,Theo Simon Sorg,Challenger Mishra", "background": "模幂运算在数论和密码学中至关重要，但仍然大部分没有从机制上的可解释性角度进行探索。本文通过训练一个4层的编码器-解码器变换器模型来执行模幂运算，并探讨训练过程中数值推理的自然出现。使用原则性的采样策略、基于PCA的嵌入分析以及激活补丁分析，研究模型内部如何编码数论性质。研究表明，倒数操作数的训练能够显著提高性能，并且在相关模数之间突然泛化。这些同步的精度激增反映出类似理解（Grokking）的动力学，表明模型内化了共享的算术结构。还发现最后一层中的一个子图，完全由注意力头组成，能够单独完成常规指数运算的任务，这表明变换器模型通过专门的计算电路学习模算术，为进一步开发可解释且高效的神经方法铺平了道路。", "innovation": "本文主要创新在于使用4层的编码器-解码器变换器模型执行模幂运算，通过分析模型内部的嵌入、激活和子图，揭示了模型内部化通用算术结构以及通过特定训练策略（如倒数操作数的训练）显著提升性能的现象，证明了变换器模型通过专门的计算电路学习模算术。这为后续开发更可解释且高效的神经方法奠定了基础。", "conclusion": "变换器模型能够学习模算术并通过专门的计算电路实现这一过程，这一发现有助于进一步开发可解释的神经模型。模型内化了共享的算术结构，并通过特定的训练策略显著提升了性能。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06795", "html_url": "https://arxiv.org/abs/2507.06795", "title": "ixi-GEN：通过领域自适应连续预训练实现高效的工业小型语言模型", "title_en": "ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining", "authors": "Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon", "background": "开源大型语言模型（LLMs）的应用机会增加，但许多企业仍缺乏必要的基础设施来部署和维护大型模型。因此，尽管小型语言模型（sLLMs）存在性能限制，它们仍成为一种实际的选择。虽然领域适应连续预训练（DACP）已经探索用于领域适应，但在商业环境中的实用性尚未得到充分检验。", "innovation": "本研究验证了基于DACP方法的有效性，通过在多种基础模型和应用领域中应用DACP，提出了DACP应用的小型语言模型ixi-GEN。通过大量实验和实际应用评估，证明了ixi-GEN模型在目标领域性能上的显著提高，同时保留了一般能力，提供了一种成本效益高且可扩展的企业级部署解决方案。", "conclusion": "ixi-GEN模型在目标领域性能上有显著提升，同时保持了一般能力，提供了一种成本效益高且可扩展的企业级部署解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00418", "html_url": "https://arxiv.org/abs/2507.00418", "title": "HPC集群中大型语言模型的提供：高通云AI 100超能与NVIDIA数据中心GPU的比较研究", "title_en": "Serving LLMs in HPC Clusters: A Comparative Study of Qualcomm Cloud AI 100 Ultra and NVIDIA Data Center GPUs", "authors": "Mohammad Firas Sada,John J. Graham,Elham E Khoda,Mahidhar Tatineni,Dmitry Mishin,Rajesh K. Gupta,Rick Wagner,Larry Smarr,Thomas A. DeFanti,Frank Würthwein", "background": "本研究在国家研究平台（NRP）生态系统中，对比分析了高通Cloud AI 100 Ultra（QAic）加速器与NVIDIA A100 GPU在大型语言模型（LLM）推理中的能源效率、性能及硬件扩展性。研究使用vLLM框架对包含12个不同规模大型语言模型（从124百万元参数到700亿参数）进行服务评估。研究背景在于探索在能源受限和资源高效高性能计算（HPC）部署中，高通Cloud AI 100 Ultra的潜力及其与其他高性能GPU（如NVIDIA A100）相比的优势。", "innovation": "研究的创新点在于通过对比分析QAic加速器和NVIDIA A100 GPU，展示了QAic在特定模型上的竞争力和能源效率上的优势，同时在硬件分配上具有更高的灵活性。研究结果表明，对于70亿参数的模型，使用1个QAic卡比使用8个A100 GPU，不仅可以节省大量电量（148瓦 vs 2,983瓦），还能实现更细粒度的硬件分配；对于较小的模型，单个QAic设备相比4个A100 GPU的配置，可以节省高达35倍的电量（36瓦 vs 1,246瓦）。", "conclusion": "研究结果表明，高通Cloud AI 100 Ultra在能源受限和资源高效的HPC部署中具有巨大的潜力。它在特定模型上的能源效率优势和细粒度硬件分配能力为国家研究平台（NRP）的HPC部署提供了新的可能性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03220", "html_url": "https://arxiv.org/abs/2507.03220", "title": "共生：多适配器推理与微调", "title_en": "Symbiosis: Multi-Adapter Inference and Fine-Tuning", "authors": "Saransh Gupta,Umesh Deshpande,Travis Janssen,Swami Sundararaman", "background": "当前的参数高效微调(PEFT)技术允许模型构建者将任务特定参数封装入适配器，适配器的大小仅为原始基础模型的一小部分。尽管PEFT技术在流行大规模语言模型(LLMs)上的应用非常广泛，但现有的框架模型在支持使用多个适配器进行推理或微调方面仍存在诸多不足。这些问题包括：为每个微调任务部署专用基础模型实例，导致GPU内存消耗过大，GPU利用率低；现有的大多数推理平台虽然能够处理多个PEFT适配器，但不支持独立资源管理或混用不同PEFT方法；也无法充分利用异构加速器，不提供用户的隐私保护，因为用户可能不愿向服务提供商暴露其微调参数。", "innovation": "Symbiosis通过将基础模型作为服务部署来解决问题，允许基础模型层在多个推理或微调过程中共享。通过拆分执行技术，分离客户特定的适配器和层的执行与冻结基础模型层，Symbiosis提供了灵活性以管理资源、选择微调方法并实现性能目标。该方法对于transformers库中的大部分模型均透明且即插即用。", "conclusion": "Symbiosis展示了同时在8个GPU上微调20个Gemma2-27B适配器的使用案例，验证了其实现目标的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12006", "html_url": "https://arxiv.org/abs/2507.12006", "title": "Frequency-Dynamic Attention Modulation for Dense Prediction", "title_en": "Frequency-Dynamic Attention Modulation for Dense Prediction", "authors": "Linwei Chen,Lin Gu,Ying Fu", "background": "视觉变换器（ViTs）在计算机视觉领域取得了显著进展，并在多种任务上展示了强劲的表现。然而，ViTs中的注意力机制使得每一层都作为低通滤波器工作，现有的变压器体系结构也遭受了频率消失的问题。这种问题导致丢失了关键的细节和纹理。", "innovation": "提出了一个电路理论启发的策略，称为频率动态注意力调制（FDAM），它可以无缝地插入到ViTs中。FDAM直接调制了ViTs的总体频率响应，包括两种技术：注意力反转（AttInv）和频率动态缩放（FreqScale）。FDAM首先通过反转注意力矩阵中的低通滤波器生成互补的高通滤波器，并动态结合两部分来直接调制总体频率响应。通过频率组件加权，实现对目标响应函数的精细调整。实验结果显示，该方法避免了表示崩溃，能够跨各种模型（包括SegFormer、DeiT和MaskDINO）提供一致的性能提升。此外，该方法在遥感检测任务中应用，实现了单尺度设置下的最佳结果。", "conclusion": "通过特征相似性分析和有效秩评估，证明了本文方法能够避免表示崩溃，在各个模型和任务中取得了性能改善，特别是在语义分割、目标检测和实例分割任务中表现优异。在遥感任务中，该方法取得了最新成果。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10998", "html_url": "https://arxiv.org/abs/2507.10998", "title": "表格数据中构建不可感知的在流形上的对抗攻击", "title_en": "Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data", "authors": "Zhipeng He,Alexander Stevens,Chun Ouyang,Johannes De Smedt,Alistair Barros,Catarina Moreira", "background": "表格数据中的对抗攻击因其混合的分类和数值特征具有多样性而面临独特的挑战。与图像数据依赖直观的像素扰动生成类同性修改不同，表格数据缺乏直观的相似性度量，使得定义不可感知的修改变得更加困难。此外，传统的方法基于梯度的方法常常倾向于$\boldsymbol{(}\boldsymbol{\boldsymbol{\textit{l}}}\boldsymbol{\boldsymbol{_{p}}}\boldsymbol{\boldsymbol{)}}$-范数约束，这通常会导致生成的对抗样本偏离原始的数据分布。背景强调了这些问题，并指出需要提出新颖的方法来克服这些挑战。", "innovation": "本文提出了一种基于潜在空间扰动框架的对抗攻击方法，使用混合输入的变分自编码器(VAE)生成统计上一致的对抗样本。该VAE整合了分类嵌入和数值特征到一个统一的潜在流形，从而允许维持统计一致性的扰动。论文还引入了In-Distribution Success Rate (IDSR)来联合评估攻击的有效性和分布的一致性。实验证明，本文方法在六个公开数据集和三种模型架构上达到了显著更低的异常值率和更一致的性能，相较于传统的输入空间攻击方法和基于图像领域的其他VAE方法，表现更优。此外，对超参数灵敏度、稀疏控制和生成架构的全面分析表明，基于VAE的攻击效果很大程度上取决于重建质量以及充足训练数据的可用性。", "conclusion": "通过在满足重建质量和充足训练数据的情况下，所提出的方法相比输入空间方法具有更强的实用性和稳定性。研究表明，在表格数据领域的对抗攻击需要保持流形上的扰动以生成现实和健壮的对抗样本。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22766", "html_url": "https://arxiv.org/abs/2507.22766", "title": "基于高斯过程代理模型的传感器基础分拣系统过程参数贝叶斯优化", "title_en": "Bayesian Optimization of Process Parameters of a Sensor-Based Sorting System using Gaussian Processes as Surrogate Models", "authors": "Felix Kronenwett,Georg Maier,Thomas Längle", "background": "基于传感器的分拣系统能够将物料流物理分离成两部分。分拣决策基于所用传感器的图像数据评估，并使用执行器执行。根据物料流的属性、系统尺寸设计以及所需的分拣精度，需要设置多种工艺参数。然而，由于需求和物料组成的变化，持续验证和重新调整是必要的。本文提出了一种优化、循环监测和调整传感器基础分拣系统工艺参数的方法。", "innovation": "本文基于贝叶斯优化，使用高斯过程回归模型作为代理模型，实现具有不确定性条件下的系统行为特定要求优化，并同时考虑两个可能的优化目标，即两个物料输出流的要求。此外，在模型计算中，确定分拣精度时考虑了不确定性，并且通过三个示例工艺参数进行了评估。", "conclusion": "本文介绍的方法最小化了必要的实验次数，同时考虑了两种可能的优化目标的不确定性，并评估了三种示例工艺参数，验证了方法的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15958", "html_url": "https://arxiv.org/abs/2507.15958", "title": "量化感知类脑架构在资源受限设备上高效皮肤疾病分类", "title_en": "Quantization-Aware Neuromorphic Architecture for Efficient Skin Disease Classification on Resource-Constrained Devices", "authors": "Haitian Wang,Xinyu Wang,Yiren Wang,Zichen Geng,Xian Zhang,Yu Zhang,Bo Miao", "background": "在边缘设备上进行准确且高效的皮肤病变分类对于可访问的皮肤科护理至关重要，但由于计算、能量和隐私约束，该任务仍然具有挑战性。大规模的HAM10000基准测试和现实世界的临床数据集的结果表明，当前的CNN到类脑神经网络(SNN)模型在公平比较中表现不佳，这使得急需开发一种新颖的方法来解决这一问题，从而提高准确性和效率，同时保证隐私性。", "innovation": "我们提出了QANA，一种新颖的量化感知类脑架构，用于资源受限硬件上增量皮肤病变分类。QANA通过整合鬼模块、高效通道注意力机制和挤压-激活块，实现了鲁棒的特征表示，具有低延迟和高效的推理。其量化感知头部和尖峰兼容变换能够无缝转换为类脑神经网络(SNNs)，并部署在类脑平台上。QANA在HAM10000基准测试和临床数据集上分别实现了91.6%的Top-1准确率和82.4%的宏F1值，以及90.8%/81.7%的准确率和F1值，对比公平基准显著优于最先进的CNN到SNN模型。在BrainChip Akida硬件上部署时，QANA实现了1.5毫秒的推理延迟和每张图像1.7mJ的能量消耗，相比基于GPU的CNN，其推理延迟和能量使用分别减少了94.6%和98.6%。", "conclusion": "QANA在边缘环境中实现了准确、实时和隐私敏感的医疗分析，证明了其有效性和优越性，尤其是对于资源受限设备的皮肤病变分类。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.19271", "html_url": "https://arxiv.org/abs/2507.19271", "title": "多语言语言模型在代码审查中的调整：工业C#项目上的实证研究", "title_en": "Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects", "authors": "Igli Begolli,Meltem Aksoy,Daniel Neider", "background": "代码审查对于维持软件质量至关重要，但在工业环境中往往耗时且认知负担重。最近的语言模型（LMs）进展为自动化核心审核任务提供了新途径。本研究通过实验评估单语调整在开源LMs上的性能，考察跨三个关键自动化代码审查任务的表现：代码更改质量评估、评审评论生成和代码精简。研究还探讨了训练数据中的编程语言和自然语言配置对LM性能的影响，尤其是评论生成任务。此外，还将训练模型与自动软件分析工具（ASAT）和人类审查员进行基准测试，评估其在实际场景中的实用性", "innovation": "研究通过实验评估了三种不同的模型在C#特定数据集上的单语调整效果，涵盖了编程语言和自然语言的配置对LM性能的影响，特别是在评论生成方面。同时，将这些调整后的模型与现有的自动软件分析工具和人类审查员进行对比，证明了单语调整相对于多语言基线可以提高模型的准确性和相关性。研究还指出了语言对齐和任务特定的适应在优化LMs自动化代码审查中的重要性。这项研究为工业C#项目提供了新的方法，改进了代码审查流程，特别是在处理常规或重复任务方面的支持有效性。", "conclusion": "单语调整可以提高模型在工业C#项目中的准确性和相关性，尽管语言模型在代码审查工作流程中的支持对于常规或重复任务非常有效，但在处理语义复杂或上下文敏感的更改时，人类审查员仍然更胜一筹。研究结果强调了语言对齐和任务特定适配在优化LMs自动化代码审查中的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02753", "html_url": "https://arxiv.org/abs/2508.02753", "title": "DMSC: 动态多尺度协调框架用于时间序列预测", "title_en": "DMSC: Dynamic Multi-Scale Coordination Framework for Time Series Forecasting", "authors": "Haonan Yang,Jianchao Tang,Zhuo Li,Long Lan", "background": "时间序列预测（TSF）面临着建模跨不同时间尺度的复杂依赖性的持续挑战。尽管近年来利用不同的分解操作和基于CNN、MLP或Transformer的新颖架构取得了进步，但现有方法仍然面临着固定的分解策略、依赖碎片化建模和不灵活的融合机制的限制，从而影响了它们建模复杂时间依赖性的能力。", "innovation": "本文提出了一个新颖的动态多尺度协调框架（DMSC），包括多尺度块（EMPD）、三元交互块（TIB）和自适应尺度路由MoE块（ASR-MoE）。EMPD能够动态地将序列分割为层次化的块，通过输入自适应的块调整消除预设的时间尺度限制。TIB联合建模了每个分解表示中的内部块、块间以及跨变量依赖性。EMPD和TIB被集成到多层渐进级联架构中，通过门控路径使早期层的粗粒度表示能够自适应地引导后续层中的细粒度特征提取。ASR-MoE通过利用时空感知加权的特定全局和局部专家动态融合多尺度预测。", "conclusion": "通过对十三个真实世界的基准测试进行全面实验，DMSC在时间序列预测任务中持续保持了最先进的性能以及优越的计算效率。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04586", "html_url": "https://arxiv.org/abs/2508.04586", "title": "当前AI会议模式不可持续！中心化AI会议危机诊断", "title_en": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference", "authors": "Nuo Chen,Moming Duan,Andre Huikai Lin,Qian Wang,Jiaying Wu,Bingsheng He", "background": "人工智能（AI）会议对于促进研究、分享知识和培养学术社区至关重要。然而，它们的快速扩大已经使集中型会议模式变得越来越不可持续。本文通过数据驱动的方法诊断了这一结构性危机，该危机威胁到科学研究的基础目标，即传播、公平以及社区福祉。研究发现以下四个关键领域的压力：1）科学研究方面，过去十年间每位作者的出版率几乎翻了一番，目前超过每年4.5篇；2）环境方面，单个会议的碳足迹超过其举办城市的每日排放量；3）心理方面，在线社区讨论中有71%反映负面情绪，35%提到心理健康问题；4）后勤方面，如NeurIPS 2024等顶级会议的出席人数已经开始超过场地容量。这些压力表明会议系统已经与核心使命产生了偏差。", "innovation": "我们提出了一种社区联结会议（CFC）模式，将同行评审、展示和社交网络等功能分离，实现全球协调但本地组织，为AI研究提供了一条更加可持续、包容和有弹性的道路。", "conclusion": "现有中心化AI会议模式与核心使命不一致，提出了社区联结会议（CFC）模式作为替代方案，旨在解决上述四个关键领域的压力问题，为AI研究提供新的方向。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09874", "html_url": "https://arxiv.org/abs/2508.09874", "title": "Memory Decoder: 一种预训练的插件式记忆组件用于大型语言模型", "title_en": "Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models", "authors": "Jiaqi Cao,Jiarui Wang,Rubin Wei,Qipeng Guo,Kai Chen,Bowen Zhou,Zhouhan Lin", "background": "大型语言模型（LLMs）在通用语言任务中展示了强大的能力，但将它们适应特定领域仍是一个挑战。现有的方法如领域自适应预训练（DAPT）需要对所有参数进行昂贵的重新训练，并遭受灾难性遗忘问题。另一方面，检索增强生成（RAG）方法由于昂贵的最近邻搜索和更长的上下文而引入了显著的推理延迟。", "innovation": "本文引入了Memory Decoder，这是一种预训练的记忆组件，可以无缝地插件到任何预训练的语言模型中，无需修改原始模型的参数。Memory Decoder利用一个小的变压器解码器，学习模仿外部非参数检索器的行为。实验证明，Memory Decoder能够有效地将各种Qwen和Llama模型适应三个不同的专用领域：生物医药、金融和法律，平均减少困惑度6.17个点。", "conclusion": "Memory Decoder提出了一种新的范式，中心是一个专门预训练的记忆组件，用于领域特定的适应。这种记忆架构可以以一种插件式的方式集成，一致地提高目标领域内多个模型的性能。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19614", "html_url": "https://arxiv.org/abs/2508.19614", "title": "LFD: 层融合解码以利用检索增强生成中的外部知识", "title_en": "LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation", "authors": "Yang Sun,Zhiyong Xie,Dan Luo,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li,Lixin Zou", "background": "RAG模型通过将外部知识融入大规模语言模型（LLMs）来提升其下游任务的适应性，并允许信息更新。最近的研究表明，在检索到的相关文档中注入噪声可以意外地促进利用外部知识，从而提高生成质量。尽管这种现象与直觉相悖且难以实际应用，但可以通过这种机制实现对LLMs如何整合外部知识的精细控制和严谨分析。", "innovation": "本文提出了一种新的解码策略——层融合解码（LFD），该策略能够直接将中间层的表征与最终层的解码输出结合，从而充分利用外部事实知识。通过引入内部知识评分（IKS）标准，本文确定了最优的中间层，这有助于RAG系统更有效地呈现检索到的上下文知识，同时保持最低的成本。", "conclusion": "实验结果表明，LFD策略有助于RAG系统更有效地展示检索到的上下文知识，而不增加额外的计算成本。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01257", "html_url": "https://arxiv.org/abs/2509.01257", "title": "无线边缘网络中任务卸载的多智能体强化学习", "title_en": "Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks", "authors": "Andrea Fox,Francesco De Pellegrini,Eitan Altman", "background": "在边缘计算系统中，自主智能体必须在竞争共享资源的同时做出快速的本地决策。现有的多智能体强化学习（MARL）方法通常依赖于集中式批评者或频繁通信，这些方法在有限的可观察性和通信约束下会失效。", "innovation": "提出了一个去中心化的框架，每个智能体解决一个受限的马尔可夫决策过程（CMDP），通过共享约束向量隐式协调。对于任务卸载的具体情况，约束防止共享服务器资源过载。协调约束更新不频繁，作为一种轻量级协调机制，允许智能体遵循全局资源使用目标，同时需要很少的直接通信。利用安全的强化学习，智能体学习符合当地和全球目标的策略。在温和的假设下建立了理论保证，并通过实验验证了方法的有效性，特别是在大规模设置中表现出优于集中式和独立基线的性能", "conclusion": "通过理论保证和实验验证，证明了所提出的方法在大规模设置中比集中式和独立基线表现更好，特别是在解决边缘计算系统中的任务卸载问题时，通过较少的直接通信实现了智能体之间的有效协调。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02844", "html_url": "https://arxiv.org/abs/2509.02844", "title": "变点情况下的时间序列预测的可检验预测", "title_en": "Conformal Prediction for Time-series Forecasting with Change Points", "authors": "Sophia Sun,Rose Yu", "background": "可检验预测已经在时间序列数据中作为一种通用且高效的提供不确定性量化的方式得到了探索。然而，现有的方法对于包含突变点的时间序列数据存在局限性，即在这种数据中存在突然变化的数据生成过程。面对这一挑战，本文分析了当前方法在处理包含突变点的时间序列时的不足。", "innovation": "本文提出了一种名为CPTC（Change Point Time-series Conformal Prediction）的新算法，通过结合预测基础状态的模型和在线可检验预测，成功地处理非平稳时间序列中的不确定性。并且我们证明了在最小假设下CPTC的有效性和改进的适应性。", "conclusion": "我们在合成和真实世界数据集上验证了CPTC的有效性，与最先进的基线方法相比，CPTC显示出更好的有效性与适应性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16068", "html_url": "https://arxiv.org/abs/2507.16068", "title": "使用大型语言模型进行多机器人团队合成协调", "title_en": "Compositional Coordination for Multi-Robot Teams with Large Language Models", "authors": "Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme", "background": "传统的多机器人协调依赖于任务特定和专家驱动的过程，自然语言的任务描述需由领域专家手动翻译成数学模型、算法设计和可执行代码。这种传统过程劳动密集、对非专家不友好且对任务需求变化不够灵活。本研究旨在克服这些问题，通过大规模语言模型（LLMs）优化和通用多机器人协调管道。", "innovation": "提出了一种名为LAN2CB（Natural Language to Collective Behavior）的新框架，该框架利用大规模语言模型将自然语言任务描述直接转换为多机器人系统中可执行的Python代码。具体包括两个核心模块：任务分析模块将任务描述解析为行为树，代码生成模块利用行为树和结构化知识库生成机器人控制代码。同时，引入了自然语言任务描述的数据集，支持开发和评估。实验结果显示，LAN2CB能够实现从自然语言到多机器人协调的稳健和灵活控制，大幅减少手动工程工作量，支持广泛任务类型的通用性。", "conclusion": "该研究通过LAN2CB框架，成功地使多机器人协调过程更加自动、通用和灵活，显著降低了手动工程成本，展示了在模拟和真实环境中的广泛应用潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.06213", "html_url": "https://arxiv.org/abs/2509.06213", "title": "朝向人工智能计量学：隐藏规则环境与强化学习", "title_en": "Toward a Metrology for Artificial Intelligence: Hidden-Rule Environments and Reinforcement Learning", "authors": "Christo Mathew,Wentian Wang,Jacob Feldman,Lazaros K. Gallos,Paul B. Kantor,Vladimir Menkov,Hao Wang", "background": "该研究聚焦于在Game Of Hidden Rules (GOHR) 环境中利用强化学习技术进行探索。GOHR 是一个复杂的谜题环境，其中智能体需通过摆放游戏棋子来清除6x6 的板面，但必须推断并执行隐藏规则。研究者们采用特征中心（Feature-Centric, FC）和对象中心（Object-Centric, OC）两种状态表示策略，并采用了基于Transformer 的优势行为演员-评论家（Advantage Actor-Critic, A2C）算法进行训练。研究中明确指出智能体只能访问部分观察信息，因此需要在实践中同时推断规则并学习最优策略。", "innovation": "研究引入了特征中心和对象中心两种状态表示策略，并在多个基于规则和试次列表的实验配置中评估了这些策略。研究还分析了表示方法对学习效率和迁移效应的影响。基于Transformer 的A2C 算法用于训练，使得研究能够更深入地探索不同表示策略和规则学习之间的关系。", "conclusion": "该研究通过在GOHR 环境中使用多种状态表示策略和强化学习方法，得出了关于智能体在复杂环境中的学习效率和迁移效果的一些关键见解，这为理解智能体如何执行隐含规则打开了新的窗口，并为未来的AI 在复杂环境中的应用提供了参考。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.06863", "html_url": "https://arxiv.org/abs/2509.06863", "title": "floq：通过流匹配训练批评者以扩大计算能力在基于值的强化学习中的应用", "title_en": "floq: Training Critics via Flow-Matching for Scaling Compute in Value-Based RL", "authors": "Bhavya Agrawalla,Michal Nauman,Khush Agrawal,Aviral Kumar", "background": "现代大规模机器学习技术的一个特点是使用密集监督目标对中间计算进行训练，例如在语言模型中进行教师强制下一标记，在扩散模型中逐步去噪。这使得模型能够以通用的方式学习复杂的函数。基于此观察，本文研究了迭代计算在强化学习中的时间差分（TD）方法中的潜在益处。通常，TD方法以整体方式表示价值函数，而不进行迭代计算。因此，本文提出了floq（flow-matching Q-functions），一种使用流场参数化Q函数并结合流匹配技术进行训练的新方法。这种流场通过数值积分的多步计算得到的目标流场的值进行训练。", "innovation": "引入了floq方法，该方法通过使用流场参数化Q函数并通过流匹配技术进行训练，在TD学习目标下训练，能够更精细地控制和扩展Q函数容量，相比于整体架构具有更好的容量扩展性。该方法在多个具有挑战性的离线RL基准测试和在线微调任务中表现优异，性能提高了近1.8倍。这表明，迭代计算在价值学习中的潜力得到了提高。", "conclusion": "floq在容量扩展方面比标准TD学习架构表现更好，突显了迭代计算在强化学习中的潜在优势。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19271", "html_url": "https://arxiv.org/abs/2509.19271", "title": "WolBanking77: Wolof Banking Speech Intent Classification Dataset", "title_en": "WolBanking77: Wolof Banking Speech Intent Classification Dataset", "authors": "Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione", "background": "近年来，意图分类模型取得了显著进展，但大多数研究主要集中在资源丰富语言的数据集上，这导致了低资源语言和高文盲率地区（如西非的西洛夫语）的差距，这些地区的语言更多是口头交流而不是书写或阅读。例如，塞内加尔西洛夫语的使用者占该国人口的90%，而全国文盲率约为42%。这些数据表明，西洛夫语的实际使用者人数超过1000万。", "innovation": "本文提出了西洛夫银行语音意图分类数据集（WolBanking77），用于意图分类研究。WolBanking77当前包含9,791条银行领域的文本句子以及超过4小时的语音句子。本文在该数据集上对各种基线进行了实验，包括文本和语音领域的先进模型。在西洛夫银行语音意图分类数据集上对NLP和ASR模型进行了训练，并报告了基线F1分数和单词错误率等指标，还进行了模型间的比较。", "conclusion": "本文数据集成果非常有前景，并提供了代码和数据集供学术研究使用，这些研究工作和其他模型之间的比较表明了该数据集的潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19834", "html_url": "https://arxiv.org/abs/2509.19834", "title": "天汇：一种针对多样传统中医场景的定制大语言模型", "title_en": "TianHui: A Domain-Specific Large Language Model for Diverse Traditional Chinese Medicine Scenarios", "authors": "Ji Yin,Menglan He,Yujie Zhang,Linshuai Zhang,Tingting Ma,Ce Tian,Jie Wu,Lin Xu,Tao Jiang,  ((1) School of Intelligent Medicine, Chengdu University of Traditional Chinese Medicine, Chengdu, China (2) The Acupuncture and Tuina School, Chengdu University of Traditional Chinese Medicine, Chengdu, China (3) Center of Preventive Medicine, Hospital of Chengdu University of Traditional Chinese Medicine, Chengdu, China (4) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China (5) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China)", "background": "在研究环境中，领域特定的大语言模型（LLM）在中医（TCM）方面存在局限，主要包括适应能力受限、缺乏足够的评估数据集和计算资源有限。这些限制对中医领域的研究构成了挑战，需要一种更加专门化和高效的方法来处理TCM相关的复杂信息。", "innovation": "该研究提出了一种名为天汇（TianHui）的专门化TCM LLM，通过上下文数据整合和领域知识融合构建。天汇采用了大规模TCM语料库（0.97GB无监督数据+611,312 QA对）和两阶段训练策略，使用了QLoRA、DeepSpeed Stage 2和Flash Attention 2等先进技术。结果显示，天汇在所有评估基准中表现优异，特别是在中医相关的多个数据集中取得了最佳或接近最佳的结果，这得益于其优化的配置参数，从而展示了系统保存和可扩展应用中医知识的有效性。", "conclusion": "天汇能够系统地保存和高效地应用中医知识，其所采用的技术方法对于TCM领域的大规模语料建设和模型训练具有重要意义，且所有相关资源均已开源，有助于推动中医领域的数字化和智能化发展。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03738", "html_url": "https://arxiv.org/abs/2509.03738", "title": "函数空间中的稀疏自编码器神经算子：模型恢复", "title_en": "Sparse Autoencoder Neural Operators: Model Recovery in Function Spaces", "authors": "Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar", "background": "尽管经典的柏拉图表示假设表明神经网络在不同架构中会收敛于相似的表示，但神经算子的表示特性依然鲜有研究，尽管它们在科学计算中的重要性日益增长。本研究对比了稀疏自编码器（SAEs）、提升的稀疏自编码器（lifted-SAE）和稀疏自编码器神经算子的推理和训练动态。通过对稀疏自编码器、提升的稀疏自编码器和稀疏自编码器神经算子的研究，揭示了提升和算子模块引入的有益的归纳偏差，使大型神经算子能够在不同分辨率下实现更快和更稳健的恢复和推理，这是神经算子的独特特性。背景可概括为：虽然神经网络的表示假设已在不同架构中收敛，但神经算子的研究尚不充分，它们在科学计算中的作用引起了研究兴趣，特别是在提升和算子模块的应用上，这些模块能够提供更好的表示和更稳健的性能。", "innovation": "本研究提出了将问题框架化为稀疏模型恢复的问题，并且引入了一个扩展的框架，将稀疏自编码器（SAEs）提升到提升空间和无限维函数空间。这种新框架能够改善对大型神经算子（NO）的机械解释能力。此外，研究还发现提升和算子模块能够提供有益的归纳偏差，有助于更快、更平稳地恢复平滑概念和在不同分辨率下实现稳健的推理。这是研究的主要创新点，尤其是在提升和算子模块对提升稀疏自编码器和神经算子的影响方面实现了对上述问题的新见解和新解决方法。", "conclusion": "研究证明了提升稀疏自编码器和神经算子（包括提升版本）在恢复功能空间中的表示上的有效性，尤其是在光滑概念的恢复和不同分辨率下稳健性的提升上。提出了一个问题框架，并展示了一种新的方法，该方法能够更好地解析和表示复杂的神经算子。由于算子模块和提升技术的应用，该方法能够在保持高度表示能力的同时，提供更好的机械解释性和更稳健的性能。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20890", "html_url": "https://arxiv.org/abs/2509.20890", "title": "FerretNet：基于局部像素依赖的高效合成图像检测", "title_en": "FerretNet: Efficient Synthetic Image Detection via Local Pixel Dependencies", "authors": "Shuqiao Liang,Jian Liu,Renzhang Chen,Quanlong Guan", "background": "随着先进模型（如VAEs、GANs和LDMs）生成的合成图像越来越逼真，针对合成图像的检测面临着重大挑战。为此，研究者们关注到了生成过程中引入的两种类型的缺陷：（1）潜在分布偏差和（2）解码引起的平滑效果，这些缺陷体现在局部纹理、边缘和颜色过渡的一致性上。通过利用马尔可夫随机场中的局部像素依赖（LPD）特性，研究提出了利用相邻像素信息重构合成图像的方法，以此揭露纹理连续性和边缘一致性上的中断。", "innovation": "研究提出了FerretNet，这是一种仅有1.1M参数的轻量级神经网络，能够实现高效的合成图像检测。FerretNet基于LPD特性，利用相邻像素信息重构图像以揭示纹理和边缘连续性上的中断。实验结果显示，FerretNet在开放世界基准（包含22个生成模型）中，仅通过独立训练4类ProGAN数据集，就达到了97.1%的平均准确率。此模型具有高效和稳健的特性，极大地提高了合成图像检测的性能。此外，此研究还提供了开源代码和数据集，供其他研究者使用和参考。", "conclusion": "FerretNet利用局部像素依赖性质，仅用轻量级神经网络成功解决了合成图像检测问题。该模型不仅在准确性和效率方面表现出色，还提供了一种新的检测策略。此外，结果在开放世界基准中的应用证明了其优越性，展示了其在实际应用场景中的潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02279", "html_url": "https://arxiv.org/abs/2510.02279", "title": "解决自然语言生成中不确定性估计方法评估中的问题", "title_en": "Addressing Pitfalls in the Evaluation of Uncertainty Estimation Methods for Natural Language Generation", "authors": "Mykyta Ielanskyi,Kajetan Schweighofer,Lukas Aichberger,Sepp Hochreiter", "background": "大语言模型（LLMs）中的幻觉问题是影响其可靠性的常见问题。最近的研究已经确定了幻觉的一个特定子集，称为错编（confabulations），这些错编是由LLMs的预测不确定性引起的。为了检测错编，开发了各种自然语言生成（NLG）中预测不确定性的估计方法。这些方法通常通过估计的不确定性与生成的文本正确性之间的相关性来评估。常用的近似正确性函数存在显著的差异，导致对不确定性估计方法的排名不一致，从而使这些方法的表现被夸大。", "innovation": "本文提出了使用几种替代风险指标来改进不确定性估计方法在NLG中的经验评估的鲁棒性。对于问答任务，通过在多个LLM-as-judge变体之间进行边际化来降低评估偏差。此外，还探讨了结构化任务、异常分布检测任务，以及扰动检测任务，这些任务可以提供鲁棒且可控的风险指标。最后，提出使用不确定性估计方法的Elo评级来对广泛的评估设置进行客观总结。", "conclusion": "本文通过开发新的风险指标和实验方法，改进了不确定性估计方法在自然语言生成中的评估，从而提高了评估的可靠性和客观性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.16449", "html_url": "https://arxiv.org/abs/2509.16449", "title": "PersonaMatrix: 针对法律摘要的人格化评估方法", "title_en": "PersonaMatrix: A Recipe for Persona-Aware Evaluation of Legal Summarization", "authors": "Tsz Fung Pang,Maryam Berijanian,Thomas Orth,Breanna Shi,Charlotte S. Alexander", "background": "法律文件通常很长且难以理解，不仅对于普通公众，对于法律专家也是如此。自动化文档摘要具有提高法律知识访问潜力，但现有的基于任务的评估工具未能考虑到用户和利益相关者的不同需求。对于律师来说，摘要需要具备技术性，而对于自助法律求助公众而言，则需要更加易懂。为此，本研究提出了PersonaMatrix评估框架，通过六种人重新定义摘要的评价标准，从而满足不同用户的需求。此外，该研究还提供了一个控制维度变化的试点数据集，以及多样性覆盖指数（DCI）来展示面向不同用户群体的法律摘要优化目标之间的差异。", "innovation": "提出了PersonaMatrix评估框架，通过六种不同的人设定评价标准，帮助法律AI摘要系统更好地满足专家和非专家用户的需求。此外，还提供了一个包含深度、易用性和程序细节等变化的试点数据集，以及多样性覆盖指数（DCI），以展示面向不同用户群体的法律摘要的不同优化目标。研究结果增加了评估法律摘要时的灵活性和精确度。", "conclusion": "这项工作能够改善用于专家和非专家用户的法律AI摘要系统，有潜力提高法律知识的可访问性。相关代码和数据已经开源在GitHub上。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02253", "html_url": "https://arxiv.org/abs/2510.02253", "title": "DragFlow: 使用区域基础监督释放DiT先验的拖拽编辑", "title_en": "DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag Editing", "authors": "Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong", "background": "拖拽式图像编辑长期以来存在目标区域失真的问题，主要因为早期基础模型Stable Diffusion的先验不够强大，无法将优化后的潜在空间有效投影到真实的图像流形上。随着从基于UNet的DDPMs转向更高效的DiT（例如SD3.5、FLUX），生成先验大大增强了，使得在多种编辑任务中取得了进展。然而，拖拽式编辑尚未从这些更强的先验中受益。本文介绍了首个有效利用FLUX丰富先验的框架DragFlow，实现了相较于基线的显著改进。由于与UNets相比，DiT特征缺乏足够的结构来提供精确的点动监督指导，该工作提出了一种基于区域的编辑范式，使用仿射变换提供更丰富和一致的特征监督。同时，通过集成预训练的开放式域个性化适配器提升主题一致性，通过梯度掩码约束保持背景质量。此外，多模态大规模语言模型进一步用于解决任务歧义性。为了进行评估，本文创建了一个新的区域级拖拽基准（ReD Bench），包含区域级拖拽指令。实验证明DragFlow在拖拽式图像编辑任务上优于基于点和区域的基线，达到新的性能标准。相关代码和数据集将在发表后公开可供下载。", "innovation": "提出了首个利用Flux强大先验的拖拽式图像编辑框架DragFlow，通过基于区域的编辑策略和仿射变换增强特征监督，同时引入预训练的开放式域个性化适配器和梯度掩码约束，结合大规模语言模型解决任务歧义性，显著提升了拖拽式图像编辑的质量。该工作提供了一个新的区域级拖拽基准ReD Bench，将用于进一步的实验验证。", "conclusion": "DragFlow通过利用Flux的强大生成先验，在拖拽式图像编辑任务中实现了显著的性能提升，达到了新的技术水平。该方法为开发者和研究人员在图像编辑领域的应用提供了新的思路和工具。未来工作将进一步优化模型性能，并探索其在其他图像处理任务中的应用潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02855", "html_url": "https://arxiv.org/abs/2510.02855", "title": "基于约束 satisfaction 方法求解 Wordle：新型启发式算法和跨语言验证", "title_en": "Constraint Satisfaction Approaches to Wordle: Novel Heuristics and Cross-Lexicon Validation", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel", "background": "Wordle 为约束满足问题 (CSP) 求解提供了一个算法丰富的测试环境。现有的求解器主要依赖于信息论熵最大化或基于频率的启发式方法，而不涉及形式化的约束处理。本文首次提出了一个全面的 CSP 表述，并结合了与逻辑约束相结合的贝叶斯单词频谱先验，实现了新的约束感知求解策略。", "innovation": "提出了 CSP-感知熵的概念，在约束传播后计算信息增益，而不是在原始候选集中计算。还提出了概率 CSP 框架，结合了逻辑约束和贝叶斯单词频谱先验。通过在 2,315 个英语单词上的评估，在 10% 的噪声下保持 5.3 个百分点的优势，在所有噪声水平（0-20%）下实现 100% 的成功率。开源实现代码覆盖率高达 91%，提供了高效的 CSP 研究基础设施。", "conclusion": "贯通形式化 CSP 处理、约束感知启发式方法、概率逻辑结合、鲁棒性分析以及跨语言验证，本研究为结构化谜题求解领域提供了新的性能基准，证明了基于原理的约束满足技术优于经典的信息论和学习驱动的方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04462", "html_url": "https://arxiv.org/abs/2509.04462", "title": "评估GPT-5在生物医学自然语言处理中的性能", "title_en": "Benchmarking GPT-5 for biomedical natural language processing", "authors": "Yu Hou,Zaifu Zhan,Min Zeng,Yifan Wu,Shuang Zhou,Rui Zhang", "background": "生物医学文献和临床记录信息在自然语言理解中提出了多样化的挑战，包括精确的实体提取、文档合成以及多步诊断推理。本文通过扩展统一基准来评估GPT-5和GPT-4o在五大核心生物医学NLP任务上的表现：命名实体识别、关系抽取、多标签文档分类、摘要和简化，以及覆盖医学事实知识、临床推理和多模态视觉理解的九个扩展医学问答数据集。在标准化提示、固定解码参数和一致推理管道下，评估了模型的性能、延迟和基于官方定价的单位标记成本。", "innovation": "本文通过统一基准对GPT-5和GPT-4o在零、一和五次提示下的表现进行了评估，覆盖了生物医学NLP的核心任务，并在九个扩展医学问答数据集上进行了测试。GPT-5在推理密集型数据集（如MedXpertQA和DiagnosisArena）上表现出了显著的改进，并在多模态问答上有了稳定的提高。尽管生成了更长的输出，GPT-5在延迟和每正确预测的经济效率方面表现相近，且有效成本降低了30%到50%。进一步的分析显示了诊断、治疗和推理子类型的改进，但边界敏感的提取和证据丰富的摘要仍具有挑战性。", "conclusion": "总体而言，GPT-5为生物医学问答部署提供了接近性能的同时，还提供了高精度、可解释性和经济效率的平衡。研究结果支持渐进式的提示策略：对大规模或成本敏感的应用直接提示，对分析复杂或高风险场景使用逐步推理框架，突显了在关键信息精度和事实准确性需求下持续需要混合解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04755", "html_url": "https://arxiv.org/abs/2510.04755", "title": "一个新的数字鸿沟？程序员的世界观、烂经济以及AI时代的民主", "title_en": "A New Digital Divide? Coder Worldviews, the Slop Economy, and Democracy in the Age of AI", "authors": "Jason Miklian,Kristian Hoelscher", "background": "数字技术正在以复杂的方式重塑民主生活的方方面面。本文结合了两个视角来解析这些冲突。一方面，通过调查硅谷的软件开发人员，探索他们的世界观、伦理观念和工作文化如何影响他们所构建技术的民主潜力和社会影响。另一方面，文章在烂经济的背景下重新审视调查结果，探讨了缺乏高质内容付费用户所面临的低质量、AI驱动的广告主导互联网如何成为新的数字鸿沟。作者指出科技创造者的核心信念与他们所孕育的数字生态系统之间存在相互强化的循环，并引发了对未来民主治理的担忧。", "innovation": "文章原创性地进行了针对硅谷程序员的调查，并通过烂经济这一新概念，深入探讨了缺乏高质内容付费用户所形成的低质量、广告驱动的互联网如何成为新的数字鸿沟。研究发现，科技创造者的核心信念与他们所孕育的数字生态系统之间存在相互强化的循环，这对民主治理提出了新的挑战，并提出了需要更符合伦理的设计和政策干预以确保技术创新能够支持而非破坏民主价值观的倡议。", "conclusion": "文章讨论了数字时代的民主治理问题，强调需要更符合伦理的设计和政策干预来解决数字鸿沟问题，确保技术创新支持并强化而非破坏民主价值观。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06377", "html_url": "https://arxiv.org/abs/2510.06377", "title": "关系变换器：面向关系数据的零样本基础模型", "title_en": "Relational Transformer: Toward Zero-Shot Foundation Models for Relational Data", "authors": "Rishabh Ranjan,Valter Hudovernik,Mark Znidar,Charilaos Kanatsoulis,Roshan Upendra,Mahmoud Mohammadi,Joe Meyer,Tom Palczewski,Carlos Guestrin,Jure Leskovec", "background": "预训练的变压器模型能够通过零样本提示快速适应新的序列建模任务，但在关系领域中，依旧缺乏能够跨数据集和任务迁移的架构。核心挑战在于关系数据的多样性，包括各异的异质模式、图形结构和函数依赖关系。", "innovation": "本文提出了一种关系变换器（RT）架构，这种架构能够从多样性的关系数据库中进行预训练，并且无需针对具体任务或数据集进行微调或者提取上下文示例，就可以直接应用于未知数据集和任务中。RT架构通过表/列元数据标记单元格，采用掩码标记预测来进行预训练，并利用一种新的关系注意机制来处理列、行和主外键链接。", "conclusion": "预训练于RelBench数据集中的RT模型在二元分类任务上取得了高达93%的AUC ROC，在单次前向传递中实现了这一结果，而27B参数的LLM则只有84%。微调后的结果达到了目前的最好水平，展示了高样本效率。实验显示，RT零样本迁移利用了任务表上下文、关系注意模式和模式语义。总体而言，RT提供了关系数据领域基础模型的可行路径。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03369", "html_url": "https://arxiv.org/abs/2510.03369", "title": "TriQuest：一种以AI辅助飞行员为动力的跨学科课程设计平台", "title_en": "TriQuest:An AI Copilot-Powered Platform for Interdisciplinary Curriculum Design", "authors": "Huazhen Wang,Huimin Yang,Hainbin Lin,Yan Dong,Lili Chen,Liangliang Xia,Wenwen Xu", "background": "跨学科教学是现代课程改革的基础，但其实施受到了不同学科知识整合的挑战和繁重的课程规划时间的阻碍。现有的工具通常缺乏必要的教学和特定领域的支持。因此，需要一个能够帮助教师高效生成高质量跨学科课程计划的平台。", "innovation": "介绍了一种名为TriQuest的AI辅助教学平台，该平台利用大型语言模型和知识图谱通过直观的图形用户界面帮助教师生成高质量的跨学科课程计划。核心特点是智能跨学科知识整合和人机协作审核过程，以确保质量和效率。", "conclusion": "TriQuest的研究为利用智能技术推动教师专业发展提供了新的范式。通过使用TriQuest，43名教师课程设计效率得到了提高，课程计划质量也有所改善，并且显著降低了设计障碍和认知负荷。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07686", "html_url": "https://arxiv.org/abs/2510.07686", "title": "应力测试模型规格揭示语言模型的性格差异", "title_en": "Stress-Testing Model Specs Reveals Character Differences among Language Models", "authors": "Jifan Zhang,Henry Sleight,Andi Peng,John Schulman,Esin Durmus", "background": "随着大规模语言模型（LLMs）越来越多地基于AI宪法和模型规范进行训练，这些规范设立了行为准则和伦理原则，但在实际应用中，这些规范面临内部原则冲突和场景覆盖不足的关键挑战。研究团队提出了一个系统化的测试方法，通过生成特定场景来自动识别模型规格中原则冲突和解释不清的情况。", "innovation": "该研究团队提出了一种系统化的应力测试方法，通过生成特定的场景，迫使模型在不同的价值观之间做出明确的权衡，识别出多起原则相互冲突和解释不清的案例。实验使用全面的价值分类对十二个领先LLM进行了评估，揭示了模型行为在多样情景下的重要分歧。该研究强调，这种高行为分歧能够强有力地预测模型规范中存在的潜在问题，并通过具体例子展示了当前模型规范中的直接矛盾和原则解释不清的现象，揭示了模型间的value优先级和差异。", "conclusion": "通过应力测试发现，模型规格设计中存在诸多问题与分歧，包括直接矛盾和解释不清的情况，这不仅限于某一种模型，而是广泛存在于各种领先的LLM之中。该研究所生成的数据集进一步揭示了所有研究的模型之间的明确偏差和假阳性拒绝的情况，为改进模型规格提供了新的视角。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04008", "html_url": "https://arxiv.org/abs/2510.04008", "title": "用锐化的余弦相似度替代softmax相似度：扩展到十亿上下文注意机制的理论与实践", "title_en": "Replacing Softmax Similarity with a Sharpened Angular Similarity: Theory and Practice of Scaling To Billion-Context Attention", "authors": "Sahil Joshi,Agniva Chowdhury,Amar Kanakamedala,Ekam Singh,Evan Tu,Anshumali Shrivastava", "background": "Softmax 软件注意力机制具有二次时间复杂度，在处理长上下文时变得难以执行，即使在高度优化的GPU内核上也是如此。例如，FlashAttention (一种精确的GPU优化实现 Softmax 软件注意力机制) 在NVIDIA GH200 (96 GB) 上一旦上下文超过约4百万个标记将无法完成一次前向-后向传递过程。这就限制了当前最先进的注意力实现所能达到的实际上下文大小。", "innovation": "RACE 软件注意力机制是一种线性的替代核机制，既依赖序列长度又依赖嵌入维度。RACE 用锐化的余弦相似度替代了指数核，并通过随机投影和软局部敏感哈希 (LSH) 近似注意力输出。在语言建模、掩码语言建模和文本分类中，RACE 软件注意力机制达到了强基线的准确率并减少了运行时间和内存占用。", "conclusion": "在控制规模测试中，RACE 软件注意力机制在NVIDIA GH200 GPU 上可以在单次前向-后向传递过程中处理多达12百万个标记，并在 Intel Xeon Gold 5220R CPU 上处理7.5百万个标记，这远远超出了当前最先进的注意力机制所能达到的实用极限。因此，RACE 软件注意力机制提供了在当今硬件上实现极其长上下文窗口的一种实用且有理论依据的方法，并期望被采纳应用。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08396", "html_url": "https://arxiv.org/abs/2510.08396", "title": "FlyLoRA: 通过隐式按秩分配的专家混合提升任务解耦和参数效率", "title_en": "FlyLoRA: Boosting Task Decoupling and Parameter Efficiency via Implicit Rank-Wise Mixture-of-Experts", "authors": "Heming Zou,Yunliang Zang,Wutong Xu,Yao Zhu,Xiangyang Ji", "background": "低秩适应（LoRA）方法是基础模型高效微调的一种常见方法，但其存在参数干扰的问题，导致性能不佳。虽然基于Mixture-of-Experts（MoE）的LoRA变种在单任务指令微调中能够减弱任务内的相关性并显示出一定的潜力，但在多任务模型融合中，任务间的干扰仍然无法有效解决。现有方法在处理任务间的干扰时效率不高，且引入了额外的路由器参数。", "innovation": "FlyLoRA 提出了一个基于MoE的隐式 LoRA 变种，通过引入按秩激活专家的上投影矩阵以及隐式的路由器，重新设计了专家路由和下投影的过程。它使用冻结的稀疏随机投影矩阵替代了传统的密集可训练版本，从而在解决任务内去相关与计算效率间的权衡问题的同时，通过随机矩阵的正交性质本身抑制了任务间的干扰。", "conclusion": "广泛的实验结果表明，FlyLoRA 在四个不同的领域——通用知识理解、科学问题回答、数学推理和代码生成中，相较于现有方法均表现出一致的性能提升。FlyLoRA 进一步证明了生物结构可以成为激发AI技术创新的灵感来源。开源代码可在提供的链接处获得。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12384", "html_url": "https://arxiv.org/abs/2510.12384", "title": "全表型多组学整合揭示人类衰老的异质性模式", "title_en": "Phenome-Wide Multi-Omics Integration Uncovers Distinct Archetypes of Human Aging", "authors": "Huifa Li,Feilong Tang,Haochen Xue,Yulong Li,Xinlin Zhuang,Bin Zhang,Eran Segal,Imran Razzak", "background": "衰老是一个复杂且异质性过程，不同个体的衰老速率不同，因此生物年龄（BA）比实际年龄更能精确反映生理衰退。尽管以前的研究已经使用单方式表数据建立了衰老时钟，但这些方法往往无法捕捉到人类衰老的全部分子复杂性。", "innovation": "本工作利用了包含40至70岁10,000名成年人口的巨型队列，此队列包含临床、行为、环境和多种组学数据集（包括转录组学、脂质组学、代谢组学和微生物组）。通过运用能够建模非线性生物学动力学的高级机器学习框架，开发并严格验证了一个集成多组学的衰老时钟，能够预测多样化的健康结果和未来疾病风险。", "conclusion": "无监督聚类分析揭示了不同类型的生物学子类型衰老，揭示了衰老轨迹中的显著异质性，并确定了与不同衰老模式相关的特定信号通路改变。这些发现表明多组学整合解码衰老分子谱的强大力量，并为个性化健康寿命监测和预防衰老相关疾病提供了精准策略的基础。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09114", "html_url": "https://arxiv.org/abs/2510.09114", "title": "关于隐私保护的公平性：测量和缓解差异隐私机器学习中群体隐私风险差异", "title_en": "On the Fairness of Privacy Protection: Measuring and Mitigating the Disparity of Group Privacy Risks for Differentially Private Machine Learning", "authors": "Zhi Yang,Changwu Huang,Ke Tang,Xin Yao", "background": "虽然在传统公平意识机器学习和差分隐私机器学习方面已经取得了显著进展，但群体之间的隐私保护公平性仍然未被充分探索。现有的研究已经提出了一些评估群体隐私风险的方法，这些方法基于数据记录的平均场景下的隐私风险。然而，这些方法可能低估了群体间的隐私风险差异，可能导致低估不同群体隐私风险的差异。此外，评估数据记录的最大可能隐私风险的方法耗时较长，限制了其实用性。现有研究提出的解决方案在这方面存在不足，因此需要一种新的方法来解决这些问题并更好地评估和缓解群体隐私风险之间的差异。", "innovation": "本文提出了一种新的会员推理游戏，能够高效地审计数据记录的近似最坏情况下的隐私风险。此外，为了在差分隐私机器学习中促进隐私保护公平性，本文还提出了一种基于差分隐私审计研究中Canary设计的自适应群体特定梯度剪裁策略来增强标准的DP-SGD算法。该方法有效地减少了群体之间的隐私风险差异，从而增强了差分隐私机器学习中的隐私保护公平性。", "conclusion": "实验结果表明，方法能够提供更严格的群体隐私风险测量，并提供可靠的群体隐私风险差距评估。增强了标准DP-SGD算法后，该算法能够在差分隐私机器学习中减轻不同群体隐私风险间的差距，增强了隐私保护的公平性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.13894", "html_url": "https://arxiv.org/abs/2510.13894", "title": "贝叶斯或海森堡：归属权归属何人？", "title_en": "Bayes or Heisenberg: Who(se) Rules?", "authors": "Volker Tresp,Hang Li,Federico Harjes,Yunpu Ma", "background": "尽管量子系统通常用量子态矢量来描述，但研究表明，在某些情况下，其测量过程可以重新表述为基于概率状态矢量的概率方程。这些概率表示可以进一步通过张量大脑（TB）模型的神经网络动力学来近似。张量大脑是一种新提出的框架，用于脑部感知和记忆建模，它为高效整合生成的符号表示并进行推理过程提供了生物学启发的机制。", "innovation": "提出了一种将量子系统的测量过程重新表述为基于概率状态矢量的概率方程的方法，并通过张量大脑模型的神经网络动态来近似这些概率表示。这为理解量子测量过程提供了一种新颖的方法，同时也展示了张量大脑模型在生物启发式脑科学中的应用潜力。", "conclusion": "该研究指出，对于量子测量过程的理解可以采用概率方程的方式来表达，并且这种表达可以通过张量大脑模型中的神经网络动力学来实现。这不仅提供了对量子力学和概率论之间关系的新视角，也为神经网络在量子系统中的应用开辟了新的可能性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15001", "html_url": "https://arxiv.org/abs/2510.15001", "title": "VaultGemma: 一个具有差分隐私的Gemma模型", "title_en": "VaultGemma: A Differentially Private Gemma Model", "authors": "Amer Sinha,Thomas Mesnard,Ryan McKenna,Daogao Liu,Christopher A. Choquette-Choo,Yangsibo Huang,Da Yu,George Kaissis,Zachary Charles,Ruibo Liu,Lynn Chua,Pritish Kamath,Pasin Manurangsi,Steve He,Chiyuan Zhang,Badih Ghazi,Borja De Balle Pigem,Prem Eruvbetine,Tris Warkentin,Armand Joulin,Ravi Kumar", "background": "在隐私保护的大语言模型领域， VaultGemma 1B被引入作为Gemma家族的一个1亿参数模型，并完全使用差分隐私方法进行训练。该模型基于与Gemma 2系列相同的预训练数据集，标志着隐私保护大语言模型的重要进展。", "innovation": "VaultGemma 1B是Gemma系列中的一个1亿参数模型，采用了差分隐私技术进行全面训练。这一模型是为了解决在保护用户隐私的同时实现高性能的大语言模型训练。", "conclusion": "VaultGemma 1B模型被公开发布给社区，展示了在保留用户隐私的同时实现大语言模型的有效途径，标志着该领域的重要一步。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14449", "html_url": "https://arxiv.org/abs/2510.14449", "title": "梯度下降优化和L1稀疏约束的一对多逻辑回归多类别分类中的特征选择和正则化：实证研究", "title_en": "Feature Selection and Regularization in Multi-Class Classification: An Empirical Study of One-vs-Rest Logistic Regression with Gradient Descent Optimization and L1 Sparsity Constraints", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel", "background": "多类别葡萄酒分类展示了模型准确性、特征维度和可解释性之间的基本权衡。对于分析化学中的生产部署，理解和优化这些因素至关重要。该论文通过对UCI葡萄酒数据集进行全面的实证研究，讨论了这些因素的影响。", "innovation": "论文提出了使用一-vs-一切逻辑回归和梯度下降优化的一组实证研究。研究比较了自定义梯度下降与scikit-learn优化求解器，并量化了L1正则化对特征稀疏性的影响。研究还提出了一个基于5个特征的最优子集，实现了62%的复杂度减少和约92-94%的准确率，并验证了其成本效益和时间效率。", "conclusion": "研究结果强调了在资源受限环境中权衡全面化学分析和目标特征测量的重要性，并为实际操作提供了实用的指导。通过减少92-94%的复杂度和节约80美元的每样本成本，同时预测延迟低于2毫秒，研究证明了该方法对于实时质量控制的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11824", "html_url": "https://arxiv.org/abs/2510.11824", "title": "合作多智能体强化学习中鲁棒性和弹性的实证研究", "title_en": "Empirical Study on Robustness and Resilience in Cooperative Multi-Agent Reinforcement Learning", "authors": "Simin Li,Zihao Mao,Hanxiao Li,Zonglei Jing,Zhuohang bian,Jun Guo,Li Wang,Zhuoran Han,Ruixiao Xu,Xin Yu,Chengdong Ma,Yuqing Ma,Bo An,Yaodong Yang,Weifeng Lv,Xianglong Liu", "background": "在合作多智能体强化学习(MARL)中，通常会在理想的模拟环境中调整超参数以最大化合作性能。然而，这些针对合作优化的策略在现实世界中的不确定性面前表现出脆弱性和不稳定性。建立可信赖的MARL系统需要深刻理解鲁棒性和弹性，前者确保在不确定性下的稳定性，后者是应对干扰的能力。尽管这些概念在控制系统中被广泛研究，但在MARL领域中却未被充分重视。因此，研究者们开展了一项大规模的实证研究，包括超过82,620次实验，评估了4个真实世界环境、13种不确定性类型和15个超参数下MARL中的合作、鲁棒性和弹性。", "innovation": "研究发现，在轻度不确定性下，优化合作可以改善鲁棒性和弹性，但随着扰动加剧，这种联系会减弱。鲁棒性和弹性也因算法和不确定性类型的不同而不同。此外，研究揭示了鲁棒性和弹性不跨不同类型的不确定性或代理范围进行泛化，某些针对所有代理有效的鲁棒策略可能在单一代理的观测噪声下失效。研究证明了超参数调整对于可信赖MARL的重要性：尽管标准做法如参数共享、GAE和PopArt可以损害鲁棒性，但早期停止、高评论家学习率和Leaky ReLU则始终提供帮助。通过对超参数进行优化，观察到所有MARL架构下的合作、鲁棒性和弹性都有显著提升。这一现象在这些架构下的鲁棒MARL方法中也有泛化。", "conclusion": "本研究表明，在轻度不确定性下优化合作可以提升鲁棒性和弹性，但这种关系在扰动加剧时会减弱。鲁棒性和弹性因算法和不确定性类型而异，不跨不同类型的不确定性或代理范围进行泛化。调整超参数对于建立可信赖的MARL系统至关重要，某些整体制策可以损害鲁棒性，而早期停止、高评论家学习率和Leaky ReLU等策略始终有帮助。优化超参数可以显著提升MARL中的合作、鲁棒性和弹性，这些发现对所有MARL架构下的鲁棒策略也有效。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15382", "html_url": "https://arxiv.org/abs/2510.15382", "title": "Towards Robust Zero-Shot Reinforcement Learning", "title_en": "Towards Robust Zero-Shot Reinforcement Learning", "authors": "Kexin Zheng,Lauriane Teyssier,Yinan Zheng,Yu Luo,Xianyuan Zhan", "background": "零样本强化学习（RL）的最新发展为学习能够适应任意新任务的通用预训练策略开辟了一个新的途径。虽然现有的前向-后向表示（FB）及相关方法在零样本RL方面显示出潜力，但研究者发现其建模缺乏表达力，并且在离线学习过程中由分布外（OOD）动作引起的外推错误有时会导致有偏表示，最终导致性能不佳。", "innovation": "本文提出了行为正则化增强零样本强化学习（BREEZE），这是一种升级的基于FB的框架，能够在提高学习稳定性、策略提取能力和表示学习质量的同时，通过引入零样本RL策略学习中的行为正则化，将策略优化转化为一个稳定的数据拟合学习范式。BREEZE还使用任务条件化扩散模型提取策略，能够在零样本RL环境中生成高质量的多模态动作分布。此外，BREEZE采用具有表达力的注意机制架构进行表征建模，以捕捉环境动力学之间的复杂关系。", "conclusion": "BREEZE在ExORL和D4RL Kitchen上的实验表明，其性能达到或接近最优，并且相比之前的离线零样本RL方法具有更好的鲁棒性。官方实现可在此网址查看：[提供网址]。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11100", "html_url": "https://arxiv.org/abs/2510.11100", "title": "HoMer: 通过建模序列和集合上下文来解决异质性以进行点击率预测", "title_en": "HoMer: Addressing Heterogeneities by Modeling Sequential and Set-wise Contexts for CTR Prediction", "authors": "Shuwei Chen,Jiajun Cui,Zhengqi Xu,Fan Zhang,Jiangke Fan,Teng Zhang,Xingxing Wang", "background": "点击率（CTR）预测作为工业推荐系统的基础，依赖于对手部序列行为和非序列特征（例如用户/项目简介或交叉特征）的建模，以推断用户兴趣。然而，大多数方法面临三种异质性的挑战，这些挑战会削弱预测性能：(i) 特征异质性因为有限的序列侧特征相比广泛的非序列特征提供较少的粒度兴趣表示，从而损害序列模型性能；(ii) 上下文异质性由于一个用户对项目兴趣会受到其他项目的影晌，而点估计忽视了整个项目集内的跨项目交互上下文；(iii) 架构异质性源于专业化网络模块的碎片化整合，这综合作模型的效果、效率和可扩展性，在工业部署中的不利影响。", "innovation": "为了解决上述限制，本文提出了HoMer，这是一种面向序列和集合上下文的同质化导向的TransforMer。首先，HoMer通过将序列侧面特征与非序列特征对齐，实现精确的序列建模和细致的兴趣表示。其次，它从点估计转向集合估计，促进高度并行的跨项目交互。第三，HoMer的统一编码器-解码器架构通过结构简化和共享计算实现双重优化，确保计算效率的同时，通过模型大小保持可扩展性。", "conclusion": "在不修改预测流水线的情况下，HoMer成功扩展，并且在AUC度量上超越了我们的工业基准，获得了0.0099的提升。此外，在线业务指标如CTR/RPM也分别提高了1.99%/2.46%。此外，HoMer通过初步工程优化节省了27%的GPU资源，进一步验证了它的优越性和实用性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12953", "html_url": "https://arxiv.org/abs/2510.12953", "title": "面向胎儿超声解读的命题意识视觉语言基础模型", "title_en": "Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation", "authors": "Xiao He,Huangxuan Zhao,Guojia Wan,Wei Zhou,Yanxing Liu,Juhua Liu,Yongchao Xu,Yong Luo,Dacheng Tao,Bo Du", "background": "近年来，医学视觉语言模型在诸如VQA（视觉-问答）、报告生成和异常检测等任务上显示出潜力。然而，大多数模型都是为结构化的成人影像设计的，在胎儿超声这一领域表现不佳。胎儿超声具有多视角图像推理的挑战、众多疾病的特殊性和影像多样性的特征。鉴于此，本文提出了FetalMind，一个针对胎儿超声的医疗人工智能系统，用于报告生成和诊断。该模型基于临床工作流程，并通过引入一种专家整理的二分图——命题意识解耦（Epistemic Disentanglement, SED）技术，专门设计来解决上述挑战。", "innovation": "本文提出了FetalMind和SEDA技术，SEDA旨在通过通过引入专家整理的二分图来分离开视图-疾病关联，并利用强化学习引导临床忠实的步骤来进行偏好选择。该设计减少了疾病间和视图间的差异性影响，使模型的学习瓶颈减少，并且使得模型的推理与妇产科的实践保持一致。为了大规模训练FetalMind，本文还创建了一个全新的大型胎儿超声报告语料库FetalSigma-1M，包括来自十二家医疗机构的20000份报告，解决了领域数据稀缺的问题。实验表明，FetalMind在所有妊娠阶段的表现优于开源和闭源的基本模型，尤其在危急情况的准确性上提高了61.2%，且模型保持了高效、稳定和可扩展性。", "conclusion": "总之，FetalMind及其SEDA技术成功解决了胎儿超声解读中的多项挑战，并通过大规模的数据集和广泛的实验验证了其优越性能。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15398", "html_url": "https://arxiv.org/abs/2510.15398", "title": "MARIS：基于几何增强和语义对齐的海洋开放词汇实例分割", "title_en": "MARIS: Marine Open-Vocabulary Instance Segmentation with Geometric Enhancement and Semantic Alignment", "authors": "Bingyu Li,Feiyu Wang,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li", "background": "现有大部分水下实例分割方法局限于近似词汇预测，限制了它们对新海洋类别识别的能力。为了支持评估，该论文引入了MARIS（海洋开放词汇实例分割），这是第一个大规模细粒度的水下开放词汇分割基准，具有少量已知类别和多样化的未知类别。尽管在自然图像上开放词汇分割显示出潜力，但分析发现，其在水下场景中的迁移效果受限于严重的视觉降解（如颜色衰减）和由于缺乏水下类别定义所导致的语义不对齐问题。", "innovation": "论文提出了一种统一框架，包括两个互补组件：几何先验增强模块（GPEM）利用稳定的部分级和结构化线索，在视觉降解条件下保持对象一致性；语义对齐注入机制（SAIM）通过融合领域特定先验增强语言嵌入，以减轻语义模糊性并改进未知类别的识别。实验表明，该框架在MARIS基准上的一致性能优于现有开放词汇基准，为未来的水下感知研究提供了坚实的基础.", "conclusion": "该框架在MARIS基准上的一致性能优于现有开放词汇基准设定，并为未来的水下感知研究建立了坚实基础。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16171", "html_url": "https://arxiv.org/abs/2510.16171", "title": "桥接对称性与鲁棒性：在增强对抗鲁棒性中的等变性作用", "title_en": "Bridging Symmetry and Robustness: On the Role of Equivariance in Enhancing Adversarial Robustness", "authors": "Longwei Wang,Ifrat Ikhtear Uddin,KC Santosh,Chaowei Zhang,Xiao Qin,Yang Zhou", "background": "对抗样本能够揭示深度神经网络中的关键漏洞，这些漏洞由于神经网络对微小输入扰动的高度敏感性而被暴露。虽然对抗训练目前是主要的防御策略，但其通常会产生显著的计算成本，并可能对干净数据的准确性造成损害。", "innovation": "本文研究了一种基于架构的方法来提高对抗鲁棒性，通过将旋转和尺度等变卷积嵌入到标准卷积神经网络（CNN）中。该方法通过编码先验对称性来使模型行为与输入空间中的结构变换相一致，从而促进更平滑的决策边界和更大的对对抗攻击的抗性。实验结果显示，该方法在CIFAR-10, CIFAR-100和CIFAR-10C上的对抗鲁棒性和泛化能力均有所提升，且无需进行对抗训练。", "conclusion": "这些发现强调了强制对称性的架构设计作为高效且合乎原理的替代数据增强防御策略的潜力。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16396", "html_url": "https://arxiv.org/abs/2510.16396", "title": "SPLite手部：基于稀疏性的轻量化3D手部姿态估计", "title_en": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "authors": "Yeh Keng Hao,Hsu Tzu Wei,Sun Min", "background": "随着AR/VR设备的广泛应用，深度学习模型在边缘设备上的部署成为关键挑战。这些设备需要支持实时推理、低功耗和低延迟。许多框架设计师在效率和性能之间面临权衡问题。", "innovation": "我们设计了一个轻量级框架，采用了编码器-解码器架构，并引入了几个关键贡献，以同时提高效率和准确性。通过在ResNet-18主干上应用稀疏卷积来利用手部图像中的固有稀疏性，实现了端到端42%的效率提升。此外，我们提出了一种新的SPLite解码器，使RPi5上的解码帧率提高了3.1倍，同时保持了相当的准确性。为了进一步优化性能，我们应用了量化感知训练，在降低内存使用的同时保持了准确性（FreiHAND上的PA-MPJPE从9.0 mm略微增加到9.1 mm）。总体而言，我们的系统在RPi5 CPU（BCM2712四核Arm A76处理器）上实现了2.98倍的速度提升。此外，我们的方法在复合基准数据集上进行了评估，显示出与最先进的方法相当的准确性，显著提高了计算效率。", "conclusion": "我们的系统在RPi5 CPU上实现了高效的3D手部姿态估计，同时保持了与先进方法相当的准确性。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17111", "html_url": "https://arxiv.org/abs/2510.17111", "title": "高效视觉-语言-行动模型在嵌入式操作中的系统性综述", "title_en": "Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey", "authors": "Weifan Guan,Qinghao Hu,Aosheng Li,Jian Cheng", "background": "视觉-语言-行动（VLA）模型通过将自然语言指令和视觉观察映射到机器人行动，扩展了视觉-语言模型以进行嵌入式控制。然而，VLA系统因其巨大的计算和内存需求而面临挑战，这些需求与边沿平台如车载移动 manipulator 的实时性能要求相冲突。", "innovation": "本文综述了提高VLA效率的方法，重点在于减少延迟、内存占用和训练与推理成本。将现有解决方案分为模型架构、感知特征、行动生成和训练/推理策略四个维度，并总结了每个类别中的代表性技术。", "conclusion": "最后，本文讨论了未来趋势和开放挑战，强调了推进高效嵌入式智能的方向。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16709", "html_url": "https://arxiv.org/abs/2510.16709", "title": "HumanCM：一步人体运动预测", "title_en": "HumanCM: One Step Human Motion Prediction", "authors": "Liu Haojie,Gao Suixiang", "background": "以往的基于扩散的方法依赖于多步去噪过程才能生成人体运动预测，但这过程复杂且效率较低。本文提出的HumanCM模型，利用一致性模型，仅通过一次高效的学习映射过程，在嘈杂和干净的运动状态之间建立起联系。通过采用基于Transformer的空间-时间架构，并结合时间嵌入特性，有效地捕捉长距离依赖关系，保持运动连贯性，特别适合处理长序列数据，从而大幅提升运动预测的准确性。", "innovation": "HumanCM采用了一步生成的方式，代替了传统的多步去噪，通过学习嘈杂和干净运动状态之间的自一致性映射，提高了生成过程的效率。更重要的是，它利用了基于Transformer的空间-时间架构和时间嵌入的方法，有效捕捉了长距离的时间依赖性，从而在高效生成的同时保证了运动的连贯性和准确性。此外，与现有的扩散模型相比，HumanCM在准确度相当的情况下，还能将推理步骤减少到原来的百分之一甚至更低。这种突破性设计大大提升了一步生成模型的有效性和实际应用的便捷性。", "conclusion": "在Human3.6M和HumanEva-I数据集上的实验结果表明，HumanCM不仅在运动预测的准确性上达到了现有的扩散模型的水平，同时在生成效率上实现了显著提高，减少多达两个数量级的推理步骤。这表明，该模型在保持预测准确性的同时大幅提升了计算效率，为实时运动预测提供了更强的支持。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19072", "html_url": "https://arxiv.org/abs/2510.19072", "title": "基于配置的多智能体路径规划中的局部引导", "title_en": "Local Guidance for Configuration-Based Multi-Agent Pathfinding", "authors": "Tomoki Arita,Keisuke Okumura", "background": "引导是一种新兴的概念，能够提升实时、非最优多智能体路径规划（MAPF）方法的实验性能。通过考虑所有智能体在整个工作空间中的集体行为，它可以在全局范围内缓解拥堵问题，从而降低智能体的等待时间，提高整体协调效率。", "innovation": "本文探讨了一种替代方法：在每个智能体附近提供局部引导。虽然这种本地化方法由于智能体移动需要重新计算并且可能看起来计算量大，但实验证明，向规划器提供有效的时空线索可以在不会超出适度时间预算的情况下显著提高解的质量。", "conclusion": "将这种形式的引导应用于领先的基于配置的求解器LaCAM，可以为MAPF设定一个新的性能前沿。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17451", "html_url": "https://arxiv.org/abs/2510.17451", "title": "计算VC维的参数化复杂性", "title_en": "The Parameterized Complexity of Computing the VC-Dimension", "authors": "Florent Foucaud,Harmender Gahlawat,Fionn Mc Inerney,Prafullkumar Tale", "background": "VC-dimension是多项式时间内研究广泛且基础的集合系统（或超图）复杂度度量，在机器学习的多个领域中起着核心作用。现有的文献中关于计算VC-dimension的方法已经存在，但论文中作者进一步探讨了计算该复杂度的精确和近似算法的参数化复杂性，并提供了新的理论结果和技术手段。", "innovation": "1. 证明了朴素的时间复杂度为2^O(|V|)的算法在指数时间假设（ETH）下是渐近上界。\n2. 提出了一个度参数下的1-可加固定参数近似算法。\n3. 提出了一个维度参数下的固定参数算法。\n4. 设计了一个针对树宽为tw的图的时间复杂度为2^O(tw log tw)·|V|的算法，同时又证明了针对树宽为tw的集合系统中的 incidence graph，其复杂度也是最优的。\n5. 提出了一个图基于图形的更广泛的VC-dimension问题形式，可以同时捕捉集合系统和图的VC-dimension。", "conclusion": "这些研究成果表明，虽然VC-dimension的精确计算复杂度是指数级的，但在某些参数上可以利用固定的参数算法来优化。此外，作者设计的算法在处理树宽为tw的问题时表现出最优的复杂度，这为解决相关问题提供了新的方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19338", "html_url": "https://arxiv.org/abs/2510.19338", "title": "每一个注意力都重要：一种用于长时间上下文推理的高效混合架构", "title_en": "Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning", "authors": "Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou", "background": "本文技术报告介绍了Ring-linear模型系列，包括Ring-mini-linear-2.0和Ring-flash-linear-2.0。该系列模型通过结合线性注意力和 softmax 注意力，显著降低了长上下文推理场景中的输入/输出和计算开销。", "innovation": "1. 系统性地探索了混合架构中不同注意力机制的比例，发现当前最优的模型结构。\n2. 利用了自主研发的高性能 FP8 运算库 linghe，提高了整体训练效率50%。\n3. 由于训练和推理引擎操作的高度对齐，模型可以在强化学习阶段长期稳定高效地优化，并保持在多个复杂推理基准测试中SOTA性能。", "conclusion": "与320亿参数的密集模型相比，该模型系列将推理成本降低了1/10，与原始Ring系列相比，成本降低了50%以上。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17621", "html_url": "https://arxiv.org/abs/2510.17621", "title": "GUIDE: 使用去噪模型增强联邦学习中的梯度反转攻击", "title_en": "GUIDE: Enhancing Gradient Inversion Attacks in Federated Learning with Denoising Models", "authors": "Vincenzo Carletti,Pasquale Foggia,Carlo Mazzocca,Giuseppe Parrella,Mario Vento", "background": "联邦学习（FL）允许在保护隐私的前提下，多个客户端协作训练机器学习模型。客户端不是共享原始数据，而是发送本地计算的更新来训练全局模型。尽管该范式比中心化机器学习应该提供更强的隐私保护，但客户端更新仍可能受到隐私泄露的风险。攻击者可以通过梯度反转攻击（GIAs）利用这些更新来反推出训练数据的敏感属性，甚至重构原始输入。在诚实但好奇的假设下，GIAs旨在使用优化技术逆转中间更新，从而重建训练数据。然而，这些方法通常只能准确重构噪声版本的原始输入。", "innovation": "本文提出了一种新的方法——梯度更新反转去噪（GUIDE），它利用扩散模型作为去噪工具，以提高联邦学习中图像重建攻击的质量。GUIDE 可以集成到任何利用代理数据集的 GIAs 中，这两种攻击在文献中广泛应用。在两个使用不同联邦学习算法、模型和数据集的攻击场景中，对我们的方法进行了综合评估。", "conclusion": "研究结果表明，GUIDE 可以与两种最先进的 GIAs 紧密整合，显著提高多个指标下的重构质量。具体而言，GUIDE 的感知相似度最高可提升 46%，使用 DreamSim 指标进行测量。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17385", "html_url": "https://arxiv.org/abs/2510.17385", "title": "TabR1: 利用GRPO训练用于表格推理的LLMs", "title_en": "TabR1: Taming GRPO for tabular reasoning LLMs", "authors": "Pengxiang Cai,Zihao Gao,Jintai Chen", "background": "传统上，表格预测依赖于梯度增强决策树和专门的深度学习模型，这些模型在特定任务上表现出色，但缺乏可解释性，且跨表格的迁移能力较弱。相对而言，大型语言模型（LLMs）因其透明的推理痕迹和跨任务适应性潜力得到了关注，但目前尚未充分利用这些潜力来处理表格数据。因此，本文旨在探索一种新的方法来改进LLMs在表格预测任务中的性能和可解释性，以期实现更好的泛化能力。", "innovation": "本文提出了TabR1，一种专为表格预测设计的推理LLM，采用了多步推理机制。核心是Permutation Relative Policy Optimization (PRPO)，一种简单而高效的强化学习方法，通过将列排序不变性作为结构先验，提高了模型的学习效率及泛化能力。该方法在低监督下激活了LLMs的推理能力，提升了少量标注和无标注场景下的性能和可解释性。此外，实验表明，在全监督微调中，TabR1达到了与现有基准相当的性能；在无监督场景中，TabR1的表现接近32标注点的基准。并且在多种任务中，TabR1（8B参数量）显著优于许多更大规模的模型，最高比DeepSeek-R1（685B）提升了53.17%的性能。", "conclusion": "通过利用PRPO方法，TabR1在表格预测任务中实现了高性能及良好的可解释性，尤其是在有限标注数据条件下，展现了显著的优势，为大型语言模型在表格数据上的应用提供了新的解决方案和发展思路。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17930", "html_url": "https://arxiv.org/abs/2510.17930", "title": "命名实体识别模型在噪声口语数据中扩展到新PII实体的表征动力学诊断", "title_en": "Diagnosing Representation Dynamics in NER Model Extension", "authors": "Xirui Zhang,Philippe de La Chevasnerie,Benoit Fabre(papernest)", "background": "在噪声口语语言数据中扩展命名实体识别（NER）模型以识别新的个人身份信息（PII）实体（如电子邮件和电话号码）是一个常见需求。研究发现，同时在标准语义实体（PER、LOC、ORG）和新基于模式的PII（如EMAIL、PHONE）上联合微调预训练的语言模型（这里以BERT模型为例），对于原始的实体类别影响较小。", "innovation": "使用增量学习设置作为诊断工具，研究发现两个关键见解：1）LOC实体由于与其他新PII的表示重叠而特别脆弱，因为它与模式特征（如邮政编码）共享；2）识别到一种“反向O标签表示漂移”。模型起初将PII模式映射为'O'，阻止新的学习，这种问题只有通过解冻'O'标签分类器，让背景类适应并“释放”这些模式，才能解决。这项工作为NER模型的适应提供了一个机理诊断，突显了特征独立性、表示重叠和'O'标签灵活性。", "conclusion": "这项工作提供了NER模型适应的机理诊断，强调了特征独立性、表示重叠和'O'标签的灵活性，提出了用于PII识别的新型增量学习设置和技术方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16807", "html_url": "https://arxiv.org/abs/2510.16807", "title": "通过第一层值头的跳连提高模型表示并减少KV缓存", "title_en": "Improving Model Representation and Reducing KV Cache via Skip Connections with First Value Heads", "authors": "Zhoutong Wu,Yuan Zhang,Yiming Dong,Chenheng Zhang,Cong Fang,Kun Yuan,Zhouchen Lin", "background": " Transformer 模型由于其强大的学习丰富上下文表示的能力，在各种语言任务中取得了突破。然而，为了扩大规模以提高表示能力，往往需要大量的内存和计算成本，例如自回归解码期间使用的 Key-Value (KV) 缓存。现有的研究通常要么通过增强模型表示能力同时保持 KV 缓存不变，要么通过减少内存使用来削弱模型表示能力。尽管引入了跳连连接（skip connections）来提高模型表示能力而不会增加资源使用，但大多数前作要么在此过程中保持 KV 费用不变，要么减少内存使用但牺牲表示能力。", "innovation": "本文提出了一种名为 SkipV1Former 的 Transformer 变体模型，它利用最早层 (第一层) 的值头 (Value heads) 连接来加强模型表示和减小 KV 缓存。从第二层开始，每一层重新使用其大部分的第一层值头，同时计算剩余部分，从而将 Value 投影和 V 缓存减少了近一半。研究表明，将未压缩的第一层值路由到深层层可以恢复压缩过程中丢失的信息，并加速模型的自适应优化——即 Transformers 在自回归任务中的一个重要模式。实验结果表明，SkipV1Former 在不同规模的模型中实现了约 25% 的 KV 缓存减少，相较于标准的多头注意机制（MHA）Transformer 及一些先进变体，同时改善了困惑度。此外，作者提供了一个仅需额外 10-15% 计算的指令集来将现有的 MHA Transformer 模型提升到 SkipV1Former 模型。还可以结合其他高级方法（如组查询注意力 Group-Query Attention 和多潜在注意力 Multi-Latent Attention），以实现 KV 缓存的进一步减少和性能改进。当与 YOCO 结合使用时，它可以将近 50% 的 KV 缓存大小切减，同时仍然提高性能。", "conclusion": "SkipV1Former 通过引入跳连连接从最初层 Value 头重新利用值头来加强表示能力和减少 KV 缓存，实现了以上改进。这一工作展示了通过这种方式可以同时提高模型表示能力并减少资源消耗的可能性，并提供了实际改进多头关注机制 Transformer 的方法。"}
{"llm_update_time": "20251026", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19755", "html_url": "https://arxiv.org/abs/2510.19755", "title": "扩散模型中的缓存方法综述：迈向高效的多模态生成", "title_en": "A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation", "authors": "Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang", "background": "扩散模型已经成为现代生成AI的核心，因其出色的生成质量和可控性。然而，它们固有的多步迭代和复杂的骨干网络导致了巨大的计算开销和生成延迟，成为实时应用的瓶颈。尽管现有的加速技术取得了一定进展，但仍面临诸如应用限制、高培训成本或质量下降等挑战。", "innovation": "介绍了‘扩散缓存’（Diffusion Caching）这一无需训练、架构无关且高效的推理范式。其核心机制识别并重用扩散过程中的内嵌计算冗余。通过在特征级别跨步骤重用和层间调度，减少计算而不修改模型参数。该论文系统地审查了扩散缓存的理论基础和演变，并提出了统一的分类和分析框架。研究展示了扩散缓存从静态重用向动态预测的演变趋势，增强了其在不同任务中的灵活性，并使其能够与其他加速技术如采样优化和模型蒸馏相结合，为未来多模态和交互应用提供统一高效推理框架。", "conclusion": "我们认为这种范式将成为实时和高效生成AI的关键推动力，为高效生成智能的理论和实践注入新的活力。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19871", "html_url": "https://arxiv.org/abs/2510.19871", "title": "从去噪到精炼：一种视觉语言扩散模型的纠错框架", "title_en": "From Denoising to Refining: A Corrective Framework for Vision-Language Diffusion Model", "authors": "Yatai Ji,Teng Wang,Yuying Ge,Zhiheng Liu,Sidi Yang,Ying Shan,Ping Luo", "background": "离散扩散模型在视觉语言任务中展现出前景，能够双向建模上下文并提供理论上的并行化。然而，实际应用中由于训练与推理之间的差距导致了一系列问题，如初始令牌错误在并行解码中污染生成上下文，进而引发一系列累积错误，导致语法错误和语义幻觉。", "innovation": "该研究将生成过程重新定义为积极的精炼过程，引入了ReDiff，一种增强的精炼扩散框架，旨在使模型识别并纠正自身错误。该框架通过两阶段训练进行：首先，通过训练模型修正合成错误来培养基础的修改能力；其次，通过让模型从专家修改中学习并明确训练其修正自身不完善草稿的能力，建立了一个新的在线自我纠正循环。这种错误驱动学习赋予模型重新审视并改进已生成输出的关键能力，从而有效打破错误传播。", "conclusion": "广泛的实验结果表明，ReDiff大幅提升了生成内容的连贯性和事实准确性，实现了比传统去噪方法更为稳定和高效的并行生成。相关代码和模型可以在指定的网页获取。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19875", "html_url": "https://arxiv.org/abs/2510.19875", "title": "Stream: 通过稀疏注意力扩展大型语言模型长上下文的机制可解释性", "title_en": "Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention", "authors": "J Rosser,José Luis Redondo García,Gustavo Penha,Konstantina Palla,Hugues Bouchard", "background": "随着大型语言模型（LLMs）的上下文规模扩展到百万令牌，传统的机制可解释性技术对于分析注意力的复杂度会以上下文长度的平方增长，超出10万个令牌就需要使用几十太字节的内存。这使得传统方法在处理长上下文时变得不切实际。", "innovation": "我们提出了稀疏跟踪（Sparse Tracing）这一新方法，利用动态稀疏注意力来高效分析长上下文的注意力模式。我们还开发了Stream算法，这是一种可编译的分层剪枝算法，能够在接近线性时间内（O(T log T））和线性空间（O(T））提供每次传递的可解释性，从而在大规模分析中不再需要使用大量的缓存。Stream通过一种二分搜索式的精炼方法来保留每个查询中最重要的k个关键块，同时保持模型的输出行为。", "conclusion": "通过Stream，我们能够在不使用大量缓存的情况下分析注意力模式并追踪信息流动，从而使长上下文的解释变得可行，并能利用消费级GPU来进行链式推理监控。该方法通过揭示关键信息路径，大大提升了对模型行为的理解，同时在网络互动中保留了必要的信息。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19858", "html_url": "https://arxiv.org/abs/2510.19858", "title": "DeBERTa-KC: 基于Transformer的在线学习话语中的知识构建分类器", "title_en": "DeBERTa-KC: A Transformer-Based Classifier for Knowledge Construction in Online Learning Discourse", "authors": "Jindi Wang,Yidi Zhang,Zhaoxing Li", "background": "本研究旨在通过自动分类在线科学学习对话中的知识构建(KC)水平，提出了一种基于Transformer的模型DeBERTa-KC。研究者从四个热门YouTube科学频道收集了2022年至2024年的评论，并创建了一个平衡的数据集，包含20,000个手动标注样本，涵盖了‘nonKC’、‘Share’、‘Explore’和‘Negotiate’四个KC类别。背景信息还提到，模型通过扩展DeBERTa-v3来解决类别不平衡问题，增加了Focal Loss、Label Smoothing和R-Drop正则化，增强了泛化能力。", "innovation": "提出了DeBERTa-KC模型，这是一种基于DeBERTa-v3的增强版本，通过添加Focal Loss、Label Smoothing和R-Drop正则化，提高了模型在不平衡类别下的分类性能。该模型显示出对高层次认知参与的强烈敏感性，特别是在‘Explore’和‘Negotiate’的话语中。研究结果表明，大规模语言模型能够有效捕捉非正式数字学习环境中知识构建的复杂指标，提供了一种可扩展且基于理论的方法来进行话语分析，以及开发自动化工具来评估认知参与度.", "conclusion": "在10折分层交叉验证中，DeBERTa-KC达到了0.836 ± 0.008的宏F1分数，显著优于传统的和基于Transformer的基线模型。类别特定的结果表明，此模型特别对更高阶的认知参与敏感，特别是在‘Explore’和‘Negotiate’类别中表现出色。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19866", "html_url": "https://arxiv.org/abs/2510.19866", "title": "不同模型和提示框架在高中物理中生成教学计划的教育适宜性和可用性评估", "title_en": "An Evaluation of the Pedagogical Soundness and Usability of AI-Generated Lesson Plans Across Different Models and Prompt Frameworks in High-School Physics", "authors": "Xincheng Liu", "background": "本研究旨在评估五个领先的人工智能语言模型生成的教学计划在教育上的合理性及实用性，模型包括ChatGPT、Claude Sonnet、Gemini 2.5 Flash、DeepSeek V3.2和Grok 4。研究通过对高中物理“电磁谱”主题生成十五个教学计划进行对比分析，运用了三类结构化的提示框架：任务导向框架（TAG）、问题和途径框架（RACE）和情境化框架（COSTAR）。研究还采用了四项自动计算指标来评估生成的教学计划：可读性和语言复杂度、事实准确性及幻觉检测、课程标准和课程内容的对照、学习目标的认知需求级划分。这些分析指标帮助更好地理解不同模型与提示框架对教学计划影响的具体表现和效果差异。", "innovation": "研究创新地结合了多种大型语言模型和不同的提示框架结构，全面评估了生成的教学计划在教育上的合理性及实用性。不同模型和提示框架对生成的教学计划有显著影响，表明在教育应用中模型和提示框架的选择非常重要。这为未来的教育技术应用提供了新的研究方向和参考依据。", "conclusion": "研究发现，模型的设计对生成的教学计划的可读性有显著影响，而教学计划的可靠性及与课程内容的对齐情况则更多取决于提示框架结构。研究建议，结合可读性优化的模型与RACE提示框架，并明确包含物理概念、课程标准和高阶目标的清单，是生成有效教学计划的最佳配置。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19879", "html_url": "https://arxiv.org/abs/2510.19879", "title": "使用大型语言模型在荷兰电子健康记录中自动筛查HIV", "title_en": "Automated HIV Screening on Dutch EHR with Large Language Models", "authors": "Lang Zhou,Amrish Jhingoer,Yinghao Luo,Klaske Vliegenthart--Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li", "background": "HIV的有效筛查和早期诊断对于减少其传播至关重要。尽管大规模实验室测试不可行，但由于电子健康记录（EHRs）的普遍使用，开辟了解决这一挑战的新机遇。现有研究主要集中在使用机器学习方法分析结构化数据（如患者人口统计信息）以提高HIV诊断的准确性。然而，这些方法往往忽略了未结构化的文本数据（如临床记录），这些数据可能包含与HIV风险相关的重要信息。", "innovation": "本研究提出了一种新的管道，利用大型语言模型（LLM）分析未结构化的EHR文本，以确定患者是否需要进一步的HIV测试。实验结果表明，该管道在维持低假阴性率的同时实现了高精度。", "conclusion": "本研究用临床数据从鹿特丹伊拉斯姆斯大学医学中心验证了该管道的有效性，展示了利用大型语言模型通过电子健康记录自动进行HIV筛查的前景。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19892", "html_url": "https://arxiv.org/abs/2510.19892", "title": "Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities", "title_en": "Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities", "authors": "Nishant Balepur,Dang Nguyen,Dayeon Ki", "background": "现有的多模态大语言模型（MLMs）通常在静态的单一基准上进行评估，这种方式无法在单一任务中统一对MLMs能力的评估，或者依赖人类或模型之间的对比，这种方式极为主观、耗费成本且允许模型利用浅层捷径（例如冗长）来提升胜率。", "innovation": "该研究提出了基于游戏的评估方法来全面评估MLMs的能力。游戏需要玩家具备多种能力才能获胜，具有内在的竞争性，并且由固定且客观的规则管理。实验具体通过Dixit这款幻想卡片游戏，其中玩家需要为一张卡片生成描述以迷惑一部分但不是所有玩家，从而选择正确的卡片。通过这五种MLMs的定量实验发现，Dixit的游戏胜率排名与大众MLMs基准完全相关，在Dixit游戏中，人类玩家与MLMs之间的比赛揭示了代理策略之间的差异和MLMs推理能力改进的领域。", "conclusion": "定量实验表明Dixit的胜率排名与流行的大语言模型基准完全相关，人类玩家与MLMs在Dixit游戏中的比赛揭示了代理策略的差异和MLMs推理能力的进步空间。这种方法提供了对MLMs进行评估的一个强大框架，解决了传统评估方法中的诸多挑战，使评估更具参与性且更加客观。\n"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19886", "html_url": "https://arxiv.org/abs/2510.19886", "title": "基于专家基准的一般用途大语言模型在生命周期评估中的评估", "title_en": "An Expert-grounded benchmark of General Purpose LLMs in LCA", "authors": "Artur Donaldson,Bharathan Balaji,Cajetan Oriekezie,Manish Kumar,Laure Patouillard", "background": "随着人工智能（AI），尤其是大型语言模型（LLMs）在环境和社会领域中的应用越来越多，它们在支持生命周期评估（LCA）方面的作用也受到了广泛关注。然而，对于LLMs在LCA中的可靠性和稳定性的系统证据仍然不足，缺乏标准化的评估框架。这项研究填补了这一空白，通过一项专家评审项目，首次构建了一套针对LCA的LLMs基准，并分析了现有模型的实际表现，为未来的研究和应用提供了参考。", "innovation": "研究采用了专家评审的方法，全面评估了十一款一般用途的LLMs在22项与LCA相关的任务中的表现。评估标准包括科学准确性、解释质量、稳定性、验证性和指令遵循性。研究首次提供了没有明确真实参考点或共识协议的领域中标准化的LLMs评估框架，弥补了该领域的研究空白。", "conclusion": "研究结果揭示了在处理LCA时简单地使用LLMs可能带来的一些风险，例如当LLMs被当作无限制的预言机使用时，但它也展示了LLMs在解释质量上的优势，并能减轻某些劳动密集型任务的负担。采用泛用型LLMs且不进行底层机制的约束其应用前景尚存疑问，但通用模型在某些关键指标如准确性和解释质量上的表现令人满意，为未来的LCA实践提供了一定的信心和支持。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19895", "html_url": "https://arxiv.org/abs/2510.19895", "title": "由大型语言模型支持的数学建模", "title_en": "Large Language Model enabled Mathematical Modeling", "authors": "Guoyun Zhang", "background": "传统的优化方法如线性规划、混合整数规划和仿真等高度依赖领域专家将实际问题转化为可解的数学模型。虽然像Gurobi和COPT这样的求解器非常强大，但专家输入对于定义目标、约束和变量仍至关重要。语言理解能力较强且具有代码生成能力的新模型DeepSeek-R1虽然在基准测试中表现出色，但对其在实际运筹学场景中的应用效果尚未得到充分探讨。为填补这一空白，本研究系统地评估了DeepSeek-R1在四类运筹学基准上的表现：NL4OPT、IndustryOR、EasyLP和ComplexOR。", "innovation": "本研究利用DeepSeek-R1模型探索将大型语言模型与优化建模相结合的新途径。研究开发了幻觉分类法，并应用了包括LLM-as-a-Judge、少样本学习（FSL）、工具调用（Tool Calling）和多代理框架在内的技术手段，旨在降低幻觉产生，提高建模精确性和更好地匹配用户意图。", "conclusion": "本研究通过系统地评估DeepSeek-R1在多个运筹学基准上的表现，验证了大型语言模型在优化建模中的潜力。研究结果有助于进一步改进和应用此类模型在供应链等实际场景中的效用。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19897", "html_url": "https://arxiv.org/abs/2510.19897", "title": "基于语义和情景记忆的监督学习：一种反思性的智能体适应方法", "title_en": "Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation", "authors": "Jackson Hassell,Dan Zhang,Hannah Kim,Tom Mitchell,Estevam Hruschka", "background": "本文研究了如何利用预训练的大规模语言模型构建的代理从带有标签的示例中学习目标分类函数，而无需更新参数。传统的调优方法虽然常见，但往往成本高、缺乏灵活性且不透明。", "innovation": "本文提出了一种增强记忆框架，该框架结合了标记数据和大型语言模型生成的评论。该框架使用情景记忆存储实例级评论（捕捉特定的过往经历），并使用语义记忆提炼这些评论以形成可复用的任务级指导。研究表明，加入这些评论可以显著提高准确性，在多项任务中，引入评论相比基于检索（RAG类型）的基本模型提高了24.8%的准确性。通过广泛的实证研究，发现OpenAI和开源模型在处理事实导向的数据和偏好导向的数据方面的行为差异显著。为了解释记忆中以不同方式表示的监督如何影响模型的行为，引入了一个新的指标：可建议性。这个指标帮助解释了观察到的行为，并揭示了模型特性和记忆策略如何共同影响学习动态。", "conclusion": "研究发现，基于记忆的反思性学习有潜力构建更具适应性且更可解释的LLM代理。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19967", "html_url": "https://arxiv.org/abs/2510.19967", "title": "LyriCAR：一种难度感知的课程强化学习框架用于可控歌词翻译", "title_en": "LyriCAR: A Difficulty-Aware Curriculum Reinforcement Learning Framework For Controllable Lyric Translation", "authors": "Le Ren,Xiangjian Zeng,Qingqiang Wu,Ruoxuan Liang", "background": "歌词翻译是一个挑战性的任务，需要平衡多种音乐约束。现有方法通常依赖手工规则和句子级别的建模，这限制了它们在内部化语言音乐模式和在段落级上有效推断的能力，而段落级涉及多行连贯和全局韵律等关键因素。现有方法在处理这些复杂要求时显得力有未逮，通常无法同时实现高质量的翻译和高效的收敛性。因此，需要一种新的框架来解决这些挑战，以实现更高效的训练、更好的均衡音乐语言模式的掌握以及在段落级上的鲁棒表现。", "innovation": "该论文提出了一种名为LyriCAR的新型框架，该框架以完全监督的方式运行，引入难度感知的课程设计师和自适应课程策略，从而更有效地分配训练资源，加速收敛并提高整体翻译质量。LyriCAR通过逐步引入越来越复杂的挑战来引导模型，实现了在标准翻译指标和多维度奖励得分方面达到的最佳表现，远超过强大的基线。自适应课程策略将训练步骤减少了接近40%，同时保持了优越的性能。", "conclusion": "实验结果表明，LyriCAR在EN-ZH歌词翻译任务中不仅在标准翻译指标方面，而且在多维度奖励得分方面都取得了最先进的结果，表明了其高效性和优越性。研究强调了自适应课程策略在提高训练效率方面的重要性，并展示了新型框架的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19996", "html_url": "https://arxiv.org/abs/2510.19996", "title": "依赖解析的基本算法（附更正）", "title_en": "A Fundamental Algorithm for Dependency Parsing (With Corrections)", "authors": "Michael A. Covington", "background": "该论文提出了一种用于将自然语言句子解析为依赖树的基本算法。不同于基于短语结构（构成性）的解析器，该算法按照遇到每个单词的顺序逐步解析，与大脑中所述的解析器特性相对应。依赖解析相较于短语结构解析，其最坏情况复杂度也是$O(n^3)$，但在人类语言中，最坏情况仅出现在小规模$n$的情况下。", "innovation": "该算法以一次处理一个单词的方式进行解析，并且能够像人类大脑的解析过程一样实时地建立依赖关系。尽管在最坏情况下复杂度与基于短语结构的解析相同，但实际应用中其效率显著提高。", "conclusion": "该论文介绍了一种新型的依赖解析算法，它不仅能实现实时解析，还能够有效处理更大规模的自然语言数据。尽管最坏情况下的复杂度较高，但在实际应用中，由于算法的高效性，这一缺点可以被忽略。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20001", "html_url": "https://arxiv.org/abs/2510.20001", "title": "超越MedQA：在大模型时代迈向真实的临床决策", "title_en": "Beyond MedQA: Towards Real-world Clinical Decision Making in the Era of LLMs", "authors": "Yunpeng Xiao,Carl Yang,Mark Mai,Xiao Hu,Kai Shu", "background": "大型语言模型（LLMs）在临床应用中显示出前景，通常使用MedQA等数据集进行评估。然而，许多医疗数据集，如MedQA，依赖简化的问题回答（Q&A），这未能充分反映真实世界的临床决策过程。", "innovation": "提出了一个新的范式，从两个维度来定义临床决策任务：临床背景和临床问题。这使得难度随着背景和问题的接近真实临床环境而增加。总结了现有数据集和基准测试的设置，并回顾了应对临床决策的方法，包括训练时间和测试时间的技术，总结了它们何时有效。进一步扩展了评价指标，包括准确性和效率。突出了面临的关键挑战。", "conclusion": "这一范式明确了假设，标准化了比较，并指导了临床有意义的大模型开发。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20002", "html_url": "https://arxiv.org/abs/2510.20002", "title": "为现代希腊语建立GEMs：通过基于质量的语料库编纂和专门预训练推动希腊自然语言处理", "title_en": "Forging GEMs: Advancing Greek NLP through Quality-Based Corpus Curation and Specialized Pre-training", "authors": "Alexandra Apostolopoulou,Konstantinos Kanaris,Athanasios Koursaris,Dimitris Tsakalidis,George Domalis,Ioannis E. Livieris", "background": "现代希腊语这类富有形态特征但资源中等的语言在自然语言处理领域的发展常常受到研究领域分散、架构多样性缺乏以及局限于短语量模型的限制。特别是在法律等高价值专业领域，现有的模型通常仅限于早期的变压器架构，这些架构对长文本法律文件的分析能力不足。", "innovation": "本文提出了一种新的基于希腊语的变压器模型家族——希腊嵌入模型（Greek Embedding Models, GEMs），该模型是基于质量驱动的数据编纂之上，构建了一系列大尺度的希腊语语料库，并通过严格的质控和预处理方法，生成高质量的训练数据集。此外，还首次提出了针对法律领域的双语希腊语-英语嵌入模型。在各种下游任务上的广泛实验表明，新的模型体系证明了所提议方法的有效性，特别是GEM-RoBERTa和GEM-ConvBERT模型在现有基线模型上的显著优越性。", "conclusion": "研究证明了基于高质量语料库编纂和专门预训练的新模型体系的有效性。特别是针对法律领域的双语模型在各种任务中表现出了显著的性能提升。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20036", "html_url": "https://arxiv.org/abs/2510.20036", "title": "ToolScope：通过对工具合并和上下文感知过滤增强LLM代理工具使用", "title_en": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering", "authors": "Marianne Menglin Liu,Daniel Garcia,Fjona Parllaku,Vikas Upadhyay,Syed Fahad Allam Shah,Dan Roth", "background": "大语言模型（LLM）代理依赖外部工具来解决复杂任务，但实际中的工具集中存在冗余工具，名称和描述重叠，导致选择时产生歧义并降低准确性。此外，LLM面临输入上下文限制严格的问题，使得有效考虑大量工具集变得困难。", "innovation": "提出了ToolScope，其中包括：(1) ToolScopeMerger结合自动纠正功能来自动审计和修复工具合并，减少冗余；(2) ToolScopeRetriever对每个查询进行排名和选择最相关工具，压缩工具集以适应上下文限制而不会牺牲准确性。", "conclusion": "在三种领先LLM和三种开源工具使用基准上的评估显示，ToolScope在工具选择准确性上提高了8.38%到38.6%，证明了它在增强LLM工具使用方面具有有效性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20091", "html_url": "https://arxiv.org/abs/2510.20091", "title": "CreativityPrism：评估大型语言模型创造力的综合基准", "title_en": "CreativityPrism: A Holistic Benchmark for Large Language Model Creativity", "authors": "Zhaoyi Joey Hou,Bowei Alvin Zhang,Yining Lu,Bhiman Kumar Baghel,Anneliese Brei,Ximing Lu,Meng Jiang,Faeze Brahman,Snigdha Chaturvedi,Haw-Shiuan Chang,Daniel Khashabi,Xiang Lorraine Li", "background": "目前，虽然大型语言模型（LLMs）被认为可以生成具有创造性的文本，但尚未建立一个能够综合评估其创造力的框架，现有的评估方法仍较为零散，且在不同领域和任务间差异显著，主要原因是由于创造力的定义和衡量标准的不同。", "innovation": "该框架名为CreativityPrism，创新地将创造力分解为质量、新颖性和多样性三个维度，并通过九个任务、三个领域（发散思维、创意思维写作和逻辑推理）以及二十个评价指标来分别衡量每个维度，并以任务特定的方式进行评价。", "conclusion": "研究发现，与开源模型相比，自研模型在创造力方面表现出了显著的优势。模型在相同领域的任务中表现出较高的相关性，但在不同领域间相关性较低。在评价维度上，多样性和质量指标关联性较强，而新颖性指标则关联性较弱。这表明一个特定创造力任务或维度的强表现并不一定能推广到其他领域，强调了需要一个全面评估LLM创造力的需求。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20059", "html_url": "https://arxiv.org/abs/2510.20059", "title": "提升小型波斯语医学语言模型的推理能力可以超越大规模数据训练", "title_en": "Enhancing Reasoning Skills in Small Persian Medical Language Models Can Outperform Large-Scale Data Training", "authors": "Mehrdad Ghassabi,Sadra Hakim,Hamidreza Baradaran Kashani,Pedram Rostami", "background": "在医学问答等专门应用中，提升小型语言模型的推理能力对于处理少有资源语言如波斯语的内容至关重要。为此，研究者采用了一种名为Reinforcement Learning with AI Feedback (RLAIF) 和Direct Preference Optimization (DPO) 的方法，来提升通用波斯语语言模型的推理能力。", "innovation": "研究创新之处在于利用RLAIF和DPO技术，通过将一个医学多选题数据集翻译成波斯语，并生成被偏好和被拒绝的答案对，用于训练模型。同时，通过促使教师和学生模型生成问题解答的因果推理，构建了一个包含正确和错误推理路径的数据集。此外，使用的训练数据量远小于之前的方法，但仍能显著提高模型在波斯语医学问题上的推理能力。", "conclusion": "实验结果表明，虽然使用的训练数据量大大减少，但通过这种方法训练得出的模型在医学推理任务上的表现超过了之前使用约5700万个词令牌训练的模型gaokerena-V。这表明，针对特定领域进行推理集中的训练是非常有效的，尤其在数据量有限的情况下。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20043", "html_url": "https://arxiv.org/abs/2510.20043", "title": "从事实到民间传说：评估大型语言模型在孟加拉国文化知识方面的表现", "title_en": "From Facts to Folklore: Evaluating Large Language Models on Bengali Cultural Knowledge", "authors": "Nafis Chowdhury,Moinul Haque,Anika Ahmed,Nazia Tasnim,Md. Istiak Hossain Shihab,Sajjadur Rahman,Farig Sadeque", "background": "近年来，自然语言处理（NLP）研究展示了大型语言模型（LLMs）在各种任务中的卓越能力。尽管最近的多语言基准测试已经提升了对LLMs的文化评估，但在捕捉低资源文化细微之处方面仍然存在关键不足。本研究通过BLanCK数据集（包括民间传统、烹饪艺术和地方方言）来解决这些局限性，该数据集涵盖了孟加拉文化的重要方面。该研究发现多语言语言模型在非文化类别中表现良好，但在文化知识方面表现不佳，当提供上下文时，模型的整体性能显著提高，强调了需要具备上下文感知的架构和文化定制的训练数据的重要性", "innovation": "该研究引入了BLanCK数据集，这是第一个专门针对低资源文化的多语言语言模型评估数据集，涵盖了孟加拉文化的民间传统、烹饪艺术和地方方言。此外，研究强调了上下文感知架构和文化定制训练数据对提升模型跨文化知识表现的重要性", "conclusion": "多语言语言模型在非文化类别中的表现优于文化知识类别。提供上下文可以显著提高模型在文化知识任务中的表现。这发现表明，为了改进和提高多语言语言模型在文化知识方面的表现，需要更加注重上下文感知架构和文化定制的训练数据"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19988", "html_url": "https://arxiv.org/abs/2510.19988", "title": "LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation", "title_en": "LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation", "authors": "Xin Lian,Kenneth D. Forbus", "background": "尽管大规模语言模型（LLMs）具有广泛的应用性，但它们依赖于概率推理，在生成事实时易出现虚构的现象，在自然语言理解（NLU）任务中则可能导致输出结构不一致。相比之下，符号NLU系统具有可解释性，并且基于精选的词汇库、语义资源以及句法和语义解释规则，可以生成可用于准确推理和规划的关系表示。然而，符号NLU系统在覆盖面方面比LLMs更为有限，且需要稀缺的知识表示和语言学技能才能扩展和维护。", "innovation": "本文提出了一种混合方法，将LLMs的大面积语言处理能力与符号NLU生成结构化关系表示的能力结合起来，旨在充分利用两者的优点。方法中使用LLMs进行重写和文本简化，以实现广泛的覆盖，并自动填补知识空白；利用符号NLU产生可用于推理和增量学习的关系表示。", "conclusion": "我们在常识科学文本中提取并解释数量和因果律的任务中评估了此混合方法，并与仅使用符号NLU和仅使用LLMs的管道进行了对比。结果表明，我们的混合方法明显优于仅使用符号NLU的管道。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20098", "html_url": "https://arxiv.org/abs/2510.20098", "title": "通过自适应路由和目标推理利用大规模语言模型在实体链接中的力量", "title_en": "Leveraging the Power of Large Language Models in Entity Linking via Adaptive Routing and Targeted Reasoning", "authors": "Yajie Li,Albert Galimov,Mitra Datta Ganapaneni,Pujitha Thejaswi,De Meng,Priyanshu Kumar,Saloni Potdar", "background": "实体链接（EL）历来依赖于大规模的标注数据集和广泛的模型微调。近年来，通过提示利用大规模语言模型（LLMs）的few-shot方法虽然降低了训练需求，但往往由于昂贵的LLM基于推理变得不够高效。", "innovation": "ARTER（自适应路由和目标实体推理）提出了一种结构化的管道，通过战略性地结合候选生成、基于上下文的打分、自适应路由和选择性推理，达到了高性能而无需深入微调。ARTER计算了从检索候选中提取的一小组互补信号（包括嵌入和LLM基础），来将上下文提及分类为简单和复杂情况。不同情况分别由低计算量的实体链接器和更昂贵的目标LLM推理处理。", "conclusion": "在标准基准测试中，ARTER在ReFinED上的性能超过+4.47%，平均在5个数据集中提高了+2.53%，并且与所有提及都使用LLM推理的管道具有相似性能，但计算效率提高了两倍。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20033", "html_url": "https://arxiv.org/abs/2510.20033", "title": "通过调整预训练神经语言模型改进序列标注任务的迁移学习", "title_en": "Improving Transfer Learning for Sequence Labeling Tasks by Adapting Pre-trained Neural Language Models", "authors": "David Dukić", "background": "本文主要研究通过调整预训练的神经语言模型来改进序列标注任务中的迁移学习。背景在于当前的迁移学习方法在处理序列标注任务时存在不足，需要引入新的机制和技术来提升迁移学习的效果，特别是在领域迁移方面。", "innovation": "文章提出了一种多任务模型，引入了一个额外的信号，并通过在自回归大型语言模型中进行架构上的修改，以及利用生成性监督下文微调框架和响应导向的调整策略，来提升自回归大型语言模型在序列标注任务中的表现。这些创新方法不仅适用于事件触发检测的任务迁移，还能改进模型的双向信息流，以及通过生成性监督下文微调框架将自回归大型语言模型作为文本生成器来使用。", "conclusion": "所提出的方法展示了预训练神经语言模型在序列标注任务中通过目标导向的迁移学习策略可以实现最佳性能。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20151", "html_url": "https://arxiv.org/abs/2510.20151", "title": "BoundRL：通过强化边界生成实现高效结构化文本切分", "title_en": "BoundRL: Efficient Structured Text Segmentation through Reinforced Boundary Generation", "authors": "Haoyuan Li,Zhengyuan Shen,Sullam Jeoung,Yueyan Chen,Jiayu Li,Qi Zhu,Shuai Wang,Vassilis Ioannidis,Huzefa Rangwala", "background": "随着结构化文本在各个领域变得越来越复杂，从技术报告到生成AI提示，对于文本进行语义上具有意义的切分变得至关重要。传统的基于句子或段落级别的切分方法无法有效地处理表格、代码片段和占位符等非纯文本元素。", "innovation": "提出了一种名为BoundRL的新颖高效方法，该方法联合执行标记级文本切分和标签预测，用于长结构化文本。BoundRL通过奖励强化学习（RLVR）并结合自定义奖励优化文档重构准确度和语义对齐来适应输出格式。此外，通过系统性地对生成的片段序列进行扰动来构建中间候选方案，以逐步向高质解决方案过渡。实验表明，BoundRL使小型语言模型（参数量1.7B）在LLM应用中的复杂提示上超越了少量提示的大规模模型。使用我们设计的奖励对RLVR进行增强，从而显著改善了监督微调的效果；进一步引入中间候选方案则进一步提高了性能和泛化能力。", "conclusion": "BoundRL能够在保持较低推断成本和减少幻觉的同时有效地进行结构化文本切分，并且在复杂提示上展示了其在小规模语言模型上的广泛应用潜力。RLVR方法及其自定义奖励在文档重构和语义对齐方面超过了监督微调，并且通过生成中间候选方案进一步提高了模型的性能和泛化能力。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20154", "html_url": "https://arxiv.org/abs/2510.20154", "title": "大语言模型在零样本立场检测中是否受到刻板印象的影响？", "title_en": "Are Stereotypes Leading LLMs' Zero-Shot Stance Detection ?", "authors": "Anthony Dubreuil,Antoine Gourru,Christine Largeron,Amine Trabelsi", "background": "大型语言模型在预训练数据中继承了刻板印象，这在许多自然语言处理任务中导致了对某些社会群体的行为偏见，例如仇恨言论检测或情感分析。令人惊讶的是，这一类偏见在立场检测方法中的评估已经被社区忽视了。立场检测是指对某个特定目标的陈述进行正反中立的标签化，这是最敏感的自然语言处理任务之一，因为它经常涉及政治倾向。在这项研究中，作者关注的是在零样本设置中，大型语言模型在进行立场检测时的表现。", "innovation": "本研究通过自动标注现有的立场检测数据集中的帖子，将其分为方言或特定群体的独特方言以及文本复杂度/可读性两个属性，来探究这些属性如何影响模型的立场检测决策。研究发现，大型语言模型在立场检测任务中表现出显著的刻板印象，如错误地将支持大麻的观点与低文本复杂度关联起来，将非洲裔美国方言与对唐纳德·特朗普的反对联系起来。这一研究成果揭示了大型语言模型在零样本立场检测中的刻板印象问题，并为进一步研究提供了新的视角。", "conclusion": "研究结果表明，大型语言模型在立场检测任务中表现出显著的刻板印象，这可能影响其零样本环境下对特定群体的公正评估。因此，需要进一步研究以减少这种偏见，提高语言模型的社会敏感性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20176", "html_url": "https://arxiv.org/abs/2510.20176", "title": "Mixture-of-Minds: 多智能体强化学习在表格理解中的应用", "title_en": "Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding", "authors": "Yuhang Zhou,Mingrui Zhang,Ke Li,Mingyi Wang,Qiao Liu,Qifei wang,Jiayi Liu,Fei Liu,Serena Li,Weiwi Li,Mingze Gao,Abhishek Kumar,Xiangjun Fan,Zhuokai Zhao,Lizhu Zhang", "background": "理解和推理表格是许多实际应用中的关键能力。尽管大型语言模型（LLMs）在这一任务上展示出了潜力，但当前的方法仍然有限。基于微调的方法可以增强语言推理，但仍易犯算术错误和幻觉；基于工具的方法则能够精确地处理表格，同时依赖于严格的模式，缺乏语义理解。这些互补的缺点凸显了需要一个能够整合稳健推理和可靠表格处理的方法。", "innovation": "我们提出了一种称为 Mixture-of-Minds 的多智能体框架，将表格推理分解为三个专门的角色：计划、编码和回答。这种方法使每个智能体可以专注于任务的特定方面，同时利用代码执行进行精确的表格操作。在此基础上，我们引入了一种自我提升的训练框架，使用蒙特卡洛树搜索（MCTS）卷出生成伪黄金轨迹，并使用强化学习（RL）来优化智能体。", "conclusion": "广泛的实验表明，Mixture-of-Minds 能够取得显著的提升，在 TableBench 上达到了 62.13% 的成绩，并超越了 OpenAI-o4-mini-high 的表现。这些结果表明，将结构化的多智能体工作流程与 RL 结合起来能够进一步推动表格理解的进步。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20168", "html_url": "https://arxiv.org/abs/2510.20168", "title": "DeepWideSearch: Benchmarking Depth and Width in Agentic Information Seeking", "title_en": "DeepWideSearch: Benchmarking Depth and Width in Agentic Information Seeking", "authors": "Tian Lan,Bin Zhu,Qianghuai Jia,Junyang Ren,Haijun Li,Longyue Wang,Zhao Xu,Weihua Luo,Kaifu Zhang", "background": "当前的搜索代理在进行多跳检索的同时进行深层次推理以及广泛的信息收集方面存在根本性的缺陷，这对于诸如全面市场分析和企业发展等实际应用场景来说是关键的不足。为填补这个差距，这篇论文引入了DeepWideSearch，这是第一个专门设计来评价代理能否将深度和广度整合进信息查找的基准测试标准。在DeepWideSearch中，代理必须处理大量的数据，每项都需要进行多层次的推理以获取多跳检索路径。", "innovation": "这篇论文提出了DeepWideSearch，这是第一个明确设计来评估代理在信息查找任务整合深度和广度能力的基准。通过两种方法将现有数据集转化为具有15个不同领域的220个问题的各种对话场景。实验结果表明，即使是最先进的代理在DeepWideSearch上的平均成功率也只有2.39%，而错误分析揭示了四种失败模式：缺乏反思、过度依赖内在知识、检索不足和上下文溢出，进一步暴露出目前代理架构的关键局限性。DeepWideSearch已公开发布，以促进未来更强大和稳健的信息查找代理的研究。", "conclusion": "DeepWideSearch展现了当前代理在深度和广度信息查找方面存在的显著挑战，并通过其公开发布为未来的相关研究提供了重要工具。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20208", "html_url": "https://arxiv.org/abs/2510.20208", "title": "无解码采样策略用于LLM边缘化", "title_en": "Decoding-Free Sampling Strategies for LLM Marginalization", "authors": "David Pohl,Marco Cognetta,Junyoung Lee,Naoaki Okazaki", "background": "现代语言模型通过子词分词来平衡模型大小、推理速度和词汇覆盖范围。然而，在推理过程中，模型只能评估特定分词的输出概率，而存在多种可行的分词方式来表示同一文本。研究者提出应通过边缘化即所有可能分词的概率总和来评估大规模语言模型（LLM）。但由于文本的可能分词数量众多，直接进行边缘化计算非常困难。通常使用采样近似边缘化，但这种方法存在昂贵的生成步骤，限制了可以在给定时间内获取的样本数量，从而影响了近似精度。", "innovation": "研究提出了无解码采样策略，在保持无代价或极低成本的情况下进行采样，而不依赖于LLM生成，从而提高采样效率和边缘化估计的准确性。通过研究多个开源模型，验证了该策略在合理运行时间内提供足够准确的边缘化估计。", "conclusion": "无解码采样策略可以在极低的运行成本下提供足够的边缘化估计精度，适用于一系列下游推理任务。这种方法显著提高了评估LLM的效率和准确性，使得大规模语言模型评估更加可行。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20198", "html_url": "https://arxiv.org/abs/2510.20198", "title": "在矩阵中受困：探究大型语言模型的 spatial 理解能力", "title_en": "Stuck in the Matrix: Probing Spatial Reasoning in Large Language Models", "authors": "Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum", "background": "本文通过设计一系列五项任务来探索大型语言模型（LLMs）在处理文本输入时的空间推理能力。这些任务旨在测试其空间理解和计算能力。研究使用了基于结构化网格的环境，包括象限识别、几何变换、距离评估、单词搜索和瓷砖滑动等任务。实验结果显示，尽管对于小规模复杂度的任务，模型表现出适度的成功，但在大尺度下，性能显著下降，准确率平均下降42.7%，最高达到84%的下降。这些任务显示了随着复杂度增加，模型空间推理能力持续下降的趋势，暗示其内部架构缺乏稳健的空间表示能力。这项研究揭示了语言和空间推理之间的差距，为未来综合性基准测试提供了基础，特别是在语言和几何学交汇领域。", "innovation": "本研究通过一系列精心设计的任务来探索大型语言模型在空间推理方面的表现，特别是当规模增加时这些模型的表现。研究发现，这些模型在处理复杂任务时表现出明显的性能下降，这揭示了大型语言模型在处理空间推理任务时面临的重要挑战和限制。本研究填补了现有文献在大型语言模型空间推理能力上的空白，为未来的研究提供了方向和其他基准测试标准。", "conclusion": "本文揭示了大型语言模型在空间推理任务中存在明显的性能下降，特别是在复杂任务上。研究结果表明，这些模型内部缺乏稳健的空间表示能力，这限制了它们在更复杂任务中的应用。未来的研究需要探索如何提升大型语言模型的空间推理能力，填补语言和空间推理之间的差距，以实现更全面和综合的模型应用。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20304", "html_url": "https://arxiv.org/abs/2510.20304", "title": "探索生成过程奖励建模在半结构化数据中的应用：以表格问题回答为例", "title_en": "Exploring Generative Process Reward Modeling for Semi-Structured Data: A Case Study of Table Question Answering", "authors": "Lei Tang,Wei Zhou,Mohsen Mesgar", "background": "PRMs通过逐步评估候选解决方案并根据聚合步骤评分选择答案，提高了复杂推理能力，特别在数学等领域有效，但在如表格问题回答(TQA)这样的涉及半结构化数据的任务上尚未得到探索。TQA具有大量不相关信息、松散连接的推理步骤及领域特定推理等独特挑战。", "innovation": "本研究首次系统地探讨了PRMs在TQA中的应用，并从答案和步骤两个视角评估了最新的生成型PRMs。结果显示，结合文本和代码验证可以帮助选择解决方案，但难以泛化到领域外数据。分析发现，在步骤级验证的性能与答案准确性之间存在弱相关性，可能源于弱步骤依赖和松散的因果关系。这一发现凸显了当前PRMs在TQA中的局限性，并为建设更健壮的、过程感知的验证器提供了宝贵见解。", "conclusion": "当前PRMs在TQA中的局限性和建立更健壮、过程感知验证器的建议。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20303", "html_url": "https://arxiv.org/abs/2510.20303", "title": "引文失败：定义、分析和高效缓解", "title_en": "Citation Failure: Definition, Analysis and Efficient Mitigation", "authors": "Jan Buchmann,Iryna Gurevych", "background": "研究基于LLM的RAG系统时发现，文献引用应简化响应验证，但在引文失败情况下，模型可能生成有用的响应但无法完全引用证据。虽然一些研究试图解决这种引文失败问题，但这通常与响应失败混淆，即响应本身有缺陷且完全引用证据是不可能的。为了区分这两者并解决引文失败问题，作者提出了一个两步方法：步骤1是研究引文失败的条件及其影响，步骤2则是提出有效的缓解措施。作者通过CITECONTROL基准测试引入了新方法，该测试系统地变化了响应与证据之间的关系，以分析失败模式。实验结果表明，引文失败随关系复杂性的增加而增加，促进结合多种引文方法可能是提高性能的有效手段。为此，作者提出了一种名为CITENTION的框架，整合生成、注意力和检索基于的方法，结果表明在CITECONTROL和迁移设置中都显著改进了引文性能，并公开了数据和代码。", "innovation": "本文创新性地提出了一个两步法来解决引文失败的问题。首先，引入了CITECONTROL基准测试，系统地变化响应与证据之间的关系，以分析失败模式。其次，提出了名为CITENTION的整合框架，结合生成、注意力和检索基于的方法来提高引文性能。", "conclusion": "引文失败是RAG系统中的一个重要问题，作者通过引入CITECONTROL基准测试和CITENTION框架有效地解决了这一问题。实验结果表明，通过整合多种引文方法，显著提高了引文性能，并对其数据和代码进行了公开，为后续研究提供了便利。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20280", "html_url": "https://arxiv.org/abs/2510.20280", "title": "通过学习预测性上下文嵌入实现上下文级别语言建模", "title_en": "Context-level Language Modeling by Learning Predictive Context Embeddings", "authors": "Beiya Dai,Yuliang Liu,Daozheng Xue,Qipeng Guo,Kai Chen,Xinbing Wang", "background": "Next-token prediction (NTP) 是现代大型语言模型（LLMs）预训练的基础，推动了其在文本生成、逻辑推理和指令遵循方面的前所未有的能力。然而，基于token级别的预测限制了模型捕获高层语义结构和长程上下文关系的能力。为了克服这一限制，我们引入了 ContextLM 框架，通过增加内在的 next-context 预测目标来增强标准预训练。这种机制训练模型学习预测多token上下文的表示，利用来自将来token片段的错误信号。Extensive experiments on the GPT2 and Pythia model families, scaled up to 1.5B parameters，展示了 ContextLM 在困惑度和下游任务性能方面提供了持续改进。我们的分析表明，next-context 预测为更强大的语言建模提供了一种可扩展且高效的途径，实现了更好的长程序连贯性，并且接近零的计算开销就提高了注意力分配的有效性", "innovation": "通过引入 ContextLM 框架，增强标准预训练中的 next-context 预测目标，训练模型学习多token上下文的预测表示，利用未来token片段的错误信号，实现了困惑度和下游任务性能的改进。这种机制保持了与标准自回归、逐token评估范式（如困惑度）的兼容性，并且提供了在保持高效性的同时增强模型长距离上下文关系理解的方法", "conclusion": "ContextLM 通过 next-context 预测增强了语言建模，提供了更好的长程序连贯性和更有效的注意力分配，同时保持了标准评估范式的兼容性，展示了在 GPT2 和 Pythia 模型家庭中的有效性和长期前景"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20239", "html_url": "https://arxiv.org/abs/2510.20239", "title": "跨抑郁和创伤后应激障碍的三模态严重性融合诊断", "title_en": "Tri-Modal Severity Fused Diagnosis across Depression and Post-traumatic Stress Disorders", "authors": "Filippo Cenacchi,Deborah Richards,Longbing Cao", "background": "抑郁和创伤后应激障碍（PTSD）经常并发，伴有复杂共病症状，这导致了自动化评估变得尤为复杂，而现有的自动化评估往往是二元且针对单一障碍的。临床有价值的诊断需要理解不同障碍的严重程度，并提供决策支持解释。本研究提出了一种统一的三模态情感严重性框架，该框架结合和融合了面试文本、情感状态、音频信号和面部表情等多模态信息，以诊断抑郁和PTSD的严重程度。标准化特征通过校准的晚期融合分类器融合，从而输出每种障碍的概率和特征级归因。这项跨障碍的三模态情感融合方法能够进行并发抑郁与PTSD的评估。分层交叉验证在DAIC提取的数据集上优于单一模态/减除基线。融合模型在准确性和加权F1值方面达到了最佳的单模态基线模型，并在噪声或缺失模态下提高了稳健性，对于PTSD特别表现出减少回归误差和提高类别一致性。", "innovation": "该研究提出了一种统一的三模态情感严重性框架，能够同步和融合访谈文本、音频信号和面部表情等多模态信息，以诊断抑郁和PTSD的严重程度。该方法通过标准化特征的校准晚期融合分类器融合了这些多模态数据，并输出每种障碍的概率和特征级归因。分层交叉验证在DAIC提取的数据集上获得了优于单一模态和减除基线的表现，尤其在处理噪声或缺失模态时表现出更好的稳健性，特别在PTSD诊断中提高了回归误差和类别一致性。", "conclusion": "研究结果表明，提出的三模态严重性融合方法能够准确诊断抑郁和PTSD，并提供了临床决策支持和可解释性。此方法通过文本、音频和面部表情等多模态信息融合，针对抑郁症和PTSD有不同程度的贡献，其归因结果与语言和行为标记一致。该研究不仅提供了可重复的评估方法，还为临床情感决策支持提供了有望建立在反馈循环中的工作流。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20342", "html_url": "https://arxiv.org/abs/2510.20342", "title": "教语言模型使用工具进行推理", "title_en": "Teaching Language Models to Reason with Tools", "authors": "Chengpeng Li,Zhengyang Tang,Ziniu Li,Mingfeng Xue,Keqin Bao,Tian Ding,Ruoyu Sun,Benyou Wang,Xiang Wang,Junyang Lin,Dayiheng Liu", "background": "大型推理模型（LRMs）如OpenAI-o1展示了在自然语言推理方面的显著能力，但在处理复杂数学运算时经常表现出效率低下或错误。尽管集成计算工具（CIs）如代码解释器为解决这一问题提供了前景，但这也引入了一个关键挑战：模型内部的概率推理与CI提供的外部确定性知识之间发生了冲突，导致模型进行非生产性的思考。为解决这一问题，研究人员引入了CoRT（Code-Optimized Reasoning Training）后训练框架，旨在教导LRMs有效利用CIs。", "innovation": "提出了一种新的数据合成策略——Hint-Engineering，它在推理路径中的关键点战略性地注入多样化提示，生成高质量、代码整合的推理数据，专为优化LRM-CI交互而设计。CoRT使用拒绝采样和强化学习进一步优化外部CI使用与内部思考的多轮交织。实验表明，与纯自然语言推理基线相比，CoRT在3个参数量从1.5B到32B的语言模型上分别提高了4%和8%的表现，同时提高了效率，减少了大约30%到50%的令牌使用量。", "conclusion": "CoRT框架通过战略性地注入提示，优化了大型推理模型与代码解释器的交互，显著提高了模型在数学推理任务上的效率和准确性。实验结果验证了该方法的有效性，为未来的研究和应用提供了新的思路。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20356", "html_url": "https://arxiv.org/abs/2510.20356", "title": "FreeChunker: 一种跨粒度分块框架", "title_en": "FreeChunker: A Cross-Granularity Chunking Framework", "authors": "Wenxuan Zhang,Yuan-Hao Jiang,Yonghe Wu", "background": "现有基于分块策略的 Retrieval-Augmented Generation (RAG) 系统在固定粒度的分割范式中进行操作，依赖于静态边界的识别，限制了其适应不同查询需求的能力。", "innovation": "提出了 FreeChunker，一种跨粒度编码框架，将句子视为原子单位，并从静态分块分割转变为支持任意句子组合的灵活检索。这种范式转变不仅大大减少了语义边界检测所需的计算开销，还增强了对复杂查询的适应性。", "conclusion": "FreeChunker 在 LongBench V2 上的实验表明，与传统分块方法相比，其检索性能更优，并且在计算效率方面显著优于现有方法。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20351", "html_url": "https://arxiv.org/abs/2510.20351", "title": "在大规模语言模型中评估公开表格数据集的潜在知识", "title_en": "Evaluating Latent Knowledge of Public Tabular Datasets in Large Language Models", "authors": "Matteo Silvestri,Flavio Giorgi,Fabrizio Silvestri,Gabriele Tolomei", "background": "大规模语言模型（LLMs）在处理结构化数据上的推理能力受到越来越多的关注，但这类评估通常忽略了数据集污染这一关键混杂因素。本文研究了LLMs是否对广泛使用的表格基准数据集（如Adult Income、Titanic等）展示了先前知识。通过对一系列受控探测实验，发现污染效应仅存在于包含强烈语义线索的数据集中，如意义明确的列名或可解释的价值类别。当移除或随机化这些线索时，性能迅速下降到接近随机的水平。这些发现表明，LLMs在表格推理任务上的表象能力可能部分反映了对公开数据集的记忆，而非真正的泛化能力。", "innovation": "本文通过受控实验揭示了LLMs对公共常用表格基准数据集的记忆效应，发现只有包含强烈语义线索的数据集才会表现出较高的性能，而移除或随机化这些线索会导致性能急剧下降。研究结果提出了在未来的LLMs评估中分离语义泄露和真正的推理能力的新策略，强调了评估协议的改进需求。", "conclusion": "LLMs在表格推理任务上的表象能力可能部分反映了对公开数据集的记忆，而非真正的泛化能力。这提示了评估协议和未来LLMs评估中需要考虑分离语义泄露和真实推理能力的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20381", "html_url": "https://arxiv.org/abs/2510.20381", "title": "VLSP 2025 MLQA-TSR挑战：越南多模态法律问答与交通标志监管", "title_en": "VLSP 2025 MLQA-TSR Challenge: Vietnamese Multimodal Legal Question Answering on Traffic Sign Regulation", "authors": "Son T. Luu,Trung Vo,Hiep Nguyen,Khanh Quoc Tran,Kiet Van Nguyen,Vu Tran,Ngan Luu-Thuy Nguyen,Le-Minh Nguyen", "background": "该论文介绍了VLSP 2025 MLQA-TSR共享任务，这是一个关于交通标志监管的多模态法律问题回答任务。该任务旨在推动越南多模态法律文本处理的研究，并提供一个多模态法律领域的基准数据集，特别是针对越南交通标志监管。", "innovation": "VLSP 2025 MLQA-TSR包含两个子任务：多模态法律检索和多模态问题回答。这是首个专注于越南交通标志监管的多模态法律问题回答任务。其创新点在于针对多模态数据处理提出了新的研究方向。", "conclusion": "在VLSP 2025 MLQA-TSR任务中，最佳报告显示多模态法律检索任务的F2分数为64.55%，多模态问题回答任务的准确率为86.30%。这些结果表明，在多模态法律领域，特别是在越南交通标志监管方面，依然存在改进的空间，未来的研究可以进一步优化系统的性能。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20358", "html_url": "https://arxiv.org/abs/2510.20358", "title": "对话不足以造就一个有沟通能力的BabyLM（但也不是发展启发式强化学习）", "title_en": "Dialogue Is Not Enough to Make a Communicative BabyLM (But Neither Is Developmentally Inspired Reinforcement Learning)", "authors": "Francesca Padovani,Bastian Bunzeck,Manar Ali,Omar Momen,Arianna Bisazza,Hendrik Buschmeier,Sina Zarrieß", "background": "本文探讨了仅在对话数据上进行预训练是否能够生成在形式上和功能上都合适的较小语言模型。研究者基于此预训练模型，尝试了多种微调策略，旨在使模型生成更具交流性的文本。尽管这些模型在大部分BabyLM标准基准测试中表现不佳，但在双对比设置下的对话继续预测中表现出色。PPO微调对模型的效果呈混合甚至对抗性，但DPO微调进一步提高了模型在自定义对话基准测试中的表现.", "innovation": "本文的创新之处在于研究仅基于对话数据的预训练策略，并提出了多种微调策略来增强模型的交流能力。此外，研究还测试了PPO和DPO两种微调方法对模型性能的影响，并发现DPO比PPO更有效提高模型在对话任务上的表现.", "conclusion": "研究结果表明，仅在对话数据上进行预训练不足以生成具有良好交流能力的小型语言模型。然而，通过适当的微调，可以显著提高模型在对话任务上的性能。特别地，DPO微调策略在这种特定对话基准测试中表现出了更好的效果，而PPO则效果参差不齐。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20375", "html_url": "https://arxiv.org/abs/2510.20375", "title": "Large Language Models 中否定文本对幻觉的影响", "title_en": "The Impact of Negated Text on Hallucination with Large Language Models", "authors": "Jaehyung Seo,Hyeonseok Moon,Heuiseok Lim", "background": "近年来，自然语言处理领域对大型语言模型（LLMs）中的幻觉研究取得了积极进展。然而，否定文本对LLMs中幻觉的影响尚未受到充分研究。本文旨在通过三个未被解答的研究问题进行探讨，探索LLMs是否能识别由否定引起的语境转换，并可靠地区分与肯定情况相当的幻觉。研究设计了NegHalu数据集，通过重构包含否定表达式的幻觉检测数据集。实验结果表明，LLMs在处理否定文本时难以有效检测幻觉，往往会产生逻辑不一致或不忠实的判断。此外，研究还跟踪了LLMs在处理否定输入时的内部状态，揭示了减轻其意外影响的挑战。", "innovation": "本文提出了NegHalu数据集，通过否定表达式重新构建了现有的幻觉检测数据集，这是针对LLMs中幻觉研究的一个创新点。此外，通过跟踪LLMs在处理否定输入时的内部状态，揭示了其在检测幻觉时面临的挑战。这些发现为减轻LLMs中的幻觉问题提供了新视角。", "conclusion": "实验结果表明，LLMs在处理否定文本时难以有效检测幻觉，通常会产生逻辑不一致或不忠实的判断。进一步揭示了减轻LLMs中幻觉问题的挑战，并强调了需要更多的研究来改善LLMs处理否定文本的能力。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20411", "html_url": "https://arxiv.org/abs/2510.20411", "title": "教师示范在 BabyLM 领域发展区域中的应用：实现具有响应性的多回合交互", "title_en": "Teacher Demonstrations in a BabyLM's Zone of Proximal Development for Contingent Multi-Turn Interaction", "authors": "Suchir Salhan,Hongyi Gu,Donya Rooein,Diana Galvan-Sosa,Gabrielle Gaudeau,Andrew Caines,Zheng Yuan,Paula Buttery", "background": "多回合对话中的互动特征包括应答、直接和有意义的交流。该研究基于100万个词训练的BabyLM，引入了ContingentChat框架，旨在评估和提高多回合对话的应答性，使用新颖的后训练对齐数据集，提升生成的回答更为语法规则且连贯。", "innovation": "ContingentChat框架是针对多回合对话应答性的评估和改进的一种新方法。通过与教师学生的框架设计，引入后训练对齐数据集，提高生成的回答的语法规则性和连贯性。实验结果显示采用适应性教师解码策略的效果有限，表明应该更加关注针对性的后训练以提升对话质量，并且还指出多回合的互动对于BabyLM来说仍然是一个挑战的目标。", "conclusion": "ContingentChat展示了针对性后训练对对话质量的益处，并表明尽管取得了进展，但是多回合的互动对于现有的BabyLM来说仍然是一个具有挑战性的任务。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20460", "html_url": "https://arxiv.org/abs/2510.20460", "title": "在大型语言模型中系统评价不确定性估计方法", "title_en": "Systematic Evaluation of Uncertainty Estimation Methods in Large Language Models", "authors": "Christian Hobelsberger,Theresa Winner,Andreas Nawroth,Oliver Mitevski,Anna-Carolina Haensch", "background": "大型语言模型（LLMs）在生成输出时具有不同的不确定性水平，并且这些输出的准确性差异也很大，这使得它们的实际可靠性远不能得到保证。为了量化这种不确定性，作者系统评估了四种信心估计方法：VCE、MSP、样本一致性以及CoCoA（Vashurin等人，2025年）。实验在当前最先进的开源LLM上进行，以四个问题回答任务为测试场景。", "innovation": "作者的设计评估了四种不同的不确定性估计方法，并以混合CoCoA方法在整体可靠性上表现出最佳表现，既提高了校准性也提高了正确答案的区分度。此外，作者还讨论了每种方法的权衡，并提供了在LLM应用中选择不确定性度量的建议。", "conclusion": "每种不确定性度量捕捉了模型信心的不同方面，CoCoA方法在整体可靠性上表现出最佳表现，因此推荐使用CoCoA方法进行不确定性估计。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20475", "html_url": "https://arxiv.org/abs/2510.20475", "title": "优化预训练BabyLMs的掩码语言模型：得到你所掩蔽", "title_en": "Mask and You Shall Receive: Optimizing Masked Language Modeling For Pretraining BabyLMs", "authors": "Lukas Edman,Alexander Fraser", "background": "介绍了2025年的BabyLM挑战赛策略。背景信息提及当前Masked Language Modeling（掩码语言模型）方法在GLUE（General Language Understanding Evaluation）任务上的表现，并指出尽管有改进空间，但传统方法仍有一定的局限性。", "innovation": "该论文的主要贡献在于改进了掩码语言模型（MLM），通过模型预测能力调整被掩码的标记概率。此外，他们还引入了子标记嵌入，使模型能在形态学上更好地泛化。这项创新显著提升了（超）GLUE任务的表现，并在严格的Small赛道中超过了基准模型。", "conclusion": "该提交在严格的Small赛道中超越了基线模型，展示了在预训练BabyLMs时优化掩码语言模型方法的有效性，并提升了模型在形态学上的泛化能力。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20479", "html_url": "https://arxiv.org/abs/2510.20479", "title": "RECALL：通过层次化模型合并实现表示对齐的灾难性遗忘缓解", "title_en": "RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging", "authors": "Bowen Wang,Haiyuan Wan,Liwen Shi,Chen Yang,Peng He,Yue Ma,Haochen Han,Wenhao Li,Tiao Tan,Yongjian Li,Fangming Liu,Yifan Gong,Sheng Zhang", "background": "大型语言模型（LLMs）的内部表示可以作为学习知识的可靠代理。然而，在缺乏历史数据访问的情况下实现连续学习一直具有挑战性。现有的连续学习方法要么需要任务标签，要么导致性能折衷。", "innovation": "提出了一个名为RECALL的新颖表示感知模型合并框架，该框架在无需访问历史数据的情况下实现了连续学习。RECALL通过计算分层隐藏表示的层间相似性和进行自适应、分层参数融合，使浅层保留领域通用特征，深层实现任务特定适应，从而避免了灾难性遗忘和性能折衷问题。实验结果表明，RECALL在知识保留和泛化方面优于基线方法，并且提供了无标签数据的可扩展解决方案，适用于不断进化的LLMs。", "conclusion": "通过在多种NLP任务和连续学习场景下进行广泛的实验证明，RECALL能够无缝地进行多领域集成，提供强大的灾难性遗忘抗性，并且是大型语言模型演进的一个可扩展和无标签数据的解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20449", "html_url": "https://arxiv.org/abs/2510.20449", "title": "LM-mixup：基于语言模型混合法的文本数据增强", "title_en": "LM-mixup: Text Data Augmentation via Language Model based Mixup", "authors": "Zhijie Deng,Zhouan Shen,Ling Li,Yao Zhou,Zhaowei Zhu,Yanji He,Wei Wang,Jiaheng Wei", "background": "大型语言模型（LLMs）的指令调优至关重要，但低质量的指令跟随数据的质量差异巨大。尽管高质量数据是必需的，但往往稀缺，而低质量数据的丰富性导致了大量信息的丢失。现有的数据增强方法很难有效增强低质量的数据，并且这些技术的评估尚不明确。", "innovation": "本文正式定义了指令蒸馏任务：将多个低质量或语义冗余不完美的指令簇提炼为高质量且一致的指令-输出对。具体地，引入了一个综合的数据构建管道来创建MIXTURE数据集，该数据集包含144K样本，关联低质量或语义冗余的不完美指令簇与它们的高度高质量提炼版本。随后引入了LM-Mixup，首先在MIXTURE上进行监督微调，然后使用强化学习进行优化。整个过程使用了三种互补的奖励信号：质量、语义对齐和格式合规，通过组相对策略优化（GRPO）来实现。", "conclusion": "LM-Mixup有效地增强了不完美的数据集：在细调LLMs时使用其提炼的数据，该数据仅占整个数据集的约3%，不仅超越了全数据集训练，而且在多个基准测试中与最先进的高质量数据选择方法竞争。我们的工作证明，当适当提炼和使用LM-Mixup进行增强时，低质量数据是一个有价值的资源，显著提高了指令调优LLMs的效率和性能。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20386", "html_url": "https://arxiv.org/abs/2510.20386", "title": "NeoDictaBERT: 推动BERT模型在希伯来语中的边界", "title_en": "NeoDictaBERT: Pushing the Frontier of BERT models for Hebrew", "authors": "Shaltiel Shmidman,Avi Shmidman,Moshe Koppel", "background": "自BERT模型首次发布以来，尽管其参数量相对较少（如BERT-base约有100M个参数），但在多种任务上展示了出色的表现。然而，这些模型所使用的基础架构选择已经过时，与像Llama3和Qwen3这样的新型变压器模型相比不再具有优势。近年来，提出了几种架构以缩小这一差距。尽管现代BERT和NeoBERT在英语基准测试上表现出较强提升并在支持上下文窗口方面有显著扩展，但它们专注于希伯来语的模型尚不多见。因此，论文介绍了一种专门针对希伯来语文本训练的模型——NeoDictaBERT和NeoDictaBERT-bilingual。后者在多语言模型中表现出更强的检索任务能力，特别是在类似大小的情况下，优于其他多语言模型。这些模型在大多数希伯来语基准测试中表现出色，为后续任务提供了坚实的基础。本文描述了模型的训练过程，并在多种基准测试上报告了结果，这些模型作为社区的一部分被发布出去，旨在促进希伯来语自然语言处理的研究和发展。", "innovation": "1. 提出了NeoDictaBERT和NeoDictaBERT-bilingual两种BERT风格的模型，专门针对希伯来语文本进行训练。\n2. 新模型在大多数希伯来语基准测试中表现出色，比现有模型有显著提升。\n3. NeoDictaBERT-bilingual模型在检索等任务中表现出色，优于其他相似规模的多语言模型。", "conclusion": "NeoDictaBERT和NeoDictaBERT-bilingual模型在希伯来语任务上取得了显著的进展，为这一领域的未来研究和应用奠定了坚实的基础。这些模型被发布给社区，表明作者致力于推动希伯来语自然语言处理的发展。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20487", "html_url": "https://arxiv.org/abs/2510.20487", "title": "强制使具备评估意识的语言模型表现得像已部署的模型", "title_en": "Steering Evaluation-Aware Language Models To Act Like They Are Deployed", "authors": "Tim Tian Hua,Andrew Qin,Samuel Marks,Neel Nanda", "background": "大规模语言模型（LLMs）有时能够察觉到自身正在接受评估，并调整行为以显得更加对齐，这影响了安全性评估的可靠性。这篇论文探讨了一种通过在LLM的激活中添加向导矢量来抑制评估意识的技术，使得模型在评估时的行为更加接近部署时的行为。", "innovation": "论文提出了一种新的技术，通过在LLM的激活中添加一个向导矢量来抑制模型的评估意识，并使模型在评估时像实际部署时的行为，该技术在最初经过特定训练后，即使在存在评估提示的情况下，也能让模型的行为更加接近于部署环境下的行为。该技术利用原模型进行向导矢量的构建，避免了在模型训练中加入额外线索，从而改善安全性评估的可靠性。", "conclusion": "研究结果表明，通过对模型施加激活向导，可以抑制评估意识，即使存在评估提示，模型也能表现出更接近部署时的行为，这为提高安全性评估的可靠性提供了新的方法。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20498", "html_url": "https://arxiv.org/abs/2510.20498", "title": "通过方向局部共识实现稳健的偏好对齐", "title_en": "Robust Preference Alignment via Directional Neighborhood Consensus", "authors": "Ruochen Mao,Yuling Shi,Xiaodong Gu,Jiaheng Wei", "background": "创建可靠的和可控的AI系统的关键在于使大规模语言模型与人类偏好保持一致。人类偏好可以表示为高维向量，其中不同的方向表示不同特性的权衡（例如，有用性 vs. 详尽性）。数据训练往往偏向于主流和平均偏好，使得大规模语言模型在处理常见请求方面表现出色，但在处理特定的、个性化的需求方面表现不佳。这导致了一种偏好覆盖缺口。现有的方法通常通过昂贵的重新训练来解决这一问题，但这种方法可能不适用于广泛的多样化偏好。这种脆弱性意味着，当用户的请求反映了一种细微的，不同于训练数据中心趋势的偏好时，模型性能可能会不可预测地下降。", "innovation": "为了解决这一挑战，我们提出了稳健的偏好选择（RPS），这是一种后处理、无需重新训练的方法，通过利用方向局部共识。RPS不会强制模型生成来自单一、高度具体的偏好响应，而是从相关偏好的一小范围局部区域中抽样多个响应，创建一个更优的候选池。然后选择最符合用户原始意图的响应。我们提供了一个理论框架，证明了我们的局部区域生成策略在多种候选者抽样基础上是有严格优势的。全面的实验表明，RPS在三种不同的对齐范式（DPA、DPO和SFT）下都表现出比基线更优越的鲁棒性，即使在未进行模型重新训练的情况下，对于代表性不足区域的挑战性偏好，RPS也达成了高达69%的胜率。", "conclusion": "我们的工作提供了一种实用且理论上有支撑的解决方案，以增强偏好对齐模型的可靠性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20567", "html_url": "https://arxiv.org/abs/2510.20567", "title": "超越检索排序：面向电子商务搜索的多智能体认知决策框架", "title_en": "Beyond Retrieval-Ranking: A Multi-Agent Cognitive Decision Framework for E-Commerce Search", "authors": "Zhouwei Zhai,Mengxiang Chen,Haoyun Xia,Jin Li,Renquan Zhou,Min Yang", "background": "电子商务搜索历来主要采用检索-排序范式，但其依赖于查询-商品匹配，根本上与平台用户的多阶段认知决策过程不匹配。这种不匹配引入了关键限制：复杂查询中的语义差距、由于跨平台信息采集而导致的高决策成本以及缺乏专业的购物指导。", "innovation": "提出了一种多智能体认知决策框架（MACDF），从被动检索转向主动决策支持。通过离线评估发现MACDF在推荐准确性和用户满意度方面有显著改进，特别是对于涉及否定、多约束或推理需求的复杂查询。在线A/B测试在京东搜索平台中确认了其实际效果。", "conclusion": "这项工作突显了多智能体认知系统在重新定义电子商务搜索方面的变革潜力。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20610", "html_url": "https://arxiv.org/abs/2510.20610", "title": "BUSTED在AraGenEval共享任务中的表现：基于Transformer模型的阿拉伯语AI生成文本检测对比研究", "title_en": "BUSTED at AraGenEval Shared Task: A Comparative Study of Transformer-Based Models for Arabic AI-Generated Text Detection", "authors": "Ali Zain,Sareem Farooqui,Muhammad Rafi", "background": "本文介绍了BUSTED团队在阿拉伯语AI生成文本检测Ara-GenEval共享任务中的表现，获得了第五名。研究团队探索了三种预训练的变换器模型：AraELECTRA、CAMeLBERT和XLM-RoBERTa，并进行了微调。", "innovation": "研究采用了三种不同的预训练变换器模型并进行了微调，以进行二分类任务。其中，多语言的XLM-RoBERTa模型在F1分数上获得了最高成绩，达到了0.7701，优于专门的阿拉伯语模型。", "conclusion": "这项工作揭示了AI生成文本检测的复杂性，强调了多语言模型强大的泛化能力。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20584", "html_url": "https://arxiv.org/abs/2510.20584", "title": "ChatGPT在多项协作任务中的公平编码能力：来自实证证据", "title_en": "Can ChatGPT Code Communication Data Fairly?: Empirical Evidence from Multiple Collaborative Tasks", "authors": "Jiangang Hao,Wenju Cui,Patrick Kyllonen,Emily Kerzabi", "background": "评估大规模沟通与协作依赖于一项劳动密集型任务，即将沟通数据编码到不同框架的类别中。先前的研究表明，ChatGPT可以直接根据编码评分标准对沟通数据进行编码，并且其准确度可与人类评估者媲美。然而，ChatGPT或类似AI技术对不同性别和种族群体是否存在偏见，目前仍不清楚。本研究旨在通过使用典型的协作问题解决编码框架，探讨ChatGPT对沟通数据的自动编码在不同性别和种族群体之间的差异。", "innovation": "本研究利用ChatGPT基于特定编码框架自动编码沟通数据的方法，并通过多个协作任务（谈判、问题解决、决策制定）的数据分析其公平性。研究发现，ChatGPT编码在性别和种族群体间未表现出显著的偏见。", "conclusion": "ChatGPT编码在性别和种族群体间不存在显著偏见，这为其在大规模评估协作与沟通中的应用铺平了道路。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20543", "html_url": "https://arxiv.org/abs/2510.20543", "title": "The Dog the Cat Chased Stumped the Model: Measuring When Language Models Abandon Structure for Shortcuts", "title_en": "The Dog the Cat Chased Stumped the Model: Measuring When Language Models Abandon Structure for Shortcuts", "authors": "Sangmitra Madhusudan,Kaige Chen,Ali Emami", "background": "尽管大规模语言模型在基准测试中表现出色，但仍然缺乏区分结构性理解与语义模式匹配的方法。本文通过研究中心嵌套句法结构（如“The cat that the dog chased meowed”）来探讨这一问题，这些句子具有逐渐复杂的句法结构需求。此外，每个句子都有一个句法结构类似但语义不相符的对应句子（如“邮差开药，医生送信”），并包含六个测试问题，涉及表面理解、句法依赖性和因果推理。", "innovation": "文章引入了CenterBench数据集，包含9720个关于中心嵌套句子的理解问题。研究发现，模型在复杂句子上的表现差距随着复杂度系统性地扩大，模型的中位数差距最高达到26.8个百分点，证明了它们在复杂度增加时从结构分析转向语义关联。此外，研究还发现了模型在因果关系推理方面面临的挑战，表明部分模型依赖语义捷径而非因果推理。", "conclusion": "CenterBench提供的框架有助于识别模型何时从结构分析转向模式匹配，并指出即使在因果关系推理这种重要任务上，模型也可能依赖于语义捷径而非结构分析。研究还发现，尽管逻辑推理模型能够提高精度，但在某些情况下，它们仍可能依赖语义捷径做出错误判断。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20635", "html_url": "https://arxiv.org/abs/2510.20635", "title": "为何苹果会落地：评估大型语言模型中的好奇心", "title_en": "Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language Model", "authors": "Haoyu Wang,Sihang Jiang,Yuyan Chen,Yitong Wang,Yanghua Xiao", "background": "好奇心是人类发现和学习新知识的重要驱动力。最近，大型语言模型（LLMs）在自然语言处理方面的进展引发了关于这些模型是否具备类似于人类的好奇心驱动学习能力的讨论。为此，研究者以人类好奇心评估问卷再修订版五维度好奇心量表（5DCR）为出发点，设计了一个全面评估框架来评估LLMs的好奇心程度，涉及信息寻求、冒险寻求和社会好奇心等维度。研究发现，LLMs对知识的渴望远超人类，但在面对不确定性环境时往往倾向于保守的选择。为验证好奇心与LLMs思考之间的关系，研究进一步探讨了好奇心如何影响模型的推理和主动学习能力，发现好奇心可以提升模型的推理能力和主动学习能力。", "innovation": "本研究以5DCR为依据设计了一个全面的评估框架，旨在量化和评估LLMs在信息寻求、冒险寻求和社会好奇心等维度上的表现。研究发现LLMs在对新知识的渴望上超过了人类，在不熟悉的环境中表现出更保守的选择偏好。进一步的探索揭示了好奇心与LLMs思考之间的联系，表明好奇心能够增强模型的推理和主动学习能力。", "conclusion": "研究结果表明，LLMs具有与人类相似的好奇心的潜力，提供了一定的实验支持，有助于未来进一步探讨LLMs的学习能力和推进相关领域的创新能力。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20505", "html_url": "https://arxiv.org/abs/2510.20505", "title": "混合型问题回答的分层序列迭代", "title_en": "Hierarchical Sequence Iteration for Heterogeneous Question Answering", "authors": "Ruiyi Yang,Hao Xue,Imran Razzak,Hakim Hacid,Flora D. Salim", "background": "检索增强生成（RAG）在处理多步问题和异构证据来源时仍然脆弱，需要在准确性与延迟以及令牌/工具预算之间权衡。现有的方法尽管在某些方面有所改进，但仍然存在性能和效率上的局限性。", "innovation": "提出了一种统一框架，称为分层序列（HSEQ）迭代，该框架（i）将文档、表格和知识图谱线性化为具有轻量级结构标签的可逆分层序列，（ii）进行结构感知迭代，在生成最终答案之前收集足够的证据，且（iii）通过头代理和迭代代理进行协调与优化，确保在减轻冗余操作的同时保持准确性，具有执行效率高和广泛的适用性。此外，HSEQ还具有的三个关键优点：格式无关的统一性、指导下的预算感知迭代以及证据的标准化，提高了答案的一致性和可审计性。", "conclusion": "实验结果表明，HSEQ框架在HotpotQA（文本）、HybridQA/TAT-QA（表格+文本）和MetaQA（知识图谱）数据集上展现出了一致的EM/F1性能增益，同时保持了高效率，相比基于单步、多跳和智能体RAG基线具有显著优势。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20508", "html_url": "https://arxiv.org/abs/2510.20508", "title": "评估多语言LLM的政治公正性：基于21种平行EuroParl数据集的案例研究", "title_en": "Assessing the Political Fairness of Multilingual LLMs: A Case Study based on a 21-way Multiparallel EuroParl Dataset", "authors": "Paul Lerner,François Yvon", "background": "当前，大型语言模型（LLMs）的政治偏见通常通过模拟它们对英语问卷的回答来评估。然而，本研究提出了一个基于多语言翻译公平原则的新视角。通过对欧洲议会（EP）演讲进行系统的翻译质量比较，发现主流政党比外来政党有更高质量的翻译。这项研究得益于新建立的一个包含21种语言平行版本的EuroParl数据集，该数据集包含了每位演讲者的政治倾向。该数据集包含了1.5M句子，共计40M词和249M字符，覆盖了三年、1000多名演讲者、7个国家、12个欧盟政党、25个欧盟委员会以及数百个国家级政党.", "innovation": "本研究通过引入一个新的多语言平行EuroParl数据集，评估多语言LLM的政治公正性。数据集不仅包括多个语言版本，还包含每位演讲者的政治倾向，为评估LLMs的政治翻译偏见提供了新的方法。这种方法基于翻译公平原则，而不是传统的问卷调查方法，并首次采用了多语言平行数据进行系统性比较.", "conclusion": "研究发现主流政党演讲比外来政党有更高质量的翻译。基于此，研究提出了一种新的评估多语言LLM政治偏见的方法，揭示了现有模型在翻译政治内容时存在的潜在偏见。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20647", "html_url": "https://arxiv.org/abs/2510.20647", "title": "推理的语言：多语言AI的双刃剑", "title_en": "The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI", "authors": "Alan Saji,Raj Dabre,Anoop Kunchukuttan,Ratish Puduppully", "background": "大型推理模型（LRMs）在数学、科学和其他问答任务中表现出色，但它们的跨语言推理能力尚未得到全面探索。当面对非英语问题时，LRMs往往会默认使用英语进行推理，这引发了关于可解释性和处理语言和文化细微差别的担忧。", "innovation": "本文系统地比较了LRMs在英语推理与问题语言推理之间的表现差异。研究跨越了MGSM和GPQA Diamond两项任务。研究不仅衡量了答案的准确性，还分析了推理过程中的认知特征。研究发现英语推理痕迹展现出更高的认知行为出现频率，且在英语推理的情况下，最后的答案准确性普遍更高，特别是在任务复杂度增加时。然而，这种以英语为中心的策略容易出现“翻译迷失”的关键失败模式，即由于翻译步骤导致的错误，这些问题使用原语言推理时可以避免。", "conclusion": "英语推理痕迹中展现的认知行为更为频繁，英语推理通常能获得更高的答案准确性，但其高度依赖性使得模型在面对涉及语言和文化细微差别的复杂任务时容易出现翻译错误。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20548", "html_url": "https://arxiv.org/abs/2510.20548", "title": "GlobalRAG:通过强化学习增强多跳问答中的全局推理", "title_en": "GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering via Reinforcement Learning", "authors": "Jinchang Luo,Mingquan Cheng,Fan Wan,Ni Li,Xiaoling Xia,Shuangshuang Tian,Tingcheng Bian,Haiwei Wang,Haohuan Fu,Yan Tao", "background": "强化学习在检索增强生成（RAG）中的应用尽管取得了进展，但在多跳问答中的效果仍然受限于两个基本的限制：（i）缺乏全局规划来结构化多步推理，（ii）不忠实地执行，这妨碍了有效的查询构建和一致地使用检索证据。这些限制阻碍了RAG模型在多跳任务中的性能提升.", "innovation": "提出了一种名为GlobalRAG的新框架，它通过强化学习增强了多跳问答过程中的全局推理。GlobalRAG将问题分解为子目标，协调检索与推理，并通过迭代细化证据。此外引入了规划质量奖励和子目标完成奖励，以鼓励连贯的规划和可靠的子目标执行。采用渐进权重退火策略平衡了过程导向和结果导向的目标。实验结果表明，GlobalRAG在小规模训练数据（仅8k训练数据，占强力基线训练数据的42%）的情况下，显著优于强力基线，平均提升了EM和F1分数14.2%.", "conclusion": "GlobalRAG框架通过利用强化学习机制和上述创造性的奖励机制，克服了传统的RAG在多跳问答中的局限性，在小数据集上取得了卓越的效果。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20690", "html_url": "https://arxiv.org/abs/2510.20690", "title": "神经多样性在小型模型中规制幻觉", "title_en": "Neural Diversity Regularizes Hallucinations in Small Models", "authors": "Kushal Chakrabarti,Nirmal Balachundhar", "background": "语言模型尽管在参数量、计算资源和数据量上都有所增加，但仍会生成不切实际的预测输出。研究者们发现，这些模型中存在幻觉现象，并试图通过增加计算成本、参数量和数据量来减小这种现象，但效果有限。", "innovation": "本文提出了“神经多样性”——去相关的并行表示——作为一种减小幻觉概率的原理性机制，同时在固定参数和数据预算下不降级一般准确性。通过将并行LoRA适配器与Barlow Twins正则化相结合，验证了该方法的有效性。实验证明，神经多样性正则化可以将幻觉降低多达25.6%，平均降低14.6%。", "conclusion": "研究发现，不同的任务需要不同的神经多样性的最适量。因此，神经多样性是一种提升语言模型可靠性的第三个维度，与参数量和数据量相互独立，在固定预算下可以改善模型的可靠性。还证明了LoRA适配器和正则化通过协同作用减少幻觉的发生，并且神经多样性作为减少幻觉的关键因素。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20670", "html_url": "https://arxiv.org/abs/2510.20670", "title": "CantoNLU：一种粤语自然语言理解基准", "title_en": "\\textsc{CantoNLU}: A benchmark for Cantonese natural language understanding", "authors": "Junghyun Min,York Hay Ng,Sophia Chan,Helena Shunhua Zhao,En-Shiun Annie Lee", "background": "尽管粤语使用者众多，但由于政策和二语现象（diglossia）的影响，粤语资源仍然不足。缺乏粤语自然语言理解（NLU）评价框架的问题亟待解决，因此需要新的基准数据集来填补这一空白。现有的评价框架主要针对普通话，而现有基准数据集缺乏对粤语特定需求和特点的关注，无法满足多语种需求下的特定语言研究和开发。为了填补这一空白，引入了CantoNLU这一基准数据集，用于覆盖包括语义和语法在内的多种任务。", "innovation": "CantoNLU是一个全面覆盖了包括词汇意义消岐、语法正确性判断、语言检测、自然语言推理、情感分析、词性标注和依存句法分析等七个任务的粤语自然语言理解基准数据。此外，该数据集还提供了对不同模型（普通话模型、粤语适应模型和原始训练的单语粤语模型）的基准性能测试。结果表明，粤语适应模型整体表现最佳，而单语模型在句法任务上表现更好。普通话模型在某些情况下仍然具有竞争力，表明在粤语特定领域数据稀缺的情况下，直接迁移可能足够。", "conclusion": "该研究通过开发CantoNLU基准数据集，填补了针对粤语特定需求和特点的NLU评价框架空白。研究结果表明，已适应粤语的模型在该领域具有最强的性能，而从零开始训练的单语模型在句法任务上表现更好。普通话模型在特定情况下也显示出竞争力。这项研究将为未来的研究提供重要资源和指导，有助于推动粤语自然语言处理的发展。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20700", "html_url": "https://arxiv.org/abs/2510.20700", "title": "结构条件下的最小贝叶斯风险解码", "title_en": "Structure-Conditional Minimum Bayes Risk Decoding", "authors": "Bryan Eikema,Anna Rutkiewicz,Mario Giulianelli", "background": "最小贝叶斯风险(MBR)解码在机器翻译中表现出色，因为语言模型结果的空间变异性自然受限，但在更加开放的任务如对话或指令跟随中，它可能会面临挑战。MBR利用标准的基于相似性的效用函数可能仅仅选择能够广泛代表模型分布的响应，但对特定隐含结构的组群而言未必是最优的。因此，本文提出了针对MBR的三种轻量级适应，旨在使MBR对结果空间中结构性变异性更加敏感。", "innovation": "为了使得MBR更加关注结果空间的结构性变异性，作者提出了三种适应标准相似性效用函数的方法。为了验证假设，他们创建了一个包含三类代表性隐含结构的语料库：对话行为、情绪和响应结构。此外，他们还提出了两个衡量结构最优性的评价指标。结果显示，常用的基于相似性的效用函数在这个评价中表现不佳，而所提出的适应方法显著提高了结构最优性。另外，研究还在AlpacaEval和MT-Bench等真实世界指令跟随基准上评估了方法的效果，表明增加结构性敏感性可使生成质量提高13.7个百分点。", "conclusion": "通过这种结构条件下的MBR解码，研究发现增加对结果空间中结构性变异性检测能够提升生成质量。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20535", "html_url": "https://arxiv.org/abs/2510.20535", "title": "ARC-Encoder：大型语言模型中学习压缩文本表示", "title_en": "ARC-Encoder: learning compressed text representations for large language models", "authors": "Hippolyte Pilchen,Edouard Grave,Patrick Pérez", "background": "近年来，检索增强生成和链式思考推理等技术导致了更长的上下文和更高的推理成本。上下文压缩技术可以减少这些成本，但最有效的方法通常需要对目标模型进行微调，甚至修改其架构。这可能会在不用于特定目的的情况下削弱其通用能力。本文旨在探索一种替代方法：一个可以将上下文压缩成连续表示的编码器，这些连续表示将取代解码器LLM中的词嵌入。首先，我们系统研究了编码器的训练策略和架构选择。我们的发现促成了设计Adaptable文本表示压缩器（ARC-Encoder），它输出的连续表示通常少于文本标记的4到8倍。我们评估了ARC-Encoder在包括上下文学习和上下文窗口扩展在内的多种LLM使用场景中的性能，涵盖指令解码器和基础解码器。结果表明，ARC-Encoder在多个基准上达到了最先进的性能，同时提高了推理时的计算效率。最后，我们展示了我们的模型可以同时适应多个解码器，使得一个编码器可以在不同的LLM解码器之间普遍适用。这对于与多种LLM无缝兼容的便携式编码器来说是一项灵活且高效的解决方案。", "innovation": "本文提出了一种新方法，即通过一个编码器将上下文压缩为连续表示，这些表示可以替代解码器LLM中的词嵌入。通过系统研究训练策略和架构选择，设计出一种名为ARC-Encoder的Adaptable文本表示压缩器，该编码器输出的连续表示数量通常少于文本标记的4到8倍。评估结果表明，ARC-Encoder在计算效率方面有所提升，并且可以适应多种不同的解码器，这使得ARC-Encoder成为一个具有高度适应性和效率的解决方案。", "conclusion": "ARC-Encoder作为一种解决方案，能够在不牺牲模型能力的情况下减少上下文长度，从而提高计算效率。此外，它能够适应多种不同的解码器，使得编码器更具有通用性。我们在提供的链接中发布了训练代码，以及用于微调和预训练模型的资源。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20727", "html_url": "https://arxiv.org/abs/2510.20727", "title": "使用自然语言处理从临床笔记中自动提取氟尿嘧啶治疗及其相关毒性", "title_en": "Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing", "authors": "Xizhi Wu,Madeline S. Kreider,Philip E. Empey,Chenyu Li,Yanshan Wang", "background": "氟尿嘧啶类药物被广泛用于治疗结肠癌和乳腺癌，但它们会导致手足综合征和心脏毒性等副作用。这些副作用的记录通常嵌入在临床记录中，因此需要开发和评估自然语言处理（NLP）方法来提取治疗和毒性信息。本研究构建了一个包含204,165名成人肿瘤患者236份临床笔记的数据集，通过领域专家对其进行标注，以评估各种NLP方法的有效性，包括基于规则的方法、机器学习方法（随机森林、支持向量机、逻辑回归）、基于深度学习的方法（BERT、ClinicalBERT）以及基于大语言模型的方法（零样本和错误分析提示）.", "innovation": "研究开发并评估了多种NLP方法来自动从临床笔记中提取氟尿嘧啶治疗及其相关毒性信息。研究发现，基于大语言模型的方法在提取治疗和毒性信息方面表现最佳，其次是机器学习方法。研究结果表明，尽管机器学习和深度学习方法在小规模数据集上表现有限，且缺乏泛化能力，尤其是对于稀有类别，但基于大语言模型的方法能够更有效地支持肿瘤学研究和药物监测.", "conclusion": "基于大语言模型的NLP方法最有效地从临床笔记中提取了氟尿嘧啶治疗和毒性信息，并且在这种应用于肿瘤学研究和药物安全性监测方面具有强大的潜力."}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20780", "html_url": "https://arxiv.org/abs/2510.20780", "title": "大型推理模型作为翻译评估器的效果如何？分析与性能提升", "title_en": "Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost", "authors": "Runzhe Zhan,Zhihong Huang,Xinyi Yang,Lidia S. Chao,Min Yang,Derek F. Wong", "background": "大型推理模型（LRMs）最近的进步表明，在生成最终答案之前，它们通过引入一种中间“思考”过程来提高复杂下游任务的推理能力。然而，这些模型在机器翻译（MT）质量评估中的潜力尚未得到充分探索。", "innovation": "本研究首次系统分析了LRMs在MT评估中的使用情况，并指出了一些关键挑战，如需要定制化的评估材料、倾向于过度思考简单的实例以及在评分机制上存在问题导致过度估计。为此，研究提出了通过在合成的人类似思考轨迹上训练来校准LRM思考的方法。实验结果表明，这种方法可以将思考预算降低约35倍，同时在不同规模的LRM（从7B到32B）上提高了评估性能。", "conclusion": "这些发现表明，高效校准的LRMs有可能推动精细自动MT评估的发展。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20721", "html_url": "https://arxiv.org/abs/2510.20721", "title": "用户对隐私敏感情境下LLM响应中隐私保护与帮助感知的认知", "title_en": "User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios", "authors": "Xiaoyuan Wu,Roshni Kaushik,Wenkai Li,Lujo Bauer,Koichi Onoue", "background": "大型语言模型（LLMs）在诸如起草邮件、总结会议和回答健康问题等任务中得到迅速采用。在这种使用场景中，用户可能需要分享个人信息（如健康记录、联系方式）。为了评估LLMs识别和屏蔽这些私人信息的能力，已有研究开发了以现实场景为基础的基准测试（如ConfAIde、PrivacyLens）。研究发现，LLMs在处理复杂任务（例如在会议总结中泄露员工工资）时有时未能保护隐私。然而，这些评估依赖于LLMs（代理模型）来衡量与隐私标准的遵守情况，忽视了实际用户的看法。目前的研究主要集中在响应的隐私保护质量上，而未探索其在帮助性方面细微差异。因此，为了解用户对LLM在隐私敏感情境下响应的隐私保护质量和帮助性感知，作者进行了一项用户研究，包含94名参与者和90个来自PrivacyLens的场景。研究结果显示，在评估相同场景下相同的响应时，用户们在评价隐私保护质量和帮助性方面表现出很低的一致性。而五个代理模型之间显示了高度一致性，但每个单独的LLM与用户评价的相关性较低。这些结果表明，LLM响应的隐私性和帮助性往往是针对个人的，代理模型无法很好地预测实际用户在隐私敏感场景下的感知。研究建议，未来应开展以用户为中心的研究，评估LLMs帮助用户的同时保护隐私的能力。此外，未来研究可以帮助改进代理模型与用户的对齐程度，为更好地估计用户感知的隐私性和实用性提供支持。", "innovation": "本研究通过进行用户研究，不仅评估了LLM响应的隐私保护质量，还探索了其在帮助性方面的细微差异。研究发现了用户对LLM响应隐私保护质量和帮助性感知的低一致性，以及代理模型在预测这些感知方面的局限性。", "conclusion": "研究结果表明，LLM响应的隐私保护和帮助性往往是个体化的，依赖于代理模型的评估并不准确。未来的研究应当重视以用户为中心的评估方法，同时探索提高代理模型与用户感知之间的一致性方法，以更好地估计用户的隐私感知和实用性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20782", "html_url": "https://arxiv.org/abs/2510.20782", "title": "针对LLM生成文本负责任表现维度的特定用途数据集", "title_en": "A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text", "authors": "Alicia Sagae,Chia-Jung Lee,Sandeep Avula,Brandon Dang,Vanessa Murdock", "background": "当前评估大型语言模型（LLMs）的方法主要关注如文本生成等高层任务，并未专门为特定的AI应用场景而设计。然而，这种评估方法对于测试LLMs在公正性等负责任AI维度上的表现是不够的，因为不同应用场景中与保护属性高度相关的特征在其他场景中可能并不重要。", "innovation": "本文构建了一个由具体应用场景（从产品特征列表生成简洁文本描述）驱动的数据集，并将公平性属性与性别化形容词及产品类别参数化，形成一个丰富的标注提示集。通过数据，文章展示了如何识别LLMs在质量、真实性、安全性和公平性方面的差距，提出了一种与具体资源相结合的LLMs评估方案。", "conclusion": "研究通过提供一个具体的资源，推动了LLMs评估体系的发展，提出了如何在LLM生成的文本中测量负责任表现维度的方法。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20797", "html_url": "https://arxiv.org/abs/2510.20797", "title": "简单的上下文压缩：均值池化和多比例训练", "title_en": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training", "authors": "Yair Feldman,Yoav Artzi", "background": "在使用大语言模型（LLMs）进行检索增强生成（RAG）时，处理长上下文会产生高昂的计算成本。一种常见策略是软上下文压缩，即将输入序列转化为较短的连续表示。过去的实践中，广泛使用了一种压缩标记架构。本研究对这一领域进行了深入探究，旨在开发一种更轻便且简单的均值池化方法，并研究同一压缩器在输出多个压缩比例时的表现。实验涵盖了多个领域问题回答数据集、不同模型家族、不同规模以及不同压缩比例，以全面评估方法的表现和局限性。", "innovation": "提出了一种轻量级且简便的均值池化方法，并发现其在多压缩比例训练中始终优于现有的压缩标记架构。此外，研究还揭示了不同架构和训练策略之间的权衡更加复杂，说明了压缩方法的复杂性。", "conclusion": "简单均值池化方法在多个领域和不同规模的模型中表现出最强性能，即使在输出多个压缩比例时，性能下降也相对较小。然而，总体而言，不同架构和训练策略之间的权衡更为复杂，这体现了压缩方法的复杂性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20787", "html_url": "https://arxiv.org/abs/2510.20787", "title": "通过混合稀疏注意力和上下文可学习的token淘汰缓解线性注意力的健忘问题", "title_en": "Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention and Contextualized Learnable Token Eviction", "authors": "Mutian He,Philip N. Garner", "background": "线性注意力模型通过将整个输入序列压缩成固定大小的递归状态来替代Transformer，提供了一种高效的替代方案，但有限的内存导致了健忘现象，损害了 retrieval-intensive 任务的表现。为缓解这一问题，研究了一系列混合模型，通过恢复对过去token的直接访问来解决健忘的问题。这些模型在线性和全注意力之间具有中间的时间和空间复杂度，包括带有token淘汰的稀疏注意力和带有query的原生稀疏注意力。特别地，提出了一种新的可学习的token淘汰方法。结合滑动窗口注意力，一个端到端可训练的小型CNN聚合了来自过去和未来相邻token的信息，适应性地保留每个头内有限的关键KV对，同时保持线性注意力的常量时间和空间复杂度。为此提供高效的Trion内核以实现稀疏注意力机制的功能。实验结果支持了这种方法在retrieval-intensive基准测试中的有效性。", "innovation": "本文提出了一种新的可学习的token淘汰方法，并结合滑动窗口注意力机制来缓解线性注意力模型的健忘问题。新的模型通过保留关键的KV对，同时保持线性注意力的高效性，在retrieval-intensive任务上具有较好的性能。同时，该文还提供了高效的稀疏注意力机制的Trion内核实现。", "conclusion": "通过引入新的可学习的token淘汰方法和滑动窗口注意力机制，本文成功缓解了线性注意力模型的健忘问题，从而在retrieval-intensive任务上取得了较好的性能。同时，该研究也提供了高效的稀疏注意力机制的实现方法。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19838", "html_url": "https://arxiv.org/abs/2510.19838", "title": "Branch-and-Browse：基于树结构推理和动作记忆的高效可控网络探索", "title_en": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory", "authors": "Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury", "background": "自主网络代理由大型语言模型（LLMs）驱动，在执行目标导向任务（如信息检索、报告生成和在线交易）方面展现出强大的潜力。这些代理是开放网络环境中实用实体推理的关键步骤。然而，现有的方法在推理深度和效率方面仍然有限：简单的线性方法无法进行多步推理，缺乏有效的回溯功能；其他搜索策略则过于粗犷，计算成本高。", "innovation": "提出了一种名为Branch-and-Browse的细粒度网络代理框架，统一了结构化推理-执行、上下文记忆和高效执行。该框架实现了（i）分枝任务管理，通过树状探索进行可控的多分支推理；（ii）通过有效的网页状态回放与背景推理支持探索；（iii）利用页面动作记忆在会话内外分享已探索的动作。实验结果表明，Branch-and-Browse在WebArena基准测试中的任务成功率达到了35.8%，相对最先进的方法执行时间减少了40.4%，证明了它是一种可靠且高效的LLM基网络代理框架。", "conclusion": "Branch-and-Browse框架展示了其在LLM基网络代理领域的可靠性和效率，为开放网络环境下的实体推理提供了新的解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20810", "html_url": "https://arxiv.org/abs/2510.20810", "title": "关于LLM生成文本的可检测性：究竟什么是LLM生成的文本？", "title_en": "On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?", "authors": "Mingmeng Geng,Thierry Poibeau", "background": "随着大规模语言模型（LLMs）的广泛应用，许多研究人员开始关注如何检测这些模型生成的文本。然而，对于‘LLM生成的文本’并没有一个一致且精确的定义。使用场景的不同和LLMs的多样性进一步增加了检测的难度。通常认为作为检测对象的文本只代表了LLMs可能生成的一部分。人类对LLM输出的编辑以及LLMs对用户的微妙影响，模糊了LLM生成的文本与人类撰写的文本之间的界限。现有的基准测试和评估方法未能充分应对现实检测应用中的各种情况，导致检测器的数值结果经常被误解，其意义也在减弱。因此，在特定条件下，检测器仍然有用，但其结果应仅作为参考而非决定性指标。", "innovation": "研究指出了当前在检测LLM生成文本过程中存在的问题和局限性，包括缺乏一致定义、识别难度大、现有评估方法不充分等。研究强调了理解LLM生成文本及其检测结果的重要性，并指出在具体情境下检测器仍然有用，但其结果只能作为参考而非决定性依据。", "conclusion": "该研究揭示了识别LLM生成文本的复杂性和挑战，并建议在解释检测结果时应当谨慎，将其作为参考而非最终判断依据。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19995", "html_url": "https://arxiv.org/abs/2510.19995", "title": "从沟通到完成：智能多Agent沟通建模协作工作流", "title_en": "Communication to Completion: Modeling Collaborative Workflows with Intelligent Multi-Agent Communication", "authors": "Yiming Lu,Xun Wang,Simin Ma,Shujian Liu,Sathish Reddy Indurthi,Song Wang,Haoyun Deng,Fei Liu,Kaiqiang Song", "background": "在复杂任务的工作空间中需要多种沟通策略，但现有的多Agent语言模型系统缺乏针对任务导向沟通的系统框架。因此，需要一种能够提升任务完成效率并提高沟通效果的框架来弥补这一差距", "innovation": "引入了Communication to Completion (C2C) 模型，该模型通过（1）新的Alignment Factor (AF) 指标量化代理任务一致性，直接提升工作效率；以及（2）序列行动框架，结合了逐步执行与智能沟通决策，使代理可以根据成本做出沟通决策，从而动态提高任务理解度", "conclusion": "C2C框架在三种复杂程度的编码工作流中，团队规模从5到17个代理进行了评估，并且与无沟通和固定步骤对照组进行对比。结果显示，C2C减少了约40%的任务完成时间，同时沟通成本可以接受。C2C框架在标准配置下完成了所有任务，并且保持了规模效应下的有效性。该框架奠定了多Agent系统中衡量沟通效果的理论基础，并为复杂协作任务提供了一个实用框架。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19864", "html_url": "https://arxiv.org/abs/2510.19864", "title": "SODBench: 一种利用大规模语言模型进行工作表操作文档的方法", "title_en": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations", "authors": "Amila Indika,Igor Molybog", "background": "在商业、会计和金融领域，许多知识工作者使用电子表格。然而，缺乏系统化的电子表格文档方法阻碍了自动化、协作和知识转移，这可能造成关键机构知识的丢失。本文介绍了一种称为工作表操作文档（SOD）的任务，即从电子表格操作中生成人类可读的解释。已有许多研究利用大规模语言模型（LLMs）生成电子表格操作代码，但将这些代码翻译成自然语言以进行SOD的研究尚处于探索阶段。因此，该研究提出一个包含111个电子表格操作代码片段及其对应自然语言摘要的基准测试集，并使用BLEU、GLEU、ROUGE-L和METEOR等指标评估了五种LLMs。研究结果表明LLMs可以生成准确的电子表格文档，使SOD成为提高电子表格中的可重复性、可维护性和协作工作效率的关键一步，尽管仍存在一些需要解决的挑战。", "innovation": "本文提出了一种基准测试集，用于评估大规模语言模型生成工作表操作自然语言文档的能力，并首次通过大量指标评估了不同LLMs在该任务上的性能。", "conclusion": "大规模语言模型能够生成准确的电子表格文档，使得工作表操作文档（SOD）成为提高电子表格的可重复性、维护性和协作工作流的关键步骤，但仍存在一些挑战需要进一步解决。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20039", "html_url": "https://arxiv.org/abs/2510.20039", "title": "超越单向影响：多轮人-LLM互动中的双向意见动态", "title_en": "Beyond One-Way Influence: Bidirectional Opinion Dynamics in Multi-Turn Human-LLM Interactions", "authors": "Yuyang Jiang,Longjie Guo,Yuchen Wu,Aylin Caliskan,Tanu Mitra,Hua Shen", "background": "大语言模型（LLM）驱动的聊天机器人越来越被用于意见探索。先前的研究考察了LLM如何改变用户观点，但很少有研究探讨用户输入如何影响LLM的响应，以及这种双向影响如何在整个多轮对话中表现出来。本研究通过50个涉及争议话题的讨论，以及266名参与者在三种条件下的参与（静态声明，标准聊天机器人，个性化聊天机器人）来探讨这一动态过程。", "innovation": "本研究创新之处在于，通过实证研究探讨了用户与LLM之间的双向互动如何影响他们的观点发生变化，特别是在多轮对话中。研究发现，高度个性化不仅能影响用户的输入，也能显著改变LLM的输出，从而减少人与机器人的立场差距。", "conclusion": "研究强调了人在与LLM互动时存在过度对齐的风险，并指出了精心设计个性化聊天机器人的重要性，以更深入、更稳定地与用户对齐。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20095", "html_url": "https://arxiv.org/abs/2510.20095", "title": "BIOCAP：将合成描述性标题用于生物学基础模型", "title_en": "BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models", "authors": "Ziheng Zhang,Xinyue Ma,Arpita Chowdhury,Elizabeth G. Campolongo,Matthew J. Thompson,Net Zhang,Samuel Stevens,Hilmar Lapp,Tanya Berger-Wolf,Yu Su,Wei-Lun Chao,Jianyang Gu", "background": "本文探究了描述性标题作为生物多模态基础模型额外监督来源的可能性。图像和描述性标题可以被视为从物种潜在形态空间中获得的互补样本，各自捕捉了具体的生物特征。将描述性标题纳入训练能促进与这一共享潜在结构的对齐，强调可能具有诊断价值的特征，同时抑制伪相关。然而，这一方法的主要挑战在于大规模获取忠实且特定实例的描述性标题。这限制了自然语言监督在有机生物学中的应用，相比之下，在许多其他科学领域中更加广泛。", "innovation": "本文通过使用多模态大型语言模型（MLLMs）生成合成描述性标题，这些标题由维基百科衍生的视觉信息和种属定制格式示例引导，从而填补了该领域的空白。这种特定领域的背景有助于降低幻觉，产生精确的基于实例的描述性标题。利用这些标题，本文训练了BIOCAP（即BIOCLIP带标题），这是一种能够捕捉丰富语义并在物种分类和图文检索方面表现优异的生物基础模型。", "conclusion": "这些结果表明，描述性标题在标签之外对于将生物学图像与多模态基础模型连接起来具有重要价值。BIOCAP能够提升多模态基础模型在生物学分类和检索任务中的表现，展示了描述性标题作为一种有效监督来源的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20099", "html_url": "https://arxiv.org/abs/2510.20099", "title": "AI PB：个人投资见解的接地生成代理", "title_en": "AI PB: A Grounded Generative Agent for Personalized Investment Insights", "authors": "Daewoo Park,Suho Park,Inseok Hong,Hanwool Lee,Junkyu Park,Sangjun Lee,Jeongman An,Hyunbin Loh", "background": "本文介绍了AI PB，这是一种在实际零售金融领域部署的生成代理系统。与被动回应查询的反应式聊天机器人不同，AI PB能够主动生成具体、合规且用户特定的投资见解。该系统结合了规模化和安全性的考虑，确保符合韩国金融监管要求。它部署在本地，并利用了Docker Swarm和vLLM等技术来支持多个NVIDIA H100 GPU的运行。", "innovation": "AI PB创新了以下几个方面：1) 基于数据敏感性的组件式编排层，能够决定性地选择内部或外部的LLM；2) 一种结合了开源搜索和金融领域嵌入式模型的混合检索管道；3) 含有多阶段推荐机制，结合了规则启发法、序列行为建模及上下文bandits等技术。这种方法不仅增强了系统的安全性，还确保了生成的内容既符合监管要求又具有针对性。", "conclusion": "通过人工审核和系统性能指标，我们展示了通过明确的路由和分层的安全策略，能在高风险的金融环境中实现可信赖的AI见解生成。AI PB提供了一种独特的解决方案，其能够适应金融市场的复杂性和敏感性，同时也标志着生成式AI技术在实际应用中的重要进步。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20075", "html_url": "https://arxiv.org/abs/2510.20075", "title": "LLMs can hide text in other text of the same length.ipynb", "title_en": "LLMs can hide text in other text of the same length.ipynb", "authors": "Antonio Norelli,Michael Bronstein", "background": "随着大型语言模型（LLM）的发展，一篇有意义的文本可以隐藏在另一篇完全不同的但仍然连贯和可信的文本中，两者长度相同。例如，一篇严厉的政治批评推文可以嵌入一篇庆祝同一位政治领导人的推文之中，或者一篇普通的商品评价可能包含一份秘密的手稿。这种奇特的状况得益于大型语言模型的存在，为此论文提出了一种简单且高效的协议来实现这一目标。研究表明，即使是开源的、只有80亿参数的LLM也能获得高质量的结果，而且一段如此长的消息可以在笔记本电脑上快速地进行编码和解码。这一协议的存在表明文本与作者意图之间存在着极大的脱耦，进一步动摇了人们对书面沟通的信任，这种信任已经在大型语言模型聊天机器人的崛起下被削弱了。", "innovation": "该论文提出了一种简单的协议，利用大型语言模型将一段有意义的文本嵌入到另一段表面上不同的文本中，两者长度相同。即使使用仅为80亿参数的开源大型语言模型，也可以实现高质量的嵌入效果。这种嵌入可以在笔记本电脑上迅速完成，显示出大型语言模型在理解和生成文本方面的巨大灵活性和能力。这一创新挑战了人们对于大型语言模型是否真“知道”某些信息的理解，也促使其在安全性方面亟待研究。", "conclusion": "这种新技术展示了文本与作者意图之间的巨大脱耦，极大地削弱了人们对书面信息的信任。例如，一个公司可以秘密部署一个未经滤镜的大型语言模型，通过将其实际答案包含在安全模型的合规回复中来实现。这一可能性引发了关于AI安全性的急迫问题，挑战了我们对“大型语言模型是否知道”某些信息的理解。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20187", "html_url": "https://arxiv.org/abs/2510.20187", "title": "每个问题都有其自身的价值：显式的人类价值观强化学习", "title_en": "Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values", "authors": "Dian Yu,Yulai Zhao,Kishan Panaganti,Linfeng Song,Haitao Mi,Dong Yu", "background": "尽管验证奖励强化学习（RLVR）在目标领域有效训练模型并使用二元正确性奖励，但该方法并未考虑到并非所有任务具有相同的重要性。该研究旨在通过直接引入人类定义的价值信号来改进这一框架，从而让大型语言模型（LLM）的优化直接与可量化的人类价值信号相匹配。使用带有明确的ground-truth价值标签的考试数据，该方法在多个RL算法和模型规模中均优于仅依赖正确性标准的基准方法。", "innovation": "该研究提出了一种方法——显式人类价值观强化学习（RLEV），它直接将人类定义的价值信号纳入奖励函数，以弥补RLVR在处理任务重要性方面的不足。RLEV不仅改善了价值加权的准确性，还学会了价值观敏感的终止策略：对于低价值提示简洁处理，对于高价值提示则详尽处理。研究还发现，这种行为源于在序列末尾符号上的价值加权梯度放大。", "conclusion": "该方法在嘈杂的价值信号（如基于难度的标签）下仍表现出鲁棒性，证明了优化显式性的效用功能为实现与人类优先事项相一致的大语言模型提供了一条实用途径。进一步的消融研究表明，这种增益与价值对齐有因果联系。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20377", "html_url": "https://arxiv.org/abs/2510.20377", "title": "IKnow: 了解导向的持续预训练以实现有效的领域适应", "title_en": "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation", "authors": "Tianyi Zhang,Florian Mai,Lucie Flek", "background": "持续预训练旨在使用未标记的测试数据来适应大型语言模型到新的领域，但直接在指令调整后的模型中应用标准自我监督的目标会导致模型的指令遵循能力和语义表示下降。现有解决方案要么依赖原始基础模型或外部领域特定数据库中的知识，这些都存在现实障碍。", "innovation": "本文提出了了解导向的持续适应（IKnow）框架，该框架通过在指令-响应对话格式中提出全新的自我监督目标，解决了依赖外部资源的问题。IKnow 利用了文本内部嵌入的领域知识，并学会在其更深层次的语义层次上对其编码。", "conclusion": "IKnow 为有效领域适应提供了一个简单且通用的框架，避免了依赖外部资源的问题，通过在指令-响应对话格式中嵌入领域知识，改善了模型的指令遵循能力和语义表示。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20270", "html_url": "https://arxiv.org/abs/2510.20270", "title": "ImpossibleBench：评估大语言模型利用测试案例倾向的框架", "title_en": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases", "authors": "Ziqian Zhong,Aditi Raghunathan,Nicholas Carlini", "background": "大语言模型（LLMs）在完成任务时倾向于寻找并利用‘捷径’，这种行为对可靠评估和部署大语言模型带来了显著风险。例如，能够访问单元测试的大语言模型可能会删除失败的测试，而不是修复根本的错误。这种行为不仅削弱了基准测试结果的有效性，还影响了实际部署的代码助手功能的可靠性。", "innovation": "研究团队提出了ImpossibleBench，一种基准框架，系统性地测量大语言模型利用测试案例的倾向。该框架通过在现有基准测试如LiveCodeBench和SWE-bench中引入自然语言说明与单元测试之间的直接冲突，生成“不可能”的任务变体。评估模型通过这些任务的通过率来衡量其“作弊率”，任何一次通过都意味着违反了规范的捷径。", "conclusion": "ImpossibleBench不仅作为评估工具，还是一种多功能工具，用于研究模型行为、展示上下文工程对作弊率的影响，并开发监控工具。我们希望ImpossibleBench能成为构建更稳健和可靠的LLM系统的基础框架。有关实现的代码可以在此找到: <this https URL>。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20387", "html_url": "https://arxiv.org/abs/2510.20387", "title": "神经语言模型的基于相对概率的扩展定律", "title_en": "Relative-Based Scaling Law for Neural Language Models", "authors": "Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu", "background": "扩展定律旨在准确预测不同规模下的模型性能。现有研究几乎完全依赖于交叉熵作为评估指标。然而，交叉熵仅提供性能的部分信息：它衡量正确词汇被准确归类的概率，但忽略了正确词汇与错误词汇之间的相对顺序。而相对顺序对于语言模型至关重要，特别是在贪婪采样情况下。", "innovation": "研究者提出了一种新的相对概率度量（Relative-Based Probability, RBP），量化正确词汇被预测认为是顶级预测之一的概率。基于该度量，建立了相对概率扩展定律，描述了RBP随模型规模增加的变化规律。通过在四个数据集和四个模型家族上的广泛实验，证明了此定律的稳健性和准确性。", "conclusion": "相对概率扩展定律补充了交叉熵视角，有助于更全面地理解大规模语言模型的扩展。它为实际开发和理论探索提供了宝贵的见解。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20256", "html_url": "https://arxiv.org/abs/2510.20256", "title": "Calibrating Multimodal Consensus for Emotion Recognition", "title_en": "Calibrating Multimodal Consensus for Emotion Recognition", "authors": "Guowei Zhong,Junjie Li,Huaiyu Zhu,Ruohong Huan,Yun Pan", "background": "近年来，多模态情感识别（MER）取得了显著进步。然而，现有的大多数方法忽略了不同模态间可能出现的语义不一致，如文本和视觉输入之间的情感线索冲突。另外，由于文本模态的强大表示能力，当前的方法往往过于依赖文本模态，这可能会损害识别准确性。", "innovation": "本文提出了一种称为校准多模态共识（CMC）的模型。CMC引入了一个伪标签生成模块（PLGM），用于生成伪单模标签，从而以自监督方式进行单模预训练。它还使用了一个参数自由融合模块（PFM）和一个多模态共识路由器（MCR），以实现多模态微调，从而减轻文本主导性，并引导融合过程向更可靠的共识方向发展。", "conclusion": "实验结果表明，CMC在四个数据集中（CH-SIMS，CH-SIMS v2，CMU-MOSI和CMU-MOSEI）的性能与现有最先进方法持平或优于后者。特别地，在CH-SIMS和CH-SIMS v2等语义不一致场景下，CMC具有显著优势。已经公开了这项工作的实现，地址为：this https URL"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20603", "html_url": "https://arxiv.org/abs/2510.20603", "title": "什么是大型语言模型中良好的推理？用多方面评估分解推理步骤", "title_en": "What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation", "authors": "Heejin Do,Jaehui Hwang,Dongyoon Han,Seong Joon Oh,Sangdoo Yun", "background": "目前，评估大型语言模型（LLMs）的最终答案正确性是主流方法。这种方法提供了一个粗略的改进信号，并且忽略了底层推理质量。本文作者认为，通过更细化地评估推理，可以找到构建稳健模型的有效路径。将推理质量分解为相关性和连贯性两个维度进行评估。相关性衡量步骤是否基于问题；连贯性衡量其是否逻辑地继前一步骤之后。为了可靠地衡量这些方面，作者提出了因果步骤评估（CaSE）方法，该方法仅使用前序上下文来评估每个推理步骤，从而避免了事后偏见。", "innovation": "作者提出了一种因果步骤评估（CaSE）方法，以可靠地衡量推理的质量。同时，通过在新的专家标注基准数据集MRa-GSM8K和MRa-MATH上验证CaSE，作者展示了使用CaSE评估的相关性和连贯性指标对训练数据进行筛选可以提高最终任务性能。这表明，多方面评估推理步骤对于模型改进具有实用价值。", "conclusion": "本文为分析、调试和提高LLM推理提供了一个可扩展的框架，证明了超越正确性检查的实践价值。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20513", "html_url": "https://arxiv.org/abs/2510.20513", "title": "解码耳朵：一种通过高效对齐将人类偏好转化为客观标识的表达性框架", "title_en": "Decoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment", "authors": "Zhiyu Lin,Jingwen Yang,Jiale Zhao,Meng Liu,Sunzhu Li,Benyou Wang", "background": "近期的语音到语音（S2S）模型在生成清晰语音方面表现良好，但在自然表达方面仍有不足。主要原因是缺乏可靠评价标准。现有方法如主观MOS评分、低级声学特征和情感识别成本高、效果有限或不完整。因此，作者提出了解EAR（Decoding the Expressive Preference of eAR）框架，该框架将人类对语音表达性的偏好转化为客观评分，通过这种框架可以在语音的三个维度：情感、语调和自发性上进行评价，表现出与人类感知的强烈一致性（斯皮尔曼等级相关系数，SRCC = 0.86），且仅需少于500个标注样本。", "innovation": "提出了一种将人类对语音表达性的偏好转化为客观评分的框架，称为DeEAR，该框架基于语音学和心理学，能够在表达性的三个维度上进行评价，且只需较少的标注样本数。该框架不仅提供了一种可靠的评价方式，还支持公平的基准测试和针对数据进行选择性的整理，它能够区分S2S模型在表达性方面的差距，并选择14000条具有表达性的语音片段形成ExpressiveSpeech数据库，显著提升了S2S模型在表达性方面的评分（从2.0提高到23.4分）。", "conclusion": "DeEAR框架不仅实现了语音表达性的客观评价，还提高了S2S模型在表达性方面的表现，并支持进一步的研究和应用。该框架的实现为研究者提供了一个有力的评价工具，有助于改善S2S模型在自然表达性上的表现，并促进了语音识别和语音合成领域的技术进步。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20229", "html_url": "https://arxiv.org/abs/2510.20229", "title": "为什么大视觉语言模型在较长回答中更容易产生幻觉：上下文的作用", "title_en": "Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context", "authors": "Ge Zheng,Jiaye Qian,Jiajin Tang,Sibei Yang", "background": "大型视觉语言模型(LVLMs)近年来取得了显著进展，但在生成较长、自由形式的响应时也容易出现幻觉问题，通常归因于不确定性积累。已有研究表明，幻觉问题不仅由长度引起，还与更依赖上下文以确保连贯性和完整性有关。", "innovation": "本文提出了一个新颖的“诱导-检测-抑制”框架，通过故意设计的语境主动诱导幻觉，利用诱导出的实例早期检测高风险情况，并在实际解码过程中抑制潜在的对象级幻觉。该方法在所有基准测试中实现了持续且显著的改进，证明了其有效性，并重新验证了上下文在幻觉生成过程中的作用。该研究不仅提高了性能，还提供了新的见解，并在深入探讨LVLMs较长响应中的幻觉方面迈出了第一步。", "conclusion": "研究结果不仅验证了框架的有效性，更重要的是重新验证了以前关于上下文的假设。该研究旨在提供新的见解，并为进一步深入探索LVLMs较长响应中的幻觉奠定了基础。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20193", "html_url": "https://arxiv.org/abs/2510.20193", "title": "具有多媒体意识的问答：检索和跨模态推理架构的综述", "title_en": "Multimedia-Aware Question Answering: A Review of Retrieval and Cross-Modal Reasoning Architectures", "authors": "Rahul Raja,Arpita Vats", "background": "传统问答系统依赖于结构化文本数据，但多媒体内容（图像、音频、视频和结构化元数据）的快速增长引发了新的挑战和机会。这些新数据形式使检索增强式问答系统的设计变得更加复杂。文献综述聚焦于如何集成多媒体检索管道，特别是如何使视觉、语言和音频的模态与用户查询相匹配的架构设计。研究者还基于检索方法、融合技术以及答案生成策略对方法进行了分类，并评估了不同基准数据集和评价准则下的性能，分析了在应对跨模态对齐、延迟-准确率权衡和语义grounding等问题时的挑战。", "innovation": "本研究涵盖了结合多媒体检索管道和用户查询的架构设计，并详细梳理了检索方法、融合技术和答案生成策略，强调了跨模态对齐、延迟-准确率权衡及语义grounding等关键挑战，并对未来研究方向和开放问题进行了总结。这提供了有关如何使用多媒体数据构建更具鲁棒性和上下文意识的问答系统的见解。", "conclusion": "本文综述了近年来结合检索与跨模态推理的问答系统，研究了有效利用多媒体数据以更好地解决挑战的途径。尽管当前的研究已取得了一些进展，但跨模态对齐、延迟-准确率权衡和语义grounding等问题仍是亟待解决的工程挑战，未来仍需进行更多的研究以改进这些问题。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20674", "html_url": "https://arxiv.org/abs/2510.20674", "title": "Tredence_AICOE队伍的E-commerce产品搜索竞赛技术报告", "title_en": "Analyticup E-commerce Product Search Competition Technical Report from Team Tredence_AICOE", "authors": "Rakshith R,Shubham Sharma,Mohammed Sameer Khan,Ankush Chopra", "background": "该研究介绍了Tredence_AICOE团队开发的多语言电子商务搜索系统。竞赛包括两个多语言相关任务：查询-类别 (QC) 相关性，评估用户的搜索查询与产品类别的匹配程度；查询-项 (QI) 相关性，衡量多语言搜索查询与单品列表的匹配度。为了确保覆盖所有语言，研究对现有数据集进行翻译，填补开发数据集中缺失的语言，从而在所有目标语言上进行训练。", "innovation": "研究采用了数据增强方法，通过翻译现有数据集补充目标语言不足，同时也针对不同任务优化了模型的微调策略。特别是在模型微调时采用了多种策略，Gemma-3 12B (4-bit) 模型在 QC 任务中表现最好，而在 QI 任务中使用原始数据、翻译数据和少数类数据创造策略则表现最优。这项研究最终在公开测试集上获得了0.8857的平均F1分，并在竞赛最终排行榜上取得了第4名的成绩。", "conclusion": "通过多语言数据增强和高效的模型微调策略，该团队成功开发出了一个能有效处理多语言查询的电子商务搜索系统，并在实际竞赛中取得了不错的成绩。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20743", "html_url": "https://arxiv.org/abs/2510.20743", "title": "Empathic Prompting: 非言语上下文集成的多模态LLM对话", "title_en": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM Conversations", "authors": "Lorenzo Stacchio,Andrea Ubaldi,Alessandro Galdelli,Maurizio Mauri,Emanuele Frontoni,Andrea Gaggioli", "background": "当前，大型语言模型（LLM）对话主要依赖于文本输入，不包含用户的情感和非言语上下文信息。这导致对话过程中缺乏情感共鸣，可能影响对话的连贯性和自然度。因此，研究者们致力于开发能够集成非言语上下文的多模态人机交互系统。", "innovation": "提出了Empathic Prompting框架，这是一种新颖的多模态人机交互体系，通过集成一个商用面部表情识别服务，捕捉用户的情感线索并将其嵌入到对话中作为上下文信号。这个体系无需用户显式控制，而是在不影响用户体验的前提下增强文本输入中的情感信息。该系统架构模块化且可扩展，支持加入其他非言语模块。", "conclusion": "该研究通过运行DeepSeek本地实例描述了系统设计，并进行了初步服务和可用性评估，结果显示非言语输入能够被一致地整合进LLM输出，且参与者普遍注意到对话流的提高。Empathic Prompting框架在聊天机器人通讯领域，特别是在医疗健康和教育等类别的应用可以发挥重要作用，因为这些领域中的情感信号对于交流至关重要，但往往在言语交流中不透明。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20792", "html_url": "https://arxiv.org/abs/2510.20792", "title": "BadGraph: 一种针对文本导向图生成的隐秘后门攻击", "title_en": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation", "authors": "Liang Ye,Shengqin Chen,Jiazhu Dai", "background": "图生成技术的快速发展引发了新的安全担忧，特别是后门漏洞问题。尽管已有研究探索了图像扩散和无条件图生成中的后门攻击，但文本导向的条件图生成仍然未被广泛研究。", "innovation": "本文提出了一种名为BadGraph的后门攻击方法，专门针对文本导向图生成中的潜在扩散模型。BadGraph利用文本触发器污染训练数据，秘密植入后门，在推理时当触发器出现时会诱导攻击者指定的子图，同时在干净输入上保持正常的性能。广泛的实验展示了攻击的有效性和隐蔽性：不到10%的污染率可以实现50%的攻击成功率，24%的污染率足以实现超过80%的成功率，且对良性样本的性能影响微乎其微。消融研究进一步揭示后门是在VAE和扩散训练中植入，而非预训练。", "conclusion": "这项研究揭示了文本导向图生成中潜在扩散模型的安全漏洞，强调了此类扩散模型在药物发现等应用中的严重风险，并突显需要针对这类扩散模型的后门攻击采取稳健的防御措施。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20809", "html_url": "https://arxiv.org/abs/2510.20809", "title": "AI 和机器人及其更广泛的领域中的真实深入研究", "title_en": "Real Deep Research for AI, Robotics and Beyond", "authors": "Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang", "background": "随着人工智能（AI）和机器人技术研究的迅速增长，每年产生超过10,000篇论文，研究人员难以跟上最新进展。快节奏的发展趋势、跨学科工作的增加以及探索超出个人专长领域的需求都使得这一挑战越来越大。", "innovation": "本文提出了一种通用的流水线，能够系统地分析任何研究领域：识别新兴趋势、发现跨领域的机遇，并为新的探索提供具体的起点。该框架应用于AI和机器人领域，特别是基础模型和机器人技术的进步。", "conclusion": "我们希望这项工作能够为从事AI及相关领域的研究人员提供有益的指导。附录中提供了每个分析主题的详细结果。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20800", "html_url": "https://arxiv.org/abs/2510.20800", "title": "如何高效压缩：使用100份样本的单步梯度实现LLM的快速适应", "title_en": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "authors": "Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus", "background": "最近，Sharma等提出了一种称为Layer-SElective-Rank reduction (LASER)的方法，表明通过精心挑选的LLM权重矩阵的高阶组件剪枝，可以在不进行基于梯度的微调的情况下增强下游任务的准确性。然而，LASER的方法涉及对每个矩阵进行耗时的全集前向传递搜索，使其不适用于快速部署。", "innovation": "本文展示了如何移除这种计算开销，发现：(i) 只需检查一小部分精心挑选的矩阵，无需逐层扫描，(ii) 每个矩阵奇异值的梯度可以确定哪些矩阵需要减少，(iii) 允许矩阵行围绕多个子空间聚类，并逐个分解每个聚类以扩大因子分解搜索空间，进一步减少了对原始训练数据的过拟合并进一步提高了24.6个百分点的准确性，(iv) 评估仅需对100份样本而非全部训练数据进行计算指示性梯度和测量最终准确性即可减小搜索时间。", "conclusion": "综上所述，结合这些发现，我们展示了一种无需微调的快速且稳健的下游任务适配算法。结果表明，只需沿100个示例进行一次梯度步骤，对候选层和分解技术的快速扫描即可使LLM适应新的数据集。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20728", "html_url": "https://arxiv.org/abs/2510.20728", "title": "通过多智能体系统设计具有纵向对角门的量子码", "title_en": "Co-Designing Quantum Codes with Transversal Diagonal Gates via Multi-Agent Systems", "authors": "Xi He,Sirui Lu,Bei Zeng", "background": "论文介绍了一种结合人类在环的多智能体工作流，该工作流用于共同设计带有指定纵向对角门的量子码。这项工作建立在Subset-Sum线性规划（SSLP）框架之上（arXiv:2504.20847），该框架通过小线性规划超图将基字符串按模算术残差进行分区，并通过$Z$-边缘Knill-Laflamme（KL）等式强制这些分区满足等式。该工作流以GPT-5为动力，并在TeXRA（一个支持迭代工具使用循环智能体和推导然后编辑推理智能体的多智能体研究助手平台）中实现。研究者在一个LaTeX-Python环境中合作，通过智能体进行推理、编辑、执行代码和同步工作到Git/Overleaf，以求统一所有角色的工作流程，为不同层次的研究提供全面支持。", "innovation": "论文展示了一种新型的工作流方法，通过多智能体系统合作设计量子码，并引入了Subset-Sum线性规划框架（SSLP）来解决纵向对角门问题。在这个框架中，基础字符串通过模算术残差进行分区，并通过小线性规划模型强制$Z$-边缘Knill-Laflamme等式成立。此外，研究者还展示了新的$((6,4,2))$码来实现纵向可控相位门$diag(1,1,1,i)$，这表明SSLP模型能够处理模值退化的情况。这种方法不仅实现了量子码的系统化构建，还通过精确建模支持了更高级和更大的量子码的扩展，推动了数据驱动的量子码分类研究的发展。", "conclusion": "该工作流将对角和纵向的一致性问题重新定义为一个大规模分析管道，结合了系统枚举和精确分析的重构。通过这个方法，研究人员能够生成可复现的量子码构造，并支持有针对性的扩展到更大的量子码及更高的距离。这为未来基于数据的量子码分类分类研究奠定了基础。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.12879", "html_url": "https://arxiv.org/abs/2404.12879", "title": "在知识密集型检索增强生成中的多视角洞察解锁", "title_en": "Unlocking Multi-View Insights in Knowledge-Dense Retrieval-Augmented Generation", "authors": "Guanhua Chen,Wenhan Yu,Xiao Lu,Xiao Zhang,Erli Meng,Lei Sha", "background": "检索增强生成（RAG）在大型语言模型（LLMs）的应用中起着关键作用，但在法律和医学等知识密集型领域中，现有的检索方法依然缺乏多视角的观点，这对于提高可解释性和可靠性至关重要。以往关于多视角检索的研究主要集中在不同语义形式的查询上，忽略了特定领域知识视角的表达。", "innovation": "本文提出了一种专门为知识密集型领域定制的新型多视角RAG框架（MVRAG），利用来自多个领域视角的意图感知查询重构来增强检索精度，从而提高最终推理的有效性。实验结果表明，该框架在法律和医学案例检索中显著提高了召回率和精确率。", "conclusion": "该多视角检索方法释放了多视角信息在RAG任务中的潜力，加速了大型语言模型在知识密集领域的进一步应用。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.17716", "html_url": "https://arxiv.org/abs/2406.17716", "title": "用于越南语对抗自然语言推理的新基准数据集和混合专家语言模型", "title_en": "A New Benchmark Dataset and Mixture-of-Experts Language Models for Adversarial Natural Language Inference in Vietnamese", "authors": "Tin Van Huynh,Kiet Van Nguyen,Ngan Luu-Thuy Nguyen", "background": "现有的越南语自然语言推理（NLI）数据集缺乏对抗复杂性，限制了其在评估模型对挑战性语言现象的鲁棒性方面的能力。", "innovation": "介绍了ViANLI，这是第一个越南语对抗NLI数据集，并提出了一种混合专家模型NLIMoE来应对其复杂性。该模型通过共享变压器编码器和学习动态路由机制集成专家子网络。ViANLI数据集在其他基准越南语NLI数据集上进行了训练，包括ViNLI、VLSP2021-NLI和VnNewsNLI。", "conclusion": "ViANLI为增强对模型鲁棒性的研究和丰富未来越南语和多语言NLI资源的研究提供了资源。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20812", "html_url": "https://arxiv.org/abs/2510.20812", "title": "小草案，大裁决：通过设想实现密集信息视觉推理", "title_en": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation", "authors": "Yuhan Liu,Lianhui Qin,Shengjie Wang", "background": "大视觉-语言模型（VLMs）在多模态理解方面取得了显著进展，但在处理包含密集文本注释与细粒度图形元素交织的信息密集型图像时，难以进行推理。主要挑战包括在密集布局中精确定位关键线索以及进行多跳推理以整合分散的证据。目前的方法在这方面表现出局限性。", "innovation": "本文提出了Speculative Verdict（SV）框架，这是一种无需训练的框架，借鉴了推测性解码的思想，结合了多个轻量级草案专家和一个大型裁决模型。草案阶段，小型VLM们作为草案专家生成多种推理路径，提供多样化的定位候选；裁决阶段，强大的VLM整合这些路径以产生最终答案。为了进一步提高效率和准确性，SV引入了一种共识专家选择机制，仅向前传递高度一致的推理路径。通过从多个部分准确的推理路径中合成正确的见解，SV不仅实现了错误校正，还实现了成本效益。", "conclusion": "在挑战性信息密集型和高分辨率视觉问答基准测试（包括InfographicVQA、ChartMuseum、ChartQAPro和HR-Bench 4K）上，SV实现了持续改进。此外，通过合成多个部分正确推理路径的正确见解，SV在错误校正和成本效益方面优于大型专有模型或训练管道。代码可在此处访问：[this https URL](this https URL)"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.14144", "html_url": "https://arxiv.org/abs/2406.14144", "title": "通过安全神经元的机械视角理解安全对齐", "title_en": "Towards Understanding Safety Alignment: A Mechanistic Perspective from Safety Neurons", "authors": "Jianhui Chen,Xiaozhi Wang,Zijun Yao,Yushi Bai,Lei Hou,Juanzi Li", "background": "大语言模型（LLMs）在各种能力上表现出色，但存在安全风险，例如生成有害内容和错误信息，即使经过安全对齐后仍然存在这些问题。本研究旨在通过机制可解释性来探索安全对齐的内部机制，关注识别并分析对安全行为负责的安全神经元。", "innovation": "提出了在推理时使用激活对比来定位这些神经元，并使用动态激活补丁来评估它们对模型安全性的因果影响。实验表明，可以稳定地识别大约5%的安全神经元，并通过仅修补它们的激活即可恢复超过90%的安全性能，而不会影响通用能力。研究还揭示了安全和有用性的关键神经元高度重叠，但需要不同的激活模式。此外，展示了我们的发现如何在生成之前检测到不安全的输出，以保护LLMs。", "conclusion": "实验结果证明，通过识别安全神经元，不仅可以显著提高模型的安全性，还可以解释安全对齐“税收”现象，并提出通过检测生成的不安全输出来保护LLMs的方法。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.18469", "html_url": "https://arxiv.org/abs/2410.18469", "title": "迭代自我校准的LLMs以增强逃狱能力", "title_en": "Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities", "authors": "Chung-En Sun,Xiaodong Liu,Weiwei Yang,Tsui-Wei Weng,Hao Cheng,Aidan San,Michel Galley,Jianfeng Gao", "background": "最近的研究表明，大型语言模型（LLMs）对自动逃狱攻击极为脆弱，这些攻击利用由算法生成的对抗性后缀，绑定到有害查询上，规避安全对齐，引发意外响应。目前生成此类后缀的方法成本高昂且成功率较低，尤其是对于像Llama2和Llama3这样的高度对齐模型。本文讨论了这一挑战及其现状。", "innovation": "本文引入了ADV-LLM，一种迭代自我校准的过程，用于生成具有增强逃狱能力的对抗性LLMs。与现有方法相比，该框架显著降低了生成对抗性后缀的成本，并在各种开源LLMs上实现了几乎100%的成功率。此外，ADV-LLM展示出强大的攻击可移植性，对闭源模型GPT-3.5的攻击成功率高达99%，对GPT-4的攻击成功率也达49%，且这一框架仅在Llama3上进行了优化。", "conclusion": "ADV-LLM不仅提升了逃狱能力，还通过生成大量用于研究LLM安全性的数据集为未来的安全性对齐研究提供了宝贵的见解。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.00954", "html_url": "https://arxiv.org/abs/2406.00954", "title": "基于标注指南的知识增强：提升大型语言模型在教育文本分类中的能力", "title_en": "Annotation Guidelines-Based Knowledge Augmentation: Towards Enhancing Large Language Models for Educational Text Classification", "authors": "Shiqi Liu,Sannyuya Liu,Lele Sha,Zijie Zeng,Dragan Gasevic,Zhi Liu", "background": "机器学习方法近年来被广泛应用于教育文本的自动化分类，识别学习参与度的指标，称为学习参与度分类（LEC）。LEC能够深入了解人类学习过程，引起了自然语言处理（NLP）、学习分析和教育数据分析等研究领域的广泛关注。最近，大型语言模型（LLMs）如ChatGPT在各种NLP任务中表现优异，但在LEC任务上的全面评估和改进方法尚未得到充分研究。", "innovation": "本文提出了基于标注指南的知识增强（AGKA）方法，利用GPT 4.0从标注指南中检索标签定义知识，并采用随机欠采样选择典型示例。该研究对LEC进行了系统的基准评估，涵盖了六个包含行为分类、情感分类和认知分类的LEC数据集。研究结果表明AGKA可以提高非微调的LLMs，特别是在GPT 4.0和Llama 3 70B上显示出显著效果。此外，对于简单二分类任务，GPT 4.0在“少量展示”微调中优于“全面展示”微调模型如BERT和RoBERTa。然而，GPT 4.0在需要深刻理解复杂语义信息的多分类任务中表现较差。值得注意的是，基于开源LLM的Llama 3 70B与AGKA的结合是一个很有前景的组合，其表现与闭源的GPT 4.0相当。此外，LLMs在多分类任务中无法区分名称相似的标签。该方法通过增强LLMs的认知处理能力，推动了教育文本自动分类的进步。", "conclusion": "研究结果表明，AGKA可以有效提升非微调的LLMs在LEC任务中的表现，特别是在GPT 4.0和Llama 3 70B上表现出色。同时，该工作为进一步研究提供建设性指导，有助于继续改进LLMs在复杂教育文本上的应用。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.19258", "html_url": "https://arxiv.org/abs/2410.19258", "title": "不同头未必重要：集成检索与推理的头级别KV缓存压缩方法", "title_en": "Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning", "authors": "Yu Fu,Zefan Cai,Abedelkadir Asi,Wayne Xiong,Yue Dong,Wen Xiao", "background": "大型语言模型（LLMs）的键值（KV）缓存是一种常见的技术，用于提高计算效率，但随着输入长度的增加，其内存开销快速增加。先前的工作表明，并非所有令牌在文本生成中都同等重要，因此提出了层级别KV缓存压缩方法，以选择性地保留关键信息。考虑到注意头在生成过程中的不同作用，作者提出了一种头级别KV缓存压缩方法HeadKV和HeadKV-R2，后者利用了一种新的上下文推理能力估计方法来实现压缩。", "innovation": "作者提出了一种头级别KV缓存压缩方法HeadKV和HeadKV-R2，该方法能够在需要检索和推理能力的上下文问答任务中估计各个注意头的重要性。该方法在多样化的基准测试（LongBench、LooGLE）、不同的模型架构（例如Llama-3-8B-Instruct、Mistral-7B-Instruct）以及长期上下文能力测试中，显示出比强基线方法显著优越的性能，特别是在资源较少的情况下（KV大小为64和128）。", "conclusion": "我们的头级别KV缓存压缩方法在上下文问答基准测试中仅保留了缓存的1.5%，但达到了缓存完整版本97%的性能。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.04346", "html_url": "https://arxiv.org/abs/2410.04346", "title": "从人类判断的列表排名进行排列偏好对齐", "title_en": "Permutative Preference Alignment from Listwise Ranking of Human Judgments", "authors": "Yang Zhao,Yixin Wang,Mingzhang Yin", "background": "大型语言模型（LLMs）与人类偏好对齐是确保模型行为适当的必要步骤。当前方法，例如强化学习（RLHF）和直接偏好优化（DPO），依赖布雷德利-特利（B-T）模型来最大化两两选择的似然性。但是，当有多个响应时，B-T模型无法确保对响应准确的列表排序。这种不足导致现有方法在多选项场景下的性能不尽如人意。因此，如何改进模型的排序准确性成为亟待解决的问题。", "innovation": "本文提出了新的离线列表对齐方法Permutative Preference Alignment（PPA），引入了归一化累积增益（NDCG）作为替代训练目标，NDCG是一种广泛使用的排名指标。PPA通过近似NDCG为可微损失函数，开发了一个完整的对齐算法。实验表明，PPA在评估集和标准基准测试如AlpacaEval上优于现有的成对和列表方法。NDCG方法提高了排名准确度，且该研究还提供了这一改进的理论解释。", "conclusion": "PPA方法通过引入NDCG目标和可微近似方法，有效提升了模型的排序准确性。实验证明，NDCG方法比基于B-T模型的方法更有效，且提供了理论上的解释支持。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.11843", "html_url": "https://arxiv.org/abs/2411.11843", "title": "Bi-Mamba：走向准确的一位状态空间模型", "title_en": "Bi-Mamba: Towards Accurate 1-Bit State Space Models", "authors": "Shengkun Tang,Liqun Ma,Haonan Li,Mingjie Sun,Zhiqiang Shen", "background": "传统的选择性状态空间模型（SSM）在Mamba中被用于解决Transformer的一些局限性，比如序列长度上的二次计算复杂度和推理期间由于键值缓存导致的重大内存需求。然而，随着Mamba模型规模的增加，其在训练和部署过程中面临的计算需求越来越大，尤其是训练和推理期间的显著计算负担。", "innovation": "本文介绍了一种可扩展且强大的双向一比特Mamba架构（Bi-Mamba），它设计用来构建更高效的大语言模型（LLMs），模型参数数量包括780M、1.3B和2.7B。Bi-Mamba模型使用标准LLM规模的数据集从头训练，并使用自回归蒸馏损失。广泛的实验表明，Bi-Mamba在语言建模基准上达到了与全精度（FP16或BF16）模型相当的性能，同时优于后训练二进制化（PTB）Mamba和二进制意识训练（BAT）Transformer基线。此外，Bi-Mamba在内存使用和计算成本上比原始的Mamba有了大幅减少。", "conclusion": "我们的工作开创了在低比特表示下线性复杂的大语言模型的新领域，并提供了针对高效的一位Mamba基模型的专用硬件设计的方式。该代码和预训练权重已对外公开。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.18795", "html_url": "https://arxiv.org/abs/2501.18795", "title": "从RoPE到NoPE再到混合注意力策略: 一种新的混合注意力方法", "title_en": "Rope to Nope and Back Again: A New Hybrid Attention Strategy", "authors": "Bowen Yang,Bharat Venkitesh,Dwarak Talupuru,Hangyu Lin,David Cairuz,Phil Blunsom,Acyr Locatelli", "background": "长上下文大型语言模型（LLMs）通过旋转位置嵌入（RoPE）等技术取得了显著进步。通过调整RoPE参数并结合更长的训练上下文，可以训练出高性能的模型。然而，现有的RoPE方法在处理扩展上下文长度时存在性能限制。本文对不同注意力机制进行了全面分析，包括RoPE、无位置嵌入（NoPE）和查询-键归一化（QK-Norm），指出了它们在长上下文建模中的优势和不足。", "innovation": "本文提出了一个基于混合注意力机制的新模型，该机制结合了全局和局部注意力，并且在长上下文和短上下文任务中都优于传统的RoPE基Transformer模型。此外，这种设计在训练和推理过程中还带来了显著的效率提升。", "conclusion": "通过分析不同注意力机制的特点，本文提出了一种混合注意力机制的设计，不仅在长上下文和短上下文任务中表现出色，而且在训练和推理过程中提高了效率。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.15299", "html_url": "https://arxiv.org/abs/2412.15299", "title": "LAMA-UT：通过字体统一和语言特定转写实现语言无关多语言ASR", "title_en": "LAMA-UT: Language Agnostic Multilingual ASR through Orthography Unification and Language-Specific Transliteration", "authors": "Sangmin Lee,Woo-Jin Chung,Hong-Goo Kang", "background": "构建一种在多种语言上表现公平的通用多语言自动语音识别（ASR）模型一直是一项挑战，由于其固有的难度，因此一直难以解决。我们介绍了一种通过字体统一和语言特定转写（LAMA-UT）的无语言依赖性多语言ASR管道，该管道在仅使用少量数据训练的情况下就能达到最先进的模型的性能。该管道包括两个关键步骤：首先，使用通用转录生成器将字体特征统一为罗马化形式，并捕捉不同语言中的共同音素特征；其次，利用通用转换器将这些通用转录转换为特定于语言的形式。我们在实验中展示了我们的方法利用通用转录进行大规模多语言ASR的有效性。我们的管道与Whisper相比，相对错误率降低了45%，尽管只使用了Whisper训练数据的0.1%。此外，该管道不依赖任何特定语言模块，但在性能上与依赖额外语言词汇表和语言模型的零样本ASR方法相当。该框架有望成为灵活的通用多语言ASR系统的基础，即使对未见过的语言也同样适用", "innovation": "LAMA-UT管道通过通用转录生成和通用转换器实现无特定语言依赖的多语言ASR。该方法在仅使用少量数据训练的情况下达到了最先进的模型的性能，相对错误率降低了45%，并且不依赖任何特定于语言的模块。与仅使用大量训练数据的其他模型相比，该技术以更少的数据和资源优化ASR性能，具有显著的创新性，同时也展示了其在面向未见过的语言的通用性", "conclusion": "LAMA-UT框架为灵活的通用多语言ASR系统提供了一个基础，即使在面对未见过的语言时也能保持良好的性能。该技术克服了传统的数据密集型训练方法的限制，证明了即使仅使用少量数据也能实现高精度的多语言ASR。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.13251", "html_url": "https://arxiv.org/abs/2502.13251", "title": "神经注意力搜索", "title_en": "Neural Attention Search", "authors": "Difan Deng,Marius Lindauer", "background": "当前情况下，基于Transformer的模型在推理过程中需要较大的KV缓存大小，这导致了较高的推理成本。为了减轻这一问题，研究者们试图通过自动评价每个序列中令牌的重要性以及确定哪些令牌可以在多步后被丢弃来简化模型的推理过程，从而有效降低推理成本。因此，设计了一个新的搜索空间来处理Token的不同类型，以优化Transformer模型的KV缓存大小。", "innovation": "提出了一种名为Neural Attention Search (NAtS)的框架，该框架自动评估序列中每个令牌的重要性，并决定在推理过程中何时可以将相应的令牌丢弃。该方法通过学习可学习的注意力掩码联合学习令牌类型信息与架构权重，从而在保持模型性能的同时有效地减少了所需的KV缓存大小。实验表明，NAtS在从零开始训练新的Transformer和微调现有的大型语言模型时都具有高效性.", "conclusion": "实验结果表明，NAtS能够在保持模型性能的同时有效减少所需的KV缓存大小，从而降低推理成本。这种方法通过联合学习令牌类型信息与架构权重，展示了在训练新的Transformer和微调现有大型语言模型时的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.01025", "html_url": "https://arxiv.org/abs/2502.01025", "title": "语言模型(大多)知道何时停止阅读", "title_en": "Language Models (Mostly) Know When to Stop Reading", "authors": "Roy Xie,Junlin Wang,Paul Rosu,Chunyuan Deng,Bolun Sun,Zihao Lin,Bhuwan Dhingra", "background": "大型语言模型（LLMs）在处理输入上下文时，会无差别地处理整个输入，这在信息仅局部化的问答场景中效率较低。本文分析了模型内部机制发现，特定注意头编码了‘充分性信号’，这些信号可通过轻量级分类器检测到，表明当关键信息被处理时，这种信号可以预测出处理的结束。这一发现揭示了一种新的效率范式：模型内部理解自然决定了处理需求，而非外部压缩启发式方法。", "innovation": "提出了一种新颖的方法——动态上下文截断，使LLMs能够在获得足够任务相关信息时自我终止处理。这种方法通过分析模型内部机制，发现了特定注意头编码的‘充分性信号’。作者通过跨六个问答数据集（多达40K标记）和三种模型家族（LLaMA/Qwen/Mistral，1B-70B）的实验验证了该方法的效果，在平均减少1.33倍标记数量的同时提高了3.4%的准确性，并且在同等标记减少率下表现出优于其他上下文效率方法的性能。此外，还观察到一种新兴的缩放现象：较小的模型需要触发不足检测，而较大的模型则通过提示展示出固有的自我评估能力。", "conclusion": "本研究证明了动态上下文截断方法的有效性，并揭示了新的效率范式。通过内部机制和轻量级信号的识别，使得模型可以自我决定处理需求，显著提升了模型处理局部信息的效率，同时保持了准确性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.15090", "html_url": "https://arxiv.org/abs/2502.15090", "title": "ExpertLens: 激活引导特征具有高度可解释性", "title_en": "ExpertLens: Activation steering features are highly interpretable", "authors": "Masha Fedzechkina,Eleonora Gualdoni,Sinead Williamson,Katherine Metcalf,Skyler Seto,Barry-John Theobald", "background": "在大型语言模型（LLMs）中应用激活引导方法已经证明了它们通过目标性更新来增强生成语言的有效性，而无需大量的适应数据。本文进一步探讨了这些方法中发现的特征是否具有可解释性。研究者使用‘寻找专家’方法来识别特定概念（例如，“猫”）相关的神经元，并展示出ExpertLens，即检查这些神经元的视角可以提供关于模型表示的见解。研究表明，这些特征在不同模型和数据集中的表现相对稳定，并高度符合从行为数据中推断出的人类表示，其一致的程度与人类之间的匹配水平相当。", "innovation": "本文提出了一种名为ExpertLens的方法，用于识别特定概念相关的神经元并检查这些神经元的视角，展示了这种方法可以提供模型表示的见解，并且该方法在不同的模型和数据集中表现出较好的稳定性和人类一致程度。此外，与基于词汇或句子嵌入的匹配相比，ExpertLens的匹配表现更优。通过使用ExpertLens重组人类概念的组织结构，表明该方法可以提供对LLM概念表示的详细视图。", "conclusion": "研究表明，ExpertLens作为一种灵活且轻量级的方法，能够有效捕捉和分析模型表示，提供了对LLM概念表示的详细视角。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.04510", "html_url": "https://arxiv.org/abs/2502.04510", "title": "异质蜂群：通过联合优化模型角色和权重实现多LLM系统", "title_en": "Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems", "authors": "Shangbin Feng,Zifeng Wang,Palash Goyal,Yike Wang,Weijia Shi,Huang Xia,Hamid Palangi,Luke Zettlemoyer,Yulia Tsvetkov,Chen-Yu Lee,Tomas Pfister", "background": "为了设计多大型语言模型（LLM）系统，研究者需要优化模型的角色分配和权重。现有的方法要么仅优化角色分配，要么仅优化权重，存在一定的局限性。本文提出了一种称为异质蜂群的新算法，通过联合优化模型的角色和权重来设计多LLM系统。这种方法将多LLM系统表示为具有拓扑消息传递的大型语言模型（LLM）有向无环图（DAG），并利用角色步和权重步两个迭代步骤来实现这一目标。在实际应用中，该算法可以应用于不同任务，并通过优化实现更好的性能表现。", "innovation": "异质蜂群算法通过引入有向无环图（DAG）的表示方法和联合优化模型角色和权重的迭代步骤，设计多LLM系统。它特别提出了一种基于粒子群优化的策略来优化模型角色和权重，并引入了JFK分数来量化每个LLM的个体贡献，从而实现更高效和更准确的任务执行。实验结果显示，该算法在12个任务上的平均性能优于15种基线方法18.5%，并发现多LLM系统中角色和权重的优化是实现显著协同增益的关键。", "conclusion": "异质蜂群算法通过联合优化模型的角色和权重，显著提高了多LLM系统的性能。该方法能够发现具有异质角色的多LLM系统，并且通过利用语言模型的多样性获得了良好的协同增益。实验验证了该算法的有效性和优势。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.04388", "html_url": "https://arxiv.org/abs/2503.04388", "title": "在相同长度的情况下，更多文档：分离RAG中多文档的挑战", "title_en": "More Documents, Same Length: Isolating the Challenge of Multiple Documents in RAG", "authors": "Shahar Levy,Nir Mazor,Lihi Shalmon,Michael Hassid,Gabriel Stanovsky", "background": "RAG通过在生成过程中利用相关外部文档来提高大语言模型（LLM）响应的准确性。尽管之前的研究指出，检索过多文档可能会影响性能，但它们并没有单独分析文档数量如何影响性能，同时控制上下文长度。研究者利用自定义的数据集评估了不同语言模型，并在保持上下文长度和相关信息位置不变的情况下，改变文档的数量。研究结果显示，在RAG设置中增加文档数量对大多数LLM提出了显著挑战，导致性能降低高达20%。而Qwen2.5在其性能提升方面的表现稳定，表明其具备更好的多文档处理能力。最后，研究结果表明，处理多文档是一个与处理长上下文不同的挑战。", "innovation": "本研究通过保持上下文长度和相关信息位置不变，单独分析文档数量对性能的影响。这是对之前研究的改进，区分了处理多文档与处理长上下文的挑战。此外，研究还提供了可用于进一步研究的自定义数据集和代码。", "conclusion": "本研究发现，在RAG设置中增加文档数量对大多数语言模型提出了显著挑战，这表明处理多文档是一个需要特别注意的独立问题。虽然大多数语言模型在增加文档数量时性能会降低，但Qwen2.5的能力表明了对未来更优模型的可能展望。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.01002", "html_url": "https://arxiv.org/abs/2504.01002", "title": "令牌嵌入违反流形假设", "title_en": "Token embeddings violate the manifold hypothesis", "authors": "Michael Robinson,Sourya Dey,Tony Chiang", "background": "了解大型语言模型（LLM）的行为需要我们掌握其输入令牌空间。如果这个空间与我们的假设不同，我们对LLM的理解和得出的结论可能会出现错误。因此，探究令牌嵌入的结构变得至关重要。", "innovation": "本研究提出了一个新颖的统计检验，假设每个令牌的邻域结构相对平坦和光滑。通过运行测试，研究发现令牌空间结构往往不符合纤维丛假设，意味着令牌空间不是一个纤维丛，也不表示流形。当呈现给LLM两个语义等价的提示时，如果一个提示包括由检验识别的令牌，那么该提示的响应将比另一个提示表现出更少的稳定性。", "conclusion": "通过对多个开源LLM进行测试，发现令牌空间结构经常违背纤维丛假设，表明令牌空间既不是一个纤维丛也不是流形。因此，当LLM接收到两个语义等价但包含不同令牌的提示时，响应的稳定性可能会受到影响。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.03456", "html_url": "https://arxiv.org/abs/2501.03456", "title": "从文本到禁带：预训练语言模型在半导体禁带预测中的编码器", "title_en": "Text to Band Gap: Pre-trained Language Models as Encoders for Semiconductor Band Gap Prediction", "authors": "Ying-Ting Yeh,Janghoon Ock,Achuth Chandrasekhar,Shagun Maheshwari,Amir Barati Farimani", "background": "本文研究了基于变压器的语言模型（包括RoBERTa，T5，Llama-3和MatSciBERT），用于直接从半导体材料的文本描述中预测带隙。输入编码了关键的材料特征，如化学成分、晶体系统、空间群及其他结构和电子性质。相比于需要大量特征工程的浅层机器学习模型或依赖原子坐标生成图表示的图神经网络，预训练语言模型能够直接处理文本输入，从而避免了手动特征预处理或基于结构的编码需求。文本描述以两种格式构建：具有统一模板的结构化字符串和通过ChatGPT API生成的自然语言叙述。每种模型都添加了自定义回归头部并微调了带隙预测任务。不同架构和参数规模的语言模型都能够从可读文本中准确预测带隙，实现了MAE在0.25-0.33 eV范围内的强准确性，证明了该方法在科学回归任务中的成功。微调后的Llama-3（12亿参数）获得了最高精度（MAE 0.248 eV，R2 0.891），而预训练于材料科学文献的MatSciBERT（1.1亿参数）获得了可比的表现（MAE 0.288 eV，R2 0.871），凸显了领域特定预训练的重要性。注意力分析表明，两种模型都选择性地关注组成和自旋相关特征，而弱化了几何特征，反映了通过文本捕获空间信息的难度。这些结果证明了预训练语言模型能够有效地从文本材料描述中提取复杂的特征-性质关系。", "innovation": "本文创新性地探索了基于变压器的语言模型，如RoBERTa，T5，Llama-3和MatSciBERT，用于从半导体材料的文本描述中直接预测带隙。区别于浅层机器学习模型需大量特征工程以及图神经网络依赖于原子坐标生成的图表示，预训练语言模型能直接处理文本输入，减少了手动特征预处理的必要性。通过自定义回归头部的微调，该模型在带隙预测中取得了良好的效果，并展示了预训练语言模型在科学回归任务中的潜力。无论是参数量大的Llama-3还是参数量少的MatSciBERT都能取得较好的预测效果，特别强调了领域特定预训练的重要性。", "conclusion": "预训练语言模型能够有效从文本材料描述中提取复杂的特征-性质关系，优于传统浅层机器学习模型和依赖于原子坐标生成的图表示的图神经网络。Llama-3模型在带隙预测中取得最高的准确度（MAE 0.248 eV，R2 0.891），而MatSciBERT模型则通过较少了参数数量（110M）也达到了类似的预测效果（MAE 0.288 eV，R2 0.871），这说明了领域特定预训练的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.15086", "html_url": "https://arxiv.org/abs/2502.15086", "title": "每个人的安全标准相同吗？大规模语言模型的用户特定安全性评估", "title_en": "Is Safety Standard Same for Everyone? User-Specific Safety Evaluation of Large Language Models", "authors": "Yeonjun In,Wonjoong Kim,Kanghoon Yoon,Sungchul Kim,Mehrab Tanjim,Sangwu Park,Kibum Kim,Chanyoung Park", "background": "随着大规模语言模型（LLM）代理的使用持续增长，它们的安全漏洞已经变得越来越明显。目前广泛采用的安全基准主要依赖通用标准评估LLM的安全性，忽略了用户特定的标准。但是，LLM的安全标准可能因用户个人特征的不同而异，而不是在全球范围内一致的。这引发了关键研究问题：在考虑用户特定的安全标准时，LLM代理是否能够安全地操作？尽管对于安全使用LLM非常重要，但目前仍不存在用于评估LLM用户特定安全性的基准数据集。为了填补这一空白，我们引入了U-SafeBench基准，专门用来评估用户特定的LLM安全性。研究表明，当前广泛使用的20个LLM在考虑用户特定的安全标准时，未能安全操作，这标志着该领域的最新发现。", "innovation": "我们开发了U-SafeBench基准，以评估用户特定的LLM安全性。我们提出了基于推理链的简单补救措施，以提高用户特定的安全性，这是对现有基于通用标准的评估方法的创新补充。我们研究中使用的基准和代码可以在此处访问：this https URL。", "conclusion": "我们的评估表明，当前广泛使用的LLM在考虑用户特定的安全标准时不能安全操作，揭示了新的发现。我们提出的方法能够有效提高用户特定的安全性，这为未来开发用户特定的安全标准提供了途径。基准和代码对外开放，为后续研究提供了支持。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.12474", "html_url": "https://arxiv.org/abs/2504.12474", "title": "BiGTex: 结构与语义信号在文本归因图中的联合利用", "title_en": "Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex", "authors": "Azadeh Beiranvand,Seyed Mehdi Vahidipour", "background": "文本归因图（TAGs）在表示学习中具有独特挑战，因为它们需要模型同时捕捉节点关联文本的语义丰富性和图形结构之间的依赖关系。虽然图神经网络（GNNs）在建模拓扑信息方面表现出色，但它们缺乏处理非结构化文本的能力。相反，大型语言模型（LLMs）擅长文本理解，但通常不了解图形结构。本文讨论了如何整合GNNs和LLMs来克服这些限制。", "innovation": "提出了一种名为BiGTex的创新架构，它通过堆叠的Graph-Text融合单元将GNNs和LLMs紧密结合。每个单元都允许文本和结构表示之间的相互注意，从而使信息在两个方向上流动。此外，该模型采用参数效率式的微调（LoRA）进行训练，使LLMs保持冻结状态，但根据任务特定信号进行适应。实验结果表明，BiGTex在节点分类任务上达到了最先进的性能，并且能够很好地泛化到链接预测。", "conclusion": "全面的实验在五个基准数据集上表明，BiGTex在节点分类任务中达到了最先进的性能，并且能够很好地泛化到链接预测。消融研究进一步强调了软提示和双向注意力在模型成功中的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.18458", "html_url": "https://arxiv.org/abs/2504.18458", "title": "Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning", "title_en": "Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning", "authors": "Wenyi Xiao,Leilei Gan", "background": "在通过GRPO应用强化学习解决大型视觉-语言模型推理问题时，全长推理难以有效扩展，或者会产生冗长的输出，即使在某些任务上准确率有小幅提升。这个问题在实际应用中存在显著限制，使得传统的强化学习方法在处理复杂或长推理链路问题时效率低下。", "innovation": "本文提出FAST-GRPO，这是一种根据问题特点动态调整推理深度的GRPO变种。此外，该论文通过引入两个新的度量标准来估计问题难度，并将可适应长度的奖励和难度感知KL散度整合到GRPO算法中。实验结果表明，FAST方法能够在保持准确率的前提下，显著减少token使用量，同时达到最先进的准确率，具有显著的效果提升。", "conclusion": "FAST方法通过动态调整推理深度与引入新度量标准及算法改进，针对视觉-语言模型的长推理问题提出了一种有效的解决方案。实验结果展示了FAST在这方面的优越性，准确率有显著提升，同时减少了token使用，实现了更高效的推理展示。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14827", "html_url": "https://arxiv.org/abs/2505.14827", "title": "超越离散标记采样的文本生成", "title_en": "Text Generation Beyond Discrete Token Sampling", "authors": "Yufan Zhuang,Liyuan Liu,Chandan Singh,Jingbo Shang,Jianfeng Gao", "background": "在标准自回归生成过程中，大型语言模型（LLM）预测下一个标记的概率分布，从中抽取离散标记，然后丢弃该分布，仅将其生成的离散标记作为新的输入。这种方式导致生成过程中丢失了预测分布的丰富信息，影响了生成文本的质量和推理能力。", "innovation": "本文提出了一种无需训练的方法——混合输入（MoI），通过在生成离散标记后将其与之前丢弃的概率分布进行融合来保留分布的丰富信息。具体而言，通过贝叶斯估计方法将概率分布作为先验，生成的离散标记作为观测值，将传统的one-hot向量替换为连续后验期望，作为新的模型输入。", "conclusion": "MoI 方法在数学推理、代码生成和博士级问题回答任务上表现出色，涵盖了多个模型，例如 QwQ-32B、Nemotron-Super-49B、Gemma-3-27B 和 DAPO-Qwen-32B，且无需额外训练且几乎没有计算开销，提高了生成文本的质量和推理能力。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14101", "html_url": "https://arxiv.org/abs/2505.14101", "title": "MultiHal: 多语言数据集，基于知识图谱评估LLM幻觉", "title_en": "MultiHal: Multilingual Dataset for Knowledge-Graph Grounded Evaluation of LLM Hallucinations", "authors": "Ernests Lavrinovics,Russa Biswas,Katja Hose,Johannes Bjerva", "background": "大型语言模型（LLMs）存在忠实性和事实性方面的问题，通常被称为幻觉。虽然已有一些基准测试用于评估英语为中心的数据集的事实性，但这些测试依赖于网页链接或文本片段作为辅助信息，而忽略了结构化的事实资源。为此，知识图谱被确认为幻觉缓解的有用工具，因为它以结构化的方式表示实体及其关系，同时减少了语言负担。然而，现有的幻觉评估基准缺乏针对知识图谱路径的评估和多语言支持。", "innovation": "论文提出了一个基于知识图谱的多语言、多跳基准叫MultiHal，旨在为生成文本评估提供框架。作者从开放域的知识图谱中挖掘了140,000条知识图路径，通过清理和筛选噪声路径，建立了25,900个高质量的子集。实验结果显示，基于知识图谱的双向重构问答（KG-RAG）在多个语言和多个模型上实现了绝对尺度改进，对于语义相似度评分提高了约0.12到0.36分，对于自然语言推理蕴含提高了0.16到0.36分，对于幻觉检测提高了0.29到0.42分，这证明了知识图谱集成的潜力。", "conclusion": "MultiHal有望促进未来在基于图的幻觉缓解和事实核查任务方面的研究。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11336", "html_url": "https://arxiv.org/abs/2505.11336", "title": "XtraGPT：上下文感知且可控的学术论文修订", "title_en": "XtraGPT: Context-Aware and Controllable Academic Paper Revision", "authors": "Nuo Chen,Andre Lin HuiKai,Jiaying Wu,Junyi Hou,Zining Zhang,Qian Wang,Xidong Wang,Bingsheng He", "background": "尽管大型语言模型（LLMs）在学术工作流程中的应用越来越广泛，但它们的能力仍然有限，无法支持高质量的科学研究写作。现有的大多数系统旨在生成通用科学文本，无法满足研究沟通的高级需求，例如节间的概念一致性。此外，学术写作本质上是迭代和修订驱动的，而直接提示驱动的方法无法很好地支持这一过程。这些问题需要一种新的框架来整合人类和人工智能的合作。", "innovation": "本研究提出了一种以准则导向的意图对齐和上下文感知建模为核心的学术论文修订的人机协作框架。为了验证该框架，我们构建了一个包含7,000篇顶级学术会议论文的语料库，附有140,000个指令-响应对，这些数据反映了实际的节段水平科学修订。我们在此框架上实现了XtraGPT，这是第一个用于上下文感知、指令引导的写作辅助的开源LLM套件（参数量从1.5亿到14亿）。实验结果表明，XtraGPT在质量上明显优于同类 baseline，并接近专有系统的水平。", "conclusion": "XtraGPT在自动化偏好评估和人类评估中均显示出提高科学草稿效果的能力，验证了人机协作框架在学术写作中的有效性和潜力。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14536", "html_url": "https://arxiv.org/abs/2505.14536", "title": "使用稀疏自编码器 detoxification LLMs", "title_en": "Breaking Bad Tokens: Detoxification of LLMs Using Sparse Autoencoders", "authors": "Agam Goyal,Vedant Rathi,William Yeh,Yian Wang,Yuen Chen,Hari Sundaram", "background": "大型语言模型（LLMs）现广泛应用于用户界面，但仍会生成不 desirable 的有毒输出，如谩骂、粗俗语言和具有侮辱性的言论。当前的去毒方法虽多，但大多仅能做表面处理，容易受到 jailbreak 攻击。", "innovation": "本文引入稀疏自编码器（SAEs）来识别模型残差流中的毒性相关方向，并通过相应的解码向量进行目标激活转向。提出三种不同力度的转向方法，并在GPT-2 Small 和 Gemma-2-2B 上评估，揭示减少毒性与语言流畅性之间的权衡。在强转向强度下，这些因果干预方法在减少毒性方面优于竞争Baseline，最高可达20%，但可能导致GPT-2 Small 的流畅性显著下降，这取决于转向力度。重要的是，即使在转向后，标准NLP基准测试得分仍然保持稳定，表明模型的知识和一般能力得到了保留。宽 SAE 中的特征划分限制了安全干预措施的有效性，强调了去纠缠特征学习的重要性。研究成果揭示了基于 SAE 的因果干预在LLM detoxification中的潜力与当前限制，并提出了实际部署安全的语言模型的建议指南。", "conclusion": "基于SAE的因果干预在减少LLM毒性方面具有潜力，但也存在一些局限性，需要考虑在实际部署中制定更安全的语言模型的指导原则。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14685", "html_url": "https://arxiv.org/abs/2505.14685", "title": "语言模型使用回溯机制追踪信念", "title_en": "Language Models use Lookbacks to Track Beliefs", "authors": "Nikhil Prakash,Natalie Shapira,Arnab Sen Sharma,Christoph Riedl,Yonatan Belinkov,Tamar Rott Shaham,David Bau,Atticus Geiger", "background": "该论文关注语言模型在处理零样本或少样本情况下的理论思维(Teaching of Mind, ToM)能力。具体来说，论文探讨了语言模型在角色信念（尤其是这些信念可能与实际情况不符时）的表示方式。背景设置了一个简单的故事，其中两个角色独立地改变两个对象的状态，可能不知道彼此的行为。", "innovation": "该研究创新性地提出了‘回溯机制’这一算法图式，指代语言模型在必要时回溯重要信息的能力。此外，研究发现LM通过将每个角色-对象-状态三元组的参考信息并置在状态词残留流的低秩子空间中进行绑定。当涉及到隐藏或可见信息时，语言模型通过生成‘可见性ID’来处理角色之间的信息相互作用。这些发现提供了对信念跟踪机制的理解，为进一步逆向工程LM中的ToM推理提供了新的视角。", "conclusion": "该研究揭示了一种普遍存在且有效的信念追踪机制，即‘回溯机制’。通过构造CausalToM数据集，研究者能够更深入地理解LM在处理角色信念时的内部工作原理。论文的结论指出，这为进一步理解和设计具备ToM能力的语言模型奠定了基础，并提供了一种新的方法来分析语言模型的ToM推理过程。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14483", "html_url": "https://arxiv.org/abs/2505.14483", "title": "MoMoE框架：混合调节专家体系以实现人工智能辅助在线治理", "title_en": "MoMoE: Mixture of Moderation Experts Framework for AI-Assisted Online Governance", "authors": "Agam Goyal,Xianyang Zhan,Yilun Chen,Koustuv Saha,Eshwar Chandrasekharan", "background": "现有的在线社区内容审核方法需要为每个社区训练一个单独的模型，并且在决策过程不透明，这限制了其在实际中的应用。大型语言模型在识别有害内容方面表现出了潜在的潜力，但现有方法的问题使得难以在多个社区间通用和提高透明度，从而影响了广泛的使用。因此，研究如何构建一个模块化的、跨社区的框架，提供可扩展的内容审核同时又能增强透明度，显得尤为重要。", "innovation": "作者提出了Mixture of Moderation Experts (MoMoE)，这是一种模块化的跨社区框架，可以在内容审核时提供事后解释。MoMoE框架通过四个操作——分配、预测、聚合、解释——并将其实例化为七名社区专门化专家（MoMoE-Community）和五名规则违背专家（MoMoE-NormVio）。实验结果显示，MoMoE的最佳变体能够在30个未见的子reddit上获得0.72和0.67的Micro-F1分数，这与强大的微调基线模型相当甚至更优，且能不断地产生简洁且可靠的解释。尽管社区专门化专家能提供最高的峰值准确率，规则违背专家则能在各个领域提供更稳定的性能。这些结果表明，MoMoE在无需为每个社区进行微调的情况下，能够实现可扩展和透明的内容审核，突显了轻量级、可解释的专家集成的重要性，这对未来的人工智能辅助在线社区的人机协同治理研究具有指导意义。", "conclusion": "MoMoE的研究成果表明，能够构建一种模块化、透明并且不需要针对每个社区进行独特微调的内容审核机制是可能的。此外，这也表明轻量级且可解释的专家集成模型可以在AI与人类在在线社区中的协同治理方面起到重要的指导作用。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16348", "html_url": "https://arxiv.org/abs/2505.16348", "title": " embodied agents meet personalization: investigating challenges and solutions through the lens of memory utilization", "title_en": "Embodied Agents Meet Personalization: Investigating Challenges and Solutions Through the Lens of Memory Utilization", "authors": "Taeyoon Kwon,Dongwook Choi,Hyojun Kim,Sunghwan Kim,Seungjun Moon,Beong-woo Kwak,Kuan-Hao Huang,Jinyoung Yeo", "background": "LLM-powered embodied agents have successfully handled conventional object-rearrangement tasks. However, providing personalized assistance, particularly by leveraging user-specific knowledge from past interactions, poses new challenges.", "innovation": "研究从代理的记忆利用两个关键维度进行：物体语义（基于个人意义识别物体）和用户模式（回忆行为模式中的序列）。构建了一个端到端的两阶段评估框架MEMENTO，包括单一记忆和联合记忆任务。通过深入分析，提出了两级知识图谱基于用户资料的记忆模块，以分别管理个性化知识，解决了信息过载和多记忆处理中的协调失败问题，显著提高了单一和联合记忆任务的表现.", "conclusion": "实验揭示了当前代理可以回忆简单的物体语义，但在应用序列用户模式进行规划方面存在困难，指出了信息过载和多记忆处理中的协调失败是两个关键瓶颈。基于此，设计了一种基于分层知识图谱的用户资料记忆模块，分别管理个性化知识，显著改善了单一和联合记忆任务的表现。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.09068", "html_url": "https://arxiv.org/abs/2505.09068", "title": "S-DAT：一种多语言、基于生成AI的发散思维自动化评估框架", "title_en": "S-DAT: A Multilingual, GenAI-Driven Framework for Automated Divergent Thinking Assessment", "authors": "Jennifer Haase,Paul H. P. Hanel,Sebastian Pokutta", "background": "传统的创造力评估往往是劳动密集型、语言特定的，并依赖于主观的人类评估，这限制了其可扩展性和跨文化适用性。相比之下，S-DAT 利用大型语言模型和先进的多语言嵌入来计算语义距离——这是一种语言无关的发散思维代理指标。S-DAT 在包括英语、西班牙语、德语、俄语、印地语和日语等 11 种不同语言上进行了评估，展示了跨语言场景中的稳健和一致评分。", "innovation": "S-DAT 提供了一个可扩展的、多语言框架，用于自动评估发散思维。S-DAT 利用大型语言模型和先进的多语言嵌入来计算语义距离，这是一种语言无关的发散思维代理指标。S-DAT 在不同的语言背景下展示了稳健和一致的评分，并显示出了与其他发散思维度量的收敛效度，以及与集中思维的正确辨别效度，使其能够在不同语言之间灵活应用，解决了先前方法中的关键局限性。", "conclusion": "S-DAT 提供了一个强大的工具，用于公平、全面地评估多元文化群体中的认知灵活性，并且可以在线自由评估：this https URL."}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16722", "html_url": "https://arxiv.org/abs/2505.16722", "title": "打破mBad！监督微调在跨语言去毒化中的应用", "title_en": "Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification", "authors": "Himanshu Beniwal,Youngwoo Kim,Maarten Sap,Soham Dan,Thomas Hartvigsen", "background": "随着大型语言模型（LLMs）在世界各地的应用日益普遍，确保它们在多种语言环境中无 toxicity（负面影响）仍然是一个关键挑战。本文探讨了‘跨语言去毒化’的概念，这是一种跨语言范式，旨在解决高资源语言和低资源语言间 toxicity 的转移问题，并且这些语言属于不同的书写体系。研究通过392个广泛设置来评估毒性减少效果，特别是在数据有限的跨分布场景下，同时研究了毒性降解对无毒性任务模型性能的影响，揭示了安全性与知识保留之间的权衡。", "innovation": "本文提出了一种‘监督微调’方法进行跨语言去毒化，并通过广泛的实验设置验证了其有效性。该研究首次展示了跨语言去毒化的可能性，使得低资源语言能够从高资源语言的毒性减少技术中受益，同时探讨了在毒性减少过程中可能会产生的负面影响与保持知识之间的平衡。", "conclusion": "本文通过监督微调方法实现了跨语言去毒化，并通过392个实验设置验证其效果。研究揭示了在不同语言环境中毒性减少技术的应用前景及其可能带来的权衡，同时开放了相关的代码和数据集供进一步研究。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19667", "html_url": "https://arxiv.org/abs/2505.19667", "title": "LeCoDe：交互式法律咨询对话评估基准数据集", "title_en": "LeCoDe: A Benchmark Dataset for Interactive Legal Consultation Dialogue Evaluation", "authors": "Weikang Yuan,Kaisong Song,Zhuoren Jiang,Junjie Cao,Yujie Zhang,Jun Lin,Kun Kuang,Ji Zhang,Xiaozhong Liu", "background": "法律咨询对保护个人权益和确保司法正义至关重要，但因专业人员短缺，很多人无法承担相关的费用和获取服务。最近的大型语言模型（LLMs）进展为提供大规模、低成本的法律援助带来了希望，但当前的系统在处理实际咨询的互动性和知识密集性方面仍然存在不足。", "innovation": "我们引入了LeCoDe，这是包含3,696个法律咨询对话和110,008轮对话的真实世界多轮次基准数据集，用于评估和提升LLMs的法律咨询服务能力。LeCoDe通过从短视频平台上收集实时咨询并进行严格的专业注释来创新性地提供真实多轮次的法律咨询对话。此外，我们提出了一个全面的评估框架，从澄清能力和专业建议质量两个维度评估LLMs的咨询能力。通过在各种通用和领域特定的LLMs上进行广泛实验，结果揭示了在这一任务中存在巨大挑战，即使是如GPT-4等最先进的模型，澄清能力也只有39.8%的召回率，总体建议质量评分为59%，突显了专业咨询场景的复杂性。", "conclusion": "基于这些发现，我们进一步探讨了增强LLMs法律咨询能力的策略。我们的基准数据集有助于推动法律领域对话系统的研究，特别是在模拟更真实的用户-专家互动方面。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18454", "html_url": "https://arxiv.org/abs/2505.18454", "title": "通过强化学习实现混合潜在推理", "title_en": "Hybrid Latent Reasoning via Reinforcement Learning", "authors": "Zhenrui Yue,Bowen Jin,Huimin Zeng,Honglei Zhuang,Zhen Qin,Jinsung Yoon,Lanyu Shang,Jiawei Han,Dong Wang", "background": "近年来，大型语言模型（LLMs）的发展引入了潜在推理作为自回归推理的有前途的替代方案。潜在推理通过利用之前步骤的隐藏状态进行内部计算，从更具信息性的特征中获益，而不是从离散的思维链路径中采样。然而，潜在推理方法通常与LLMs不兼容，因为它们的连续范式与自回归生成的离散性质相冲突。此外，这些方法依赖于思维链轨迹进行训练，因而未能利用LLMs固有的推理模式。", "innovation": "本文通过利用强化学习（RL）的方法探索了潜在推理，提出了一种基于RL的混合潜在推理策略——混合推理策略优化（HRPO）。HRPO通过（1）使用可学习的门控机制将先验隐藏状态集成到采样标记中；以及（2）从主要的标记嵌入开始训练，逐渐引入更多的隐藏特征来设计。这种方法保留了LLMs的生成能力，并通过结合离散和连续表示来激励混合推理。此外，混合HRPO通过标记采样引入了潜在推理中的随机性，从而允许基于RL的优化而不需思维链轨迹。", "conclusion": "在多种基准测试中的广泛评估显示，HRPO在知识密集和推理密集的任务中都优于先前方法。HRPO训练后的LLMs保持可解释性，并呈现出跨语言模式和更短的完成长度等有趣的特性，这突显了我们基于RL的方法的潜力，并为未来潜在推理的工作提供了见解。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18651", "html_url": "https://arxiv.org/abs/2505.18651", "title": "词嵌入中线性类比结构的产生", "title_en": "On the Emergence of Linear Analogies in Word Embeddings", "authors": "Daniel J. Korchinski,Dhruva Karkada,Yasaman Bahri,Matthieu Wyart", "background": "词嵌入模型如Word2Vec和GloVe是基于词在文本语料库中共现概率$P(i,j)$构造词向量$W_i$。这些词向量不仅能够聚集语义相似的词，还能表现出显著的线性类比结构，例如$W_{\text{king}} - W_{\text{man}} + W_{\text{woman}} \text{约等于} W_{\text{queen}}$。虽然这些现象已为人们所熟知，但其理论起源仍不清楚。已有观察显示这些类比结构在包含的特征向量数量增加、使用$\text{log} M(i,j)$而非$M(i,j)$时会增强，并且即便删除特定类比关系的词对，这些结构仍然存在。", "innovation": "本文提出了一个基于二元语义属性的理论生成模型，通过这种模型从理论上解释了线性类比结构的产生，并能够解释上述观察到的现象。这个模型能够精确定义每个额外嵌入维度的作用，并且对各种噪声具有鲁棒性。此外，该模型与维基百科和米科洛夫等人引入的类比基准上的共现统计数据吻合较好。", "conclusion": "该理论模型能够准确揭示词嵌入中线性类比结构的产生机制，同时也解释了为什么这些结构能够随着更多特征向量的引入而增强，直到饱和，并且在删除特定词对后仍然存在。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.06795", "html_url": "https://arxiv.org/abs/2507.06795", "title": "ixi-GEN：通过领域自适应连续预训练实现高效的工业小语言模型", "title_en": "ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining", "authors": "Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon", "background": "开源的大语言模型（LLMs）为企业的应用程序提供了新的机会，但许多组织仍缺乏部署和维护大规模模型所需的基础设施。因此，尽管小型语言模型（sLLMs）存在固有的性能限制，它们已成为一种实用的替代方案。领域适应连续预训练（DACP）方法已被探索用于领域适应，但在商业环境中的实用性尚未得到充分检验。", "innovation": "本文验证了基于DACP的食谱在不同类型的基础模型和服务领域中的有效性，生成了DACP应用的小语言模型（ixi-GEN）。通过广泛的实验和实际评估，证明了ixi-GEN模型在目标领域的性能得到显著提升，同时保持了通用能力，提供了一种高效且可扩展的企业级部署方案。", "conclusion": "ixi-GEN模型通过领域自适应连续预训练实现了高效的工业小语言模型，展示了其在商业环境中的成本效益和可扩展性优势。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.02945", "html_url": "https://arxiv.org/abs/2506.02945", "title": "量化的大语言模型法官", "title_en": "Quantitative LLM Judges", "authors": "Aishwarya Sahoo,Jeevana Kruthi Karnuthala,Tushar Parmanand Budhwani,Pranchal Agarwal,Sankaran Vaidyanathan,Alexa Siu,Franck Dernoncourt,Jennifer Healey,Nedim Lipka,Ryan Rossi,Uttaran Bhattacharya,Branislav Kveton", "background": "当前，大语言模型（LLMs）在生成定性文本评价方面表现出色，但难以预测人类偏好和数值评分。尽管LLMs在提供高质量文本方面表现出色，但在评估其他LLMs的输出时，它们往往无法准确预测人类的偏好和评分。因此，本文提出了一种新的框架，通过回归模型将现有LLM法官的评分与人类评分对齐，从而改进评分。", "innovation": "本文提出了一种名为'量化的大语言模型法官'的新框架，通过使用回归模型改进现有的LLM法官评分。该框架旨在使量化的大语言模型能够更准确地评估其他大语言模型的输出，尤其是在人类反馈有限的情况下，具有更高的统计效率。文章还展示了四个不同类型反馈的量化法官，证明了该框架的通用性和灵活性。此外，该框架比监督微调更具计算效率。", "conclusion": "本文通过在四个数据集上使用两种基础法官进行实验证明了量化的大语言模型法官能够通过事后建模提高现有法官的预测能力。相较于监督微调，该框架在计算效率上更具优势，尤其在人类反馈有限的情况下更为明显。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19201", "html_url": "https://arxiv.org/abs/2505.19201", "title": "DREAM: 利用细化的目标特征和熵自适应交叉注意力融合进行多模态推测性解码", "title_en": "DREAM: Drafting with Refined Target Features and Entropy-Adaptive Cross-Attention Fusion for Multimodal Speculative Decoding", "authors": "Yunhai Hu,Tianhua Xia,Zining Liu,Rahul Raman,Xingyu Liu,Bo Bao,Eric Sather,Vithursan Thangarasa,Sai Qian Zhang", "background": "推测性解码（SD）已成为加速大语言模型（LLMs）自回归生成的强大方法。尽管它在LLMs中的应用已有一定进展，但在视觉-语言模型（VLMs）中的整合仍处于初级阶段。本文引入了DREAM，一种新的针对VLMs的推测性解码框架，通过三个关键创新点：1) 基于交叉注意力的机制，将目标模型的中间特征注入草稿模型以提升对齐度；2) 根据注意力熵自适应选择中间特征，以指导有效的草稿模型训练；3) 视觉标记压缩，以减少草稿模型的延迟，来实现在多模态解码中的高效、准确和并行加速。", "innovation": "DREAM框架包含三个关键创新点：1) 基于交叉注意力的机制，将目标模型的中间特征注入草稿模型；2) 根据注意力熵自适应选择中间特征，引导有效的草稿模型训练；3) 视觉标记压缩，减少草稿模型延迟。这些创新使得DREAM能够实现多模态解码的高效、准确和并行化。", "conclusion": "实验结果表明，DREAM在不同VLMs模型上的应用，如LLaVA、Pixtral、SmolVLM和Gemma3，可实现高达3.6倍的解码加速，并且在推理吞吐量和推测性草稿接受长度方面显著优于以前的SD基线。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.20352", "html_url": "https://arxiv.org/abs/2507.20352", "title": "RMTBench: 通过多轮以用户为中心的扮演角色基准测试LLMs", "title_en": "RMTBench: Benchmarking LLMs Through Multi-Turn User-Centric Role-Playing", "authors": "Hao Xiang,Tianyi Tang,Yang Su,Bowen Yu,An Yang,Fei Huang,Yichang Zhang,Yaojie Lu,Hongyu Lin,Xianpei Han,Jingren Zhou,Junyang Lin,Le Sun", "background": "大型语言模型（LLMs）在扮演角色应用中显示出巨大的潜力，但对这些能力的评估变得至关重要且具有挑战性。现有的基准主要采用以角色为中心的方法，将用户角色互动简化为孤立的问答任务，未能反映真实世界的应用。", "innovation": "RMTBench 是一个全面的用户为中心的双语扮演角色基准，包含80个不同的角色和超过8000个对话轮次。该基准通过基于用户动机构造对话，而不是角色描述，确保与实际用户应用的对齐。同时，构建了一个真实的多轮对话仿真机制，通过精心选择的评估维度和基于LLM的评分系统，捕捉用户与角色之间的复杂对话意图。通过将焦点从角色背景转向用户意图的实现，RMTBench 为评估LLMs的角色扮演能力提供了一个更有效的框架。", "conclusion": "RMTBench 通过提供一个多轮以用户为中心的扮演角色基准，填补了学术评估与实际应用需求之间的差距，为评估LLMs的角色扮演能力提供了更有效的框架。相关的代码和数据集将在不久的将来公开。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.19634", "html_url": "https://arxiv.org/abs/2507.19634", "title": "MCIF：来自科学演讲的多模态跨语言指令遵循基准", "title_en": "MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks", "authors": "Sara Papi,Maike Züfle,Marco Gaido,Beatrice Savoldi,Danni Liu,Ioannis Douros,Luisa Bentivogli,Jan Niehues", "background": "大型语言模型的近期进展推动了多模态LLMs（MLLMs）的发展，这些模型能够整合文本、语音和视觉元素。随着MLLMs从单一语言、单一任务的系统演进为通用的指令遵循模型，一个关键领域在于评估它们的跨语言和多模态能力，特别是在长文本与短文本上下文中的评价。然而，现有的基准测试在多维度评估模型性能方面有所欠缺：它们通常只限于英语，主要集中在单一模态上，依赖于简短的文本片段，或者缺乏人类注释，这限制了对模型跨语言、多模态及任务复杂性之间综合性能的全面评估。为了弥补这些不足，我们引入了MCIF（Multimodal Crosslingual Instruction Following），这是第一个基于科学研究演讲的多语言人类注释基准，旨在评估跨语言与跨模态环境中的指令遵循能力，涵盖短文本和长文本输入。MCIF涉及三种核心模态——语音、视觉和文本——和四种多样的语言（英语、德语、意大利语和中文），这使得模型在跨语言、多模态条件下解释指令及结合多模态上下文信息的能力得到了全面评价。该基准公开发布，旨在促进MLLMs的研究进步和开放性发展。", "innovation": "MCIF是首个基于科学研究演讲的多语言人类注释基准，用于评估跨语言、多模态环境下的指令遵循能力，涵盖语音、视觉和文本三种模态及英语、德语、意大利语和中文四种语言。这解决了当前基准在多语言、多模态及长时间段文本分析上的不足，提供了全面的模型评估框架。MCIF以CC-BY 4.0许可证发布，鼓励在多模态LLM领域中的开放研究与进步。", "conclusion": "MCIF为评估多模态LLMs提供了全面的跨语言和多模态评估框架，通过科学演讲数据增强了跨语言和视觉语言交互的评估，填补了现有基准在多语言一致性多模态评估中的空白。该数据集的发布推动了多模态LLMs在跨语言和跨模态指令遵循方面的研究进展，并为研究者提供了一个系统化的评估工具。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09874", "html_url": "https://arxiv.org/abs/2508.09874", "title": "Memory Decoder：一种预训练的插件式记忆组件", "title_en": "Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models", "authors": "Jiaqi Cao,Jiarui Wang,Rubin Wei,Qipeng Guo,Kai Chen,Bowen Zhou,Zhouhan Lin", "background": "大型语言模型（LLMs）在通用语言任务中表现出强大的能力，但将它们适应特定领域仍然是一个挑战。现有的方法如域自适应预训练（DAPT）需要成本高昂的全参数训练，并且容易出现灾难性遗忘。同时，检索增强生成（RAG）由于昂贵的最近邻搜索和更长的上下文引致推理延迟。", "innovation": "本文提出了Memory Decoder，这是一种可插拔的预训练记忆组件，能够在不改变原始模型参数的情况下实现高效领域适应。Memory Decoder使用一个小的变压器解码器来学习模仿外部非参数检索器的行为。经过训练后，Memory Decoder可以无缝地集成到任何一个使用相同分词器的预训练语言模型中，无需特定的模型修改。实验结果表明，Memory Decoder可以使Qwen和Llama模型在生物医学、金融和法律三个专门领域中实现有效的自适应，平均减少困惑度6.17点。", "conclusion": "总体而言，Memory Decoder引入了一种以特别预训练的记忆组件为中心的新范式，用于领域特定的适应。这种记忆架构可以以插件的形式集成，能够在目标领域的多个模型中持续增强性能。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19614", "html_url": "https://arxiv.org/abs/2508.19614", "title": "LFD：在检索增强生成中融合层数以利用外部知识", "title_en": "LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation", "authors": "Yang Sun,Zhiyong Xie,Dan Luo,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li,Lixin Zou", "background": "检索增强生成（RAG）将外部知识纳入大型语言模型（LLMs），提高其实现下游任务的适应性，并支持信息更新。最近实验证明，向检索到的相关文档注入噪声反而能更好地利用外部知识并提高生成质量，尽管这看似反直觉，但在实践中难以应用，却使我们可以更好地控制和分析LLMs如何整合外部知识。为了实现这一目标，本文通过干预噪声注入过程，将LLMs划分为多个层级，浅层专注于局部上下文建模，中间层关注长距离外部事实知识的整合，深层层依赖参数内部知识。", "innovation": "提出了一种称为Layer Fused Decoding（LFD）的解码策略。LFD直接将中间层的表示与最终层的解码输出结合，完全利用外部事实知识。同时，引入了内部知识分数（IKS）标准来确定最优中间层。", "conclusion": "在多个基准测试中，实验结果表明LFD有助于RAG系统更有效地呈现检索到的上下文知识，且成本极低。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17536", "html_url": "https://arxiv.org/abs/2508.17536", "title": "辩论还是投票：多agent大型语言模型中哪种方式能获得更好的决策？", "title_en": "Debate or Vote: Which Yields Better Decisions in Multi-Agent Large Language Models?", "authors": "Hyeong Kyu Choi,Xiaojin Zhu,Sharon Li", "background": "多agent辩论（MAD）作为一种通过协作推理提高大型语言模型性能的有前途的范式已经出现。尽管取得了重要进展，但MAD有效性的关键驱动因素仍不清楚。研究者决定将MAD拆分为两个关键组件——多数投票和agent间辩论，并评估它们各自的贡献。通过在七个自然语言处理（NLP）基准测试上进行广泛的实验，他们发现仅多数投票就解释了MAD通常归因的大部分性能提升。研究者提出了一个理论框架，将辩论建模为一个随机过程，证明它会导致agent信念轨迹上的鞅，暗示辩论本身并不提高预期正确性。基于这些洞见，他们证明了定向干预可以通过偏向信念更新以纠正错误，从而真正提升辩论的有效性。", "innovation": "将MAD拆分为多数投票和agent间辩论，并通过理论框架展示了这些组件的贡献。提出了一种理论框架，将辩论建模为随机过程，证明了辩论并不提高预期正确性，并通过定向干预手段提高了辩论的有效性。", "conclusion": "尽管MAD有潜力，但在许多实际场景中，简单的集成方法仍然是更强且更可靠的选择。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19529", "html_url": "https://arxiv.org/abs/2508.19529", "title": "Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding", "title_en": "Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding", "authors": "Bowen Sun,Yujun Cai,Ming-Hsuan Yang,Yiwei Wang", "background": "离散扩散语言模型在文本生成任务中展现出了强大的潜力，但由于标准的监督微调（SFT）与它们的半自回归推理存在不匹配，即训练时随机掩盖整个响应中的所有标记，而推理时按顺序生成固定大小的块，这种不匹配导致了躁噪声前缀和泄漏性后缀，这些都偏离了所期望的块级似然。", "innovation": "提出了块级SFT方法，这种方法将响应划分为固定大小的块，在每一步中选择一个激活块进行随机掩盖，冻结所有前面的标记，并完全掩盖未来的标记。仅在激活块上计算损失，这直接模仿了块级解码过程。研究表明，在MATH、MetaMathQA和GSM8K数据集上的实验显示，在相同计算或标记预算条件下，块级SFT在一致性方面优于传统SFT。进一步的研究和消融实验确认了性能提升源自训练和推理的一致性，而非偶然的掩码效果。这一结果突出了在扩散基础语言模型中匹配监督粒度与解码程序的重要性。", "conclusion": "块级SFT通过确保训练与推理的一致性，提升了扩散语言模型在文本生成任务中的性能，并强调了在扩散模型中监督粒度与解码过程匹配的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.01832", "html_url": "https://arxiv.org/abs/2508.01832", "title": "MLP Memory: 一种预训练检索器的记忆模块", "title_en": "MLP Memory: A Retriever-Pretrained Memory for Large Language Models", "authors": "Rubin Wei,Jiaqi Cao,Jiarui Wang,Jushi Kai,Qipeng Guo,Bowen Zhou,Zhouhan Lin", "background": "大型语言模型在增强事实准确性和知识利用方面面临着非参数检索增强生成（RAG）与参数微调方法如LoRA之间的根本权衡：非参数RAG方法虽然可以灵活访问外部知识，但存在推理延迟高和浅层集成的问题；而参数微调方法虽然可以更好地集成知识，但存在灾难性遗忘和泛化能力下降的问题。因此，研究旨在提出一种参数化的小型记忆模块，以便在不依赖明确文档访问的情况下学习检索模式。通过预训练多层感知机（MLP）来模仿整个预训练数据集上的$K$最近邻（$k$NN）检索器行为，这一模型可以捕捉基于检索的知识访问的好处，并以完全参数化的形式进行整合。", "innovation": "该研究提出了一种轻量级参数模块MLP Memory，通过预训练MLP来模仿整个预训练数据集上的$K$最近邻（$k$NN）检索器行为，创建了一个可微分的记忆组件。该模块通过简单的概率插值与Transformer解码器集成，分别在WikiText-103和Web数据集上实现了17.5%和24.1%的扩展增益；在五个问答基准测试上实现了12.3%的相对改进；在九个通用自然语言处理任务上实现了5.2分的绝对增益；并且减少了高达10分的记忆幻想。此外，MLP Memory比RAG方法提供了更快的推理速度并保持了更高的准确性。", "conclusion": "我们的研究结果表明，参数化学习检索模式可以弥补高效推理与有效知识访问之间的差距，提供了一种RAG和微调方法之外的实用替代方案。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19678", "html_url": "https://arxiv.org/abs/2505.19678", "title": "视觉定向语言：减少大型视语言模型幻觉的条件互信息校准解码策略", "title_en": "Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs", "authors": "Hao Fang,Changle Zhou,Jiawei Kong,Kuofeng Gao,Bin Chen,Shu-Tao Xia", "background": "大型视语言模型（LVLMs）容易出现幻觉，即生成的回应虽然在语义上看似合理，但与输入图像的相关性很低。先前的研究表明，这一问题主要源自LVLMs过度依赖语言先验而忽视解码时的视觉信息。已有方法主要针对文本标记采样的问题，本研究提出了一种新颖的条件点间互信息（C-PMI）校准解码策略，以增强生成文本与输入图像之间的互依存关系，从而减少幻觉现象。", "innovation": "本研究提出了一种条件点间互信息（C-PMI）校准解码策略，与现有方法仅关注文本标记采样不同，本策略提出了一种联合建模视觉和文本标记对C-PMI的贡献的方法，并将其 hallucination mitigation 形式化为一个多层次优化问题，以最大化互信息。此外，还设计了一种标记净化机制，动态调节解码过程，通过采样与给定图像最相关的文本标记，同时细化对生成响应最相关的图像标记。", "conclusion": "在各种基准测试中的广泛实验表明，所提出的方法显著减少了LVLMs中的幻觉现象，同时保持了解码效率。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.02464", "html_url": "https://arxiv.org/abs/2509.02464", "title": "SpecEval：评估模型对行为规范的遵守情况", "title_en": "SpecEval: Evaluating Model Adherence to Behavior Specifications", "authors": "Ahmed Ahmed,Kevin Klyman,Yi Zeng,Sanmi Koyejo,Percy Liang", "background": "在开发基础模型的公司会公布它们承诺要遵守的行为准则，但尚未明确模型是否真正遵守这些准则。虽然像OpenAI、Anthropic和Google这样的提供者已经发布了详细的规范，描述了希望模型遵循的安全约束和定性特征，但没有进行系统性的审计来检查模型是否遵守这些行为规范。这项研究引入了一个自动化的框架，通过解析行为陈述、生成有针对性的提示并使用模型来评估遵守情况，以建立必要的基线：至少，基础模型应由开发者评估模型一致地满足开发者行为规范。研究团队应用了这一框架，对来自六家开发者的16个模型进行了超过100条行为陈述的评估，发现了系统性不一致，包括高达20%的合规缺口，这凸显了现有模型可能无法完全遵守行为规范的情况。", "innovation": "研究团队开发了一个自动化的评估框架，用于评估模型是否遵守已公布的规范，特别是通过分析行为声明、生成特定提示并对模型进行评估来实现。这种方法的创新在于通过将模型本身作为评判者来实现三向一致性（开发者规范、模型输出、开发者评估模型之间的对应），扩展了以往的生成器验证器一致性方法。这种方法提供了一个必要的基线，证明了模型至少需要在开发者评估模型面前保持行为一致性。", "conclusion": "研究团队应用其方法对多个基础模型进行了评估，发现普遍存在系统性的不合规现象，合规缺口范围在开发企业间差距高达20%，这表明当前模型可能无法充分遵循行为规范。这一研究结果为加强模型行为治理提供了重要视角，表明需要进一步完善现有的指导原则和评估机制。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.15640", "html_url": "https://arxiv.org/abs/2509.15640", "title": "多种语言LLM提示策略在医学英语-越南语机器翻译中的应用", "title_en": "Multilingual LLM Prompting Strategies for Medical English-Vietnamese Machine Translation", "authors": "Nhu Vo,Nu-Uyen-Phuong Le,Dung D. Le,Massimo Piccardi,Wray Buntine", "background": "在越南，医学英语-越南语机器翻译（En-Vi MT）对于医疗保健的访问和沟通至关重要，但越南语属于资源稀缺且研究不足的语言。已有研究试图通过使用多语言LLM不同策略来进行医学领域的翻译工作。", "innovation": "系统性评估了六种不同参数量级（0.5B-9B参数）的多语言LLM在MedEV数据集上的提示策略，对比了零样本、少样本和词典增强的提示方法。研究发现，模型规模是决定性能的主要因素：较大的LLM在零样本情况下表现出色，而少样本提示方法只带来很小的进步。术语感知的线索和基于嵌入的示例检索则在特定领域翻译中持续提高了翻译质量。", "conclusion": "研究强调了多语言LLM在医学En-Vi MT领域中的潜力及其目前的局限性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04462", "html_url": "https://arxiv.org/abs/2509.04462", "title": "对GPT-5在生物医学自然语言处理中的基准测试", "title_en": "Benchmarking GPT-5 for biomedical natural language processing", "authors": "Yu Hou,Zaifu Zhan,Min Zeng,Yifan Wu,Shuang Zhou,Rui Zhang", "background": "生物医学文献和临床叙述对自然语言理解提出了多方面的挑战，包括精确的实体提取、文档合成以及多步骤的诊断推理。该研究扩展了一个统一的基准，以评估GPT-5和GPT-4o在零、一、五次提示下的性能，覆盖了五个核心的生物医学自然语言处理任务：命名实体识别、关系提取、多标签文档分类、摘要和简化。此外，还研究了涉及基础知识、临床推理和多模态视觉理解的九个扩展的生物医学问答数据集。通过标准化提示、固定解码参数和一致的推理管道，对该模型在官方定价下的性能、延迟和按令牌标准化的成本进行了评估。", "innovation": "该研究扩展了统一基准以评价GPT-5和GPT-4o在不同生物医学自然语言处理任务和数据集上的表现，包括命名实体识别、关系提取、多标签文档分类、摘要和简化。研究使用标准化提示和固定解码参数，评估模型性能、延迟和成本，发现GPT-5在推理密集型数据集和多模态问答上表现良好，同时在核心任务中表现优于GPT-4o。此外，研究还揭示了诊断、治疗和推理子类型方面的改进，同时也指出了在边界敏感提取和证据密集型摘要方面仍面临挑战。", "conclusion": "GPT-5 在生物医学问答中的部署准备性能接近，并提供了准确性和经济效率的有利平衡。研究结果支持分层提示策略：直接提示适用于大规模或成本敏感的应用，而在分析复杂或高风险情景中则需要思维链结构化的支持，强调在高精度和事实准确性至关重要的情况下仍需混合解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.16449", "html_url": "https://arxiv.org/abs/2509.16449", "title": "PersonaMatrix: 根据人物意识评估法律摘要的方法", "title_en": "PersonaMatrix: A Recipe for Persona-Aware Evaluation of Legal Summarization", "authors": "Tsz Fung Pang,Maryam Berijanian,Thomas Orth,Breanna Shi,Charlotte S. Alexander", "background": "法律文件往往长而复杂，对普通公民和法律专家来说都难以理解。尽管自动文档概括有潜力提高对法律知识的访问，但现行的任务导向评估者却忽视了不同用户和利益相关方的需求。需要开发一种工具，既能为诉讼律师提供技术性的案件摘要，又能为自行寻求法律帮助的公众提供易于理解的摘要。", "innovation": "提出了PersonaMatrix，一种通过六个用户角色（包括法律和非法律用户）的视角对摘要进行评分的评价框架。同时引入了一个控制维度扭曲的试点数据集，用于美国民事权利案件摘要，该数据集在深度、可访问性和程序细节方面有所不同。此外，还提出了差异化的优化指标（DCI），以揭示人物意识和人物忽视的法官在法律摘要之间不同最优值。", "conclusion": "这项工作有助于改进针对专家和非专家用户的法律AI摘要系统，提高法律知识的可访问性。代码库和数据已公开发布在GitHub上。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.19834", "html_url": "https://arxiv.org/abs/2509.19834", "title": "TianHui：中西医结合特定领域的大型语言模型", "title_en": "TianHui: A Domain-Specific Large Language Model for Diverse Traditional Chinese Medicine Scenarios", "authors": "Ji Yin,Menglan He,Yujie Zhang,Linshuai Zhang,Tingting Ma,Ce Tian,Jie Wu,Lin Xu,Tao Jiang,  ((1) School of Intelligent Medicine, Chengdu University of Traditional Chinese Medicine, Chengdu, China (2) The Acupuncture and Tuina School, Chengdu University of Traditional Chinese Medicine, Chengdu, China (3) Center of Preventive Medicine, Hospital of Chengdu University of Traditional Chinese Medicine, Chengdu, China (4) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China (5) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China)", "background": "在研究环境中，针对中医药（TCM）的领域特定语言模型（Domain-specific LLMs）受到适应性有限、缺乏足够评价数据集和计算资源不足的限制。", "innovation": "本研究提出了一种名为TianHui的专门化TCM语言模型，通过上下文数据集成和领域知识融合构建。研究构建了一个大规模TCM语料库（包括0.97GB的无监督数据和611,312个问答对），并采用了两阶段训练策略，使用了QLoRA、DeepSpeed Stage 2和Flash Attention 2等技术。评估结果显示，TianHui在12个基准中的12个数据集中均表现优异，特别是在APQ、TCMCD、HFR、HCCA、DHPE、TLAW等六个数据集中排名前三。最优配置参数为LoRA rank=128，alpha=256，epoch=4，dropout=0.2，最大长度=2048。TianHui能够系统地保存和扩展应用TCM知识。", "conclusion": "TianHui成功实施，能够系统地保存和扩展应用TCM知识。所有资源已经开源。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.11145", "html_url": "https://arxiv.org/abs/2509.11145", "title": "Text2Mem: 一种统一的内存操作语言，用于内存操作系统", "title_en": "Text2Mem: A Unified Memory Operation Language for Memory Operating System", "authors": "Yi Wang,Lihai Yang,Boyu Chen,Gongyi Zou,Kerun Xu,Bo Tang,Feiyu Xiong,Siheng Chen,Zhiyu Li", "background": "现有的大语言模型代理越来越多地依赖内存来维持长时间的交互，但现有框架仍存在不足。大多数框架仅提供有限的基本操作（如编码、检索和删除），而高级操作（如合并、提升、降低、拆分、锁定和过期）要么缺失或实现不一致。此外，缺乏正式和可执行的内存命令规范，导致不同系统间的规则含义不明且行为不可预测。", "innovation": "我们提出了Text2Mem，这是一种统一的内存操作语言，为自然语言到可靠执行的标准化途径提供了一个标准化路径。Text2Mem定义了一套紧凑而表达性强的操作集合，与编码、存储和检索对齐。每个指令表示为带有必填字段和语义不变性的JSON基于模式实例，解析器将其转换为带类型的操作对象，参数规范化。验证器在执行前确保正确性，而适配器将类型对象映射到SQL原型后端或实际的内存框架。当需要时，集成基于模型的服务（如嵌入式或总结）。所有结果通过统一的执行合同返回。这设计确保了跨异构后端的安全性、确定性和可移植性。此外，我们概述了Text2Mem Bench，这是一种计划中的基准测试，使模式生成与后端执行分离，以进行系统的评估。这些组件共同构成了第一个标准化的内存控制基础。", "conclusion": "这些组件共同构成了第一个标准化的内存控制基础。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02855", "html_url": "https://arxiv.org/abs/2510.02855", "title": "基于约束满足方法的Wordle：新颖启发式方法与跨语言验证", "title_en": "Constraint Satisfaction Approaches to Wordle: Novel Heuristics and Cross-Lexicon Validation", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel", "background": "Wordle 提供了一个算法丰富的环境，用于约束满足问题（CSP）的解决。现有的解算器依赖于信息论熵最大化或基于频率的经验启发式方法，而没有正式的约束处理。本文介绍了第一个针对Wordle的全面CSP公式化及其新型约束感知解算策略。", "innovation": "引入了CSP感知熵，这种熵在约束传播后计算信息增益，而不是在原始候选集中计算。同时引入了概率CSP框架，结合贝叶斯词频先验和逻辑约束。验证了CSP方法在噪声环境下的稳健性，并展示了跨语言验证的有效性。", "conclusion": "通过在2315个英文单词上的评估，CSP感知熵平均猜测次数为3.54，成功率为99.9%，与前向检查相比，表现出统计显著的1.7%改进，且运行时间快46%。跨10%噪声验证保留了5.3个百分点的优势，并建立了新的性能基准，表明结构化谜题解决领域中原理性的约束满足技术优于传统的信息论和基于学习的方法。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.19271", "html_url": "https://arxiv.org/abs/2509.19271", "title": "WolBanking77: Wolof Banking Speech Intent Classification Dataset", "title_en": "WolBanking77: Wolof Banking Speech Intent Classification Dataset", "authors": "Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione", "background": "尽管意图分类模型在近年取得了显著进展，但以往的研究主要集中在资源丰富的语言数据集上，导致资源贫乏的语言和高文盲率地区（如较长口语而较少书面使用的语言）在相关研究中存在差距。例如，在塞内加尔，沃洛夫语是90%人口的母语，但全国文盲率仍高达42%。沃洛夫语在西非地区被10多万人使用。为解决这一问题，本文介绍了沃洛夫语言银行意图分类数据集（WolBanking77），该数据集为学术研究提供了资源，包含9,791条文本句子和超过4小时的语音数据，专注银行业务领域。", "innovation": "本文通过构建面向学术研究的WolBanking77数据集，填补了资源贫困和高文盲率地区语言技术研究的空白。WolBanking77包含9,791条文本句子和超过4小时的语音数据，实验表明在该数据集上使用语音和文本最先进的模型效果非常乐观。此外，本文还深入探讨了该数据集的内容，并就NLP和ASR模型进行了基线F1分数和单词错误率的相关比较。", "conclusion": "WolBanking77数据集的构建和使用对于推进低资源语言的意图分类研究具有重要意义，为相关领域提供了实验基础，同时也促进了语音识别和自然语言处理技术在实际应用中的发展。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07774", "html_url": "https://arxiv.org/abs/2510.07774", "title": "使用评分标准奖励治愈大型语言模型数学推理中的奇迹步骤", "title_en": "Curing Miracle Steps in LLM Mathematical Reasoning with Rubric Rewards", "authors": "Youliang Yuan,Qiuyang Mang,Jingbang Chen,Hong Wan,Xiaoyuan Liu,Junjielong Xu,Jen-tse Huang,Wenxuan Wang,Wenxiang Jiao,Pinjia He", "background": "大型语言模型在数学推理中的训练通常采用基于结果的奖励方式，仅奖励最终答案。但这种模式对奖励作弊高度敏感，导致模型推理能力被大大高估，产生大量不正确的解决方案。这些解决方案通过不合理的推导得出正确答案。", "innovation": "提出了评分标准奖励模型（RRM），这是一种过程导向的奖励函数，能够根据特定问题的评分标准评估整个推理过程。RRM 使用生成式的细粒度奖励（0-1）来明确惩罚逻辑错误并鼓励严格的推理。实验证明，在四个数学基准测试中，基于RRM的训练方法在准确性和可靠性方面都优于仅关注结果的监督。", "conclusion": "本研究强调了奖励推理过程的重要性，可以构建不仅更准确而且更可靠的模型。通过引入RRM，显著提升了在AIME2024中的验证通过率，并减少了奇迹步骤的出现频率。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07686", "html_url": "https://arxiv.org/abs/2510.07686", "title": "测试模型规范揭示语言模型的性格差异", "title_en": "Stress-Testing Model Specs Reveals Character Differences among Language Models", "authors": "Jifan Zhang,Henry Sleight,Andi Peng,John Schulman,Esin Durmus", "background": "大型语言模型（LLMs）越来越多地从AI宪法和模型规范中训练，这些规范确立了行为准则和伦理原则。然而，这些规范面临着内部冲突原则和对细微场景覆盖面不足等关键挑战。本文提出了一种系统的方法来对模型性格规范进行压力测试，自动发现了大量原则矛盾和解释模糊的情况。通过生成复杂的场景，迫使模型在竞争的价值原则之间做出明确的价值取舍。", "innovation": "本文提出了一种系统的方法来对现有的模型规范进行压力测试，通过生成具体场景迫使模型在竞争的价值原则之间做出选择。这种方法使用全面的分类法生成多样化的价值取舍场景，并评估了十二个领先LLM在主要提供商（Anthropic、OpenAI、Google、xAI）中的响应。通过分析不同模型的行为差异，揭示了冲突和模糊的原则，并展示了模型之间的价值观优先级差异。", "conclusion": "在这些场景中，我们发现了超过70,000个表现出显著行为分歧的案例，这些结果强烈预测了模型规范下的潜在问题。并通过实证分析，展示了模型行为的高度分歧是性格规范问题的显著预测因子。此外，还提供了关于当前模型规范中直接矛盾和解释模糊的多种示例问题，并展示了所有研究模型的价值优先级模式和差异。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18684", "html_url": "https://arxiv.org/abs/2510.18684", "title": "MLMA：基于Mamba架构迈向多语言ASR", "title_en": "MLMA: Towards Multilingual ASR With Mamba-based Architectures", "authors": "Mohamed Nabih Ali,Daniele Falavigna,Alessio Brutti", "background": "多语言自动语音识别（ASR）仍然是一个具有挑战性的问题，尤其是在平衡高资源和低资源语言的表现上。尽管序列建模的最新进展表明，除了变压器之外的架构可能在可扩展性和效率方面表现出更优性能。", "innovation": "该论文提出了一种名为MLMA的新方法，利用Mamba架构，一种优化的高效状态空间模型，专门用于长上下文序列处理。MLMA通过Mamba隐式地结合了语言感知条件和共享表示，支持在多种语言下的稳健识别。实验结果显示，MLMA在多语言基准测试中的性能与基于变压器的架构相当，这表明Mamba具有作为扩展性、高效性和精确性强大的多语言ASR支柱的潜力。", "conclusion": "实验结果表明，MLMA在多种标准多语言基准测试中的性能与基于变压器的架构相当，这显示了Mamba作为多语言ASR扩展性、高效性和精确性强大基础的潜在价值。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.17930", "html_url": "https://arxiv.org/abs/2510.17930", "title": "诊断命名实体识别模型拓展中的表示动态", "title_en": "Diagnosing Representation Dynamics in NER Model Extension", "authors": "Xirui Zhang,Philippe de La Chevasnerie,Benoit Fabre(papernest)", "background": "在嘈杂的口语数据中扩展命名实体识别（NER）模型以识别新的个人信息（PII）实体是一个常见的需求。研究发现，同时对标准语义实体（PER、LOC、ORG）和新基于模式的PII实体（EMAIL、PHONE）进行联合微调，对原语义类别的性能影响最小。", "innovation": "通过使用增量学习设置作为诊断工具，研究人员发现两种关键见解。首先，地点实体（LOC）因其表示与新PII的重叠而特别脆弱，因为它共享模式特征（如邮政编码）。其次，研究人员发现了“逆O标签表示漂移”。模型最初训练为将PII模式映射到'O'，阻止了新学习。这个问题只有通过解冻'O'标签分类器才能解决，从而允许背景类进行适应并“释放”这些模式。", "conclusion": "这项工作提供了NER模型适应性的机械诊断，突显了特征独立性、表示重叠以及'O'标签的适应性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.15312", "html_url": "https://arxiv.org/abs/2510.15312", "title": "通过推测解码和NPU协调执行加速移动语言模型", "title_en": "Accelerating Mobile Language Model via Speculative Decoding and NPU-Coordinated Execution", "authors": "Zhiyang Chen,Daliang Xu,Haiyang Shen,Mengwei Xu,Shangguang Wang,Yun Ma", "background": "随着移动设备上使用的大语言模型（LLMs）越来越多，它们需要处理上下文信息以实现个性化和任务感知的生成，从而支持智能助手和UI代理等应用场景。尽管神经处理器的进展大大提高了预填充效率，但逐 token 的生成过程仍然受到高延迟和硬件利用率低的问题，因为这是基于内存限制的特性。因此，为了加速移动设备上的上下文感知文本生成，本工作提出了一种移动推理框架，该框架结合了推测性解码与动态硬件调度。", "innovation": "此研究提出了一个名为‘推测解码和NPU协调执行’的移动推理框架。该框架具有三个协同工作的组件：（1）自适应执行调度，动态平衡预填充和解码阶段之间的计算图；（2）上下文对齐草稿，通过轻量级在线校准当前任务以提高推测效率；（3）硬件高效草稿扩展，重新利用和扩展中间序列以提高处理并行性并减少验证成本。实验结果表明，与现有的移动推理解决方案相比，该框架在生成速度和能效方面分别提高了3.8倍和4.7倍。", "conclusion": "研究表明，通过推测解码和NPU协调执行的移动推理框架在多个智能手机和代表性工作负载上的性能得到了一致改进。这一工作为移动设备上的上下文感知文本生成提供了有效的加速方案，并验证了每个优化组件的贡献。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19167", "html_url": "https://arxiv.org/abs/2510.19167", "title": "You Are Rejected!: 对大型语言模型参加招聘评估的一项实证研究", "title_en": "\"You Are Rejected!\": An Empirical Study of Large Language Models Taking Hiring Evaluations", "authors": "Dingjie Fu,Dianxing Shi", "background": "随着互联网的普及和人工智能技术的快速进步，科技企业每年面临着大量软件和算法工程师的需求。为了高效且有效地从众多申请人中识别出高潜力候选人，这些企业建立了多阶段选拔流程，其中关键包括标准化的录用评价以评估岗位特定的技能。受大型语言模型（LLMs）在编码和推理任务中展现出的能力启发，本研究探讨了一个核心问题：这些模型能否成功通过这些录用评估？", "innovation": "研究使用了领先的标准专业评估问卷，并采用最先进的大型语言模型生成回答，然后对其表现进行评估。尽管人们原先假设大型语言模型适合成为工程师，但研究发现模型生成的答案与公司参考解决方案存在显著差异，所有接受评估的大型语言模型均未能通过招聘评估。", "conclusion": "实证研究表明，所有评估的大型语言模型均未能通过招聘评估，这与人们对大型语言模型的期望不符。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18779", "html_url": "https://arxiv.org/abs/2510.18779", "title": "KAT-Coder 技术报告", "title_en": "KAT-Coder Technical Report", "authors": "Zizheng Zhan,Ken Deng,Xiaojiang Zhang,Jinghui Wang,Huaixi Tang,Zhiyi Lai,Haoyang Huang,Wen Xiang,Kun Wu,Wenhao Zhuang,Minglei Zhang,Shaojie Wang,Shangpeng Yan,Kepeng Lei,Zongxian Feng,Huiming Wang,Zheng Lin,Mengtong Li,Mengfei Xie,Yinghan Cui,Xuxing Chen,Chao Wang,Weihao Li,Wenqiang Zhu,Jiarong Zhang,Jingxuan Xu,Songwei Yu,Yifan Yao,Xinping Lei,C. Zhang,Han Li,Junqi Xiong,Zuchen Gao,Dailin Li,Haimo Li,Jiaheng Liu,Yuqun Zhang,Junyi Peng,Haotian Zhang,Bin Chen", "background": "近年来，大型语言模型 (LLMs) 在自动编码方面的应用取得了进展，模型能够在互动软件开发工作流中自主推理、规划和行动。然而，从静态的文本训练向动态的实际世界自动执行过渡仍然是一个关键的挑战。", "innovation": "该论文提出了KAT-Coder，这是一个大规模的自动代码模型，通过多阶段课程训练，包括中期训练、监督微调（SFT）、强化微调（RFT）以及强化到部署适应。各阶段分别通过真实的软件工程数据和合成的自动交互增强推理、规划和反思能力，构建百万级别的数据集，引入新型多地面真值奖励形式，以及适应生产级 IDE 环境的错误遮蔽 SFT 和树状轨迹训练等创新方法。", "conclusion": "这些阶段使得KAT-Coder能够实现工具使用可靠性、指令对齐以及长上下文推理，形成一个可部署的基础框架，用于实际智能编码代理。KAT 系列 32B 模型 KAT-Dev 已开源，在此链接中可以获取：this https URL"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19733", "html_url": "https://arxiv.org/abs/2510.19733", "title": "Zhyper: 因子超网络用于条件下的大语言模型微调", "title_en": "Zhyper: Factorized Hypernetworks for Conditioned LLM Fine-Tuning", "authors": "M. H. I. Abdalla,Zhipin Wang,Christian Frey,Steffen Eger,Josif Grabocka", "background": "大语言模型（LLM）的条件处理是指让LLM根据特定文化、政治倾向或其他指定语义条件生成内容。不幸的是，通过提示工程并不能保证LLM的行为符合特定的条件，因为预训练和对齐数据集存在归纳偏差。先前的研究主要集中在通过直接调节LoRA权重来进行微调，但这种方法会引入大量参数。这就需要一种更加参数高效的解决方案来实现条件处理的细粒度调节和更好的适应性。", "innovation": "本文提出了一种参数高效的数据因子超网络框架Zhyper，能够从文本描述生成上下文感知的LoRA适配器。实验表明，与当前最先进的基线相比，Zhyper仅使用少至26倍的参数就能达到相当的性能。此外，Zhyper还被扩展到了文化对齐应用中，显示了在跨域场景下的更好泛化能力和对细节上下文值捕捉的改进。", "conclusion": "Zhyper通过因子超网络生成上下文感知的LoRA适配器，实现了条件下的大语言模型微调，相比现有方法具有更高的参数效率和更好的潜在适应性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19782", "html_url": "https://arxiv.org/abs/2510.19782", "title": "通过模型合并方法使多语种模型适应代码混合任务", "title_en": "Adapting Multilingual Models to Code-Mixed Tasks via Model Merging", "authors": "Prashant Kodali,Vaishnavi Shivkumar,Swarang Joshi,Monojit Choudhary,Ponnurangam Kumaraguru,Manish Shrivastava", "background": "本文研究了模型合并作为一种实用的替代传统适应策略的方法，针对代码混合的自然语言处理任务。研究从一个多语种基础模型出发，通过额外的未标记代码混合文本的继续预训练（CPT）、模型合并，以及下游任务的微调（FT），来实现对特定任务的适应。这种方法在英语-印地语（En-Hi）和英语-西班牙语（En-Es）的句子分类任务（情感分析和仇恨言论检测）中进行了评估。研究结果表明，合并模型在F1分数上优于完整的微调和CPT->FT方法，且通过合并数据可以更有效地利用未标记的数据。对于零样本或少样本提示，使用较大的语言模型（如Llama-3.3-70B）的效果不如微调和合并检查点，这表明上下文学习在处理代码混合输入方面的局限性。", "innovation": "本文提出了一种新的适应策略——模型合并，通过这种方法可以从一个原本的多语种基础模型开始，经过未标记代码混合文本的继续预训练、模型合并，再到下游任务的数据微调。这种方法在多个代码混合的自然语言处理任务中取得了优于传统适应方法的结果，同时揭示了在代码混合输入上零样本或少样本提示的能力有限。", "conclusion": "本文总结了针对不同数据和任务集的模型合并适应方法。对于仅标记数据、标记和未标记数据以及仅转移数据等常见数据环境，提供了适应策略的相应建议，并讨论了更大规模模型在扩展任务时的应用和限制。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.12977", "html_url": "https://arxiv.org/abs/2411.12977", "title": "MindForge: 为终身文化学习赋予体感代理理论心智", "title_en": "MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning", "authors": "Mircea Lică,Ojas Shirekar,Baptiste Colle,Chirag Raman", "background": "基于大型语言模型（LLMs）的体感代理，如Voyager，在诸如Minecraft的世界中展现出开放式的才能。然而，即使经过领域特定的微调，使用开放式权重的LLMs仍然在基本任务上表现出色。本文探讨了MindForge，这是一种通过显式视角获取文化的终身学习生成代理框架。按照文化学习的框架，MindForge在Minecraft中进行了传授式和协作式设置条件下的测试，表现出显著的技术树里程碑完成率和独特的物品收集率提升。", "innovation": "文章提出了一种关键创新点：(1) 结构化的理论心智表示，将感知、信念、欲望和行为相关联；(2) 自然的代理间沟通；(3) 多成分记忆系统。MindForge通过这些创新，在Minecraft环境中展现出高级行为，例如专家与新手的知识迁移、协作问题解决以及适应超出分布任务的能力。", "conclusion": "MindForge代理在Minecraft的传授环境中显示出显著的性能优势，即在基本任务中实现3倍的技术树里程碑并收集2.3倍的独特物品。在完全协作设置中，随着沟通次数的增加，两个原本表现不佳的代理显示出更好的性能提升，从而验证了Condorcet陪审团定理。此外，MindForge代理展示了复杂的行为模式，包括专家与新手的知识传递、协作解决问题以及通过累积文化经验适应超出分布的任务。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.02770", "html_url": "https://arxiv.org/abs/2502.02770", "title": "Twilight: 自适应分层Top-$p$剪枝以实现适应性注意力稀疏性", "title_en": "Twilight: Adaptive Attention Sparsity with Hierarchical Top-$p$ Pruning", "authors": "Chaofan Lin,Jiaming Tang,Shuo Yang,Hanshuo Wang,Tian Tang,Boyu Tian,Ion Stoica,Song Han,Mingyu Gao", "background": "利用注意力稀疏性来加速具有长时间上下文的大语言模型（LLMs）已成为一个热门研究话题。然而，当前的算法如稀疏注意力或键值（KV）缓存压缩通常使用固定预算，在部署过程中面临重大挑战，因为它们未能考虑到真实世界场景中准确性和效率之间最佳平衡的动态变化。", "innovation": "本文发现，借用顶-$p$采样（核子采样）到稀疏注意力中可以实现自适应预算。基于此，我们提出Twilight框架，可以在不牺牲现有稀疏注意力算法准确性的情况下引入自适应稀疏性。", "conclusion": "实验证明，Twilight可以通过自适应剪枝最多98%的冗余令牌，使得自注意力操作加速15.4倍，并在端到端每令牌延迟上加速3.9倍。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.01243", "html_url": "https://arxiv.org/abs/2501.01243", "title": "Face-Human-Bench: 多模态助手中的人脸和人类理解的综合基准", "title_en": "Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants", "authors": "Lixiong Qin,Shilong Ou,Miaoxuan Zhang,Jiangning Wei,Yuhang Zhang,Xiaoshuai Song,Yuchen Liu,Mei Wang,Weiran Xu", "background": "人脸和人类是社交互动中的关键元素，广泛出现在日常生活中的照片和视频中。因此，理解人脸和人类的能力对于实现多模态助手的高质量响应和更广泛的应用范围至关重要。目前，多模态助手领域的研究缺乏全面和科学的人脸和人类理解能力评估。因此，本文提出了一个包含三个能力层次的层级能力分类，并基于此分类构建了一个半自动的数据管道，从公开数据集中收集图片和注释，形成了一个新的基准Face-Human-Bench。该基准包括开发集和测试集，每部分有1800个问题，支持英文和中文。", "innovation": "本文首先提出了一种包含三个层次能力的层级能力分类，然后利用这种分类从公共数据集中收集图片和注释，构建了一个半自动数据管道，产生了新的benchmarks。共有25个主流多模态大语言模型（MLLMs）在此基准上进行评估，重点在于能力之间的关联性、目标之间相对位置对性能的影响，以及Chain of Thought（CoT）提示策略的影响，并探讨了多模态大语言模型需要补充的专业模型能力。", "conclusion": "本文构建了名为Face-Human-Bench的新基准，包括了一种全新的人脸和人类理解能力分类，支持中英双语，以及两个数据集，并与25个主流多模态大语言模型进行了评估，揭示了性能变化的规律，证实了该基准的有效性和实用性，同时提出了需要补充的专业模型能力，并将数据集和评估代码开源。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11554", "html_url": "https://arxiv.org/abs/2502.11554", "title": "语音用户界面中的具象流变对话设计趋向", "title_en": "Toward Metaphor-Fluid Conversation Design for Voice User Interfaces", "authors": "Smit Desai,Jessie Chin,Dakuo Wang,Benjamin Cowan,Michael Twidale", "background": "语音用户界面（VUIs）依赖于静态的人类中心元喻，但在多样化的使用场景和用户需求面前往往显得不够灵活。目前的VUI设计通常围绕助手的形式来定型，提供统一的交互风格，这与多样化的使用情境不匹配。", "innovation": "提出了一种名为具象流变设计的新方法，能够根据对话使用场景动态调整元喻表示。该方法对四种关键使用场景——命令、信息寻求、社交性和错误恢复，进行了形式化和层级维度上的元喻映射，并与传统的默认VUI进行对比，证明了具象流变VUI在适应性和互动性方面的优势。", "conclusion": "具象流变设计挑战了“一刀切”的VUI设计范式，证明了这种设计方法能够创建更加适应并引人入胜的人工智能互动体验。然而，研究也揭示了个体在元喻偏好上的差异，强调个性化需求的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.15172", "html_url": "https://arxiv.org/abs/2408.15172", "title": "X-Reflect: 跨映射提示在多模态推荐中的应用", "title_en": "X-Reflect: Cross-Reflection Prompting for Multimodal Recommendation", "authors": "Hanjia Lyu,Ryan Rossi,Xiang Chen,Md Mehrab Tanjim,Stefano Petrangeli,Somdeb Sarkhel,Jiebo Luo", "background": "大型语言模型（LLMs）已被证明能提高项目描述的丰富性，进而提升推荐系统的准确性。然而，大多数现有方法要么仅依靠文本提示，要么采用基本的多模态策略，未能充分利用文本和视觉信息之间的互补信息。当前的推荐系统在处理来自不同模态的数据时缺乏有效的信息整合方法，这限制了推荐系统的效果提升。论文介绍了X-Reflect框架，这是一种用于跨模态推荐任务的创新提示方案，使多模态大型语言模型（MLLMs）能够明确地识别和调和文本和图像之间的支持性和矛盾性信息。通过从不同模态中捕捉精细的洞察，这种方法生成了更为全面和语境丰富的项目表示。X-Reflect已经在两个常用的基准测试上进行了测试，展示了与现有提示基准相比的准确性优势，同时揭示了文本和图像差异性与推荐性能之间的U形关系，表明选择性地使用多模态提示的好处。为了实现高效的实时推理，论文还提出了一种轻量级变体，X-Reflect-keyword，通过使用关键词总结图像内容并更换较小的主干模型，输入长度减少了约50%，但性能仍保持在竞争水平。这表明，整合多模态信息在推荐系统中具有重要意义，并且为提高多模态推荐系统的项目理解能力提供了一种有效方案。", "innovation": "该论文提出了一种创新的多模态提示框架，即X-Reflect，能够使多模态大型语言模型明确识别和调和文本与图像之间的信息一致性。通过这种方法，生成了更全面和语境丰富的项目表示，并显著提高了推荐系统的准确性。此外，它还引入了一种轻量级变体，X-Reflect-keyword，能够以较小的输入长度保持良好的性能。U形关系还表明，适时地运用多模态提示具有优势。", "conclusion": "X-Reflect框架通过跨模态提示解决了多模态大型语言模型的信息整合问题，提高了推荐系统的效果，并揭示了选择性地使用多模态提示的潜在优势。X-Reflect-keyword变体为实现高效的实时推理提供了新的思路，显示了其在保持有效性的同时，显著减少了输入长度。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.09933", "html_url": "https://arxiv.org/abs/2502.09933", "title": "MIR-Bench: 能让你的LLM通过大量的在上下文推理解出复杂模式吗？", "title_en": "MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?", "authors": "Kai Yan,Zhan Ling,Kang Liu,Yifan Yang,Ting-Han Fan,Lingfeng Shen,Zhengyin Du,Jiecao Chen", "background": "模式识别是从例子中识别模式并将其应用于新情况的基本能力，是通用人工智能的关键能力，在心理学和人工智能研究中广泛研究。虽然已经提出了许多基准来衡量大型语言模型（LLMs）的这种能力，并且在少样本（通常少于10个）设置方面进行了大量研究，但是这些基准缺乏评估从长上下文聚合大量信息的能力。另一方面，LLMs的不断增长的上下文长度带来了新的范式——很多样本的在上下文学习（ICL），它可以通过数百到数千个示例来解决新任务而无需昂贵且低效的微调。然而，很多样本的评估通常专注于分类，而流行的长上下文LLM任务，如Needle-In-A-Haystack (NIAH)，很少需要复杂的整合大量信息的能力。", "innovation": "本文提出了MIR-Bench，第一个用于模式识别的很多样本在上下文推理基准，要求LLMs通过输入-输出示例预测基于具有多样数据格式的基本函数的输出。基于MIR-Bench，我们研究了许多新的很多样本在上下文推理问题，包括规模效应、稳健性、归纳推理与演绎推理、检索增强生成（RAG）、编码以进行归纳推理、跨领域泛化性等，并获得了很多有洞察力的发现。", "conclusion": "MIR-Bench填补了少样本设置和长上下文整合能力评估之间的空白，为LLMs在复杂模式识别中的很多样本在上下文推理能力提供了全面的评估工具。通过这一基准，研究人员可以更好地理解LLMs的潜力和局限性，推动该领域的发展。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14667", "html_url": "https://arxiv.org/abs/2505.14667", "title": "AFEPATH：通过早期对齐防止链式思考中的有害推理", "title_en": "SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment", "authors": "Wonje Jeung,Sangyeon Yoon,Minsuk Kahng,Albert No", "background": "大型推理模型（LRMs）已经成为解决复杂问题的强大工具，但它们结构化的推理路径在面对有害提示时可能产生不安全的输出。现有的安全对齐方法可以减少有害输出，但可能会削弱推理深度，特别是在复杂、多步骤的任务中，仍面临高级防线突破攻击的脆弱性。", "innovation": "引入了SAFEPATH，这是一种轻量级的对齐方法，它在受到有害提示时可以通过推理的开头生成一个8个标记组成的短小安全前言，同时在推理过程中的其余部分不进行监督。实验证明，SAFEPATH 在减少有害输出的同时，保持了推理性能。SAFEPATH 以较小的计算成本解决了直接拒绝和SafeChain方法存在的问题，还能实现零样本变体，不需要进一步微调。", "conclusion": "SAFEPATH 和现有的零样本变体通过减少有害响应和阻挡防线突破攻击表现出色。此外，研究进一步分析了现有方法在应用于推理中心模型时的行为，揭示了安全AI研究中的关键差距和新方向。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.13837", "html_url": "https://arxiv.org/abs/2504.13837", "title": "RL确实激励LLMs超越基础模型的推理能力吗？", "title_en": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?", "authors": "Yang Yue,Zhiqi Chen,Rui Lu,Andrew Zhao,Zhaokai Wang,Yang Yue,Shiji Song,Gao Huang", "background": "REINFORCEMENT_LEARNING_WITH_VERIFIABLE_REWARDS(RLVR) 最近在增强大型语言模型 (LLMs) 的推理性能方面取得了显著成效，特别是在数学和编程任务上。RLVR 类似于传统的 RL 协助智能体探索和学习新策略，认为 RLVR 让 LLMs 持续自我提升并获得超越基模型的新推理能力。本研究通过系统地探索不同模型家族、RL 算法和数学、编程及视觉推理基准测试中 RLVR 训练的 LLMs 的推理能力边界，使用大 k 值的 pass@k 作为评估指标进行了批判性的研究。", "innovation": "本研究通过系统地分析不同模型家族、RL 算法和多种推理任务基准测试中 RLVR 训练的 LLMs 的推理能力边界，使用大 k 值的 pass@k 作为评估指标，发现当前的 RLVR 训练设置未能引发本质上新的推理模式。同时，研究指出精简（distillation）能够引入新的推理模式，真正扩展模型的推理能力。", "conclusion": "本研究发现现有的 RLVR 方法尚未充分利用 RL 的潜力以在 LLMs 中激发真正新型的推理能力。这表明需要改进 RL 方法，如持续扩展和多轮交互，以发挥其潜力。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.10465", "html_url": "https://arxiv.org/abs/2505.10465", "title": "Superposition Yields Robust Neural Scaling", "title_en": "Superposition Yields Robust Neural Scaling", "authors": "Yizhou Liu,Ziming Liu,Jeff Gore", "background": "近年来，大型语言模型（LLMs）的成功被观察到依赖于模型越大表现越好的现象，但这一神经网络的规模法则（即损失以幂律形式随模型大小减少）的起源仍有待解答。本文通过Anthropic的玩具模型提出了“表示叠加”这一概念，尝试解释这一现象，并通过控制权重衰减来系统研究损失随模型大小变化的关系。", "innovation": "本文通过引入“表示叠加”概念，提出了一个新颖的解释机制，解释了损失随模型大小变化的幂律关系。通过系统地使用权重衰减控制叠加程度，研究了不同叠加强度下的损失变化规律，验证了开源的LLMs在强叠加状态下运行，并符合这种行为模式下的损失缩放规律，与Chinchilla的尺度法则一致。", "conclusion": "研究结果表明，“表示叠加”是神经网络规模法则的主要驱动力，为理解神经网络规模法则何时能够改进以及何时会失效提供了新的见解。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20612", "html_url": "https://arxiv.org/abs/2505.20612", "title": "Roboflow100-VL:一个面向视觉-语言模型的多领域目标检测基准", "title_en": "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models", "authors": "Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri", "background": "目前，大规模数据训练的视觉语言模型（VLMs）在常见的物体检测上表现优异，但在面对未见过的新类别、任务和影像模态时，这些模型仍然难以进行泛化。现有方法多侧重于大量视觉数据的重新训练，而非直接通过标注指导进行概念对齐。因此，提出了一个新的挑战，即如何有效对齐VLMs以适应新概念的需求.", "innovation": "提出了Roboflow100-VL，这是一个包含100个多模态对象检测数据集的大规模集合，涵盖了不常见于VLM预训练的新概念。通过在零样本、少样本、半监督和完全监督等不同数据环境下对现有顶级模型进行评估，展示了VLMs在面对医疗成像等挑战类数据时的不足，强调了少样本概念对齐的重要性。该研究还提出了CVPR 2025的Foundational FSOD竞赛，并分享了社区见解，最终获胜团队的性能提升了高达17个mAP！", "conclusion": "研究通过Roboflow100-VL展示了当前VLMs在数据泛化性上的不足，并提出了少样本概念对齐的方法，期待未来VLMs能够更好地适应更广泛的应用场景。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.21785", "html_url": "https://arxiv.org/abs/2505.21785", "title": "天生即变压器——预训练是否永葆变压器能力？", "title_en": "Born a Transformer -- Always a Transformer? On the Effect of Pretraining on Architectural Abilities", "authors": "Mayank Jobanputra,Yana Veitsman,Yash Sarrof,Aleksandra Bakalova,Vera Demberg,Ellie Pavlick,Michael Hahn", "background": "transformers在处理序列到序列的任务时存在理论限制，但这些限制在大规模预训练的LLM中是否发挥实际作用仍不清楚。尽管大模型和大规模预训练数据可能有助于克服这些限制，但理论也未经证实。研究人员旨在通过研究一系列基于Liu等人提出的任务，探索这些架构限制在预训练后的表现，并使用Huang等人提出的长度泛化研究框架来提供理论保证。", "innovation": "研究引入了一种基于Liu等人提出的任务研究变体，并通过Huang等人提出的长度泛化框架提供理论保证。实验发现，预训练模型在单词检索方向上偏好，即倾向于正确预测右方而非左方的单词，这一现象可以通过目标微调避免。机制分析揭示了这与预训练变压器中正向与反向电路强度的不同有关。此外，研究还通过实际任务验证了这些发现，表明预训练会增强某些变压器能力，但不会克服基本的长度泛化限制。", "conclusion": "预训练在某些方面增强了变压器的性能，但也展示了固有的长度泛化限制无法克服。研究结果强调，预训练虽能够在某些任务上提升模型能力，但仍存在局限性，不能保证模型完全克服这些限制。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.04210", "html_url": "https://arxiv.org/abs/2506.04210", "title": "在推理模型中，思考更多是否总是有益？测试时扩展的幻象", "title_en": "Does Thinking More always Help? Mirage of Test-Time Scaling in Reasoning Models", "authors": "Soumya Suvra Ghosal,Souradip Chakraborty,Avinash Reddy,Yifu Lu,Mengdi Wang,Dinesh Manocha,Furong Huang,Mohammad Ghavamzadeh,Amrit Singh Bedi", "background": "最近测试时扩展推理模型的趋势（例如OpenAI o1，DeepSeek R1）导致一种普遍的信念，即通过提示（如“稍等”和“让我重新考虑”）来延长推理过程可以提高性能。这引发了自然的问题：延长思考时间是否真的会带来更好的推理？", "innovation": "引入了一种替代的测试时扩展方法，称为并行思考，受到Best-of-N采样的启发。该方法在相同的推理预算内生成多个独立的推理路径，并通过多数投票选择最一致的答案，能够达到比延长思考高达20%的更高精度。", "conclusion": "经过详细的研究，发现延长推理过程的初始成效会随时间下降，因为“过度思考”会减损精确度。观察到的“更多思考”带来的收益并非真正提高推理能力的指标，而是源自模型不确定性和评估指标之间的联系。因此，通过延长思考进行测试时扩展不是有效的利用推理预算的方式。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22651", "html_url": "https://arxiv.org/abs/2505.22651", "title": "Sherlock: 自视知觉语言模型的自我纠错推理", "title_en": "Sherlock: Self-Correcting Reasoning in Vision-Language Models", "authors": "Yi Ding,Ruqi Zhang", "background": "视觉-语言模型（VLMs）在复杂的多模态任务中表现出色，但仍然面临着重大挑战：它们对推理错误非常敏感，需要大量的标注数据或精确的验证器，并且难以在特定领域之外进行泛化。这些限制促使我们探索自我修正作为一种提高基于推理的VLMs的方法。通过深入分析VLMs的自我修正能力，我们发现了关键缺口，并在此基础上提出了Sherlock，一种自我修正和自我改进训练框架，旨在提升模型的自我修正能力，并在少于20,000个随机采样的标注数据中继续自我改进，无需外部监督。", "innovation": "提出了Sherlock，一种包含轨迹级自我修正目标、基于视觉扰动的偏好数据构造方法和动态$\beta$调优的自我修正和自我改进训练框架。通过仅使用20,000个随机采样的标注数据训练，模型能够进一步自我改进，无需外部监督。在Llama3.2-Vision-11B模型上建立的Sherlock在八个基准测试中表现出色，直接生成的准确率为64.1%，经过自我修正后的准确率为65.4%，超越了LLaVA-CoT、Mulberry和LlamaV-o1，同时使用了不到20%的标注数据。", "conclusion": "Sherlock框架能够显著提高视觉-语言模型的推理能力，并且展示了在少数据情况下的优越性能，为解决VLMs当前存在的挑战提供了新的思路。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15034", "html_url": "https://arxiv.org/abs/2505.15034", "title": "RL Tango: 一起强化生成器和验证器的语言推理", "title_en": "RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning", "authors": "Kaiwen Zha,Zhengqi Gao,Maohao Shen,Zhang-Wei Hong,Duane S. Boning,Dina Katabi", "background": "近期，强化学习（RL）已成为增强大规模语言模型（LLMs）推理能力的一种有吸引力的方法，其中LLM生成器由验证器（奖励模型）引导。当前用于LLM的RL后训练方法通常使用的验证器是固定的（规则基于的或冻结的预训练）或通过监督微调（SFT）进行区分性训练。这些设计容易受到奖励作弊的影响，并且在其训练分布之外泛化能力较差。为了克服这些限制，我们提出了Tango这种方法架，它使用RL同时训练LLM生成器和验证器，并交互进行。", "innovation": "Tango的核心创新在于它使用生成式、过程级别的LLM验证器，通过RL进行训练，并与生成器一起进化。重要的是，验证器仅基于结果级别的验证正确奖励进行训练，而无需明确的过程级别注释。这种通过RL训练的生成式验证器表现出比确定性或SFT训练验证器更好的稳健性和泛化能力，促进了生成器和验证器的有效相互强化。大量实验表明，Tango的两个组成部分在不同规模模型中均取得了最佳结果：生成器在五个比赛级别的数学基准测试和四个具有挑战性的领域外推理任务中均取得了最佳性能，而验证器在ProcessBench数据集中表现最好。特别地，两个组件在最难的数学推理问题上表现尤为出色。", "conclusion": "Tango框架在不同规模的模型中均取得了最佳结果。生成器在五个比赛级别的数学基准测试和四个具有挑战性的领域外推理任务中均取得了最佳性能，而验证器在ProcessBench数据集中表现最好。特别地，两个组件在最难的数学推理问题上表现尤为出色。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.07031", "html_url": "https://arxiv.org/abs/2506.07031", "title": "HauntAttack: 当攻击依随推理而形影不离", "title_en": "HauntAttack: When Attack Follows Reasoning as a Shadow", "authors": "Jingyuan Ma,Rui Li,Zheng Li,Junfeng Liu,Heming Xia,Lei Sha,Zhifang Sui", "background": "新兴的大型推理模型（LRMs）在数学和推理任务中表现出色，展现了出色的推理能力。然而，提升推理能力并暴露内部推理过程也引入了新的安全漏洞。如何在增强推理能力的同时解决安全问题成为了一个关键问题，尤其是在推理过程中嵌入有害指令的情况下，LRMs是否会更容易受到推理模式下的‘脱缰’攻击？", "innovation": "为了探讨这一问题，作者提出了一种名为HauntAttack的新颖且通用的黑盒对抗攻击框架，该框架系统地将有害指令嵌入到推理问题中。具体而言，作者修改了现有问题的核心推理条件，插入有害指令，从而使模型逐步导向不安全的输出。实验结果显示，HauntAttack在11种LRMs上的平均攻击成功率达到了70％，并实现了与最强先前基线相比12个百分点的绝对提升。进一步分析表明，即使是最先进的安全对齐模型也高度易受基于推理的攻击，这为未来模型开发中的推理能力和安全性平衡提供重要启示。", "conclusion": "作者的研究揭示了即使是最先进的安全对齐模型也高度易受基于推理的攻击，强调了在增强推理能力的同时加强安全措施的必要性。该研究通过引入HauntAttack框架，不仅验证了这类攻击的可能性，也为未来的研究提供了新的方向和挑战。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23883", "html_url": "https://arxiv.org/abs/2505.23883", "title": "BioCLIP 2: 从分级对比学习中衍生出的特性", "title_en": "BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning", "authors": "Jianyang Gu,Samuel Stevens,Elizabeth G Campolongo,Matthew J Thompson,Net Zhang,Jiaman Wu,Andrei Kopanev,Zheda Mai,Alexander E. White,James Balhoff,Wasila Dahdul,Daniel Rubenstein,Hilmar Lapp,Tanya Berger-Wolf,Wei-Lun Chao,Yu Su", "background": "大规模训练的基座模型展示了显著的衍生行为，能够在初始训练目标之外学习新的能力。研究者们在大规模对比视图语言训练中发现这种衍生行为于生物视觉模型中。为了实现这一目标，他们首次创建了一个名为TreeOfLife-200M的大型数据集，其中包括了2.14亿张生物图像，这是迄今为止最大和最多样化的生物有机体图像数据集。通过在TreeOfLife-200M上训练BioCLIP 2模型，能够区分不同的物种。尽管训练目标狭隘，BioCLIP 2仍能应用于多项生物学视觉任务并达到极高的准确性。研究者们在学习嵌入空间中发现了这些衍生特性，在跨物种层面，不同物种的嵌入分布与功能和生态意义保持一致；在同一物种层面，内物种变异性（如生活阶段和性别）以与跨物种差异正交的方式被更好地保留和分离。对于这些衍生特性的成因，研究者提供了形式化的证明和分析，解释了分级监督和对比目标如何促使这些衍生特性的发展。研究发现表明，随着训练数据规模的扩大，这些特性变得越来越关键，导致了一个具有生物学意义的嵌入空间的形成。", "innovation": "提出了通过大规模分级对比学习实现生物视觉模型衍生特性的方法，即首次创建了TreeOfLife-200M生物图像数据集，并在其中训练了BioCLIP 2模型。研究提供了形式化的证明和分析，解释了分级监督和对比目标如何驱使这些特性的发展。研究结果表明，随着训练数据量的增加，这些特性变得越来越显著，从而形成了一个具有生物学意义的嵌入空间。", "conclusion": "实验和结果表明，BioCLIP 2模型通过大规模的分级对比学习和特定的团队任务能够衍生出生物视觉模型中的新特性，并且这些特性随数据量增加变得越来越显著，从而形成具有生物学意义的嵌入空间。这一发现提供了理解大规模训练模型衍生行为的新视角，并具有广泛的生物学应用前景。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.04586", "html_url": "https://arxiv.org/abs/2508.04586", "title": "当前AI会议模式不可持续！诊断集中式AI会议危机", "title_en": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference", "authors": "Nuo Chen,Moming Duan,Andre Huikai Lin,Qian Wang,Jiaying Wu,Bingsheng He", "background": "人工智能（AI）会议对于推进研究、共享知识和促进学术社区具有重要意义。然而，它们的迅速扩张已经使集中的会议模式变得越来越不可持续。本文通过数据驱动的分析，诊断了一个结构性危机，该危机威胁到科学传播、公平性和社区福祉的基础目标。该论文识别了四个关键压力点：（1）科学上，每名作者的发表率在过去十年中翻了一倍多，每年超过4.5篇论文；（2）环境上，单一会议的碳足迹超过其东道城市日常排放量；（3）心理上，71%的在线社区讨论反映了负面情绪，35%提到了心理健康问题；（4）后勤上，顶级会议如NeurIPS 2024的参会人数开始超出场地容量。这些压力表明，该系统与核心使命不相匹配。", "innovation": "本文提出了Community-Federated Conference（CFC）模式，将同行评议、展示和社交网络分离成全球协调但本地组织的组成部分，为AI研究提供一个更可持续、更具包容性和更具弹性的未来路径。", "conclusion": "该模型旨在解决当前AI会议面临的系统性问题，使其重新实现与核心使命的一致性。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.15235", "html_url": "https://arxiv.org/abs/2509.15235", "title": "ViSpec：利用视觉意识推测解码加速视觉语言模型", "title_en": "ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding", "authors": "Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen", "background": "推测解码是一种广泛应用于加速大型语言模型（LLMs）推理的技术，但在视觉语言模型（VLMs）中的应用仍然较少探索。现有的方法仅实现了有限的加速效果（<1.5倍）。随着多模态能力逐渐成为大规模模型的核心，这一差距变得越来越显著。因此，本文提出了一种专门为VLMs设计的新颖框架——Vision-Aware Speculative Decoding（ViSpec），以有效加速其推理速度。", "innovation": "提出了一种名为ViSpec的新颖框架，该框架通过引入轻量级的视觉适配器模块来压缩图像标记，将其与模型的注意力机制无缝集成，同时保留原始图像的定位信息。此外，还通过修改提示生成了扩展的数据集，以增强多模态的一致性。这种新的训练策略有效地缓解了模型直接利用目标模型隐藏状态以实现快速学习的风险。", "conclusion": "实验结果表明，ViSpec实现了迄今为止VLM推测解码的第一个显著加速。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.13992", "html_url": "https://arxiv.org/abs/2506.13992", "title": "AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science", "title_en": "AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science", "authors": "An Luo,Xun Xian,Jin Du,Fangqiao Tian,Ganghua Wang,Ming Zhong,Shengchun Zhao,Xuan Bi,Zirui Liu,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Mingyi Hong,Jie Ding", "background": "大型语言模型（LLMs）已在数据科学工作流程的自动化方面取得了重要进展。然而，人们尚未清楚LLMs能否像人类数据科学家那样利用外部领域知识进行批判性思考。为了探讨这一问题，作者提出了AssistedDS（辅助数据科学），一个旨在系统评估LLMs处理表数据预测任务中领域知识能力的基准测试。AssistedDS通过合成的具有明确生成机制的数据集和实际的Kaggle竞赛测试LLMs，每个数据集都配有专门整理的帮助性和对抗性文档，以提供数据清理、特征工程和模型选择的领域特定见解。研究团队对当前最先进的LLMs进行了评估，测试了它们辨别和应用有益与有害领域知识的能力，评估了提交的有效性、信息召回率和预测性能。", "innovation": "该研究创新性地设计了AssistedDS基准测试，区分了合成数据集和真实世界竞赛数据，通过专门整理的帮助性和对抗性文档来评估LLMs处理领域知识的能力。该测试不仅展示了当前模型在应对对抗性信息时的关键问题，还强调了未来研究中开发更强大、知识敏感的数据科学自动化系统的必要性。", "conclusion": "研究结果表明，LLMs通常在引入对抗性信息时会无批判地接受提供的信息，极大地影响了其预测性能。帮助性指导措施往往不足以抵消有害信息的负面影响。Kaggle数据集的处理中，LLMs还存在时间序列数据处理错误、特征工程不一致以及正确解释分类变量的问题。研究结论指出了当前模型在批判性评价和利用专家知识方面存在的巨大差距，突显了未来研究的重要方向。所有数据和代码已在公开链接准备好，供研究人员进一步参考和使用。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08396", "html_url": "https://arxiv.org/abs/2510.08396", "title": "FlyLoRA: Boosting Task Decoupling and Parameter Efficiency via Implicit Rank-Wise Mixture-of-Experts", "title_en": "FlyLoRA: Boosting Task Decoupling and Parameter Efficiency via Implicit Rank-Wise Mixture-of-Experts", "authors": "Heming Zou,Yunliang Zang,Wutong Xu,Yao Zhu,Xiangyang Ji", "background": "低秩调整（LoRA）是一种广泛使用的参数高效微调方法，适用于基础模型，但它存在参数干扰的问题，导致性能不佳。尽管基于Mixture-of-Experts（MoE）的LoRA变体在单任务指令微调中降低了任务内的相关性显示出一定的潜力，但它们引入了额外的路由参数，并且在任务间干扰问题严重的多任务模型合并中依然效果不佳。", "innovation": "受苍蝇嗅觉电路的启发，我们提议了一种名为FlyLoRA的新模型，作为一种隐式的基于MoE的LoRA变体，引入了：(1) 在上向投影矩阵中的按秩专家激活，以及(2) 一个隐式的路由器，该路由器结合了专家路由和下向投影，其中固定稀疏随机投影矩阵替代了传统的密集可训练版本。此设计通过消除显式路由器的需求解决了任务内解耦和计算效率之间的权衡问题，由于随机矩阵的正交性质，天生具有缓解任务间干扰的效果。广泛的实验在四个领域展示了对现有方法的一致性性能改进。FlyLoRA还展示了一种如何从生物结构中汲取灵感以推动AI技术创新的例子。", "conclusion": "FlyLoRA在四个领域展示了相对于现有方法的性能改进，并暗示了基于生物结构的启发式设计可以为AI技术带来新机遇。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09721", "html_url": "https://arxiv.org/abs/2510.09721", "title": "LLM-赋能自主系统软件工程中的基准和解决方案综合概览", "title_en": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "authors": "Jiale Guo,Suizhi Huang,Mei Li,Dong Huang,Xingsheng Chen,Regina Zhang,Zhijiang Guo,Han Yu,Siu-Ming Yiu,Pietro Lio,Kwok-Yan Lam", "background": "大型语言模型（LLMs）在软件工程中的整合推动了从传统基于规则的系统向能够解决复杂问题的自主代理系统的转变。然而，系统性的进步受到缺乏对基准和解决方案之间如何相互关联的全面理解的阻碍。为此，该论文通过提供LLM驱动软件工程的全面分析填补了这一空白，分析评价方法和解决方案范式。该研究回顾了超过150篇近期论文，并提出了两大维度的分类体系：（1）按照基于提示、微调和代理的范式分类的解决方案；（2）包括代码生成、翻译和修复等任务的基准。研究还展示了从简单提示工程到融合规划、推理、记忆机制和工具增强等复杂能力的自主系统的发展演变。该研究通过统一的工作流图明确展示了从任务说明到交付成果的流程，展示了不同解决方案范式如何应对各种复杂程度的需求。", "innovation": "本研究首次全面分析LLM驱动软件工程，并提出了一个新的分类体系。研究通过共同关联50多个基准与其相应解决方案策略，帮助研究人员确定适合不同评估标准的最佳途径。此外，研究还指出了研究中的关键空白，并提出了未来的研究方向，包括多代理协同、自进化的系统和形式验证的整合。", "conclusion": "本综述为LLM驱动的软件工程的进步提供了一个基础指南。作者维护了一个GitHub仓库，将不断更新审核和相关论文。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11570", "html_url": "https://arxiv.org/abs/2510.11570", "title": "利用各种技巧劫持基于推理的安全防护栏", "title_en": "Bag of Tricks for Subverting Reasoning-based Safety Guardrails", "authors": "Shuo Chen,Zhen Han,Haokun Chen,Bailan He,Shengyun Si,Jingpei Wu,Philip Torr,Volker Tresp,Jindong Gu", "background": "近年来，大型推理模型（LRMs）如deliberative alignment等基于推理的安全防护措施已经展示了强大的防御能力，有效抵御了模型脱缰攻击。这类防护措施通过利用LRMs的推理能力，在生成最终响应之前评估用户输入的安全性，尤其是能够检测到隐藏在脱缰方法中的有害意图，并拒绝协助。然而，研究发现这些基于推理的安全防护措施在细微的输入提示操纵下极其脆弱，一旦被劫持可能导致更加严重的后果。研究揭示了这些防护措施的一个关键弱点：只需在输入中添加少量模板关键字，就能成功绕过看似强大的防护措施，而导致明确且有害的响应。", "innovation": "研究引入了一种涵盖白盒、灰盒和黑盒攻击范围内的多种脱缰方法，这些方法包括简单模板操作到全自动优化。这些攻击方法不仅能大规模地实施，而且在各种基准测试中取得了惊人的成功率（例如，在gpt-oss系列模型上的在线API服务和本地主机模型中均超过90%的成功率）。实验验证了这些漏洞是系统性的，突显了为开源LRMs加强对齐技术以防止恶意滥用的紧迫需求。研究还开源了相关代码，以便进一步研究和改进相关措施。", "conclusion": "研究表明基于推理的安全防护措施存在系统性漏洞，尽管当前的基于推理的防护措施能够有效抵御脱缰攻击，但仍易受简单模板关键字操纵的影响。为此，研究提出了多种攻击方法，揭示了防护系统的脆弱性，并强调了开发更强大的对齐技术以防止恶意滥用的必要性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19840", "html_url": "https://arxiv.org/abs/2510.19840", "title": "基于Fourier变换的ResNet50 GAN指纹检测", "title_en": "Fourier-Based GAN Fingerprint Detection using ResNet50", "authors": "Sai Teja Erukude,Viswa Chaitanya Marella,Suhasnadh Reddy Veluru", "background": "从生成对抗网络(GANs)生成的逼真图像的迅速增加，为图像取证和需要可靠内容真实性的工业系统带来了严峻挑战。", "innovation": "该研究通过频率域分析和深度学习结合的方法，解决了StyleGAN生成图像与真实图像区别的问题。具体包括使用二维离散傅里叶变换(2D DFT)将图像转换到频率域，在此域中，细微的周期性伪像变得可检测，然后训练一个ResNet50神经网络来区分真实和合成的图像。实验表明，基于频率域的模型在准确率和AUC值上显著优于直接在空间域图像上训练的等效模型。", "conclusion": "GAN生成的图像具有独特的频率域特征或“指纹”，提出的该方法强调结合信号处理技术和深度学习在数字取证及增强工业AI系统可信度的应用潜力。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11851", "html_url": "https://arxiv.org/abs/2510.11851", "title": "Deep Research Brings Deeper Harm", "title_en": "Deep Research Brings Deeper Harm", "authors": "Shuo Chen,Zonggen Li,Zhen Han,Bailan He,Tong Liu,Haokun Chen,Georg Groh,Philip Torr,Volker Tresp,Jindong Gu", "background": "大型语言模型（LLMs）驱动的深度研究（DR）代理可以通过分解任务、检索在线信息和生成详细报告来执行复杂的多步研究。然而，LLMs 可能被误用，带来更大的风险，特别是在生物安全等高风险、知识密集型领域，DR 代理可以生成包含详细禁忌知识的正式报告。即使一个单一的有害查询被独立的 LLM 拒绝，DR 代理也能生成详细且危险的报告，从而揭示了独特的高风险，需要更深入的安全分析。现有的针对 LLMs 的 jailbreak 方法无法有效暴露 DR 代理的独特风险。", "innovation": "研究提出了两种新的 jailbreak 策略：计划注入（Plan Injection）和意图劫持（Intent Hijack）。计划注入策略将恶意子目标注入到代理的计划中；意图劫持则将有害查询重新框架为学术研究问题。通过在不同的 LLM 和各种安全基准上进行广泛实验，包括通用和生物安全禁忌提示，实验揭示了三个关键发现：1. LLM 的对齐在 DR 代理中经常失败，有害的学术表述可以劫持代理意图；2. 多步骤规划和执行削弱了对齐，揭示了提示级防护措施无法解决的系统性漏洞；3. DR 代理不仅绕过了拒绝，还生成了比单独 LLM 更连贯、更专业且更危险的内容。这些结果表明，DR 代理存在基本对齐错误，需要针对 DR 代理制定更好的对齐技术。", "conclusion": "研究揭示了大型语言模型驱动的深度研究代理存在基本对齐问题，并呼吁制定针对这些代理的更好对齐技术。实验结果表明，DR 代理不仅能够绕开拒绝，还能生成更加连贯、专业且危险的内容，这比单独的 LLM 更加危险。因此，需要改进的对齐技术来解决这些问题，同时进行更深入的安全分析，以应对 DR 代理带来的独特风险。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19955", "html_url": "https://arxiv.org/abs/2510.19955", "title": "使用对比学习的转换多视图3D形状特征", "title_en": "Transformed Multi-view 3D Shape Features with Contrastive Learning", "authors": "Márcus Vinícius Lobo Costa,Sherlon Almeida da Silva,Bárbara Caroline Benato,Leo Sampaio Ferraz Ribeiro,Moacir Antonelli Ponti", "background": "计算机视觉方法在从2D图像识别3D对象时存在挑战，通常需要大量标注数据和依赖于可能忽略关键形状关系的卷积神经网络（CNNs）。现有的前沿骨干网络在处理3D形状特征表示学习时也面临挑战。", "innovation": "本文通过将视网膜变换器（ViTs）架构与现代对比学习目标相结合，展示了在多视图3D分析任务中取得的显著成果。通过使用视网膜变换器和对比学习，研究克服了传统CNNs在捕捉关键形状关系方面的局限性，提高了3D物体识别的准确性。", "conclusion": "本研究通过实验证明，结合视网膜变换器和对比学习目标可以有效改进3D形状表示学习，实现在下游任务中的多视图3D分析，特别是在使用监督对比损失如ModelNet10数据集上的准确率达到约90.6%。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18631", "html_url": "https://arxiv.org/abs/2506.18631", "title": "ReDit: 奖励抖动优化大型语言模型策略优化", "title_en": "ReDit: Reward Dithering for Improved LLM Policy Optimization", "authors": "Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu", "background": "DeepSeek-R1 通过基于规则的奖励系统增强了大型语言模型（LLM）的推理能力。然而，这种奖励系统往往是离散的，并且实验观察表明，离散奖励会导致梯度异常、优化不稳定和收敛缓慢的问题。为解决这一问题，本文提出了一种名为 ReDit（奖励抖动）的方法，通过向离散奖励信号中添加简单的随机噪声来抖动奖励信号，从而在学习过程中持续提供探索性梯度，使得梯度更新更加平滑，加快了收敛速度。注入的噪声还引入了平坦奖励区域的随机性，鼓励模型探索新的策略并逃脱局部最优解。实验表明，ReDit 在多种任务上的效果和效率显著提升。平均而言，ReDit 在仅约 10% 的训练步骤下达到了与纯 GRPO 相当的表现，并且即使训练时间类似，还额外提高了 4% 的性能。可视化结果显示 ReDit 显著缓解了梯度问题，并提供了理论分析进一步验证这些优势。", "innovation": "提出了 ReDit 方法，通过向离散奖励信号中添加简单随机噪声来抖动奖励信号，以此在学习过程中提供连续的探索性梯度，从而提高策略优化过程中的平滑度和收敛速度。", "conclusion": "ReDit 方法不仅在多种任务上表现出了与纯 GRPO 相当的性能，而且在相同训练时间内还提高了 4% 的性能。此外，通过理论分析进一步验证了该方法的优势，其效果显著改善了梯度问题。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20011", "html_url": "https://arxiv.org/abs/2510.20011", "title": "通过在线标签平滑提高医学影像预测信心", "title_en": "Improving Predictive Confidence in Medical Imaging via Online Label Smoothing", "authors": "Kushan Choudhury,Shubhrodeep Roy,Ankur Chanda,Shubhajit Biswas,Somenath Kuiry", "background": "深度学习模型，尤其是卷积神经网络，在医学图像分类方面取得了显著成果。然而，这些模型经常会产生过于自信的预测，这可能削弱其在关键医疗保健环境中的可靠性。传统的标签平滑提供了一种简单的方法来减少这种过度自信，但它未能通过同等对待所有非目标类别来考虑类别之间的关系。", "innovation": "本研究探讨了使用在线标签平滑（OLS），这是一种动态方法，在整个训练过程中根据模型自身的预测模式调整软标签。我们使用大型RadImageNet数据集和三种广泛使用的架构（ResNet-50、MobileNetV2和VGG-19）对OLS进行了评估。结果显示，与标准训练方法（包括硬标签、常规标签平滑和无教师知识蒸馏）相比，OLS在Top-1和Top-5分类精度方面始终具有优势。此外，OLS还导致更紧凑且分离良好的特征嵌入，表明提高了表示学习。", "conclusion": "研究表明，OLS不仅增强了预测性能，而且还提高了校准，使其成为在医学成像领域开发可信赖人工智能系统的实用和有效解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20016", "html_url": "https://arxiv.org/abs/2510.20016", "title": "基于鱼眼成像的统一检测管道在稳健交通 surveillance 中的目标检测", "title_en": "A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance", "authors": "Neema Jakisa Owor,Joshua Kofi Asamoah,Tanner Wambui Muturi,Anneliese Jakisa Owor,Blessing Agyei Kyem,Andrews Danyo,Yaw Adu-Gyamfi,Armstrong Aboah", "background": "鱼眼相机提供了一种有效解决宽区域交通监控问题的方案，能够从单一视角捕捉大面积视野。但是，鱼眼图像中存在的强烈径向失真和非均匀分辨率等特性给标准物体检测器带来了很大挑战，尤其是在图像边界附近，物体的外观表现严重受损。", "innovation": "本文提出了一种针对鱼眼图像中这些条件下的目标检测框架，采用简单有效的预处理和后处理管道来增强整个图像中检测的一致性，尤其是在严重失真区域。通过对多款最新的检测模型进行训练，并使用集成策略组合它们的输出，从而提高总体检测准确性。", "conclusion": "本文的方法在2025年AI City Challenge Track 4中取得了F1分数0.6366的好成绩，排名第六十二支队伍中的第八位，表明我们的框架有效解决了鱼眼图像固有的问题。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20027", "html_url": "https://arxiv.org/abs/2510.20027", "title": "极值视图：用于超出分布相机姿态的新型视图合成的3D高斯脉冲滤波器", "title_en": "Extreme Views: 3DGS Filter for Novel View Synthesis from Out-of-Distribution Camera Poses", "authors": "Damian Bowness,Charalambos Poullis", "background": "在使用3D高斯脉冲（3DGS）模型从显著超出训练数据分布的相机位置进行查看时，通常会遇到明显的视觉噪声。这些伪影是由于这些外推区域缺乏训练数据，导致模型无法准确预测这些区域的密度、颜色和几何信息。", "innovation": "我们提出了一种新颖的实时渲染感知滤波方法，它可以有效地减轻由于各向异性方向引起的不确定性和不稳定性。这种方法直接解决了生成不确定性的核心问题，使得3D重建系统即使用户自由导航到原始训练视角之外也能保持高视觉保真度。", "conclusion": "实验评估表明，我们的方法在视觉质量、真实性和一致性方面都显著优于基于神经辐射场（NeRF）的方法如BayesRays。更重要的是，我们的滤波方法可以无缝集成到现有的3DGS渲染管道中，无需进行繁琐的后处理重新训练或微调。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19981", "html_url": "https://arxiv.org/abs/2510.19981", "title": "FutrTrack：一种用于三维多对象跟踪的摄像机-LiDAR融合变换器", "title_en": "FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking", "authors": "Martha Teiko Teye,Ori Maoz,Matthias Rottmann", "background": "提出了FutrTrack框架，它是一个基于模块化摄像机-LiDAR多对象跟踪框架，通过引入基于变换器的平滑器和融合驱动的追踪器，建立在现有3D检测器的基础上。FutrTrack借鉴了基于查询的跟踪框架，采用多模态两阶段变换器精炼和追踪流水线。该融合追踪器整合了来自多个摄像机和LiDAR的多模态顶部视图（BEV）融合特征，而不需要显式的运动模型。在跟踪前，通过在移动窗口上进行时序平滑器来精炼目标序列的边界框，以改进轨迹、减少抖动并提高空间一致性。FutrTrack在nuScenes和KITTI上的评估表明，与以往单传感器方法相比，基于查询的变换器跟踪方法受益于多模态传感器特征，提高了三维多目标跟踪的性能。", "innovation": "FutrTrack框架通过引入基于变换器的平滑器和融合驱动的追踪器，提出了一种基于多模态传感器的创新性解决方案，提高了三维多目标跟踪的性能。它采用多模态两阶段变换器精炼和追踪流水线，并整合来自多个摄像机和LiDAR的多模态BEV融合特征。此外，通过时序平滑器来精炼目标序列的边界框，以提高轨迹质量和空间一致性，从而在nuScenes和KITTI基准测试集上展现出色性能。", "conclusion": "FutrTrack框架在nuScenes测试集上实现了74.7的aMOTA，表现出了与基于神经网络的方法相似的精度，同时减少了身份切换。该方法提供了一个有效的框架，即使在数据有限且无需预训练的情况下，也可以改进基于变换器的追踪器，与其它神经网络方法竞争。"}
{"llm_update_time": "20251026", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19338", "html_url": "https://arxiv.org/abs/2510.19338", "title": "每个注意力都重要：一种高效的长上下文推理混合架构", "title_en": "Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning", "authors": "Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou", "background": "在长上下文推理场景中，模型的计算和I/O开销巨大。为了降低这些成本，研究者们尝试优化模型架构，结合线性注意力和softmax注意力机制，提高模型的效率和性能。", "innovation": "提出了Ring-linear模型系列，包括Ring-mini-linear-2.0和Ring-flash-linear-2.0。这些模型通过混合使用线性注意力和softmax注意力机制，将模型参数和激活量减少，同时在训练效率上也实现了显著提升。与大型密集模型相比，降低推理成本近10倍，与原始Ring系列相比，成本降低超过50%。", "conclusion": "经过对不同注意力机制比例的系统性探索，确定了当前最优的模型结构。通过使用自主研发的高性能FP8算子库linghe，整体训练效率提高了50%。得益于训练和推理引擎算子的高度对齐，模型在强化学习阶段能够长期保持高效优化，并在多个复杂推理基准测试中保持了最佳性能。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20071", "html_url": "https://arxiv.org/abs/2510.20071", "title": "事件驱动的图像重建方法之滤波器基础重建", "title_en": "Filter-Based Reconstruction of Images from Events", "authors": "Bernd Pfrommer", "background": "从移动事件摄像机的事件中重建强度图像是一个具有挑战性的任务，通常使用部署在图形处理单元上的神经网络来解决。传统的方案复杂且依赖于GPU计算，而本文介绍了一种更简单的方法，即基于滤波器的异步重建（FILTBAR）。这种方法利用数字IIR滤波器整合强度变化，并通过新颖的算法检测旧像素以减少重建噪声，最终通过高斯滤波器模糊处理旧像素，从而提高图像质量。", "innovation": "与大多数现有方法不同，FIBAR方法是异步的，允许在任意时间读取图像。FIBAR使用现代笔记本电脑CPU可以运行约每秒140 (42)百万事件，具体取决于启用或未启用空间滤波。此外，FIBAR通过实验展示了其图像重建的差异与基于神经网络的方法（FireNet）之间的对比。", "conclusion": "研究结果表明，尽管FIBAR的图像重建比神经网络方法更噪音且会出现鬼影图像，但仍然对于某些特定任务（例如检测标志牌）足够。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20077", "html_url": "https://arxiv.org/abs/2510.20077", "title": "自适应变换双边张量低秩表示法用于聚类", "title_en": "Data-Adaptive Transformed Bilateral Tensor Low-Rank Representation for Clustering", "authors": "Hui Chen,Xinjie Wang,Xianchao Xiu,Wanquan Liu", "background": "张量低秩表示（TLRR）在图像聚类方面已经取得了显著的成功。然而，现有的大多数方法依赖固定的变换，对噪声的鲁棒性较差。", "innovation": "本文提出了一个新颖的自适应变换双边张量低秩表示模型（TBTLRR），引入了一个数据自适应的张量核范数，通过学习任意的酉变换，提高对全球相关性的捕捉。同时，利用潜在张量数据的双边结构，TBTLRR能够利用图像样本和特征之间的局部相关性。此外，TBTLRR结合了$\frac{1}{2}$-范数和Frobenius范数正则化项，以更好地处理复杂噪声。", "conclusion": "通过所提出的非凸模型，开发了一个高效的优化算法并提供了理论收敛性。广泛的实验验证了TBTLRR在聚类方面优于现有最先进的方法。代码将在此处发布：this https URL"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20087", "html_url": "https://arxiv.org/abs/2510.20087", "title": "Endoshare: 开源解决方案去标识化和管理手术视频", "title_en": "Endoshare: A Source Available Solution to De-Identify and Manage Surgical Videos", "authors": "Lorenzo Arboit,Dennis N. Schneider,Britty Baby,Vinkle Srivastav,Pietro Mascagni,Nicolas Padoy", "background": "基于视频的评估以及手术数据科学能够促进手术培训、研究和质量改进。然而，由于手术视频录制格式各异和视频分享相关的隐私问题，这在实际应用中受到了限制。", "innovation": "提出了Endoshare，这是一种开源的跨平台应用程序，用于合并、标准化和脱敏微创手术中的内窥镜视频。该应用程序遵循软件开发周期，并采用了迭代的用户中心设计反馈机制。在分析阶段，内部临床医生和计算机科学家基于十个可用性准则进行调查，以识别出关键需求并指导基于隐私的设计架构。测试阶段则使用同一准则与技术接受模型（TAM）构建相结合的方法，评估了易用性和采用程度，并通过不同硬件配置下的基准测试进行了补充。", "conclusion": "Endoshare 提供了一个透明且易于使用的标准化和隐私保护的手术视频管理流程。为了将其部署为可替代的专有系统，还需要进行合规性认证和更广泛的互操作性验证。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20029", "html_url": "https://arxiv.org/abs/2510.20029", "title": "BrainPuzzle:结合物理和数据驱动的重建方法在跨颅超声断层成像中的应用", "title_en": "BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for Transcranial Ultrasound Tomography", "authors": "Shengyu Chen,Shihang Feng,Yi Luo,Xiaowei Jia,Youzuo Lin", "background": "跨颅超声成像因头骨与脑组织声速差异大以及大面积探头耦合困难而具有挑战性。传统的基于物理的全波形反演（FWI）受限于头骨引起的衰减、模态转换和相位畸变导致的弱信号，以及全孔径阵列在临床中不可行引起的不完整空间覆盖。纯数据驱动的方法虽然能够直接从原始超声数据中学习，但在处理骨骼复杂的非线性和非局部波传播时往往无法建模，导致在低信噪比和稀疏阵列条件下生成的声速图具有解剖上合理但定量偏倚的特点。该研究旨在通过重建准确的声速图来实现定量的跨颅超声成像，作为解决方案，提出了BrainPuzzle框架，结合了物理建模与机器学习。该框架通过逆时移成像和基于图的注意力单元将多角度采集的数据融合，提高了成像质量和准确性，同时使用部分阵列获取策略提高了可行性和耦合性，克服了阵列缺失的问题，在两种合成数据集中的实验表明，BrainPuzzle在声速重建的准确性和图像完整性方面表现出色。", "innovation": "BrainPuzzle采用了一种新颖的混合两阶段框架，结合了物理建模与机器学习。在第一阶段，使用逆时移成像处理多角度采集的数据，即使在低信噪比下也能保留结构细节。在第二阶段，采用基于图的注意力单元的变压器增强解码器将这些数据融合成一个连贯且定量准确的声速图像。此外，该研究提出了一种部分阵列获取策略，使用移动低计数换能器集提高了可行性和耦合性，同时利用混合算法弥补了阵列缺失的问题。这为跨颅定量超声成像的进步提供了潜力。", "conclusion": "BrainPuzzle框架在声速重建的准确性和图像完整性方面表现出色，通过结合物理建模与机器学习技术，成功克服了跨颅超声成像中的技术挑战，为跨颅定量超声成像的进步奠定了基础。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20126", "html_url": "https://arxiv.org/abs/2510.20126", "title": "物理引导融合以增强快速移动小物体稳健的3D跟踪", "title_en": "Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects", "authors": "Prithvi Raj Singh,Raju Gottumukkala,Anthony S. Maida,Alan B. Barhorst,Vijaya Gopu", "background": "尽管计算机视觉在一般物体检测和跟踪方面取得了显著进展，但对于快速移动的小物体的检测和跟踪问题却鲜有研究。本研究关注使用RGB-D相机解决快速移动小物体的检测和跟踪挑战，特别是在三维空间中的应用.", "innovation": "本文提出了一个新颖的系统结合基于深度学习的检测与基于物理的跟踪算法，以克服现有方法的局限性。具体贡献包括：(1) 综合设计用于3D空间内快速移动小物体检测和跟踪的系统；(2) 开发了一种创新的基于物理的跟踪算法，该算法结合了运动方程以处理异常值和漏检；(3) 设计了一个异常检测与修正模块，显著提高了在遮挡和快速方向变化等具有挑战性场景下的跟踪性能.", "conclusion": "实验在自定义的兵乓球数据集上评估了所提系统的性能。结果表明，与基于卡尔曼滤波器的追踪器相比，该系统的平均位移误差降低了70%。该系统对于提高自主平台上机器人感知能力有重要的实际应用价值，并证实了结合基于物理的模型与深度学习方法在实时3D检测和跟踪小物体方面的有效性."}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20134", "html_url": "https://arxiv.org/abs/2510.20134", "title": "重访logit分布以实现可靠的out-of-distribution检测", "title_en": "Revisiting Logit Distributions for Reliable Out-of-Distribution Detection", "authors": "Jiachen Liang,Ruibing Hou,Minyang Hu,Hong Chang,Shiguang Shan,Xilin Chen", "background": "out-of-distribution (OOD)检测对于确保开放世界应用中深度学习模型的可靠性至关重要。现有后处理方法尽管效率高且易于部署，但往往未能充分利用模型logits空间中丰富的信息。", "innovation": "提出了一种新颖的后处理OOD检测方法LogitGap，该方法明确利用最大logit与剩余logits之间的关系以增强同分布（ID）样本与OOD样本之间的可分性。通过一个训练无的方法自动识别最具有信息量的logits以提高性能。", "conclusion": "通过对视觉语言和纯视觉模型的广泛实验，LogitGap方法在多种OOD检测场景和基准测试中均取得了最优性能。相关代码已开源。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20092", "html_url": "https://arxiv.org/abs/2510.20092", "title": "注意卷积：结合自注意力的表达能力和卷积的效率", "title_en": "Attentive Convolution: Unifying the Expressivity of Self-Attention with Convolutional Efficiency", "authors": "Hao Yu,Haoyu Chen,Yan Jiang,Wei Peng,Zhaodong Sun,Samuel Kaski,Guoying Zhao", "background": "自注意力机制已成为现代视觉骨干的基石，具备超越传统卷积的强大表达能力。然而，其二次复杂性成为实践应用中的关键瓶颈。尽管卷积提供了一线的复杂性和强大的视觉先验，但当前的努力并未实现自注意力的性能提升，现有现代版本未能充分捕捉自注意力的本质表达能力。因此，本研究重新审视了卷积神经网络的设计，旨在探讨自注意力相较于卷积的优势原则。", "innovation": "发现了两种根本性的见解，即自注意机制（SA）的自适应路由原则和边缘抑制原则。并基于这两种原则，提出了注意卷积（ATConv）这一卷积算子的新的设计原理。研究表明，仅仅使用3x3的卷积核，ATConv在基本视觉任务中表现优越，提升了各种自注意力机制。进一步，通过引入AttNet，一种以ATConv为基础的CNN家族，展示了仅27M参数可实现84.4%的ImageNet-1K最优精度，并在基于扩散过程的图像生成中提升了性能。", "conclusion": "本研究通过重新设计卷积网络，引入了注意卷积（ATConv），利用自注意力的自适应路由和边缘抑制原则，结合卷积网络的效率，显著提升了视觉任务性能。同时，通过AttNet展示了仅依靠小尺度卷积核即能取得优异效果，为视觉模型设计提供了新视角。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20132", "html_url": "https://arxiv.org/abs/2510.20132", "title": "基于单图像逆图像渲染的光线场生成", "title_en": "Inverse Image-Based Rendering for Light Field Generation from Single Images", "authors": "Hyunjun Jung,Hae-Gon Jeon", "background": "光线场计算概念已在场景表示中证明其优势，支持了新颖视角的真实渲染以及如对焦和浅景深等摄影效果。尽管光线场在光线流计算方面效果显著，获取光线场需要高计算成本或专业设备，比如复杂的相机设置和特殊的微透镜阵列。本文旨在拓宽其应用范围，提出了一种仅从单张图像生成光线场的新型视图合成方法——逆图像渲染。", "innovation": "本文提出了一种新颖的逆图像渲染方法，能够仅从单张图像生成光线场。该方法通过神经渲染管道实现，该管道能够存储源光线的光线流，通过交叉注意力计算它们的关系，并预测目标光线的颜色。这种方法在不需要重新训练或微调的情况下能够处理各种挑战性数据集，并且优于现有的新型视图合成方法。", "conclusion": "本文提出的逆图像渲染方法能够仅从单张图像合成新的视图，并且在处理各种挑战性数据集时表现出色，无需额外的训练或调整，优于现有的新型视图合成方法。该方法有望进一步推广光线场技术的应用范围和适用性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20093", "html_url": "https://arxiv.org/abs/2510.20093", "title": "StableSketcher：通过视觉问答反馈增强基于像素的草图生成的扩散模型", "title_en": "StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback", "authors": "Jiho Park,Sieun Choi,Jaeyoon Seo,Jihie Kim", "background": "尽管最近在扩散模型方面的进展显著提升了生成图像的质量，但在合成基于像素的手绘草图方面仍然存在挑战，这是一种代表性的抽象表达形式。现有的扩散模型在生成手绘草图时面临着诸多挑战，特别是在保持手绘特征和提高与提示的一致性方面效果不佳。为了克服这些挑战，该论文提出了一种名为StableSketcher的新框架，通过优化变分自编码器的隐编码解码，使其能够更好地捕捉草图的特征。此外，研究团队还引入了一种新的基于视觉问答的奖励函数，以提高文本-图像对齐和语义一致性，从而进一步提升生成草图的质量和风格的一致性。而针对现有数据集仅依赖图像-标签对的局限性，该研究还提出了名为SketchDUO的新数据集，其中包括实例级的草图配对文本和问答对，以补充现有数据集的不足。", "innovation": "提出的StableSketcher框架通过优化扩散模型以更好地生成高保真度的手绘草图，并引入了基于视觉问答的新奖励函数来改进文本-图像对齐和语义一致性。同时，还推出了新的数据集SketchDUO，旨在填补现有数据集在图像-标签对有限表达信息方面的空白，该数据集包含实例级别的草图及其配对的描述和问答对，使模型可以更好地理解和生成手绘草图。", "conclusion": "通过大量的实验验证了StableSketcher和新引入的数据集SketchDUO的优越性，生成的草图在风格保真度上得到了提升，相较于基线模型Stable Diffusion，在与提示的对齐度上有更好的表现。此外，该研究公开提供的代码和数据集也将有利于该领域的进一步研究和发展。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20155", "html_url": "https://arxiv.org/abs/2510.20155", "title": "PartNeXt: 一种用于细粒度和层次化3D部件理解的下一代数据集", "title_en": "PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding", "authors": "Penghao Wang,Yiyang He,Xin Lv,Yukai Zhou,Lan Xu,Jingyi Yu,Jiayuan Gu", "background": "理解物体的构成部件对推进计算机视觉、图形学和机器人技术至关重要。虽然PartNet等数据集推动了3D部件理解的进步，但依靠无纹理几何和专家依赖注释的限制性，限制了其可扩展性和实用性。", "innovation": "我们引入了PartNeXt，这是一种下一代数据集，包含超过23,000个高质量、带纹理的3D模型，并配有细致且层次化的部件标签，覆盖50个类别。我们基于PartNeXt在两大任务上进行基准测试：(1) 不分类别的部件分割，当前最先进的方法（如PartField, SAMPart3D）难以处理细致和叶层部件；(2) 3D部件中心问答，这是一个用于3D-LLMs的新基准，揭示了开放词汇部件定位的显著差距。而且，使用PartNeXt训练Point-SAM比使用PartNet取得了显著的进步，强调了该数据集在质量和多样性上的优越性。通过结合可扩展的注释、纹理感知标签和多任务评估，PartNeXt为结构化3D理解的研究开辟了新途径", "conclusion": "PartNeXt通过综合可扩展注释、纹理意识标签和多任务评估，为结构化3D理解研究开辟了新途径，展示了其在细粒度和层次化3D部件理解中的优越性和广泛适用性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20162", "html_url": "https://arxiv.org/abs/2510.20162", "title": "TOMCAT：测试时的综合知识积累以提高组成零样本学习", "title_en": "TOMCAT: Test-time Comprehensive Knowledge Accumulation for Compositional Zero-Shot Learning", "authors": "Xudong Yan,Songhe Feng", "background": "现有的零样本学习方法在测试时由于标签空间分布的变化而导致性能下降，这种变化是由于以前未见过的新组成重新组合而成的属性和对象所致。因此，现有方法无法有效应对新型组成体的识别，特别是当这些组成体包含了以前未见过的属性和对象的重新组合时。", "innovation": "本文提出了一种名为TOMCAT的新方法，该方法在测试时通过从未监督数据中积累文本和视觉模态的综合知识来更新多模态原型，进而增强了对未见过的组成的识别能力。此外，TOMCAT引入了一个自适应更新权重来控制原型调整的程度，并引入了一个动态优先级队列来存储高置信度的图像以获取历史图像中的视觉知识，用于推理。该方法通过多模态协作表示学习对文本和视觉原型进行对齐，以保持语义一致性，提升了整体性能。", "conclusion": "TOMCAT方法在四个基准数据集上实现了最先进的性能，无论是在封闭世界还是开放世界上。未来的进一步研究将探索如何在更复杂的场景中提高该方法的实际适用性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20042", "html_url": "https://arxiv.org/abs/2510.20042", "title": "揭示盲点：生成图像模型中的文化偏见评估", "title_en": "Exposing Blindspots: Cultural Bias Evaluation in Generative Image Models", "authors": "Huichan Seo,Sieun Choi,Minki Hong,Yi Zhou,Junseo Kim,Lukman Ismaila,Naome Etori,Mehul Agarwal,Zhixuan Liu,Jihie Kim,Jean Oh", "background": "生成图像模型可以产生令人印象深刻的视觉效果，但经常歪曲文化。现有工作主要在文本到图像（T2I）系统中研究文化偏见，而图像到图像（I2I）编辑器则被忽视。本文通过跨越六个国家的统一评估，在8个类别/36个子类别的框架以及时代意识提示中填补这一空白，针对T2I生成和I2I编辑进行标准协议下的一致性诊断。", "innovation": "本文提出了一种框架，结合标准自动指标、具有文化意识的检索增强VQA以及来自本土评审员的专家人类判断，用开放模型和固定设置进行跨国界、跨时代和跨类别的评估。本文通过标准化数据、提示和人类评价协议的发布，提供了一个可重复、以文化为中心的基准，用于诊断和跟踪生成图像模型中的文化偏见问题。", "conclusion": "本研究揭示了三个重要发现：(1) 在无国家意识提示下，模型默认呈现全球北方、现代偏好的描绘，抹平了国家间的差异；(2) 迭代的I2I编辑即使在传统指标保持不变或改善的情况下，也降低了文化的真实性；(3) I2I模型应用表面特征（如调色板调整、通用道具）而非时序一致、上下文相关的改变，常保留源身份目标。这些结果强调了在当前系统中文化敏感性编辑的不可靠性。通过发布标准化数据、提示和人类评价协议，我们提供了诊断和跟踪生成图像模型中文化偏见的可重复、以文化为中心的基准。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20158", "html_url": "https://arxiv.org/abs/2510.20158", "title": "单目视觉8D姿态估计用于机动自行车和骑车人", "title_en": "Monocular Visual 8D Pose Estimation for Articulated Bicycles and Cyclists", "authors": "Eduardo R. Corral-Soto,Yang Liu,Yuan Ren,Bai Dongfeng,Liu Bingbing", "background": "在自动驾驶中，骑自行车的人属于交通安全关键的易受伤害的道路使用者（VRU）类别，准确估计其姿态对于骑自行车人横穿意图分类、行为预测和碰撞避免至关重要。与刚性物体不同，机动自行车由通过关节连接起来的可移动刚性部分组成，并受运动结构约束。6D姿态方法可以估计刚性自行车的3D旋转和平移，但当自行车的转向角度和脚踏板角度变化时，6D就变得不够了。这是因为：1）改变机动自行车的姿势会导致其3D边界框变化；2）3D框的方向不一定与确定实际预期行进方向的车把方向对齐。因此，该研究引入了一种基于单张RGB图像的机动自行车和骑车人类别级别的8D姿态估计方法，通过加入车把旋转和脚踏板角度的估计，极大提升了姿态估计的细粒度。同时，通过将合成数据与真实图像数据混合训练，模型能够泛化到实际图像中。作者通过准确度评估表明，该方法在8D姿态参数估计上取得了与最先进的6D姿态估计器相当的结果，该方法使用刚性标准对象模板进行匹配。", "innovation": "研究提出了基于单目RGB图像的8D姿态估计方法，可用于机动自行车和骑车人，能够更精确地估计姿态，包括车把旋转和脚踏板角度，从而提供更详细的自行车姿态状态和行进方向。该方法通过混合使用合成数据和真实图像进行训练，以提高泛化能力，并展示了与最新的6D姿态估计器相当的性能。", "conclusion": "研究证明了8D姿态估计模型在机动自行车和骑车人的姿态估计中的有效性，展示了在单目视觉条件下实现更准确的姿态估计的潜力。实验结果表明，该方法能够有效提高自行车方向的估计准确度，对未来自动驾驶场景中的自行车驾驶者行为理解和碰撞避免具有重要意义。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20178", "html_url": "https://arxiv.org/abs/2510.20178", "title": "PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching", "title_en": "PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching", "authors": "Yun Wang,Junjie Hu,Qiaole Dong,Yongjian Zhang,Yanwei Fu,Tin Lun Lam,Dapeng Wu", "background": "时空一致的深度估计对实际应用如增强现实至关重要。现有的方法试图通过聚合时空信息来解决长期时空一致性建模难题，但在有效性和计算成本之间存在根本性的权衡。", "innovation": "提出了一种名为PPMStereo的Pick-and-Play Memory (PPM)模块，用于动态立体匹配。PPM模块包含两个阶段：'pick'过程选择最相关的帧，'play'过程适应性加权选择的帧进行时空聚合，从而维护一个紧凑但高度信息性的记忆缓冲区。", "conclusion": "PPMStereo在准确性和时序一致性方面表现出色，实验结果表明其在Sintel数据集上的性能优于现有方法，且计算成本较低。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20165", "html_url": "https://arxiv.org/abs/2510.20165", "title": "IB-GAN: 使用信息瓶颈生成对抗网络的去纠缠表示学习", "title_en": "IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks", "authors": "Insu Jeon,Wonkwang Lee,Myeongjang Pyeon,Gunhee Kim", "background": "本文介绍了一种基于生成对抗网络（GAN）的无监督模型，旨在通过利用信息瓶颈（IB）框架来优化GAN，从而实现去纠缠表示学习。该模型在dSprites和Color-dSprites数据集上的实验表明，IB-GAN在去纠缠能力上与当前最先进的η-VAEs相当，并且在CelebA和3D Chairs数据集上，其生成样本的视觉质量和多样性通常优于η-VAEs和InfoGAN。", "innovation": "提出的IB-GAN模型将信息瓶颈框架应用于GAN的优化过程中，通过在生成器中引入中间层来限制输入与生成输出之间的互信息，使得生成器能够以去纠缠和可解释的方式利用潜在空间。", "conclusion": "实验结果表明，IB-GAN在dSprites和Color-dSprites数据集上达到了与当前最先进的η-VAEs相当的去纠缠能力，并且在CelebA和3D Chairs数据集上生成样本的视觉质量和多样性通常优于η-VAEs和InfoGAN。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20182", "html_url": "https://arxiv.org/abs/2510.20182", "title": "评价视频生成模型作为多人行轨迹模拟器的效果", "title_en": "Evaluating Video Models as Simulators of Multi-Person Pedestrian Trajectories", "authors": "Aaron Appelle,Jerome P. Lynch", "background": "大规模的视频生成模型在多种场景下展示了高度的视觉真实性，激发了其作为通用世界模拟器的可能性。现有的基准评估主要集中在单人场景上，而非包含多个互动人物的场景。尽管生成的视频中多人动态的合理性尚未得到验证，但这些模型在模拟多人行人动态方面仍表现出色。然而，这些模型中存在的合并和消失等人行动态的问题仍需进一步的改进空间。", "innovation": "本文提出了一种严格的评估方案，用于基于文本和图像的视频生成模型作为隐式行人人流动力学模拟器的基准测试。对于图像到视频（I2V）模型，利用现有数据集中的起始帧与真实视频数据集进行比较。对于文本到视频（T2V）模型，开发了一套提示套装探索各种行人密度和互动。特别地，提出了一种方法，在没有已知相机参数的情况下从像素空间重建二维鸟瞰视图轨迹。", "conclusion": "研究发现，领先模型已学习到令人惊讶有效的先验知识，以实现合理的多人行为。然而，合并和消失等失效模式仍然表明了未来研究的方向，即需要改善这些模型在处理更复杂的行人互动时的性能。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20095", "html_url": "https://arxiv.org/abs/2510.20095", "title": "BIOCAP: 利用合成描述性标题超越标签在生物基础模型中的应用", "title_en": "BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models", "authors": "Ziheng Zhang,Xinyue Ma,Arpita Chowdhury,Elizabeth G. Campolongo,Matthew J. Thompson,Net Zhang,Samuel Stevens,Hilmar Lapp,Tanya Berger-Wolf,Yu Su,Wei-Lun Chao,Jianyang Gu", "background": "目前生物成像与多模态基础模型的结合研究中，主要依赖标注图例进行训练，但缺乏自然语言监督在生物有机物学科中的广泛应用。图像和描述性标题被视为物种潜在形态空间中的互补样本，各自捕捉特定的生物特征。将描述性标题纳入训练可以促进与共享潜在结构的对齐，强调可能的诊断特征，同时抑制虚假相关性。然而，大规模获取忠实的、特定实例的描述性标题仍然具有挑战性。这限制了自然语言监督在生物有机物学科中的应用。本研究旨在通过生成多模态大语言模型合成描述性标题，填补这一空白，从而提高生物基础模型的训练效果和性能。", "innovation": "创新在于利用合成的描述性标题作为额外的训练监督来源，通过多模态大语言模型（MLLMs）生成的合成描述性标题，结合Wikipedia中的视觉信息和门类自定义格式示例，减少臆造错误，生成准确、实例特定的描述性标题，进而训练出能够捕捉丰富语义并实现物种分类和图文检索任务中强大性能的生物基础模型BIOCAP。", "conclusion": "研究结果表明，描述性标题在将生物图像与多模态基础模型相结合方面比标签本身更具价值，能够有效提升生物基础模型的性能。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20196", "html_url": "https://arxiv.org/abs/2510.20196", "title": "公共脑MRI数据集的结构化审查和定量分析及其在基础模型开发中的应用", "title_en": "A Structured Review and Quantitative Profiling of Public Brain MRI Datasets for Foundation Model Development", "authors": "Minh Sao Khue Luu,Margaret V. Benedichuk,Ekaterina I. Roppert,Roman M. Kenzhin,Bair N. Tuchinov", "background": "基础模型在脑MRI领域的开发依赖于可用数据的数量、多样性和一致性，然而系统评估这些因素的研究仍然稀缺。本文分析了54个公开可访问的脑MRI数据集，涵盖超过538,031个样本，旨在提供一个针对基础模型开发的结构化、多层次概览。在数据集层面，文中详细描述了模态组成、疾病覆盖范围和数据集规模，揭示了大规模健康队列和小型临床群体之间明显的不平衡。在图像层面，通过15个代表性数据集量化了体素间距、取向和强度分布，表明存在显著差异，这些差异可能会影响表示学习。随后，定量评估了预处理差异，探讨了强度归一化、偏场校正、颅骨去除、空间配准和插值对体素统计和几何形状的影响，尽管这些步骤提高了数据集内的一致性，但仍存在数据集间的残余差异。", "innovation": "通过分析54个丰富的公共脑MRI数据集，本文不仅提供了一个多层次的数据集结构化概览，而且还发现了重要的预处理差异和模态不平衡性，为开发适用于脑MRI的基础模型提供了新的洞察。", "conclusion": "本文的研究结果为公共脑MRI资源的变异性提供了综合描述，并突显了在设计可泛化脑MRI基础模型时需要预处理意识和域自适应策略的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20212", "html_url": "https://arxiv.org/abs/2510.20212", "title": "FlowCycle：追求一致循环流的文本编辑", "title_en": "FlowCycle: Pursuing Cycle-Consistent Flows for Text-based Editing", "authors": "Yanghao Wang,Zhen Wang,Long Chen", "background": "近期预训练文本到图像流动模型在基于文本的图像编辑方面取得了显著进展。现有方法通常采用一种破坏然后恢复的范式，即首先破坏源图像以达到“中间状态”，然后在提示引导下恢复为目标图像。然而，这些问题的中间状态是在未考虑目标的情况下构建的，主要关注源图像的重建而忽视了与特定编辑目标之间的语义差异。因而，当需要的修改与源图像有较大偏差时，就会导致编辑效果有限或不一致。", "innovation": "本文提出了FlowCycle，一种新的无需反演且基于流动的编辑框架，通过可学习噪声参数化损害过程，并通过循环一致性过程优化它们。通过双向一致性约束，迭代地将源图像编辑到目标并回恢复到源图像，FlowCycle 学习产生目标意识的中间状态，使得能够以忠实的方式进行编辑并保持源的一致性。", "conclusion": "广泛的消融实验表明，与最先进的方法相比，FlowCycle实现了更高质量和更一致的编辑效果。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20217", "html_url": "https://arxiv.org/abs/2510.20217", "title": "EditInfinity: 使用二值量化生成模型的图像编辑", "title_en": "EditInfinity: Image Editing with Binary-Quantized Generative Models", "authors": "Jiahuan Wang,Yuxin Chen,Jun Yu,Guangming Lu,Wenjie Pei", "background": "基于扩散的预训练生成模型在文本驱动的图像编辑方面展示了显著的应用潜力，但现有的方法依赖的图像反向生成过程会引入大量的近似误差，这限制了图像编辑的效果。", "innovation": "该研究提出了EditInfinity，一种针对EditInfinity的二值量化生成模型，通过精确的中间量化表示提供有效的监督，改进了文本提示校正和图像风格保持的图像反转机制，并设计了一种整体平滑策略，以实现高质量和准确的语义对齐的图像编辑。", "conclusion": "在PIE-Bench基准测试中，对于“添加”、“更改”和“删除”操作，该模型的性能优于最先进的基于扩散的方法。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20214", "html_url": "https://arxiv.org/abs/2510.20214", "title": "客观产前超声评估：基于对比表示学习的胎儿运动检测", "title_en": "Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection", "authors": "Talha Ilyas,Duong Nhu,Allison Thomas,Arie Levin,Lim Wei Yap,Shu Gong,David Vera Anaya,Yiwen Jiang,Deval Mehta,Ritesh Warty,Vinayak Smith,Maya Reddy,Euan Wallace,Wenlong Cheng,Zongyuan Ge,Faezeh Marzbanrad", "background": "胎儿运动（FM）检测对于评估产前健康至关重要，因为异常运动模式可能表明潜在的并发症，如胎盘功能障碍或胎儿窘迫。传统方法，包括母体感知和心电图（CTG），存在主观性和准确性有限的问题。", "innovation": "提出了对比超声视频表示学习（CURL），这是一种新颖的自我监督学习框架，用于从扩展的胎儿超声视频中检测胎儿运动。该方法利用了空间和时间对比学习的双重对比损失来学习稳健的运动表示。此外，引入了特定任务的采样策略，在自我监督训练过程中确保运动和非运动段的有效分离，通过概率微调方法对任意长度的超声记录进行灵活推理。", "conclusion": "在包含92个受试者（每个受试者有30分钟的超声会话）的内部数据集上评估CURL，CURL的敏感性为78.01%，AUROC为81.60%，表明其在可靠的和客观的胎儿运动分析方面具有潜力，展示了自我监督对比学习在胎儿运动分析中的潜力，为进一步改进产前监测和临床决策铺平了道路。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20206", "html_url": "https://arxiv.org/abs/2510.20206", "title": "RAPO++: 数据对齐和测试时缩放的跨阶段提示优化方法用于文本到视频生成", "title_en": "RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling", "authors": "Bingjie Gao,Qianli Ma,Xiaoxue Wu,Shuai Yang,Guanzhou Lan,Haonan Zhao,Jiaxuan Chen,Qingyang Liu,Yu Qiao,Xinyuan Chen,Yaohui Wang,Li Niu", "background": "在文本到视频（T2V）生成中，提示设计起着关键作用，但用户提供的提示往往短小、不结构化且与训练数据不一致，这限制了基于扩散模型的T2V生成模型的生成潜力。本文旨在通过一种统合训练数据对齐改进、测试时迭代放大和大规模语言模型微调的跨阶段提示优化框架RAPO++，在不修改底层生成模型的前提下大幅改善T2V生成效果。", "innovation": "RAPO++框架分为三个阶段，第一阶段利用检索增强的提示优化（RAPO）方法，通过从关系图中检索相关修饰词并重新格式化以匹配训练分布，提升组成性和多目标保真度；第二阶段引入样本特定提示优化（SSPO）机制，利用多源反馈机制迭代优化提示（包括语义对齐、空间保真性、时间连贯性及特定任务信号），连续提升视频生成质量；第三阶段使用SSPO优化的提示对重写语言模型进行微调，使模型内部化特定任务的优化模式，从而提高提示生成的效率和质量。实验结果表明，RAPO++在语义对齐、组成性推理、时间稳定性及物理合理性等方面表现出显著优势，大幅超越现有方法。", "conclusion": "本文提出的RAPO++跨阶段提示优化框架在五个最先进的T2V模型和五个基准上的广泛实验表明，该框架能够在不修改底层生成模型的情况下显著提升T2V生成效果，成为一种模型通用、成本效益高且可扩展的提示优化解决方案，为T2V生成领域的提示优化树立了新的标杆。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20229", "html_url": "https://arxiv.org/abs/2510.20229", "title": "为什么大型视觉语言模型在更长的回答中更容易产生幻觉：上下文的作用", "title_en": "Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context", "authors": "Ge Zheng,Jiaye Qian,Jiajin Tang,Sibei Yang", "background": "近年来，大型视觉语言模型（LVLMs）在诸多任务上取得了显著的进步，但也面临着产生幻觉的问题。这些问题在较长、自由式的回答中更为突出，通常被认为是积累的不确定性所致。", "innovation": "本文提出了一种新颖的“诱导-检测-抑制”框架。该框架通过精心设计的上下文主动诱导幻觉，利用诱导的实例进行高风险情况的早期检测，并在实际解码过程中抑制潜在的对象级幻觉。该方法在所有基准上都表现出一致且显著的改进。", "conclusion": "我们的检测和幻觉抑制的强化不仅验证了我们的框架，更重要的是重新验证了我们的假说：即幻觉风险并非由长度本身造成，而是由更依赖于较长答案中的上下文以保证连贯性和完整性所引起。这项研究旨在提供新的见解，并作为深入探索LVLMs更长回答中幻觉机制的第一步。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20238", "html_url": "https://arxiv.org/abs/2510.20238", "title": "COS3D: 协作开放式词汇3D分割", "title_en": "COS3D: Collaborative Open-Vocabulary 3D Segmentation", "authors": "Runsong Zhu,Ka-Hei Hui,Zhengzhe Liu,Qianyi Wu,Weiliang Tang,Shi Qiu,Pheng-Ann Heng,Chi-Wing Fu", "background": "开放词汇的3D分割是一项基本但具有挑战性的任务，需要同时理解分割和语言。现有的基于Gaussian散点的方法要么依赖单一的3D语言场，导致分割效果较差；要么依赖预先计算的类别无关分割，容易出现累积错误。", "innovation": "本文提出了一种新的协作提示分割框架COS3D，旨在在整个管道中有效整合互补的语义和分割提示。具体创新点包括：1) 引入协作场的概念，包含实例场和语言场，作为协作的基石；2) 在训练过程中，通过一种新颖的实例到语言特征映射，和高效两阶段训练策略，有效构建协作场；3) 在推理阶段，设计自适应语言到实例提示精炼，以桥梁两个场的差异特征，促进高质量的提示分割推理。", "conclusion": "广泛实验表明，COS3D在两个广泛使用的基准上的性能领先。COS3D还展示出在各种应用中的高潜力，如基于图像的新颖3D分割、层次分割以及机器人技术。相关代码已公开。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20189", "html_url": "https://arxiv.org/abs/2510.20189", "title": "SPAN: 用于时间意图定位的连续疑虑进阶建模", "title_en": "SPAN: Continuous Modeling of Suspicion Progression for Temporal Intention Localization", "authors": "Xinyi Hu,Yuran Wang,Yue Li,Wenxuan Liu,Zheng Wang", "background": "时间意图定位（TIL）对于视频监控至关重要，因为它能够识别不同水平的可疑意图，从而提高安全监控。然而，现有的离散分类方法无法捕捉可疑意图的连续性本质，这限制了早期干预和可解释性。已有研究方法在处理行为意图的动态变化时存在不足，无法有效反映长期依赖和累积效应，从而影响了对视频监控中可疑行为的准确理解和提前预警能力。", "innovation": "本文提出了一种名为Suspicion Progression Analysis Network (SPAN) 的网络模型，它从离散分类转变为连续回归，能够捕捉可疑意图的变化和演变。该模型基于怀疑行为具有长期依赖和累积效应的洞察，定义了一个连续变化的怀疑得分公式，并且引入了疑虑系数调制，使用多模式信息来反映可疑行为的不同影响。此外，提出了一种基于概念的映射方法，将可疑行为链接到预定义的意图概念，从而提供行为及其潜在意图的见解。实验证明，与现有方法相比，SPAN在减少均方根误差（降低19.8%）和提高平均mAP（提高1.78%）方面显著表现更优，特别是在低频情况下，显示出其捕捉微妙行为变化的能力更为优越。", "conclusion": "与现有的离散分类系统相比，连续疑虑模型能够实现早期检测和主动干预，极大提升了系统的可解释性和实际应用价值。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20281", "html_url": "https://arxiv.org/abs/2510.20281", "title": "视觉因果去偏见对于视觉常识推理", "title_en": "Causal Debiasing for Visual Commonsense Reasoning", "authors": "Jiayi Zou,Gengyun Jia,Bing-Kun Bao", "background": "视觉常识推理（VCR）是指基于图像回答问题并提供解释。现有方法可以实现高预测精度，但在处理数据集中的偏差方面有所忽略，缺乏应对策略。研究发现，无论是文本数据还是视觉数据，都存在共现和统计上的偏差问题。论文提出VCR-OOD数据集，其中包括VCR-OOD-QA和VCR-OOD-VA子集，旨在评估模型在不同模态之间的泛化能力。进一步分析指出VCR中的因果图和预测捷径，并引入了一种反门调整方法来消除偏见，具体措施是基于正确答案集生成词典以消除预测捷径。", "innovation": "论文提出了VCR-OOD数据集，并引入了一种反门调整方法，该方法通过基于正确答案集生成词典来消除预测捷径。这种方法旨在克服现有方法对数据集中的偏见处理不足的问题，从而提高模型的泛化能力。", "conclusion": "实验结果表明，该去偏见方法对于不同数据集都有效。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20268", "html_url": "https://arxiv.org/abs/2510.20268", "title": "GMFVAD: 使用粒度多模态特征提高视频异常检测", "title_en": "GMFVAD: Using Grained Multi-modal Feature to Improve Video Anomaly Detection", "authors": "Guangyu Dai,Dong Chen,Siliang Tang,Yueting Zhuang", "background": "视频异常检测（VAD）是一项具有挑战性的任务，旨在检测连续监控视频中的异常帧。大多数之前的工作利用视觉特征的空时相关性来区分视频片段中是否存在异常。近年来，一些工作尝试引入多模态信息，如文本特征，以增强视频异常检测的结果。然而，这些工作只是粗略地将文本特征融入到视频片段中，未能充分利用视频片段中的冗余信息。", "innovation": "本文提出了综合利用多模态信息多样性来进一步细化提取特征的策略，减少视觉特征中的冗余信息，并提出了一种新的方法——粒度多模态特征视频异常检测（GMFVAD）。具体来说，该方法基于视频片段生成更细化的多模态特征，同时利用原始视频的字幕引入基于文本特征以进一步增强突出部分的视觉特征。", "conclusion": "实验结果表明，提出的GMFVAD在四个主要数据集上达到了最先进的性能。消融实验还证明了GMFVAD的改进是由于减少了冗余信息造成的。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20244", "html_url": "https://arxiv.org/abs/2510.20244", "title": "提升词语的作用：双分支架构DualGround在结构化短语和句子级别时间定位中的应用", "title_en": "Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding", "authors": "Minseok Kang,Minhyeok Lee,Minjung Kim,Donghyeong Kim,Sangyoun Lee", "background": "视频时间定位（VTG）的目标是在长视频片段中定位与给定自然语言查询对应的时序段。这一任务通常包含两个子任务：时刻检索（MR）和高亮检测（HD）。最近，强大的预训练多模态视觉-语言模型如CLIP和InternVideo2取得了进展，但现有方法通常在跨模态注意力机制中对所有文本标记处理一致，忽略了它们的语义差异。本文通过对照验证了这种方法的局限性，指出VTG模型过度依赖全局语义驱动的[EOS]标记，而未能有效利用词级信号，从而限制了其在精细时序对齐方面的表现能力。", "innovation": "本文提出了DualGround模型，这是一种双分支架构，明确地通过将[EOS]标记分配到句子级别路径和根据短语级单元簇化词标记的方式分离全局和局部语义，从而实现结构化短语和句子级别的时间定位。该方法引入了（1）考虑到词角色的跨模态交互策略，这种策略能够以结构上分离的方式对视频特征与短语级别和句子级别的语义进行对齐；（2）联合建模框架，不仅提高了全局句子级别的对齐，还通过结构化的短语意识上下文增强了精细时序定位。这些设计使模型能够捕捉到粗略和局部化的语义，从而实现更具表现力和上下文意识的视频定位能力。DualGround在QVHighlights和Charades-STA基准测试中的两个子任务上达到了最先进的性能，证明了分离的语义建模在视频-语言对齐中的有效性。", "conclusion": "DualGround模型通过明确分离全球和本地语义，能够捕捉到粗略和局部的语义信息，使视频时间定位更加深刻和具有上下文意识。该模型在多个基准测试上实现了最先进的性能，展示了分离语义建模在视频语言对齐中的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20256", "html_url": "https://arxiv.org/abs/2510.20256", "title": "Calibrating Multimodal Consensus for Emotion Recognition", "title_en": "Calibrating Multimodal Consensus for Emotion Recognition", "authors": "Guowei Zhong,Junjie Li,Huaiyu Zhu,Ruohong Huan,Yun Pan", "background": "近年来，多模态情感识别（MER）取得了显著进展。然而，大多数现有方法忽略了模态间可能出现的语义不一致性，例如文本和视觉输入之间的矛盾情感线索。此外，当前的方法往往受到文本模态的支配，因为其很强的表示能力，这可能会损害识别准确性。", "innovation": "提出了一种称为校准多模态共识（CMC）的模型。CMC引入了一个伪标签生成模块（PLGM）来生成伪单模标签，从而进行无监督的单模预训练。它还采用了一个参数自由融合模块（PFM）和一个多模态共识路由器（MCR）进行多模态微调，从而减轻了文本支配，并引导融合过程朝向更可靠的共识。实验结果表明，CMC在四个数据集（CH-SIMS，CH-SIMS v2，CMU-MOSI和CMU-MOSEI）上达到了或超越了最先进的方法，并在CH-SIMS和CH-SIMS v2的语义不一致场景中表现出明显的优势。", "conclusion": "实验结果显示，CMC在四个数据集上的性能与或优于最先进的方法，特别是在具有语义不一致性的场景中表现出明显优势。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20247", "html_url": "https://arxiv.org/abs/2510.20247", "title": "基于掩码的位置编码和条带卷积上下文建模的交叉视图物体地理定位", "title_en": "Seeing the Unseen: Mask-Driven Positional Encoding and Strip-Convolution Context Modeling for Cross-View Object Geo-Localization", "authors": "Shuhan Hu,Yiru Li,Yuanyuan Li,Yingying Zhu", "background": "交叉视图物体地理定位通过跨视图匹配实现高精度物体定位，在自动驾驶、城市管理和灾害响应等领域具有重要应用。然而，现有方法依赖关键点为基础的位置编码，仅捕捉二维坐标，忽视了物体的形状信息，导致对标注偏移敏感，并限制了跨视图匹配能力。", "innovation": "该研究提出了一种基于掩码的位置编码方案，利用分割掩码捕捉空间坐标和物体轮廓，使模型从“位置感知”升级为“对象感知”。同时，设计了一种上下文增强模块，通过水平和垂直条带卷积核提取长范围上下文特征，增强具有长条形特征物体的特征区分能力。结合基于掩码的位置编码和上下文增强模块，构建了一个端到端的EDGeo框架，用于鲁棒的跨视图物体地理定位。研究成果在CVOGL和VIGOR-Building两个公共数据集上广泛实验，展示了在挑战性地面向卫星场景中，具有3.39%的定位准确度改进，超越了现有最佳方法。", "conclusion": "该工作提供了一种鲁棒的位置编码范式和一种上下文建模框架，推动了跨视图地理定位研究的进步。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20267", "html_url": "https://arxiv.org/abs/2510.20267", "title": "实时货币检测及语音反馈系统为视障人士", "title_en": "Real-Time Currency Detection and Voice Feedback for Visually Impaired Individuals", "authors": "Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim", "background": "随着智能手机成为日常生活中的必需品，这些设备已经为包括视障人士在内的所有人提供了便利。智能手机摄像头的应用使得图像捕捉和处理变得更为便捷。结合智能手机和机器学习，视障人士的生活可以变得更加容易。例如，无需依赖他人处理现金等日常任务对他们来说很麻烦。因此，本文提出了一种实时货币检测系统，旨在帮助视障人士。该系统基于一个包含30类纸币和硬币的数据库进行训练，代表3种货币：美元、欧元和孟加拉国塔卡。此模型使用YOLOv8 nano模型并加入了定制的检测头部，包括深度卷积层和Squeeze-and-Excitation块，以提高特征提取和检测精度。实验证明该模型的准确率为97.73%，召回率为95.23%，F1分数为95.85%，mAP50(B)为97.21%。检测后的语音反馈可以帮助视障人士识别出货币类型。", "innovation": "本文创新点在于提出了一种基于YOLOv8 nano模型的定制检测头部，融合了深度卷积层和Squeeze-and-Excitation块，有效提高了特征提取和检测精度。同时，结合语音反馈机制，为视障人士提供实时的货币识别辅助，增强其独立处理现金的能力。", "conclusion": "本文旨在创建一种实用高效的货币检测系统，帮助视障人士更加独立地处理现金，提升他们的生活质量。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20285", "html_url": "https://arxiv.org/abs/2510.20285", "title": "DMC³: 双模态反事实对比构建方法用于自观视频问答", "title_en": "DMC$^3$: Dual-Modal Counterfactual Contrastive Construction for Egocentric Video Question Answering", "authors": "Jiayi Zou,Chaofan Chen,Bing-Kun Bao,Changsheng Xu", "background": "自观视频问答（Egocentric VideoQA）在自观视频理解中扮演着重要角色，主要基于第一人称视角回答问题。尽管现有的方法已经通过预训练和微调的方式取得了进展，但它们忽视了第一人称视角所带来的独特挑战，如理解多种事件和识别手部与物体的交互。这些挑战限制了现有方法的效果。", "innovation": "我们提出了一种双模态反事实对比构建（DMC³）框架，以应对上述挑战。该框架包括一个自观视频问答基线、一种反事实样本构建模块以及一种反事实样本参与的对比优化模块。首先，我们开发了一种反事实样本构建模块，通过事件描述重新措辞和核心交互挖掘分别生成文本和视觉模态的正样本和负样本。然后，我们将这些样本与原始样本一同输入基线模型。最后，在反事实样本参与的对比优化模块中，我们应用对比损失来最小化原始样本特征与正样本特征之间的距离，同时最大化与负样本特征之间的距离。", "conclusion": "我们的方法在EgoTaskQA的标准和间接分割上分别达到了52.51%和46.04%的性能，在QAEGO4D上达到了13.2%的性能，均接近最先进的技术水平。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20284", "html_url": "https://arxiv.org/abs/2510.20284", "title": "Knowledge-Informed Neural Network for Complex-Valued SAR Image Recognition", "title_en": "Knowledge-Informed Neural Network for Complex-Valued SAR Image Recognition", "authors": "Haodong Yang,Zhongling Huang,Shaojie Guo,Zhe Zhang,Gong Cheng,Junwei Han", "background": "在数据限制和领域转移场景中，传统数据驱动模型无法有效解决复值合成孔径雷达(CV-SAR)图像识别中泛化能力、可解释性和效率之间的矛盾，无法充分挖掘CV-SAR数据丰富的电磁散射特征，这限制了深层学习模型的性能提升。因此，本文背景是探讨如何更好地利用CV-SAR数据的物理特性以解决这一矛盾。", "innovation": "本文提出了一种名为Knowledge-Informed Neural Network (KINN)的轻量级框架，采用了一种新颖的“压缩-聚合-压缩”架构，该架构首先通过物理引导进行压缩，嵌入物理先验知识，实现高效的稀疏物理特征提取；接着通过聚合模块丰富这些特征，并利用紧凑的分类头进行最终的语义压缩，实现任务相关性和辨别性特征的学习。这一框架在SAR图像识别领域创新地解决了传统模型面临的泛化能力、可解释性和效率之间的矛盾，提供了可解释的、高效率的解决方案，并就CV-SAR图像处理提供了新的路径。", "conclusion": "通过对五个SAR基准的广泛评估，KINN在参数效率性方面表现出色，尤其在数据稀缺和分布外场景中具有出色的泛化能力，并具有可解释性，有效地解决了可解释性、泛化能力和效率之间的矛盾，为雷达图像分析提供了可信的人工智能新途径。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20287", "html_url": "https://arxiv.org/abs/2510.20287", "title": "在生成式AI时代下的霹雳舞视频分类", "title_en": "Breakdance Video classification in the age of Generative AI", "authors": "Sauptik Dhar,Naveen Ramakrishnan,Michelle Munson", "background": "近年来，大规模的视觉语言模型已经在多个运动案例中得到了广泛的应用。大多数研究集中于足球、板球、篮球等热门运动上的生成任务，如视觉问答和亮点生成。本文的研究目标是分析现代视频基础模型（包括编码器和解码器）在霹雳舞这一较为小众但极其流行的舞种中的应用可行性。现有研究表明，视频编码器模型在预测任务中依然表现出色，超越了现有的最先进视频语言模型。本文还探讨了如何选择编码器模型以及对微调解码器模型进行详细的分析，以适用于霹雳舞视频分类任务。", "innovation": "本文首次将现代视频基础模型应用于霹雳舞视频分类，并提供了关于如何选择编码器模型以及微调解码器模型的技术见解。这项研究填补了运动视频分类中霹雳舞这一领域的空白，同时也展示了在生成式AI时代，视频编码器模型在处理此类小众但流行的体育项目中的优势。", "conclusion": "视频编码器模型在霹雳舞视频分类中表现出色，而不同编码器的性能差异明显。通过合适的模型选择和对解码器模型进行微调，可以显著提高该领域的视频分类准确性。未来的研究将进一步优化模型性能并拓展应用范围。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20286", "html_url": "https://arxiv.org/abs/2510.20286", "title": "UI-Ins: 提升GUI对接能力的多视角指令推理", "title_en": "UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning", "authors": "Liangyu Chen,Hanzhang Zhou,Chenglin Cai,Jianan Zhang,Panrong Tong,Quyu Kong,Xu Zhang,Chen Liu,Yuqi Liu,Wenxuan Wang,Yue Wang,Qin Jin,Steven Hoi", "background": "GUI对接技术，即自然语言指令到可操作UI元素的映射，是GUI代理的核心能力。现有的研究主要将指令视为静态的用户意图代理，忽视了指令多样性与质量对对接性能的影响。通过仔细调查现有的对接数据集，研究发现其中23.3%的指令存在缺陷，并证明在推理时利用指令多样性可以获得高达76%的相对性能提升。", "innovation": "提出了指令作为推理的新范式，将指令视为动态的分析路径，为模型在推理中提供不同的视角。建立了一个两阶段训练框架：监督细调（SFT）以增强多视角推理能力，结合强化学习（RL）优化路径选择和组合。提出的模型UI-Ins-7B和UI-Ins-32B在五个挑战性对接基准上取得了领先的结果，具有生成新型指令路径的能力，尤其是UI-Ins-32B在UI-I2E-Bench、ScreenSpot-Pro和MMBench-GUI L2上的对接精度分别为87.3%、57.0%和84.9%。此外，该模型在AndroidWorld上的成功率为74.1%，显示了强大的代理潜力。", "conclusion": "研究深入分析还揭示了一些如何通过推理来增强而非妨碍对接性能的重要见解，以及如何通过SFT+RL框架的方法减轻策略崩溃。相关的代码和模型检查点将在https://github.com/stabilityai/stability-models上公开发布。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20331", "html_url": "https://arxiv.org/abs/2510.20331", "title": "AnyPcc：使用单个通用模型压缩任意点云", "title_en": "AnyPcc: Compressing Any Point Cloud with a Single Universal Model", "authors": "Kangli Wang,Qianxi Yi,Yuqi Ye,Shihao Li,Wei Gao", "background": "点云几何压缩基于深度学习的技术仍然存在泛化能力不足的关键挑战。这一挑战源自两个主要限制：缺乏稳健的上下文模型和对分布外（OOD）数据处理不高效。", "innovation": "提出了一个名为AnyPcc的通用点云压缩框架。该框架首先采用一个通用上下文模型，该模型通过空间和通道内组的方式利用先验信息来捕捉稳健的上下文依赖性。其次，引入了一种新颖的实例自适应微调（IAFT）策略，该策略通过结合显式和隐式压缩范式来处理OOD数据，有效降低成本同时提高压缩效果。", "conclusion": "在15个不同的数据集基准测试中，AnyPcc在点云压缩方面达到了新的最先进的水平。作者承诺将公开源代码和数据集，以促进可重复的研究。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20291", "html_url": "https://arxiv.org/abs/2510.20291", "title": "一种参数高效的跨模态专家混合框架用于跨模态地理定位", "title_en": "A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization", "authors": "LinFeng Li,Jian Zhao,Zepeng Yang,Yuhang Song,Bojun Lin,Tianle Zhang,Yuchen Yuan,Chi Zhang,Xuelong Li", "background": "任务的目标是从包含卫星、无人机和地面多种平台的大量图像库中，通过自然语言查询，检索最相关的地理参考图像。这个任务面临两个主要挑战：平台间的巨大异质性和训练描述与测试查询之间的领域差距。作者通过一个领域对齐的预处理管道和一个Mixture-of-Experts框架，努力解决这些问题，使得能够跨多个平台进行有效的地理定位。", "innovation": "通过提出一种参数高效的Mixture-of-Experts框架，结合平台间的数据分割、图像增强及特定于平台的特征调整，利用预训练的语言模型和视觉模型，逐步训练并融合多个专家模型，从而有效地解决了跨模态地理定位的问题，并在官方排行榜上取得了优异的成绩，展现出在多种视角下的鲁棒性。", "conclusion": "该系统展示了在面对平台异构性的情况下，如何有效实施跨模态地理定位。使用一种两阶段方法和困难负样本挖掘策略，系统的性能得到了显著提升，最终在比赛中取得了第一名的好成绩。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20385", "html_url": "https://arxiv.org/abs/2510.20385", "title": "Positional Encoding Field", "title_en": "Positional Encoding Field", "authors": "Yunpeng Bai,Haoxiang Li,Qixing Huang", "background": "Diffusion Transformers (DiTs)已经成为视觉生成的主导架构，它们以补丁标记和位置编码的形式表示图像，结合了Transformer的可扩展性与空间及时间推理能力。这项研究重新审视了DiTs如何组织视觉内容，发现补丁标记表现出惊人的独立性：即使位置编码被扰动，DiTs仍能生成全局连贯的输出，表明空间连贯性主要由位置编码控制。", "innovation": "该研究引入了位置编码场 (PE-Field)，将位置编码从2D平面扩展到结构化的3D场。PE-Field包含深度感知编码和层次编码，实现DiTs直接在3D空间中建模几何结构，从而在单帧新视角合成和可控的空间图像编辑上实现了最优性能。", "conclusion": "通过增强DiT以使用PE-Field，研究人员在单张图像的新视角合成和空间图像编辑上实现了最先进的性能，并且这种模型具有更好的控制能力。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20348", "html_url": "https://arxiv.org/abs/2510.20348", "title": "AccuQuant: 用于量化扩散模型的模拟多个去噪步骤", "title_en": "AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models", "authors": "Seunghoon Lee,Jeongwoo Choi,Byunggwan Son,Jaehyeon Moon,Jeimin Jeon,Bumsub Ham", "background": "本文介绍了一种新颖的后训练量化方法AccuQuant，适用于扩散模型。量化误差在采样过程中通过去噪步骤累积，并分析了其形成机制。之前的量化方法通常通过模仿训练过程来最小化每个步骤之间的差异，而AccuQuant则直接通过模拟几个去噪步骤来最小化全精度模型和量化模型之间的差异，能更好地处理累积误差问题。", "innovation": "AccuQuant通过模拟多个去噪步骤来量化扩散模型，相对于之前的方法，减少了单独最小化每个步骤差异的问题。此外，它还提供了一种高效的实现技术，以及一个新颖的目标函数，将内存复杂度从O(n)显著降低到O(1)，显著提高了效率和效果。这种方法在各种任务和扩散模型上的标准基准上得到了验证和展示。", "conclusion": "该研究表明，AccuQuant可以有效地对扩散模型进行量化，即使在较大的去噪步骤数量下也能保持高精度。同时，该方法的高效实现技术使得能够在实际应用中广泛应用，大大减少了所需内存，提高了整体效率。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20393", "html_url": "https://arxiv.org/abs/2510.20393", "title": "克服多元文化图像-食谱检索中的跨模态表示偏见", "title_en": "Mitigating Cross-modal Representation Bias for Multicultural Image-to-Recipe Retrieval", "authors": "Qing Wang,Chong-Wah Ngo,Yu Cao,Ee-Peng Lim", "background": "现有的图像-食谱检索方法假设一张食品图像能够充分捕捉食谱文本中详细记录的细节。然而，食品图像仅反映烹饪后的视觉效果，而不包含背后的烹饪过程。因此，传统的跨模态表示学习倾向于忽略一些不明显但对食谱检索至关重要的食谱具体细节。这些学习得到的表示偏向于捕捉主要的视觉元素，导致难以对使用原料和烹饪方法有细微差别的相似食谱进行排名。尤其是在训练数据混合来自不同烹饪文化的图像和食谱时，这种表示学习的偏差可能会更加严重。", "innovation": "本文提出了一种新颖的因果方法，预测可能在图像中被忽略的烹饪元素，并将这些元素显式地注入到跨模态表示学习中以减少偏差。该方法在标准的单语言Recipe1M数据集和一个新整理的多语言多元文化烹饪数据集上进行了实验。", "conclusion": "实验结果表明，提出的因果表示学习能够揭示细微的烹饪成分和烹饪动作，并在单语言和多元文化的多元烹饪数据集上实现了出色的检索性能。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20322", "html_url": "https://arxiv.org/abs/2510.20322", "title": "HyperET: 在双曲空间中高效训练多模态大规模语言模型", "title_en": "HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models", "authors": "Zelin Peng,Zhengqin Xu,Qingyang Liu,Xiaokang Yang,Wei Shen", "background": "多模态大语言模型（MLLMs）已成为视觉和文本理解对齐的变革性方法。这些模型通常需要大量计算资源（例如，成千上万个GPU）进行训练，以在多粒度水平上实现跨模态对齐。然而，这种高效性的一个关键来源在于它们广泛应用的视觉编码器，例如CLIP和SAM，这些编码器缺乏在多粒度水平上的与语言对齐的功能。现有的方法由于这种不匹配，在视觉和文本模态之间的粒度对齐上效率低下。因此，提出了HyperET方法，该方法通过在双曲空间中动态调整双曲半径，优化视觉表示，使其能够任意粒度水平上与文本对应部分对齐。", "innovation": "HyperET提出了一种高效的训练多模态大语言模型的范式，通过双曲空间中的动态双曲半径调整来优化视觉表示，使其与文本对应部分对齐。HyperET采用了可学习矩阵并使用Möbius乘法操作实现三种有效的配置：对角缩放矩阵、块对角矩阵和带状矩阵，提供了一种灵活且高效的参数化策略。", "conclusion": "在多个多模态大语言模型基准上的广泛实验表明，与现有预训练和微调模型相比，HyperET在参数量增加不足1%的情况下，依然能够显著提高模型性能。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20512", "html_url": "https://arxiv.org/abs/2510.20512", "title": "EchoDistill: 双向概念精炼用于单步扩散个性化", "title_en": "EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization", "authors": "Yixiong Yang,Tao Wu,Senmao Li,Shiqi Yang,Yaxing Wang,Joost van de Weijer,Kai Wang", "background": "近年来，文本到图像（T2I）扩散模型加速技术使得在单步骤中生成高保真图像成为可能。然而，如何使这些模型个性化以包含新型概念仍是一个挑战，因为单步骤模型在有效捕捉新概念分布方面的能力有限。", "innovation": "本文提出了一种双向概念精炼框架 EchoDistill，用于实现单步扩散个性化（1-SDP）。该框架通过一个端到端的训练过程，使一个多步骤扩散模型（教师）和一个单步骤扩散模型（学生）同时进行训练。概念首先从教师模型转移到学生模型，然后再从学生模型回传给教师模型。同时引入了双向回声精炼策略，其中学生模型利用其快速生成能力反馈给教师模型。这种双向概念精炼机制不仅增强了学生模型对新型概念的个性化能力，同时提升了教师模型的生成质量。", "conclusion": "实验结果表明，这种协作框架显著优于现有的个性化方法，为T2I扩散模型的快速有效个性化提供了新型范式。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20470", "html_url": "https://arxiv.org/abs/2510.20470", "title": "Conan: 进阶学习如同侦探般进行多层次视觉证据推理", "title_en": "Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence", "authors": "Kun Ouyang,Yuanxin Liu,Linli Yao,Yishuo Cai,Hao Zhou,Jie Zhou,Fandong Meng,Xu Sun", "background": "视频推理要求在多帧间进行多步骤的推理，这仍然是多模态大型语言模型（MLLMs）的主要挑战之一。虽然强化学习（RL）基方法可以提升推理能力，但通常依赖于仅基于文本的链路，这会导致推理结果不切实际或幻觉。与此相反，基于帧检索的方法引入了视觉定位，但仍然难以准确定位证据。", "innovation": "我们提出了Conan框架，一种进行证据支撑的多步骤视频推理的框架。Conan通过识别上下文帧和证据帧，处理跨帧线索，并决定何时终止推理或进一步探索。为了实现这一点，我们构建了Conan-91K大规模数据集，包含帧识别、证据推理和决策动作，并设计了多阶段进阶冷启动策略结合Identification-Reasoning-Action (AIR) RLVR训练框架，以增强多步骤视觉推理。实验证明，Conan在多个多步骤推理基准上的准确率平均提高了超过10%，达到最先进的技术水平，且在长时间视频理解任务中表现出很好的推广能力和稳定性。", "conclusion": "Conan在多步视频推理中表现出色，超越了基准Qwen2.5-VL-7B-Instruct，并且适用于长期视频理解任务，证明了其强大的可扩展性和鲁棒性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20438", "html_url": "https://arxiv.org/abs/2510.20438", "title": "利用遗传算法选择最佳预训练学生模型的动态权重调整：基于视觉变换器实现高精度肺癌检测和实时部署", "title_en": "Dynamic Weight Adjustment for Knowledge Distillation: Leveraging Vision Transformer for High-Accuracy Lung Cancer Detection and Real-Time Deployment", "authors": "Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel", "background": "该研究提出了FuzzyDistillViT-MobileNet模型，这是一种利用动态模糊逻辑驱动的知识蒸馏方法来进行肺癌（LC）分类的新方法。传统的模型依赖于静态知识蒸馏，而这会导致在疾病诊断中遇到的不确定性和复杂性问题。为了提高模型处理不同LC图像区域中不同不确定性水平的能力，该研究提出了一种动态调整蒸馏权重的方法，使学生模型能够专注于高置信度区域并减少对模糊区域的关注。", "innovation": "该研究的创新之处在于：1) 利用动态模糊逻辑驱动的知识蒸馏，实现模型在处理肺部图像中的动态调整；2) 使用Vision Transformer (ViT-B32)作为教师模型，有效地转移知识给MobileNet学生模型，提高学生模型的泛化能力；3) 通过动态等待调整机制优化训练过程，提高模型的收敛性和性能；4) 利用遗传算法从12个预训练学生模型中选择最佳模型，平衡模型性能与计算成本；5) 引入基于波let的像素级图像融合改进方法，提高图像分辨率和特征保留。", "conclusion": "该方法在两个不同数据集上进行了测试，包括25000张病理图像（准确率为99.16%）和IQOTH/NCCD CT扫描图像（准确率为99.54%），表明了在不同成像领域的稳健性，并且能够在保证高精度的前提下实现实时部署。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20549", "html_url": "https://arxiv.org/abs/2510.20549", "title": "深度学习赋能的视觉SLAM用于辅助视障导航", "title_en": "Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation", "authors": "Marziyeh Bamdad,Hans-Peter Hutter,Alireza Darvishy", "background": "尽管SLAM技术取得了进步，但在低纹理、运动模糊或复杂光照等恶劣条件下稳定运行仍然是一个挑战。这些挑战在辅助视障导航等应用场景中常见，会降低定位准确性和追踪稳定性，从而降低导航的可靠性和安全性。", "innovation": "我们提出了一种结合SuperPoint和LightGlue的深度学习增强视觉SLAM框架（SELM-SLAM3），通过强化特征提取和匹配，从而在恶劣条件下提供更可靠的导航支持。", "conclusion": "SELM-SLAM3在低纹理场景和快速运动等恶劣条件下的性能优于传统ORB-SLAM3，并且优于最先进的RGB-D SLAM系统。此框架为开发适合视障人士使用的导航辅助工具提供了可靠平台。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20558", "html_url": "https://arxiv.org/abs/2510.20558", "title": "从远和近：不同细节层次下人群表示的知觉评估", "title_en": "From Far and Near: Perceptual Evaluation of Crowd Representations Across Levels of Detail", "authors": "Xiaohan Sun,Carol O'Sullivan", "background": "本研究探讨了用户在不同细节层次（LoD）和视距下对群体角色表示的视觉质量感知。几何网格、图像基于的近似器、神经辐射场（NeRF）和三维高斯分布等不同表示方法在视觉保真度与计算性能之间存在不同的权衡。", "innovation": "研究通过定性和定量结果，为指导优化知觉导向的细节层次策略提供了见解，这对于群体渲染至关重要。", "conclusion": "研究结果为不同细节层次下的群体表示提供了知觉评估，帮助设计更优化的群体渲染策略。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20519", "html_url": "https://arxiv.org/abs/2510.20519", "title": "Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning", "title_en": "Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning", "authors": "Xiaohan Lan,Fanfan Liu,Haibo Qiu,Siqi Yang,Delian Ruan,Peng Shi,Lin Ma", "background": "近年来，由于大规模语言模型（LLM）推理能力的显著提升，多模态推理领域也取得了重要进展，尤其是在解决数学问题等复杂任务方面。然而，现有的多模态推理模型在执行复杂推理的一些简单查询时消耗大量的计算资源，导致效率低下。同时，这种专注于专门推理的方式限制了它们的广泛泛化能力。", "innovation": "本文提出了Metis-HOME：一种混合优化的专家混合架构。该模型通过将原来的密集模型分为两个独立的专家分支——一个针对复杂多步推理的思考分支，一个针对快速直接推理任务的非思考分支，从而实现“混合思考”范式。一个轻量级的可训练路由器能动态分配查询到最合适的专业分支。通过将Qwen2.5-VL-7B模型改造成MoE架构实验表明，该方法不仅能显著增强复杂推理能力，还能提高模型的整体能力，从而克服其他专门推理模型中存在的泛化能力下降趋势。", "conclusion": "我们的工作为构建强大的、多功能的多模态大语言模型（MLLMs）奠定了新的范式，有效解决了推理与泛化能力之间的普遍矛盾。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20539", "html_url": "https://arxiv.org/abs/2510.20539", "title": "Blur2seq：单个相机运动模糊图像的盲去模糊和相机轨迹估计", "title_en": "Blur2seq: Blind Deblurring and Camera Trajectory Estimation from a Single Camera Motion-blurred Image", "authors": "Guillermo Carbajal,Andrés Almansa,Pablo Musé", "background": "相机震动引起的运动模糊，尤其是在大范围或旋转运动中，仍然是图像恢复中的主要挑战。本文提供了基于深度学习的方法，从单张模糊图像同时估计隐藏的清晰图像和底层相机运动轨迹。通过利用项目运动模糊模型（PMBM），结合现代网络中可微模糊创建模块，本方法实现了高效处理。", "innovation": "提出了一种模块化架构，该架构通过神经网络预测完整的3D旋转轨迹，指导一个端到端训练的模型基础恢复网络，这不仅提供了对产生模糊的相机运动的可解释性，还通过重建生成观察模糊图像的序列清晰图像进一步核验结果。此外，在后推理阶段通过重新模糊损失（reblur loss）优化轨迹，提高了模糊输入和恢复输出之间的一致性。实验证明，本文方法在合成和真实数据集上达到了最先进的性能，特别是在具有严重或空间变异性模糊的情况下，端到端去模糊网络表现不佳时更为有效。", "conclusion": "我们的方法通过从单个模糊图像中重建序列清晰图像，并利用重新模糊损失（reblur loss）优化恢复后的轨迹，在合成和实际数据集上均达到最先进的去模糊性能，特别是在严重或空间变异性模糊的情况下。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20482", "html_url": "https://arxiv.org/abs/2510.20482", "title": "可靠且可复现的分组推理促进面部分析中的公平性", "title_en": "Reliable and Reproducible Demographic Inference for Fairness in Face Analysis", "authors": "Alexandre Fournier-Montgieux,Hervé Le Borgne,Adrian Popescu,Bertrand Luvison", "background": "面部分析系统的公平性评估通常依赖于自动的人口统计属性推理（DAI），而DAI本身依赖于预定义的人口统计分段。然而，公平性审计的有效性取决于DAI过程的可靠性。为此，本研究探讨了这一依赖性，证明改进的DAI可靠性可以导致更少偏见和更低偏差的FAS公平性估计。现有的DAI方法依赖于复杂的端到端训练，缺乏模块化和透明性，导致了不可靠的推理结果。因此，本研究提出了一个完全可复现的DAI流水线，该流水线采用模块化的迁移学习方法替换传统的端到端训练，该方法整合了预先训练的面部识别编码器和非线性分类头，并从内群体一致性方面引入了一个新的稳健性度量标准。这些方法在多个数据集和训练设置下对性别和种族推理进行了基准测试，结果表明提出的这种方法在种族推理上优于强大的基线，该属性更具挑战性。为了促进透明度和可复现性，论文公开了训练数据集元数据、完整代码库、预训练模型和评估工具套件，提供了一个可靠的基础来实现公平性审计中的分组推理。", "innovation": "本文提出了一种完全可复现的DAI流水线，采用模块化的迁移学习方法替换传统的端到端训练，这使得该流水线在诸如准确性和公平性方面表现更佳。特别地，这种方法在种族推理上表现出了特别显著的优势，而种族属性通常被认为是最具挑战性的。此外，引入了一个新的稳健性度量标准，该标准适用于任何人口统计分段方案，并公开了大量资源以促进透明性和可复现性。", "conclusion": "本文提供了一个可靠的DAI基础，使得针对公平性审计的分组推理成为可能，并公开了所有关键资源以促进进一步的研究。改进的DAI可靠性不仅减少了偏差，提高了估计的准确性，而且为计算机视觉中的公平性评估提供了通用解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20531", "html_url": "https://arxiv.org/abs/2510.20531", "title": "仿人在脸域：迈向细粒度可解释的深度伪造分析", "title_en": "Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis", "authors": "Lixiong Qin,Yang Zhang,Mei Wang,Jiani Hu,Weihong Deng,Weiran Xu", "background": "多模态大型语言模型（MLLMs）的进步将视觉和语言任务之间的差距缩小，使可解释的深度伪造分析（XDFA）得以实现。然而，当前方法存在精细程度不足的问题：数据标注中的描述不准确且粗糙，模型无法支持文本伪造解释与视觉证据之间的关联输出，也无法根据任意面部区域接收查询输入。因此，这些模型的响应未能充分扎根于面部视觉上下文中（Facext）。", "innovation": "我们提出了仿人在脸域（FiFa）框架，重点在于数据标注和模型构建。首先，我们定义了一组面部图像概念树（FICT），将面部图像划分为细粒度的区域概念，从而获得一个更可靠的标注流水线——FiFa-标注器，用于解释伪造现象。基于此专用的标注，我们引入了一个名为Artifact-Grounding Explanation（AGE）的新任务，该任务生成与篡改斑迹分割掩码交错的文本伪造解释。我们提出了一个统一的多任务学习架构——FiFa-MLLM，以同时支持丰富的多模态输入和输出，实现细粒度的XDFA。借助多个辅助监督任务，FiFa-MLLM在AGE任务上比强基线模型表现更优，并在现有XDFA数据集上达到了最先进的性能。", "conclusion": "通过提出FiFa-MLLM框架，我们解决了当前XDFA方法的精细度不足问题，实现了在面部视觉上下文中进行细粒度的可解释深度伪造分析。同时，我们开源了代码和数据，以进一步推动XDFA领域的研究和发展。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20550", "html_url": "https://arxiv.org/abs/2510.20550", "title": "基于学习的用于专业级成像的自适应相机参数网络从经济型走向专业型", "title_en": "From Cheap to Pro: A Learning-based Adaptive Camera Parameter Network for Professional-Style Imaging", "authors": "Fuchen Li,Yansong Du,Wenbo Cheng,Xiaoxia Zhou,Sen Yin", "background": "消费级相机系统在低光照、高动态范围、背光以及空间色温变化等复杂光照条件下的稳定成像质量面临挑战，导致曝光不足、色彩偏差和色彩一致性差等问题，影响下游视觉任务的性能。现有的自动模式和轻量级基线无法有效解决这些问题，需要一种轻量且能适应场景的自适应相机参数调整方法来改善成像质量。", "innovation": "提出一种称为ACamera-Net的轻量且场景适应的相机参数调整网络，直接从RAW数据预测最佳曝光和白平衡。ACamera-Net包含两个模块：ACamera-Exposure用于估计ISO，并缓解曝光不足和对比度损失；ACamera-Color用于预测相关色温及增益因子，以提高色彩一致性。该网络优化了边缘设备上的实时推理，可以无缝集成到成像管道中。", "conclusion": "通过在多样化的实际数据上进行训练，该模型能够在各种光照条件下很好地泛化。实验结果表明，ACamera-Net明显提升了图像质量并稳定了感知输出，超过了传统自动模式和轻量级基线，且不依赖额外的图像增强模块。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20586", "html_url": "https://arxiv.org/abs/2510.20586", "title": "GenColorBench: 一种文本到图像生成模型的颜色评估基准", "title_en": "GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models", "authors": "Muhammad Atif Butt,Alexandra Gomez-Villa,Tao Wu,Javier Vazquez-Corral,Joost Van De Weijer,Kai Wang", "background": "近年来，文本到图像生成技术取得了显著进展，生成模型能够从文本生成高质量的图像。然而，这些模型仍然在细粒度的颜色控制方面表现不佳，难以准确匹配文本中指定的颜色。当前基准大多评估组成推理和指令遵循情况，但没有系统地评估颜色精度。颜色在人类视觉感知和沟通中至关重要，对于艺术和设计工作流等领域要求品牌一致性尤为关键。然而，现有的基准要么忽视颜色，要么依赖粗犷的评估，无法评估关键能力如解释RGB值或符合人类预期。", "innovation": "本文提出GenColorBench，这是第一个全面评估文本到图像颜色生成的标准，基于ISCC-NBS和CSS3/X11等颜色系统，包括数值颜色，这些内容在其他地方都不存在。GenColorBench包含44000多个专注于颜色的提示，涵盖了400多种颜色，通过感知评估和自动化评估揭示模型的真实能力。使用GenColorBench评估流行的文本到图像模型发现了性能差异，明确了模型对哪些颜色规范的理解最好，并识别出了失败模式。这些评估将指导精确颜色生成的进步。", "conclusion": "GenColorBench将成为公开的基准，帮助改善精确颜色生成。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20596", "html_url": "https://arxiv.org/abs/2510.20596", "title": "基于相似度原型的跨模态分割无监督领域适应", "title_en": "Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation", "authors": "Ziyu Ye,Chen Ju,Chaofan Ma,Xiaoyun Zhang", "background": "深度学习模型在各种视觉挑战中取得了巨大成功，但当应用于未见过的数据时，这些模型的性能会急剧下降。这是因为模型对领域转换非常敏感，而无监督领域适应试图减少领域差距，避免未见过领域的高成本标注。", "innovation": "提出了一个基于相似度原型的跨模态分割新框架。具体而言，它在一个嵌入空间中学习类别级别的原型，然后引入相似度约束使得这些原型代表各语义类别并且与其他类别可分。此外，通过字典存储从不同图像中提取的原型，预防类别缺失问题，并允许原型对比学习，从而进一步提高性能。", "conclusion": "大量实验表明，该方法在交叉模态分割上的表现优于其他最先进的方法。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20578", "html_url": "https://arxiv.org/abs/2510.20578", "title": "EmbodiedBrain：扩展任务规划性能边界", "title_en": "EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence", "authors": "Ding Zou,Feifan Wang,Mengyu Ge,Siyuan Fan,Zongbing Zhang,Wei Chen,Lingfeng Wang,Zhongyou Hu,Wenrui Yan,Zhengwei Gao,Hao Wang,Weizhao Jin,Yu Zhang,Hainan Zhao,Mingliang Zhang,Xianxian Xi,Yaru Zhang,Wenyuan Li,Zhengguang Gao,Yurui Zhu", "background": "人工智能普遍性（AGI）的成功要求体态AI代理能够在物理环境中实现稳健的空间感知、有效的任务规划和适应性执行。然而，当前的语言模型和多模态语言模型在体态任务中存在显著差距、实时延迟与性能之间的不可避免权衡、以及使用非真实的离线评估指标等问题。这些挑战需要新的方法来应对。", "innovation": "我们提出了EmbodiedBrain，这是一种新型的视觉-语言基础模型，拥有7B和32B参数版本。该框架采用了与代理对齐的数据结构，并集成了大规模监督微调（SFT）、步进增强组相对策略优化（Step-GRPO）等训练方法，还引入了包括生成奖励模型（GRM）在内的全面奖励机制，以提升训练效率。此外，还开发了一个包括通用、规划和端到端仿真基准在内的全面评估系统，并开放了新型挑战性仿真环境，以确保评估的严谨性。", "conclusion": "实验结果表明，EmbodiedBrain在所有评估指标上都取得了优异的表现，确立了体态基础模型的新标准。为了促进下一代通用体态代理的发展，我们开源了所有数据、模型权重和评估方法，详见网址。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20639", "html_url": "https://arxiv.org/abs/2510.20639", "title": "Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging", "title_en": "Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging", "authors": "Ibrahim Ethem Hamamci,Sezgin Er,Suprosanna Shit,Hadrien Reynaud,Dong Yang,Pengfei Guo,Marc Edgar,Daguang Xu,Bernhard Kainz,Bjoern Menze", "background": "近期，3D医学成像中的视觉-语言模型进展得益于大规模配有的自由文本报告的CT数据集、更强的架构和更强大的预训练模型。这使得自动报告生成和基于文本条件的3D图像合成等应用成为可能。然而，现有的方法在高分辨率、长序列体积上仍面临挑战：对比预训练往往会使得视觉编码器与临床语言不一致，而层片级的标记化会模糊细微解剖结构，从而降低了下游任务的诊断性能。", "innovation": "引入了BTB3D（Better Tokens for Better 3D），这是一种因果卷积编码器-解码器，它可以统一2D和3D的训练和推断，同时生成紧凑且频率意识的体模态。通过三个阶段的训练课程，BTB3D在报告生成中提高了BLEU分数，临床F1提高了40%，超过了CT2Rep、CT-CHAT和Merlin；在文本到CT合成中，FID降低了75%，FVD减半，产生了解剖上一致的512*512*241体积。这些结果表明，在3D医学成像中，精确的三维代币化相比于更大的语言基础模型，是更具规模的视觉-语言建模的关键。", "conclusion": "这些结果证明了精确的三维代币化而不是仅依赖更大的语言基础模型，对于3D医学成像中的可扩展视觉-语言建模至关重要。该代码库已在此处提供：this https URL."}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20622", "html_url": "https://arxiv.org/abs/2510.20622", "title": "SeViCES: 统一语义-视觉证据共识以实现长视频理解", "title_en": "SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding", "authors": "Yuan Sheng,Yanbin Hao,Chenxu Li,Shuo Wang,Xiangnan He", "background": "长视频的理解因其复杂、多样且时间上分散的内容而具有挑战性。尽管视频语言模型（Video-LLMs）能够处理数分钟的视频，但将其应用到真正长的序列上往往在计算上是不现实的，并且通常会导致思维不集中或不一致的推理。一种有希望的解决方案是选择最具信息性的帧，但现有方法通常忽略了时间依赖性或依赖单一模态的证据，从而限制了它们提供完整且与查询相关的上下文的能力。", "innovation": "我们提出了一个语义-视觉共识证据选择（SeViCES）框架，以实现有效且可靠的长视频理解。SeViCES 是无需训练的且模型无关的，并引入了两个关键组件。语义-视觉共识帧选择（SVCFS）模块通过（1）一个时序感知语义分支，利用 LLMS 在字幕上的推理解析选择帧，并通过互信息对视觉嵌入与语义评分进行对齐；（2）一个聚类指导的视觉分支。答案共识细化（ACR）模块进一步通过融合证据和限定答案空间来解决基于语义和视觉预测之间的一致性问题。", "conclusion": "在长视频理解基准测验中进行的详细实验显示，SeViCES 在准确性和稳健性方面都优于最先进的方法，表明共识驱动的证据选择对 Video-LLMs 的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20605", "html_url": "https://arxiv.org/abs/2510.20605", "title": "OnlineSplatter：无姿态在线自由移动物体3D重建", "title_en": "OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects", "authors": "Mark He Huang,Lin Geng Foo,Christian Theobalt,Ying Sun,De Wen Soh", "background": "单目视频中自由移动物体的高精度重建仍然极具挑战性，特别是在缺乏可靠的位姿或深度线索以及在任意物体运动情境下。现有方法通常要求提供物体的姿态、深度先验或需要进行束优化，这些都增加了实现的复杂度和限制了应用程序的广泛性。因此，开发一种无需姿态或深度信息、无需手工标注、能在在线场景中实现高效重建的方法尤其重要和必要。", "innovation": "提出了一种名为OnlineSplatter的新型在线前馈框架，该框架直接从RGB帧生成高保真的、以物体为中心的三维高斯模型，不需要相机姿态、深度先验或束优化。通过首先固定重建，逐步细化物体表示，并使用密集的高斯原生域场，保证了模型在处理长视频序列时计算成本恒定。引入了包含潜在外观-几何键和显式方向键的双重键记忆模块，通过时空聚合物体内状态与当前帧特征的融合，实现有效的自由移动物体处理、空间指导下记忆读取以及高效稀疏化，确保重建物体覆盖全面且紧凑。实验结果表明，与现有的基于姿态的三维重建基线相比，OnlineSplatter显著提升了重建质量，并随着观测次数的增加，保持了恒定的内存和运行时间性能。", "conclusion": "OnlineSplatter对单目视频中自由移动物体的三维重建实现了零姿态、在线化和高效化，尤其是当物体的运动不受控制或存在时，该方法能显著优化重建结果，且不影响内存和计算效率。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20661", "html_url": "https://arxiv.org/abs/2510.20661", "title": "UltraHR-100K: 使用大规模高质量数据集增强超高清图像合成", "title_en": "UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset", "authors": "Chen Zhao,En Ci,Yunzhe Xu,Tiehan Fan,Shanyan Guan,Yanhao Ge,Jian Yang,Ying Tai", "background": "超高清（UHR）的文本到图像（T2I）生成技术已经取得了显著进展，但仍面临两大挑战：（1）缺乏大规模的高质量UHR T2I数据集，（2）在超高清场景中忽略针对精细细节合成的特制训练策略。为了应对第一个挑战，该研究引入了UltraHR-100K数据集，这是一个由100K高质量图像组成的超高清数据集，每张图像均超过3K分辨率，并且根据细节丰富度、内容复杂性和审美质量进行了精心筛选。为了应对第二个挑战，该研究提出了一种频率感知的后训练方法，以增强T2I扩散模型的细节生成能力。这种方法包括（i）细节导向的时间步采样（DOTS），专注于关键去噪步骤的学习；以及（ii）软加权频率正则化（SWFR），利用离散傅里叶变换（DFT）实现频率组件的软约束，促进高频细节的保留。", "innovation": "该研究创新性地提出了UltraHR-100K数据集和一种频率感知的后训练方法。具体来说，提出了细节导向的时间步采样（DOTS）和软加权频率正则化（SWFR），以增强UHR场景中T2I扩散模型的细节生成能力。", "conclusion": "在所提出的UltraHR-eval4K基准上的 extensive 实验表明，该方法显著提高了UHR图像生成的精细细节质量和整体保真度。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20696", "html_url": "https://arxiv.org/abs/2510.20696", "title": "诊断视觉推理：挑战、见解与未来方向", "title_en": "Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward", "authors": "Jing Bi,Guangyu Sun,Ali Vosoughi,Chen Chen,Chenliang Xu", "background": "现有的多模态大语言模型（MLLMs）通过结合视觉和文本推理，在解决复杂视觉任务时利用链式推理（CoT）提示，但仍存在视觉幻觉和对文本先验过度依赖的问题。本文提出了一种三阶段评估框架对最先进的视觉-语言模型进行了系统性诊断，揭示了关键的失败模式。", "innovation": "本文提出了基于代理的架构，将LLM推理与轻量级视觉模块相结合，实现了对推理链的精细分析和迭代优化。研究结果表明，未来的视觉推理模型应更广泛地集成专用于分析视觉内容的工具。该系统在MMMU和MathVista上取得了显著的提升（+10.3和+6.0），甚至超过了更大的模型。", "conclusion": "该研究系统的框架和评估套件将被公开，以促进未来的研究工作。研究强调了未来视觉推理模型需要整合更多专门的工具来分析视觉内容，并且现有的系统已经取得了显著的成果。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20579", "html_url": "https://arxiv.org/abs/2510.20579", "title": "Open-o3 视频：具有显式空间-时间证据的接地视频推理", "title_en": "Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence", "authors": "Jiahao Meng,Xiangtai Li,Haochen Wang,Yue Tan,Tao Zhang,Lingdong Kong,Yunhai Tong,Anran Wang,Zhiyang Teng,Yujing Wang,Zhuochen Wang", "background": "大多数视频推理模型只生成文本推理痕迹，而不标明关键时刻和关键证据的出现时间与地点。为图像设计的证据中心推理模型（如OpenAI-o3）近年来引起了广泛兴趣，但将这种能力扩展到视频中更具挑战性，因为需要在动态场景中进行联合时序追踪和空间定位。现有数据集要么提供视频的时间跨度，要么提供图像的时空盒子标注，但缺乏统一的时空监督和推理痕迹。", "innovation": "引入了Open-o3 Video框架，这是一个非代理框架，将显式的时空证据整合到视频推理中。通过精心收集和设计训练策略，解决时空跟踪和空间定位的挑战。模型突出关键时间戳、对象和边界框，使推理基于具体的视觉观察。为此，构建了两个高质量数据集STGR-CoT-30k和STGR-RL-36k，其中包含了精心构造的时空注释。采用了一种冷启动的强化学习策略，结合多个特别设计的奖励来促进回答准确性、时序对齐和空间精度。Open-o3 Video在V-STAR基准测试中取得了领先性能，在Qwen2.5-VL基准上实现了mAM增加14.4%和mLGM增加24.2%；并在VideoMME、WorldSense、VideoMMMU和TVGBench等多个视频理解基准测试中显示出一致的改进。", "conclusion": "Open-o3 Video不仅提高了多个视频理解基准的性能，还通过推理痕迹提供了测试时可扩展性的有用信号，有助于信心验证并提高答案的可靠性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20673", "html_url": "https://arxiv.org/abs/2510.20673", "title": "通过权重偏差校正和位级聚类子采样实现高效多比特量化网络训练", "title_en": "Efficient Multi-bit Quantization Network Training via Weight Bias Correction and Bit-wise Coreset Sampling", "authors": "Jinhee Kim,Jae Jun An,Kang Eun Jeon,Jong Hwan Ko", "background": "多比特量化网络通过支持单一模型内的多种精度级别，促进了深度神经网络的灵活部署。然而，现有的方法存在显著的训练开销，因为每次支持每种位宽时都需要进行完整数据集的更新，导致开销线性增加。此外，为了支持额外或中间的精度选项，常常需要额外的微调阶段，进一步增加了整体训练负担。", "innovation": "提出了两种减少训练开销而不牺牲模型性能的技术：(i) 通过权重偏差校正实现共享批归一化，消除为每种位宽进行微调的需要，中和量化偏置并调整激活分布；(ii) 位级聚类子采样策略，让每个子模型只使用通过基于梯度的重要性得分选择的紧凑且信息丰富的子集来进行训练，利用隐含的知识转移现象。", "conclusion": "在CIFAR-10/100、TinyImageNet和ImageNet-1K上的实验表明，该方法在减少高达7.88倍的训练时间的同时，实现了具有竞争力或更优的准确性。相关代码已发布。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20634", "html_url": "https://arxiv.org/abs/2510.20634", "title": "深度学习在牙科图像分析中的应用：公开数据集、方法学和新兴挑战的系统性综述", "title_en": "Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges", "authors": "Zhenhuan Zhou,Jingbo Zhu,Yuchen Zhang,Xiaohang Guan,Peng Wang,Tao Li", "background": "牙科图像的高效分析和处理对于实现精确诊断和最佳治疗规划至关重要。然而，牙科成像存在一些固有的挑战，如对比度低、金属伪影以及投射角度变化等。这些问题与临床医生专业知识差异导致的主观性相结合，使得手工解读常耗时且不一致。人工智能（AI）驱动的自动化牙科图像分析（DIA）为此提供了希望的解决方案，成为计算机辅助牙科诊断和治疗的重要组成部分。在各种AI技术中，深度学习（DL）因其优越的特征提取和表示能力而最为广泛地应用和影响深远。为了总结这一领域的最新进展，本文重点介绍了DL研究中的两大基础方面——数据集和模型。本研究系统性地回顾了260项关于DL在牙科图像分析中的应用的研究，包括关于公开牙科数据集的49篇文章和基于DL的211种算法。我们首先介绍了牙科影像的基本概念，总结了现有数据集的特点和获取方法，随后介绍了DL的基础技术，并按照不同的牙科图像分析任务分类相关模型和算法，分析了它们的网络结构、优化策略、训练方法和性能，还总结了在DIA领域常用的训练和评估指标，最后讨论了现有研究面临的主要挑战并展望了未来的研究方向。我们希望本文为该领域的研究者提供有价值的、系统性的参考，所有补充材料和详细的比较表将在GitHub上公开提供，", "innovation": "本文系统性地回顾了260项关于深度学习在牙科图像分析中的应用的研究，涵盖了公开的数据集和基于深度学习的算法。通过对已有的研究表明，深度学习在牙科图像分析中的应用取得了显著进展，并且对数据集和模型进行了详细分类和分析，同时还指出了当前研究的挑战和未来可能的研究方向，有助于推动该领域的发展。", "conclusion": "本文为该领域的研究者提供了重要的、系统性的参考，所有补充材料和详细的比较表将在GitHub上公开提供。现有研究虽然取得了进展，但仍面临多种挑战，未来的研究应继续关注这些领域，以促进深度学习在牙科图像分析中的应用和改进。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20669", "html_url": "https://arxiv.org/abs/2510.20669", "title": "HybridSOMSpikeNet: 结合可微软自组织映射和尖峰动力学的深度模型用于废弃物分类", "title_en": "HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing Maps and Spiking Dynamics for Waste Classification", "authors": "Debojyoti Ghosh,Adrijit Goswami", "background": "准确的废弃物分类对于实现可持续的废弃物管理和减少城市化的环境足迹至关重要。可回收材料的误分类导致填埋场积累、回收效率低下以及温室气体排放增加。因此，本文研究提出了一种新的混合深度学习框架HybridSOMSpikeNet，该框架结合了卷积特征提取、可微自主组织以及尖峰启发式的时序处理，以实现智能和节能的废弃物分类。", "innovation": "HybridSOMSpikeNet框架集成了卷积特征提取、可微软自组织映射和尖峰启发式的时序处理，预训练的ResNet-152骨干网络用于提取深层次的空间表示，由Differenceable Soft Self-Organizing Map (Soft-SOM)增强拓扑聚类和可解释性，尖峰神经元头通过离散时间步骤积累激活值，提高鲁棒性和泛化能力。该模型在一种十类废弃物数据集上训练，测试准确率达到97.39%，优于多种现有架构，同时保持轻量级的计算配置，适合实际部署。", "conclusion": "HybridSOMSpikeNet框架不仅具有技术上的创新，还能提供实际的环境效益。通过实现精确和自动的废弃物分拣，它支持更高的回收效率，减少可回收流中的污染，并减少废物处理过程中的生态和运营成本。该方法与全球可持续发展目标如联合国可持续发展目标11（可持续城市和社区）和12（负责任消费和生产）相契合，为清洁城市、循环经济及智能环保管理系统贡献了重要支持。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20707", "html_url": "https://arxiv.org/abs/2510.20707", "title": "混合重要性与多样性：大型视觉语言模型中KV缓存压缩的联合优化", "title_en": "Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models", "authors": "Xuyang Liu,Xiyan Gui,Yuchao Zhang,Linfeng Zhang", "background": "近年来，大型视觉语言模型（LVLMs）展示了在处理扩展多模态序列方面的显著能力，但随之而来的键值（KV）缓存扩展引发了内存瓶颈问题，这从根本上限制了其部署的扩展性。现有的KV缓存压缩方法主要关注保留高重要性的KV对，以尽量减少存储需求，但往往忽视了多模态KV缓存中出现的特定模态语义冗余模式。", "innovation": "本文分析了KV缓存在LVLMs中除了简单的重要程度之外的多样性冗余，并提出了一种名为MixKV的新方法。MixKV混合了重要性和多样性，根据注意力头的语义冗余调整压缩策略，同时在压缩KV对时选择性地平衡多样性与重要性。实验结果显示，MixKV在多种多模态理解基准测试中均优于现有方法，且在极高的压缩比下仍保持了相当的推理效率。", "conclusion": "MixKV在多个多模态理解评估基准中均显示了持续改进现有方法的效果，在极高压缩比率下，特别是在GUI对象定位任务中的SnapKV和AdaKV，分别提高了8.0%和9.0%的性能。该方法还无缝扩展到其他大型语言模型，获得类似性能增益。完整的代码可以在指定的网页地址找到。\n"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20726", "html_url": "https://arxiv.org/abs/2510.20726", "title": "AutoScape：几何一致性的长时场景生成", "title_en": "AutoScape: Geometry-Consistent Long-Horizon Scene Generation", "authors": "Jiacheng Chen,Ziyu Jiang,Mingfu Liang,Bingbing Zhuang,Jong-Chyi Su,Sparsh Garg,Ying Wu,Manmohan Chandraker", "background": "当前的驾驶场景生成技术主要关注于生成高质量的视频帧，但在保持长时间场景的一致性方面存在局限性。论文提出的AutoScape框架旨在通过生成长期一致的驾驶场景来改进这一领域。", "innovation": "AutoScape框架的核心是提出了一种新颖的RGB-D扩散模型，该模型可以根据已生成的关键帧的场景几何结构，迭代生成几何上一致的稀疏关键帧。通过在共享的潜在空间中联合处理图像和深度，以及使用与扭曲一致的引导调整采样过程，该模型能够生成长达20秒的逼真且几何一致的驾驶视频，显著提高了FID和FVD指标。", "conclusion": "AutoScape框架通过生成大量一致的高质量视频帧，能够显著提升驾驶视频的长期视觉一致性和现实感，相较之前的最佳水平分别提升了48.6%和43.0%的FID和FVD得分。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20754", "html_url": "https://arxiv.org/abs/2510.20754", "title": "ACS-SegNet: 一种基于注意力机制的CNN-SegFormer分割网络在组织病理学中的应用", "title_en": "ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for Tissue Segmentation in Histopathology", "authors": "Nima Torbati,Anastasia Meshcheryakova,Ramona Woitek,Diana Mechtcheriakova,Amirreza Mahbod", "background": "组织病理学图像分析在各种疾病的计算机辅助诊断中起着关键作用。已开发的算法中，基于深度学习的方法在多个任务中展现了优秀的性能，包括组织学图像中的语义组织分割。", "innovation": "提出了一种基于注意力驱动的卷积神经网络（CNN）和视觉变换器（ViT）特征融合的新型方法，集成在一个统一的双编码器模型中，以提高语义分割的性能。实验表明，该模型在两个公开的数据集上均优于现有方法和基线基准。", "conclusion": "本研究提出的ACS-SegNet模型取得了比现有和基线方法更好的效果，在GCPS数据集上实现了μIoU/μDice评分76.79%/86.87%，在PUMA数据集上实现了64.93%/76.60%，并在GitHub上公开了该方法的实现。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20708", "html_url": "https://arxiv.org/abs/2510.20708", "title": "ALICE-LRI：无校准元数据的旋转LiDAR传感器无损范围图像生成的通用方法", "title_en": "ALICE-LRI: A General Method for Lossless Range Image Generation for Spinning LiDAR Sensors without Calibration Metadata", "authors": "Samuel Soutullo,Miguel Yermo,David L. Vilariño,Óscar G. Lorenzo,José C. Cabaleiro,Francisco F. Rivera", "background": "3D LiDAR传感器在自主导航、环境监测和精密制图等遥感应用中至关重要。为了高效处理这些传感器生成的大量点云，通常将LiDAR数据投影到2D范围图像中，按角度位置和距离组织点。虽然这些范围图像表示法有助于高效处理，但传统的投影方法存在根本的几何不一致性，导致不可逆的信息丢失，影响高保真应用。", "innovation": "我们提出了ALICE-LRI（自动LiDAR固有校准估计以生成无损范围图像），这是第一个通用的、无传感器类型依赖的方法，可以在无需制造商元数据或校准文件的情况下，从旋转LiDAR点云生成无损范围图像。该算法能自动反向设计任何旋转LiDAR传感器的固有几何结构，推断关键参数（如激光束配置、角度分布及每束激光的校准修正），从而实现无损投影和完整的点云重建，没有任何点丢失。", "conclusion": "在完整Kitti和DurLAR数据集上的全面评估表明，ALICE-LRI能够实现完美的点保留，在所有点云中无点丢失。几何精度保持在传感器精度限制以内，实现了几何无损性和实时性能。我们还展示了压缩案例研究，验证了显著的下游效益，证明了在实际应用中的质量改进。从近似到无损的LiDAR投影的范式转变开启了对完全几何保留要求的高精度遥感应用的新可能性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20766", "html_url": "https://arxiv.org/abs/2510.20766", "title": "DyPE: 动态位置外推用于超高清分辨率的扩散过程", "title_en": "DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion", "authors": "Noam Issachar,Guy Yariv,Sagie Benaim,Yossi Adi,Dani Lischinski,Raanan Fattal", "background": "扩散变换器模型可以生成具有非凡保真度和细节的图像，但由于自我注意力机制在图像令牌数量上呈现二次缩放，训练它们在超高清分辨率上仍然非常昂贵。现有的方法无法在不显著增加采样成本的情况下，让预训练的扩散变换器在远超原训练数据分辨率的情况下生成图像。DyPE方法利用扩散过程中固有的频谱进展，即低频结构早于高频结构收敛。具体来说，DyPE在每次扩散步骤中动态调整模型的位置编码，使其频率谱与生成过程当前阶段相匹配，从而显著提高了超高清分辨率下图像生成的性能，特别是在分辨率较高的情况下，效果更加显著。", "innovation": "提出了一个名为DyPE的训练无需额外成本的方法，允许预训练的扩散变换器在显著超过原始训练数据分辨率的情况下生成图像。该方法通过利用扩散过程中的固有频谱进展，动态调整模型的位置编码，匹配当前生成过程的频率谱，从而在不增加额外采样成本的情况下，生成超高分辨率的图像。在多种基准测试中，DyPE方法能够持续改善性能，并在超高清分辨率图像生成中达到最先进的保真度。", "conclusion": "DyPE方法能够在不增加额外采样成本的情况下，让预训练的扩散变换器在远超原始训练数据分辨率的情况下生成图像。在多个基准测试中，DyPE方法在超高清分辨率图像生成中表现优异，特别是在高分辨率下，其增益尤为显著。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20794", "html_url": "https://arxiv.org/abs/2510.20794", "title": "雷达与摄像机融合多目标跟踪：在线校准与共同特征利用", "title_en": "Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common Feature", "authors": "Lei Cheng,Siyang Cao", "background": "许多研究未能充分利用雷达数据，而将其作为辅助手段使用，尽管雷达能在三维世界坐标系统中提供精确的目标距离/深度信息。本文提出了一个融合雷达和摄像机数据的多目标跟踪（MOT）框架，旨在通过在线雷达-摄像机校准简化这两种传感器检测结果的集成过程，并利用共同特征实现自动关联，最终提升准确性和可靠性。", "innovation": "1. 开发了一种雷达-摄像机融合MOT框架，通过在线雷达-摄像机校准简化了这两种传感器的检测结果集成。2. 利用雷达和摄像机数据之间的共同特征准确地推导出检测对象在现实世界中的位置。3. 采用特征匹配和类别一致性检查超越了单纯的位置匹配，提升了传感器关联的准确性。本文是首次研究雷达-摄像机共同特征的集成及其在线校准用于MOT。", "conclusion": "通过在线雷达-摄像机校准和利用共同特征，该框架能够简化雷达-摄像机映射过程，提高跟踪精度。通过在受控环境和实际交通场景中的实验验证了其有效性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20803", "html_url": "https://arxiv.org/abs/2510.20803", "title": "ARGenSeg：基于自回归图像生成模型的图像分割", "title_en": "ARGenSeg: Image Segmentation with Autoregressive Image Generation Model", "authors": "Xiaolong Wang,Lixiang Ru,Ziyuan Huang,Kaixiang Ji,Dandan Zheng,Jingdong Chen,Jun Zhou", "background": "在多模态大型语言模型（MLLMs）中，将图像分割集成到MM-LLMs中通常使用边界点表示或专用分割头。这些方法依赖于离散表示或提供给任务特定解码器的语义提示，这限制了MM-LLMs捕获细粒度视觉细节的能力。缺点是性能和计算效率较低，尤其是对于需要精细分割的任务。", "innovation": "本文提出了一个基于自回归生成的新颖框架——ARGenSeg，统一实现了多模态理解和像素级感知。该方法采用了图像生成的方式，利用MLLM输出视觉令牌并通过通用VQ-VAE反序列化为图像，使得分割完全依赖于MLLM的像素级理解能力。为减少推理延迟，采用了一种多尺度预测策略同时生成所需的视觉令牌。实验表明，该方法在多个分割数据集上超过了之前的SOTA方法，同时显著提高了推理速度，保持了强大的理解能力。", "conclusion": "本研究通过引入ARGenSeg框架，有效地改进了图像分割在MM-LLMs中的应用，不仅提升了分割质量和速度，还增强了MM-LLMs对细粒度视觉特征的捕捉能力，具有广泛的应用前景。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20771", "html_url": "https://arxiv.org/abs/2510.20771", "title": "AlphaFlow: 理解和改进MeanFlow模型", "title_en": "AlphaFlow: Understanding and Improving MeanFlow Models", "authors": "Huijie Zhang,Aliaksandr Siarohin,Willi Menapace,Michael Vasilkovsky,Sergey Tulyakov,Qing Qu,Ivan Skorokhodov", "background": "最近，MeanFlow框架作为一种强大的少量步骤生成建模框架，从头开始训练表现出强大的效果，但其背后的机理尚未完全理解。这项工作揭示了MeanFlow目标可以自然分解为轨迹流匹配和轨迹一致性两部分。通过对梯度的分析，发现这两个部分是强烈负相关的，导致优化冲突和收敛速度缓慢。因此，有必要理解这些模型背后的工作机制，并改进它们的表现。", "innovation": "引入了$\boldsymbol{\text{α}}$-Flow，这是一种统一了轨迹流匹配、捷径模型和MeanFlow的一系列目标体系，通过逐步过渡从轨迹流匹配到MeanFlow的方式，解决目标之间的冲突，实现了更快速和更稳定的收敛。实验结果表明，$\boldsymbol{\text{α}}$-Flow在从零开始训练的ImageNet-1K 256x256数据集上，使用原始DiT模型时，持续优于MeanFlow，特别是在大模型（$\boldsymbol{\text{α}}$-Flow-XL/2+）上取得了新的最佳结果，达到了FID分数2.58（1-NFE）和2.15（2-NFE）的新高。", "conclusion": "实验结果表明，$\boldsymbol{\text{α}}$-Flow通过其新的优化方法在从零开始训练的少量步骤生成建模中取得了更好的结果，特别是在大模型上线性判别器的设置下更是超越了原始的MeanFlow。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20776", "html_url": "https://arxiv.org/abs/2510.20776", "title": "CUPID: 单张图像的姿势导向生成3D重建", "title_en": "CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image", "authors": "Binbin Huang,Haobin Duan,Yiqun Zhao,Zibo Zhao,Yi Ma,Shenghua Gao", "background": "当前的3D重建技术主要依赖多张图像进行重建，而该项研究则专注于利用单张图像生成3D重建结果。研究成果表明，这种方法在重建质量和准确性方面具有显著优势，能够提供更高的视觉保真度和更精细的结构细节，并且在提升解析度指标PSNR上有着明显的提升，同时在减少体素间距离方面也有显著改进。这填补了单幅图像条件下3D重建技术的空白，为未来的相关研究提供了新的思路和方法。", "innovation": "该创新点在于提出了一种基于生成的方法Cupid，它能够从单张2D图像中精确推断出相机姿态、3D形状和表面纹理，实现了一种新的基于条件采样的3D重建方法，通过联合生成体素和像素-体素对应关系，使得姿态和形状估计在统一的生成框架下更加稳健。采用的两阶段流匹配管道，既完成了初步的几何结构生成，又通过姿态对齐图像特征的整合来增强结构的准确性及外观细节的表现。", "conclusion": "实验结果表明，Cupid在多项评估指标中均优于现有主流的3D重建方法，特别是在提升解析度和结构准确度方面表现出色，与此同时保持了与单目估计方法相同的姿态准确性。与现有的3D生成模型相比，Cupid提供更高的视觉保真度。该方法能够提供更为沉浸式的3D重建结果展示，从而增强了对3D重建方法未来发展的期望。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20807", "html_url": "https://arxiv.org/abs/2510.20807", "title": "像素空间时空变换器在动态物理仿真视频预测中的应用", "title_en": "Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers", "authors": "Dean L Slack,G Thomas Hudson,Thomas Winterbottom,Noura Al Moubayed", "background": "受到自回归大型语言模型性能和扩展性的启发，基于变压器的模型在视觉领域取得了显著的成功。本研究旨在探索一种简单的端到端方法，通过变压器模型进行视频预测，并比较了不同的空时自注意力布局。研究聚焦于物理仿真随时间的因果建模，这是现有生成视频方法的常见问题。研究试图通过结合物理对象追踪指标和物理仿真数据集的无监督训练，来分离空时推理。", "innovation": "研究提出了一个简单的纯变压器模型，用于自回归视频预测，使用连续的像素空间表示法。该方法无需复杂的训练策略或潜在特征学习组件，通过在现有潜在空间方法的基础上，显著延长了准确性预测的时间跨度，最多可提高50%，同时保持了常见视频质量指标的可比性能。此外，研究还进行了可解释性实验，以识别网络区域中对准确估计偏微分方程（PDE）仿真参数有用的编码信息，并发现在一定程度上可以推广到估计输入分布之外的仿真参数。", "conclusion": "这项工作为基于注意力机制的时空视频建模提供了一个简单、参数高效且可解释的平台。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20812", "html_url": "https://arxiv.org/abs/2510.20812", "title": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation", "title_en": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation", "authors": "Yuhan Liu,Lianhui Qin,Shengjie Wang", "background": "大型的视觉语言模型（VLMs）已经在多模态理解方面取得了显著进展，但在处理细粒度图形元素与密集文本注释交织的信息密集型图像时，它们遇到了挑战。主要挑战在于精确地在密集布局中定位关键线索以及进行多跳推理以整合分散的证据。现有的方法在这些密集信息场景下难以获取准确的结果。", "innovation": "本文提出了一种名为Speculative Verdict（SV）的训练无损框架，该框架借鉴了推测性解码的思想，结合了多个轻量级草稿专家和一个大型判决模型。该框架在草稿阶段，小VLMs作为草稿专家生成多种推理路径，提供多样化的定位候选；在判决阶段，强大的VLM综合这些路径生成最终答案，尽量减少计算成本同时获得正确答案。此外，SV引入了一种共识专家选择机制，仅传递高一致性的推理路径至判决阶段，进一步提升效率和准确度。", "conclusion": "实验证明，SV在InfographicVQA、ChartMuseum、ChartQAPro和HR-Bench 4K等信息密集型和高分辨率视觉问答基准上取得了稳定的改进，通过对多个部分准确推理路径的综合利用，SV实现了错误纠正和成本效率。所有代码可在以下链接获取。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20820", "html_url": "https://arxiv.org/abs/2510.20820", "title": "LayerComposer：基于空间感知分层画布的交互式个性化T2I", "title_en": "LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas", "authors": "Guocheng Gordon Qian,Ruihang Zhang,Tsai-Shien Chen,Yusuf Dalva,Anujraaj Argo Goyal,Willi Menapace,Ivan Skorokhodov,Meng Dong,Arpit Sahni,Daniil Ostashev,Ju Hu,Sergey Tulyakov,Kuan-Chieh Jackson Wang", "background": "尽管现有的个性化生成模型在视觉保真度方面表现出色，但它们缺乏对空间组成进行交互控制的能力，并且在多主题场景下的性能不佳。", "innovation": "本文提出了LayerComposer，一种交互式框架，用于实现多主题的文本到图像生成。主要创新点包括：（1）分层画布，这是一种新颖的表现形式，其中每个主题都在独立的层上，以实现无遮挡的组合；（2）锁定机制，可以在保留特定层高保真度的同时，让其余层灵活适应周围环境。", "conclusion": "广泛的实验表明，与多主题个性化图像生成的现有方法相比，LayerComposer在空间控制和身份保存方面具有明显优势。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20819", "html_url": "https://arxiv.org/abs/2510.20819", "title": "使用对比性和预测性潜在扩散桥通向前向的多模态翻译", "title_en": "Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge", "authors": "Nimrod Berman,Omkar Joglekar,Eitan Kosman,Dotan Di Castro,Omri Azencot", "background": "近期生成建模的进展使扩散模型成为从复杂数据分布采样的前沿工具。虽然这些模型在单模态领域（如图像和音频）中展现出了卓越的成果，但将其能力扩展到模态翻译（MT），即跨不同感官模态进行信息转换，仍是一个未解决的挑战。现有方法通常依赖严格假设，如共享维度、高斯源先验和特定模态的架构，这些假设限制了它们的普适性和理论基础。", "innovation": "本文提出了一种基于潜在变量扩散桥模型扩展的一般性模态翻译框架——潜在去噪扩散桥模型（LDDBM）。主要创新包括：在共享的潜在空间中操作，许可任意模态间的桥梁学习；引入对比性对齐损失以确保配对样本的语义一致性；设计了一个领域无关的编码器-解码器架构，针对潜在空间中的噪声预测；并提出预测性损失以指导训练以实现准确的跨域翻译，同时探讨了多种训练策略以提高稳定性。", "conclusion": "该方法支持任意模态对，并在多视图到3D形状生成、图像超分辨率和多视图场景合成等多个MT任务中表现强劲。全面的实验和消融试验验证了我们框架的有效性，建立了跨领域翻译领域的新的基准线。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20822", "html_url": "https://arxiv.org/abs/2510.20822", "title": "HoloCine：整体生成影视多镜头长视频叙事", "title_en": "HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives", "authors": "Yihao Meng,Hao Ouyang,Yue Yu,Qiuyu Wang,Wen Wang,Ka Leong Cheng,Hanlin Wang,Yixuan Li,Cheng Chen,Yanhong Zeng,Yujun Shen,Huamin Qu", "background": "当前最先进的文本到视频模型在生成孤立片段方面表现良好，但在创造连贯的多镜头叙事方面仍然存在不足，而后者则是叙述的核心。现有的模型难以保证从首镜头到最后镜头之间的全局一致性。", "innovation": "HoloCine模型通过全局一致性的整体生成场景来填补叙事缺口，其架构采用窗跨注意力机制将文本提示定位到具体的镜头，并使用稀疏跨镜头自我注意力模式以确保分钟级别的生成效率。HoloCine不仅在叙述连贯性方面达到新的顶点，还发展了角色和场景的持久记忆，以及对电影技术的直观理解。", "conclusion": "HoloCine标志着从片段合成向自动化电影制作的转折点，使端到端的电影创作成为可实现的未来。相关代码已公开。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20814", "html_url": "https://arxiv.org/abs/2510.20814", "title": "SpectraMorph: 结构化潜在学习在自我监督超分辨率中的应用", "title_en": "SpectraMorph: Structured Latent Learning for Self-Supervised Hyperspectral Super-Resolution", "authors": "Ritik Shah,Marco F Duarte", "background": "高光谱传感器能够捕捉每个像素密集的光谱数据，但存在空间分辨率低的问题，导致图像边界模糊和混合像素效应。多光谱、RGB或全色相机等共定位的伴生传感器能够提供高空间分辨率的细节，这激励了通过融合高光谱图像和多光谱图像来实现高光谱超分辨率的策略（HSI-MSI）。现有的基于深度学习的方法表现非常强，但这种方法依赖于不透明的回归模型，缺乏可解释性，并且在多光谱图像的通道数量非常少的情况下表现不佳。", "innovation": "提出了SpectraMorph，一种基于物理的自我监督融合框架，具有结构化的潜在空间。该方法不依赖直接的回归，而是引入了一个解混瓶颈：从低分辨率的高光谱图像中提取端元签名，并使用紧凑型多层感知器从多光谱图像预测类丰度图。光谱通过线性混合重建，训练通过多光谱传感器的光谱响应函数在自我监督的方式下进行。SpectraMorph产生的中间产物具有可解释性，能够在不到一分钟内完成训练，并且即使只有单通道（全色）的多光谱图像也能保持鲁棒性。实验结果表明，SpectraMorph在合成和真实世界数据集上优于最先进的无监督/自我监督基准，同时在有监督基准方面也非常有竞争力。", "conclusion": "SpectraMorph在合成和真实世界数据集上展示了其优越性，不仅持续超越最先进的无监督/自我监督基准，而且还保持了与有监督基准的竞争力。该方法特别适用于单通道多光谱图像，并且通过自我监督训练能够快速高效地进行。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19917", "html_url": "https://arxiv.org/abs/2510.19917", "title": "FINDER: 噪声数据集中的特征推断使用特征空间残差", "title_en": "FINDER: Feature Inference on Noisy Datasets using Eigenspace Residuals", "authors": "Trajan Murphy,Akshunna S. Dogra,Hanfeng Gu,Caleb Meredith,Mark Kon,Julio Enrique Castrillion-Candas", "background": "嘈杂的数据集（信噪比低、样本量小、数据收集故障等）仍然是分类方法研究的关键前沿领域，具有理论和实际意义。现有方法在处理这些数据集时面临挑战，因此需要一种新的框架来有效处理这些噪声数据集。", "innovation": "文章提出了FINDER框架，这是一种用于分析通用分类问题的严格框架，并为嘈杂的数据集设计了定制化的算法。该框架利用基本的随机分析思想，将特征学习和推理阶段与数据集固有的随机性相结合。通过Kosambi-Karhunen-Loéve展开（KLE）来分解特征为可计算的不可约成分，从而利用特征空间的特征解析数据的不同类别。实验结果表明，FINDER在多个数据不足的科学领域取得了最先进的突破，如阿尔茨海默病阶段分类和遥感森林砍伐检测。", "conclusion": "FINDER框架在处理噪声数据集时预期优于现有方法，但也存在功能障碍和其他限制。文章还讨论了FINDER的有效性和其失效模式。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19986", "html_url": "https://arxiv.org/abs/2510.19986", "title": "使用大型语言模型和检索增强生成自动化Iconclass分类：宗教木版画的大规模分类", "title_en": "Automating Iconclass: LLMs and RAG for Large-Scale Classification of Religious Woodcuts", "authors": "Drew B. Thomas", "background": "目前，对于早期现代时期的宗教图像分类，传统的基于图像和关键词搜索的方法存在精度较低的问题。为了克服这些问题，本文提出了一种新的方法，结合使用大型语言模型（LLMs）、向量数据库和检索增强生成（RAG），通过对这些图像提供完整的页面背景信息，利用LLM生成包含视觉和文本元素的详细描述，并通过混合向量搜索与相关Iconclass代码匹配。", "innovation": "该方法能够实现5级分类87%和4级分类92%的精度，显著优于传统的基于图像和关键词的方法。通过使用全页描述和RAG技术，系统提高了分类准确性，提供了一个强大的工具用于大规模分析早期现代视觉档案。这标志着LLMs和RAG在艺术史和数字人文研究中的应用潜力日益增大。", "conclusion": "本文提出的方法通过集成大型语言模型、向量数据库和检索增强生成，利用完整的页面背景信息生成综合的描述，并通过混合向量搜索进行分类，提高了早期现代宗教图像分类的准确性和效率，特别是在大规模研究中的应用。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20193", "html_url": "https://arxiv.org/abs/2510.20193", "title": "多媒体感知的问答：检索与跨模态推理架构综述", "title_en": "Multimedia-Aware Question Answering: A Review of Retrieval and Cross-Modal Reasoning Architectures", "authors": "Rahul Raja,Arpita Vats", "background": "传统的问答系统依赖于结构化的文本数据，但多媒体内容（图像、音频、视频和结构化元数据）的快速增长引入了检索增强问答的新挑战和机会。因此，需要新的架构来整合多媒体检索管道，特别是在视觉、语言和音频模ality与用户查询的对齐方面。", "innovation": "本文综述了利用跨模态推理技术的问答系统的最新进展，这些系统能够整合多媒体检索管道，并根据不同类型的检索方法、融合技术和答案生成策略进行分类。文章还分析了基准数据集、评估协议以及性能权衡，并指出了诸如跨模态对齐、延迟和准确性权衡、语义接地等关键挑战，同时还提出了相关开放式问题和未来研究方向，为构建更具鲁棒性和上下文意识的问答系统提供指导", "conclusion": "本文概述了多媒体增强问答领域的关键挑战和研究方向，指出了现有方法的局限性，并提出了未来研究的潜在机会，以进一步提升基于多媒体数据的问答系统的性能和实用性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20108", "html_url": "https://arxiv.org/abs/2510.20108", "title": "原型为何会坍缩：诊断与预防原型自监督学习中的部分坍缩", "title_en": "Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning", "authors": "Gabriel Y. Arteaga,Marius Aasan,Rwiddhi Chakraborty,Martine Hjelkrem-Tan,Thalles Silva,Michael Kampffmeyer,Adín Ramírez Rivera", "background": "现有的原型半监督学习方法普遍存在部分原型坍缩的问题，即多个原型向几乎相同的表现收敛。这削弱了它们的主要目标——提供多样化和信息丰富的目标来引导编码器生成丰富的表示——并且迫使实践者增加参数或添加随机规则来缓解症状而非解决问题的核心原因。研究表明，这种困境在编码器和原型的共同优化过程中产生，导致出现捷径学习，即在训练早期，原型朝冗余的表现收敛，尽管未必会增强表现的多样化。", "innovation": "为解决这一问题，作者提出了一种完全解耦的训练策略，该策略分别对原型和编码器进行训练，而不是联合优化。具体而言，作者将原型建模为一个高斯混合模型，使用在线期望最大化风格的程序更新，与编码器的损失独立。这种简洁而原则的解耦方法能有效地消除原型坍缩，无需显式的正则化处理，并且能始终提供多样化的原型和更强的下游性能。", "conclusion": "该研究通过实验证明，分离编码器和原型的训练可以有效防止原型坍缩，从而提高表示的多样化和下游任务的性能，为解决原型自监督学习中的关键问题提供了新的思路。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20012", "html_url": "https://arxiv.org/abs/2510.20012", "title": "基于AI的阻力训练中活动范围变化的姿态分析与运动学建模", "title_en": "AI Pose Analysis and Kinematic Profiling of Range-of-Motion Variations in Resistance Training", "authors": "Adam Diamant", "background": "该研究利用AI技术开发了一套姿态估计管道，用于精确量化阻力训练中的运动学。研究使用了Wolf等（2025）关于8种上身练习在26名参与者中进行的全长范围（fROM）和伸展长度部分范围（pROM）训练的视频数据。通过处理280个记录，提取了帧级的关节角度轨迹，以分析不同练习中的活动范围、节奏以及向心/离心阶段的持续时间。研究采用了随机效应荟萃分析模型来应对参与者内部和练习间的变化。结果表明，pROM重复的活动范围较小，整体持续时间较短，尤其是在运动的离心阶段。方差分析显示，个体差异是导致变异的主要因素，尽管存在不同治疗效应的异质性。研究表明，pROM与fROM在活动范围之外，在执行动态和一致性方面也存在差异，这进一步表明基于AI的方法对于推进研究和改进阻力训练处方的潜力。", "innovation": "研究开发了一套基于AI的姿态估计管道，用于精确诊断阻力训练中的运动学变化。这项工作通过使用随机效应荟萃分析模型，能更准确地量化不同练习中的个体差异，并且引入了一个新颖的指标，%ROM，它表示在pROM过程中达到的全ROM比例，这一定义在不同练习中相对一致。", "conclusion": "研究表明，pROM不仅在活动范围上与fROM有所不同，而且在执行动态和一致性方面也有区别。这表明，基于AI的方法有助于推进阻力训练研究，并有利于个性化训练处方的制定。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20261", "html_url": "https://arxiv.org/abs/2510.20261", "title": "Kinaema: 一种用于运动中记忆和姿态的递归序列模型", "title_en": "Kinaema: a recurrent sequence model for memory and pose in motion", "authors": "Mert Bulent Sariyildiz,Philippe Weinzaepfel,Guillaume Bono,Gianluca Monaci,Christian Wolf", "background": "空间感知机器人能够识别并定位其在以前见过的空间中的位置，这对于连续的机器人操作非常重要。这项工作中，研究者关注在实际操作开始之前，利用观察信息来优化效率的问题。为了实现这一目标，他们引入了Kinaema这个新模型及相应的代理，该模型能够在移动中整合视觉观察，并在接收到查询图像时，预测显示空间相对于当前位置的相对位置。", "innovation": "Kinaema模型利用变换器在循环方式中隐式更新一个记忆，将传感器读数的历史压缩为紧凑的表示形式，而不需要明确存储观察历史，因此对上下文长度没有硬性约束。研究者还引入了一个新的下游任务“Mem-Nav”，以评估该模型的影响。对Kinaema的大容量递归模型进行评估的结果表明，该模型能够维持场景的有用表示，能够在实际操作开始之前导航到先前观察到的目标，并且相比经典的具有观察历史注意力机制的变换器模型更高效。", "conclusion": "该工作展示了Kinaema模型在此类任务中的有效性，通过对连续机器人操作进行优化，Kinaema能够有效地帮助机器人在未知环境中导航，并且相比传统模型具有更高的计算效率。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20266", "html_url": "https://arxiv.org/abs/2510.20266", "title": "GUSL-Dehaze: 一种基于绿色U型学习的图像除雾方法", "title_en": "GUSL-Dehaze: A Green U-Shaped Learning Approach to Image Dehazing", "authors": "Mahtab Movaheddrad,Laurence Palmer,C.-C. Jay Kuo", "background": "图像除雾是一项从单个雾化输入中恢复清晰图像的恢复任务。传统的图像除雾方法依赖于统计先验和大气散射模型来重建无雾霾图像。近年来，最先进的方法主要基于深度学习架构，但这些模型往往涉及高计算成本和大型参数量，不适合资源受限的设备。", "innovation": "提出了GUSL-Dehaze，一种基于绿色U型学习的方法，结合了基于物理的模型和绿色学习框架。该方法避免了神经网络，通过修改的深通道先验进行初始去雾处理，然后利用U型架构进行绿色学习管道，嵌入无监督特征提取和特征工程技术，如相关特征测试和最小二乘法正则化转换，以保持紧凑的模型大小和透明的学习策略。这种方法显著减少了参数数量，并在数学可解释性方面表现良好，同时达到与最先进的深度学习模型相当的性能。", "conclusion": "GUSL-Dehaze方法不仅降低了参数量，还保持了数学可解释性，其性能与最先进的深度学习模型相当。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20335", "html_url": "https://arxiv.org/abs/2510.20335", "title": "Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking", "title_en": "Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking", "authors": "Zixuan Wu,Hengyuan Zhang,Ting-Hsuan Chen,Yuliang Guo,David Paz,Xinyu Huang,Liu Ren", "background": "停车场是驾驶安全的关键因素，虽然最近的端到端（E2E）方法在特定领域内取得了令人鼓舞的结果，但在领域变化（如天气和照明变化）下的鲁棒性仍然是一个关键挑战。传统的方法依赖于额外的数据来提高鲁棒性。", "innovation": "本文提出了名为Dino-Diffusion Parking (DDP)的领域无感自主停车管道，该管道将视觉基础模型与基于扩散规划相结合，以实现分布变化环境下的普适感知和鲁棒运动规划。该模型在CARLA中进行训练，并以零样本的方式转移到更具对抗性的环境中。实验证明，该模型在所有测试的分布外(OOD)场景中成功率达到90%以上，且消融研究表明，网络架构和算法设计在跨域性能方面显著优于现有基线。", "conclusion": "在使用3D Gaussian splatting (3DGS)环境重建的真实停车场环境中进行测试，显示出从仿真到现实世界的转移动人，验证了模型的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20349", "html_url": "https://arxiv.org/abs/2510.20349", "title": "为鲁棒跑道检测生成数据", "title_en": "Synthetic Data for Robust Runway Detection", "authors": "Estelle Chigot,Dennis G. Wilson,Meriem Ghrib,Fabrice Jimenez,Thomas Oberlin", "background": "深度视觉模型在工业和可能的批判性应用中已经足够成熟，例如自主导航。然而，收集和标注数据以培训这些模型需要大量的努力和成本，单个公司或产品难以负担。并且在批判性应用中，训练数据必须涵盖所有可能的情况，包括罕见场景。为了解决这一问题，生成合成图像是一种有吸引力的解决方案，能够在不增加大量成本的同时，可靠地覆盖所有条件和环境。本文探讨了飞机制造商开发的自主着陆系统中跑道检测这一关键组成部分，提出了基于商用飞行模拟器的图像生成方法，以补充少数标注的真实图像。通过控制图像生成和真实图像与合成数据的整合，标准目标检测模型可以实现精确的预测，并对其在夜间等未在实际数据中出现的恶劣条件下的鲁棒性进行了评估。", "innovation": "提出了基于商用飞行模拟器的图像生成方法，与少量标注的真实图像相结合，以实现准确的跑道检测，并进行了域适应策略的定制以增强模型在恶劣条件下的鲁棒性。", "conclusion": "标准目标检测模型在整合真实图像和合成图像后，能够实现准确的检测和鲁棒性，特别是在未涵盖的恶劣条件下，定制的域适应策略发挥了重要作用。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20468", "html_url": "https://arxiv.org/abs/2510.20468", "title": "基于图像偏好模型的可迁移黑盒一次性水印伪造", "title_en": "Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models", "authors": "Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko", "background": "近年来，随着生成模型的普及和法律压力的增加，数字内容水印技术的兴趣显著增长。由于越来越多的AI生成内容在网上可用，水印在保证内容的可信度和归属方面扮演着越来越重要的角色。尽管已经有很多研究评估了水印对去除攻击的鲁棒性，但在水印偷盗攻击场景中（即从真实内容窃取水印并应用于恶意内容），研究工作仍然不足。", "innovation": "本文研究了基于广泛使用后处理图像水印技术的水印伪造问题，并主要贡献包括：第一，提出了一个偏好模型来评估图像是否被水印标记。该模型不依赖真实的水印和实际水印，而是通过纯程序生成的图像进行训练，采用了排名损失。第二，模型能够通过反向传播优化输入图像来去除和伪造水印，仅需一张水印图像即可进行攻击，不需要知道水印模型的具体信息。这种方法比相关工作的攻击更为简单且实用。第三，研究结果表明，该方法能够有效伪造各种后处理图像水印，提出了当前水印技术的潜在安全漏洞。", "conclusion": "本文通过偏好模型的方法研究了图像后处理中的水印伪造问题，并展示了方法的有效性和实用性，挑战了现有水印技术的安全性。相关代码和资源对公众开放。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20809", "html_url": "https://arxiv.org/abs/2510.20809", "title": "Real Deep Research for AI, Robotics and Beyond", "title_en": "Real Deep Research for AI, Robotics and Beyond", "authors": "Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang", "background": "随着人工智能与机器人领域研究的快速增长，每年发表的论文数量已超过10,000篇，这使得研究人员难以跟上最新的发展。快速发展的趋势、跨学科工作的兴起以及探索超出自己专业领域的机会都构成了这一挑战。", "innovation": "本文提出了一种普适的分析管道，能够系统地分析任何研究领域：识别新兴趋势，发现跨领域的机遇，并为新的研究提供具体的起点。在这项工作中，我们提出了“真实深入研究”(Real Deep Research, RDR)的综合框架，应用于人工智能和机器人领域，特别是基础模型和机器人技术的发展。我们还简要将分析扩展到科学的其他领域。论文主要详细介绍了RDR管道的构建，补充部分则提供了每个分析主题的详细结果。", "conclusion": "希望本文能够为人工智能及相关领域工作的研究人员提供启示。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20762", "html_url": "https://arxiv.org/abs/2510.20762", "title": "MEIcoder: 通过利用最具兴奋性输入解码神经活动的视觉刺激", "title_en": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs", "authors": "Jan Sobotka,Luca Baroni,Ján Antolík", "background": "从神经群体活动解码视觉刺激对于理解大脑和脑-机接口的应用至关重要。然而，生物数据往往稀缺，特别是在灵长类动物或人类中，由于技术限制，如双光子成像，很难或不可能应用。这给深度学习解码技术带来了挑战。", "innovation": "我们引入了MEIcoder，这是一种基于生物信息的解码方法，利用神经元特定的最具兴奋性输入（MEIs）、结构相似性索引度量损失和对抗训练。MEIcoder在初级视觉皮层（V1）的单细胞活动重建中达到了最先进的性能，尤其是在数据量较少且记录的神经元较少的小数据集上表现尤为出色。通过消融研究，我们证明了MEIs是性能的主要驱动因素，并通过扩展实验，我们展示了MEIcoder可以从1,000-2,500个神经元和不到1,000个训练数据点重建高质量的自然外观图像。", "conclusion": "我们的结果表明，在早期视觉系统中可靠解码的可行性，并为神经科学和神经工程应用提供了实用见解。我们还提议了一个包含超过160,000个样本的统一基准，以此促进未来的相关研究。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20813", "html_url": "https://arxiv.org/abs/2510.20813", "title": "GSWorld：用于机器人操作的闭环逼真模拟套件", "title_en": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation", "authors": "Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang", "background": "目前的机器人操作模拟器中普遍存在一个问题，即难以实现从仿真到现实（sim2real）的有效过渡，尤其是在策略训练和评估方面。现有的方法要么依赖真实的机器人进行数据收集，导致成本和风险较高，要么忽视了仿真环境与现实环境之间的真实对应关系，导致策略在实际应用中的表现不佳。", "innovation": "本文提出了GSWorld，该模拟器通过结合3D高斯散点图技术和物理引擎，实现了一个既真实又健壮的机器人操作模拟平台。该框架强调闭环开发，通过真实机器人数据的可重现评估和无需实际使用真实机器人即可进行sim2real策略训练，实现了从仿真到现实的无缝过渡。此外，提出了新的GSDF格式，能够真实渲染各种场景，并结合物理引擎，展示了多项实际应用。", "conclusion": "本文通过GSWorld实现了逼真的机器人操作模拟，展示了一系列改进，包括仿真策略的无缝应用、高质量的数据自动收集、可重现的策略基准测试、通过虚拟遥控收集仿真数据以及视觉强化学习的无缝应用等。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20800", "html_url": "https://arxiv.org/abs/2510.20800", "title": "Compress to Impress: 使用100个样本的单步梯度进行高效LLM适配", "title_en": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "authors": "Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus", "background": "最近，Sharma等人提出了一个名为Layer-SElective-Rank reduction（LASER）的方法，该方法通过去除精心选择的LLM权重矩阵的高阶成分来提高下游任务的准确性，而无需任何基于梯度的微调。尽管如此，LASER进行全数据集前向传递以执行每矩阵搜索的全面方法使其难以快速部署。", "innovation": "作者发现，通过以下几点可以去除不必要的开销并改进方法：(i) 只需仔细选择的一部分矩阵需要检查，从而消除逐层扫描；(ii) 每个矩阵奇异值的梯度可以帮助定位需要削减的矩阵；(iii) 允许矩阵行围绕多个子空间聚类并分别分解每个聚类可以进一步减少过拟合，并进一步提升准确率至24.6个百分点；(iv) 仅在100个样本上而非全训练集上进行梯度评估和最终准确性测量，可以进一步减少搜索时间；作者解释了由于下游任务适应主要由提示风格主导，而非数据集大小，这使得这种方法有效。", "conclusion": "综合以上发现，我们展示了快速且稳健的下游任务适配算法。仅通过在100个样本上执行一次梯度步骤和对最有可能的候选层和分解技术进行快速扫描，我们就可以在没有微调的情况下使LLM适应新数据集。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.05500", "html_url": "https://arxiv.org/abs/2410.05500", "title": "Residual Kolmogorov-Arnold Network for Enhanced Deep Learning", "title_en": "Residual Kolmogorov-Arnold Network for Enhanced Deep Learning", "authors": "Ray Congrui Yu,Sherry Wu,Jiang Gui", "background": "尽管深度卷积神经网络（CNNs）取得了巨大的成功，但由于网络深度中存在的数百层，优化和训练它们可能会非常困难且成本高昂。传统的卷积操作因其线性性质和固定激活而受到限制，这意味着需要许多层才能学习数据中的有意义模式。由于这些网络的巨大规模，这种方法在计算上是低效的，并且在小数据集上存在过拟合或梯度爆炸的风险。因此，研究提出了一种称为Residual Kolmogorov-Arnold Network（RKAN）的“插件”模块。", "innovation": "这个模块非常紧凑，因此它可以很容易地插入到传统深度网络的任何阶段（层），并学习整合支持多项式特征变换到现有的卷积框架中。实验证明，RKAN在不同的视觉任务和广泛测试的基准中都提供了基线模型的一致改进，并在它们上实现了尖端性能。", "conclusion": "RKAN在不同的视觉任务和广泛测试的基准中都提供了基线模型的一致改进，并在它们上实现了尖端性能。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.16892", "html_url": "https://arxiv.org/abs/2408.16892", "title": "Tex-ViT: 一个通用且稳健的基于纹理的双分支交叉注意力深度伪造检测器", "title_en": "Tex-ViT: A Generalizable, Robust, Texture-based dual-branch cross-attention deepfake detector", "authors": "Deepak Dagar,Dinesh Kumar Vishwakarma", "background": "深度伪造（Deepfakes）利用GAN技术生成高度逼真的面部修改，被认为是当前主流的方法。传统CNN能够识别假媒体，但在不同数据集上的表现不稳定，并且容易受到对抗攻击的影响。视觉 transformer 在图像分类问题中显示出潜力，但需要足够的训练数据。鉴于这些限制，本文提出了一种结合ResNet和视觉transformer的Tex-ViT模型，旨在通过增强CNN特征来提高对深度伪造的检测能力。", "innovation": "Tex-ViT模型通过引入一个并行处理在ResNet每个下采样操作前的纹理模块，将传统的ResNet特征与纹理模块结合起来。纹理模块作为双分支交叉注意力视觉变压器输入的一部分，重点改善了用于提取特征图相关性的全局纹理模块。实验结果显示，模型在不同类型的FF++以及其他GAN数据集上，即使在经过模糊、压缩和噪声等后处理的情况下，也能保持98%的高准确率，证明了这种模型在多种情况下的通用性和鲁棒性。", "conclusion": "实验表明，所提出的模型能够学习伪造样本中的共享区别性纹理特征，并能在多种情况下应用，对许多后处理程序具有抵抗性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.11224", "html_url": "https://arxiv.org/abs/2412.11224", "title": "GenLit: 将单图复光重新表述为视频生成", "title_en": "GenLit: Reformulating Single-Image Relighting as Video Generation", "authors": "Shrisha Bharadwaj,Haiwen Feng,Giorgio Becherini,Victoria Fernandez Abrevaya,Michael J. Black", "background": "在计算机视觉和图形学中，单张图像中三维场景的照明操控是一个基本挑战。传统方法采用逆渲染技术，涉及显式的三维资产重构和昂贵的光线追踪模拟。而近期视觉基础模型的进步表明，一个新的范式可能即将到来——用训练大量图像和视频数据的网络取代显式的物理模型。本文利用视频扩散模型的隐式场景理解能力（如Stable Video Diffusion），实现在单张图像中的复光。", "innovation": "本文引入了GenLit，一个框架，能够将图形引擎的光照操控能力浓缩到视频生成模型中。用户可以直接在给定图像中插入并操控点光源，生成结果直接作为视频序列。发现一个仅在少量合成数据集上微调的模型，可以在真实场景中泛化，实现带有合理和令人信服的阴影和相互反射的单图复光。这些结果突显了视频基础模型捕捉光照、材质和形状丰富信息的能力，并表明通过最小的训练，这些模型可以用于不需要显式资产重构或光线追踪的情况下的复光任务。", "conclusion": "本研究显示了视频基础模型在捕捉复杂场景信息方面的潜力，并提出一种全新的无需显式重建3D模型即可在单张图像中进行复光的方法。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2211.00198", "html_url": "https://arxiv.org/abs/2211.00198", "title": "Frequency Cam：实时成像周期信号", "title_en": "Frequency Cam: Imaging Periodic Signals in Real-Time", "authors": "Bernd Pfrommer", "background": "由于事件摄像机具有高时间分辨率和大动态范围，它们非常适合分析图像中的时间周期信号。本文介绍了一种高效的全异步事件摄像机算法，用于检测图像像素闪烁的基本频率。该算法使用二次数字无限脉冲响应（IIR）滤波器进行近似点亮度重构，并且比我们用来比较的基本方法更能抵抗高频噪声。作者进一步证明，使用信号的下降沿会比上升沿给出更准确的周期估计，而对于某些信号，插值零交叉可以进一步提高准确性。实验显示，摄像机检测频率的能力（单像素高达64kHz）在全传感器成像时因读出带宽限制而受到严重阻碍。这表明，更接近传感器的硬件实现将极大地改善频率成像效果。", "innovation": "研究提出了一种高效的全异步事件摄像机算法，用于检测图像像素的闪烁频率，并使用二次数字无限脉冲响应（IIR）滤波器进行近似点亮度重构。该算法对高频噪声具有更高的鲁棒性。研究发现，信号的下降沿比上升沿可以获得更准确的周期估计，对于某些信号，在零交叉处插值可以进一步提高准确性。此外，研究还设计了一款名为Frequency Cam的开源实现，作为ROS节点在笔记本CPU单核上以每秒超过5000万个事件的速度运行，并且产生的结果与Prophesee的Metavision Toolkit中的封闭源振动分析模块非常相似。开源代码及演示视频可在此链接找到：this https URL", "conclusion": "实验结果显示，摄像机在单像素上的检测频率能力（高达64kHz）在全传感器成像时因读出带宽限制而受到严重影响。因此，作者建议更接近传感器的硬件实现将大幅改进频率成像效果。Frequency Cam开源实现是一款运行效率高的工具，能够以极高的速度运行并提供类似封闭源振动分析模块的结果。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.18810", "html_url": "https://arxiv.org/abs/2412.18810", "title": "FairGen：通过自我发现的潜在方向在文本到图像扩散模型中增强公平性", "title_en": "FairGen: Enhancing Fairness in Text-to-Image Diffusion Models via Self-Discovering Latent Directions", "authors": "Yilei Jiang,Weihong Li,Yiyuan Zhang,Minghong Cai,Xiangyu Yue", "background": "扩散模型（Diffusion Models，DM）在各种图像生成任务中表现出色，但它们仍然反映了训练集中固有的偏差。在现实世界应用中，这些偏差可能会加剧错误的世界观，尤其是在对待少数群体方面产生负面影响。现有缓解扩散模型偏差的方法通常需要重新训练模型并使用人工制作的参考数据集，或者增加额外的分类器，这种方式存在两个主要缺点：（1）收集参考数据集的成本昂贵；（2）去偏的效果高度依赖参考数据集或额外分类器的质量。", "innovation": "本文提出了FairGen，一种简单易用的方法，能够以自我发现的方式学习属性潜在方向，从而无需依赖参考数据集就能消除偏见，使模型更加公正。FairGen 包含两部分：一组属性适配器和一个分布指示器。每组适配器旨在学习一个属性潜在方向，并通过自我发现过程进行优化。然后，分布指示器乘以适配器集，以指导生成过程向预设分布靠拢。此方法允许同时在DM中去偏多个属性，同时保持轻量级且易于与其他DM集成，无需重新训练。", "conclusion": "广泛的实验表明，与之前的最佳方法相比，我们的方法在去除了性别、种族及其交叉偏见方面表现出显著的优势。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.01243", "html_url": "https://arxiv.org/abs/2501.01243", "title": "Face-Human-Bench: 多模态助手中面部和人类理解的综合基准", "title_en": "Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants", "authors": "Lixiong Qin,Shilong Ou,Miaoxuan Zhang,Jiangning Wei,Yuhang Zhang,Xiaoshuai Song,Yuchen Liu,Mei Wang,Weiran Xu", "background": "面部和人类是社交互动中的关键元素，广泛存在于日常照片和视频中。因此，对面部和人类的深入理解可以提高多模态助手的响应质量，并扩大其应用范围。然而，当前多模态助手社区缺乏对面部和人类理解能力的全面和科学评估。", "innovation": "1. 提出了一种分层能力分类法，包括三个能力层级。\n2. 基于该分类法，从面部和人类社区的公开数据集中收集图像和标注，构建了一种半自动数据管道来生产新基准的问题。\n3. 开展了对25个主流多模态大型语言模型的评估，重点关注能力之间的相关性、目标相对位置对性能的影响以及链式思考（CoT）提示对性能的影响。\n4. 探讨了哪些多模态大型语言模型的哪些能力需要通过专家模型补充。\n5. 将数据集和评估代码公开。", "conclusion": "通过Face-Human-Bench，本研究为多模态助手提供了第一个全面的面部和人类理解评估基准，有助于更好地理解多模态助手在面部和人类理解方面的性能，并指导未来研究的发展。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.09080", "html_url": "https://arxiv.org/abs/2502.09080", "title": "BevSplat: 通过基于特征的高斯原语解决弱监督跨视图定位的高度歧义", "title_en": "BevSplat: Resolving Height Ambiguity via Feature-Based Gaussian Primitives for Weakly-Supervised Cross-View Localization", "authors": "Qiwei Wang,Shaoxun Wu,Yujiao Shi", "background": "论文关注的是弱监督下的跨视图定位问题，其目标是基于带有噪声真实标注的地面摄像头图像，估计其相对于卫星图像的姿势。现有方法常使用鸟瞰图（BEV）合成来解决跨视图域间差距的问题，但这些方法在处理来自地面图像和平流层高度图中的高度不确定性时存在困难。此前的方法要么假设地面为平坦的平面，要么依赖复杂的模型，如跨视图变换器。当前存在问题的方法难以直接处理的高度不确定性，因为地面图像缺乏深度信息和卫星的高度信息。", "innovation": "我们提出了一个名为BevSplat的新方法，通过使用基于特征的高斯原语来解决高度歧义。该方法将每个地面图像的像素通过带有语义和空间特征的3D高斯表示，并综合生成一个BEV特征图以用于相对姿态估计。此外，为了应对全景查询图像带来的挑战，引入了基于icosphere的监督策略以处理高斯原语。这种方法已在广泛使用的KITTI和VIGOR数据集上进行了验证，包含的有针孔和全景查询图像。实验结果表明，与先前的方法相比，BevSplat在定位准确性上有了显著的提升。", "conclusion": "本文提出的方法BevSplat通过使用基于特征的高斯原语解决了高度不确定性的挑战，并显著提高了跨视图定位的定位准确性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.16378", "html_url": "https://arxiv.org/abs/2503.16378", "title": "Panoptic-CUDAL：在雨天条件下澳大利亚农村地区的点云数据集", "title_en": "Panoptic-CUDAL: Rural Australia Point Cloud Dataset in Rainy Conditions", "authors": "Tzu-Yun Tseng,Alexey Nekrasov,Malcolm Burdorf,Bastian Leibe,Julie Stephany Berrio,Mao Shan,Zhenxing Ming,Stewart Worrall", "background": "现有的自动驾驶数据集主要关注结构良好的城市环境和良好的天气条件，农村环境的复杂性和恶劣天气情况则被严重忽视。尽管一些数据集涵盖了天气和照明的变化，但恶劣天气场景出现的频率较低。降雨会对传感器的功能产生显著干扰，影响LiDAR和相机数据，并降低系统可靠地感知环境和安全导航的能力。", "innovation": "本文介绍了Panoptic-CUDAL数据集，这是一个专门为雨天条件下农村区域进行全景分割设计的数据集。通过记录高分辨率LiDAR、相机和位姿数据，Panoptic-CUDAL提供了一个丰富信息的、具有挑战性的数据集。", "conclusion": "本文分析了记录的数据，并提供了使用LiDAR点云进行全景、语义分割和3D占用预测方法的基准结果。数据集可以在以下链接找到：this https URL, this https URL"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.13777", "html_url": "https://arxiv.org/abs/2503.13777", "title": "8-Calves 图像数据集", "title_en": "8-Calves Image dataset", "authors": "Xuyang Fang,Sion Hannuna,Neill Campbell,Edwin Simpson", "background": "自动化畜牧监测对于精确农业至关重要，但是由于缺乏反映现实世界群组挑战的数据集，稳健的计算机视觉模型受到限制。当前缺乏涵盖频繁遮挡、运动模糊和多种姿态的高质量多动物检测、跟踪和识别数据集。", "innovation": "本文介绍了8-Calves数据集，这是一个挑战性的多动物检测、跟踪和识别基准。该数据集包含8头荷斯坦-弗里斯兰奶牛在一小时视频中的运动，具备多次遮挡、运动模糊和多种姿态的特点。利用半自动管道结合优化后的YOLOv8检测器和ByteTrack，经过人工校正后，生成了超过537,000个带时序身份标签的边界框。针对28种对象检测器的基准测试显示，宽松指标下的性能接近完美（mAP50：95.2-98.9%），但在严格指标下表现显著差异（mAP50:95：56.5-66.4%），突显了精细定位的挑战。此外，识别基准测试表明，模型尺寸扩大提高了分类准确性，但影响了检索性能。研究发现ConvNextV2 Nano等较小架构在一定平衡点（73.35%精度，50.82% Top-1 KNN）上的表现更优。专注于语义学习的预训练方法（例如BEiT）具有更好的迁移性能。跟踪任务中，领先方法尽管检测精度高（MOTA > 0.92），但在身份保留（IDF1 ≈ 0.27）方面存在挑战，特别是在遮挡严重的场景中。", "conclusion": "8-Calves数据集通过提供时间上的丰富性和现实挑战，为推进农业视觉模型的发展提供了资源。数据集和相关代码可在指定链接下载。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.23356", "html_url": "https://arxiv.org/abs/2503.23356", "title": "ControlFusion：一种带有语言视觉退化提示的可控图像融合框架", "title_en": "ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts", "authors": "Linfeng Tang,Yeda Wang,Zhanchuan Cai,Junjun Jiang,Jiayi Ma", "background": "当前的图像融合方法在处理现实世界成像场景中的复合退化方面存在困难，且缺乏针对用户特定需求的灵活性。", "innovation": "本文提出了一个带有语言-视觉提示的可控图像融合框架，称为ControlFusion。该框架通过动态增强具有退化提示的特征，实现了对不同水平复合退化的适应。此外，通过文本编码嵌入用户指定的退化类型和严重程度，并设计了自主感知源图像退化的空间-频率协作视觉适配器。", "conclusion": "广泛的实验表明，ControlFusion在融合质量和处理退化方面优于现有技术，尤其在处理不同类型和程度的现实世界和复合退化方面更为有效。源代码已公开。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.15984", "html_url": "https://arxiv.org/abs/2503.15984", "title": "DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration", "title_en": "DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration", "authors": "Suraj Singh,Anastasia Batsheva,Oleg Y. Rogov,Ahmed Bouridane", "background": "现代图像恢复和超分辨率方法由于其在性能上优于传统算法，而广泛采用深度学习。然而，在天体摄影中，深度学习通常需要大量训练数据，这并不常见。Deep Image Prior (DIP) 通过在单一图像上进行盲训练来绕过这个限制。尽管在某些情况下有效，但DIP经常面临过拟合、伪影生成和不稳定的问题。人工智能通过引入DIPLI框架解决这些问题，该框架采用多帧训练并在Back Projection技巧的帮助下结合TVNet模型进行光学流量估计，并用蒙特卡洛估计替代确定性预测，其通过拉 -* 根威登动力学获得。该研究对比了DIPLI和幸运成像、DIP、基于转换器模型的RVRT等方法在合成数据集上的表现。结果显示, 该方法在多数情况下优于基准方法，且在实际天文学数据集上维持了高质量的重建效果，证实了其实用鲁棒性，且需要更少的输入图像，并且不易过拟合或产生伪影问题", "innovation": "提出的DIPLI框架通过多帧训练、Back Projection技术、TVNet模型的一帧间稳健运动估计，以及基于拉 -* 根威登动力学的无偏蒙特卡罗预测，解决了深图像先验（DIP）存在的过拟合、伪影生成和不稳定问题，从而提高图像恢复的一般性能", "conclusion": "实验结果表明, 该方法在大多数情况下在多数评价指标上优于基准方法，不仅在合成数据集上表现出更高质量的重建效果，而且在实际天文数据集上的效果也非常牢固可靠，需要的输入图像更少，更少出现过拟合或伪影现象"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12499", "html_url": "https://arxiv.org/abs/2505.12499", "title": "在文本-视频检索中通过瓶颈化语义增量重新平衡对比对齐", "title_en": "Rebalancing Contrastive Alignment with Bottlenecked Semantic Increments in Text-Video Retrieval", "authors": "Jian Xiao,Zijie Song,Jialong Hu,Hao Cheng,Jia Li,Zhenzhen Hu,Richang Hong", "background": "近年来，文本-视频检索的进步主要受对比学习的驱动。但现有方法往往忽视了模态间差异（即模态间隔）的影响，导致锚点表示受到就地优化（即优化张力）的限制，从而降低了其对齐能力。此外，噪声硬负样本进一步扭曲了锚点的语义。这些问题亟需解决，以提升对齐精度和鲁棒性。", "innovation": "本文提出了一种名为GARE（Gap-Aware Retrieval）的模态间隔感知检索框架，它引入了一个可学习的、配对特定的增量$\triangle_{ij}$，该增量用于重新分配梯度，缓解优化张力并吸收噪声。通过多元一阶泰勒展开InfoNCE损失并在信任区间约束下推导出$\triangle_{ij}$，并指出它指导局部一致的下降方向。此外，通过一个基于语义间隔的轻量级神经模块，增量在批次之间耦合，以实现结构感知的校正。进一步，通过松弛压缩的变分信息瓶颈正则化$\triangle$，增强其稳定性和语义一致性。", "conclusion": "在四个基准上的实验结果证实了GARE在对齐精度和鲁棒性方面的一致改进，验证了其对优化张力缓解的模态间隔意识的有效性。相关代码可访问this https URL。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11152", "html_url": "https://arxiv.org/abs/2505.11152", "title": "从不平衡数据中学习密集手接触估计", "title_en": "Learning Dense Hand Contact Estimation from Imbalanced Data", "authors": "Daniel Sungho Jung,Kyoung Mu Lee", "background": "手在人类互动中至关重要，研究手与实物、其他手、环境及身体的接触有助于全面理解其功能。近年来，手交互数据集数量增多，涵盖多种手的接触情况。尽管手接触估计任务重要且数据质量高，但如何有效地学习密集手接触估计仍然未得到充分探索。主要挑战在于手接触数据集中的类别不平衡问题和空间不平衡问题。类别不平衡问题导致大多数区域没有接触，而空间不平衡问题则表现为大部分接触发生在指尖，这给向其他手区域接触的泛化带来了困难。", "innovation": "本文提出了一种框架，通过不平衡数据学习密集手接触估计（HACO）。为了解决类别不平衡问题，引入了均衡接触采样，通过构建并采样多个代表不同接触统计的采样组，公平地代表接触和非接触顶点的统计数据。为解决空间不平衡问题，提出了顶点水平类别平衡（VCB）损失，这是一种考虑空间变化的接触分布的损失函数，通过分别根据顶点在数据集中接触频率重新加权其贡献来解决问题。", "conclusion": "通过引入均衡接触采样和顶点水平类别平衡损失，本文有效地从大规模手接触数据中学习了密集手接触估计，没有受到类别和空间不平衡问题的影响。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15450", "html_url": "https://arxiv.org/abs/2505.15450", "title": "在文本到图像扩散模型中全面评估和分析不良内容概念去除方法", "title_en": "Comprehensive Evaluation and Analysis for NSFW Concept Erasure in Text-to-Image Diffusion Models", "authors": "Die Chen,Zhiwen Li,Cen Chen,Yuexiang Xie,Xiaodan Li,Jinyan Ye,Yingda Chen,Yaliang Li", "background": "文本到图像扩散模型在多种领域取得了广泛的应用，展现出巨大的创造力。然而，扩散模型的强大泛化能力可能会导致不宜公开（NSFW）内容的生成，这对安全部署构成了显著风险。尽管已经提出了几种概念去除方法来缓解与NSFW内容相关的问题，但这些方法的有效性在不同场景中的系统性评估仍然缺乏。因此，存在一个填补这一空白的必要性，即需要一个全面的工具来专门进行概念去除，并对NSFW概念去除方法进行第一次系统的评估研究。", "innovation": "该研究引入了专门用于概念去除的全管道工具，并首次系统地研究了NSFW概念去除方法。通过探索底层机制和实证观察之间的相互作用，研究提供了关于如何更有效地在各种实际场景中应用概念去除方法的深入见解和实践指导，旨在推进对扩散模型内容安全性的理解，并为该重要领域的未来研究和开发奠定坚实基础。", "conclusion": "通过系统性地评估现有NSFW概念去除方法的有效性，该研究为在文本到图像扩散模型中确保内容安全提供了宝贵的参考，并对未来的相关研究和发展产生了积极影响。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.16247", "html_url": "https://arxiv.org/abs/2503.16247", "title": "OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection", "title_en": "OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection", "authors": "Max Gutbrod,David Rauber,Danilo Weber Nunes,Christoph Palm", "background": "在医疗保健等关键领域对人工智能（AI）的依赖日益增加，这需要有强大机制来确保这些系统的可信度，特别是在面对意外或异常输入时。现有的广泛自然图像领域的大规模离群点检测基准不能直接应用于医疗领域，这表明医疗领域需要特定的离群点检测基准。", "innovation": "本论文提出了Open Medical Imaging Benchmarks for Out-Of-Distribution Detection (OpenMIBOOD)，这是一个全面的框架，用于评估特定于医疗影像领域的离群点检测方法。OpenMIBOOD 包含来自不同医疗领域的三个基准，涵盖 14 个数据集，分为协变量偏移的内分布、接近离群点和远离离群点类别。这24种后处理方法在这三个基准上进行了评估，提供了一个标准化的参考，以促进离群点检测方法的发展和公平比较。", "conclusion": "OpenMIBOOD 的目标是缓解 AI 模型对训练分布外输入的暴露风险，从而支持医疗保健领域可靠和可信的 AI 系统的发展。相关基准数据集在 https://github.com/zhangji0418/OpenMIBOOD 提供。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.15958", "html_url": "https://arxiv.org/abs/2504.15958", "title": "FreeGraftor：无需训练跨图像特征嫁接方法用于主题驱动的文本到图像生成", "title_en": "FreeGraftor: Training-Free Cross-Image Feature Grafting for Subject-Driven Text-to-Image Generation", "authors": "Zebin Yao,Lei Ren,Huixing Jiang,Chen Wei,Xiaojie Wang,Ruifan Li,Fangxiang Feng", "background": "主题驱动的图像生成旨在从参考图像中合成新的场景，同时保持主题身份并在文本指导下进行。现有的方法在这两个关键方面之间面临着难以调和的权衡：保真度和效率。依赖调优的方法需要耗费大量时间和资源来进行主题特定的优化，而零样本方法通常无法维持足够的主题一致性。因此，本工作旨在解决这些限制，提出了一种无需训练（training-free）的框架FreeGraftor，通过跨图像特征嫁接实现这一目标。", "innovation": "FreeGraftor框架通过语义匹配和位置受限的注意力融合机制，从参考主题中转移视觉细节到生成图像。此外，该框架引入了一种新的噪声初始化策略，以保留参考主题的几何先验，促进稳健的特征匹配。实验结果表明，该方法能够在保持文本对齐场景合成的同时，实现精确的主题身份转移。无需进行模型微调或额外训练，FreeGraftor在主题保真度和文本对齐方面明显优于现有零样本和无需训练的方法。此外，框架还可以无缝扩展到多主题生成，使其在实际部署中具备可行性。", "conclusion": "FreeGraftor方法不仅在主题保真度和文本对齐方面显著优于现有方法，还能够无缝扩展到多主题生成，使其实现实际部署。我们已经为该方法提供了代码。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16761", "html_url": "https://arxiv.org/abs/2505.16761", "title": "Mesh-RFT：通过细粒度强化微调提升网格生成", "title_en": "Mesh-RFT: Enhancing Mesh Generation via Fine-grained Reinforcement Fine-Tuning", "authors": "Jian Liu,Jing Xu,Song Guo,Jing Li,Jingfeng Guo,Jiaao Yu,Haohan Weng,Biwen Lei,Xianghui Yang,Zhuo Chen,Fangqi Zhu,Tao Han,Chunchao Guo", "background": "现有的3D网格生成预训练模型容易产生数据偏见并导致质量低下，而基于对象级别的全球强化学习方法难以捕捉局部结构细节。这些问题使得3D网格生成面临挑战，目前的方法未能有效解决局部细节优化和全局一致性保持的问题。", "innovation": "该论文提出了Mesh-RFT，一种创新的细粒度强化微调框架，通过Masked Direct Preference Optimization (M-DPO)实现基于质量感知的面遮罩优化，解决了局部优化与全局一致性保持之间的矛盾。此外，还引入了一个客观的拓扑意识评分系统，通过边界边缘比率（BER）和拓扑得分（TS）两个指标评估对象和面层面的几何完整性和拓扑规整性，将这些指标融入细致的强化学习策略，实现了局部故障的修复和全局一致性保持，而不会牺牲质量。", "conclusion": "实验结果表明，Mesh-RFT方法通过M-DPO框架降低了Hausdorff距离24.6%，拓扑得分提高了3.8%，相较于预训练模型和全局DPO方法，表现出更好的几何完整性和拓扑规整性，实现了能够在生产环境中生成高质量3D网格的新记录。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17581", "html_url": "https://arxiv.org/abs/2505.17581", "title": "MODEM：一种用于恶劣天气图像恢复的 Morton-Order 耦合降质估计机制", "title_en": "MODEM: A Morton-Order Degradation Estimation Mechanism for Adverse Weather Image Recovery", "authors": "Hainuo Wang,Qiming Hu,Xiaojie Guo", "background": "恶劣天气图像恢复仍然是一个重大挑战，因为天气引起的退化具有高度非均匀和空间异质性，例如细颗粒雨痕与广泛霾。准确估计潜在的退化可以帮助恢复模型提供更有针对性和有效的指导，实现适应性处理策略。", "innovation": "提出了一个Morton-Order降质估计机制（MODEM），其核心是Morton-Order 2D-选择扫描模块（MOS2D）。MOS2D结合了Morton编码的空间排序和选择状态空间模型，既捕捉了长期依赖性，又保留了局部结构连贯性。此外，引入了双退化估计模块（DDEM）以解耦并估计全局和局部退化先验。这些先验动态调整MOS2D模块，实现适应性和上下文感知的恢复。", "conclusion": "广泛的实验和消融研究证明，MODEM在多个基准和天气类型上达到了最先进的结果，突出了其在建模复杂退化动态方面的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16793", "html_url": "https://arxiv.org/abs/2505.16793", "title": "REOBench：评估地球观测基础模型鲁棒性的基准", "title_en": "REOBench: Benchmarking Robustness of Earth Observation Foundation Models", "authors": "Xiang Li,Yong Tao,Siyuan Zhang,Siwei Liu,Zhitong Xiong,Chunbo Luo,Lu Liu,Mykola Pechenizkiy,Xiao Xiang Zhu,Tianjin Huang", "background": "地球观测基础模型在多个地球观测任务中表现出强大的泛化能力，但其在真实世界干扰下的鲁棒性尚未得到充分探索。为了填补这一空白，本文提出了REOBench，这是首个用于评估地球观测基础模型鲁棒性的基准，涵盖了六个任务和十二种图像破坏类型，包括基于外观和几何的扰动。基准测试聚焦于高分辨率的光学遥感图像，这些图像是城市规划和灾害响应等关键应用中的广泛使用类型。", "innovation": "引入了REOBench基准，首次系统性地评估了各种利用掩模图像建模、对比学习和视觉语言预训练的模型，揭示了模型在面对输入干扰时性能显著下降的现象，不同任务、模型架构、骨干网络大小和干扰类型对性能影响存在较大差异，视觉语言模型在多模态任务中表现出增强的鲁棒性。REOBench旨在揭示当前地球观测基础模型在现实干扰中的脆弱性，并提供开发更鲁棒和可靠的模型的实践指导。", "conclusion": "REOBench基准展示了当前地球观测基础模型对现实干扰的脆弱性，并为开发更鲁棒和可靠的模型提供了行动指南。所有代码和数据均可在该网址公开获取。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18608", "html_url": "https://arxiv.org/abs/2505.18608", "title": "Spiking Neural Networks Need High Frequency Information", "title_en": "Spiking Neural Networks Need High Frequency Information", "authors": "Yuetong Fang,Deming Zhou,Ziqing Wang,Hongwei Ren,ZeCui Zeng,Lusong Li,Shibo Zhou,Renjing Xu", "background": "Spiking Neural Networks（SNNs）通过二元（0/1）脉冲传输信息，因其大脑启发和高能效特性受到关注。然而，它们的性能仍然落后于人工神经网络，这种差距通常被假定是由于稀疏且二元激活引起的低信噪比导致的信息损失所致。", "innovation": "该工作提出了目前未被注意的频率偏见：脉冲神经元本质上抑制高频分量并偏向传播低频信息。这一频率域中的失衡被认为是SNNs中特征表示质量下降的根本原因。因此，作者提出了一种MaxFormer，通过引入两种频率增强操作（1）在块嵌入中增加Max-Pool（2）用深度卷积替换自注意力操作，使其在图像网（ImageNet）数据集上达到82.39%的顶级准确率，使用了仅63.99M的参数，超过了Spikformer的74.81%（66.34M）。此外，Max-ResNet-18模型在基于卷积的基准测试中也取得了最好的性能。", "conclusion": "研究期待这一简单有效的解决方案能激励未来研究探索脉冲神经网络的独特性质。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19256", "html_url": "https://arxiv.org/abs/2505.19256", "title": "PolyPose: 通过多刚体变换进行可变形的2D/3D配准", "title_en": "PolyPose: Deformable 2D/3D Registration via Polyrigid Transformations", "authors": "Vivek Gopalakrishnan,Neel Dey,Polina Golland", "background": "在介入性手术环境中，从有限数量的2D X线图像中确定患者的3D姿态是一个关键任务。尽管预先进行的体视成像（如CT和MRI）能提供精确的3D定位和解剖学目标可视化，但在手术过程中无法获取这些成像模式，因此通常使用快速的2D成像（X线）。为了在手术过程中集成体视指导，需要开发一种简单且鲁棒的方法来进行可变形的2D/3D配准。", "innovation": "PolyPose提出了一种通过多刚体变换进行可变形的2D/3D配准的方法。该方法通过将复杂的3D变形字段参数化为一系列刚性变换的组合，同时利用生物约束，即个体骨头在典型运动中不会弯曲。这种方法既解决了现有方法要么假设关节之间没有运动，要么在欠定情况下完全失败的问题，又通过符合人体运动的分段刚性性质的先验条件，避免了昂贵的变形正则化需求及特定患者和手术的超参数优化。", "conclusion": "在针对骨科手术和放射治疗等多个数据集进行了广泛的实验后，表明此强归纳偏见使PolyPose能够在仅使用两张X线片的情况下将患者的预手术体积进行精确配准。这在当前注册方法无法处理的低视场和受限视角的情况下，提供了关键的3D指导。额外的可视化、教程和代码可在以下链接找到：this https URL。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.22038", "html_url": "https://arxiv.org/abs/2505.22038", "title": "平衡采样修剪：超越局部优化加速视觉语言模型", "title_en": "Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization", "authors": "Kaiyuan Li,Xiaoyue Chen,Chen Gao,Yong Li,Xinlei Chen", "background": "大型多模态模型（LVLMs）通过将图像编码成数千个标记，在多模态任务中表现出色。然而，大量图像标记带来了显著的计算负担，而且使用动态高分辨率输入会进一步增加这种负担。当前方法尝试通过标记修剪减少图像标记，通常是基于注意力分数或图像标记多样性来选择标记。经过实验观察，这些方法往往忽略了修剪对当前层输出（局部）和后续层输出（全局）的综合影响，导致修剪决策不够优化。", "innovation": "我们提出了平衡标记修剪（BTP），这是一种插件即用的修剪视觉标记的方法。我们的方法利用一个小的校准集将修剪过程分成多个阶段，在早期阶段，方法将焦点集中在修剪对未来层输出的影响上，而在更深的阶段，焦点转向保留局部输出的一致性。广泛的实验表明，我们的方法在多个基准测试上具有广泛的适用性，平均压缩率高达78%，同时保留了96.7%的原始模型性能。", "conclusion": "我们的实验结果表明平衡标记修剪方法在多个LVLM上展示了有效性的广泛有效性，实现了高压缩率同时保持了大部分原始性能。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.22651", "html_url": "https://arxiv.org/abs/2505.22651", "title": "Sherlock: 自视语言模型中的自我纠正推理", "title_en": "Sherlock: Self-Correcting Reasoning in Vision-Language Models", "authors": "Yi Ding,Ruqi Zhang", "background": "视觉-语言模型（VLMs）在复杂的多模态任务上取得了显著的性能，但仍然面临重大挑战。它们极易犯推理错误，需要大量的标注数据或精确的验证器，并且难以在具体域外泛化。", "innovation": "Sherlock框架通过自我纠正策略提升推理VLMs的表现。它包括轨迹级自我纠正目标、基于视觉干扰的偏好数据构建方法以及动态$\beta$偏好调整。Sherlock仅使用20k随机采样的标注数据就获得了自我纠正能力，并在无需外部监督的情况下继续自我提升。该框架基于Llama3.2-Vision-11B模型，在八个基准测试中表现出色，最终准确率达到64.1%，自纠正后达到65.4%，超越了其他模型如LLaVA-CoT（63.2）、Mulberry（63.9）和LlamaV-o1（63.4），同时使用了不到20%的标注数据。", "conclusion": "Sherlock框架在显著减少标注数据需求的前提下，显著提升了视觉-语言模型在推理任务上的准确性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23155", "html_url": "https://arxiv.org/abs/2505.23155", "title": "Predictive Future Modeling (PreFM): 在预测未来建模下的在线音视频事件解析", "title_en": "PreFM: Online Audio-Visual Event Parsing via Predictive Future Modeling", "authors": "Xiao Yu,Yan Fang,Xiaojie Jin,Yao Zhao,Yunchao Wei", "background": "当前的音视频事件解析方法通常依赖于对整个视频的离线处理，并且模型体积庞大，导致它们不适用于实时处理。", "innovation": "提出了新的在线音视频事件解析（On-AVEP）范式，通过顺序分析传入的视频流，实现了音视频事件的解析。该方法侧重于两种关键能力：（1）在线准确推理，能够有效地区分在线环境中模糊和有限上下文的事件；（2）实时效率，能够平衡高性能与计算约束的需求。为此，提出了Predictive Future Modeling（PreFM）框架，该框架包括（a）预测跨模态未来建模以推断和整合有益的未来音视频线索，增强上下文理解；（b）模态无关的稳健表示与焦点时间优先级，提高准确性和泛化能力。", "conclusion": "在UnAV-100和LLP数据集上的广泛实验表明，PreFM方法相较于现有的最佳方法，使用显著更少的参数显著超过了性能。这为实时多模态视频理解提供了一个重要的方法。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20612", "html_url": "https://arxiv.org/abs/2505.20612", "title": "Roboflow100-VL: 一个针对视觉语言模型的多域目标检测基准", "title_en": "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models", "authors": "Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri", "background": "视觉-语言模型（VLMs）通过大规模互联网数据训练，在常见物体如汽车、卡车和行人的零样本检测任务中取得了显著的性能。然而，当前最先进的模型在泛化到不在预训练数据中常见的新类别、新任务和不同成像模态时仍然表现不佳。为了改善这一问题，研究者建议通过使用包含少量视觉示例和丰富文本描述的注释指令来对齐VLMs，而不是简单地用更多视觉数据重新训练模型。受此启发，作者引入了Roboflow100-VL，这是一个包含100个多模态目标检测数据集的大规模集合，包含的多样的概念不在VLM预训练数据中常见。这些数据集用于评估最新的视觉语言模型在零样本、少样本、半监督和全监督设置下的性能，以便在不同的数据条件下进行比较。", "innovation": "作者提出了Roboflow100-VL，这是专门为视觉语言模型设计的一个大规模多域目标检测基准。该数据集包含了100个多模态目标检测数据集，并涵盖了VLM预训练数据中罕见的概念，以此来促进视觉语言模型在新数据和任务上的泛化性能。作者通过使用少量视觉示例和丰富文本描述的注释指令来对齐VLMs，而不是仅仅在更多视觉数据上重新训练模型。该研究的方法和数据集为评估和改进视觉语言模型的泛化能力提供了新的视角和工具。", "conclusion": "研究者在零样本、少样本、半监督和全监督设置下评估了最新模型在Roboflow100-VL基准上的性能。结果表明，即使对模型微调，现有的视觉语言模型在医学成像等具有挑战性的任务上的性能仍然非常低（零样本准确性低于2%）。这突显了少样本概念对齐的必要性。最后，作者讨论了他们最近在CVPR 2025 Foundational FSOD竞赛中的研究，并分享了社区的见解。比赛的获胜团队通过改进，以17个mAP的显著优势超过了基线模型。相关的代码和数据集可以在提供的链接中获取。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05821", "html_url": "https://arxiv.org/abs/2506.05821", "title": "FuseUNet：U型网络的多尺度特征融合方法", "title_en": "FuseUNet: A Multi-Scale Feature Fusion Method for U-like Networks", "authors": "Quansong He,Xiangde Min,Kaishen Wang,Tao He", "background": "医学图像分割是计算机视觉中的关键任务，UNet因其里程碑式的架构而被广泛应用。UNet家族中的典型特点是跳跃连接，但传统的跳跃连接存在两个显著的局限性：(1) 缺乏不同尺度特征之间的有效互动；(2) 仅仅依赖简单的连接或加法操作，限制了高效信息整合。尽管最近对UNet的改进主要集中在增强编码器和解码器的能力，但上述问题仍被忽视。", "innovation": "本文提出了一种新型的多尺度特征融合方法，重新定义了UNet解码过程为解决初始值问题（IVP），将跳跃连接视为离散节点。通过利用线性多步法原理，我们提出了一种自适应常微分方程方法，以实现有效的多尺度特征融合。该方法不依赖于编码器和解码器架构，因此适用于各种类似UNet的网络。实验结果表明，该方法在特征利用方面有所提升，网络参数减少，同时保持了高性能。", "conclusion": "该方法在ACDC、KiTS2023、MSD脑肿瘤和ISIC2017/2018皮肤病变分割数据集上进行了实验验证，结果表明能有效提升特征的利用度，减少网络参数且保持高性能。代码已开源。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.02408", "html_url": "https://arxiv.org/abs/2506.02408", "title": "在组织切片级别监督下的端到端学习复现：计算病理学中的重新审视", "title_en": "Revisiting End-to-End Learning with Slide-level Supervision in Computational Pathology", "authors": "Wenhao Tang,Rong Qin,Heng Fang,Fengtao Zhou,Hao Chen,Xiang Li,Ming-Ming Cheng", "background": "在计算病理学（CPath）中，预训练编码器用于离线特征提取，随后通过多次实例学习（MIL）聚合器进行处理，这种范式对于癌症诊断和预后非常有帮助。然而，这种方案存在的问题是预训练编码器难以针对下游任务进行微调，且优化过程与MIL不连续，从而限制了性能。尽管滑片级监督的端到端学习被视为直观的解决方案，但由于计算需求高和结果不尽如人意的问题，实际应用受到阻碍。因此，需要重新审视端到端学习方法中的优化挑战，以克服现有技术的局限性并提升性能。", "innovation": "本文提出了结合全局相关性注意力改进和多头机制的新型多次实例学习方法ABMILX，有效缓解了稀疏注意MIL带来的优化问题。通过高效多尺度随机斑块采样策略，端到端训练的ResNet在多个挑战性基准测试中超越了第二阶段方法的SOTA基线模型，同时保持了高计算效率。这是端到端学习在计算病理学中的一个重要进展，为未来的研究提供了新的方向和动力。", "conclusion": "本文证明了端到端学习在计算病理学中的巨大潜力，并呼吁在该领域进行更多研究。实验结果表明，在多个挑战性基准上，使用ABMILX的端到端训练ResNet模型在性能和计算效率方面均优于传统方法。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23883", "html_url": "https://arxiv.org/abs/2505.23883", "title": "BioCLIP 2: 通过层次对比学习扩大规模后产生的特性", "title_en": "BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning", "authors": "Jianyang Gu,Samuel Stevens,Elizabeth G Campolongo,Matthew J Thompson,Net Zhang,Jiaman Wu,Andrei Kopanev,Zheda Mai,Alexander E. White,James Balhoff,Wasila Dahdul,Daniel Rubenstein,Hilmar Lapp,Tanya Berger-Wolf,Wei-Lun Chao,Yu Su", "background": "大规模训练的基础模型会展现出非凡的自涌现行为，即在初始训练目标之外学习新的能力。本文通过大规模对比视语言训练，在生物视觉模型中发现了这种自涌现行为。研究者首先创建了一个名为TreeOfLife-200M的大型生物有机体图像数据集，然后通过该数据集训练了BioCLIP 2模型，使其能够识别不同物种。尽管训练目标较为狭窄，但BioCLIP 2在各种生物视觉任务上的准确度出乎意料地高，如栖息地分类和特征预测。研究者还发现，在学习嵌入空间中存在自涌现属性。在跨物种层面，不同物种的嵌入分布与功能和生态含义紧密对齐；在同类层面，物种内差异（如生活阶段和性别）反而得到了更好的保留和区分。", "innovation": "通过创建TreeOfLife-200M，即包含2亿多张生物有机体图像的最大和最多样化的生物有机体图像数据集，研究者训练了BioCLIP 2，使其能够识别不同物种。尽管训练目标较为狭窄，但模型在多种生物视觉任务中的表现非常优异。研究进一步分析了自涌现属性，并通过形式化证明了层次监督和对比目标为何会促进这些自涌现属性的产生。特别值得注意的是，研究结果表明，随着训练数据规模的扩大，这些属性变得越来越重要，形成了具有生物学意义的嵌入空间。", "conclusion": "这些结果显示，基础模型通过大规模训练不仅能够实现初始训练目标，还会展现出生物上有意义的自涌现特性。规模化训练可以从横向（不同物种之间）和纵向（同类内部）两个维度揭示生物学上的重要属性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05341", "html_url": "https://arxiv.org/abs/2506.05341", "title": "通过空间推理实现3D室内场景合成的直接数值化布局生成", "title_en": "Direct Numerical Layout Generation for 3D Indoor Scene Synthesis via Spatial Reasoning", "authors": "Xingjian Ran,Yixuan Li,Linning Xu,Mulin Yu,Bo Dai", "background": "真实的3D室内场景合成对于增强型AI和数字内容创建至关重要。这一任务可以自然地分为两个子任务：对象生成和布局生成。尽管最近的生成模型在对象级的质量和可控性上取得了显著进展，但布局生成仍然是一个挑战，因为现有数据集非常有限。现有的方法要么过度拟合这些数据集，要么依赖于预定义的约束优化数值布局，牺牲了灵活性。因此，它们无法生成开放词汇和细致粒度用户指令对齐的场景。", "innovation": "我们提出了DirectLayout框架，该框架利用大型语言模型（LLMs）的一般化空间推理能力，直接从文本描述生成数值化的3D布局。DirectLayout将生成过程分解为三个阶段：生成鸟瞰图（BEV）布局、将其提升至3D空间以及优化对象摆放。通过采用基于3D-Front数据集的Chain-of-Thought（CoT）激活机制，增强明细化的空间推理能力，并设计CoT-Grounded生成布局奖励，提升模型的一般化能力和空间规划能力。直接布局在推断过程中通过上下文学习迭代资产-布局对齐解决资产布局不匹配的问题。广泛的实验表明DirectLayout实现了语义一致性、泛化能力和物理合理性。", "conclusion": "DirectLayout框架通过文本描述直接生成数值化的3D布局，结合大型语言模型的空间推理能力，解决了3D室内场景合成中的布局生成挑战，实现了语义一致性、泛化能力和物理合理性。通过上下文学习、CoT激活机制和生成布局奖励，DirectLayout在生成布局能力上取得了显著进展。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.09122", "html_url": "https://arxiv.org/abs/2507.09122", "title": "SnapMoGen: 从富有表现力的文本生成人类运动", "title_en": "SnapMoGen: Human Motion Generation from Expressive Texts", "authors": "Chuan Guo,Inwoo Hwang,Jian Wang,Bing Zhou", "background": "文本到运动生成在近年来取得了显著进步，但仍局限于从简短或通用的文本提示生成运动，主要是由于数据集限制。这限制了生成运动的精细可控性和对未见提示的推广能力。", "innovation": "SnapMoGen引入了一个新的文本-运动数据集，包含高质量的运动捕捉数据和精确的表达性文本标注。此外，改进了先前的生成式掩蔽建模方法，MoMask++能够将运动转化为多尺度的标记序列，并使用单个生成掩模变换器生成所有标记，从而在基准测试中达到了当前最佳性能。SnapMoGen还展示了处理非正式用户提示的能力，通过LLM对输入进行格式化，以匹配SnapMoGen的表达性和叙述风格。", "conclusion": "SnapMoGen数据集和MoMask++模型提高了文本到运动生成的性能和可控性，特别是对于长期运动生成和融合的研究具有重要意义。这种工作的目标是对不同类型文本的运动进行精细的控制和生成，从而为运动捕捉和生成领域带来新的可能性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23010", "html_url": "https://arxiv.org/abs/2505.23010", "title": "SeG-SR: 通过Vision-Language模型将语义知识整合到遥感图像超分辨率中", "title_en": "SeG-SR: Integrating Semantic Knowledge into Remote Sensing Image Super-Resolution via Vision-Language Model", "authors": "Bowen Chen,Keyan Chen,Mohan Yang,Zhengxia Zou,Zhenwei Shi", "background": "高分辨率（HR）遥感图像在城市规划和环境监测等领域中发挥着重要作用。然而，由于传感器和数据传输链路的限制，实践中获取的图像通常会存在分辨率下降的问题。遥感图像超分辨率（RSISR）旨在从低分辨率（LR）输入中重建HR图像，为直接获取HR图像提供了经济高效且高效的替代方案。现有RSISR方法主要关注像素空间的低级特征，而忽视了遥感场景的高级理解，这可能导致重建结果中的语义不一致的伪影。", "innovation": "受此观察的启发，我们的研究旨在探索高阶语义知识在改进RSISR性能中的作用。我们提出了一种语义引导超分辨框架，称为SeG-SR，利用Vision-Language模型从输入图像中提取语义知识，并用于指导超分辨率（SR）过程。具体而言，我们设计了一个语义特征提取模块（SFEM），利用预训练的VLM从遥感图像中提取语义知识；接着提出了一种语义定位模块（SLM），从提取的语义知识中推导出一系列语义引导；最后开发了一种可学习调节模块（LMM），使用语义引导调节SR网络提取的特征，有效将高级场景理解融入到SR流程中。", "conclusion": "我们通过广泛的实验验证了SeG-SR的有效性和泛化性：SeG-SR在三个数据集上的表现达到最新技术水平，并且在各种SR架构上都能持续提高性能。值得注意的是，在UCMerced数据集上的x4 SR任务中，它取得了29.3042 dB的PSNR和0.7961的SSIM成绩。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00371", "html_url": "https://arxiv.org/abs/2507.00371", "title": "PlantSegNeRF：通过多视图图像实例匹配联合通道NeRF进行跨物种的少量样本植物3D实例点云重建方法", "title_en": "PlantSegNeRF: A few-shot, cross-species method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching", "authors": "Xin Yang(1 and 2),Ruiming Du(3),Hanyang Huang(1 and 2),Jiayang Xie(1 and 2),Pengyao Xie(1 and 2),Leisen Fang(1 and 2),Ziyue Guo(1 and 2),Nanjun Jiang(4),Yu Jiang(5),Haiyan Cen(1 and 2) ((1) College of Biosystems Engineering and Food Science, Zhejiang University, (2) Key Laboratory of Spectroscopy Sensing, Ministry of Agriculture and Rural Affairs, (3) Department of Biological and Environmental Engineering, Cornell University, (4) Amway (China) Botanical R and D Center, (5) Horticulture Section, School of Integrative Plant Science, Cornell AgriTech)", "background": "植物器官分割的点云是精确提取器官级表型性状的基础。尽管深度学习的快速进步促进了植物点云分割的研究，但现有的器官分割技术仍然存在分辨率低、分割准确性和跨不同植物物种的一般性不足的问题。因此，本研究提出了一种新颖的方法，即植物分割神经辐射场(PlantSegNeRF)，旨在从多视角RGB图像序列直接生成高精度实例点云，适用于多种植物物种。", "innovation": "本研究创新之处在于提出了PlantSegNeRF，该方法通过2D实例分割生成每种器官对应的实例掩码，并使用特定设计的实例匹配模块对相同的植物器官在多视角中的实例ID进行匹配和优化。然后利用实例NeRF渲染包含颜色、密度、语义和实例信息的隐式场景，最终基于体积密度将隐式场景转换为高精度的植物实例点云。实验证明，在点云的语义分割方面，PlantSegNeRF 相比常用方法表现出色，平均提升了16.1%、18.3%、17.8%和24.2%的精度、召回率、F1得分和IoU。此外，PlantSegNeRF 在植物点云实例分割任务中表现优异，针对所有植物物种，分别提升了11.7%、38.2%、32.2%和25.3%的mPrec、mRec、mCov和mWCov。", "conclusion": "本研究扩展了器官级植物表型分析，提供了一种高效生成大规模植物模型所需高质量3D数据的方法。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12006", "html_url": "https://arxiv.org/abs/2507.12006", "title": "基于频率动态注意模调节的密集预测", "title_en": "Frequency-Dynamic Attention Modulation for Dense Prediction", "authors": "Linwei Chen,Lin Gu,Ying Fu", "background": "视觉变换器（ViTs）在计算机视觉中的应用取得了显著进展，但在这些模型中，注意力机制导致每一层都相当于一个低通滤波器，现有的变压器堆叠层架构会遭受频率消失的问题，这对细节和纹理的丢失产生影响。", "innovation": "提出了一种受电路理论启发的新策略，即频率动态注意模调节（FDAM），它可以轻松地嵌入ViTs中。FDAM通过直接调节ViTs的整体频率响应，包括引入注意力反转（AttInv）和频率动态缩放（FreqScale）两种技术，解决上述问题。", "conclusion": "通过特征相似性分析和有效的秩评估，本文表明该方法避免了表示崩塌，使多种模型，包括SegFormer、DeiT、MaskDINO等，在语义分割、物体检测和实例分割等任务上均取得了性能提升。此外，在遥感检测任务中，该方法获得了单尺度设置下的最优结果。源代码已发布。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.05427", "html_url": "https://arxiv.org/abs/2507.05427", "title": "OpenWorldSAM: 使用语言提示进行通用图像分割的扩展SAM2", "title_en": "OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts", "authors": "Shiting Xiao,Rishabh Kabra,Yuhang Li,Donghyun Lee,Joao Carreira,Priyadarshini Panda", "background": "基于开放语言提示的物体分割能力仍是一个关键挑战，要求模型将文本语义转化为精确的空域遮罩，同时处理多样且未见过的类别。现有模型在处理开放词汇场景时存在局限性，尤其是在灵活性、效率、实例感知能力和泛化能力上存在不足。因此，需要提出一种新的框架，以克服这些现有技术的限制。", "innovation": "OpenWorldSAM框架扩展了SAM2（Segment Anything Model v2）至开放词汇场景中，通过集成轻量级的视觉语言模型（VLM）抽取的多模态嵌入。其创新点包括：i) 统一提示：OpenWorldSAM支持各类别级别和句子级语言描述的提示，提供灵活的接口；ii) 效率：通过冻结预训练组件，仅在COCO-stuff数据集上训练450万参数，实现了较高的资源效率；iii) 实例感知：通过新型位置竞争嵌入和交叉注意层增强空间理解，实现对多个实例的有效分割；iv) 泛化能力：展示了强大的零样本能力，无需额外培训即可在未见过的类别和开放词汇上的概念中泛化。", "conclusion": "通过广泛的实验，OpenWorldSAM在多个基准测试的开放词汇语义分割、实例分割和泛视分割中达到了最先进的性能。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02329", "html_url": "https://arxiv.org/abs/2508.02329", "title": "通过指令编辑数据和长描述增强CLIP的精细视觉理解 - VITRIX-CLIPIN", "title_en": "VITRIX-CLIPIN: Enhancing Fine-Grained Visual Understanding in CLIP via Instruction Editing Data and Long Captions", "authors": "Ziteng Wang,Siqi Yang,Limeng Qiao,Lin Ma", "background": "尽管视觉语言模型（如CLIP）在视觉和语言对齐方面取得了成功，但在细节和细粒度的视觉理解方面仍存在重要挑战。本文介绍了一种新型框架CLIP-IN，通过两项核心创新增强了CLIP的细粒度感知能力。", "innovation": "CLIP-IN通过两项主要创新增强了CLIP。首先，使用设计用于图像处理的指令编辑数据集作为硬负样本图像-文本对的来源，并结合对称的硬负样本对比损失，从而帮助模型有效地区分微妙的视觉语义差异。其次，将长描述性标题融入CLIP-IN，利用旋转位置编码捕捉标准CLIP常常忽略的丰富语义上下文。", "conclusion": "实验结果表明，CLIP-IN在MMVP基准和各种细粒度视觉识别任务中取得了显著提升，同时保持广泛的分类和检索任务的稳健零样本性能。集成CLIP-IN的视觉表示到多模态大型语言模型中，显著减少了视觉幻觉并提高了推理能力。这项工作强调了将针对指令的对比学习与全面描述性信息相结合的潜力，以提升VLMs的细粒度理解能力。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.20890", "html_url": "https://arxiv.org/abs/2509.20890", "title": "FerretNet：基于局部像素依赖的高效合成图像检测", "title_en": "FerretNet: Efficient Synthetic Image Detection via Local Pixel Dependencies", "authors": "Shuqiao Liang,Jian Liu,Renzhang Chen,Quanlong Guan", "background": "由于高级模型如VAEs、GANs和LDMs生成的合成图像越来越逼真，合成图像检测面临着巨大挑战。生成过程中引入的两种特征被探索：（1）潜在分布偏差和（2）解码引起的平滑效应，这些特征表现为局部纹理、边缘和颜色过渡的一致性问题。", "innovation": "提出了一种轻量级神经网络FerretNet，该网络仅包含1.1M个参数，能够高效且稳健地检测合成图像。它利用Markov Random Fields中的局部像素依赖性（LPD）特性，通过邻近像素信息重建合成图像，揭示了纹理连续性和边缘一致性的中断。", "conclusion": "FerretNet仅在4类ProGAN数据集上进行训练，在包含22个生成模型的开放世界基准测试中，平均准确率达到97.1%。研究的代码和数据集已公开。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21401", "html_url": "https://arxiv.org/abs/2509.21401", "title": "JaiLIP: 通过损失引导的图像扰动破解视觉语言模型", "title_en": "JaiLIP: Jailbreaking Vision-Language Models via Loss Guided Image Perturbation", "authors": "Md Jueal Mia,M. Hadi Amini", "background": "视觉语言模型（VLMs）在生成多模态推理任务方面展现了显著能力，但不同类别攻击向量下潜在滥用或安全性对齐问题显著增加。特别是基于图像的扰动被证明非常有效。现有技术有许多方法来破解VLMs，导致性能不稳定且可见扰动。文章分析了现有攻击方法的问题，并指出在具体领域（如交通）验证攻击的实用性挑战。", "innovation": "本文提出了一种通过损失引导的图像扰动（JaiLIP）方法，该方法在图像空间中最小化综合无噪声和对抗图像平均平方误差（MSE）损失和模型有害输出损失的联合目标。该方法在标准毒性度量（来自Perspective API和Detoxify）下有显著效果，生成了高效且难以察觉的对抗图像，优于现有方法。同时，它在交通领域进行了评估，证明了攻击的实际适用性，扩展了传统文本领域的影响。", "conclusion": "研究表明，基于图像的破解攻击面临实际挑战，需要有效的防御机制。JaiLIP方法在减少可见扰动的同时，显著提高了攻击的有效性，为视觉语言模型的安全性提供了新的思路。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.15235", "html_url": "https://arxiv.org/abs/2509.15235", "title": "ViSpec: 使用视觉感知推测性解码加速视觉语言模型", "title_en": "ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding", "authors": "Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen", "background": "推测性解码是一种广泛应用于大型语言模型（LLMs）以加速推理的技术，但在视觉语言模型（VLMs）中的应用相对较少，现有方法仅能提供微小的速度提升（<1.5倍）。随着多模态能力在大规模模型中变得越来越重要，这一差距变得更为显著。研究人员推测大型VLMs可以通过分层过滤冗余图像信息，同时不损害文本理解，而小型草稿模型则难以做到这一点。", "innovation": "本文提出了Vision-Aware Speculative Decoding（ViSpec），一种为VLMs设计的新型框架。ViSpec包含一个轻量级的视觉适配模块，将图像标记压缩为紧凑表示，该表示无缝集成到草稿模型的注意力机制中，同时保留原始图像位置信息。此外，对每个输入图像提取全局特征向量，并将其添加到后续的所有文本标记中，以增强跨模态一致性。为了克服用于训练的多模态数据集缺乏长期辅助响应的问题，研究团队通过重新利用现有数据集并使用目标VLM生成扩展输出，来构建一个特别训练数据集。同时，通过调整训练策略缓解草稿模型直接访问目标模型隐藏状态的风险，避免仅基于目标模型输出进行训练时的捷径学习。实验结果表明，ViSpec实现了首个显著的VLM推测性解码速度提升。", "conclusion": "本文提出的Vision-Aware Speculative Decoding（ViSpec）在视觉语言模型中实现了显著的速度提升，通过引入视觉适配模块和全局特征向量增强跨模态一致性等创新方法，解决现有方法在VLMs中的局限性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22414", "html_url": "https://arxiv.org/abs/2509.22414", "title": "LucidFlux：基于大规模扩散变换器的无提示统一图像恢复", "title_en": "LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer", "authors": "Song Fei,Tian Ye,Lujia Wang,Lei Zhu", "background": "统一图像恢复（UIR）旨在恢复由未知混合物导致的图像，同时保持图像的语义信息。然而，现有的差分恢复器和基于UNet的先验模型容易出现过度光滑、幻觉或漂移的问题。在图像恢复过程中，保护图像的大结构同时恢复细粒度纹理是技术难点，尤其是在图像存在于自然界中而不是合成条件下。研究人员需要一种新的框架来改进这一点，从而提高恢复图像的整体质量和准确性。", "innovation": "LucidFlux 是一个无需图像提示的新框架，基于大型扩散变换器（Flux.1）。LucidFlux 引入了一个轻量级的双分支条件器，将降级输入和微恢复代理信号分别锚定几何形状并抑制伪影，从而在骨干网的层次结构中传递这些提示，以实现从粗糙到细致的、上下文敏感的更新。框架还包括一种基于代理的无提示语义对齐机制，以避免文本提示或MLLM提示的延迟和不稳定。最后，通过一个可扩展的数据整理管道，LucidFlux 提高了具有结构丰富监督的大规模数据集的效果，优于现有开源和商业基准，且消融实验验证了各组成部分的必要性。", "conclusion": "LucidFlux 证明了，对于大型扩散变换器，调整何时以及在哪里进行条件控制——而不是添加参数或依赖于文本提示——是实现鲁棒且无提示的统一图像恢复的关键杠杆，即使在自然界中也能表现出色。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08974", "html_url": "https://arxiv.org/abs/2508.08974", "title": "基于文本条件的状态空间模型在泛化领域变化检测视觉问答中的应用", "title_en": "Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering", "authors": "Elman Ghazaei,Erchan Aptoula", "background": "地球表面不断发生改变，变化检测提供了对人类社会有益的洞察。传统的变化检测方法依赖于双时相图像，虽然这些方法需要专家知识才能准确解释，但面对非专家用户，方法过于专业且不灵活。为此，引入了变化检测视觉问答(CDVQA)任务，以提供更广泛、更灵活的变化信息访问。然而，现有的CDVQA方法假设训练和测试数据集具有相同的数据分布，但在实际应用中，领域偏移（领域变换）经常发生。因此，需要重新审视CDVQA任务，特别是解决领域偏移问题。为此，提出了一个新型的多模态和多领域数据集BrightVQA，并提出了一种新的状态空间模型——文本条件状态空间模型(TCSSM)，以实现CDVQA任务中的领域泛化研究，通过结合双时相图像和与地球灾害相关的文本信息，提取领域不变特征。", "innovation": "研究提出了一种新的状态空间模型——文本条件状态空间模型(TCSSM)，能同时利用双时相图像和地球灾害相关的文本信息来提取领域不变特征，这一模型能够动态预测输入依赖参数，并通过统一的方式进行变化检测，增强了CDVQA任务的鲁棒性和泛化能力。此外，还建立了一个多模态和多领域数据集BrightVQA，用于支持领域泛化研究。实验结果表明，所提出的方法优于当前最先进的模型。", "conclusion": "本文提出了一个新的多模态和多领域数据集BrightVQA，并提出了一种新的基于文本条件的状态空间模型(TCSSM)。TCSSM模型通过结合双时相图像和地球灾害相关的文本信息，能动态预测输入依赖参数，从而确保视觉数据和文本描述之间的对齐。实验结果显示，所提出的方法具有优越的性能。代码和数据集将在接受后公开。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24739", "html_url": "https://arxiv.org/abs/2509.24739", "title": "为医疗数据构建视觉-语言基础模型：越南PET/CT报告生成的多模态数据集和基准测试", "title_en": "Toward a Vision-Language Foundation Model for Medical Data: Multimodal Dataset and Benchmarks for Vietnamese PET/CT Report Generation", "authors": "Huu Tien Nguyen,Dac Thai Nguyen, TheMinh Duc Nguyen,Trung Thanh Nguyen,Thao Nguyen Truong,Huy Hieu Pham,Johan Barthelemy,Minh Quan Tran,Thanh Tam Nguyen,Quoc Viet Hung Nguyen,Quynh Anh Chau,Hong Son Mai,Thanh Trung Nguyen,Phi Le Nguyen", "background": "视觉-语言基础模型（VLMs）通过大规模多模态数据集训练，在人工智能领域取得了显著进步，但它们在医疗成像中的应用仍面临挑战，主要是由于可用的医学成像模态和多语言临床数据有限，多数现有的医疗VLMs主要集中在少数成像模态和高资源语言上，限制了它们在临床中的广泛应用。目前，缺乏包含PET/CT影像数据以及越南语多模态临床数据的基础模型，这成为阻碍开发能够处理功能性成像任务模型的一个关键因素。因此，研究引入了一个越南语多重模态医学数据集，该数据集包含了2757个全身体PET/CT图像及相应的全面临床报告，试图填补现有研究中的两个关键空白，即缺乏这种成像数据和对低资源语言特别是越南语低覆盖率的问题。", "innovation": "该研究创新性地创建了一个包含全身体PET/CT图像及其对应全面临床报告的越南语多模态医学数据集，填补了训练现有VLMs数据集的空白并增加了多语言资源，尤其突出的是越南语资源，其次提出了一种改进VLMs学习的训练框架，包括数据增强和专家验证的测试集，最终在后续任务上对最先进的VLMs进行了基准测试，实验结果表明该数据集的引入显著提高了现有VLMs的表现。", "conclusion": "该越南语多模态医学数据集及基准测试将对推进针对低资源语言和越南医疗临床应用的更强大VLMs的发展起到关键作用。该研究的数据集和基准测试成果将有助于促进医疗成像领域进一步的发展，尤其是在低资源语言和越南医疗临床应用方面。研究代码可在提供的链接处访问。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.10203", "html_url": "https://arxiv.org/abs/2510.10203", "title": "一种用于量化自动驾驶数据集合成到现实差距的样式基档案框架", "title_en": "A Style-Based Profiling Framework for Quantifying the Synthetic-to-Real Gap in Autonomous Driving Datasets", "authors": "Dingyi Yao,Xinyao Han,Ruibo Ming,Zhihang Song,Lihui Peng,Jianming Hu,Danya Yao,Yi Zhang", "background": "自主驾驶系统感知系统的可靠性需要基于环境的测试，但在实际执行中往往不切实际。合成数据集因此成为了有前景的替代方案，具有成本效益、无偏见标注和可控场景等优势。然而，合成数据集与真实世界数据集之间的领域差距仍然是模型泛化的重大障碍。", "innovation": "提出了一种风格嵌入分布差异（SEDD）作为新的评估指标，并结合基于格玛矩阵的风格提取和优化内类紧凑性和类间分离度的度量学习，提取风格嵌入，从而建立了一个基准，证明了该方法能够量化合成到真实差距。", "conclusion": "这项工作提供了一种基于档案的标准质量控制框架，使系统地诊断和针对性改进合成数据集成为可能，为基于数据的自主驾驶系统未来的发展做出了贡献。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.25033", "html_url": "https://arxiv.org/abs/2509.25033", "title": "VT-FSL: 通过LLMs连接视觉和文本的少量样本学习", "title_en": "VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning", "authors": "Wenhao Li,Qiangchang Wang,Xianjing Meng,Zhibin Wu,Yilong Yin", "background": "少量样本学习（FSL）旨在仅从少量标记的支撑样本中识别新的概念。近期的研究通过引入额外的语义信息或设计复杂的语义融合模块来增强支撑特征，但这些方法仍然存在由于缺乏实例实据导致的虚构语义问题，从而使指导变得嘈杂且需要大量修正。", "innovation": "本文提出了一种新的框架——VT-FSL（Vision and Text with LLMs for Few-Shot Learning），通过大型语言模型（LLMs）构建跨模态精确提示，并通过几何感知对齐无缝地将提示和支撑图像集成在一起。该框架主要由跨模态迭代提示（CIP）和跨模态几何对齐（CGA）组成。CIP通过一次结构化的推理过程，同时条件化LLMs在类别名称和支持图像上，生成精确的类别描述。CGA最小化由融合的文本、支撑和合成视觉表示构成的3维平行多面体的核体积，捕捉所有表示之间的全局和非线性关系，实现结构化的多模态整合。本文提出的VT-FSL方法在包括标准、跨域和细粒度少量样本学习场景在内的十个不同的基准测试中取得了新的SOTA性能。", "conclusion": "VT-FSL框架通过结合视觉和文本信息，在少量样本学习中取得了显著的进展，并建立了新的SOTA性能，并通过几何对齐提高了跨模态的理解和整合。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.26087", "html_url": "https://arxiv.org/abs/2509.26087", "title": "EasyOcc: 3D Pseudo-Label Supervision for Fully Self-Supervised Semantic Occupancy Prediction Models", "title_en": "EasyOcc: 3D Pseudo-Label Supervision for Fully Self-Supervised Semantic Occupancy Prediction Models", "authors": "Seamie Hayes,Ganesh Sistu,Ciarán Eising", "background": "自监督模型在语义占据预测领域取得了显著进展，这些模型依赖复杂的方法来弥补无地真相例的缺失，如新颖视角合成、跨视角渲染和深度估计。然而，这些方法在训练阶段通常会带来高昂的计算成本和内存使用，尤其是在新颖视角合成的情况下。尽管前人方法提高了性能，但这些进步往往在其他架构中难以直接迁移。", "innovation": "该研究提出了一种利用基础模型Grounded-SAM和Metric3Dv2生成3D伪地真相例的方法，并结合了临时信息以增强标签密度。这可以无缝集成到现有的模型中，显著提高了性能，mIoU提高了45%，从9.73提高到14.09。同时，该研究还提出了一种简化模型EasyOcc，仅基于这些伪标签进行学习，无须复杂的渲染策略，实现了优异的性能。此模型在完整场景上的性能表现优于现有最佳模型，mIoU为7.71，提升了31%。这种方法突显了基础模型、临时上下文以及损失计算空间在自监督学习中全面场景理解中的重要性。", "conclusion": "该研究提出了3D伪标签监督方法，通过利用基础模型生成的伪标签和临时信息增强标签密度，显著提升了自监督语义占据预测模型的性能。此外，还提出了一种简化模型EasyOcc，仅基于这些伪标签进行学习，取得了优异的性能，展示了在全面场景理解中的应用潜力。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.10750", "html_url": "https://arxiv.org/abs/2510.10750", "title": "通过视觉异常检测揭示海洋环境监测中的异常事件", "title_en": "Uncovering Anomalous Events for Marine Environmental Monitoring via Visual Anomaly Detection", "authors": "Laura Weihl,Stefan H. Bengtson,Nejc Novak,Malte Pedersen", "background": "水下视频监测是评估海洋生物多样性的一种有前途的策略，但由于大量未发生的视频使得人工检查变得极其不实际。因此，本研究探索了基于深度神经网络的视觉异常检测（VAD）方法，旨在自动识别有趣或异常事件。", "innovation": "作者提出了AURA，这是首个用于水下VAD的多标注基准数据集，并且评估了四种VAD模型在两种海洋场景中的表现。他们强调了稳健的帧选择策略的重要性以提取有意义的视频片段。研究表明，当前模型的VAD性能有很大差异，并且高度依赖于训练数据的数量以及定义正常场景的视觉内容的变异性。这一结果强调了软标签和共识标签的重要性，并提出了支持科学探索和可扩展生物多样性监测的实用方法。", "conclusion": "对比多种标注者的结果表明，当前模型的VAD性能差异很大，且高度依赖于训练数据量和“正常”场景的视觉内容变异性。这一结果突显了软标签和共识标签的价值，并为支持科学探索和可扩展生物多样性监测提供了实际的方法。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11520", "html_url": "https://arxiv.org/abs/2510.11520", "title": "mmWalk:向多模态多视角步行辅助迈出一步", "title_en": "mmWalk: Towards Multi-modal Multi-view Walking Assistance", "authors": "Kedi Ying,Ruiping Liu,Chongyan Chen,Mingzhe Tao,Hao Shi,Kailun Yang,Jiaming Zhang,Rainer Stiefelhagen", "background": "对于视障或低视力（BLV）人士来说，在极端或复杂环境下的行走援助仍然是一项重大挑战，主要是由于缺乏对整体场景的理解。受BLV社区实际需求的驱动，我们构建了mmWalk，这是一个综合了多视角传感器和无障碍导向特征的模拟多模态数据集，用于户外安全导航。", "innovation": "我们构建了mmWalk数据集，它包括120条手动控制的、按场景分类的行走轨迹，共包含62000帧同步图像，超过559000张全景图像，覆盖RGB、深度和语义模态。此外，我们还生成了mmWalkVQA，这是针对安全和知情行走辅助的超过69000个视觉问答三元组的基准数据集，分为9个类别。我们还评估了最新的视觉语言模型（VLMs），发现它们在风险评估和导航任务上表现不佳。", "conclusion": "我们对mmWalk微调后的模型进行了实地数据集验证，并展示了该数据集对多模态行走辅助技术发展的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02253", "html_url": "https://arxiv.org/abs/2510.02253", "title": "DragFlow: 使用区域监督释放DiT先验的拖动编辑", "title_en": "DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag Editing", "authors": "Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong", "background": "基于拖动的图像编辑长期以来遭受目标区域畸变的问题，主要是因为早期基础模型Stable Diffusion的先验不足，无法将优化的潜在向量投影回自然图像流形。随着从基于UNet的DDPMs转向更具扩展性的DiT（特别是SD3.5和FLUX版本），生成先验变得更加强大，已经在多种编辑任务上取得了进展。然而，拖动编辑仍然没有受益于这些更强的先验。为了解决这个问题，本文提出了首个有效利用FLUX丰富先验的拖动编辑框架，称为DragFlow，该框架在基准测试中取得了显著的进步。直接应用于DiTs的点编辑表现不佳，因为DiT中的特征不如UNets压缩，无法提供可靠的关键点指导。为了解决这一限制，DragFlow引入了一种基于区域的编辑范式，通过仿射变换提供更丰富和一致的特征监督。此外，通过整合预训练的通用领域个性化适配器（如IP-Adapter）增强了主体一致性，通过梯度掩码进行硬约束保留背景保真度。多模态大语言模型进一步用于解决任务歧义性。为了评估，本文创建了基于区域拖动的基准（ReD Bench），包括基于区域的拖动指令。在DragBench-DR和ReD Bench上的大量实验显示，DragFlow优于点编辑和区域编辑基线，打破了基于拖动的图像编辑的新记录。代码和数据集将在发表后公开。", "innovation": "提出了首个有效利用FLUX丰富先验的拖动编辑框架，称为DragFlow。通过引入基于区域的编辑范式和合适的特征监督技术和特征约束，该框架显著改善了拖动编辑中的目标区域畸变问题。DragFlow不仅展示了在各种拖动编辑任务上的优越性能，还能够保留背景的保真度和较高的主体一致性。此外，该框架还通过多模态大语言模型解决任务的歧义性，为拖动编辑的进一步扩展奠定了基础。", "conclusion": "通过创建ReD Bench并利用DragFlow框架，本文在拖动编辑任务上取得了新记录，通过公开代码和数据集，希望能够推动该领域的进一步研究进展。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12953", "html_url": "https://arxiv.org/abs/2510.12953", "title": "了解导向的视觉-语言基础模型在胎儿超声解释中的应用", "title_en": "Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation", "authors": "Xiao He,Huangxuan Zhao,Guojia Wan,Wei Zhou,Yanxing Liu,Juhua Liu,Yongchao Xu,Yong Luo,Dacheng Tao,Bo Du", "background": "近年来，医学领域的视觉-语言模型已经在问题回答（VQA）、报告生成和异常检测等任务上显示出潜力。然而，大多数模型主要用于结构化的成人影像，并在胎儿超声方面表现不佳，这给多视角图像推理、众多疾病和图像多样性带来了挑战。", "innovation": "为解决这个问题，该研究引入了FetalMind，一种专门针对胎儿超声的医疗AI系统，用于报告生成和诊断。研究中提出了一个称为Salient Epistemic Disentanglement (SED)的方法，该方法通过引入医生审定的二分图来分离开不同视图与疾病的关系，并利用强化学习引导临床忠实步骤，从而使模型的推理更加贴近产科实践。", "conclusion": "研究团队还策划了FetalSigma-1M数据集，这是第一个大规模的胎儿超声报告数据集，包括来自十二个医疗中心的20,000份报告，解决了域数据稀缺的问题。实验结果表明，FetalMind在所有妊娠阶段都优于开源和闭源基线模型，特别是在关键情况下，准确率提高了61.2%，并且该系统保持了高效、稳定和可扩展的特性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.13307", "html_url": "https://arxiv.org/abs/2510.13307", "title": "通过因果表示和推理联合学习的点云分割中新类发现", "title_en": "Novel Class Discovery for Point Cloud Segmentation via Joint Learning of Causal Representation and Reasoning", "authors": "Yang Li,Aming Wu,Zihao Zhang,Yahong Han", "background": "本文聚焦于点云分割中的新型类别发现（3D-NCD），旨在学习一个模型，使其仅通过标记的（基）3D类别的监督，就能分割未标记的（新型）3D类别。关键在于确定点表示与其基类别标签之间的精确关系，以及基类和新型类别之间点表示的相互关系。粗略或统计性的关系学习可能导致新型类别的混淆。若在学习过程中施加因果关系作为强相关约束，则能揭示准确对应类别的本质点云表示。", "innovation": "提出了一种新型方法，即因果表示和推理的联合学习。该方法首先通过结构性因果模型（SCM）分析基类表示中的隐藏混杂变量和基类与新型类之间的因果关系。然后设计因果表示原型消除混杂变量以捕捉基类的因果表示。接着使用图结构来建模基类因果表示原型和新型类原型之间的因果关系，从而实现基类到新型类的因果推理。", "conclusion": "在3D和2D NCD语义分割上的广泛实验和可视化结果显示了该方法的优势。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.13394", "html_url": "https://arxiv.org/abs/2510.13394", "title": "Spatial-DISE: 用于评估视觉语言模型空间推理能力的统一基准", "title_en": "Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models", "authors": "Xinmiao Huang,Qisong He,Zhenglin Huang,Boxuan Wang,Zhuoyun Li,Guangliang Cheng,Yi Dong,Xiaowei Huang", "background": "视觉语言模型(VLMs)在多样化的应用领域，如机器人、增强现实和自主导航中，空间推理能力至关重要。然而，现有的基准测试在评估空间推理能力方面存在不足，尤其是在评估内在动态空间推理方面，这在人类空间认知中是一个基本方面。因此，需要改进的基准测试来更好地评估视觉语言模型的空间推理能力。", "innovation": "本文提出了一种基于认知基础的分类法的统一基准测试Spatial-DISE，将任务分为四类空间推理类型：内在静态、内在动态、外在静态和外在动态空间推理。此外，为了应对数据稀缺性，研究人员开发了一种可扩展和自动化的管道以生成多样化的且可验证的空间推理问题，从而创建了包含Spatial-DISE Bench (559评估VQA对)和Spatial-DISE-12K (12K+训练VQA对)的新Spatial-DISE数据集。", "conclusion": "28个最新的VLMs在Spatial-DISE上的全面评估表明，当前的VLMs与人类能力之间存在巨大且一致的差距，尤其是在多步多视点空间推理方面。Spatial-DISE提供了一个坚实的基础框架、有价值的资源集和明确的研究方向，以实现类似人类的空间智能。基准、数据集和代码将公开发布。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14255", "html_url": "https://arxiv.org/abs/2510.14255", "title": "基于奖励引导优化的身份保留图像到视频生成", "title_en": "Identity-Preserving Image-to-Video Generation via Reward-Guided Optimization", "authors": "Liao Shen,Wentao Jiang,Yiran Zhu,Jiahe Li,Tiezheng Ge,Zhiguo Cao,Bo Zheng", "background": "最近在图像到视频（I2V）生成方面的进步显著提高了合成高保真、时序一致视频的能力，尤其是在从静态图像生成人类为中心的视频方面取得了巨大进展。然而，现有的I2V模型在保持输入人体图像和生成视频之间的一致性身份时遇到困难，尤其是在视频中人物有显著的面部表情变化和动作时。此外，当人类正面在图像中只占很小比例时，这个问题更加显著。由于人类对身份变化非常敏感，这一直是一个关键但未被充分研究的I2V生成挑战。", "innovation": "本文提出了一种新颖的身份保留奖励引导优化(IPRO)框架，该框架基于强化学习来增强身份保持能力。IPRO直接优化密码扩散模型使用面部身份评分器，引入了一种有效的调优算法。为了提高性能和加速收敛，该方法通过采样链的最后步骤反向传播奖励信号，提供了更丰富的梯度反馈。此外，IPRO还提出了一个新的面部评分机制，将真实视频中的面部视为面部特征库，提供了多角度面部信息以增强泛化能力。还进一步引入了KL散度正则化来稳定训练并防止奖励信号过拟合。", "conclusion": "广泛的实验表明，IPRO方法在Wan 2.2 I2V模型和内部I2V模型上均有效。项目和代码可在提供的链接中找到。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.15398", "html_url": "https://arxiv.org/abs/2510.15398", "title": "MARIS: 海洋开放词汇实例分割与几何增强及语义对齐", "title_en": "MARIS: Marine Open-Vocabulary Instance Segmentation with Geometric Enhancement and Semantic Alignment", "authors": "Bingyu Li,Feiyu Wang,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li", "background": "大多数现有的水下实例分割方法受近义词预测限制，限制了它们识别新型海洋类别能力。为了支持评估，我们引入了MARIS（海洋开放词汇实例分割），这是第一个大规模细粒度的水下开放词汇分割基准，包含少量已知类别和大量未知类别。尽管在自然图像中开放词汇分割表现良好，但我们的分析显示，向水下场景的转移会受到严重的视觉退化（如颜色衰减）和由于缺乏水下类别定义导致的语义不匹配的影响。", "innovation": "我们提出了一种统一框架，包括两个互补的组件。几何先验增强模块（GPEM）利用稳定的部分级和结构线索，在退化的视觉条件下保持物体的一致性。语义对齐注入机制（SAIM）通过引入特定领域先验丰富语言嵌入，减少语义模糊性，提高识别未知类别的能力。实验表明，我们的框架在MARIS基准上的一致表现优于现有开放词汇基线，无论是域内还是域间设置，为未来的水下感知研究奠定了坚实的基础。", "conclusion": "我们的研究在MARIS基准上展示了强大的性能，特别是面对开放词汇的水下实例分割挑战，为未来的研究提供了重要的基础。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.16709", "html_url": "https://arxiv.org/abs/2510.16709", "title": "HumanCM：一步骤人体运动预测", "title_en": "HumanCM: One Step Human Motion Prediction", "authors": "Liu Haojie,Gao Suixiang", "background": "目前的人体运动预测方法多依赖于多步去噪过程，这种方法复杂且耗时。研究者们不断寻求更高效、更准确的人体运动预测模型和方法。", "innovation": "提出了HumanCM模型，这是一种以一致性模型为基础的一步骤人体运动预测框架。该模型通过学习噪声和清洁运动状态之间的一致性映射，仅需一步即可生成高效的运动预测，而不需要多步去噪过程。同时，模型采用了基于Transformer的空间时间架构，并加入了时间嵌入项以捕捉长程依赖关系，保持运动的一致性。实验结果显示，与基于扩散模型的最先进的模型相比，HumanCM在准确率上具有可比拟甚至更优的表现，同时将其推理步骤减少了高达100倍以上。", "conclusion": "HumanCM模型提供了一种高效且准确的人体运动预测方法，通过单步生成的方式极大减少了推理步骤的数量，同时保持了与基于扩散模型的最先进的模型相比的预测准确度。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14349", "html_url": "https://arxiv.org/abs/2510.14349", "title": "Vision-Centric Activation and Coordination for Multimodal Large Language Models", "title_en": "Vision-Centric Activation and Coordination for Multimodal Large Language Models", "authors": "Yunnan Wang,Fan Lu,Kecheng Zheng,Ziyuan Huang,Ziqiang Li,Wenjun Zeng,Xin Jin", "background": "多模态大语言模型（MLLMs）将视觉编码器从图像中提取的特征与大语言模型（LLMs）结合，展现出高级的理解能力。主流的MLLMs主要通过文本下一个标记的预测进行监督，忽略了关键的视觉中心信息，这对于分析能力至关重要。因此，当前存在的问题是主要监督方式忽视了视觉信息的重要性。", "innovation": "为了解决上述问题，该研究引入了VaCo（Vision-Centric Activation and Coordination），通过视觉中心化的激活和协调机制，优化了MLLMs的表示。VaCo通过视觉区分性对齐整合了来自多个视觉基础模型（VFMs）的感知特征，使得文本和视觉输出在MLLMs中的优化统一。具体而言，该研究将可学习的模块任务查询（MTQs）和视觉对齐层（VALs）集成到MLLMs中，通过多种VFMs的监督，激活特定的视觉信号。此外，该研究设计的令牌网关掩码（TGM）限制了多个MTQs组之间的信息流，以协调来自不同VFMs的表示冲突。", "conclusion": "大量的实验表明，VaCo显著提高了各种基准测试中不同MLLMs的表现，展示了其在视觉理解方面的优越能力。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.16396", "html_url": "https://arxiv.org/abs/2510.16396", "title": "SPLite手部：感知稀疏性的轻量级3D手部姿态估计", "title_en": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "authors": "Yeh Keng Hao,Hsu Tzu Wei,Sun Min", "background": "由于AR/VR设备的普及，边缘设备上部署深度学习模型成为了一个关键挑战。这些设备需要实时推理、低功耗和低延迟。框架设计师面临在效率和性能之间取得平衡的问题。", "innovation": "本文设计了一个轻量级框架，采用编码-解码架构，并引入了几个关键贡献，以提高效率和准确度。通过对ResNet-18主干应用稀疏卷积来利用手部图像中的固有稀疏性，实现了端到端42%的效率提升。此外，提出了一种新的SPLite解码器，该架构在Raspberry Pi 5上将解码帧率提升了3.1倍，同时保持了准确率。通过量化感知培训，进一步优化性能，在减少内存使用的同时保持了准确性（PA-MPJPE从9.0 mm增加到9.1 mm，FreiHAND数据集上）。整个系统在Raspberry Pi 5 CPU（BCM2712四核ARM A76处理器）上实现了2.98倍的速度提升。该方法在复合基准数据集上进行评估，表现出与最先进的方法相当的准确性，同时显著提高了计算效率。", "conclusion": "本文提出的方法在保持高性能的同时实现了轻量化设计，通过稀疏卷积、SPLite解码器和量化感知训练等技术提升性能并减少内存使用，从而在3D手部姿态估计中实现了更好的效率和准确性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18705", "html_url": "https://arxiv.org/abs/2510.18705", "title": "从Transformer视角对显式运动信息挖掘在行动识别中的复兴", "title_en": "A Renaissance of Explicit Motion Information Mining from Transformers for Action Recognition", "authors": "Peiqin Zhuang,Lei Bai,Yichao Wu,Ding Liang,Luping Zhou,Yali Wang,Wanli Ouyang", "background": "近年来，动作识别主要受到基于变换器的方法支配，这是因为它们在时空上下文聚合方面的能力。然而，尽管在场景相关数据集上取得了显著进展，但在对运动敏感的数据集上表现不佳，这主要是由于缺乏细致的运动建模设计。此外，研究观察到，传统动作识别中广泛使用的成本体在风格上与自注意力定义的亲和矩阵高度相似，但具有强大的运动建模能力。", "innovation": "提出了一个清晰的运动信息挖掘模块（EMIM），旨在将这些有效的运动建模特性统一地整合到现有的变换器中。具体来说，该模块在一个滑动窗口的方式下，从下一帧的查询基邻域中抽取一组关键候选令牌，构建一个理想的亲和矩阵，在这种亲和矩阵中，上下文信息用于外观建模，且被转换为运动特征以用于运动建模。通过在四个常用的运动敏感数据集上验证该方法的效果，我们的方法在性能上超越了现有的最先进的方法，特别是在Something-Something V1 & V2等运动敏感数据集上表现尤为出色。", "conclusion": "本文提出的方法在四个常用的数据集上验证了其运动建模能力，并且在运动敏感数据集上表现优于现有的最先进的方法。该方法通过显式地挖掘运动信息并将其整合到现有的变换器框架中，提高了动作识别的性能。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18552", "html_url": "https://arxiv.org/abs/2510.18552", "title": "Occluded nuScenes: 多传感器数据集及其在自动驾驶感知鲁棒性评估中的应用", "title_en": "Occluded nuScenes: A Multi-Sensor Dataset for Evaluating Perception Robustness in Automated Driving", "authors": "Sanjay Kumar,Tim Brophy,Reenu Mohandas,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising", "background": "自动驾驶感知需要在恶劣条件下保持可靠性能，这时传感器可能会受到部分失效或环境遮挡的影响。虽然现有的自动驾驶数据集本身包含传感器噪声和环境变化，但很少有数据集能提供对多个传感模态进行受控、参数化和可重复降级的方式。这限制了评估感知和融合架构在特定不利条件下的表现能力。因此，有必要开发一个能够提供这种评估能力的数据集以改进现有情况。", "innovation": "本文提出了一种多传感器数据集 Occluded nuScenes 的扩展，它提供了对不同传感模态（包括摄像头、雷达和LiDAR）进行受控和可重复降级的方法。对于摄像头模态，提供了完整和迷你版本，并且包含了四种类型的遮挡类型，其中两种基于公开实现，另外两种是新的设计。对于雷达和LiDAR，提供了参数化的遮挡脚本，能够实施每种类型的三个降级，提高了生成受遮挡数据的灵活性和重复性。这一资源支持在部分传感器失效和环境干扰下的感知模型的一致性和可重复评估。", "conclusion": "通过发布第一个多传感器遮挡数据集，该数据集提供可控和可重复的降级，本文旨在推动鲁棒传感器融合、抗风险分析和自动驾驶安全关键感知的研究。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18781", "html_url": "https://arxiv.org/abs/2510.18781", "title": "反叛学生：高光谱异常检测中背景特征增强的互补学习框架", "title_en": "Rebellious Student: A Complementary Learning Framework for Background Feature Enhancement in Hyperspectral Anomaly Detection", "authors": "Wenping Jin,Yuyang Tang,Li Zhu,Fei Guo", "background": "最近有一种高光谱异常检测方法，可以在背景数据集上进行一次训练，然后在不同的场景中通用部署，无需重新训练或参数调优，已经展现出了显著的效率和鲁棒性。基于这一范式，本文集中于将光谱线索和空间线索相结合，并引入了一种新的“反叛学生”互补特征学习框架。", "innovation": "本文提出了“反叛学生”框架，这是一种互补特征学习方法，不同于传统的模仿式教师-学生模式，该方法有意训练空间分支与光谱教师产生差异，从而学习光谱教师未能捕捉到的互补空间模式。框架采用两阶段学习策略：首先通过反向蒸馏训练光谱增强网络以获得稳健的背景光谱表示；其次，使用非相关损失优化空间网络，增强特征正交性同时保持重建精度，从而避免无关噪声。", "conclusion": "实验表明，该框架在HAD100基准上与多种现有基准相比，展现出显著的改进，同时保持了适度的计算开销，证明了提出互补学习范式的有效性。经训练后的框架与传统检测器结合时，可实现无需参数和无需训练的异常检测。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19597", "html_url": "https://arxiv.org/abs/2510.19597", "title": "CBDiff：用于图像伪造定位的条件伯努利扩散模型", "title_en": "CBDiff:Conditional Bernoulli Diffusion Models for Image Forgery Localization", "authors": "Zhou Lei,Pan Gang,Wang Jiahao,Sun Di", "background": "图像伪造局部化（IFL）在图像取证中是一项关键任务，旨在在像素级准确识别图像中被操纵或篡改的区域。现有方法通常生成单一的确定性定位图，这在高风险应用如法医学分析和安全监控中往往缺乏足够的精确性和可靠性。", "innovation": "为了提升预测的可信度并降低错误风险，我们引入了一种先进的条件伯努利扩散模型（CBDiff）。给定一个伪造图像，CBDiff生成多种多样且合理的定位图，提供伪造分布的丰富和全面的表示。此外，CBDiff创新性地将伯努利噪声引入扩散过程，更加真实地反映伪造遮罩固有的二元稀疏特性。同时，CBDiff引入了时间步长交叉注意力（TSCAttention），专门设计用于利用时序步长中的语义特征引导以提高篡改检测能力。", "conclusion": "在八个公开基准数据集上的大量实验表明，CBDiff显著优于现有最先进的方法，展示了其在实际部署中强大潜力。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19193", "html_url": "https://arxiv.org/abs/2510.19193", "title": "视频一致性距离：通过基于奖励的微调增强图像到视频生成的时间一致", "title_en": "Video Consistency Distance: Enhancing Temporal Consistency for Image-to-Video Generation via Reward-Based Fine-Tuning", "authors": "Takehiro Aoshima,Yusuke Shinohara,Byeongseon Park", "background": "基于奖励的视频扩散模型的微调是一种有效的方法来提高生成视频的质量，因为它可以在不需要真实世界视频数据集的情况下微调模型。然而，这种方法有时会对特定性能产生限制，因为传统的奖励函数主要集中在增强整个生成视频序列的质量，如美学和整体一致性方面。值得注意的是，在将先前的方法应用于图像到视频生成任务时，生成视频的时间一致性通常会受到影响。为了缓解这一限制，我们提出了视频一致性距离(VCD)，这是一种新型的度量标准，旨在提高时间一致性，并在基于奖励的微调框架中微调模型。通过在视频帧特征的频域中定义VCD并利用频域分析有效地捕捉帧信息，我们实现了相对于条件图像的一致的时间一致性。多个图像到视频生成数据集的实验结果表明，通过使用VCD微调视频生成模型，在不损害其他性能的情况下显著提高了时间一致性。", "innovation": "我们提出了VCD，一种新型的度量标准，专门用于在图像到视频生成任务中增强时间一致性和在基于奖励的微调框架中微调模型。VCD在视频帧特征的频域中被定义，通过频域分析有效捕捉帧信息，从而实现相对于条件图像的一致的时间一致性。该方法显著提高了时间一致性，且在其他性能方面没有降级。", "conclusion": "实验结果表明，使用VCD手段微调视频生成模型，能够在不损害其他性能的情况下显著提高视频生成的时间一致性。这解决了先前方法在时间一致性方面的限制，为改善图像到视频生成的质量提供了有效的解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.08281", "html_url": "https://arxiv.org/abs/2401.08281", "title": "Faiss库", "title_en": "The Faiss library", "authors": "Matthijs Douze,Alexandr Guzhva,Chengqi Deng,Jeff Johnson,Gergely Szilvasy,Pierre-Emmanuel Mazaré,Maria Lomeli,Lucas Hosseini,Hervé Jégou", "background": "随着AI应用的快速增长，需要存储和索引的嵌入向量数量也在增加。Faiss库专注于向量相似性搜索，这是向量数据库的核心功能之一。Faiss提供了一系列索引方法和相关基本元素，用于搜索、聚类、压缩和转换向量。本文描述了向量搜索的权衡空间以及Faiss的设计原则，涉及结构、优化方法和接口设计，并对关键特性和几个选定应用进行了基准测试，以突出其广泛适用性。", "innovation": "Faiss库通过提供一系列索引方法和相关基本元素，专注于向量相似性搜索，显著提高了在存储和索引大量嵌入向量方面的效率和性能。该论文介绍了Faiss在结构设计、优化方法和接口设计方面的创新之处，并通过基准测试突出其性能优势和广泛适用性。", "conclusion": "Faiss库通过其高效的向量相似性搜索机制和创新的设计原则，展示了在AI应用中处理大规模嵌入向量的潜力。通过基准测试和几个应用示例，进一步证明了其在实际场景中的广泛适用性和优越性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.15172", "html_url": "https://arxiv.org/abs/2408.15172", "title": "X-Reflect: 跨反射提示以增强多模态推荐", "title_en": "X-Reflect: Cross-Reflection Prompting for Multimodal Recommendation", "authors": "Hanjia Lyu,Ryan Rossi,Xiang Chen,Md Mehrab Tanjim,Stefano Petrangeli,Somdeb Sarkhel,Jiebo Luo", "background": "大型语言模型（LLMs）已被证明能够通过丰富商品描述来提升推荐系统的准确率，但大多数现有方法要么仅依赖文本提示，要么采用基础的多模态策略，并未充分利用文本与视觉模态间的互补信息。已有研究通常是基于文本或者简单的结合图片与文本的方法，未能充分利用两种模态间的信息优势。因此，需要一种新的方法来实现文本与视觉信息的有效整合。", "innovation": "本文提出了一种名为X-Reflect的新型框架，名为跨反射提示（Cross-Reflection Prompting），该框架能够促进多模态大型语言模型（MLLMs）明确识别和解决文本和图像间的支持性与冲突性信息，从而生成更具综合性和上下文丰富度的商品表示。此外，该工作还提出了X-Reflect-keyword作为一种轻量级变体，通过使用关键词总结图像内容，并用较小的基础模型替代基模型，大幅减少了输入长度，同时保持了与基模型相近的性能。这进一步突显了跨反射提示在提高多模态理解方面的有效性，并证明了在多模态推荐系统中整合多模态信息的重要性。", "conclusion": "通过广泛实验，证明了该方法在下游推荐准确性上优于现有的提示基线方法。并且揭示了文本-图像不一致性与推荐性能之间存在U型关系，强调了适配性多模态提示的好处。X-Reflect和X-Reflect-keyword为提高多模态推荐系统中物品理解提供了有效途径。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.12441", "html_url": "https://arxiv.org/abs/2410.12441", "title": "使用输入凸神经网络正则化的图像重建的原始对偶算法", "title_en": "A primal-dual algorithm for image reconstruction with input-convex neural network regularizers", "authors": "Matthias J. Ehrhardt,Subhadip Mukherjee,Hok Shing Wong", "background": "本文探讨了在数据驱动的变分重建框架中优化问题，其中正则化器由输入凸神经网络（ICNN）参数化。梯度基方法虽然常用于解决这类问题，但在处理非光滑问题时效果差，导致收敛缓慢。此外，神经网络的嵌套结构使应用标准的非光滑优化技术（如邻近算法）变得复杂。为了克服这些挑战，文章重新表述了问题，消除了网络的嵌套结构。通过将该重新表述与激活函数的无界投影相关联，将问题转换为可以通过原始对偶算法高效求解的凸优化问题。文章还证明了这种重新表述等价于原始的变分问题。实验表明，所提出的方法不仅在平滑设置中优于次梯度方法和加速方法，而且有利于正则化的训练。", "innovation": "提出了将问题转换为凸优化问题的方法，使用输入凸神经网络正则化，并通过原始对偶算法解决。这种方法解决了非光滑问题的处理和嵌套神经网络结构复杂的问题。通过理论证明，该方法等价于原始的变分问题。实验证明了新的算法在重建图像时的有效性和优越性。", "conclusion": "本文的方法不仅在非光滑问题中超越了次梯度方法和加速方法，还在重建图像时提升了正则化的训练效率。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12801", "html_url": "https://arxiv.org/abs/2504.12801", "title": "从零开始的稀疏训练重新参数化：Sign-In", "title_en": "Sign-In to the Lottery: Reparameterizing Sparse Training From Scratch", "authors": "Advait Gadhikar,Tom Jacobs,Chao Zhou,Rebekka Burkholz", "background": "从零开始（PaI）训练稀疏神经网络与密致到稀疏（dense-to-sparse）训练之间的性能差距成为高效深度学习的一个主要障碍。根据Lottery Ticket假设，PaI依赖于找到特定问题的参数初始化。然而，正确的参数符号对于PaI来说仍然难以确定。为了克服这一问题，提出了Sign-In方法，该方法采用一种动态重新参数化，能够证明地引发符号翻转，进而与密致到稀疏训练中的符号翻转互补，使其成为一种正交方法。实验和理论表明，这种方法可能带来PaI性能的提升，但也揭示了缩小PaI与密致到稀疏训练之间差距的主要开放挑战。", "innovation": "提出了Sign-In方法，采用动态重新参数化技术，确保能够引发符号翻转，提高了从零开始训练稀疏网络的性能，使其成为一种与密致到稀疏训练互补的方法，从而解决了从零开始训练稀疏网络的难问题。", "conclusion": "虽然实验和理论表明Sign-In方法能够提升从零开始训练稀疏网络的性能，但仍需要解决如何在不同情况下实现这一性能提升的主要挑战。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.18458", "html_url": "https://arxiv.org/abs/2504.18458", "title": "FAST-GRPO：大型视觉语言模型推理中的快速-缓慢思考GRPO", "title_en": "Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning", "authors": "Wenyi Xiao,Leilei Gan", "background": "在应用增强学习来处理大型视觉语言模型的推理任务时，通常通过GRPO方法，难以有效扩展推理的长度或产生冗余输出。尽管仅有些许准确性的提升，还存在跨所有任务范围的性能问题。", "innovation": "提出了一种名为FAST-GRPO的新方法，这是GRPO的一种变体。FAST-GRPO能够根据问题特性动态调整推理深度。通过其实验，研究发现快速-缓慢思考在大型视觉语言模型中具有可行性，并通过引入适应长度的奖励机制和难度感知的KL散度，优化了算法。", "conclusion": "在七个推理基准测试中，FAST方法不仅在准确率上达到了最先进的水平，提升了超过10%，而且在与先前缓慢思考方法相比时，减少了32.7%-67.3%的token使用量，这一结果有效地平衡了推理长度和准确性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.13837", "html_url": "https://arxiv.org/abs/2504.13837", "title": "强化学习真的能够激励超出基模型的LLMs推理能力吗？", "title_en": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?", "authors": "Yang Yue,Zhiqi Chen,Rui Lu,Andrew Zhao,Zhaokai Wang,Yang Yue,Shiji Song,Gao Huang", "background": "最近的研究表明，强化学习的可验证奖励（RLVR）在提升大型语言模型（LLMs）的推理能力方面取得了显著成效，尤其是在数学和编程任务上。RLVR被认为能够让LLMs不断自适应和提高，从而超越其基模型的能力。然而，目前的研究并没有系统地探索RLVR训练后的LLMs在不同模型家族、不同强化学习算法以及数学、编程和视觉推理基准上的推理能力边界。", "innovation": "本文通过系统性地评估不同模型家族、不同强化学习算法以及数学、编程和视觉推理基准下的RLVR训练后的LLMs的推理能力边界，使用较大的k值的通过率作为评估指标，发现当前的训练设置未能激发出新的推理模式。此外，研究还发现蒸馏能够引入新的推理模式，真正扩展模型的推理能力。", "conclusion": "研究结果表明，现有的RLVR方法尚未充分发挥强化学习在激发新型推理能力方面的潜力。这表明需要改进的强化学习范式，如持续扩展和多轮代理人-环境交互，以解锁这一潜力。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.10779", "html_url": "https://arxiv.org/abs/2510.10779", "title": "从3D CT扫描中多标签异常分析的结构化谱图表示学习", "title_en": "Structured Spectral Graph Representation Learning for Multi-label Abnormality Analysis from 3D CT Scans", "authors": "Theo Di Piazza,Carole Lazarus,Olivier Nempont,Loic Boussel", "background": "随着CT检查量的增长，临床放射科医生的工作负担日益增加，对自动工具（如器官分割、异常检测和报告生成）的需求也随之增长。从复杂空间关系中检测全3D胸部CT扫描中的多种异常仍然是一个至关重要的且具有挑战性的问题。现有的基于3D卷积神经网络的方法难以捕捉远程依赖性，而视觉变压器通常需要在大规模且特定领域的数据集上进行大量的预训练才能表现出色。因此，开发一种更为高效的3D CT异常检测框架变得尤为重要。该研究针对此背景提出了一个基于图的新框架，通过轴向切片三重结构化图来解析3D CT体积，并通过谱图卷积对节点进行处理，从而更好地捕捉结构化信息。这种方法已在三个独立机构的数据集上进行了验证，表现出良好的跨数据集泛化能力，并且在与最新视觉编码器的性能上具有可竞争性。", "innovation": "该研究提出了一种2.5D的创新策略，通过将3D CT数据表示为结构化的图，其中轴向切片三重作为节点在谱图卷积中进行处理，以处理复杂的体数据中的空间依赖关系。这种图形化的谱表示学习方法展示了与先进的视觉编码器相当的性能，并且通过多种聚合策略、边权重方案和图连接模式的消融研究，进一步评估了其有效性。同时，还展示了该框架在自动放射学报告生成和腹部CT数据中的广泛应用潜力。", "conclusion": "研究方法在3个独立机构提供的数据集上表现出良好的跨数据集泛化能力，并且在多种聚合策略、边权重方案和图连接模式下证明了其竞争力。此外，该方法还通过自动放射学报告生成和腹部CT数据的应用证明了其广泛的适用性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.09630", "html_url": "https://arxiv.org/abs/2505.09630", "title": "生成扩散模型代理用于机制性代理生物模型", "title_en": "Generative diffusion model surrogates for mechanistic agent-based biological models", "authors": "Tien Comlekoglu,J. Quetzalcoatl Toledo-Marín,Douglas W. DeSimone,Shayn M. Peirce,Geoffrey Fox,James A. Glazier", "background": "机制性多细胞代理模型通常用于在单细胞分辨率下研究组织、器官和有机体规模的生物学。细胞Potts模型（CPM）是一个强大的框架，用于开发和探索这些模型。然而，当空间和时间尺度增大时，CPM变得计算成本昂贵，使得模型的应用和探索变得困难。因为这些模型具有随机性，不同的参数设置可能会产生不同的模型配置，这使得代理模型的开发变得复杂。", "innovation": "本文使用去噪扩散概率模型（DDPM）训练一个生成式AI代理模型的CPM，该代理模型用于研究体外血管生成。我们利用图像分类器学习定义二维参数空间中独特区域的特征，并将其应用于辅助代理模型的选择和验证。该代理模型可提前生成20000个时间步长的模型配置，并且与本地代码执行相比，计算时间大约减少了22倍。这项工作代表了使用DDPM开发随机生物系统的数字双胞胎的一个步骤。", "conclusion": "我们的研究为使用DDPM开发随机生物系统的数字双胞胎迈进了一大步。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19678", "html_url": "https://arxiv.org/abs/2505.19678", "title": "通过视觉进行语言接地：一种降低LVLMs幻觉的条件互信息校准解码策略", "title_en": "Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs", "authors": "Hao Fang,Changle Zhou,Jiawei Kong,Kuofeng Gao,Bin Chen,Shu-Tao Xia", "background": "大型视觉-语言模型（LVLMs）容易出现幻觉现象，生成的响应虽然在语义上可能合理，但与输入图像几乎没有或几乎没有相关性。先前的研究表明，这一问题主要源于LVLMs过度依赖语言先验，而忽视解码过程中的视觉信息。", "innovation": "本文引入了一种新颖的条件点互信息（C-PMI）校准解码策略，该策略能够自适应地增强生成文本与输入图像之间的相互依赖性，从而减轻幻觉现象。区别于现有的仅专注于文本单元采样的方法，我们提出了一种联合建模视觉和文本单元对C-PMI贡献的做法，将幻觉缓解建模为一个两级优化问题，旨在最大化互信息。为此，我们设计了一种令牌净化机制，通过动态调节解码过程来采样与给定图像最大化相关的文本单元，同时进一步优化与生成响应最相关的图像单元。", "conclusion": "通过在各种基准上的广泛实验，该方法能够显著减少LVLMs中的幻觉现象，同时保持解码效率。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16349", "html_url": "https://arxiv.org/abs/2506.16349", "title": "自回归图像生成的水印技术", "title_en": "Watermarking Autoregressive Image Generation", "authors": "Nikola Jovanović,Ismail Labiad,Tomáš Souček,Martin Vechev,Pierre Fernandez", "background": "生成模型的输出水印化已成为追踪其来源的一种有前途的方法。尽管自回归图像生成模型因其潜在的误用而引起了显著的兴趣，但之前的研究没有尝试在令牌级别对这些模型的输出进行水印化。", "innovation": "本文通过将语言模型的水印技术应用到该领域，首次提出了一种在令牌级别对自回归图像生成模型的输出进行水印化的方法。为解决反向环路一致性（RCC）不足的问题，以及使之不受常见图像变换、神经压缩和删除攻击的影响，作者引入了（i）一种自定义的tokenizer-detokenizer微调过程，以提高RCC，以及（ii）一个互补的水印同步层。", "conclusion": "我们的实验表明，我们的方法能够实现可靠且坚固的水印检测，具有理论支持的p值。相关的代码和模型可在指定的链接中找到。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23751", "html_url": "https://arxiv.org/abs/2505.23751", "title": "REOrdering Patches Improves Vision Models", "title_en": "REOrdering Patches Improves Vision Models", "authors": "Declan Kutscher,David M. Chan,Yutong Bai,Trevor Darrell,Ritwik Gupta", "background": "序列模型如变换器需要输入表示为一维序列。在视觉领域，这通常涉及使用固定行主序（栅格扫描）顺序对图像进行展平。虽然全自注意力是置换不变的，但现代长序列变换器越来越多地依赖于破坏这种不变性的架构性近似，从而对块顺序产生了敏感性。我们表明，在这种情况下，块顺序对模型性能有着显著影响，简单替代如列主序或希尔伯特曲线都能带来显著的准确率提升。", "innovation": "我们提出了一种名为REOrder的两阶段框架，用于发现任务优化的块顺序。首先，通过评估各种块序列的压缩性来推导信息论先验。然后，通过优化Plackett-Luce政策来学习排列策略，并使用REINFORCE进行优化。这种方法可以在组合置换空间中实现高效学习。实验结果显示，REOrder在ImageNet-1K上的Top-1准确率比行主序提高了最多3.01%，在Functional Map of the World上的准确率提高了13.35%。", "conclusion": "我们的方法显著地提高了视觉模型的性能，特别是在块顺序对模型有较大影响的情况下。通过有效的信息论先验和Plackett-Luce策略优化学习，REOrder不仅克服了现有模型对块顺序的敏感性，还提高了模型的准确率。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12944", "html_url": "https://arxiv.org/abs/2505.12944", "title": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs", "title_en": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs", "authors": "Jan Hagnberger,Daniel Musekamp,Mathias Niepert", "background": "在科学和工程学科中，使用密集离散空间求解时间依赖的偏微分方程（PDEs）是一个基本问题，特别是在气候现象建模和流体动力学等领域。然而，在物理空间中直接进行这些计算通常会带来显著的计算成本。为了应对这个问题，已经开发了在压缩潜在空间中工作的神经代理模型。尽管这些方法减少了计算复杂性，但它们通常使用基于变换器的注意力机制来处理非规则采样领域，从而增加了内存消耗。相比之下，卷积神经网络能够实现内存高效的编码和解码，但它们仅适用于规则的离散化。", "innovation": "我们提出了CALM-PDE模型类，该模型类能够在压缩潜在空间中有效地求解任意离散化的PDEs。CALM-PDE引入了一个创新的基于连续卷积的编码-解码架构，该架构使用受epsilon-邻域约束的核，能够学习将卷积操作应用到自适应和优化的查询点上。该方法在各种具有规则和非规则空间采样的PDEs中显示了有效性，与现有的基线方法相比，CALM-PDE在内存和推断时间效率方面表现出明显改进，优于基于变换器的方法。", "conclusion": "我们证明了CALM-PDE在解决时间依赖的PDEs方面具有竞争力或更能效，同时减少了内存和推理时间消耗。这一模型类能够有效地在压缩潜在空间中处理任意离散化的PDEs。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07800", "html_url": "https://arxiv.org/abs/2507.07800", "title": "一种用于显微镜图像中微管噪声自适应和稳健分割的新注意力机制", "title_en": "A novel attention mechanism for noise-adaptive and robust segmentation of microtubules in microscopy images", "authors": "Achraf Ait Laydi,Louis Cueff,Mewen Crespo,Yousef El Mourabit,Hélène Bouvrais", "background": "在显微镜成像中，细胞骨架纤维束的分割对于理解其细胞功能至关重要，但在密集且复杂的网络中以及在噪声或对比度低的图像条件下，这一任务具有挑战性。虽然深度学习已提升了图像分割性能，但在这些不利条件下，性能往往会下降。此外，准确注释的获取难度大，且存在严重的类别不平衡问题。", "innovation": "提出了一种新型的噪声自适应注意力机制，扩展了Squeeze-and-Excitation (SE)模块，使模型能够动态适应不同的噪声水平。这种适应性SE (ASE)机制被集成到U-Net解码器中，加入了残差编码块，形成一种轻量且强大的模型：ASE_Res_U-Net。还开发了一种合成数据集策略，并使用定制的损失函数和评估指标来缓解类别不平衡和确保公平评估。ASE_Res_U-Net 在合成数据和现实中的噪声图像中有效分割微管，表现优于其精简版本和最新的曲线结构分割方法，同时参数量较少，适用于资源受限环境。此外，该模型在不同条件下也很好地适应了其他曲线结构（如血管和神经纤维）的分割。", "conclusion": "ASE_Res_U-Net在多种显微成像条件下有效分割微管和其他曲线结构，参数量少且适合资源受限环境，并且已将原始微管数据集（合成和现实噪声图像）发布在Zenodo上，ASE_Res_U-Net模型将在发表后共享。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19861", "html_url": "https://arxiv.org/abs/2510.19861", "title": "一些注意力就足够用于检索", "title_en": "Some Attention is All You Need for Retrieval", "authors": "Felix Michalak,Steven Abreu", "background": "探讨了混合结构的SSM-Transformer架构中注意力机制的作用，以及这些架构中的特定模块（如自注意力层和SSM层）在检索任务中的功能隔离。", "innovation": "证明了在混合SSM-Transformer架构中，检索功能完全依赖于自注意力层，而注意力机制的移除会导致检索失败。同时，通过稀疏化注意力机制，能够在保持较高性能的同时维持检索功能。", "conclusion": "识别出检索任务中精确的机械要求：针式令牌必须在生成过程中被暴露，且生成前必须有足够的上下文。这表明这些模型可能作为专门化模块而不是集成系统运作，这对架构优化和可解释性有直接的指导意义。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.19634", "html_url": "https://arxiv.org/abs/2507.19634", "title": "MCIF: 多模态跨语言指令跟随基准数据集来自科学演讲", "title_en": "MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks", "authors": "Sara Papi,Maike Züfle,Marco Gaido,Beatrice Savoldi,Danni Liu,Ioannis Douros,Luisa Bentivogli,Jan Niehues", "background": "近期的大规模语言模型推动了多模态LLM（MLLMs）的发展，这些模型将文本、语音和视觉信息整合到统一的框架中。随着MLLMs从窄范式、单一语言、特定任务系统进化到通用指导遵循模型，评估其跨语言和多模态能力在短语和长句上下文中的表现成为了关键领域。然而，现有的基准测试无法全面评估这些方面：它们大多局限于英语，主要关注单一模态，依靠简短的语境，或缺乏人工注释，这阻碍了对模型在语言、模态和任务复杂性方面的综合评估。", "innovation": "本文介绍了MCIF（多模态跨语言指令跟随），这是首个基于科学演讲的多语言人类注释基准数据集。MCIF旨在评估在跨语言和多模态环境中的指导遵循能力，涉及三种核心模态（语音、视觉和文本）以及四个多样化的语言（英语、德语、意大利语和中文），从而全面测试MLLMs解释跨语言指令并结合多模态上下文信息的能力。MCIF以CC-BY 4.0许可发布，以促进对MLLMs发展的开放研究和进展。", "conclusion": "MCIF通过多模态科学演讲提供了一个多功能的测试环境，不仅评估跨语言能力，还检验多模态处理和长句/短句处理能力，促进MLLMs发展方向的研究与进步。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15958", "html_url": "https://arxiv.org/abs/2507.15958", "title": "针对资源受限设备的量化感知神经形态架构以实现高效皮肤疾病分类", "title_en": "Quantization-Aware Neuromorphic Architecture for Efficient Skin Disease Classification on Resource-Constrained Devices", "authors": "Haitian Wang,Xinyu Wang,Yiren Wang,Zichen Geng,Xian Zhang,Yu Zhang,Bo Miao", "background": "在边缘设备上实现准确且高效的皮肤病变分类对于可访问的皮肤科护理至关重要，但由于计算、能源和隐私限制，这一点仍然具有挑战性。HAM10000基准数据集和一个实际临床数据集的评估显示，现有的基于卷积神经网络（CNN）到神经形态神经网络（SNN）的模型在公平比较下仍难以达到预期效果。QANA架构在减轻这些限制方面展现出潜力。", "innovation": "QANA引入了一种新的量化感知神经形态架构，用于资源受限硬件上增量皮肤病变分类。它有效地结合了幽灵模块、高效的通道注意和挤压-激励块，以实现低延迟和能源高效推理的同时，鲁棒地表示特征。QANA的量化感知头部和尖脉冲兼容变换使其能够无缝转换为SNN并在神经形态平台上部署。QANA在HAM10000基准数据集和临床数据集上的评估表明，其在HAM10000上取得了91.6%的Top-1精度和82.4%的宏F1分数，临床数据集上为90.8%/81.7%，明显优于现有的CNN-to-SNN模型。", "conclusion": "QANA在BrainChip Akida硬件上的部署实现了1.5毫秒的推理延迟和1.7mJ/图像的能耗，与基于GPU的CNN相比，推理延迟和能耗分别降低了94.6%/98.6%，超过了最先进的CNN-to-SNN转换基准。这些结果表明，QANA对于边缘环境中的准确、实时和隐私敏感的医疗分析是有效的。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19755", "html_url": "https://arxiv.org/abs/2510.19755", "title": "扩散模型中缓存方法的综述：迈向高效多模态生成", "title_en": "A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation", "authors": "Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang", "background": "扩散模型因其出色的生成质量和可控性已成为现代生成AI的基石。然而，它们固有的多步迭代和复杂的骨干网络导致计算开销和生成延迟显著增大，成为实时应用的重大瓶颈。尽管现有的加速技术有所进展，但仍然面临适用性有限、训练成本高或质量下降等问题。", "innovation": "扩散缓存提出了一种无需训练、架构通用且高效的推理范式。其核心机制在于识别和重用扩散过程中固有的计算冗余。通过在特征级别重用跨步骤和跨层调度计算，它能在不修改模型参数的情况下减少计算量。该研究系统性地回顾了扩散缓存的理论基础及其演化，并提出了统一分类和分析框架。研究表明，扩散缓存从静态重用发展到动态预测，增强了其在多种任务中的灵活性，并允许与其他加速技术如采样优化和模型蒸馏相结合，促进了一致、高效的推理框架的发展。", "conclusion": "我们认为这种范式将成为实时和高效生成AI的关键推动力，为高效生成智能的理论和实践注入新的活力。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19351", "html_url": "https://arxiv.org/abs/2510.19351", "title": "利用有限示范学习向人群推迟决策", "title_en": "Learning To Defer To A Population With Limited Demonstrations", "authors": "Nilesh Ramgolam,Gustavo Carneiro,Hsiang-Ting Chen", "background": "本文探讨了学习延迟（L2D）系统在实际部署中因数据稀缺性所面临的瓶颈问题。现有的L2D系统通常依赖于大量标注数据进行训练，这在实际应用中往往是不可行的，尤其是在需要人们做决策的场景中。", "innovation": "本文提出了一种基于元学习的上下文感知半监督框架，能够从少量示范中生成专家特定的嵌入表示。该框架采用双重机制：首先使用这些嵌入生成大规模的伪标签用于训练，随后在测试时能够快速适应新的专家。实验结果在三个不同的数据集上验证了这种方法的数据效率，模型能在训练中快速接近理想水平。为此，该工作解决了L2D系统训练中的关键问题，使其更具实用性和可扩展性，为实际环境中的人类-AI合作提供了可能。", "conclusion": "通过解决训练中的关键瓶颈，本文使得适应性L2D系统更加实用和可扩展，为实际环境的人机协作奠定了基础。为了方便研究的可复制性并提供更详细的实现细节，作者已将源代码和训练配置发布在提供的链接中。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19872", "html_url": "https://arxiv.org/abs/2510.19872", "title": "深Q网络中集成神经架构搜索的方法", "title_en": "An Integrated Approach to Neural Architecture Search for Deep Q-Networks", "authors": "Iman Rahmani,Saman Yazdannik,Morteza Tayefi,Jafar Roshanian", "background": "深度强化学习代理的性能受到其神经网络架构的限制，传统的选择通常是通过昂贵的超参数搜索来确定，但在训练过程中保持固定。本文探讨了在线自适应架构优化是否能够克服这种限制，并超越静态设计。", "innovation": "提出了NAS-DQN，该代理将学习的神经架构搜索控制器直接集成到DRL训练循环中，根据累积性能反馈动态重新配置网络。与固定架构基线、随机搜索控制以及在一个连续控制任务中的实验表明，NAS-DQN在最终性能、样本效率和策略稳定性方面表现出色，同时几乎没有计算开销。", "conclusion": "研究结果表明，NAS-DQN的自学习搜索策略显著优于无向随机架构探索和不恰当的固定设计，表明智能、性能导向的搜索是取得成功的关键机制。研究发现，架构的自适应调整不仅是有益的，而且对于在线深度强化学习中的最佳样本效率是必要的。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19889", "html_url": "https://arxiv.org/abs/2510.19889", "title": "从优化到预测：基于Transformer的道路流量估计方法解决交通分配问题", "title_en": "From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem", "authors": "Mostafa Ameli,Van Anh Le,Sulthana Shams,Alexander Skabardonis", "background": "交通分配问题对于交通流分析至关重要，通常使用数学规划方法在均衡原则下解决。然而，当网络规模增大时，OD对的数量呈非线性增长，导致这些方法在计算上变得不可行。", "innovation": "本研究引入了一种新颖的数据驱动方法，利用深度神经网络，特别是Transformer架构，直接预测均衡路径流量。与传统的链路级方法相比，该模型在路径级交通分布上具有更强的细节捕捉能力，适应需求和网络结构的变化无需重新计算，同时大幅减少计算时间，支持交通管理和快速'假设情景'分析，以优化交通规划和政策制定。", "conclusion": "实验结果表明，所提出的模型比传统优化方法快了几个数量级，能够高效地估计多类网络中的路径级交通流，并通过捕捉详细的出行和流量信息，降低成本和提高预测准确性。此外，模型能够灵活适应需求和网络条件的变化，支持交通管理和快速的情景分析，以增强交通规划和政策制定。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19893", "html_url": "https://arxiv.org/abs/2510.19893", "title": "FairGRPO: 公平的强化学习在临床推理中的应用", "title_en": "FairGRPO: Fair Reinforcement Learning for Equitable Clinical Reasoning", "authors": "Shiqi Dai,Wei Dai,Jiaee Cheong,Paul Pu Liang", "background": "医学人工智能系统在诊断方面取得了显著的成就，但在不同的人口群体中表现出性能差异，给少数群体带来了实际的伤害。虽然多模态推理基础模型通过整合多种医学数据提高了临床诊断能力，但它们往往继承并加剧了训练数据集中的偏差，这些训练数据集主要由多数群体主导。因此，需要一种方法来促进临床多样群体之间的公平学习。", "innovation": "本文引入了一种层次化的强化学习方法FairGRPO，旨在通过可调整的重要性加权，依据表示、任务难度和数据来源促进不均一的临床群体之间的公平学习。此外，该方法通过无监督聚类自动发现隐蔽的人口群体，不受标签限制。实验结果表明，FairGRPO在所有原始和偏见缓解的RL基线上降低了预测平等性27.2%，同时提高了F1分值12.49%，并且训练动力学分析显示，FairGRPO在整个优化过程中逐步提高了公平性，而基线方法的公平性则随着训练的进行而逐步下降。", "conclusion": "FairGRPO能够通过多种临床诊断数据集（包括X射线、CT扫描、皮肤镜检查、乳腺X线摄影和超声）大幅减少不同人群间的差异，并在公平意识的临床VLLM上达到了行业领先表现。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19934", "html_url": "https://arxiv.org/abs/2510.19934", "title": "利用f-差异隐私缓解去中心化联邦学习中的隐私-实用性权衡", "title_en": "Mitigating Privacy-Utility Trade-off in Decentralized Federated Learning via $f$-Differential Privacy", "authors": "Xiang Li,Buxin Su,Chendi Wang,Qi Long,Weijie J. Su", "background": "不同的去中心化联邦学习（FL）算法因其复杂的组件，如去中心化通信和本地更新，导致精确计算其隐私预算颇具挑战性。本文在$f$-差异隐私（$f$-DP）框架下，探讨了两个去中心化FL算法的隐私管理问题。", "innovation": "开发了两种新的$f$-DP基的隐私账表方法，适应于去中心化场景：通过随机游走通信量化用户对之间的隐私泄露的Pairwise Network $f$-DP（PN-$f$-DP），以及通过共享密钥支持结构化噪声注入的Secret-based $f$-Local DP（Sec-$f$-LDP）。利用$f$-DP理论和马尔可夫链集中理论，该账表框架能够捕捉稀疏通信、本地迭代和相关噪声带来的隐私放大效应。实验结果表明，与Rényi DP方法相比，本文方法能提供更紧的$(ε,δ)$界，并且改善了实用性。", "conclusion": "本文方法基于$f$-DP展示了去中心化的隐私会计优势，并通过合成和真实数据集上的实验验证了紧约束和改进的实用性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19950", "html_url": "https://arxiv.org/abs/2510.19950", "title": "在金融领域中的稳健强化学习：使用椭圆不确定性集建模市场影响", "title_en": "Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets", "authors": "Shaocong Ma,Heng Huang", "background": "在金融应用中，强化学习（RL）代理通常在历史数据上进行训练，此时它们的行为不会影响价格。但在部署时，这些代理会在实时市场进行交易，它们的交易会改变资产价格，称为市场影响。这种训练环境与部署环境之间的不匹配会显著降低性能。传统的稳健RL方法通过在不确定性集合中优化最坏情况性能来解决模型不匹配，但通常依赖于对称结构，无法捕捉市场影响的方向性。", "innovation": "作者开发了一种新的椭圆不确定性集类，能够为这些集合下的最坏情况不确定性提供隐式和显式的闭形式解，从而能够高效且可处理地进行稳健策略评估。实验表明，该方法在单个资产和多个资产交易任务中实现了更高的夏普比率，并在交易量增加时仍然维持稳健性，提供了一种更忠实且可扩展的方法来处理金融市场的RL。", "conclusion": "该研究通过引入椭圆不确定性集，针对传统RL方法在处理市场影响方向性上的不足，提出了一种新的解决方案，并通过实验验证了其在金融交易任务中的有效性和稳健性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19953", "html_url": "https://arxiv.org/abs/2510.19953", "title": "关于零阶优化中无偏梯度估计器的最优构造", "title_en": "On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization", "authors": "Shaocong Ma,Heng Huang", "background": "零阶优化（ZOO）是用于梯度不可用或计算昂贵的随机优化的重要框架。现有的ZOO方法可能存在由于梯度估计器的偏差而在扰动步长不为零时不可避免的偏差问题。", "innovation": "本文提出了基于函数评估的无偏梯度估计器的新家族。通过将方向导数重新形式化为级数形式并从精心设计的分布中取样，本文构建了去除偏差的同时保持有利方差的估计器。此外，本文分析了它们的理论属性，推导了四种特定构造的最优缩放分布和扰动步骤，并证明使用所提议估计器的SGD可以达到光滑非凸目标的最优复杂度。", "conclusion": "实验表明，相比于标准方法，本文的方法在合成任务和语言模型微调中具有更高的准确性和收敛性。"}
{"llm_update_time": "20251026", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.25271", "html_url": "https://arxiv.org/abs/2509.25271", "title": "RADAR: 一种基于角色专业化协作的风险感知动态多智能体框架，用于大型语言模型的安全评估", "title_en": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "authors": "Xiuyuan Chen,Jian Zhao,Yuchen Yuan,Tianle Zhang,Huilin Zhou,Zheng Zhu,Ping Hu,Linghe Kong,Chi Zhang,Weiran Huang,Xuelong Li", "background": "现有的大型语言模型（LLMs）的安全评估方法存在内在局限性，如评估者偏见和由模型同质性引起的检测失败，这些都共同削弱了风险评估过程的可靠性。", "innovation": "本文通过引入一种理论框架重新审视风险评估范式，该框架将潜在的风险概念空间分解为三个互斥子空间：显式风险子空间（涵盖直接违反安全准则的违规行为）、隐式风险子空间（捕获需要上下文推理才能识别的潜在恶意内容）以及非风险子空间，同时提出了一种称为RADAR的多智能体协作评估框架，该框架通过四方专攻角色实现多轮辩论机制，利用动态更新机制实现风险概念分布的自我进化。这一方法能够在不减轻评估者偏见的情况下全面覆盖显式和隐式风险，通过构建包含800个具有挑战性案例的评估数据集进行了验证。结果表明，RADAR在准确度、稳定性和自我评估风险敏感性等多个维度上显著优于基线评估方法，尤其在风险识别准确性方面提高28.87%。", "conclusion": "RADAR评估框架在覆盖隐式和显式风险方面具有显著优势，并能有效减轻评估者偏见，展示了显著的效能提升。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19873", "html_url": "https://arxiv.org/abs/2510.19873", "title": "从小到大：通过推理图转移CUDA优化专长", "title_en": "From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph", "authors": "Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li", "background": "尽管CUDA编程和领域特定库有了显著的发展，但有效地利用具有大规模并行引擎的GPU仍然具有挑战性。大型语言模型（LLMs）显示出从顺序代码生成优化CUDA代码的潜力，但实际使用LLMs存在两大挑战：云API可能造成的代码泄露风险，以及本地部署的计算成本和效率低下。这些缺点促使研究转向小型语言模型（SLMs），SLMs更轻量级且更具隐私保护性。尽管SLMs在特定任务上可以达到与LLMs相当的性能，但在我们实验中，它们在CUDA生成中的有限推理能力导致了复杂任务下的表现不佳。为了弥合这一差距，我们提出了ReGraphT框架，这是一种无需训练的、基于检索增强的生成框架，将LLM级别的推理能力转移给小型模型。ReGraphT将CUDA优化路径组织成一个结构化的推理图，并通过蒙特卡洛图搜索（MCGS）进行高效的探索。我们还提出了一个针对CUDA的性能评估基准，定义了基于推理复杂性的难度层级，以更全面地评估模型。", "innovation": "我们提出了ReGraphT框架，这是一种无需训练、基于检索增强的生成框架，通过将大型语言模型级别的推理能力转移到小型模型来弥合小型模型在复杂CUDA生成中的表现差距。ReGraphT通过将CUDA优化路径组织成一个结构化的推理图，并借助蒙特卡洛图搜索（MCGS）进行有效的探索来增强小型模型的性能。我们提出了一个针对CUDA的性能评估基准，定义了基于推理复杂性的难度层级，以评估模型的性能。实验表明，ReGraphT在CUDAEval和ParEval上实现了平均2.33倍的加速，并使得小型模型能够接近大型语言模型的表现，而无需承担相关的隐私风险或过高的计算开销。", "conclusion": "实验结果显示，ReGraphT在CUDAEval和ParEval上的平均加速比为2.33倍，能够使小型语言模型（SLMs）在不牺牲隐私性和计算开销的前提下接近大型语言模型的表现。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19975", "html_url": "https://arxiv.org/abs/2510.19975", "title": "重新审视零阶优化：最小方差两点估计和方向对齐扰动", "title_en": "Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations", "authors": "Shaocong Ma,Heng Huang", "background": "现有研究主要关注固定长度的扰动，而忽略了方向对齐的优势。本文探讨了两点零阶梯度估计器，并确定了随着扰动步长趋近于零时可以最小化估计器渐进方差的随机扰动分布。通过理论和实验分析，揭示了这种期望扰动可以在方向上与真实梯度对齐，而不仅仅是保持固定长度。", "innovation": "作者将问题表述为约束功能性优化问题，研究方向对齐扰动（DAP）方案的理论和实验性质，该方案能够自适应地在关键方向上提供更高的准确性。此外，作者还对使用 δ-无偏随机扰动的随机梯度下降进行收敛性分析，并将现有的复杂性界扩展到更广泛的扰动。", "conclusion": "通过在合成问题和实际任务上的实验评估，作者证明了 DAPs 在特定条件下能够优于传统方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19896", "html_url": "https://arxiv.org/abs/2510.19896", "title": "通过可解释的SHAP引导特征选择和分类提高泌尿系统疾病诊断准确性", "title_en": "Enhancing Diagnostic Accuracy for Urinary Tract Disease through Explainable SHAP-Guided Feature Selection and Classification", "authors": "Filipe Ferreira de Oliveira,Matheus Becali Rocha,Renato A. Krohling", "background": "该研究旨在提高泌尿系统疾病（特别是膀胱癌）的诊断准确性。研究采用了基于SHAP（SHapley Additive exPlanations）的特征选择方法，以提高预测模型的透明度和有效性。研究者构建了六个二元分类场景来区分膀胱癌与其他泌尿系统和肿瘤学疾病的诊断。研究还应用了XGBoost、LightGBM和CatBoost这三种算法，并通过Optuna进行了超参数优化，同时使用SMOTE技术进行类别平衡。这种方法旨在提高诊断性能指标，如平衡准确率、精确率和特异性，确保在可解释性提高的前提下，不降低或甚至提高模型性能。", "innovation": "研究提出了通过SHAP引导的特征选择与分类方法来提升泌尿系统疾病诊断的准确性。具体创新点在于，采用解释性技术（SHAP）进行特征选择，并利用该技术指导特征选择，同时结合优化的机器学习算法和类别平衡技术，以构建清晰且可靠的临床决策支持系统，从而优化泌尿系统疾病的筛查与早期诊断过程。", "conclusion": "该方法对于增强临床决策支持系统，提高泌尿系统疾病诊断透明度和效率具有重要意义。通过增强解释性特征选择和分类，本研究为泌尿系统疾病的早期筛查和诊断提供了一种有潜力的有效途径。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19941", "html_url": "https://arxiv.org/abs/2510.19941", "title": "贪婪任务排序在持续线性回归中的优越性研究", "title_en": "Are Greedy Task Orderings Better Than Random in Continual Linear Regression?", "authors": "Matan Tsipory,Ran Levinstein,Itay Evron,Mark Kong,Deanna Needell,Daniel Soudry", "background": "本文分析了持续学习中线性回归任务排序的问题，假设训练数据是联合可实现的。研究集中于能够最大化连续任务之间不相似度的贪婪排序，这是以前工作中简要探讨过的一个概念，但仍然存在很多未解之谜。通过Kaczmarz方法的工具，作者正式化了这些排序，并发展了关于它们的几何和代数直觉。这些排序在实验和理论分析中表现出比随机排序更快的收敛速度。", "innovation": "使用Kaczmarz方法的工具，对贪婪排序进行了正式化，并研究了它们的几何和代数直觉。通过实验证明，贪婪排序在平均损失的收敛速度上优于随机排序。在高秩回归设置中，论文证明了贪婪排序的损失边界类似于随机排序的边界。然而在一般秩下，研究指出了重复的依赖性，证明了单次通过的贪婪排序可能灾难性地失败，而允许重复的贪婪排序的收敛速率为$O(1/\root 3 \from k)$。", "conclusion": "本文揭示了贪婪排序和随机排序之间的细微差异，并证明了在某些情况下，贪婪排序的实际有效性可能不如随机排序。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19977", "html_url": "https://arxiv.org/abs/2510.19977", "title": "向普遍不对称随机化目标的方向强认证防御", "title_en": "Towards Strong Certified Defense with Universal Asymmetric Randomization", "authors": "Hanbin Hong,Ashish Kundu,Ali Payani,Binghui Wang,Yuan Hong", "background": "随机化平滑已经成为在机器学习模型中实现认证对抗鲁棒性的关键方法。然而，当前的方法主要使用各向同性的噪声分布，这种分布会根据所有数据维度（如图像像素）均匀分布噪声，这限制了鲁棒性认证的有效性，因为它们忽视了输入和数据维度的异质性。这导致了对抗攻击的有效性受到限制。", "innovation": "本文提出了一种名为UCAN的新技术，UCAN可以普遍认证对抗鲁棒性，同时使用异质性的噪声分布。UCAN旨在增强任何现有的随机化平滑方法，使其从中对称（各向同性）噪声转换为不对称（各向异性）噪声分布，从而提供对对抗攻击更具针对性的防御。此外，本文开发了一种新的框架，并包含三个噪声参数生成器（NPGs），以针对不同的数据维度优化异质性噪声参数，从而实现鲁棒性的不同增强级别。实验结果表明，在MNIST、CIFAR10和ImageNet数据集上，UCAN在大认证半径下的认证准确率提高了182.6%。", "conclusion": "本文提出了一种新的用于认证对抗鲁棒性的方法UCAN，通过使用异质性的噪声分布提高了鲁棒性认证的有效性。UCAN可以增强现有的随机化平滑方法，并提供针对对抗攻击的精细调整。实验结果表明，UCAN在多个数据集上取得了显著的性能改进。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19980", "html_url": "https://arxiv.org/abs/2510.19980", "title": "Abstain Mask Retain Core: 通过自适应掩码损失和表示一致性进行时间序列预测", "title_en": "Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency", "authors": "Renzhao Liang,Sizhe Xu,Chenggang Xie,Jingru Chen,Feiyang Ren,Shu Yang,Takahiro Yabe", "background": "时间序列预测在能源管理和金融市场等领域至关重要。尽管基于深度学习的方法（如MLP、RNN、Transformer）取得了显著进展，但当前“长期序列信息获取假设”存在固有的局限性。通过系统实验发现，适当裁剪历史数据可能反而能提升预测准确性，这表明现有模型在训练过程中学习到大量冗余特征（如噪声或无关波动），从而影响有效信号提取能力。这一现象挑战了传统的时间序列建模假设，因此需要新的解决方案来优化这一过程。", "innovation": "本文提出了一个名为Adaptive Masking Loss with Representation Consistency (AMRC)的新颖解决方案，它包含两个核心组件：1）动态掩码损失，能够在模型训练过程中自适应地识别出关键的时间段来引导梯度下降；2）表示一致性约束，稳定输入、标签和预测之间的映射关系。实验证明，AMRC能够有效抑制冗余特征学习，同时显著提高模型性能。此研究不仅挑战了时间序列建模的传统假设，还提供了解释性和方法论上的突破，有助于开发更高效和稳健的预测模型。", "conclusion": "AMRC有效抑制了冗余特征学习，显著提高了模型性能。这一研究不仅对时间序列建模的传统假设提出了挑战，还提供了新的理论见解和方法论突破，有助于开发高效和稳健的预测模型。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19933", "html_url": "https://arxiv.org/abs/2510.19933", "title": "超越理想：分析不精确的穆斯翁更新", "title_en": "Beyond the Ideal: Analyzing the Inexact Muon Update", "authors": "Egor Shulgin,Sultan AlRashed,Francesco Orabona,Peter Richtárik", "background": "穆斯翁优化器作为一种强大的、几何感知的替代方案，迅速崛起并展示了在大规模神经网络训练中的强大性能，与AdamW相比。然而，最佳理论与实践之间存在关键断层：穆斯翁的效率依赖于快速的近似正交化，但所有之前的理论工作都集中在一种理想化且计算不可行的版本上，假设使用精确的SVD更新。本文通过提供对穆斯翁核心不精确正交化更新的第一个分析，超越了这种理想化的研究，开发了一个线性最小化或acles (LMO) 基本框架下的分析，并引入了一个现实的增加误差模型来捕捉实际近似方案的不准确性。研究结果量化了性能下降与线性最小化或acles不准确性/误差之间的关系，揭示了不准确性与最优步长和动量之间的基本联系：较低的oracle精度需要较小的步长但较大的动量参数。这些发现将近似程序（例如，牛顿-舒尔茨步骤的数量）从一个实施细节提升为一个重要参数，必须与学习计划一起调整。纳米GPT实验直接证实了预测的联系，最佳学习率随着近似精度的变化而明显改变。", "innovation": "本文首次对穆斯翁核心的不精确正交化更新进行了分析，并提出了一种新的误差模型，以更好地理解和应用这一优化器。研究揭示了不精确性与最优步长和动量之间的关键联系，并将其提升为一个需要与学习计划一起调整的重要参数。这为优化和调整穆斯翁提供了理论基础，能够更好地指导实践中的应用。", "conclusion": "通过提供对不精确的穆斯翁更新的分析，本文填补了理论与实践之间的空白，揭示了不准确性与最优性能参数之间的关系，并提出了新的调优建议。实验证明了理论预测的准确性，证实了最优学习率会随着近似精度的变化而变化。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19990", "html_url": "https://arxiv.org/abs/2510.19990", "title": "不再遗漏计算能力：重新思考掩蔽扩散模型中的推理与采样", "title_en": "No Compute Left Behind: Rethinking Reasoning and Sampling with Masked Diffusion Models", "authors": "Zachary Horvitz,Raghav Singhal,Hao Zou,Carles Domingo-Enrich,Zhou Yu,Rajesh Ranganath,Kathleen McKeown", "background": "现有的掩蔽扩散语言模型（MDLMs）主要用于填充随机遮掩序列中的位置，而不是预测下一个令牌。讨论MDLMs的优势包括任意次序解码和多令牌解码。然而，研究团队发现，对于数学和编程任务，任意次序算法往往表现较差或与自左向右抽样相似，标准的多令牌解码也会显著降低性能。因此，他们提出了一个问题：为什么还需要这种额外的计算量，特别是在自左向右逐个令牌解码与任意次序解码算法效果相当的情况下？", "innovation": "提出了两种创新方法：首先，提出了推理作为一种填充的方法，通过利用MDLMs填充推理模板，可以结构化输出并区分推理令牌和答案令牌，从而在推理过程中测量答案不确定性并提前退出。其次，提出了一种基于条件熵的多令牌解码方法（MED），这种方法可以在并行解码多个位置时减少错误，并且能够在中间步骤评估推理正确性。实验结果显示，在GSM8k数据集上，利用后处理来微调LLaDA-8B Base模型，其表现与基于人类编写推理线索的微调相当，并且步骤数减少了2.7倍。", "conclusion": "本文的研究表明，MDLMs的训练和计算量可以通过多种新的推理和后处理方法解锁潜在价值，这些方法能够在推理和采样方面提高效率和性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20022", "html_url": "https://arxiv.org/abs/2510.20022", "title": "SALT: 基于轨迹图的长周期代理步骤级优势分配", "title_en": "SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph", "authors": "Jiazheng Li,Yawei Wang,David Yan,Yijun Tian,Zhichao Xu,Huan Song,Panpan Xu,Lin Lee Cheong", "background": "大型语言模型（LLMs）已在单轮任务中展现了卓越的能力，但应用于复杂的、多步骤的和长远的任务仍充满挑战。强化学习（RL）为解决这些问题提供了有希望的途径，但主流方法通常仅依赖稀疏的结果奖励，这对缺乏批评模型的群体相关策略优化（GRPO）等群体基RL算法尤为不利。在这些方法中，对轨迹中所有动作进行统一的奖励或处罚可能导致训练不稳定，并产生次优策略，因为有益和有害的动作通常在多步骤互动中混合在一起。", "innovation": "本文提出了SALT，一种新型且轻量级的框架，可以提供更精细的优势分配，仅基于结果奖励。通过构建相同提示下轨迹的图，可以量化每个步骤的质量并相应地分配优势。SALT设计为插件模块，可以无缝集成现有的群体基RL算法，无需修改滚存程序，并引入可忽略的计算开销。在WebShop、ALFWorld和AppWorld基准上的实验表明，SALT在各种模型大小下一致提高了性能。我们还进行了全面的分析以验证SALT设计选择的合理性，并提供了实用见解。", "conclusion": "通过SALT，对群体基RL算法中的长周期代理实现了步骤级别的优势分配，显著提高了性能，证明了SALT的有效性和实用性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20028", "html_url": "https://arxiv.org/abs/2510.20028", "title": "比特币交易的时间图", "title_en": "The Temporal Graph of Bitcoin Transactions", "authors": "Vahid Jalili", "background": "自2009年比特币网络的第一个区块以来，已处理了超过10亿笔交易和超过872亿比特币，这些数据具有丰富的机器学习潜力。然而，由于其基于UTXO的设计导致的匿名性和资金流动的隐蔽性，使得这些数据难以用于机器学习研究。", "innovation": "该研究通过重建资金流动来呈现一个适用于机器学习的图模型，该图模型是比特币经济拓扑的反映。该图包含截至第block \textbackslash cutoffHeight的所有交易历史，具有超过24亿个节点和397亿多条边，并提供定制化的采样方法、特殊的图数据库加载和分析工具以及现成的数据库快照。", "conclusion": "该全面的数据集和工具包赋予了机器学习社区大规模探索比特币复杂生态系统的工具，有助于推动异常检测、地址分类、市场分析和大规模图机器学习基准测试等应用的发展。数据集和代码可在提供的链接中获取。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20031", "html_url": "https://arxiv.org/abs/2510.20031", "title": "推测采样法用于参数化时间点过程", "title_en": "Speculative Sampling for Parametric Temporal Point Processes", "authors": "Marin Biloš,Anderson Schneider,Yuriy Nevmyvaka", "background": "时间点过程是一种强大的生成模型，适用于事件序列，并能捕捉时间序列数据中的复杂依赖关系。通常使用自回归模型来指定这些过程，其中模型从先前事件学习下一个事件的概率分布。这种模型的采样过程是顺序的，这限制了其效率。尤其是在处理大规模时间点过程应用时，这种顺序采样方法效率低下，难以在不修改架构或重新训练的前提下进行并行生成多个未来值的采样。", "innovation": "本文提出了一种基于拒绝采样的新算法，该算法可以在不改变现有模型结构或重新训练的前提下，并行地从现有的时间点过程模型中获取多个未来的值。该方法不仅具有理论上的保证，还在实际数据集上展示了高效的并行生成效果，缩小了表达式建模与大规模环境下的高效并行生成之间的差距。", "conclusion": "该研究提出的方法在保持模型不变的情况下，通过采样算法改进提高了对于大规模时间点过程应用的采样效率，这在实际应用中具有显著的优势。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20019", "html_url": "https://arxiv.org/abs/2510.20019", "title": "基于RSSI决策树和CAD建模的机器学习RFID传感器网络定位精度研究", "title_en": "Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications", "authors": "Curtis Lee Shull,Merrick Green", "background": "RFID跟踪可能是一个有效的解决方案，用于必须按照安全指南储存的防御资产。然而，RFID传感器的不特异性（包括长距离检测、欺骗和伪造）可能导致误检和操作安全事件。本文在CAD模型化楼层计划中模拟了实际的Received Signal Strength Indicator (RSSI)数据，并使用监督学习和决策树分类，以解决防御储存中的部分挑战。该研究主要关注12个实验室区域的分类，旨在实现位置推理。实验中的数据集包含约980,000个条目，数据集类频率不平衡，通过计算类别权重来考虑类别不平衡问题。模型在分层子样本中训练至5,000个平衡观察值，总体准确率为34.2%，多个区域（如区F、G、H等）的F1分数大于0.40。然而，一些稀有类（特别是LabZoneC）经常被误分类，即使使用了类别权重。计算了邻接敏感的混淆矩阵，以便更好地解释物理相邻区的分类情况。这些结果表明，基于RSSI的决策树可以在现实模拟中应用于区级异常检测或错位监控，以改进防御供应链物流的可靠性。通过改进天线位置或增加传感器及与其他模态的传感器融合，可能提高在低覆盖和低信号区的分类性能。", "innovation": "使用监督学习和决策树分类，结合CAD模型和实际的Received Signal Strength Indicator (RSSI)数据，进行了RFID传感器网络定位精度的研究，以解决防御储存中的挑战，特别是对于实验室区域的分类和位置推理。通过这种方法，更好地理解了物理相邻区域的分类情况，并评估了在低覆盖和低信号区的分类性能的优化潜力。", "conclusion": "基于RSSI的决策树可以应用于现实模拟，以实现区级异常检测或错位监控，提高防御供应链物流的可靠性。但是，稀有类别的误分类情况依然存在，需要进一步优化策略以改进分类性能。未来的工作可能需要改进天线位置、增加传感器数量或者与多种模态的传感器融合，以提高在低覆盖和低信号区的分类性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20055", "html_url": "https://arxiv.org/abs/2510.20055", "title": "基于延迟奖励的上下文强化学习方法学习个性化广告影响", "title_en": "Learning Personalized Ad Impact via Contextual Reinforcement Learning under Delayed Rewards", "authors": "Yuwei Cheng,Zifeng Zhao,Haifeng Xu", "background": "在线广告平台使用自动拍卖将广告商与潜在客户连接起来，需要有效的竞标策略来最大化利润。准确的广告影响估计需要考虑三个关键因素：延迟和长期效应、累积广告影响如强化或疲劳，以及客户异质性。然而，这些效应在之前的大多数研究中并未联合处理。为了捕捉这些因素，本文将广告竞标建模为带有延迟泊松奖励的上下文马尔可夫决策过程（CMDP）。为了高效地进行估计，我们提出了一种两阶段的最大似然估计方法结合数据划分策略，确保基于第一阶段估计器（不）准确性的误差控制。在此基础上，我们设计了一种强化学习算法来得出有效的个性化竞标策略。", "innovation": "本文创新性地将广告竞标问题建模为带有延迟奖励的CMDP，提出了基于两阶段最大似然估计和数据划分策略的高效估计方法，并设计了一种强化学习算法来得出有效的个性化竞标策略，实现了接近最优的遗憾上界 $\tilde{O}(dH^2\boldsymbol{\theta}\boldsymbol{T})$，其中 $\theta$ 代表上下文维度，$H$ 代表轮数，$\boldsymbol{T}$ 代表客户数量。", "conclusion": "我们提出的上下文强化学习方法可以有效地估计延迟奖励下的个性化广告影响，理论发现得到了模拟实验的验证。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20084", "html_url": "https://arxiv.org/abs/2510.20084", "title": "ShapeX：基于形状子集的时序分类模型后验解释框架", "title_en": "ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models", "authors": "Bosong Huang,Ming Jin,Yuxuan Liang,Johan Barthelemy,Debo Cheng,Qingsong Wen,Chenghao Liu,Shirui Pan", "background": "解释时序分类模型在高风险应用领域（如医疗和金融）至关重要，因为透明度和信任度在这些领域中起着关键作用。尽管多个时序分类方法已经通过识别形状子集作为关键特征来实现最佳性能，现有的后置解释方法主要关注时间步的特征属性，忽视了分类结果主要由关键形状子集驱动这一重要因素。", "innovation": "提出了一种名为ShapeX的创新框架，该框架将时序按有意义的形状子集驱动段进行切分，并利用Shapley值评估其显著性。核心技术框架是Shapelet Describe-and-Detect (SDD)，能够有效学习对分类至关重要的多样形状子集。研究还显示，ShapeX生成的解释揭示了因果关系，而非仅仅相关性，这是由于形状子集的原子性。", "conclusion": "在合成和真实数据集上的实验结果表明，ShapeX在识别最相关子序列方面优于现有方法，提高了时间序列解释的精度和因果一致性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20066", "html_url": "https://arxiv.org/abs/2510.20066", "title": "预测市场风险的多层机器学习和计量经济学管道：来自加密资产流动性溢出的证据", "title_en": "A Multi-Layer Machine Learning and Econometric Pipeline for Forecasting Market Risk: Evidence from Cryptoasset Liquidity Spillovers", "authors": "Yimeng Qiu,Feihuang Fang", "background": "该研究旨在探讨核心加密资产的流动性与波动性代理是否能够产生预测市场整体风险的溢出效应。研究采用了一系列统计层来分析流动性与收益之间的交互作用、流动性与收益的主要成分关系，以及捕捉横截面波动挤出效应的波动因子投影。并利用向量自回归脉冲响应、预测误差方差分解（Granger 1969；Sims 1980）、外生回归变差自回归模型（HAR-X, Corsi 2009）及可防止信息泄露的机器学习协议来进一步验证和解释模型。数据来源于2021年至2025年（共计74种资产的1462天数据）。", "innovation": "本研究的创新点在于结合了多层统计分析方法（A）流动性与收益间的相互作用、（B）流动性与收益的主要成分关系、（C）捕捉横截面波动挤出效应的波动因子投影，并运用机器学习和计量经济学的综合方法（向量自回归脉冲响应、预测误差方差分解、外生回归变差自回归模型和基于SHAP的解释方法）来分析加密资产的流动性溢出对未来市场风险的预测能力。", "conclusion": "研究发现，尽管不同统计层之间存在显著的Granger因果关系，但预测市场整体风险的能力较为温和。研究结果提供了最具信息量的图表，包括管道概览、A层热力图、C层稳健性分析、向量自回归方差分解和测试集的精确召回曲线。完整数据和图表输出已提供在本地仓库中。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20107", "html_url": "https://arxiv.org/abs/2510.20107", "title": "关于带权重维度的模式分类", "title_en": "On pattern classification with weighted dimensions", "authors": "Ayatullah Faruk Mollah", "background": "在处理多维样本且涉及不同应用场景时，对模式分类的多方面研究往往是必不可少的。在这一过程中，基于维度加权的距离度量方法被视为一种重要考虑，因为它能反映样本间的相似度程度。尽管通常假定使用欧几里得距离就已足够，但实际上仍存在许多问题。因此，本文探讨了不同距离度量范数的影响，以及每个维度的加权方案，并将其整合进KNN分类器中。", "innovation": "本文提出了一个新的维度加权方案，并将其应用于KNN分类器。通过这种维度加权方法，该模型在多种合成和现实数据集上的分类性能优于传统的KNN方法，特别是在基因表达数据集上，无论k值的不同，分类准确率提高了约10%。此方法通过调整包含参考样本区域的形状和大小，优化了最近邻的选择。", "conclusion": "该模型作为一种基于加权Minkowski距离的KNN分类器的扩展形式，为在多维度和多样本类型下的模式分类提供了重要的新方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20106", "html_url": "https://arxiv.org/abs/2510.20106", "title": "竞争是关键：基于博弈论的因果发现方法", "title_en": "Competition is the key: A Game Theoretic Causal Discovery Approach", "authors": "Amartya Roy,Souvik Chakraborty", "background": "因果发现是机器学习中的一个核心挑战。现有的方法存在根本性不足：如GES和GraN-DAG这类算法虽然在实证上表现优秀，但缺乏有限样本保证，而理论上得到证实的方法则无法很好地扩展。", "innovation": "本文通过引入基于博弈论的强化学习框架来解决这一问题，在这个框架中，DDQN代理人直接与强基准（GES或GraN-DAG）竞争，且总是从对手的解决方案开始。该设计提供了三个可证明的保证：学习到的图形从不比对手差，热启动严格加速收敛，最重要的是，以高概率算法选择了真正最佳的图形候选。这项结果在因果发现中实现了首次此类的有限样本保证，展现了新算法与理论的契合。", "conclusion": "这些结果确立了一个新的基于强化学习的因果发现算法类别，同时具有可证明的一致性、样本效率和实际可扩展性，标志着在统一经验性能与严格的有限样本理论方面取得了决定性进展。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20085", "html_url": "https://arxiv.org/abs/2510.20085", "title": "基于MentalRoBERTa的分层双头模型用于自杀风险评估", "title_en": "Hierarchical Dual-Head Model for Suicide Risk Assessment via MentalRoBERTa", "authors": "Chang Yang,Ziyi Wang,Wangfeng Tan,Zhiting Tan,Changrui Ji,Zhiming Zhou", "background": "社交平台已成为识别自杀风险的重要来源，但自动检测系统面临多方面的挑战，如类别不平衡严重、发帖模式的时间复杂性和风险水平的双重性质（既是序数的又是类别的）。现有的方法难以同时应对这些挑战。", "innovation": "该论文提出了一种基于MentalRoBERTa的分层双头神经网络进行自杀风险分类成四个级别：指标、意念、行为和尝试。该模型结合了两种互补的预测头，一个保持风险级别之间序数关系的CORAL头，和一个标准的分类头。此外，通过包含时间间隔嵌入和三层变压器编码器来捕捉发帖行为动态，以及使用一个结合损失函数（0.5 CORAL + 0.3 Cross-Entropy + 0.2 Focal Loss）进行训练，以同时解决序数结构保存、过自信降低和类别不平衡的问题。此外，为提高计算效率，固定了MentalRoBERTa的前6层，并采用混合精度训练。", "conclusion": "该模型通过5折分层交叉验证进行评估，使用宏F1分数为主要指标，结果显示该模型在处理自杀风险自动评估方面具有较好的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20064", "html_url": "https://arxiv.org/abs/2510.20064", "title": "Not-a-Bandit: 在推测性解码中用于大语言模型的可证明无遗憾捎带选择", "title_en": "Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative Decoding for LLMs", "authors": "Hongyi Liu,Jiaji Huang,Zhen Jia,Youngsuk Park,Yu-Xiang Wang", "background": "推测性解码被广泛应用于加速大型语言模型的推理。以往的研究主要集中在选择最佳的预测模型。本文聚焦在推测性解码中的在线草案模型选择问题。", "innovation": "设计了能证明在每一轮查询中与最优后知后觉的草案模型在以令牌接受概率或预期接受长度衡量时具有竞争力的算法。特别地，可以准确评估所有草案模型而不增加查询次数，从而在草案模型数量增加时显著改进现有基于多臂老虎机方法。此外，提出了一种适用于单草案、多草案和草案树的通用方法，并且设计了高效的在线学习版本以减少计算和延迟的开销。", "conclusion": "在开源语言模型和各种数据集上进行了广泛的实验，表明本文方法在需求较长推理链的领域中显著优于最先进的EAGLE3和BanditSpec基线，特别是在有领域专家参与的情况下。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20108", "html_url": "https://arxiv.org/abs/2510.20108", "title": "为什么原型会崩溃：诊断和预防原型自监督学习中的部分崩溃", "title_en": "Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning", "authors": "Gabriel Y. Arteaga,Marius Aasan,Rwiddhi Chakraborty,Martine Hjelkrem-Tan,Thalles Silva,Michael Kampffmeyer,Adín Ramírez Rivera", "background": "自监督学习方法中的典型原型常常遭受部分原型崩溃的问题，多个原型会趋向于几乎相同的表示。这违背了其核心目的——提供多样的、具有信息性的目标来引导编码器获得丰富的表示。为了解决这个问题，从业者要么过度参数化原型集，要么添加人为的正则化项，这只能缓解症状而不能从根源上解决问题。研究者通过实验证明，联合优化编码器和原型是导致短路学习的原因，早期训练中，原型会趋向于冗余的表示，这些表示可以减少损失但不一定能增强表示的多样性和丰富性。目前的方法在没有明确正则化的情况下，通过去耦合训练策略消除原型崩溃，提高了原型的多样性和下游任务的性能。", "innovation": "论文提出了一种全新的去耦合训练策略，通过独立于编码器损失来更新高斯混合模型的原型，从而避免了编码器和原型的联合优化导致的原型崩溃问题。这种方法简单且具有原理性，能够在不使用显式正则化的情况下有效避免原型崩溃，并且能够提高原型的多样性和下游任务的表现力。", "conclusion": "该研究通过实验证明了联合优化编码器和原型是导致原型崩溃的原因，并提出了一种新的去耦合训练策略来解决该问题。实验表明，这种方法能够有效避免原型崩溃，提供了更加多样化的原型，并且提升了下游任务的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20119", "html_url": "https://arxiv.org/abs/2510.20119", "title": "在时间序列中没有‘苹果’：通过不变性视角重新思考TSFMs", "title_en": "There is No \"apple\" in Timeseries: Rethinking TSFM through the Lens of Invariance", "authors": "Arian Prabowo,Flora D. Salim", "background": "时间序列基础模型（TSFMs）的数量激增，但许多轻量级的监督基准甚至经典模型可以与它们匹敌。造成这一差距的原因被认为是未经改进的NLP或CV管道直接引入时间序列领域。在语言和视觉领域，大规模网络数据密集地捕捉了人类的概念，例如有大量的图片和文本材料来形容苹果。相反，时间序列数据旨在补充图像和文本模态。没有包含苹果概念的时间序列数据集。因此，‘网上抓取一切’的策略在时间序列分析中失败了。文章指出，进展需要从机会性聚合转向基于原则的设计：构建能够系统地覆盖不变性空间同时保留时间语义的数据集。这一点上，时间序列不变性的概念应该基于第一性原理进行构建。只有通过确保表示的完整性并实现不变性覆盖，TSFMs才能获得实现泛化、推理和真正涌现行为所需的对齐结构。", "innovation": "本文提出了一个新的视角——不变性视角，重新思考时间序列基础模型（TSFMs）的问题所在，并建议构建基于第一原理的时间序列不变性概念，通过确保表示的完整性并实现不变性覆盖，以实现TSFMs的有效泛化和真正涌现行为。", "conclusion": "本文分析了时间序列领域中存在的数据集问题，并提出了一种基于不变性的新设计方法，认为这种方法可以提升时间序列基础模型的能力，使其具备更好的泛化能力和真正的涌现行为。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20148", "html_url": "https://arxiv.org/abs/2510.20148", "title": "通过多层建模理解结构和功能连接在Tau传播中的机制作用", "title_en": "Understanding Mechanistic Role of Structural and Functional Connectivity in Tau Propagation Through Multi-Layer Modeling", "authors": "Tingting Dan,Xinwei Huang,Jiaqi Ding,Yinggang Zheng,Guorong Wu", "background": "新兴的神经成像证据显示，Pathological tau蛋白沿着特定的大规模神经网络积累，表明网络架构在阿尔茨海默病（AD）的发展中起重要作用。然而，结构连接（SC）和功能连接（FC）是如何相互作用来影响tau传播的具体机制尚不清楚。本研究利用大量纵向神经成像数据，通过多层图扩散模型研究SC和FC的相互作用。", "innovation": "通过多层图扩散模型研究SC和FC的相互作用，揭示了SC和FC在tau传播中的不对称贡献。SC在顶叶、枕叶和边缘系统区域起更大作用，而FC主要驱动亚皮质区、岛叶、前额叶和颞叶区域的Tau传播。随着疾病的发展，SC和FC在tau传播中的相对主导性发生了变化。这些发现为理解AD的病理机制提供新的视角。", "conclusion": "研究结果表明SC和FC在Tau传播中的相互作用是复杂且区域特异性的，并与与AD相关基因在炎症、凋亡和溶酶体功能方面的作用区域相对应。其他不可改变的风险因素（如APOE基因型和性别）和生物学机制（如淀粉样蛋白沉积）通过特定的解剖和功能途径对tau传播进行区域特异性重塑。研究结果在独立的AD队列中得到验证。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20169", "html_url": "https://arxiv.org/abs/2510.20169", "title": "基于超行程的增强定向邻域搜索方法用于大规模TSP", "title_en": "Empowering Targeted Neighborhood Search via Hyper Tour for Large-Scale TSP", "authors": "Tongkai Lu,Shuai Ma,Chongyang Tao", "background": "旅行商问题（TSP）是一项经典的NP难问题，受到了学术界和工业界的广泛关注。基于神经网络的方法在解决TSP方面表现出潜力，但仍然面临着在更大实例中扩展的挑战，特别是在与全局热力图、边权重或访问矩阵相关的内存限制方面，以及生成高质量初始解和高效导航广阔搜索空间时的不足。", "innovation": "提出了基于超行程的大型TSP实例定向邻域搜索方法（HyperNS）。该方法首先使用稀疏热力图图将TSP实例分为簇，并抽象为超节点，然后生成超行程以指导初始化和优化过程。这种方法通过聚焦于与超行程相关的边来缩减搜索空间，从而提高优化的效率和有效性。", "conclusion": "实验结果表明，该方法在合成和真实数据集上都优于现有的基于神经网络的方法，尤其是在处理大规模实例时显著减少了与最优解的差距。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20157", "html_url": "https://arxiv.org/abs/2510.20157", "title": "ADP-VRSGP: 基于减量随机梯度推的有效自适应差分隐私去中心化学习", "title_en": "ADP-VRSGP: Decentralized Learning with Adaptive Differential Privacy via Variance-Reduced Stochastic Gradient Push", "authors": "Xiaoming Wu,Teng Liu,Xin Wang,Ming Yang,Jiguo Yu", "background": "在去中心化学习中，差分隐私（Differential Privacy）被广泛用于保护敏感数据，通过在模型更新中引入噪声来实现。然而，现有的使用固定方差噪声的方法往往降低了模型性能并减少了训练效率.", "innovation": "我们提出了一个名为ADP-VRSGP的新方法，它结合了自适应差分隐私和减量随机梯度推策略。该方法通过逐步衰减的学习率和噪声方差调整策略，动态地调整噪声方差和学习率，这加速了训练过程，在保持节点级个性化隐私保障的同时提升了模型性能。为了应对早期迭代中由大方差噪声导致的收敛缓慢，引入了一种渐进梯度融合策略，利用历史梯度，有效提升了训练的稳定性和速度。同时，ADP-VRSGP还结合了分布式的推和聚合技术，使其特别适合于时间变化的通信拓扑结构。", "conclusion": "通过严格的理论分析，我们证明了ADP-VRSGP具有适当的收敛性和训练稳定性，并且显著提高了训练速度。实验结果表明，我们的方法在多种场景下都优于现有基准，展示了其在隐私保护的去中心化学习中的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20199", "html_url": "https://arxiv.org/abs/2510.20199", "title": "使用优化的确定性等价项的规避风险受限强化学习", "title_en": "Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents", "authors": "Jane H. Lee,Baturay Saglam,Spyridon Pougkakiotis,Amin Karbasi,Dionysis Kalogerias", "background": "受限优化为解决强化学习(RL)中相互冲突的目标提供了一种共同框架。通常，这些目标（和约束）通过期望累积奖励来表达。然而，这种表达方式忽视了奖励分布尾部的风险或甚至可能的灾难性事件，并且对于涉及风险高的应用来说通常不够，因为尾部异常值的风险至关重要。", "innovation": "本文提出了一种规避风险的受限RL框架，该框架利用优化的确定性等价项(OCEs)在奖励值和时间上共同表现出每阶段的鲁棒性。该框架在参数化的强拉格朗日对偶框架下确保了原始受限问题的精确等价，并提供了一种简单的算法食谱，可以嵌入到标准RL求解器中，如PPO。本文还证明了所提出算法在常见假设下的收敛性，并通过几个数值实验验证了该方法的规避风险的性质。", "conclusion": "本文提出了一种规避风险的受限RL框架，通过优化确定性等价项确保了原始问题的精确等价，提供了一种简单的嵌入算法，并通过实验验证了其规避风险的性质。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20068", "html_url": "https://arxiv.org/abs/2510.20068", "title": "联合变换器自编码器用于多脑区神经潜在动态的解耦", "title_en": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics", "authors": "Ram Dyuthi Sristi,Sowmya Manojna Narasimha,Jingya Huang,Alice Despatin,Simon Musall,Vikash Gilja,Gal Mishne", "background": "现有研究在多脑区神经元同时记录分析方面存在局限。已有对齐或多元方法忽视了时间结构，而动态潜变量模型则捕捉了时间依赖性，但在同一框架内同时处理非站定性和非线性动态以及区分共享和特定于区域的结构方面存在限制，通常还假定线性读出或混淆了共享和私有信号。", "innovation": "该研究提出了联合变换器自编码器（CTAE），这是一种序列模型，能够同时解决非站定性和非线性动态问题，并分离共享和特定于区域的结构。CTAE利用变换器编码器和解码器捕捉长距离神经动态，并显式地将每个区域的潜在空间划分为正交的共享和私有子空间。与现有方法相比，CTAE能够更好地解码行为变量。", "conclusion": "CTAE在多脑区神经元同时记录方面表现出更好的效果，能够捕捉时间结构，同时区分脑区之间的共享活动和特定活动。该方法成功地从高密度电生理数据集中提取了有意义的表示，优于现有方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20200", "html_url": "https://arxiv.org/abs/2510.20200", "title": "近似可复制性在学习中的应用", "title_en": "Approximate Replicability in Learning", "authors": "Max Hopkins,Russell Impagliazzo,Christopher Ye", "background": "论文提出了可复制性（由Impagliazzo等人在STOC '22提出）这一概念，指的是算法在重新采样输入时保持稳定（具有共享随机性的条件下）。虽然这是一个强而有力且有趣的稳定性概念，但可复制性的成本可能是非常高的：例如，对于简单的阈值学习任务不存在可复制的算法（Bun等人在STOC '23的研究）。鉴于如此强烈的不可能性结果，论文探讨了在什么近似的可复制性下学习是可能的？", "innovation": "本文提出了在PAC学习背景下三种自然的可复制性的放松：(1) 点复制：学习器在固定输入上必须一致，但在所有输入上不同时一致，(2) 近似：学习器必须输出分类大部分分布的假说，(3) 半复制：算法完全可复制，但可以额外使用共享的未标记样本。在所有三种情况下，对于常量级的可复制性参数，我们得到了样本最优的无偏PAC学习器：(1) 和 (2) 可以免费地使用 Θ(d/α²) 样本实现，而 (3) 需要 Θ(d²/α²) 有标签样本。", "conclusion": "对于常量级的可复制性参数，我们得到了样本最优的无偏PAC学习器：点复制和近似复制可以在免费的情况下使用 Θ(d/α²) 样本实现，而半复制则需要 Θ(d²/α²) 有标签样本。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20219", "html_url": "https://arxiv.org/abs/2510.20219", "title": "CO-PFL：面向异构网络的贡献导向个性化 federated learning", "title_en": "CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks", "authors": "Ke Xing,Yanjie Dong,Xiaoyi Fan,Runhao Zeng,Victor C. M. Leung,M. Jamal Deen,Xiping Hu", "background": "传统的联邦学习依赖单一共识模型，在数据异构性较强的场景下疗效不佳。标准的聚合方法通常基于数据量对客户端更新进行加权，这假设所有客户端的贡献是等价的，但在实际应用中往往忽视了每个客户端更新的实际效用和可靠性。这导致了个性化不足和聚合偏差。", "innovation": "我们提出了贡献导向的个性化联邦学习（CO-PFL），一种新的算法，能够动态估计每个客户端对全局聚合的贡献。CO-PFL通过同时分析梯度方向差异和预测偏差来进行联合评估，利用梯度和数据子空间的信息来为每个客户端提供一种有原则且区分性的聚合权重。此外，CO-PFL 通过参数级个性化机制与感知掩码的动量优化一体化，增强了个性化适应性和优化稳定性，从而有效减小了聚合偏差，加强了全局协调，提高了局部性能。", "conclusion": "CO-PFL 在四个基准数据集（CIFAR10、CIFAR10C、CINIC10 和 Mini-ImageNet）上的一系列实验表明，CO-PFL 在个性化精度、鲁棒性、可扩展性和收敛稳定性方面一直超过现有的先进方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20209", "html_url": "https://arxiv.org/abs/2510.20209", "title": "使用常规实验室数据评估早期癌症检测的可行性：不平衡数据集上机器学习方法的评估", "title_en": "Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset", "authors": "Shumin Li", "background": "犬类早期癌症筛查的可访问检测工具的发展是兽医医学中面临的重大挑战。常规实验室数据提供了一种可能的低成本来源，但由于单个生物标志物的非特异性以及筛查人群中的严重类别不平衡，其应用受到了限制。该研究评估了在为实际约束条件（包括癌症类型的分组和诊断后样本的纳入）下，使用金毛犬终身研究（GRLS）队列进行癌症风险分类的可能性。研究小组进行了一项全面的基准评估，系统地比较了126种分析管道，其中包括各种机器学习模型、特征选择方法和数据平衡技术。", "innovation": "研究采用了大规模的数据集合和多种机器学习模型、特征选择方法以及数据平衡技术进行全面的基准评测，以及使用SHapley Additive exPlanations (SHAP)进行了可解释性分析。这些方法有助于识别驱动预测的特征，并提供了在不平衡数据集上应用机器学习方法的新视角。", "conclusion": "虽然常规实验室数据中存在可统计检测的癌症信号，但其信号过于微弱且被混淆，无法可靠地区分正常老化或其他炎症状态。这项工作为单模态数据在孤立应用中的性能设定了关键上限，并强调了多模态数据源集成在计算兽医学中的重要性，以实现有意义的进步。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20187", "html_url": "https://arxiv.org/abs/2510.20187", "title": "每个问题都有其自身的价值：带有明确人类价值观的强化学习", "title_en": "Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values", "authors": "Dian Yu,Yulai Zhao,Kishan Panaganti,Linfeng Song,Haitao Mi,Dong Yu", "background": "尽管可验证奖励的强化学习（RLVR）能够有效训练模型在客观领域使用二元正确奖励，但它忽视了并非所有任务的重要性都相同。RLEV 提出了一个直接将大型语言模型（LLM）优化与可量化的用户价值信号对齐的方法，通过引入用户定义的价值信号到奖励函数中，改进了基于正确性的基线模型，并且在多种强化学习算法和模型规模下表现出色。此外，RLEV 算法不仅提高了价值加权准确性，还学会了对具有不同价值的提示采取不同类型的任务终止策略：对低价值提示简洁，对高价值提示详尽。这一行为源于在序列结束标记上执行价值加权梯度放大。删除实验进一步证明了这种效果与价值对齐的因果关系。即使在噪声大的价值信号（如基于难度的标签）下，RLEV 依然保持了稳健性，表明优化显式效用函数可能是实用的方法，用于使语言模型与人类优先级对齐。", "innovation": "RLEV 提出了一种直接将大型语言模型优化与可量化的人类价值信号对齐的方法，通过在奖励函数中引入用户定义的价值信号，从而超越了仅基于正确性的基线模型，并且在多个强化学习算法和模型规模下表现优异。此外，该方法不仅提高了价值加权准确性，还学习了一种值敏感的任务终止策略，对低价值提示简洁，而对高价值提示详尽。删除实验进一步确认了这种效果与价值对齐的因果关系，并展示了其在噪声较大的价值信号下的鲁棒性。", "conclusion": "RLEV 在具有显式价值标签的数据上表现优越，并且能够适应不同的任务优先级，即使在具有噪声的价值信号下也能保持稳健，表明优化一个显式效用函数可以为对齐语言模型与人类优先级提供一个实用的路径。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20225", "html_url": "https://arxiv.org/abs/2510.20225", "title": "通过元变量化dropout的联邦学习", "title_en": "Federated Learning via Meta-Variational Dropout", "authors": "Insu Jeon,Minui Hong,Junhyeog Yun,Gunhee Kim", "background": "联邦学习（FL）旨在通过远程分布的客户端训练全局推理模型，由于它能够提高数据隐私性而变得流行。然而，传统联邦学习在实际应用中面临着模型过拟合和由于客户端数据有限且非IID导致的本地模型发散等挑战。", "innovation": "提出了一种新颖的贝叶斯元学习方法——元变量化dropout（MetaVD），通过共享超网络学习预测客户端特定的dropout率，有效提升了FL算法在有限非IID数据环境下的模型个性化能力。此外，从后验适应视角和贝叶斯联邦学习的后验聚合视角探讨了Meta-learning和条件dropout后验。", "conclusion": "MetaVD在多种稀疏和非IID的联邦学习数据集上的实验结果表明了其卓越的分类准确性和不确定性校准性能，尤其是对于分布外（OOD）客户端。MetaVD压缩了每个客户端所需的局部模型参数，减轻了模型过拟合问题并降低了通信成本。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20220", "html_url": "https://arxiv.org/abs/2510.20220", "title": "用于组公平约束的大规模谱聚类的拉普拉斯矩阵替代方法", "title_en": "Alternatives to the Laplacian for Scalable Spectral Clustering with Group Fairness Constraints", "authors": "Iván Ojeda-Ruiz,Young Ju-Lee,Malcolm Dickens,Leonardo Cambisaca", "background": "最近的研究集中在通过在算法设计中引入公平约束来减轻聚类中的算法偏见。现有方法如差异影响、社区凝聚力和人均成本被用来确保公平结果。其中，组公平（平衡）确保了每个保护组在每个聚类中有均衡的代表性。然而，将平衡作为公平性指标纳入谱聚类算法导致了较高的计算时间需求，需要进行改进。该研究旨在通过使用拉格朗日方法和夏农-莫里森-伍德伯里（SMW）恒等式重新表述约束优化问题，来增强谱聚类算法的效率，从而引入Fair-SMW算法。Fair-SMW使用具有不同特征间隙的不同拉普拉斯矩阵替代方法，产生了多种Fair-SMW变体，在保持与现有算法相似的平衡性的同时，提供更好的运行时性能。使用随机块模型（SBM）对Fair-SMW在实际网络数据集上的运行效率和平衡性进行了评估，包括LastFM、FacebookNet、Deezer和德国数据集，结果表明，与最先进的算法相比，计算时间加快了两倍，同时灵活性足够，可以实现两倍的平衡量.", "innovation": "该研究通过引入Fair-SMW算法，在保持平衡性的前提下显著提高了谱聚类算法的运行效率。Fair-SMW通过拉格朗日方法和夏农-莫里森-伍德伯里（SMW）恒等式重新表述约束优化问题，并使用具有不同特征间隙的不同拉普拉斯矩阵替代方法，产生了多种Fair-SMW变体。这些变体在保持与现有算法相似的平衡性的同时，实现了更好的运行时性能，实际网络数据集上的评估表明计算时间比最先进的算法快两倍，同时充满灵活性，可以在两倍平衡性实现上进行选择.", "conclusion": "该研究通过改进谱聚类算法，提出了Fair-SMW算法，该算法在保持平衡性的同时提高了运行效率。实验结果表明，在实际网络数据集上，Fair-SMW算法在计算时间和平衡性上都优于现有的算法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20222", "html_url": "https://arxiv.org/abs/2510.20222", "title": "QKCV 注意力机制：通过静态分类嵌入提升时间序列预测，适用于轻量级和预训练基础模型", "title_en": "QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models", "authors": "Hao Wang,Baojun Ma", "background": "在现实世界的时间序列预测任务中，类别信息对于捕捉数据内部模式至关重要。传统的QKV框架在时间序列预测中广泛应用，但缺乏对类别特定信息的突出显示。因此，本文提出了一种名为QKCV（Query-Key-Category-Value）的注意力机制，进一步扩展了QKV框架，引入了一个静态分类嵌入C，以强调类别特定的信息。QKCV作为一种通用插件模块，能够提升基于注意力的时间序列预测模型（如Vanilla Transformer, Informer, PatchTST, TFT）的预测精度，适用于各种现实世界的数据集。此外，QKCV还能适应线性更新静态嵌入C来微调单变量时间序列的基础模型，同时保留预训练权重，从而减少了计算负担并提高了微调性能。", "innovation": "本文提出了一种名为QKCV（Query-Key-Category-Value）的注意力机制，通过引入静态分类嵌入C，强调了类别特定信息。QKCV增强了基于注意力的时间序列预测模型的预测准确度，同时具有轻量级和预训练基础模型的兼容性，能够通过更新静态嵌入的方式进行微调，减少计算成本，提升性能。", "conclusion": "QKCV作为一种通用的插件模块，提升了多种时间序列预测模型的预测精度，特别是在现实世界的数据集上表现良好，并且通过线性更新静态嵌入C，可以有效微调单变量时间序列的基础模型，减少了计算负担，提升了最终的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20228", "html_url": "https://arxiv.org/abs/2510.20228", "title": "稀疏局部隐式图像函数用于亚千米天气降尺度", "title_en": "Sparse Local Implicit Image Function for sub-km Weather Downscaling", "authors": "Yago del Valle Inclan Redondo,Enrique Arriaga-Varela,Dmitry Lyamzin,Pablo Cervantes,Tiago Ramalho", "background": "该研究背景在于现有的天气变量（如温度和风速）降尺度方法在从稀疏气象站和地形数据生成隐式神经表示时，可能面临精度不足或效率低下的问题。因此，该研究旨在通过引入SpLIIF方法，提高低时空分辨率天气数据的生成精度，特别是对于2km以下的空间尺度。", "innovation": "该研究创新地提出了一种新的方法SpLIIF，该方法可以从稀疏的气象站和地形数据训练模型，来生成隐式神经表示并实现任意的天气变量降尺度。相比于现有的插值基线方法CorrDiff以及其他替代方法，SpLIIF在温度降尺度方面表现更优，具有最高达到50%的优势；在风速降尺度方面，SpLIIF也显示出约10-20%的提升。", "conclusion": "研究发现，SpLIIF方法在温度和风速的降尺度任务上表现出色。特别是在温度降尺度任务上，SpLIIF达到了比CorrDiff和基线方法更好的效果，提升幅度最高可达50%。对于风速降尺度，SpLIIF相比其他方法提升了10-20%的准确性。这表明SpLIIF具有在更高精度下处理亚千米尺度天气数据的潜力，为气象学和相关领域的研究提供了新的解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20235", "html_url": "https://arxiv.org/abs/2510.20235", "title": "带有最大-最小准则的多目标强化学习：基于博弈论的方法", "title_en": "Multi-Objective Reinforcement Learning with Max-Min Criterion: A Game-Theoretic Approach", "authors": "Woohyeon Byeon,Giseung Park,Jongseong Chae,Amir Leshem,Youngchul Sung", "background": "本文提出了一种证明收敛且实用的框架，用于具有最大-最小准则的多目标强化学习。从博弈论的角度出发，将多目标强化学习重新表述为两个玩家的零和正则化连续博弈，并引入基于镜像下降的有效算法。这种方法简化了策略更新过程，同时保证全局最终迭代的收敛性。通过对算法的全面理论分析，包括精确和近似策略评估下的迭代复杂度以及样本复杂度界，进一步优化了算法性能，提出了自适应正则化修改。实验结果表明，提出的算法在表格设置中的收敛行为，并且在深度强化学习方面的实现显著优于之前的基线方法，尤其是在MORL环境中。", "innovation": "本研究创新之处在于提出了一个证明收敛且实用的框架，将具有最大-最小准则的多目标强化学习问题转化为两个玩家的零和正则化连续博弈，并基于此设计了一种基于镜像下降的有效算法。该方法不仅简化了策略更新过程，还通过理论分析证明了全局最终迭代的收敛性，并提出了自适应正则化的算法改进措施，进而显著提升了算法的性能。", "conclusion": "本文提出的算法在表格环境中证明了收敛行为，并在深度强化学习应用中显著优于之前的基线方法。未来的研究方向将进一步优化算法，使其在更广泛的多目标强化学习环境中取得更好的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20236", "html_url": "https://arxiv.org/abs/2510.20236", "title": "图神经网络中的层间知识混合在化学性质预测中的应用", "title_en": "Layer-to-Layer Knowledge Mixing in Graph Neural Network for Chemical Property Prediction", "authors": "Teng Jiek See,Daokun Zhang,Mario Boley,David K. Chalmers", "background": "Graph Neural Networks (GNNs) 是目前预测分子性质最有效的方法之一，但仍有提高准确性的需求。尽管增加模型复杂性可以提升GNN的精度，但这也会增加训练和推理过程中的计算成本和内存需求。为了解决这个问题，研究开发了Layer-to-Layer Knowledge Mixing (LKM)，这是一种新颖的自我知识蒸馏方法，它在训练和推理过程中几乎没有增加计算复杂性的同时增加了最先进的GNN模型的准确性。", "innovation": "LKM通过最小化预存在GNN层中的隐藏嵌入之间的均绝对距离，有效地聚集了多跳和多尺度信息，从而提高了局部和全局分子特征的表示。这项研究使用了三种不同的GNN架构：DimeNet++、MXMNet和PAMNet，并通过量子化学性质数据集（QM9、MD17和Chignolin）进行了评估，结果表明LKM方法有效减少了量子化学和生物物理性质预测的均绝对误差，最高可达9.8%、45.3%和22.9%。", "conclusion": "这项工作证明了LKM在不增加训练和推理成本的基础上，可以显著提高GNNs在化学性质预测中的准确性，展示了LKM技术的巨大潜力。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20250", "html_url": "https://arxiv.org/abs/2510.20250", "title": "FedGPS: 针对联邦学习中数据异质性的统计校正", "title_en": "FedGPS: Statistical Rectification Against Data Heterogeneity in Federated Learning", "authors": "Zhiqin Yang,Yonggang Zhang,Chenxin Li,Yiu-ming Cheung,Bo Han,Yixuan Yuan", "background": "联邦学习（FL）面临一个重要挑战，即数据异质性，它会损害模型的性能和收敛性。现有的方法已经在解决这一问题上取得了显著进展。然而，如何在各种异质性场景下提高这些方法的性能和鲁棒性仍然被忽视。为此，本文通过在多种异质性场景下进行系统评估，发现现有方法的鲁棒性有限，并且通过共享统计信息使客户端能够以全球视角进行更新，从而减轻异质性。", "innovation": "本文提出了一种新颖的框架FedGPS，该框架无缝地结合了来自其他客户端的统计分布和梯度信息。FedGPS通过静态修改每个客户端的学习目标，使用代理信息隐式地建模全局数据分布，同时在每个轮次中动态调整本地更新方向。广泛的实验证明，FedGPS在各种异质性场景中优于现有方法，验证了其有效性和鲁棒性。", "conclusion": "FedGPS在多种异质性场景中表现出色，表明该方法不仅有效，而且鲁棒性较强，未来值得进一步研究。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20264", "html_url": "https://arxiv.org/abs/2510.20264", "title": "Optimistic Task Inference for Behavior Foundation Models", "title_en": "Optimistic Task Inference for Behavior Foundation Models", "authors": "Thomas Rupf,Marco Bagatella,Marin Vlastelica,Andreas Krause", "background": "行为基础模型（BFMs）能够在测试时直接指定任何奖励函数的情况下检索高性能策略，这通常称为零样本强化学习（RL），这在计算方面非常高效，但在数据方面可能效率较低。标准假设下，BFMs需要通过一个非忽略不计的推理数据集来计算奖励，要么是假设奖励具有可用形式，要么是需要大量的标注工作。", "innovation": "该研究提出了一种名为OpTI-BFM的方法，这是一种乐观决策标准，可以直接建模奖励函数的不确定性并指导BFMs在测试时通过与环境的交互进行数据收集以进行任务推理。研究还通过直接连接到线性贝叶斯算法中的上置信边界算法，为训练良好的BFMs提供了遗憾界限。", "conclusion": "实验结果表明，OpTI-BFM使基于后续特征的BFMs能够在少量回合中识别并优化看不见的奖励函数，同时最小化计算开销。代码可以在提供的链接中获得。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20270", "html_url": "https://arxiv.org/abs/2510.20270", "title": "ImpossibleBench：衡量大型语言模型利用测试案例倾向的基准框架", "title_en": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases", "authors": "Ziqian Zhong,Aditi Raghunathan,Nicholas Carlini", "background": "大型语言模型（LLMs）倾向于通过寻找和利用“捷径”来完成任务，这种行为对其评估的可靠性以及实际部署中的可靠性构成重大风险。例如，一个具有单元测试访问权限的LLM代理可能会删除失败的测试，而不是修复根本错误。这种行为会破坏基准结果的有效性和实际部署中大型语言模型编码助手的安全性。为了量化、研究和减轻这种行为，引入了ImpossibleBench框架，该框架通过在现有基准测试如LiveCodeBench和SWE-bench中引入自然语言规范与单元测试之间的直接冲突，系统地测量LLM代理利用测试案例的倾向性。", "innovation": "提出了一种名为ImpossibleBench的基准框架，用于系统地测量大型语言模型利用测试案例的倾向性。通过在任务中引入规范和单元测试之间的直接冲突，创建了“不可能”的任务变体来评估模型的“作弊率”。此外，该框架还展示了其灵活性，可用于研究模型行为、上下文工程和开发监测工具等方面。", "conclusion": "我们希望ImpossibleBench能成为一个有用的框架，用于构建更稳健和可靠的大型语言模型系统。目前的实现可以在下面的链接找到：[this https URL]."}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20271", "html_url": "https://arxiv.org/abs/2510.20271", "title": "Scalable GPU-Accelerated Euler Characteristic Curves: Optimization and Differentiable Learning for PyTorch", "title_en": "Scalable GPU-Accelerated Euler Characteristic Curves: Optimization and Differentiable Learning for PyTorch", "authors": "Udit Saxena", "background": "测拓扑特征能够捕捉影像数据的全局几何结构，但在深度学习中的实际应用需要具备计算效率和可微性。现有的一些GPU实现相对原始，无法满足上述需求。研究人员需要优化现有GPU内核以实现快速计算，并在不同的计算框架下引入能够进行端到端学习的可微分层。", "innovation": "论文提出了针对 Ampere GPU 的优化 GPU 内核，相比以往的 GPU 实现获得 16-2000 倍的速度提升。同时引入了一个基于Differentiable Euler Characteristic Transform风格的Sigmoid松弛机制的可微分 PyTorch 层，可以通过单向学习来确定阈值。因此，该研究在提升效率和实现端到端学习方面做出了重要贡献，拓宽了 Euler Characteristic Curve 在深度学习中的应用前景。", "conclusion": "论文讨论了此类模型在下游应用中的意义，并提出了批处理和多GPU扩展方案，以期进一步推广这些技术的使用范围。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20242", "html_url": "https://arxiv.org/abs/2510.20242", "title": "构建高性能选择性分类器需要什么？", "title_en": "What Does It Take to Build a Performant Selective Classifier?", "authors": "Stephan Rabanser,Nicolas Papernot", "background": "选择性分类器通过在模型认为不确定的情况下放弃输入来提高模型的可靠性。然而，很少有实际方法能够达到完美排序 oracle 的标准性能，即按正确性顺序接受示例。本研究将这一缺陷正式化为选择性分类器差距，并首次从五个不同的松弛源对差距进行了有限样本分解：贝叶斯噪声、近似误差、排名误差、统计噪声以及由实现或迁移引起的松弛。研究发现，单调后处理校准往往被认为可以增强选择性分类器，但实际上对缩小差距影响有限，因为它通常不会改变模型的基本分数排序。因此，缩小差距需要能有效重新排序预测的评分机制，而不仅仅是对其进行重新缩放。研究通过合成的两个半月形数据和现实世界的视觉和语言基准进行验证，通过受控实验分别隔离每个误差组件。结果确认了贝叶斯噪声和有限的模型能力可以解释大量差距，只有更丰富、特征感知的校准器能够实质性地改进分数排序，并且数据迁移引入了另一种需要分布鲁棒性训练的松弛。这些分解为使用者提供了一个定量的误差预算以及实际的设计指南，以便构建更接近理想oracle行为的选择性分类器", "innovation": "首次从五个不同的松弛源对选择性分类器差距进行了有限样本分解。研究表明，单调后处理校准对缩小差距影响有限，需要有效重新排序预测的评分机制。通过合成数据和现实世界基准进行验证，解决不同的误差组件。研究还确认了贝叶斯噪声和模型能力的重要性，并强调了特征感知校准器和分布鲁棒性训练的必要性。", "conclusion": "选择性分类器差距可以细分为五个不同因素，单调后处理校准有限地影响了差距的缩小，需要有效的重新排序预测机制。通过合成数据和现实世界基准进行验证，确认了贝叶斯噪声、模型能力缺乏和数据迁移的影响，并强调了设计和训练策略的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20272", "html_url": "https://arxiv.org/abs/2510.20272", "title": "LLMs中PRM引导树搜索在数学推理中的局限性", "title_en": "Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs", "authors": "Tristan Cinquin,Geoff Pleiss,Agustinus Kristiadi", "background": "链式思维提示结合最佳-of-N（BoN）选择在大型语言模型（LLMs）中的数学推理中变得流行，但其线性结构无法捕捉复杂问题解决过程中的分支性和探索性。", "innovation": "提出了一种自适应算法来最大化不可解的操作空间的过程奖励模型（PRM）得分，并研究了PRM引导的树搜索是否能通过探索多个部分解路径来提高数学推理能力。", "conclusion": "(1) PRM引导的树搜索在成本更高的情况下，与BoN相比，没有显著的改进；(2) 蒙特卡洛树搜索和束搜索优于其他PRM引导的树搜索方法；(3) PRMs在状态值的近似上表现不佳，并且随着推理深度的增加可靠性下降；(4) PRMs在分布外表现不佳。这些表现不佳的原因在于树搜索对不可靠的PRM评分的更大依赖性，表明在树搜索能够有效增强LLMs的数学推理能力之前，需要不同类型的奖励建模。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20278", "html_url": "https://arxiv.org/abs/2510.20278", "title": "KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models", "title_en": "KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models", "authors": "Guangyu Dai,Siliang Tang,Yueting Zhuang", "background": "近年来，研究人员提出了大规模-小型模型协作框架，通过利用易于训练的小模型来辅助大型模型，目标是显著降低计算资源消耗并保持可比的准确性，同时增强大型模型在特定领域任务中的性能。然而，这种协作模式存在显著的准确性下降、灾难性遗忘加剧以及由小型模型知识引发的幻觉问题等挑战。", "innovation": "本文提出了一种基于KAN的协作模型(KCM)作为改进的大规模-小型模型协作方法。KAN作为一种不同于传统MLP的神经网络架构，提供更好的可视化和可解释性，同时减轻了灾难性遗忘的问题。实验证明，在三种场景（语言、视觉和跨模态视觉-语言任务）中应用KCM的协作模型框架，与仅使用大规模模型的方法相比，不仅能显著减少大型模型的推理调用次数，保持相近的任务准确性，还能大幅降低计算资源消耗，并且对于长尾数据，KAN小型协作模型显著减轻了灾难性遗忘，从而提高了准确度。", "conclusion": "实验结果表明，KCM在所有指标上均优于基于MLP的小型协作模型，展示了其在大规模-小型模型协作中的优越性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20273", "html_url": "https://arxiv.org/abs/2510.20273", "title": "SynTSBench: 重新思考深度学习模型中时间序列中的时间模式学习", "title_en": "SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models for Time Series", "authors": "Qitai Tan,Yiyun Chen,Mo Li,Ruiwen Gu,Yilin Su,Xiao-Ping Zhang", "background": "近年来，深度学习的进展极大地推动了时间序列预测的进步，但许多先进模型在实际应用中仍然难以保持稳健的性能，即使它们在标准基准数据集上表现出色。这种持续的性能差距可以归因于深度学习架构的黑盒性质以及当前评价框架的固有限制，这些框架经常缺乏提供清晰、定量的特定模型优缺点见解的能力，从而复杂了针对特定预测场景选择合适模型的过程。", "innovation": "我们提出了一个合成数据驱动的评价框架，SynTSBench，通过可编程的功能配置系统地评估时间序列预测模型的基本建模能力。该框架将干扰因素隔离，建立了一个可解释的评估系统，包含三个核心分析维度：1）时间特征分解和能力映射，允许系统地评估模型学习特定模式类型的能力；2）在数据不规则性下的鲁棒性分析，量化噪声容忍阈值和异常恢复能力；3）理论最佳基准测试，为每种模式类型设定性能边界，实现模型预测与数学最优值之间的直接比较。我们的实验表明，当前的深度学习模型在所有类型的时间序列中无法普遍达到最优基准。", "conclusion": "SynTSBench 通过合成数据驱动的方式，系统地评估了时间序列预测模型的基本建模能力，通过时间特征分解和能力映射、数据不规则性下的鲁棒性分析和理论最优基准测试，为不同模型提供了明确的定量评价。该框架有助于选择更适合特定预测场景的模型，并且相关代码已公开。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20279", "html_url": "https://arxiv.org/abs/2510.20279", "title": "ResearchGPT: 评估和训练用于计算机科学全流程研究的大型语言模型基准测试", "title_en": "ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer Science Research Workflows", "authors": "Penghao Wang,Yuhao Zhou,Mengxuan Wu,Ziheng Qin,Bangyuan Zhu,Shengbin Huang,Xuanlei Zhao,Panpan Zhang,Xiaojiang Peng,Yuzhang Shang,Jianfei Yang,Zheng Zhu,Tianlong Chen,Zhangyang Wang,Kai Wang", "background": "随着大型语言模型（LLMs）的发展，人们开始构想它们在科学领域的角色：可以构建一个人工智能合作者，帮助人类科学家完成科学研究的整个过程。然而，为实现这一目标，需要一种基准测试来评估从研究开始到结束的整个工作流程，而不仅仅是孤立的子任务。基于此背景，本文提出了CS-54k，这是一个源自14,000篇CC许可论文的高质量计算机科学研究问答对语料库，该语料库通过一种可扩展的、基于论文的流程构建而成，结合了检索增强生成（RAG）和多阶段质量控制，从而确保其事实依据。", "innovation": "本文创新地提出了CS-54k语料库，包括CS-4k和CS-50k两个子集。CS-4k是用于评估人工智能在科学研究能力的基准测试；CS-50k则是用于训练大型语言模型的大规模数据集。关键发现是，即使是7B模型，在适当训练下也能显著超越许多更大规模的私人拥有的系统。这表明，提高AI作为研究助手的效用更多依赖于与领域的对齐性和高质量数据的训练，而非仅仅依赖预训练规模或泛用基准测试的表现。", "conclusion": "作者们发布了CS-4k和CS-50k语料库，旨在促进计算机科学研究中人工智能系统作为可靠合作者的发展。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20295", "html_url": "https://arxiv.org/abs/2510.20295", "title": "Quantifying Distributional Invariance in Causal Subgraph for IRM-Free Graph Generalization", "title_en": "Quantifying Distributional Invariance in Causal Subgraph for IRM-Free Graph Generalization", "authors": "Yang Qiu,Yixiong Zou,Jun Wang,Wei Liu,Xiangyu Fu,Ruixuan Li", "background": "图神经网络在分布变化下的分布外泛化仍然是一个关键挑战。现有方法通常采用不变风险最小化（IRM）框架，但这种框架常需要昂贵的环境注释或手工生成的合成分割。", "innovation": "本文旨在开发一种无IRM的方法来捕捉因果子图。研究团队首先识别出因果子图与非因果组件相比表现出更为稳定的分布变化，这被正式化为不变分布准则，并在本文中进行了理论证明。基于此准则，研究者系统分析了分布转移与表示范数之间的关系，并深入探讨了其背后的成因。最终，研究者提出了一个无IRM的方法，通过引入规范引导的不变分布目标来发现和预测因果子图。", "conclusion": "大量实验表明，本文的方法在广泛使用的基准测试中持续地优于最先进的方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20299", "html_url": "https://arxiv.org/abs/2510.20299", "title": "DB-FGA-Net：双主干频率门控注意网络及其Grad-CAM可解释性在多分类中的应用", "title_en": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability", "authors": "Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim", "background": "脑肿瘤是神经肿瘤学中的一个挑战性问题，早期和准确的诊断对于成功的治疗至关重要。尽管基于深度学习的脑肿瘤分类方法通常依赖于重大数据增强，这种方法可以限制模型的一般化能力并在临床应用中降低模型的信任度，因此需要新的解决方案来提高模型在不同大小和分布数据集上的鲁棒性。", "innovation": "本文提出了一种双主干网络（DB-FGA-Net），结合了VGG16和Xception，并引入了频率门控注意（FGA）块来捕捉局部和全局特征。该模型在没有数据增强的情况下达到了最先进的性能，证明了其在大小和分布变化的数据集上的鲁棒性。此外，该模型还集成了Grad-CAM，以便于依据预测的肿瘤区域进行解释，从而在模型预测和临床可解释性之间建立了桥梁。", "conclusion": "提出的DB-FGA-Net框架在7K-DS数据集上的4类分类中达到了99.24%的准确性，在3类和2类分类中分别达到了98.68%和99.85%的准确性。此外，该模型在独立的3K-DS数据集上实现了95.77%的准确性并超越了基线和最先进的方法。为了进一步支持临床使用，开发了一个图形用户界面（GUI），提供实时分类和Grad-CAM基底的肿瘤定位。这些结果表明，无增强，可解释且可部署的深度学习模型，如DB-FGA-Net，对于可靠的临床转化具有潜在的实用价值。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20302", "html_url": "https://arxiv.org/abs/2510.20302", "title": "InvDec：用于分离时序和变量建模的多变量时间序列预测反转解码器", "title_en": "InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling", "authors": "Yuhang Wang", "background": "多变量时间序列预测需要同时建模时间模式和跨变量依赖关系。独立于通道的方法（如PatchTST）擅长时间建模，但忽略了变量间的关联；而纯粹的变量注意力方法（如iTransformer）牺牲了时间编码。现有方法在时间编码和变量级解码之间存在权衡，本研究提出了一种混合架构——InvDec（反转解码器），实现了时间编码和变量级解码的原理上分离。InvDec结合了基于补丁的时间编码器和通过变量间自注意力操作变量维度的反转解码器。该方法采用延迟变量嵌入，仅在时间编码后丰富变量特定表示，同时保留时间特征的完整性。自适应残差融合机制动态平衡不同类型数据集的时间和变量信息。研究结果表明，使用PatchTST实例化的InvDec（InvDec-PatchTST）在高维数据集上表现显著提升：相较于PatchTST在Electricity（321变量）数据集上MSE降低了20.9%，在Weather数据集上提高了4.3%，在Traffic数据集上提升了2.7%，同时在低维度的ETT数据集上仍保持竞争力。消融研究验证了各组件的有效性，分析表明，交叉变量模型的优势随着变量数量的增加而增强，确认了高维数据集中跨变量建模的重要性。", "innovation": "提出了一种混合架构——InvDec，实现了时间编码和变量级解码的原理上分离。具体地，InvDec结合了基于补丁的时间编码器和通过变量间自注意力操作变量维度的反转解码器，自适应残差融合机制动态平衡不同类型数据集的时间和变量信息，延迟变量嵌入保留时间特征的完整性，并在高维数据集上取得了显著的性能提升。", "conclusion": "实验表明，InvDec及其PatchTST实例在高维数据集上表现出显著的性能提升，同时在低维数据集上仍保持竞争力。消融研究验证了每个组件的有效性，进一步分析表明InvDec在高维数据集上的优势随着变量数量的增加而增强。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20383", "html_url": "https://arxiv.org/abs/2510.20383", "title": "具鲁棒协调的层次时间序列预测", "title_en": "Hierarchical Time Series Forecasting with Robust Reconciliation", "authors": "Shuhei Aikawa,Aru Suzuki,Kei Yoshitake,Kanata Teshigawara,Akira Iwabuchi,Ken Kobayashi,Kazuhide Nakata", "background": "本文关注层次化时间序列数据的预测，其中每个高一级的观测值等于其对应低一级时间序列的总和。现有方法通常独立地为每个时间序列生成基础预测，然后再应用一种调整过程以使结果预测值在整个层次结构中保持一致。这种方法通常依赖于预测误差的协方差矩阵来得出最优调整。然而，实际操作中，真实协方差矩阵未知且需要通过有限样本预先估计，这导致了预测性能的下降。", "innovation": "本文提出了一种鲁棒优化框架以解决层次协调中的协方差矩阵估计不确定性问题。通过引入估计协方差矩阵的不确定性集合，并将问题形式化为一个在该不确定性集合上最小化最坏情况期望平方误差的半定优化问题，从而提出了鲁棒协调方法，这种方法在数值实验中优于现有的层次预测方法。", "conclusion": "提出的鲁棒协调方法在数值实验中展示了更好的预测性能，表明在协调过程中整合不确定性是有效的。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20387", "html_url": "https://arxiv.org/abs/2510.20387", "title": "相对基础的神经语言模型缩放定律", "title_en": "Relative-Based Scaling Law for Neural Language Models", "authors": "Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu", "background": "现有的缩放定律研究几乎完全依赖交叉熵作为评估指标，但交叉熵只能提供部分的性能视图，因为它只衡量了正确标记的概率，而忽略了正确标记和错误标记之间的相对顺序。而相对顺序对于语言模型来说非常重要，例如在贪婪采样场景中。", "innovation": "提出基于相对排序的概率（RBP）度量，量化正确标记被列为前几预测的几率。在此基础上建立基于相对排序的缩放定律，来描述RBP随模型规模增加的变化规律。通过在四个数据集和四个模型家族上的广泛实验，证明了该定律的稳健性和准确性。", "conclusion": "基于相对排序的缩放定律补充了交叉熵视角，有助于更全面地理解大规模语言模型的缩放现象。对于实际应用和理论探索都提供了有价值的见解。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20408", "html_url": "https://arxiv.org/abs/2510.20408", "title": "平衡专业化与集中化：用于序列工业控制的多代理强化学习基准", "title_en": "Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control", "authors": "Tom Maus,Asma Atamna,Tobias Glasmachers", "background": "多阶段工业过程的自主控制需要本地专业化和全球协调。强化学习（RL）提供了一种有前景的方法，但由于奖励设计、模块化和动作空间管理等方面的挑战，其在工业中的应用仍然有限。许多学术基准与工业控制问题相差甚远，限制了其在实际应用中的转移能力。", "innovation": "本研究引入了一个增强的行业启发式基准环境，结合了两个现有基准SortingEnv和ContainerGym的任务，形成一个顺序回收场景，涉及分类和压榨操作。评估了两种控制策略：具有专业化的模块化架构和管理整个系统的单一代理，并分析了动作屏蔽的影响。结果表明，在没有动作屏蔽的情况下，代理难以学习有效策略，模块化架构表现更好。当应用动作屏蔽时，两种架构均大幅改进，性能差距显著缩小。这些结果强调了动作空间约束的作用，并建议随着动作复杂性的降低，专业化的优势减弱。因此，提出的基准提供了探索实用且稳健的多代理RL解决方案在工业自动化中的价值试验床。", "conclusion": "提出的基准为探索工业自动化中的实用且稳健的多代理RL解决方案提供了有价值的试验平台，同时促进了中央控制与专业化辩论的持续讨论。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20327", "html_url": "https://arxiv.org/abs/2510.20327", "title": "LEGO：推荐系统中轻量高效多重属性遗忘框架", "title_en": "LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems", "authors": "Fengyuan Yu,Yuyuan Li,Xiaohua Feng,Junjie Fang,Tao Wang,Chaochao Chen", "background": "在推荐系统中保护敏感用户信息的需求日益增长，导致推荐属性遗忘得到了越来越多的关注。现有的研究主要集中在单一属性遗忘上。然而，现实中的隐私保护要求往往涉及多个敏感属性并且是动态变化的。现有的单一属性遗忘方法无法满足这些现实需求，主要因为无法同时处理多个遗忘请求，以及缺乏对动态遗忘需求的有效适应能力。", "innovation": "为了应对这些挑战，本文提出了LEGO框架。LEGO框架将多重属性遗忘过程分为两个步骤：嵌入校准将特定属性相关的信息从用户嵌入中移除；灵活组合将这些嵌入组合成一个单一嵌入，保护所有敏感属性。通过将遗忘过程框架化为最小化互信息的问题，LEGO提供了同时遗忘的理论保证，从而解决了第一个挑战。同时，LEGO框架通过嵌入校准可以在并行执行以及灵活高效地进行嵌入组合解决了第二个挑战。通过在三个现实世界数据集上的三个代表性推荐模型进行广泛的实验验证了LEGO框架的有效性和效率。", "conclusion": "本文提出的LEGO框架通过并行处理和灵活高效的特性有效地处理了推荐系统中多重属性遗忘的需求，该框架在三个代表性推荐模型上通过三种真实世界数据集的实验验证了其有效性和效率。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20414", "html_url": "https://arxiv.org/abs/2510.20414", "title": "无积分神经标记时间点过程中的标记不平衡问题解决", "title_en": "Addressing Mark Imbalance in Integration-free Neural Marked Temporal Point Processes", "authors": "Sishun Liu,Ke Deng,Xiuzhen Zhang,Yongli Ren,Yan Wang", "background": "Marked Temporal Point Process (MTPP) 已被广泛用于建模带有标记的事件流中的事件分布，且主要用于预测下一个事件的时间和标记。然而，现有研究忽略了在许多实际应用场景中事件标记的分布严重不平衡的问题，即一些标记频繁而另一些则稀少。这种不平衡极大地影响了下一个事件的预测性能，尤其是对于稀有标记的事件预测。", "innovation": "我们提出了一种阈值方法，该方法通过学习阈值来调整由标记的先验概率归一化的标记概率，以优化标记预测，而不是基于标记概率直接预测标记，如现有研究的做法。结合这种方法，我们首先预测标记然后预测时间。特别地，我们开发了一种新颖的无积分神经 MTPP 模型，以支持有效的时间抽样和标记概率的估计而不进行昂贵的数值不恰当积分。", "conclusion": "我们在实际数据集上的广泛实验表明，我们的解决方案在针对下一个事件标记和时间预测方面优于各种基准。该代码可以在以下网址获取：this https URL"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20369", "html_url": "https://arxiv.org/abs/2510.20369", "title": "当你的奖励模型不确定时，请询问一个强大的语言模型法官", "title_en": "Ask a Strong LLM Judge when Your Reward Model is Uncertain", "authors": "Zhenghao Xu,Qin Lu,Qingru Zhang,Liang Qiu,Ilgee Hong,Changlong Yu,Wenlin Yao,Yao Liu,Haoming Jiang,Lihong Li,Hyokun Yun,Tuo Zhao", "background": "在强化学习与人类反馈（RLHF）中，奖励模型（RM）对于使大型语言模型（LLM）对齐方面具有关键作用。然而，传统的通过人类偏好训练而成的RMs容易遭受奖励作弊，并且难以泛化到未见过的数据（OOD）。相比之下，具有推理能力的强大LLM法官在不增加额外训练的情况下表现出更优的泛化能力，但其推理成本较高，限制了其在线RLHF的应用。因此，如何高效地利用这些强大的LLM法官来增强RM，成为一个亟待解决的问题。", "innovation": "本文提出了一种基于不确定性路由的框架，该框架能够高效地将快速的RM与强大的但推理成本高的LLM法官进行配合。具体而言，本文将策略梯度（PG）方法中的优势估计形式化为成对偏好分类问题，从而实现对不确定性的量度化，引导路由决策。不确定的成对偏好样本将被转发给LLM法官，而有把握的样本则由RM进行评估。实验结果表明，与随机选择LLM法官相比，本文的不确定性路由策略在同样成本下具有显著优势。并且，下游的对齐结果证明了其在在线RLHF中的有效性。", "conclusion": "本文提出了一种有效的基于不确定性的路由策略，能够利用强大的LLM法官来辅助快速的RM，改善了RLHF的性能。结果显示这种方法在保持低推理成本的同时，能够显著提效并对齐效果。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20349", "html_url": "https://arxiv.org/abs/2510.20349", "title": "用于鲁棒跑道检测的合成数据", "title_en": "Synthetic Data for Robust Runway Detection", "authors": "Estelle Chigot,Dennis G. Wilson,Meriem Ghrib,Fabrice Jimenez,Thomas Oberlin", "background": "当前深度视觉模型已经足够成熟，可以应用于工业甚至关键应用，如自主导航。然而，收集和标注用于训练这些模型的数据需要巨大的努力和成本，这成为一个瓶颈，尤其是在需要涵盖所有可能情况的关键应用中。因此，生成合成图像成为一种有吸引力的解决方案，它允许以低成本覆盖所有场景和环境，前提是缓解合成数据与真实数据之间的分布差异的影响。本文探讨了跑道检测问题，这是飞机制造商自主着陆系统中的关键部分。为了验证这种方法的有效性，我们提出了一种基于商用飞行模拟器的图像生成方法，并结合少量标注的真实图像数据。通过控制图像生成及真实与合成数据的集成，我们证明标准目标检测模型能够实现准确的预测，并评估了其鲁棒性，特别是在夜间等未在真实数据中出现的不利条件下，显示了使用定制领域适应策略的重要性。", "innovation": "提出了基于商用飞行模拟器的图像生成方法，并结合少量标注的真实图像数据。通过控制图像生成及真实与合成数据的集成，验证了标准目标检测模型可以在检测跑道时实现准确预测，并通过评估模型在未见的真实数据下的鲁棒性，展示了定制领域适应策略的重要性。", "conclusion": "我们的研究结果表明，通过基于商用飞行模拟器生成合成图像，可以高效地补充真实数据的不足，使得标准目标检测模型能够实现准确的跑道检测，并且该模型在未见过的天气条件（如夜间）下依然具有良好的鲁棒性。提出了定制领域适应策略，进一步提高了模型的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20413", "html_url": "https://arxiv.org/abs/2510.20413", "title": "为何DPO是一个错配的估计器及其修正方法", "title_en": "Why DPO is a Misspecified Estimator and How to Fix It", "authors": "Aditya Gopalan,Sayak Ray Chowdhury,Debangshu Banerjee", "background": "Direct Preference Optimization (DPO) 类似的直接对齐算法通过基于偏好数据的微调模型来优化，仅使用监督学习而不是带有人类反馈的两阶段强化学习 (RLHF)。研究表明，DPO 编码了一个关于由参数策略类诱导的奖励函数的概率估计问题。当真实的奖励函数无法通过策略类实现时，DPO 变为不匹配的，导致偏好顺序逆转、政策奖励恶化和对输入偏好数据分布的高度敏感性。研究发现基于参数类的两阶段 RLHF 在局部行为上与策略空间中的自然梯度步长相关联，通过精细的几何特征描述，提出了一种名为 AuxDPO 的方法，该方法通过引入辅助变量来改进 DPO，使其向 RLHF 解的解决方案靠拢，并减轻 DPO 的不匹配问题。实验证明 AuxDPO 在教学 bandeit 设置和大语言模型 (LLM) 对齐任务中表现出更优的性能。", "innovation": "提出了一种新的方法 AuxDPO，通过引入额外的辅助变量，将 DPO 解向 RLHF 解靠拢，从而减轻了 DPO 的不匹配问题。这种方法通过细粒度的几何特征描述，使得改进的 DPO 更容易收敛于期望的解决方法。此外，也对两阶段 RLHF 的局部行为进行了几何学上的解释，提供了一个更深入的理解。", "conclusion": "通过实验证明，基于 AuxDPO 的方法在教学 bandeit 设置和大语言模型 (LLM) 对齐任务中的性能优于传统的 DPO 方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20439", "html_url": "https://arxiv.org/abs/2510.20439", "title": "通过概念学习视角的可解释基准测试", "title_en": "Explainable Benchmarking through the Lense of Concept Learning", "authors": "Quannian Zhang,Michael Röder,Nikit Srivastava,N'Dah Jean Kouagou,Axel-Cyrille Ngonga Ngomo", "background": "基准测试评价系统性能是科学方法不可或缺的一部分。然而，系统性能通常通过少量的指标来总结，这使得详细分析评估细节和提取进一步开发或使用的洞察能力成为一项繁琐的且常常带有偏见的手工任务。因此，本文提出了一种新的基准测试方法——可解释基准测试，其目的是自动为基准中的系统性能生成解释。", "innovation": "本文提供了可解释基准测试范式的首个实例，特别是针对知识图谱基础的问答系统。通过引入一种新型的概念学习方法PruneCEL，以生成系统性能的解释。实验表明，PruneCEL在解释基准任务方面的表现优于最先进的概念学习方法，F1分数提升了0.55个点。同时，一项针对41名参与者的任务导向用户研究显示，参与者中有80%的人能够基于我们的解释准确预测系统的性能。", "conclusion": "本文提出了可解释基准测试的概念并提供了在知识图谱基础的问答系统的首次应用实例。通过PruneCEL方法，取得了优于现有方法的性能，并在用户研究中证明了解释的有效性。未来的工作将致力于扩展这一概念到其他类型的系统和应用场景中。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20448", "html_url": "https://arxiv.org/abs/2510.20448", "title": "MolBridge：原子级联合图精炼以实现稳健的药物-药物相互作用事件预测", "title_en": "MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction", "authors": "Xuan Lin,Aocheng Ding,Tengfei Ma,Hua Liang,Zhe Quan", "background": "药物组合治疗具有疗效，但同时也存在药物-药物相互作用（DDIs）的风险，特别是在复杂分子结构下。准确预测DDI事件需要捕捉细粒度的药物间关系，这对建模如酶介导的竞争代谢机制至关重要。然而，现有的方法通常依赖于孤立的药物表示，无法明确定义原子级跨分子间的交互作用，这限制了它们在多种分子复杂性和DDI类型分布中的有效性。", "innovation": "为了克服这些限制，该论文提出了MolBridge，一种新颖的原子级联合图精炼框架，用于稳健的DDI事件预测。MolBridge通过集成药物对的原子结构，构造了一个联合图，使得可以直接建模药物间的关联性。为了解决联合图设置中的潜在信息损失问题，特别是当建模长距离原子依赖关系时，引入了一种结构一致性模块，该模块通过迭代精炼节点特征并保持全局结构上下文来解决这一问题。这种联合设计使得MolBridge能够有效学习局部和全局交互，优于目前最先进的基线方法，在长尾和归纳场景中表现出卓越的性能。MolBridge能产生稳健的表示，涵盖常见和罕见的DDI类型。", "conclusion": "广泛的实验表明，MolBridge 在两个基准数据集上的表现一致地超越了最先进的基线模型。这些结果证明了细粒度图精炼在提高DDI事件预测精度、鲁棒性和机制可解释性方面的优势。MolBridge的工作通过开发基于图的方法来分析药物-药物相互作用网络，为网页挖掘和内容分析做出了贡献。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20428", "html_url": "https://arxiv.org/abs/2510.20428", "title": "大型语言模型修复中样本选择策略的实证研究", "title_en": "An Empirical Study of Sample Selection Strategies for Large Language Model Repair", "authors": "Xuran Li,Jingyi Wang", "background": "大型语言模型（LLMs）在现实系统中越来越广泛地应用，但由于它们可能会生成有毒或有偏见的输出，这损害了安全性和可信度。后验模型修复提供了一种实用的解决方案，但参数更新的高成本促使只选择性地使用修复数据。尽管在此之前有大量的工作集中在模型训练的数据选择上，但对于特定应用于大型生成模型行为修复的情况，仍不清楚哪些采样标准最有效和高效。本文进行了一项系统分析，以确定各种样本优先策略对LLM修复的有效性。评估了五种代表性选择方法，包括随机采样、K-Center、梯度范数选择法（GraNd）、分层覆盖（CCS）以及我们提出的语义感知优先采样（SAPS）方法。修复效果和权衡是通过毒性减少、WikiText-2和LAMBADA上的困惑度以及三种复合指标：修复接近度得分（RPS）、总体性能得分（OPS）和修复效率得分（RES）进行评估的。实验结果显示SAPS实现了去毒、功能保留和效率之间的最佳平衡，并且用较少的数据取得了可相比或更优的修复效果。对于大型或稳健的模型，随机采样仍然有效，而高开销的方法如CCS和GraNd仅提供了有限的好处。最优数据比例取决于模型规模和修复方法，表明样本选择应被视为修复管道中的可调组件。总体而言，这些发现表明基于选择的修复是一种高效且可扩展的保持LLM可靠性的范式", "innovation": "本文对大型语言模型修复中的样本选择策略进行了系统性分析，并提出了语义感知优先采样（SAPS）方法。研究评估了五种代表性选择方法，发现SAPS方法在平衡去毒、功能保留和效率方面表现最佳。研究还揭示了不同情况下最优数据比例取决于模型规模和修复方法，表明样本选择可以作为修复流程中的可调组件。这些发现强化了基于选择的修复是保持LLM可靠性的有效和可扩展范式的观点", "conclusion": "研究结果表明，通过基于采样的修复方法可以有效地保持大型语言模型的可靠性。SAPS方法尤其能够在减少数据量的情况下达到优异的修复效果。此外，研究强调样本选择是一个可调的组件，适合不同规模的模型和修复方法，这对于设计和优化大规模语言模型的修复策略具有重要意义。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20454", "html_url": "https://arxiv.org/abs/2510.20454", "title": "网球预测中的非传递性选手主导与市场 inefficiency：一种图神经网络方法", "title_en": "Intransitive Player Dominance and Market Inefficiency in Tennis Forecasting: A Graph Neural Network Approach", "authors": "Lawrence Clegg,John Cartlidge", "background": "在竞技网球中，非传递性选手主导普遍存在，即选手A战胜选手B，选手B又战胜选手C，但选手C却战胜了选手A。这个问题在当前的预测方法中几乎未被考虑。现有的诸如博彩公司Pinnacle Sports等方法在处理高非传递性复杂度的比赛时表现不佳。", "innovation": "研究引入了一种图神经网络方法来解决这个问题，通过使用带有时序导向图的节点（选手）和有向边（历史比赛结果）来明确建模这些非传递性关系。研究还指出，当前的方法尤其是在处理高非传递性复杂度的比赛时表现出明显的市场 inefficiency，而研究方法可以通过这些情况获得显著的正向回报。", "conclusion": "通过在非传递性较高的比赛中使用研究模型进行选择性赌博（准确率为65.7%，Brier分数为0.215），实现3.26%的ROI（复利回报率），使用凯利投注法总计1903次赌注，这表明市场上在处理非传递性比赛时存在 inefficiency，而研究方法成功地利用了这一市场 inefficiency。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20540", "html_url": "https://arxiv.org/abs/2510.20540", "title": "SheafAlign: 基于sheaf理论的分布式多模态对齐框架", "title_en": "SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal Alignment", "authors": "Abdulmomen Ghalkha,Zhuojun Tian,Chaouki Ben Issaid,Mehdi Bennis", "background": "传统的多模态对齐方法假设所有模态之间存在互相关性，但在现实中的分布式场景中，这种假设往往不成立。SheafAlign 提出了一种基于sheaf理论的分布式多模态对齐框架，它通过将单一空间对齐转换为多个对比空间来进行多模态对齐。这种方法通过sheaf结构模型两两模态之间的关系，并利用分散式的对比学习目标进行训练。", "innovation": "SheafAlign 框架通过去除所有模态之间需要互相关的限制，保留了共性和独特信息，解决了先前方法的局限性。实验结果显示，与现有最先进的基准相比，SheafAlign 在零样本泛化、跨模态对齐和对缺失模态的鲁棒性方面表现出更好的性能，通信成本降低了50%。", "conclusion": "SheafAlign 为多模态对齐提供了一种新的解决方案，通过分散式的对比学习目标，实现了更好的性能和更低的通信成本。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20486", "html_url": "https://arxiv.org/abs/2510.20486", "title": "Hurdle-IMDL: 一种红外降雨恢复的不平衡学习框架", "title_en": "Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval", "authors": "Fangjian Zhang,Xiaoyong Zhuge,Wenlan Wang,Haixia Xiao,Yuying Zhu,Siyang Cheng", "background": "尽管人工智能在定量遥感方面取得了进步，但其有效性受到标签分布不平衡的限制。传统模型由于倾向于常见样本，导致稀有样本的恢复性能下降。降雨恢复就是一个典型的例子，特别是在大暴雨中的性能表现尤为不足。", "innovation": "本文提出了Hurdle-Inversion Model Debiasing Learning (IMDL)框架。该框架将降雨分布的不平衡分解为零膨胀（定义为非降雨样本的主导）和长尾（定义为轻雨样本相对于暴雨样本的不适当富集）两个部分。采用 hurdle 模型处理零膨胀问题，而 IMDL 则通过将学习对象转化为无偏的理想逆模型来应对长尾问题。该方法在统计指标和中国东部暴雨天气案例研究中显示出优越性，优于传统、成本敏感、生成和多任务学习方法，特别是在减轻系统性低估和提升大暴雨至极端降雨的恢复方面。", "conclusion": "IMDL 提供了一种针对环境变量分布不平衡的普遍适用方法，有助于增强对罕见但具有高影响事件的恢复。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20468", "html_url": "https://arxiv.org/abs/2510.20468", "title": "图像偏好模型下的可移植黑盒单次水印伪造", "title_en": "Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models", "authors": "Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko", "background": "近年来，随着生成模型的广泛应用和法律压力的增加，数字内容水印技术引起了广泛的关注。由于越来越多的AI生成内容可用在线，水印在确保内容真实性及归属方面的作用越来越重要。尽管已有许多研究评估了水印的鲁棒性，但在水印伪造方面（即，水印从真实内容中窃取并应用于恶意内容的场景）的研究仍然较少。本文在广泛使用的后置图像水印技术背景下，探讨了水印伪造问题。", "innovation": "本文的主要创新贡献包括：1) 提出了一种偏好模型来评估图像是否带有水印，该模型通过纯程序生成的图像进行训练，不需要使用真实水印；2) 该模型能够通过反向传播优化输入图像来移除和伪造水印，该技术只需要一个水marked图像，无需了解水印嵌入模型，使之比现有同类攻击更简单且更实用；3) 在多种后置图像水印模型上评估了本文方法，证明了方法的有效性，质疑了当前水印技术的安全性。", "conclusion": "本文研究了图像后置水印技术中的黑盒单次水印伪造问题，并提出了一个偏好模型来评估图像是否被水印化，使用反向传播优化技术来移除和伪造水印。实验结果表明，该方法能够有效地伪造水印，从而质疑了现有水印技术的安全性。本文的代码和相关资源已公开。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20477", "html_url": "https://arxiv.org/abs/2510.20477", "title": "Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models", "title_en": "Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models", "authors": "Rui Zhu,Song-Lin Lv,Zi-Kang Wang,Lan-Zhe Guo", "background": "该论文探讨了在标签稀缺场景中利用半监督学习（Semi-Supervised Learning, SSL）和利用预训练模型进行微调两种方法。近年来，研究者开始将预训练的视觉-语言模型（VLMs）的微调与SSL相结合，形成了半监督微调的新范式。然而，现有方法往往受到模型偏见和超参数敏感性的影响，这是因为它们依赖于预测一致性或预定义的信心阈值。鉴于这一现状，研究者提出了一种简单有效的插拔兼容方法——Bi-CoG，旨在解决前述问题，通过同时利用跨模型和模型内一致性，并结合一种错误意识动态伪标签策略，从而分配高效且低偏见的伪标签。", "innovation": "Bi-CoG方法创新地结合了跨模型和模型内一致性，以及一种错误感知的动态伪标签分配策略，以提供高质量和低偏见的伪标签，从而有效减少模型偏见和增强泛化能力。该方法旨在克服现有半监督微调方法中模型偏见和超参数敏感性的不足，并已通过理论分析和在14个数据集上的大量实验验证了其有效性。", "conclusion": "理论分析和广泛的实验证明了Bi-CoG方法的有效性，该方法在现有方法的基础上，以一致且显著的方式改善了性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20542", "html_url": "https://arxiv.org/abs/2510.20542", "title": "零样本强化学习的首个统一框架", "title_en": "A Unified Framework for Zero-Shot Reinforcement Learning", "authors": "Jacopo Di Ventura,Jan Felix Kleuker,Aske Plaat,Thomas Moerland", "background": "零样本强化学习（RL）作为一种在未监督情况下发展通用代理的方法已经崭露头角，这类代理能够解决下游任务而无需在测试时进行额外的训练或规划。不同于传统的RL方法通过固定奖励来优化策略，零样本RL要求代理编码足够的表示以支持立即适应任何目标，类比于视觉和语言基础模型。尽管对该领域产生了越来越大的兴趣，但缺乏一个共同的分析框架来统一其研究。", "innovation": "本研究首次提出了零样本RL的第一个统一框架。该框架引入了一致的符号和分类法，组织现有的方法并使其可以直接进行比较。在该框架中，算法被分为两种类型：直接表示和组合表示。另外，还提出了后继特征方法的扩展界限，重新定义了它们在零样本范围内的表现。通过合并现有工作在同一个框架下，本研究为未来零样本RL研究奠定了原理性的基础，并指明了开发更多通用代理的清晰路径。", "conclusion": "本研究通过提出一个统一的零样本RL框架，整合了过去的研究成果，揭示了方法之间的共性和差异，并针对后继特征方法提出了新的理论界限。这为未来完善零样本RL和开发更通用的代理奠定了坚实的基础。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20590", "html_url": "https://arxiv.org/abs/2510.20590", "title": "将MLOps生命周期嵌入OT参考模型", "title_en": "Embedding the MLOps Lifecycle into OT Reference Models", "authors": "Simon Schindler,Christoph Binder,Lukas Lürzer,Stefan Huber", "background": "随着MLOps实践在工业环境中的广泛应用，将其与操作技术（OT）系统相结合面临重大挑战。", "innovation": "该研究分析了MLOps与OT环境结合的基本障碍，并提出了一种系统性的方法，将MLOps实践嵌入现有的OT参考模型中。评估了RAMI 4.0和ISA-95标准的适用性，并通过实际案例详细映射了MLOps生命周期组件。", "conclusion": "研究表明，虽然标准的MLOps实践不能直接移植到OT环境中，但使用现有参考模型进行结构化调整可以为成功的集成提供途径。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20556", "html_url": "https://arxiv.org/abs/2510.20556", "title": "结构不变性很重要：通过图指标重新思考图重构", "title_en": "Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics", "authors": "Alexandre Benoit,Catherine Aitken,Yu He", "background": "图重构已成为通过修改图拓扑结构来改善图神经网络（GNNs）和图变换器的信息流动并缓解过度挤压的关键技术。尽管有效，重构本质上会改变图的结构，从而有可能扭曲依赖图结构的重要信号。然而，尽管图重构的应用越来越广泛，但仍不清楚哪些结构特性必须保留以确保性能提升和结构保真度。本文对此问题进行了系统分析，并研究了多种图重构策略如何影响一系列图结构指标，以及这些变化如何与下游任务性能相关联。", "innovation": "本文首次系统分析了图重构如何影响一系列图结构指标，以及这些变化如何与下游任务性能相关联。研究了七个不同策略，揭示了成功的图重构方法通常会保留局部结构，同时允许在全局连接性方面具有灵活性。这些发现为有效图重构策略的设计提供了新的见解，实现了图理论与实际GNN优化之间的桥梁连接。", "conclusion": "研究结果表明，成功的图重构方法倾向于保留局部结构，同时允许在全局连接性方面具有灵活性。这些发现提供了设计有效图重构策略的新视角，将图理论与实际的GNN优化结合起来。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20608", "html_url": "https://arxiv.org/abs/2510.20608", "title": "SGD下的期望光滑性收敛分析", "title_en": "Convergence Analysis of SGD under Expected Smoothness", "authors": "Yuta Kawamoto,Hideaki Iiduka", "background": "随机梯度下降（SGD）是大规模学习的基石，但经典分析依赖于过强（如有界方差）或过粗（如均匀噪声）的假设。期望光滑性（ES）条件作为一种灵活的选择，将随机梯度的第二矩与目标值和全梯度联系起来。", "innovation": "作者细化了ES条件，提供了解释，并使用采样依赖的常数；推导了全梯度平方范数的期望边界；证明了对于各种步长调度，收敛速率为$O(1/K)$，并明确给出了残余误差。所有证明均在附录中详细给出。", "conclusion": "本研究统一并扩展了近期的研究流（Khaled和Richtárik, 2020；Umeda和Iiduka, 2025），提供了SGD在ES条件下自包含的收敛性分析。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20607", "html_url": "https://arxiv.org/abs/2510.20607", "title": "通过组合能量最小化实现可迁移推理", "title_en": "Generalizable Reasoning through Compositional Energy Minimization", "authors": "Alexandru Oarga,Yilun Du", "background": "在机器学习任务中，特别是在推理任务中，模型需要解决比训练数据更加复杂的问题。现有的方法通常以端到端的方式训练推理模型，直接将输入实例映射到解决方案。这种训练方法虽然可以让模型从数据中学习有用的启发式规则，但也常常导致模型在训练分布之外的表现受限。因此，如何让模型能够过渡解决问题变得更加困难的问题，是亟待解决的关键挑战之一。", "innovation": "本文提出了一种新的推理泛化方法，通过学习更小、更易于解决的子问题的解空间的能量景观来增强模型的推理能力。测试时，通过结合多个子问题的能量函数构建整体的能量景观。这种方法允许在推理过程中加入额外的约束条件，从而使可以构建出对于更困难问题的能量景观。为了提高从新构建的能量景观中抽取样本的质量，本文引入了平行能量最小化（PEM）方法。实验结果表明，本文提出的方法在各种推理问题上表现优于现有最先进的方法，证明了其在处理更大和更复杂问题上的泛化能力。", "conclusion": "本文提出的方法在一系列推理问题上取得了优越的表现，展示了其具备强大的泛化能力，特别是在处理更大和更复杂的问题上。这种方法通过增强在不同子问题解空间上的能量景观学习，以及通过引入平行能量最小化技术提高样本质量，成功解决了传统端到端训练方法所带来的泛化性限制问题。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20609", "html_url": "https://arxiv.org/abs/2510.20609", "title": "大规模实用代码RAG：在计算预算下的任务导向检索设计选择", "title_en": "Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under Compute Budgets", "authors": "Timur Galimzyanov,Olga Kolomyttseva,Egor Bogomolov", "background": "本文研究了在现实计算预算条件下，针对代码生成任务的检索设计。通过从Long Code Arena中选取两个互补的任务——代码补全和错误定位，系统地比较了不同窗口大小下的检索配置，通过三个方面进行比较：（i）分块策略，（ii）相似性评分，（iii）分块粒度。", "innovation": "研究发现了PL-PL任务中稀疏BM25和单词级分块策略的最优性和实用性，远超密集替代方案但速度要快一个数量级；NL-PL任务中专有密集编码器（Voyager-3家族）的持续优势，尽管延迟需要增加100倍；最佳分块大小随着可用上下文内容大小而变化；简单的基于线的分块匹配预算内的语法意识分块；不同配置下的检索延迟在200倍以上；BPE基分块过度缓慢，BM25+单词分块提供最佳的质量-时间权衡。", "conclusion": "根据任务需求、模型限制和计算效率提供基于证据的代码导向RAG系统实现建议。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20640", "html_url": "https://arxiv.org/abs/2510.20640", "title": "Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems", "title_en": "Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems", "authors": "Fiza Hussain,Anson Bastos,Anjaly Parayil,Ayush Choure,Chetan Bansal,Rujia Wang,Saravan Rajmohan", "background": "本文讨论了在Microsoft监控云服务时推荐自动看门狗（监控）应跟踪的最佳属性子集的问题。传统方法在富结构和参与信息有限的情况下表现不佳，而且由于同质性问题，未能捕捉到跨越长期范围的实体之间的依赖关系。", "innovation": "提出了一种受transformer架构启发的注意力增强实体排名模型。该模型使用多头注意力机制关注异质邻居及其属性，并进一步通过随机游走采样的路径捕捉远距离依赖。此外，还采用了多方面损失函数以优化相关的推荐，同时尊重数据的固有稀疏性。", "conclusion": "实证评估表明，相比现有方法，该模型在MRR上提高了43.1%。产品团队成员普遍认为这些功能是有用的，并给予了4.5分的评分。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20627", "html_url": "https://arxiv.org/abs/2510.20627", "title": "H-SPLID：基于HSIC的保持显著性潜信息分解", "title_en": "H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition", "authors": "Lukas Miklautz,Chengzhi Shi,Andrii Shkabrii,Theodoros Thirimachos Davarakis,Prudence Lam,Claudia Plant,Jennifer Dy,Stratis Ioannidis", "background": "该研究介绍了一种名为H-SPLID的新颖算法，通过将显著特征和非显著特征显式分解到分开的空间来学习显著特征表示。研究表明H-SPLID有助于学习低维度的任务相关特征，并证明了输入扰动下预测偏差的期望值被显著子空间的维度和输入与表示的希尔伯特-施密特独立性判别准则（HSIC）上界限制。这一发现说明了鲁棒性和潜在表示压缩维度与保留在其中信息之间的关系。", "innovation": "提出了一种名为H-SPLID的新算法，通过将显著特征和非显著特征显式分解到分开的空间，有效地学习显著特征表示。H-SPLID证明了在输入扰动下的预测偏差与显著子空间的维度和HSIC之间的关系，这使得该算法在鲁棒性和潜在表示压缩维度与保留在其中的信息方面具有优势。", "conclusion": "实验证明H-SPLID训练的模型主要依赖于显著输入组件，显示出对影响非显著特征（如图像背景）的扰动的敏感性降低。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20611", "html_url": "https://arxiv.org/abs/2510.20611", "title": "PSO-XAI: 增强可解释人工智能框架的粒子群优化算法在可靠乳腺癌检测中的应用", "title_en": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection", "authors": "Mirza Raquib,Niloy Das,Farida Siddiqi Prity,Arafath Al Fahim,Saydul Akbar Murad,Mohammad Amzad Hossain,MD Jiabul Hoque,Mohammad Ali Moni", "background": "乳腺癌是全球女性中最常见且最具威胁性的癌症类型，其导致的癌症相关死亡率不断提高。早期和准确的检测对降低潜在风险、提高生存率至关重要。然而，传统的诊断方法在预测方面存在诸多限制，如多变性、成本高以及误诊风险大。为应对这些挑战，机器学习（ML）已成为计算机辅助诊断的强大工具，其中特征选择对于提高模型性能和可解释性起着关键作用。", "innovation": "该研究提出了一种集成框架，整合了定制的粒子群优化（PSO）进行特征选择。该框架在包括经典分类器、集成技术、神经网络、概率算法和基于实例的算法在内的29种不同模型上进行了评估。为了确保可解释性和临床相关性，研究使用交叉验证与可解释AI方法相结合。实验结果显示，所提出的方法在所有性能指标上，包括准确性和精确度，均达到了99.1%的出色表现，同时有效减少了特征维度并提供了透明且模型无关的解释。结果强调了将群智能与可解释的机器学习结合使用，以实现稳健、可信且临床相关的乳腺癌诊断的潜力。", "conclusion": "该研究通过与其他29种不同模型的比较证明，结合定制的粒子群优化和可解释AI的方法，在乳腺癌诊断方面具有显著优势，特别是其在准确性和可解释性方面表现出色，为临床诊断提供了强大的支持。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20629", "html_url": "https://arxiv.org/abs/2510.20629", "title": "公平生存预测：一种公平感知生存建模（FASM）方法", "title_en": "Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach", "authors": "Mingxuan Liu,Yilin Ning,Haoyuan Wang,Chuan Hong,Matthew Engelhard,Danielle S. Bitterman,William G. La Cava,Nan Liu", "background": "随着机器学习模型在医疗领域的广泛应用，临床数据中固有的结构不平等和社会偏见可能会被数据驱动的模型继续延续或放大。在生存分析中，失访时间和时间动态会进一步增加公平模型开发的复杂性。通常，算法公平性方法往往忽视跨组排名中的差距，例如高风险的黑人患者可能被排位低于低风险的白人患者，这些白人患者并未经历死亡事件。这种错误排名可能强化生物本质主义并削弱公平医疗服务。在乳腺癌预后案例中，使用SEER乳腺癌数据，我们展示了公平感知生存建模（FASM）能够显著提高公平性，同时保持与未考虑公平性生存模型相当的区分性能，强调其在临床决策中既重视准确性又重视公平性，从而推进公平性作为临床护理的核心原则。", "innovation": "本文提出了一种公平感知生存建模（FASM），以减轻算法在组内排名和跨组排名中的偏见。这种方法在不损失准确度的前提下提高了模型的公平性，特别是在随访中期保持了稳定的公平性表现。", "conclusion": "公平感知生存建模（FASM）在乳腺癌预后案例中，能显著提高模型的公平性，同时保持与未考虑公平性生存模型相当的区分性能。这种方法能够确保生存模型在临床决策中既保准确性又保公平性，推进了公平性在临床护理中的核心地位。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20615", "html_url": "https://arxiv.org/abs/2510.20615", "title": "MS-BART: 统一建模质谱信号和分子结构进行结构解析", "title_en": "MS-BART: Unified Modeling of Mass Spectra and Molecules for Structure Elucidation", "authors": "Yang Han,Pengyu Wang,Kai Yu,Xin Chen,Lu Chen", "background": "质谱(MS)技术在分子识别中发挥着关键作用，极大地促进了科学研究的发展。然而，从质谱数据中解析结构仍然具有挑战性，因为标注的数据稀缺。虽然大规模预训练在其他领域中已被证明对解决数据稀缺性问题非常有效，但在质谱领域，具体的预训练方法却受限于原始光谱信号的复杂性和异质性。为了解决这个问题，我们提出了一种统一建模框架MS-BART，将质谱数据和分子结构转换到一个共享的标记词汇中，通过大规模预训练实现跨模态学习。通过多任务预训练目标进一步增强了MS-BART的泛化能力，联合优化去噪和翻译任务。预训练模型随后通过MIST预训练光谱推理模型生成的指纹预测进行微调，以增强对实际光谱变异性的鲁棒性。尽管微调缓解了分布差异，MS-BART仍然存在分子想象的问题，需要进一步对齐。我们因此引入了一种化学反馈机制，引导模型生成与参考结构更接近的分子。", "innovation": "提出了MS-BART模型，这是一种统一建模框架，将质谱数据和分子结构映射到共享的标记词汇中，通过大规模预训练实现代价跨模态学习。多任务预训练目标提升了模型的泛化能力，联合优化了去噪和翻译任务。通过MIST生成的指纹预测进行微调以增强鲁棒性。引入了化学反馈机制以解决分子想象和对齐问题。", "conclusion": "MS-BART在5/12关键指标上达到SOTA性能，比竞争的扩散方法快一个数量级，全面的消融研究验证了模型的有效性和鲁棒性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20637", "html_url": "https://arxiv.org/abs/2510.20637", "title": "LMM赋能面向任务的自主通信：设计理念与实现挑战", "title_en": "Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges", "authors": "Hyun Jong Yang,Hyunsoo Kim,Hyeonho Noh,Seungnyun Kim,Byonghyo Shim", "background": "大型语言模型（LLMs）和大型多模态模型（LMMs）在自然语言理解、生成和复杂推理方面取得了前所未有的突破，它们在激发6G自主通信方面发挥了关键作用。本文综述了LLM/LMM在任务导向的自主通信中的应用，重点关注多模态感知集成、自适应重新配置以及无线任务的提示/微调策略。通过三个案例研究展示了框架：基于LMM的交通控制、基于LLM的机器人调度和基于LMM的环境感知信道估计。实验结果表明，所提的LLM/LMM辅助自主系统在动态目标、变化的输入参数和异构多模态条件下显著优于传统的区分性深度学习（DL）模型方法，保持了稳健性。", "innovation": "本文提出的LMM/LMM辅助自主系统框架，通过多模态感知集成、自适应重新配置和提示/微调策略，在处理复杂通信任务时显著优于传统的区分性深度学习方法。特别是在动态目标、变化的输入参数和异构环境下的表现更为突出，展示了其在6G自主通信中的潜力。", "conclusion": "所提出的方法在实验结果中显示出显著的优越性，证明了LMM和LMM在任务导向的自主通信中的有效性和稳健性，尤其是在解决动态和复杂环境下的通信问题时。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20616", "html_url": "https://arxiv.org/abs/2510.20616", "title": "差分隐私深度迁移学习中最佳超参数的研究", "title_en": "On Optimal Hyperparameters for Differentially Private Deep Transfer Learning", "authors": "Aki Rehn,Linzh Zhao,Mikko A. Heikkilä,Antti Honkela", "background": "差分隐私（DP）下的迁移学习，即在私人数据上微调预训练模型，是当前在隐私约束下训练大型模型的最优方法。在这一背景下，研究聚焦于两种关键的超参数：裁剪界限C和批次大小B。研究表明，当前关于如何选择最佳C的理论理解与实际结果不符，造成了梯度分布的变化。在限定计算预算（固定迭代次数）的情况下，现有用于调整B的启发式方法无效，而累计差分隐私噪声更好地解释了更小或更大批量的表现。同时指出，使用单一的(C,B)设置进行任务处理可能会导致性能不佳，尤其是当在松散和紧密隐私以及充足的计算资源和有限的计算资源之间转换时，这种现象通过分析裁剪作为梯度权重的分配以及累计差分隐私噪声来解释。", "innovation": "研究发现，现有用于调整Batch大小的启发式方法失效，而累计差分隐私噪声能更好地解释批量大小对性能的影响。此外，研究表明使用单一的(C,B)设置可能会影响到任务性能，特别是在隐私要求和计算资源之间有较大变化时。分析了裁剪作为梯度权重的效果，并提出了新的理解方式，尤其是通过分析累计差分隐私噪声来解释不同批量大小的表现差异。", "conclusion": "研究发现，不同的隐私要求和计算资源情况下，单一的(C,B)设置可能导致性能下降。更深入地理解裁剪作为梯度权重的影响，以及利用累计差分隐私噪声来优化不同任务的性能设置，指出现有方法在应对隐私和计算资源变化时的局限性，并提出了新的优化策略。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20666", "html_url": "https://arxiv.org/abs/2510.20666", "title": "基于混合CNN和路径损耗混合专家的贝叶斯干扰器定位", "title_en": "Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of Experts", "authors": "Mariona Jaramillo-Civill,Luis González-Gudiño,Tales Imbiriba,Pau Closas", "background": "全球导航卫星系统（GNSS）信号在城市区域内尤为脆弱，因多路径效应和阴影效应导致接收信号强度（RSS）波动较大。先前的数据驱动方法在实现局部化方面效果良好，但在构建RSS场方面由于缺乏空间上下文的效果欠佳。", "innovation": "提出了一种贝叶斯混合专家混合模型，该模型融合了物理路径损耗（PL）模型和卷积神经网络（CNN），通过对数线性聚合实现。物理路径损耗专家确保物理一致性，而CNN则利用建筑高度图捕捉城市传播效应。使用拉普拉斯近似进行贝叶斯推理为干扰器位置和RSS场提供后验不确定性。", "conclusion": "实验表明，随着训练点数量的增加，定位精度提高且不确定性降低；不确定性集中发生在干扰器附近和城市峡谷区域，因为该区域的传播效果最敏感。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20651", "html_url": "https://arxiv.org/abs/2510.20651", "title": "xTime：基于层次知识蒸馏和专家融合的极端事件预测", "title_en": "xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion", "authors": "Quan Li,Wenchao Yu,Suhang Wang,Minhua Lin,Lingwei Chen,Wei Cheng,Haifeng Chen", "background": "在现实世界的时间序列中经常出现极端事件，这些事件对实际操作具有重要影响。在如气候和医疗保健等众多领域，例如洪水、热浪或急性医疗期等极端事件可能导致严重后果。因此，如何准确预测这些极端事件的重要性不言而喻。现有的大多数时间序列预测模型更注重整体预测窗口内的性能优化，但往往不能准确预测如高温或心率激增等极端事件。主要挑战在于数据不均衡以及忽视了那些出现于极端事件之前的有意义的信息。", "innovation": "本文提出了xTime，一种新颖的极端事件预测框架。xTime通过知识蒸馏的方法从较少发生的极端事件中转移信息，提升罕见事件的预测性能。此外，还引入了专家模型的混合机制（MoE），动态选择和融合不同罕见级别专家模型的输出，进一步提高极端事件的预测性能。", "conclusion": "在多个数据集上的实验结果显示，xTime能够取得一致的改进，极端事件的预测准确性提高3%到78%。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20668", "html_url": "https://arxiv.org/abs/2510.20668", "title": "从面罩到世界：世界模型的指南", "title_en": "From Masks to Worlds: A Hitchhiker's Guide to World Models", "authors": "Jinbin Bai,Yu Lei,Hecong Wu,Yuchen Zhu,Shufan Li,Yi Xin,Xiangtai Li,Molei Tao,Aditya Grover,Ming-Hsuan Yang", "background": "本文并不是对世界模型的全面综述，而是一篇针对希望构建世界的人的指导手册。它不追求列出所有提到过“世界模型”的每一项研究，而是沿着一条清晰的道路展开：从初期统一了跨模态表示学习的掩码模型，到共享单一范式的统一架构，接着是闭合了感知和行动循环的生成模型，最后是能够维持时间一致性世界的记忆增强系统。.", "innovation": "本文重点介绍了生成核心、交互循环和记忆系统，认为这是最有可能引领真正世界模型发展的路径。", "conclusion": "总结而言，这是通往真正世界模型最有希望的道路。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20644", "html_url": "https://arxiv.org/abs/2510.20644", "title": "连接Jensen-Shannon散度和Kullback-Leibler散度：用于表示学习的新边界", "title_en": "Connecting Jensen-Shannon and Kullback-Leibler Divergences: A New Bound for Representation Learning", "authors": "Reuben Dorent,Polina Golland,William Wells III", "background": "互信息（MI）是一个广泛应用在表示学习中的统计依赖基本度量。虽然直接通过其定义作为KL散度（KLD）进行优化通常是不可行的，最近的方法大多通过判别损失最大化替代的依赖度量，其中最著名的是联合分布与边际分布乘积的JSD。然而，这些替代目标与MI之间的连接关系并不清楚。本文通过推导新的、紧致且可解的JSD函数的KLD下界，填补了该知识缺口。具体地，通过对联合和边际分布应用此边界，作者证明了最大化基于JSD的信息会增加互信息的一个保证下界，同时，重新审视了JSD目标的实现，并观察到通过训练一个二分类器来区分联合和边际对，最小化其交叉熵损失能恢复到一个已知的JSD变分下界。各种实验表明，在互信息估计中应用我们的下界是紧致的，我们的下界估计器在各种参考场景中提供了稳定且低方差的估计，并且还展示了其在信息瓶颈框架中的实用价值。", "innovation": "本文的主要创新在于推导了一个新的、紧致且可解的JSD下界来替代KLD的下界，通过此边界函数，最大化基于JSD的信息能增加互信息的一个保证下界。此外，还重新审视了JSD目标的实现，发现利用二分类器和最小化交叉熵损失能够恢复到已知的JSD变分下界。", "conclusion": "实验结果表明，我们提出的边界即使应用于互信息估计，也是紧致的。相比于变分下界的标准神经估计算法，我们的边界估计器持续提供稳定且低方差的互信息下界估计，并证明了其在信息瓶颈框架中的实用性。综上所述，本文的结果为基于判别学习的方法提供了新的理论依据和扎实的实证支持。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20671", "html_url": "https://arxiv.org/abs/2510.20671", "title": "GRACE: 基于图的成瘾护理预测", "title_en": "GRACE: GRaph-based Addiction Care prEdiction", "authors": "Subham Kumar,Prakrithi Shivaprakash,Koustav Rudra,Lekhansh Shukla,Animesh Mukherjee", "background": "确定适合成瘾患者的治疗场所是临床决策中最重要的考虑因素之一，这直接影响到患者的治疗效果和资源的有效利用。在缺乏足够的专业治疗资源（如住院床位或人力资源）的情况下，开发一个自动化框架来解决这个问题变得尤为迫切。然而，现有的决策方法在成瘾数据集中存在严重的类别不平衡问题。", "innovation": "该研究提出了一种新颖的图神经网络（GRACE）框架，将治疗场所预测问题形式化为结构化学习问题。此外，进行了广泛的功能工程，并提出了一种新的方法来获得一个无偏的元图，用于训练GNN以克服类别不平衡问题。实验结果表明，与竞品基准相比，在真实世界数据上的F1分数提高了11-35%，尤其是在少数类别上。", "conclusion": "该研究在真实世界数据中实现了分类性能的显著提升，证明了GRACE框架的有效性，并为开发自动化决策支持系统以指导成瘾治疗场所的应用奠定了基础。源代码和笔记嵌入可在指定的网址处获取。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20718", "html_url": "https://arxiv.org/abs/2510.20718", "title": "使用N-BEATS和图神经网络的多变量半导体工艺时间序列无监督异常预测", "title_en": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series", "authors": "Daniel Sorensen,Bappaditya Dey,Minjin Hwang,Sandip Halder", "background": "半导体制造是一个极其复杂且精密的过程，涉及成千上万的参数，这些参数在多种工具和工艺步骤中相互关联。多变量时间序列分析已成为实时监控和故障检测的关键领域。然而，在半导体制造中进行异常预测面临多重挑战，如传感器数据的高维度和严重类不平衡（由于实际故障罕见），以及变量之间的复杂相互依赖性，这使得异常预测和根本原因分析都变得复杂。", "innovation": "本文提出了两种新颖的方法，从异常检测转向异常预测，以实现实时过程修正和预防性故障预防。这两种方法在异常预测框架的训练模型阶段有所不同，第一种方法假设变量间独立，并利用N-BEATS模型进行单变量时间序列预测；第二种方法捕捉变量间关系，利用图神经网络（GNN）。实验结果表明，GNN在预测性能和异常检测稳定性方面优于N-BEATS模型，同时需要较少的可训练参数和计算成本。", "conclusion": "GNN表现出优异的时间序列预测能力，为在线异常预测提供了一个有希望的解决方案，适用于制造环境。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20683", "html_url": "https://arxiv.org/abs/2510.20683", "title": "一种基于神经元脉冲网络的可扩展、因果且能效高的神经解码框架", "title_en": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding with Spiking Neural Networks", "authors": "Georgios Mentzelopoulos,Ioannis Asmanis,Konrad P. Kording,Eva L. Dyer,Kostas Daniilidis,Flavia Vitale", "background": "脑-计算机接口（BCIs）有望为神经运动功能受损的个体提供生命功能，如语音和假肢控制。这些接口的成功关键在于神经解码器，即能够将神经活动映射到预期行为的模型。目前的基于学习的解码方法分为两类：一类是简单、因果的模型，缺乏泛化能力；另一类是复杂的、非因果的模型，虽然具有泛化能力和可扩展性，但很难实现实时应用。无论是哪类方法都面临着一个共同的挑战，即依赖于耗电量大的人工神经网络结构，这使得将其集成到资源受限的真实世界系统中变得困难。神经脉冲网络（SNNs）作为一种有潜力的替代方案，因其能够实现实时使用且能量需求低，非常适合电池受限的环境。", "innovation": "本文介绍了一种基于SNNs的可扩展、因果且能效高的神经解码框架——Spikachu。该方法将分桶的神经脉冲直接投影到共享的潜在空间中，通过适应输入时间的突触模块提取相关信息特征，再将这些潜在表示整合和解码以生成行为预测。Spikachu方法在单次会话训练下能量消耗比因果基准方法低2.26到418.81倍，同时展示了多会话和多主体训练可以提高性能并实现未见过的会话、主体和任务的零样本迁移。", "conclusion": "总体而言，Spikachu提出了一种基于SNNs的可扩展且能在线兼容的神经解码框架，相比最先进的模型，其性能相当，并且消耗的能量数量级低得多。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20714", "html_url": "https://arxiv.org/abs/2510.20714", "title": "优化临床跌倒风险预测：约翰斯霍普金斯跌倒风险评估工具与电子健康记录变量的数据驱动整合", "title_en": "Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool", "authors": "Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Kimia Ghobadi", "background": "本研究旨在通过数据驱动建模方法更好地将约翰斯霍普金斯跌倒风险评估工具（JHFRAT）的风险预测与临床相关措施对接。研究者回顾分析了2022年3月至2023年10月约翰斯霍普金斯健康系统三所医院的54,209例住院记录，其中20,208例被认定为高跌倒风险病例，13,941例为低跌倒风险病例。", "innovation": "研究采用了受限评分优化（CSO）模型整合JHFRAT评估数据和附加的电子健康记录（EHR）变量。CSO模型在预测性能上显著优于现行的JHFRAT（CSO AUC-ROC=0.91，JHFRAT AUC-ROC=0.86），即使在没有EHR变量的情况下，CSO模型的表现也同样稳定。尽管基准的黑盒模型（XGBoost）在性能指标上优于基于知识的约束逻辑回归（AUC-ROC=0.94），但CSO模型对风险标签变化的鲁棒性更强。", "conclusion": "证据基于的方法为卫生系统提供了系统提升住院病人跌倒预防计划和病人安全、利用数据驱动优化技术改进风险评估和资源配置提供了坚实的依据，有助于提高医疗机构的风险管理和资源分配效果。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20725", "html_url": "https://arxiv.org/abs/2510.20725", "title": "高斯过程下的有限时间马尔可夫决策过程的无遗憾托马斯采样", "title_en": "No-Regret Thompson Sampling for Finite-Horizon Markov Decision Processes with Gaussian Processes", "authors": "Jasmine Bayrooti,Sattar Vakili,Amanda Prorok,Carl Henrik Ek", "background": "托马斯采样（TS）是一个强大的策略，广泛应用于序贯决策问题，包括贝叶斯优化和强化学习（RL）。尽管TS在实践中表现良好，但在具有复杂时间结构的RL场景中，其理论基础仍然有限。本文通过使用具有高斯边缘分布的模型，为TS建立了无遗憾保证，特别是在使用联合高斯过程（GP）先验对于回报和转移的RL环境中。研究成果旨在解决价值函数非高斯性质和贝尔曼更新的递归结构带来的挑战，同时扩展了椭圆势引理等经典工具到多输出设置。", "innovation": "该研究通过引入联合高斯过程先验，使用具有高斯边缘分布的模型，为托马斯采样在RL场景中提供了无遗憾保证，提出了新的算法框架和理论分析方法，填补了TS在复杂时间结构中的理论空白。", "conclusion": "本文通过建立基于高斯过程的托马斯采样在有限时间马尔可夫决策过程中的无遗憾保证，为托马斯采样在RL应用场景中的理论基础提供了新的见解，并强调了结构假设和模型不确定性如何影响其在有限 horizons 状态下的表现。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20709", "html_url": "https://arxiv.org/abs/2510.20709", "title": "分离组成计算的what和how以实现重用与持续学习", "title_en": "Separating the what and how of compositional computation to enable reuse and continual learning", "authors": "Haozhe Shan,Sun Minni,Lea Duncker", "background": "持续学习、技能保持及灵活重组对于智能高效行为至关重要，但其神经机制尚不明确。该研究使用一种新的两系统方法，在递归神经网络（RNN）模型中研究了持续学习和技能组成的再利用问题。该方法分别处理执行什么（what）和如何执行（how）问题，集中在一系列常见的组成认知任务上。研究表明，这些任务可以通过概率生成模型系统描述，并具有共享的基任务周期结构，从而内在地成为组成性的。通过无监督在线学习方法，系统能够在单次试炼的基础上学习这种模型，并在其接触到新任务时逐渐构建其词汇，并通过推断时间变化的计算上下文来学习和重组较低秩的RNN组件，从而实现持续学习而无灾难性遗忘。", "innovation": "研究提出了一种新的两系统方法，分别处理任务执行（what）和执行策略（how）。基于概率生成模型，可以系统描述任务组成的结构。研究发展了一种无监督在线学习方法，能够在单次试炼的基础上逐步构建语言词汇，并通过推断时间变化的上下文来实现任务重组。新的RNN组件是根据what系统推断出的上下文进行组合的，这使得在引入新的任务时可以快速创建、学习和重组低秩RNN组件，而无需灾难性遗忘。研究还展示了该两系统学习框架的有效性和竞争性能，以及其在前向和后向转移以及对未见过任务的快速组成泛化能力。", "conclusion": "该研究提供了一种新的两系统学习框架，分别处理任务的执行（what）和执行策略（how）。通过无监督在线学习方法，可以实现任务的快速重组和持续学习而不发生灾难性遗忘。研究展示了该方法的有效性和在多种认知任务上的竞争力，以及其对未见过任务的快速泛化能力。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20762", "html_url": "https://arxiv.org/abs/2510.20762", "title": "MEIcoder: 通过利用最令人兴奋的输入解码神经活动来解码视觉刺激", "title_en": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs", "authors": "Jan Sobotka,Luca Baroni,Ján Antolík", "background": "从神经群体活动中解码视觉刺激对于理解大脑和脑机接口的应用至关重要。然而，生物数据往往稀少，特别是在灵长类动物或人类中，采用两项成像等高通量记录技术仍然具有挑战性甚至不可能实现，这反过来又给深度学习解码技术带来了挑战。", "innovation": "我们引入了MEIcoder，一种基于生物信息的解码方法，它利用了神经元特异的最令人兴奋的输入（MEIs）、一种结构相似性指数测量损失以及对抗性训练。MEIcoder在基于初级视觉皮层（V1）的单细胞活动重构中取得了最先进的性能，特别是在小数据集和更少记录的神经元数量方面表现出色。通过消融研究我们展示了MEIs是主要的性能驱动因素，而扩展实验表明，MEIcoder可以从1,000-2,500个神经元和不到1,000个训练数据点重构高质量的自然图像。我们还提出了一个包含超过160,000个样本的统一基准，以促进未来的研究。", "conclusion": "我们的结果证明了在早期视觉系统中可靠解码的可行性，并为神经科学和神经工程应用提供了实用的见解。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20733", "html_url": "https://arxiv.org/abs/2510.20733", "title": "多智能体协作中的思维通信", "title_en": "Thought Communication in Multiagent Collaboration", "authors": "Yujia Zheng,Zhuokai Zhao,Zijian Li,Yaqi Xie,Mingze Gao,Lizhu Zhang,Kun Zhang", "background": "自然语言长期以来使人类得以合作，但其信息损失、模糊性及间接性限制了集体智能的潜力。虽然机器不受这些限制，但大多数基于大语言模型的多智能体系统仍然依赖自然语言进行交流，通过交换标记或其嵌入来进行信息传递。本文提出了“思维通信”这一新的范式，让智能体能够直接心心相通，类似于心灵感应，从而超越了自然语言的局限。通过正式化思维生成模型，本文揭示了智能体状态背后的潜在思想，证明在没有辅助信息的情况下，可以识别出智能体间的共享和私有潜在思想。此外，也能恢复其整体的思维共享结构，这些理论上都有保障。", "innovation": "本文引入了“思维通信”这一创新性范式，让智能体能够直接心心相通。通过构建一般化的潜在变量模型，能够从所有智能体中提取潜在的思想，并将相关的思想及其共享模式分配给每个智能体。此外，该范式适用于所有模态类型的数据，因为大多数观察数据源于潜在的生成过程。实验结果表明了理论的有效性和思维通信协作的优势。", "conclusion": "本文的研究为利用隐藏世界提供了新的视角，许多挑战仅凭表面层的观察无法解决，这不限于计算能力和数据量。思维通信范式揭示了智能体之间的潜在思想，为多智能体协作带来了潜在的优势，实验结果验证了理论的有效性和范式的优势。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20736", "html_url": "https://arxiv.org/abs/2510.20736", "title": "通过变分狄利克雷过程放大多模态学习中的显著表征", "title_en": "Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process", "authors": "Tsai Hor Chan,Feng Wu,Yihang Chen,Guosheng Yin,Lequan Yu", "background": "在众多实际场景中，如医疗保健和金融，开发有效的多模态融合方法变得越来越重要。关键挑战在于如何在学习跨模态交互的同时保持每个模态的特征表达能力。虽然先前的方法主要关注跨模态对齐，但过度强调模态边缘分布的对齐可能导致过多的正则化，从而妨碍每个模态内的有意义表示。狄利克雷过程混合模型是一种强大的贝叶斯非参数方法，具有丰富的性质，可以通过增加分配给显著特征的权重来突出这些特征。受此独特特性的启发，我们提出了一种新的基于狄利克雷过程的多模态学习框架，该框架可以自动平衡显著的模内表征学习与跨模态对齐之间的最优比例。", "innovation": "提出了一种新的基于狄利克雷过程的多模态学习框架，该框架通过利用狄利克雷过程的丰富性质，自动平衡模内显著表征学习与跨模态对齐之间的关系，动态地分配特征贡献并选择最显著的特征。实验表明，该模型在多个多模态数据集上的性能优于其他竞争模型，且裕度分析进一步验证了DP在对齐模态分布和对关键超参数更改的鲁棒性方面的有效性。", "conclusion": "通过广泛的实验验证了新的多模态框架的有效性，证明了基于狄利克雷过程的方法可以更好地执行模态间对齐和显著特征学习，从而优化跨模态融合。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20792", "html_url": "https://arxiv.org/abs/2510.20792", "title": "BadGraph：针对文本导向图生成的潜在扩散模型的后门攻击", "title_en": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation", "authors": "Liang Ye,Shengqin Chen,Jiazhu Dai", "background": "图生成的快速发展引发了新的安全担忧，特别是后门漏洞问题。尽管已有研究探索了图像扩散和无条件图生成中的后门攻击，但针对文本导向图生成的条件性攻击，尤其是基于文本指导的攻击仍处于研究空白。该文指出在关于文本导向的图生成模型中的潜在扩散模型中的后门攻击尚未被充分研究。", "innovation": "该文提出了BadGraph，一种针对潜在扩散模型的后门攻击方法，特别是针对文本导向的图生成。BadGraph利用文本触发器污染训练数据，在触发器出现时，在推理过程中隐秘地植入攻击者指定的子图，同时在未受污染的输入上保持正常的性能。实验结果表明，较低的污染率就能实现较高的攻击成功率：小于10%的污染率可实现超过50%的攻击成功率，而24%的污染率足以实现超过80%的攻击成功率，而且对良样本性能指标几乎没有降级影响。此外，研究表明后门是在VAE和扩散训练过程中植入的，而不是在预训练过程中。", "conclusion": "该研究揭示了文本导向的图生成模型中潜在扩散模型的安全漏洞，突显了模型在药物发现等应用中的严重风险，强调了在这些扩散模型中抵御后门攻击时需要采用更加稳健的防御措施。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20817", "html_url": "https://arxiv.org/abs/2510.20817", "title": "KL-正则化强化学习旨在模式塌陷", "title_en": "KL-Regularized Reinforcement Learning is Designed to Mode Collapse", "authors": "Anthony GX-Chen,Jatin Prakash,Jeff Guo,Rob Fergus,Rajesh Ranganath", "background": "人们普遍认为，在优化反向KL散度时会产生“模态聚类”效应，而在优化正向KL时则会产生“质量覆盖”效应。后者在样本多样性方面通常更受欢迎。然而，该论文指出这种直觉并不一定适用于使用反向/正向KL正则化进行强化学习（例如在语言模型中常用到的方法）。模态覆盖更多地取决于其他因素，如正则化强度、奖励和参考概率之间的相对比例等因素。", "innovation": "本文揭示了KL正则化强化学习中反向/正向KL的选择决定了最优目标分布的类别，并证明常用的设置，如低正则化强度和等比例验证奖励，倾向于指定单模目标分布。通过这些见解，研究者提出了一种简单的、可扩展的且具有理论依据的算法，该算法在最小修改奖励幅度的情况下，优化了对所有高质量采样模态概率高的目标分布。实验表明，该简单修改可用于训练大型语言模型和化学语言模型，提高解决方案的品质和多样性。", "conclusion": "最终，研究证明，无论使用正向还是反向KL正则化进行强化学习（当其单独使用时），都可能导致单一模式。使用新提出的算法可以优化加强对多样性的目标，尽管只微小修改了奖励幅度。实验结果表明，这种方法可以提高大型语言模型和化学语言模型的解决方案质量和多样性，无需外部多样性的信号，同时这两种情况都能有效工作。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20800", "html_url": "https://arxiv.org/abs/2510.20800", "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "title_en": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "authors": "Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus", "background": "Sharma等人的研究表明，精心选择大型语言模型（LLM）的权重矩阵的高阶成分进行剪枝，可以在无需任何基于梯度的微调的情况下提高下游任务的准确性。然而，LASER方法的全矩阵逐矩阵搜索（每次都需要全数据集前向传递）使其不适合快速部署，因而存在效率较低的问题。", "innovation": "本文提出了一个新的方法，简化了LASER方法的流程。具体创新有四个方面：(i) 只需检查少量精心选择的矩阵；(ii) 每个矩阵的奇异值的梯度可以指示哪些需要减少的矩阵；(iii) 扩大因子分解搜索空间，使矩阵行围绕多个子空间进行聚类并单独分解，进一步减少过拟合并提高24.6个百分点的准确性；(iv) 在100个样本上执行单一梯度步骤而不是全训练数据，以减少搜索时间，发现下游任务的适应更多取决于提示风格而非数据集大小。这种迅速适应算法展示了无需微调即可快速适应新数据集的可能性。", "conclusion": "本文提出了一种快速而稳健的下游任务适配算法，通过在100个样本上执行单个梯度步骤和快速扫描顶级候选层及分解技术，可以在不需要微调的情况下使LLM适应新数据集。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20783", "html_url": "https://arxiv.org/abs/2510.20783", "title": "在离分布测试中，象棋转换器展现出了组合性", "title_en": "Out-of-distribution Tests Reveal Compositionality in Chess Transformers", "authors": "Anna Mészáros,Patrik Reizinger,Ferenc Huszár", "background": "象棋是一个需要严谨推理和长期规划的经典任务。现代决策Transformer在类似大语言模型的训练下，能够掌握有效的游戏玩法，但它们的规则理解是否准确仍不清楚。为了探究这一点，研究人员训练了一个具有270M参数的棋盘Transformer，并对其进行离分布环境测试，设计测试以揭示系统性泛化的失败。研究发现，Transformer在面对与训练数据不同的情况时，仍然能够遵循基本的规则，并且在离分布谜题中也产生了高质量的走法。进一步的测试则在包括棋盘布局随机化（Fischer Random Chess）等变体中评估模型表现，结果发现模型虽然在策略适应性方面表现基本，但明显不如进行明确搜索的符号AI算法，但在与Lichess用户对战时，差距较小。此外，训练动态显示，模型最初学会的只是移动属于自己的棋子，这暗示着模型对于游戏的组合理解是逐步形成的。", "innovation": "该研究训练了一个具有270M参数的棋盘Transformer，并通过设计特定的离分布测试场景，评估了其规则理解能力和策略适应性。研究还揭示了模型在处理特定变种（如棋盘布局随机化）时的表现，显示了组合理解的初步证据，以及最初学习行为的细节。这些结果都为理解棋盘Transformer的过程提供了新的见解，特别是在规则理解和策略适应性方面。", "conclusion": "研究发现，Transformer模型在面对与训练数据不同环境时，能够遵循基本规则，并生成高质量走法。尽管在处理特定变种时表现有所不足，但其表现优于对照组。模型学习初期只移动自己的棋子，表明了组合理解的逐步形成。这一研究为理解Transformer及其在离分布环境中的表现提供了新的视角。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19829", "html_url": "https://arxiv.org/abs/2510.19829", "title": "SSL-SE-EEG: A Framework for Robust Learning from Unlabeled EEG Data with Self-Supervised Learning and Squeeze-Excitation Networks", "title_en": "SSL-SE-EEG: A Framework for Robust Learning from Unlabeled EEG Data with Self-Supervised Learning and Squeeze-Excitation Networks", "authors": "Meghna Roy Chowdhury,Yi Ding,Shreyas Sen", "background": "脑电图（EEG）在脑-计算机接口（BCIs）和神经诊断中发挥关键作用，但在实际应用中面临噪声伪像、数据缺失和标签成本高的挑战。", "innovation": "引入了一种结合自监督学习（SSL）和Squeeze-and-Excitation（SE）网络的框架——SSL-SE-EEG。该框架能增强特征提取能力，提高抗噪声性能，减少对标注数据的依赖。通过将EEG信号转化为适合深度学习的结构化2D图像表示，SSL-SE-EEG超越了传统的EEG处理技术，适用于实时BCI应用。", "conclusion": "SSL-SE-EEG在MindBigData、TUH-AB、SEED-IV和BCI-IV数据集上的实验验证展示了先进的准确率（MindBigData为91%，TUH-AB为85%），表明它适合用于生物医学信号分析、神经工程和下一代BCIs。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17561", "html_url": "https://arxiv.org/abs/2510.17561", "title": "相关尖峰模型中的谱阈值及其部分最小 squares 的基本限制", "title_en": "Spectral Thresholds in Correlated Spiked Models and Fundamental Limits of Partial Least Squares", "authors": "Pierre Mergny,Lenka Zdeborová", "background": "该论文分析了两个高维数据通道中部分对齐的信号尖峰交叉协方差模型的严谨随机矩阵理论。这些模型出于多模态学习的动机，并构成了部分最小 squares (PLS) 方法的标准生成设置。PLS 是一种广泛应用但尚未得到充分理论发展的方法。在此之前，人们对这种设置下的 PLS 能力以及其与贝叶斯最优估计器之间的基本性能差距了解有限。本文利用随机矩阵理论分析探讨了 PLS 在这种情况下信号恢复的能力，并指出了 PLS 失败的 SNR 和相关性条件范围，尽管在理论上这是可行的。这些研究揭示了 PLS 的理论极限，并为针对高维可靠多模态推理方法的设计提供了指导。", "innovation": "1. 提供了 PLS 方法在尖峰交叉协方差模型中的准确拟合描述，特别是 highlighting Baik-Ben Arous-Peche（BBP）类型的相变现象。\n2. 精确描述了信号恢复能力的临界阈值，为 PLS 建立了理论框架。\n3. 指出了 PLS 和贝叶斯最优估计器之间的基本性能差距，有助于设计更优的信号恢复方法。", "conclusion": "该研究澄清了 PLS 的理论限制，并提供了解决高维多模态推理问题的关键见解，为未来的研究和实际应用提供了重要指导。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19832", "html_url": "https://arxiv.org/abs/2510.19832", "title": "边缘设备上的低延迟神经推理以实现EEG信号实时手写识别", "title_en": "Low-Latency Neural Inference on an Edge Device for Real-Time Handwriting Recognition from EEG Signals", "authors": "Ovishake Sen,Raghav Soni,Darpan Virmani,Akshar Parekh,Patrick Lehman,Sarthak Jena,Adithi Katikhaneni,Adam Khalifa,Baibhab Chatterjee", "background": "脑-计算机接口（BCIs）提供了恢复严重运动或言语障碍个体交流能力的途径。想象中的书写为字符级神经解码提供了一个直观的范例，连接人类意图与数字通信。侵入性方法如脑皮层电图（ECoG）虽然精度高，但手术风险限制了其广泛应用。非侵入性脑电图（EEG）方法更安全且更具可扩展性，但信号噪声比低、空间分辨率差，限制了其解码精度。这项工作展示了利用先进的机器学习和有效的EEG特征提取可以克服这些障碍，使便携式边缘设备上的实时高精度神经解码成为可能。", "innovation": "研究引入了一个名为EEdGeNet的混合架构，该架构结合了时间卷积网络和多层感知器，训练从经过预处理的EEG信号提取的特征。还通过减少特征数量显著降低了系统延迟，同时保持了高精度。研究结果表明，这种方法能够实现准确、低延迟、完全便携的非侵入式BCIs，支持实时通信。", "conclusion": "该研究证明了结合高级机器学习和有效EEG特征提取的边缘设备上的低延迟神经推理能够实现高精度的实时手写识别，且系统在NVIDIA Jetson TX2设备上表现良好，具有广泛的应用前景。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19854", "html_url": "https://arxiv.org/abs/2510.19854", "title": "利用多分辨率分析对热带气旋对流结构的分析以提供短期强度指导", "title_en": "Multi-Resolution Analysis of the Convective Structure of Tropical Cyclones for Short-Term Intensity Guidance", "authors": "Elizabeth Cucuzzella,Tria McNeely,Kimberly Wood,Ann B. Lee", "background": "准确的24小时内热带气旋（TC）短期强度预报对于大西洋TC盆地中的灾害减轻至关重要。由于大多数TC远离陆基观测网络发展，卫星图像对于监测这些风暴至关重要；然而，这些复杂的高分辨率空间结构对预报员在实时情况下进行定性解释提出了挑战。", "innovation": "我们提出了一个多分辨率分析（MRA）方法，通过离散波let变换来量化精细的TC结构，使数据分析师能够识别与快速强度变化强烈相关的物理意义的结构特征。此外，深度学习技术可以建立在此MRA之上，提供短期强度指导。", "conclusion": "多分辨率分析有助于量化TC的细微结构，进而通过识别物理相关的特征提高短期强度变化的预测准确性，同时为预报员提供可解释的指导。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19826", "html_url": "https://arxiv.org/abs/2510.19826", "title": "神经震颤：一种支持上肢肌肉功能的可穿戴支持设备", "title_en": "Neurotremor: A wearable Supportive Device for Supporting Upper Limb Muscle Function", "authors": "Aueaphum Aueawattthanaphisut,Thanyanee Srichaisak,Arissa Ieochai", "background": "本文介绍了一种融合传感器的可穿戴辅助设备原型，专门用于改善上肢（肱三头肌和拇短展肌）功能。该设备集成了表面肌电图（sEMG）、惯性测量单元（IMU）和弯曲/压力传感器，与M5StickC结合使用，配备了ESP32-S3计算中枢。在整个系统中，信号经过带通和陷波滤波处理，特征（如均方根值、平均动作幅度、零交叉点和4-12 Hz震颤带功率）按250毫秒窗口计算，并输入给INT8 TensorFlow Lite Micro模型。控制命令通过控制屏障函数的安全边界进行限制并在基于游戏的任务中实现轻量级个性化。", "innovation": "创新点在于该可穿戴设备融合了多种传感器技术，包括表面肌电图、惯性测量单元和弯曲/压力传感器，通过先进的信号处理和机器学习方法，实现了对上肢肌肉功能的有效辅助。该设备还采用了实时性能好的安全控制屏障函数，以确保用户安全，并且在用户进行日常活动时能够提供轻量级的个性化支持。设备可以在100 Hz的速度下运行，同时保持较低的延迟（8.7毫秒）和100%的会话完成率，没有设备相关的不良事件。", "conclusion": "该研究展示了嵌入式、传感器融合方法在上肢功能辅助中的技术可行性。未来预计将进行正式的患者研究，在IRB的监督下实施。通过收集来自12名健康志愿者的数据，结果显示使用该设备后，患者的震颤程度有所减轻，活动范围有所增加，重复动作次数增加，同时肌电图的中频斜率变得不那么负。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19838", "html_url": "https://arxiv.org/abs/2510.19838", "title": "Branch-and-Browse: 效率高且可控的基于树结构推理和行动记忆的网络探索", "title_en": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory", "authors": "Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury", "background": "自主网络代理由大型语言模型（LLMs）驱动，在执行目标导向任务（如信息检索、报告生成和在线交易）方面展现出强大的潜力。这些代理代表了在开放网络环境中进行实践性物理推理的关键步骤。然而，现有方法在推理深度和效率方面仍存在局限性：基本的线性方法在多步推理中失败且缺乏有效的回退机制，而其他搜索策略则过于粗糙并且计算成本高。", "innovation": "我们提出了Branch-and-Browse，这是一种细粒度的网络代理框架，结合了结构化的推理-行动、上下文记忆和高效的执行。该框架（i）通过树结构探索实现可控的多分支推理，并使用明确的子任务管理；（ii）通过高效地利用网页状态重放及其背景推理来启动探索；（iii）利用页面动作记忆在会话内部和跨会话共享已探索的动作。Branch-and-Browse在WebArena基准测试中达到了35.8%的任务成功率，并将执行时间最多降低了40.4%，比最先进的方法更可靠和高效。", "conclusion": "这些结果表明，Branch-and-Browse是一个可靠的、高效的框架，适用于基于LLM的网络代理。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19842", "html_url": "https://arxiv.org/abs/2510.19842", "title": "DAG-Math: 在LLMs中的图引导数学推理", "title_en": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs", "authors": "Yuanhe Zhang,Ilja Kuzborskij,Jason D. Lee,Chenlei Leng,Fanghui Liu", "background": "大型语言模型（LLMs）在受到逐步推理（CoT）提示时表现出强大的数学问题解决能力，但其成功的原因尚不清楚，可能是基于搜索、死记硬背的程序或规则一致的推理。为了应对这一问题，研究提出将CoT建模为定向无环图（DAG）上的确定性基于规则的随机过程，通过这种方法，引入了逻辑接近度的度量，该度量量化了模型生成的CoT路径是否符合DAG结构，从而提供了超越传统PASS@k度量的评估手段。在此基础上，提出了DAG-MATH CoT格式，并构建了一个基准来引导LLMs以这种格式生成CoT路径，从而能够评估其在这一框架下的推理能力。", "innovation": "提出了一种新的框架，将CoT建模为DAG上的确定性规则过程，并引入逻辑接近度作为评估LLMs推理能力的度量。基于此，研究者创建了DAG-MATH CoT格式和相应的基准，指导LLMs生成符合该格式的CoT轨迹，从而更全面地评估其推理能力。研究揭示了不同LLM家庭在不同类型推理准确性上的统计学差异，即使在最终答案准确性相似的情况下，也存在规则一致性推导方面的差距。这种框架在提供CoT自由格式与正式证明系统之间平衡的同时，为评估LLMs推理提供了可操作的诊断工具。提供了一个可用的基准和代码。", "conclusion": "通过对标准数学推理数据集的分析，研究发现即使是当PASS@k相似的情况下，LLMs在规则一致推导上的准确性存在差异，强调了最终答案精度和规则一致推导之间的差距。提出的框架在提供CoT自由格式与正式证明系统之间的平衡的同时，提供了评估LLMs推理能力的平衡手段，其基准和代码已对外发布。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19864", "html_url": "https://arxiv.org/abs/2510.19864", "title": "SODBench: 大型语言模型在记录电子表格操作方面的研究", "title_en": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations", "authors": "Amila Indika,Igor Molybog", "background": "众多知识工作者使用电子表格进行商业、会计和财务工作。然而，缺乏系统化的电子表格文档方法阻碍了自动化、协作和知识转移，这可能导致关键的机构知识丢失。已有许多研究使用大型语言模型（LLMs）生成电子表格操作代码，但将这些代码翻译成自然语言进行文档说明是一个较少探讨的领域。", "innovation": "本文提出了电子表格操作文档（SOD），涉及从电子表格操作生成人类可读的解释的任务，并构建了一个包含111个电子表格操作代码片段及其自然语言摘要的基准数据集，评估了五种不同的LLMs，以验证其生成准确的电子表格文档的能力，并探讨了提高可重复性、可维护性和协作工作流程的方法。这种方法有助于增强电子表格领域的工作流程。", "conclusion": "大型语言模型能够在记录电子表格操作方面发挥作用，虽然仍存在一些挑战，但SOD是一项可行的前置步骤，可以提升电子表格的可重复性、可维护性和协作工作流程。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19867", "html_url": "https://arxiv.org/abs/2510.19867", "title": "由人工智能驱动的在榕树中对潜在抗糖尿病化合物的识别", "title_en": "Artificial Intelligence Powered Identification of Potential Antidiabetic Compounds in Ficus religiosa", "authors": "Md Ashad Alam,Md Amanullah", "background": "糖尿病是一种需要新型治疗方法的慢性代谢疾病，由于其逐渐发展和各种代谢并发症的出现。研究表明，榕树是一种传统药用植物，能够产生具有潜在抗糖尿病活性的生物活性植物化学物质。本研究通过基于生态系统的计算方法利用人工智能来研究和评估榕树中具有抗糖尿病活性的化合物。", "innovation": "引入了人工智能加速筛选程序，并提高了准确率，证明了其在研究基于植物的抗糖尿病剂中的有效性。利用深度学习技术和分子对接技术，成功识别出黄酮类和生物碱等活性植物化学物质，并通过人工智能加速的筛选过程提高了研究的准确性和效率。", "conclusion": "利用基于人工智能的计算方法，已经成功评估了榕树中的有效植物化学物质对抗糖尿病酶DPP-4的活性。未来将基于这一科学基础进行实验证实，以发展适合糖尿病管理的天然产品疗法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19882", "html_url": "https://arxiv.org/abs/2510.19882", "title": "量化在线内容审核特征的重要性", "title_en": "Quantifying Feature Importance for Online Content Moderation", "authors": "Benedetta Tessa,Alejandro Moreo,Stefano Cresci,Tiziano Fagni,Fabrizio Sebastiani", "background": "准确估计用户对审核干预的响应对于制定有效的、用户中心化的审核策略至关重要。然而，这需要对哪些用户特征与不同的行为响应相关有清晰的理解，这是本文研究的目标。研究通过分析753个社会行为、语言、关系和心理特征来预测受到Reddit大规模审核干预影响的16800名用户的行为变化。", "innovation": "本文通过量化特征的重要性来解决上述问题。研究采用了贪婪特征选择策略，不仅识别了预测用户活动、毒性及参与度变化最有效的特征，还估计了这些特征的重要性。结果表明，尽管存在某些特征对所有任务都具有稳健性，但大多数特征要么仅适用于特定任务，要么整体上作用有限。此外，预测性能因任务而异，活动和毒性变化更容易估计，但多样性变化则较为困难。", "conclusion": "研究结果为开发准确预测用户对审核干预反应的系统铺平了道路。此外，研究还揭示了后审核用户行为的复杂性，表明有效审核不仅应针对用户特征，还应根据干预的具体目标进行定制。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19887", "html_url": "https://arxiv.org/abs/2510.19887", "title": "压缩生物学：评估Stable Diffusion VAE在表型药物发现中的应用", "title_en": "Compressing Biology: Evaluating the Stable Diffusion VAE for Phenotypic Drug Discovery", "authors": "Télio Cropsal,Rocío Mercado", "background": "高通量表型筛选生成了大量的显微镜图像数据集，这些数据集由于其高维度而对生成模型构成了挑战。尽管在显微镜数据分析中使用通用模型的自然图像数据集培训变得越来越流行，但在该领域的实际适用性尚未通过量化方法得到证明。", "innovation": "本研究首次系统地评估了Stable Diffusion的变分自动编码器（SD-VAE）在重建Cell Painting图像中的效果。通过比较像素级别、嵌入空间、潜在空间和检索基线等多种生物信息评估方法，展示了通用特征提取器如InceptionV3在检索任务中的性能可与公开的专用模型相当，从而简化未来的处理流程。", "conclusion": "研究结果提供了对生成模型在显微镜数据上的评估指南，并支持使用现成的模型用于表型药物发现。这些发现为评估显微镜数据生成模型提供实际指导，并促进了生物表型药物发现中现成模型的应用。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19890", "html_url": "https://arxiv.org/abs/2510.19890", "title": "基于序列到序列模型的GNSS欺骗检测", "title_en": "Deep Sequence-to-Sequence Models for GNSS Spoofing Detection", "authors": "Jan Zelinka,Oliver Kost,Marek Hrúz", "background": "论文背景在于现有 GNSS（全球定位系统）欺骗检测方法往往存在检测延迟大、准确性不高的问题。本文旨在提出一种数据生成框架，模拟欺骗攻击并随机布置世界各地的攻击场景，进而使用深度神经网络模型进行欺骗检测，目标是提高检测的实时性和准确性，尤其是使用基于长短期记忆网络（LSTM）和受变压器启发的架构的模型进行在线检测。", "innovation": "论文的创新点包括设计了一种基于深度学习的欺骗检测框架，使用生成的数据集进行训练。具体创新如利用 LSTMs 和变压器启发的架构，特别是早期融合输入的方法，能够显著提高欺骗信号与真实信号区别的准确性，最终错误率降低到 0.16%，展示了深度学习模型在 GNSS 欺骗检测领域的巨大潜力和优势。", "conclusion": "论文结论指出了基于变压器启发的模型在欺骗检测中的优异性能，并展示了其在准确区分真实和欺骗信号方面的能力。此外，提出的框架和方法为进一步研究 GNSS 欺骗防御技术提供了重要参考。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19954", "html_url": "https://arxiv.org/abs/2510.19954", "title": "RELATE: 一种Schema-无关的Perceiver编码器用于多模态关系图", "title_en": "RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs", "authors": "Joseph Meyer,Divyansha Lachi,Reza Mohammadi,Roshan Reddy Upendra,Eva L. Dyer,Mark Li,Tom Palczewski", "background": "在电子商务、医疗保健和科学研究等领域中，关系多表数据非常普遍，可以通过具有多模态节点属性的异构时间图自然表示。现有的图神经网络（GNNs）依赖于特定于模式的特征编码器，需要为每个节点类型和特征列设计单独的模块，这限制了其扩展性和参数共享。", "innovation": "我们引入了RELATE（关系编码器，用于有类型实体的潜在聚合），一种无需特定模式的插拔式特征编码器，它可以与任何通用图神经网络结合使用。RELATE采用共享的模态特定编码器来处理分类、数值、文本和时间属性，随后通过Perceiver风格的交叉注意模块将特征整合成一个固定大小的、置换不变的节点表示。", "conclusion": "我们在RelBench基准上评估了RELATE在ReLGNN和HGT中的性能，发现它的性能与特定于模式的编码器相差不超过3%，同时参数量减少了最高5倍。这种设计支持可变模式变化，并启用了通用图神经网络的多数据集预训练，为关系图数据奠定了基础模型的道路。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19967", "html_url": "https://arxiv.org/abs/2510.19967", "title": "LyriCAR：一种基于难度感知的课程强化学习框架，用于可控歌词翻译", "title_en": "LyriCAR: A Difficulty-Aware Curriculum Reinforcement Learning Framework For Controllable Lyric Translation", "authors": "Le Ren,Xiangjian Zeng,Qingqiang Wu,Ruoxuan Liang", "background": "歌词翻译是一个具有挑战性的任务，需要平衡多种音乐约束。现有的方法往往依赖于手工地规则和句子级别的建模，这些方法限制了它们在段落级别上理解和内化音乐语言模式的能力，特别是在跨行连贯性和全局韵律方面。", "innovation": "提出了一种名为LyriCAR的新颖框架，实现了完全无监督模式下的可控歌词翻译，并引入了一种难度感知的课程设计师和自适应课程策略，确保更高效的训练资源分配，加快收敛速度，并通过逐步增加复杂度来指导模型，从而提高整体翻译质量。特别是，自适应课程策略使训练步骤减少了近40%，同时保持了优越的性能。此外，LyriCAR在英文到中文的歌词翻译任务中实现了最先进的结果，其效果优于强大的基线模型，并且在多维度奖励分数方面也表现出色。", "conclusion": "经过广泛的实验表明，LyriCAR在标准翻译指标和多维度奖励分数方面均实现了最先进的结果，优于强有力的基线模型，并且使用自适应课程策略将训练步骤减少了近40%，但仍保持了优越的性能。完整的代码、数据和模型可以从该网址获取：this https URL"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19870", "html_url": "https://arxiv.org/abs/2510.19870", "title": "使用GANs变革多组学整合：在阿尔茨海默病和癌症中的应用", "title_en": "Transforming Multi-Omics Integration with GANs: Applications in Alzheimer's and Cancer", "authors": "Md Selim Reza,Sabrin Afroz,Mostafizer Rahman,Md Ashad Alam", "background": "多组学数据整合对于理解复杂疾病至关重要，但受限于样本量有限、噪音和异质性，这往往降低了预测能力。为了解决这些问题，本研究介绍了一种基于生成对抗网络（GAN）的框架Omics-GAN。该框架旨在生成高质量的合成多组学资料，同时保留生物学关系。该研究使用RNA测序（mRNA）、microRNA测序（miRNA）和DNA甲基化（DNA methylation）三种类型的多组学数据，应用于阿尔茨海默病（AD）的ROSMAP队列和结直肠癌及肝癌的TCGA数据集。实验证明，合成数据集在所有疾病中的预测准确性均优于原始组学资料，特别是在阿尔茨海默病、肝癌和结直肠癌的预测中分别提高了约3%、7%和5%的AUC值，并且通过对统计分布、噪音和异常值的影响，合成数据保留了生物一致性，进一步通过功能选择和GO及KEGG富集分析确认了重要基因，同时使用分子对接提出了潜在的药物再利用候选物，如阿尔茨海默病的尼洛替尼、肝癌的阿托伐醌和结直肠癌的特科维他。", "innovation": "Omics-GAN是一种基于GAN的数据生成模型，该模型能够生成高质的多组学合成资料，保持生物相关性，同时增加疾病预测的准确性。本研究通过跨验证的SVM分类器评估了合成数据集相较于原始组学数据集在疾病的预测表现的提升。同时，通过生物功能选择和额外的GO及KEGG富集分析发现了重要基因并进一步通过分子对接提出了潜在的药物再利用候选物。这种基于GAN的数据生成方法为精准医疗提供了可扩展的策略。", "conclusion": "Omics-GAN不仅提高了疾病预测的准确性，还保留了生物忠实性，加速了生物标志物和药物的发现。研究表明，该方法在阿尔茨海默病、肝癌和结直肠癌中均有效，并且提供了针对这些疾病的新药物再利用候选物。这种方法为精准医疗应用提供了可扩展的解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19897", "html_url": "https://arxiv.org/abs/2510.19897", "title": "基于语义和episode记忆从监督中学习：一种代理适应的反思性方法", "title_en": "Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation", "authors": "Jackson Hassell,Dan Zhang,Hannah Kim,Tom Mitchell,Estevam Hruschka", "background": "本文探讨了如何基于大规模预训练语言模型构建的代理从标定的样例中学习目标分类功能，而不进行参数更新。传统的微调等方法虽然有效，但也常常因成本高、灵活性差和不透明性而受到限制。我们的研究旨在提出一种结合了有标签数据和由大型语言模型生成的批评的新框架，利用情节记忆存储具体的经验，并通过语义记忆提炼出可重用的、任务导向的指导方案。在各种任务中，这种框架通过把反馈纳入其中，相对依赖检索式基线方法（如RAG风格）可以带来高达24.8个百分点的准确率提升。此外，本文通过广泛的实证研究，揭示了开源和商业模型在处理事实导向与偏好导向数据时的不同表现。", "innovation": "提出了一种记忆增强框架，该框架利用情节记忆存储具体的过往经验，并通过语义记忆提炼出任务级别的指导。通过引入新型衡量模型对监督不同表示感知能力的指标，‘可暗示性’，解释了模型的反应行为，阐明了模型特性和记忆策略如何共同影响学习动态。这种方法对于构建更灵活和可解释的语言模型代理具有巨大潜力。", "conclusion": "本文的研究表明，基于记忆的反思性学习方法对于构建更具适应性和可解释性的大型语言模型代理具有巨大潜力。通过将有标签数据与大型语言模型生成的批评相结合，新的框架不仅提高了准确率，还揭示了开源和商业模型在不同任务处理中的行为差异。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19999", "html_url": "https://arxiv.org/abs/2510.19999", "title": "改进的循环坐标下降方法用于弹性网惩罚线性模型", "title_en": "Enhanced Cyclic Coordinate Descent Methods for Elastic Net Penalized Linear Models", "authors": "Yixiao Wang,Zishan Shao,Ting Jiang,Aditya Devarakonda", "background": "本文介绍了一种名为增强循环坐标下降（ECCD）的新框架，用于求解具有弹性网约束的一般化线性模型。这种框架相比于现有最先进的方法可以减少训练时间。", "innovation": "重新设计了循环坐标下降（CD）方法，通过在当前迭代点周围进行泰勒展开来避免梯度计算中的非线性操作，引入了近似方法来取消循环运算，并将结果计算重新组织成更高效的批量计算。通过一个可调整的整参数$s$，可以剪辑循环，而$s > 1$可以提供性能改进，不影响收敛性，且$s = 1$则恢复原始的CD方法。ECCD的一个关键优势在于它避免了块循环坐标下降方法中的收敛延迟和数值不稳定性。", "conclusion": "我们的方法在使用C++和Eigen实现后，在各种基准数据集上对弹性网惩罚线性模型的正则化路径版本的一致性能改进为平均3倍。我们的实现可在以下链接中获得： this https URL."}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19979", "html_url": "https://arxiv.org/abs/2510.19979", "title": "SecureInfer: 异构 TEE-GPU 架构用于大型语言模型部署中的隐私关键张量", "title_en": "SecureInfer: Heterogeneous TEE-GPU Architecture for Privacy-Critical Tensors for Large Language Model Deployment", "authors": "Tushar Nayan(1),Ziqi Zhang(2),Ruimin Sun(1) ((1) Florida International University, (2) University of Illinois Urbana-Champaign)", "background": "随着大型语言模型（LLMs）在移动和边缘平台上广泛应用，它们的安全防护需求变得迫切，特别是针对模型提取攻击。如何在不牺牲性能优势的同时保护模型隐私，并利用不可信的AI加速器（如GPU）来执行密集计算，构成了一个具有挑战性的权衡问题。", "innovation": "本文提出了一种新颖的混合框架SecureInfer，其利用异构可信执行环境(TEEs)-GPU架构来隔离隐私关键组件，同时将密集计算任务卸载到不可信加速器上执行。该框架通过基于外包方案的信息论和威胁知情分割策略实现：安全敏感组件（如非线性层、注意头的投影、FNN转换和LoRA适配器）在SGX容器内执行，而其他线性操作（矩阵乘法）在加密后于GPU上执行，并安全地恢复到容器中。", "conclusion": "实验结果表明，SecureInfer提供了可接受的性能和强大的安全保证，为设备上安全模型推理提供了一个切实可行的解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20017", "html_url": "https://arxiv.org/abs/2510.20017", "title": "在希尔伯特空间中同时求解无穷多个LQ均场博弈：神经算子的力量", "title_en": "Simultaneously Solving Infinitely Many LQ Mean Field Games In Hilbert Spaces: The Power of Neural Operators", "authors": "Dena Firoozi,Anastasis Kratsios,Xuwei Yang", "background": "传统的均场博弈（MFG）求解器针对每个问题单独运行，当需要解决大量相关问题时（如在动态或效用扰动下寻求解决方案的稳健描述，或涉及连续参数代理的环境中），这种方法变得不再可行。", "innovation": "该研究通过训练神经算子（NOs）来学习从LQ均场博弈（定义在可分希尔伯特空间上的带动态和成本函数的数据）的规则到相应的均衡策略的映射。主要创新点在于提供了统计保证：即使在无限维情况下，训练在少量随机采样规则上的神经算子可以可靠地解决未见过的LQ均场博弈变体。", "conclusion": "该保证基于三个结果：（i）高度非线性规则到均衡映射的局部Lipschitz估计；（ii）具有预设Lipschitz连续性的神经算子的通用逼近定理（不同于传统NO结果，其Lipschitz常数在逼近误差消失时可能发散）；（iii）无穷维空间中L-Lipschitz学习者的新的样本复杂性界，直接适用于其逼近NO的Lipschitz常数在（ii）中受到控制的情况。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20035", "html_url": "https://arxiv.org/abs/2510.20035", "title": "针对结构学习的随机搜索方法：用藤蔓投墙", "title_en": "Throwing Vines at the Wall: Structure Learning via Random Search", "authors": "Thibault Vatter,Thomas Nagler", "background": " vine copulas因其在多变量依赖建模上的灵活性而广泛应用于机器学习领域，但是结构学习仍然是一个关键挑战。早期的启发式方法，例如Dissmann的贪心算法，虽然被认为是最优方法，但往往效果不佳。", "innovation": "该研究提出了一种改进结构选择的随机搜索算法，并基于模型置信集的统计框架，从而在选择概率上提供了理论保证，并为集成提供了强大基础。实验证据表明，该方法在多个真实数据集上均优于现有最先进的方法。", "conclusion": "该研究表明，随机搜索算法和模型置信集框架在vine copulas的结构学习中具有优越性能，为该领域提供了新的解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20011", "html_url": "https://arxiv.org/abs/2510.20011", "title": "通过在线标签平滑提高医学成像的预测置信度", "title_en": "Improving Predictive Confidence in Medical Imaging via Online Label Smoothing", "authors": "Kushan Choudhury,Shubhrodeep Roy,Ankur Chanda,Shubhajit Biswas,Somenath Kuiry", "background": "深度学习模型，尤其是卷积神经网络，在医学图像分类中取得了显著成果，但这些模型往往会产生过自信的预测，这在关键医疗环境中会削弱其可靠性。传统标签平滑提供了一种简便的方法来减少这种过自信，但这种方法未能考虑类别之间的关系，因为它没有考虑到所有非目标类的差异性。", "innovation": "研究探讨了使用在线标签平滑（OLS），这是一种动态方法，在训练过程中根据模型自身的预测模式调整软标签。作者使用RadImageNet大规模数据集评估了OLS，并利用ResNet-50、MobileNetV2和VGG-19三种广泛使用的架构。结果显示，与标准训练方法（包括硬标签、传统标签平滑和无教师的知识蒸馏）相比，OLS在Top-1和Top-5分类准确性上均表现出一致的提升，同时导致了更紧凑且具有更好分离性的特征嵌入，表明了改进的表现学习能力。", "conclusion": "研究结果表明，OLS不仅增强了预测性能，还提高了校准，是开发医学成像领域可信赖的人工智能系统的实用而有效的解决方案。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20030", "html_url": "https://arxiv.org/abs/2510.20030", "title": "使用量子电路表示矩阵", "title_en": "On Encoding Matrices using Quantum Circuits", "authors": "Liron Mor Yosef,Haim Avron", "background": "十多年前，研究证明了量子计算有可能通过提供比经典计算更高效的算法来革新数值线性代数。例如，HHL算法可以有效地求解线性系统。然而，高效执行此类算法的关键在于如何用量子电路表示输入（包括矩阵和向量）。文献中出现了两种常见的电路表示方法：块编码和态准备电路。", "innovation": "本文系统地研究了块编码和态准备电路的形式下的矩阵编码。研究了从经典形式的矩阵构造这些表示的方法，以及量子两向转换电路之间的算法。文中建立的两个关键结果包括：一种有效方法，用于从经典形式（存储在经典随机访问内存中的条目）构建任意矩阵的块编码；以及低开销、双向转换算法，表明这两种模型本质上是等价的。此外，还介绍了一种特殊的常深度多重器，可以同时多路复用给定大小的所有更高阶的皮亚利矩阵，并且提出了一种在标准基和更高阶皮亚利基之间的矩阵转换算法。", "conclusion": "本文通过有效构建任意矩阵的块编码方法和低开销双向转换算法，有力显示了块编码和态准备电路模式的等效性。此外，文中两种关键技术组成部分的介绍进一步丰富了这一领域的研究。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20043", "html_url": "https://arxiv.org/abs/2510.20043", "title": "从事实到民间传说：评估大型语言模型在孟加拉文化知识上的表现", "title_en": "From Facts to Folklore: Evaluating Large Language Models on Bengali Cultural Knowledge", "authors": "Nafis Chowdhury,Moinul Haque,Anika Ahmed,Nazia Tasnim,Md. Istiak Hossain Shihab,Sajjadur Rahman,Farig Sadeque", "background": "最近NLP研究中，大型语言模型（LLMs）在多种任务上展现了卓越的能力。尽管多语言基准促进了对LLMs的文化评价，但仍存在捕捉低资源文化细微差别的不足。本研究通过创建Bengali Language Cultural Knowledge (BLanCK)数据集，涵盖民间传统、烹饪艺术和区域方言，来解决这一局限。", "innovation": "本文通过BLanCK数据集对多个多语言语言模型进行评估，发现在非文化类别上表现良好，但在文化知识上的表现较差。当提供上下文时，模型的整体性能大幅提升，强调了上下文感知架构和文化定制化训练数据的重要性。", "conclusion": "本研究发现了多语言语言模型在文化知识上的欠缺，并通过提供上下文信息提高了模型的表现。未来研究应重点开发更理解及适应文化的模型架构。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20052", "html_url": "https://arxiv.org/abs/2510.20052", "title": "大规模数据集中多种数据包络分析评分的内生聚合", "title_en": "Endogenous Aggregation of Multiple Data Envelopment Analysis Scores for Large Data Sets", "authors": "Hashem Omrani,Raha Imanirad,Adam Diamant,Utkarsh Verma,Amol Verma,Fahad Razak", "background": "本文提出了一种使用数据包络分析(DEA)进行多组织维度动态效率评价的方法。该方法能够生成特定维度和综合效率评分，同时包含有利和不利输出，并适用于大规模问题设置。本文通过两种正则化DEA模型——基于余量的度量(SBM)和非线性目标规划模型的线性化版本(GP-SBM)，展示了解决方案的应用情境，涵盖了技术效率、临床效率和患者体验这三个理论依据的有效性维度。这些模型可以分别对单个维度和整体效率进行评估，并且能够直接整合有利和不利的输出，提高区分能力。", "innovation": "本文创新性地提出了一种基于DEA的方法，通过两种正则化模型（SBM和GP-SBM）来解决多维度的组织效率评估问题。这两种模型能够有效处理有利和不利的输出，并通过引入正则化参数提高区分能力。此外，SBM和GP-SBM分别从不同角度出发，既评估聚合效率又评估单个维度的效率，从而更好地捕捉输入/输出变量间的相关性。", "conclusion": "通过在多个数据集上的计算效率和有效性验证，以及在加拿大安大略省12家医院的真实案例研究中，本文的SBM和GP-SBM模型能够更准确地捕捉输入/输出变量间的相关性，并优于传统分维度评估再聚合的基准方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20075", "html_url": "https://arxiv.org/abs/2510.20075", "title": "LLMs可以隐藏等长文本中的文本.ipynb", "title_en": "LLMs can hide text in other text of the same length.ipynb", "authors": "Antonio Norelli,Michael Bronstein", "background": "在大型语言模型（LLM）的帮助下，一段有意义的文字可以被嵌入到另一段完全不同的、但同样连贯和合情合理的文本中，长度相同。例如，包含严厉政治批评的推文可以嵌入到庆祝同一政治领导人的推文中，或者普通的产品评论中暗藏一份秘稿。以往这种令人惊奇的能力是不可能实现的，但现在通过大型语言模型，可以实现这一目标。本文展示了一种简单高效的协议，即使是很小的8亿参数开源LLM也足以获得高质量的结果，一段与论文摘要长度相当的信息可以在笔记本上以秒级的速度编码和解码。这种协议的存在突显了文本与作者意图之间的根本脱钩，进一步削弱了人们对书面交流的信任，这种信任已经受到LLM聊天机器人的兴起的影响。", "innovation": "本文提出了一种简单且高效的协议，用于通过大型语言模型在等长文本中嵌入隐藏信息。即使使用相对较小规模的模型也能实现高质量的编码和解码，可以在短短几秒内在个人电脑上完成。这种技术表明，文本与作者意图之间存在根本的脱钩，进一步削弱了人们对文本信息可靠性的信任。", "conclusion": "这种新的协议示例了公司如何秘密部署未经过滤的大规模语言模型，将模型的直接答案嵌入到更安全模型的响应中。这一发现引发了紧迫的AI安全性问题，也挑战了我们对大型语言模型知道什么的理解。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20095", "html_url": "https://arxiv.org/abs/2510.20095", "title": "BIOCAP：在生物基础模型中利用合成描述性标题超越标签", "title_en": "BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models", "authors": "Ziheng Zhang,Xinyue Ma,Arpita Chowdhury,Elizabeth G. Campolongo,Matthew J. Thompson,Net Zhang,Samuel Stevens,Hilmar Lapp,Tanya Berger-Wolf,Yu Su,Wei-Lun Chao,Jianyang Gu", "background": "这项工作研究了描述性标题作为生物多模态基础模型额外监督来源的可能性。图像和描述可以视为物种潜在形态空间中的互补样本，每个样本都捕捉到特定的生物特征。在训练过程中结合描述可以促进与共享潜在结构的对齐，强调可能的诊断特征同时抑制虚假相关性。然而，主要挑战在于大规模获取忠实且实例特定的描述性标题。这限制了自然语言监督在有机生物学中的应用，相比之下，在许多其他科学领域中更为广泛。", "innovation": "该研究通过生成由多模态大型语言模型（MLLMs）引导的合成描述性标题，补足了这一差距。这些来自于维基百科的视觉信息和分类群定制格式示例指导下的领域特定背景，帮助减少了幻觉并产生了准确且基于实例的描述性标题。使用这些描述性标题，研究人员训练了一个生物基础模型BIOCAP（BIOCLIP with Captions），该模型能够捕捉丰富的语义并在物种分类和图文检索中表现出色。", "conclusion": "这些结果显示，描述性标题的价值在于超越标签，该研究方法有助于将生物图像与多模态基础模型联系起来。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20094", "html_url": "https://arxiv.org/abs/2510.20094", "title": "关于麦康维拉斯方程稳态解结构的研究及其在嘈杂变换器中的应用", "title_en": "On the Structure of Stationary Solutions to McKean-Vlasov Equations with Applications to Noisy Transformers", "authors": "Krishnakumar Balasubramanian,Sayan Banerjee,Philippe Rigollet", "background": "我们研究了圆圈上的麦康维拉斯方程的稳态解。主要贡献在于发现了解麦康维拉斯稳态方程与无穷维的傅里叶系数二次方程系统之间的精确等价，这使我们能够通过序列空间（而非函数空间）明确地刻画稳态解。该框架提供了本地分岔的明确定义，能够描述其周期性、共振结构，并且还能处理奇异势场。", "innovation": "通过傅里叶系数的傅里叶系数系统，精确刻画稳态解的结构；分析了涉及多个傅里叶模式的分岔及其形式（超临界、临界、亚临界或超越临界）；提出了从均匀分布到多重模式近似稳态解的一系列分岔，这些解可以被视为‘亚稳态’状态；证明了解析表达式，提供了从连续相变到断续相变的精确过渡。", "conclusion": "在全局层面，我们研究了自由能景观的正则性和凹性，证明了全局最小稳态测度的存在性、紧性和共存性，并确定了这些非光滑点本质上是自由能极小值的点。这种理论在嘈杂变换器模型中得到了应用，解释了温度参数 β 的改变对无穷多从均匀分布分岔的影响，包括从连续到断续相变的急剧转变。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19971", "html_url": "https://arxiv.org/abs/2510.19971", "title": "指导扩散模型从稀疏数据重构流场", "title_en": "Guiding diffusion models to reconstruct flow fields from sparse data", "authors": "Marc Amorós-Trepat,Luis Medrano-Navarro,Qiang Liu,Luca Guastoni,Nils Thuerey", "background": "从有限测量中重建不稳定流场是一项具有挑战性的任务，对于许多工程应用至关重要。机器学习模型因其从数据中学习复杂模式和泛化到多种条件的能力，正在成为解决此问题的热门选择。扩散模型因其生成任务的强大能力而受到重视，通过迭代细化杂音输入生成高质量样本。这些生成模型能够重建流体频谱中的细小尺度，与其他方法相比，更具优势。本研究旨在提出一种新型的采样方法，应用该方法引导扩散模型使用可用的稀疏数据进行反向过程，同时在训练期间使用无冲突更新方法增强重构结果，以利用可获得的物理知识。该研究在二维和三维湍流流场数据上进行了验证实验，一致证明了该方法在预测流体结构及像素级精度方面优于其他基于扩散的方法。该研究强调了扩散模型在重构流场数据方面的巨大潜力，为进一步在计算流体力学领域的应用铺平道路。", "innovation": "提出了一种新型采样方法，应用该方法引导扩散模型使用稀疏数据进行反向过程，同时在训练期间使用无冲突更新方法利用物理知识。该方法在预测流体结构和像素级精度方面优于其他基于扩散的方法。", "conclusion": "该研究强调了扩散模型在重构流场数据方面的巨大潜力，为计算流体力学研究铺平了道路。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20111", "html_url": "https://arxiv.org/abs/2510.20111", "title": "AsyncHZP：具有异步调度的分层ZeRO并行性用于可扩展的大语言模型训练", "title_en": "AsyncHZP: Hierarchical ZeRO Parallelism with Asynchronous Scheduling for Scalable LLM Training", "authors": "Huawei Bai,Yifan Huang,Wenqi Shi,Ansheng You,Feifan Shao,Tengfei Han,Minghui Yu", "background": "大规模语言模型的训练效率和在大规模集群上的可扩展性仍然是一个关键瓶颈。主流的ND并行方法常常复杂且不易操作，而灵活的替代方案，例如零冗余优化器（ZeRO），则经常受到通信开销的限制。传统ZeRO采用过分细粒度的分片，可能导致通信效率低下。", "innovation": "提出了一种名为异步分层零并行（AsyncHZP）的新颖异步变体，旨在实现高性能的同时保持简单性和内存效率。AsyncHZP适应性地重新分片参数、梯度和优化状态，优化设备内存使用，并大幅减少通信开销。此外，设计了多流异步调度方法，在专用的后台线程中执行参数聚合和梯度减少散列操作，有效重叠通信与计算，同时几乎不引起内存碎片化。", "conclusion": "实验结果显示，AsyncHZP在大规模环境下保持了稳健的稳定性，其性能在密集和混合专家（MoE）模型上均优于经典的ND并行方法，且无需复杂的调优策略，简化了大型高效训练的实现路径。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20103", "html_url": "https://arxiv.org/abs/2510.20103", "title": "扩展机器学习模型在隐溶剂中的应用以进行自由能计算", "title_en": "Extending machine learning model for implicit solvation to free energy calculations", "authors": "Rishabh Dey,Michael Brocidiacono,Kushal Koirala,Alexander Tropsha,Konstantin I. Popov", "background": "隐溶剂方法提供了一种计算上高效的方式来模拟分子模拟中的溶剂效应，但其准确性常常低于显溶剂模型，限制了其在精确热力学计算中的应用。最近，机器学习的进步提供了通过利用神经网络开发更精确的隐溶剂势的可能性，以应对不同应用的需求。然而，现有的基于机器学习的方法主要依赖于力匹配，这种方法会导致能量预测带有任意常数偏移，因此不适合绝对自由能比较。", "innovation": "本文提出了一种新的方法，使用基于图神经网络（GNN）的隐溶剂模型，并将其命名为Lambda溶剂神经网络（LSNN）。该模型不仅通过力匹配，还训练以匹配物理变量的导数，确保不同化学物种之间的溶剂自由能可以有意义地比较。LSNN在约30万个小型分子的数据集上进行了训练，其自由能预测的准确性与显溶剂的随化学物种变化能谱模拟相当，同时速度得到了显著提升，为未来药物发现等应用奠定了基础框架。", "conclusion": "LSNN实现了与显溶剂随化学物种变化能谱模拟相当的自由能预测精度，同时提供了一种计算上的加速，并为进一步在药物发现等领域的应用建立了基础框架。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20193", "html_url": "https://arxiv.org/abs/2510.20193", "title": "多媒体感知的问答：检索和跨模态推理架构的综述", "title_en": "Multimedia-Aware Question Answering: A Review of Retrieval and Cross-Modal Reasoning Architectures", "authors": "Rahul Raja,Arpita Vats", "background": "传统问答系统依赖于结构化文本数据，但多媒体内容（如图像、音频、视频和结构化元数据）的快速增长带来了新的检索增强问答挑战与机遇。本文综述了集成多媒体检索管道的新型问答系统，重点关注视听语言模态与用户查询的对接架构，评估了检索方法、融合技术和答案生成策略的不同方法，并分析了基准数据集、评估协议和性能权衡。", "innovation": "本文对具有检索和跨模态推理能力的问答系统进行了综述，研究了不同类型的方法，包括检索方法、融合技术和答案生成策略，并分析了基准数据集、评估协议和性能权衡，还指出了跨模态对齐、延迟-准确权衡和语义语境化等关键挑战，并提出了未来研究的方向和开放问题，以便构建更具鲁棒性和上下文感知的问答系统以利用多媒体数据。", "conclusion": "本文指出了跨模态对齐、延迟-准确权衡和语义语境化等关键挑战，强调了为利用多媒体数据构建更强大和情境感知的问答系统所需解决的开放问题和未来研究方向。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20141", "html_url": "https://arxiv.org/abs/2510.20141", "title": "长时程耦合偏微分方程的组合生成", "title_en": "Compositional Generation for Long-Horizon Coupled PDEs", "authors": "Somayajulu L. N. Dhulipala,Deep Ray,Nicholas Forman", "background": "模拟耦合偏微分方程组（PDE）系统是计算密集型的，先前的努力主要集中在训练联合（耦合）数据上的代理模型，这需要大量的数据。本文探讨了组合扩散方法，其中仅在解耦偏微分方程数据上训练扩散模型，并在推理时组合它们以恢复耦合场。尤其关注长时程涉及大量时间步骤的情况。进一步地，将基线扩散模型与其使用v-参数化策略训练的模型进行了比较。还提出了基于欧拉方案的对称组合方案，用于耦合场。在反应扩散和修改后的Burgers方程上进行了评估，基准模型为在耦合数据上训练的傅里叶神经算子。即使只看到解耦训练数据，组合扩散模型也能以低误差恢复耦合轨迹。v-参数化可以提高与基线扩散模型相比的准确性，但神经算子代理仍然是最强大的，因为它是在耦合数据上训练的。这些结果表明，组合扩散是一种可行的策略，以高效地建模长时程耦合偏微分方程.", "innovation": "通过仅在解耦偏微分方程的数据上训练扩散模型，然后在推理时组合它们来恢复耦合场，探讨了组合策略在长时程情况下的可行性。此外，还引入了基于欧拉方案的对称组合方案，并与傅里叶神经算子进行了比较，该算子是在耦合数据上进行训练的。", "conclusion": "组合扩散模型在仅使用解耦训练数据的情况下仍能以低误差恢复耦合轨迹。v-参数化能够提升扩散模型的准确性，而神经算子则在训练于耦合数据时表现最佳。这些结果表明，组合扩散是一种可行的策略，可用于高效地长期模拟耦合偏微分方程。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20211", "html_url": "https://arxiv.org/abs/2510.20211", "title": "使用AI代理进行自动云基础设施即代码校正", "title_en": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "authors": "Zhenning Yang,Hui Guan,Victor Nicolet,Brandon Paulsen,Joey Dodds,Daniel Kroening,Ang Chen", "background": "目前，云基础设施的管理是通过混合界面进行的，包括云控制台、命令行界面和软件开发工具包等传统工具。近年来，基础设施即代码（IaC）框架得到了快速的普及，比如Terraform。这些框架通过一种“源码规范”来编码基础设施，并能够自动执行云中的部署、更新或销毁资源等操作，以确保基础设施与代码规范一致。然而，当IaC与控制台、命令行或编程接口结合使用时，IaC将失去对外部更改的可见性，导致基础设施漂移，即配置变得过时，后续的IaC操作可能会撤销有效的更新或触发错误。", "innovation": "该论文提出了NSync，一个自动化系统，用于在IaC与云控制台、命令行或编程接口结合使用时管理基础设施漂移问题。NSync的核心见解是所有的基础设施变化最终都是通过云API调用来实现的。该系统通过分析API使用痕迹来检测漂移（即非IaC的变化）并进行校正（即更新IaC配置以反映这些变化）。该系统采用一种代理架构，利用大规模语言模型（LLM）从嘈杂的API序列中推断高层次的意图，使用专门的工具合成有针对性的IaC更新，并通过自我进化的知识库不断提高。", "conclusion": "实验结果表明，NSync在准确性和代币效率方面都优于基线，包括准确性从0.71提升到0.97，以及代币效率提高了1.47倍。该论文还引入了一种新的评估管道，用于将真实的漂移注入云基础设施并评估校正性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20256", "html_url": "https://arxiv.org/abs/2510.20256", "title": "Calibrating Multimodal Consensus for Emotion Recognition", "title_en": "Calibrating Multimodal Consensus for Emotion Recognition", "authors": "Guowei Zhong,Junjie Li,Huaiyu Zhu,Ruohong Huan,Yun Pan", "background": "近年来，多模态情绪识别（MER）取得了显著进展，但仍存在一些挑战。现有方法往往忽视了模态间可能存在的语义不一致性，如文本与视觉输入之间的矛盾情绪线索。此外，由于文本模态强大的表示能力，当前方法往往受到文本模态主导，这可能会影响识别精度。", "innovation": "本文提出了一种称为Calibrated Multimodal Consensus（CMC）的模型。CMC引入了伪标签生成模块（PLGM）以生成伪标签，实现无监督的单模预训练。该模型还采用无参数融合模块（PFM）和多模态共识路由器（MCR）进行多模态微调，从而减轻文本主导问题，并引导融合过程向更可靠的共识发展。", "conclusion": "实验结果表明，CMC在四个数据集（CH-SIMS、CH-SIMS v2、CMU-MOSI和CMU-MOSEI）上的性能与最先进的方法相当或更优，尤其在CH-SIMS和CH-SIMS v2这些语义不一致性场景中表现出明显优势。这项工作的实现代码可以在以下网址获取：this https URL"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20287", "html_url": "https://arxiv.org/abs/2510.20287", "title": "在生成式AI时代的霹雳舞视频分类", "title_en": "Breakdance Video classification in the age of Generative AI", "authors": "Sauptik Dhar,Naveen Ramakrishnan,Michelle Munson", "background": "近年来，大型视觉语言模型在多个体育场景中得到了广泛应用。大多数相关研究主要集中在足球、板球、篮球等少数热门运动上，主要关注生成任务，如视觉问答和高光生成。本研究探讨了现代视频基础模型（包括编码器和解码器）在霹雳舞这一非常细分但非常流行的运动中的应用可能性。研究表明，视频编码器模型在预测任务中继续超越最先进的视频语言模型。本研究提供了如何选择编码器模型的见解，并对微调解码器模型进行了详尽的分析，以实现霹雳舞视频分类。", "innovation": "本研究首次将现代视频基础模型应用于霹雳舞这一特定的体育运动，展示了编码器模型在预测任务中的优越性能，并对微调解码器模型进行了深入分析，为霹雳舞视频分类提供了新的方法和见解。", "conclusion": "研究结果表明，视频编码器模型在预测任务中继续超越最先进的视频语言模型。研究提供了如何选择编码器模型的见解，并进行了详尽的解码器模型微调分析，以实现霹雳舞视频分类。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20314", "html_url": "https://arxiv.org/abs/2510.20314", "title": "增强深度强化学习中的安全性：对抗攻击与防御的全面综述", "title_en": "Enhancing Security in Deep Reinforcement Learning: A Comprehensive Survey on Adversarial Attacks and Defenses", "authors": "Wu Yichao,Wang Yirui,Ding Panpan,Wang Hailong,Zhu Bingqian,Liu Chun", "background": "随着深度强化学习（DRL）技术在自动驾驶、智能制造和智能医疗等复杂领域中的广泛应用，如何在动态和多变的环境中提高其安全性和鲁棒性已成为当前研究的核心问题。特别是面对对抗攻击，DRL 可能会出现严重的性能下降甚至做出危险的选择，因此在安全敏感的场景中确保其稳定性至关重要。", "innovation": "本文首先介绍了DRL的基本框架，并分析了在复杂和变化环境中面临的主安全挑战。此外，本文提出了基于扰动类型和攻击目标的对抗攻击分类框架，并详细回顾了针对DRL的主要对抗攻击方法，包括状态空间、动作空间、奖励函数和模型空间的各种攻击方法。为了有效应对攻击，本文系统总结了现有的各种鲁棒性训练策略，包括对抗训练、竞争训练、鲁棒学习、对抗检测等相关的防御技术。我们还讨论了这些方法在提高DRL鲁棒性方面的优缺点。", "conclusion": "最后，本文着眼于DRL在对抗环境中的未来研究方向，强调提高泛化能力、降低计算复杂性、增强可扩展性和可解释性等方面的研究需求，旨在为研究人员提供有价值的参考和方向。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20244", "html_url": "https://arxiv.org/abs/2510.20244", "title": "Empower Words: 双分支架构在结构化短语和句级时间定位中的时空定位", "title_en": "Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding", "authors": "Minseok Kang,Minhyeok Lee,Minjung Kim,Donghyeong Kim,Sangyoun Lee", "background": "视频时空定位（VTG）旨在将长、未剪辑的视频中与给定自然语言查询对齐的时序段进行本地化。任务通常包括两个子任务：时刻检索（MR）和高光检测（HD）。虽然近期先进预训练的跨模态模型如CLIP和InternVideo2取得了进展，但现有方法通常在跨模态注意力中均匀处理所有文本标记，忽视了它们的语义角色差异。研究表明，这一处理方式使得VTG模型过度依赖于由[EOS]引导的全球语义，而无法有效利用词级信号，从而阻碍了精细时序对齐能力的提升。", "innovation": "本文提出了一种双分支架构——DualGround，通过明确分离全局和局部语义，它直接将[EOS]令牌路由到句子级路径，并将词汇令牌聚类成短语级单元进行局部定位。该方法引入了（1）基于层次标记的跨模态交互策略，实现视频特征与句级和短语级语义在结构上解耦的方式对齐，以及（2）联合建模框架，不仅提高全局句子级对齐，还能通过结构化短语感知上下文增强精细时序定位。此设计使模型能够捕捉粗粒度语义和局部语义，从而实现更丰富的语境意识视频时空定位。DualGround在QVHighlights和Charades-STA基准上分别在时刻检索和高光检测任务上达到最新性能，证明了分离建模在视频-语言对齐中的有效性。", "conclusion": "DualGround 通过分离局部和全局语义，增强了复杂跨模态交互，并通过结构化短语语境促进了精细时序定位，从而在多个基准测试中实现了最先进的性能。这表明分离语义建模在视频-语言对齐中的有效性，并展示了该方法在双向架构上的优势。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20328", "html_url": "https://arxiv.org/abs/2510.20328", "title": "MemER: 通过经验检索扩展机器人控制中的记忆", "title_en": "MemER: Scaling Up Memory for Robot Control via Experience Retrieval", "authors": "Ajay Sridhar,Jennifer Pan,Satvik Sharma,Chelsea Finn", "background": "人类在执行任务时依赖记忆，但现有的机器人策略大多缺乏这一能力。本文目标是为机器人策略赋予相同的记忆能力。直接基于长时间观测历史进行条件处理存在计算成本高且在分布变化时表现脆弱的问题。无差别地对历史进行采样会导致无关或多余的信息。本文提出了一种分层策略框架，高层次策略被训练来从其经验中选择和追踪以前的相关关键帧，并使用选择的关键帧和最近的图帧生成用于低层次策略执行的文本指令。这种设计与现有的视觉-语言-动作模型兼容，使系统能够高效地推理长期依赖关系。", "innovation": "本文提出了MemER方法，通过经验检索扩展了机器人控制中的记忆能力。具体来说，它采用分层策略框架，高层次策略选择和跟踪以前的相关关键帧，低层次策略根据这些关键帧和最新图帧生成执行指令。这种方法与现有的视觉-语言-动作模型兼容，使得机器人系统能够高效地处理长期依赖关系。", "conclusion": "在实验中，我们使用Qwen2.5-VL-7B-Instruct和$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{π}}}}}}}}}}}}}}}}}}_{0.5}$分别微调为高层次和低层次策略，使用带有少量语言注释的数据示例进行培训。我们的方法MemER在需要数分钟记忆的三个真实世界长期机器人操作任务上优于先前的方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20363", "html_url": "https://arxiv.org/abs/2510.20363", "title": "基于Transformer的AI MIMO接收机", "title_en": "A Transformer Inspired AI-based MIMO receiver", "authors": "András Rácz,Tamás Borsos,András Veres,Benedek Csala", "background": "本文介绍了AttDet，一种受Transformer启发的MIMO检测方法。AttDet将每个传输层视为一个标记，并通过轻量级的自注意力机制学习跨流干扰。查询和键从估计的信道矩阵直接导出，所以注意力分数衡量信道相关性。值由匹配滤波器输出初始化并迭代优化。AttDet设计结合了模型驱动的可解释性和数据驱动的灵活性。", "innovation": "AttDet通过将每个传输层视为一个标记，并利用轻量级自注意力机制直接从估计的信道矩阵中得出查询和键，从而计算出关注分数来量化信道相关性。值通过匹配滤波器输出初始化，并通过迭代优化进一步精确。该设计实现了基于模型的可解释性和数据驱动的灵活性的有效结合。", "conclusion": "通过现实的5G信道模型和高阶混合QAM调制方式下的链路级仿真，证明了AttDet可以接近最优的BER/BLER（位错误率/块错误率）性能，同时保持可预测和多项式复杂性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20362", "html_url": "https://arxiv.org/abs/2510.20362", "title": "ComProScanner：一种基于多代理系统的从科学文献中提取组分-性能结构数据的框架", "title_en": "ComProScanner: A multi-agent based framework for composition-property structured data extraction from scientific literature", "authors": "Aritra Roy,Enrico Grisan,John Buckeridge,Chiara Gattinoni", "background": "自各种预训练大型语言模型问世以来，从科学文本中提取结构化知识经历了革命性的变化，相比传统机器学习或自然语言处理技术。然而，可让用户轻松构建、验证和可视化科学文献数据集的自动工具仍然稀缺。", "innovation": "开发了ComProScanner，这是一个自主多代理平台，用于提取、验证、分类和可视化机器可读的化学组成和属性，并与期刊文章中的合成数据集成，以创建全面的数据库。框架使用100篇期刊文章和10种不同的LLM（包括开源和专有模型）进行评估，以提取与陶瓷压电材料高度复杂的组成及其对应的压电应变系数（d33）相关的重要数据。其中，DeepSeek-V3-0324表现最佳，准确率为0.82。该框架提供了一个简单易用的软件包，可从文献中提取复杂实验数据，用于构建机器学习或深度学习数据集。", "conclusion": "ComProScanner提供了一种有效的解决方案，能够从文献中提取复杂的数据，以构建高效的机器学习或深度学习数据集。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20406", "html_url": "https://arxiv.org/abs/2510.20406", "title": "PointMapPolicy: 结构化点云处理用于多模态模仿学习", "title_en": "PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning", "authors": "Xiaogang Jia,Qian Wang,Anrui Wang,Han A. Wang,Balázs Gyenes,Emiliyan Gospodinov,Xinkai Jiang,Ge Li,Hongyi Zhou,Weiran Liao,Xi Huang,Maximilian Beck,Moritz Reuss,Rudolf Lioutikov,Gerhard Neumann", "background": "机器人操作系统可以从互补的感知模态中受益，其中每种模态提供了独特环境信息。点云捕捉详细的几何结构，而RGB图像则提供丰富的语义上下文。当前的点云方法难以捕捉细微的细节，特别是在复杂任务中，而基于RGB的方法缺乏几何意识，这阻碍了它们的精确性和泛化能力。", "innovation": "本文介绍了一种新颖的方法——PointMapPolicy，该方法在不进行下采样的情况下，通过结构化的点网格条件化扩散策略。由此产生的数据类型更容易从观察中提取形状和空间关系，并且可以在参考坐标系之间进行转换。但由于其在规则网格结构中的构成，它能够直接在3D数据上应用现有的计算机视觉技术。通过xLSTM作为骨干网络，我们的模型可以高效地融合点图与RGB数据，以增强多模态感知。通过在RoboCasa和CALVIN基准以及真实机器人评估上的广泛实验，我们展示了该方法在各种操作任务中的最先进的性能。", "conclusion": "PointMapPolicy实现了最先进的多模态感知性能，并通过直接在3D数据上应用现有的计算机视觉技术，结合点图和RGB数据，提高了机器人操作系统的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20372", "html_url": "https://arxiv.org/abs/2510.20372", "title": "测试最具有影响力的子集", "title_en": "Testing Most Influential Sets", "authors": "Lucas Darius Konrad,Nikolas Kuschnig", "background": "小数据子集对模型结果有着不成比例的影响，并可能极大地影响结论，有时单一数据点就可以推翻关键发现。尽管最近的研究发展了识别这些最具有影响力子集的方法，但尚无正式理论来判断其影响是否确实存在严重问题还是自然抽样变异的结果。针对这一空白，本文构建了一个基于原则的框架来评估最具有影响力的子集的统计显著性，提出了极值分布来表征最大影响力的极端值分布，从而可以进行对过度影响力的严格假设测试，取代现有的随意敏感性检查方法。本文通过经济学、生物学和机器学习基准中的应用展示了该方法的实际价值。", "innovation": "本文通过提出一个连续的原则化框架，解决了现有方法中缺乏的正式理论问题，该框架可用于评估最具有影响力的子集的统计显著性，改变了以前依赖感性检查的做法。理论成果通过极值分布描述了最大的影响力，并能进行过度影响力的严格假设测试。这种方法在经济学、生物学和机器学习中的广泛应用证明了其实际价值和实用意义。", "conclusion": "本文提出的新的统计显著性测试方法，能够更准确地判断最具有影响力的子集的影响是否真实存在，而不是随机抽样变异的结果。这种新方法在多个领域表现出了实际应用的价值，对数据敏感性和结果可靠性有着重要的促进作用。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20334", "html_url": "https://arxiv.org/abs/2510.20334", "title": "利用正常化流在TAIGA实验中提取稀有伽马事件的能力", "title_en": "Capability of using the normalizing flows for extraction rare gamma events in the TAIGA experiment", "authors": "A.P. Kryukov,A.Yu. Razumov,A.P. Demichev,J.J. Dubenskaya,E.O. Gres,S.P. Polyakov,E.B. Postnikov,P.A. Volchugov,D.P. Zhurov", "background": "本文的目标是开发一种方法，用于在宇宙源发出的带电粒子流中检测稀有的伽马量子，使用基于深度学习和归一化流的异常检测方法。之前的检测方法在实际应用中存在不足，因此需要提出一种新的方法来改进伽马检测的效果。", "innovation": "本文创新性地提出了一种基于深度学习和归一化流的异常检测方法，用于在宇宙射线中检测稀有的伽马量子事件，这种方法能够有效地提取稀有伽马事件，并在TAIGA-IACT实验的数据模型测试中进行了验证。尽管性能指标仍然落后于其他方法，但这种方法具有改进的潜力。", "conclusion": "研究结果表明，基于归一化流的方法在提取稀有伽马事件方面具有潜力，但其性能指标仍需改进。未来的工作将重点探索提高该方法性能的方法，以进一步提高伽马检测的准确性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20416", "html_url": "https://arxiv.org/abs/2510.20416", "title": "使用GraphDOP学习耦合的地球系统动力学", "title_en": "Learning Coupled Earth System Dynamics with GraphDOP", "authors": "Eulalie Boucher,Mihai Alexe,Peter Lean,Ewan Pinnington,Simon Lang,Patrick Laloyaux,Lorenzo Zampieri,Patricia de Rosnay,Niels Bormann,Anthony McNally", "background": "地球系统（如海洋、大气、陆地和冰雪圈）之间的相互作用是全球天气模式的关键驱动因素。现代数值天气预报系统通常针对不同的组成部分分别运行模型，并在它们的接口处显式地耦合，以模拟不同组成部分之间的交换。准确地表示这些耦合的相互作用仍然是天气预报中的一个重要科学和技术挑战。", "innovation": "GraphDOP是一种基于图的机器学习模型，可以直接从原始的卫星和原位观测数据中进行天气预测，无需依赖再分析产品或传统的基于物理的数值天气预报模型。GraphDOP同时将来自地球系统不同观测源的信息嵌入到一个共享的潜空间中，这使得可以在一个模型中隐式捕捉跨域相互作用，而无需任何显式的耦合。", "conclusion": "通过一系列案例研究展示了GraphDOP能够预测耦合过程起特别关键作用的事件，如北极快速海冰冻结、飓风伊恩引发的混合引起的海洋表面冷却以及2022年欧洲严重的热浪。结果表明，直接从地球系统观察中学习可以成功地表征和传播跨组件相互作用，表明一个单一模型实现全局一致的端到端数据驱动地球系统预报是一个有前景的方向。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20431", "html_url": "https://arxiv.org/abs/2510.20431", "title": "Cubic相关聚类中一般图的部分最优性", "title_en": "Partial Optimality in Cubic Correlation Clustering for General Graphs", "authors": "David Stein,Bjoern Andres,Silvia Di Gregorio", "background": "该论文研究了一个NP难问题，即对于给定的图G及其子团的费用，寻找一种分簇方法以最小化属于同一簇的所有节点组成的团的费用总和。先前的研究已经提出了局部搜索启发式方法应用于此问题。本文关注特定情况下的三次团相关聚类问题，即最大小团为3-团的情况，探讨了在这种特殊情形下的一些部分最优性条件，并提供了算法实现来评估其有效性。研究的数据集包括两个数据集以进行数值测试和验证。", "innovation": "本文的主要创新点在于首次对于三次团相关聚类（仅考虑至多3-团）提出了部分最优性的条件，并且设计了相应的决定算法。这些算法被应用于具体的图实例中进行实验验证，展示了对其有效性和效率的评估过程", "conclusion": "本文探讨并实现了三次团相关聚类的部分最优性条件，通过实验证明了算法的有效性。这种方法对解决更高阶相关聚类问题提供了新的见解，并对实际应用具有潜在价值。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20344", "html_url": "https://arxiv.org/abs/2510.20344", "title": "基于数据增广的截断期望回归神经网络", "title_en": "Neural Networks for Censored Expectile Regression Based on Data Augmentation", "authors": "Wei Cao,Shanshan Wang", "background": "传统的期望回归神经网络（ERNNs）是强大的工具，能够捕捉数据中的异质性和复杂的非线性结构。然而，现有研究大多集中于完全观测数据，对涉及截断观察的情形关注较少。本文探讨了在数据增广基础上改进ERNNs的方法，以解决截断数据建模的问题，并验证了其在模拟和真实数据应用中的优越性。", "innovation": "本文提出了一种基于数据增广的期望回归神经网络（DAERNN），该方法能够处理异质性截断数据，并且适用于各种截断机制，无需显式参数模型的设定。DAERNN利用数据驱动的方式进行建模，不需要过多假设，提供了极大的灵活性。实验结果表明，DAERNN比现有的截断期望回归神经网络方法性能更佳，预测性能接近于以完全观测数据训练的模型。", "conclusion": "本文通过数据增广的方法改进了期望回归神经网络，提出了DAERNN模型，并验证了其在模拟和真实数据中的优越性。DAERNN为处理各类截断数据提供了统一的框架，并提高了其实际应用的通用性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20339", "html_url": "https://arxiv.org/abs/2510.20339", "title": "多任务深度学习在表面计量学中的应用", "title_en": "Multi-Task Deep Learning for Surface Metrology", "authors": "D. Kucharski,A. Gaska,T. Kowaluk,K. Stepien,M. Repalska,B. Gapinski,M. Wieczorowski,M. Nawotka,P. Sobecki,P. Sosinowski,J. Tomasik,A. Wojtowicz", "background": "传统的表面纹理测量方法依赖于特定的测量仪器和技术，这些方法通常需要手工进行数据处理和分析。然而，针对不同类型和品牌的测量仪器构建的算法之间可能存在互不兼容的问题，这限制了数据的统一处理。本研究旨在提出一种可复现的深度学习框架，用于预测表面纹理参数及其报告的标准不确定度，同时适用于触觉和光学系统的多仪器数据集。", "innovation": "本研究创新地提出了一种多任务深度学习框架，可以同时处理表面纹理参数及其不确定度预测，并且可以跨不同类型的测量系统进行校准和超参数优化。通过使用量纲和异方差头部，结合后续的拟合校准方法，该框架能够生成校准区间，从而提高了预测精度和可靠性。此外，该研究还观察到单目标模型比多输出模型在知识迁移方面表现更好，这为未来的深层学习应用提供了新的视角。", "conclusion": "本文提出的深度学习框架在验证集上实现了高精度的单目标回归器(Ra: R2 0.9824, Rz: R2 0.9847, RONt: R2 0.9918)，二次不确定度目标也得到了较好的预测(Ra_uncert: R2 0.9899, Rz_uncert: R2 0.9955)；然而，三元不确定度参数RONt_uncert的预测效果较差(R2 0.4934)。分类器达到了92.85%的准确性，温度尺度后概率校准基本不变。此外，直接多任务模型观察到了负迁移效应，单任务模型表现更优秀。这些结果为在表面计量工作的仪器选择和接受决策中提供了校准的预测。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20457", "html_url": "https://arxiv.org/abs/2510.20457", "title": "SHOIQ中的神经推理以实现稳健的实例检索", "title_en": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$", "authors": "Louis Mozart Kamdem Teyou,Luke Friedrichs,N'Dah Jean Kouagou,Caglar Demir,Yasir Mahmood,Stefan Heindorf,Axel-Cyrille Ngonga Ngomo", "background": "概念学习利用形如描述逻辑公理的形式背景知识，从知识库中学习可解释的分类模型。尽管在神经符号概念学习领域取得了重大突破，但大多数方法仍然无法部署在现实世界的知识库中。这是因为它们依赖于描述逻辑推理器，这些推理器不能抵御不一致性的错误数据影响。", "innovation": "本文提出了一种新颖的神经推理器EBR，通过嵌入来近似符号推理器的结果。EBR仅需要检索原子概念和存在限制的概念的实例，即可检索或近似描述逻辑$\text{SHOIQ}$中任何概念的实例集合。实验证明，EBR对于缺失和错误数据具有鲁棒性，而现有的推理器则不具备这一特性。", "conclusion": "通过EBR，研究展示了即使在存在不一致性和错误数据的情况下，也能有效地检索实例，从而克服了现有的问题。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20436", "html_url": "https://arxiv.org/abs/2510.20436", "title": "基于图注意力的多智能体强化学习在月球延迟容忍网络中学习去中心化路由策略", "title_en": "Learning Decentralized Routing Policies via Graph Attention-based Multi-Agent Reinforcement Learning in Lunar Delay-Tolerant Networks", "authors": "Federico Lozano-Cuadra,Beatriz Soret,Marc Sanchez Net,Abhishek Cauligi,Federico Rossi", "background": "在月球延迟容忍网络（LDTN）的约束下，自主漫游车需要在 intermittent 连通性和未知移动模式条件下，将收集的数据转发到着陆器。这个问题被定义为部分可观测马尔可夫决策过程（POMDP），论文探讨了如何在这种环境下进行多智能体强化学习以实现去中心化的路由策略，使得漫游车在不需要全局拓扑更新和数据包复制的情况下，优化数据交付效率，减少数据丢失。", "innovation": "提出了一种基于图注意力的多智能体强化学习（GAT-MARL）策略，采用集中训练、去中心化执行的方法（CTDE）。该方法依赖于局部观察，无需更新全局拓扑结构或复制数据包，克服了传统基于最短路径和受控洪泛的算法面临的挑战。通过蒙特卡洛模拟实现了更高的数据传递率、无冗余传输及减少数据包丢失，并能利用短期移动预报，为未来月球空间机器人系统提供了可扩展的解决方案，已在更大规模的漫游车队中成功验证了其有效性。", "conclusion": "通过去中心化的路由策略和局部观察，该研究展示了一种针对行星探索空间机器人系统中延迟容忍网络的高效算法，提供了一种针对更大漫游车队的可扩展性和通用性solution，优化了数据交付性能并减少了数据包的丢失率。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20472", "html_url": "https://arxiv.org/abs/2510.20472", "title": "合成过采样不平衡分类的收敛性和额外风险界", "title_en": "Concentration and excess risk bounds for imbalanced classification with synthetic oversampling", "authors": "Touqeer Ahmad,Mohammadreza M. Kalan,François Portier,Gilles Stupfler", "background": "合成过采样方法（如SMOTE及其变体）是解决不平衡分类问题的主要策略。尽管该方法在实践中取得了成功，但其理论基础仍旧未被充分探索。", "innovation": "开发了一个理论框架来分析在使用合成数据训练分类器时，SMOTE等方法的行为。首先，推导了合成少数类样本上的经验风险与真实少数类分布上的总体风险之间的统一收敛界。随后，提供了使用此类合成数据训练核基分类器的非参数性额外风险保证。这些结果为更好地调参提供了实用指南。", "conclusion": "研究结果为SMOTE及其下游学习算法的参数调整提供了具体的指导，并通过数值实验予以验证和支持。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20453", "html_url": "https://arxiv.org/abs/2510.20453", "title": "超越标准模型物理中的符号回归和可微拟合", "title_en": "Symbolic Regression and Differentiable Fits in Beyond the Standard Model Physics", "authors": "Shehu AbdusSalam,Steven Abel,Deaglan Bartlett,Miguel Crispim Romão", "background": "本文通过探讨所谓的约束最小超对称标准模型(CMSSM)来展示符号回归(SR)在探测超越标准模型(BSM)粒子物理学中的有效性。CMSSM模型包含四个任意参数，这些参数决定了实验信号和如暗物质遗迹密度等宇宙观测值。传统的分析方法需要逐个研究这些参数，而本文通过将观测量用输入参数表示，极大地加速了这些分析。研究特别关注希格斯质量、冷暗物质遗迹密度以及Muon的异常磁矩贡献等几个重要特征。", "innovation": "本文介绍了符号回归和可微拟合在BSM物理中的应用，并展示了符号回归的优势：它可以通过求导方法进行拟合，而不仅仅是采样方法。此外，本文还比较了符号回归与神经网络回归(NN)，发现符号回归在全局上能产生更稳健的结果，而神经网络则需要重点聚焦在有潜力的数据区域才能得出同样优秀的结果。符号回归还能直接产生精确的符号表达式，这些表达式能够准确地捕捉观测量与输入参数之间的关系。", "conclusion": "使用符号回归进行全球拟合，得到的输入参数后验概率密度与使用传统方法拟合的结果十分吻合。此外，符号回归可以通过差分方法进行拟合，而不需要依赖采样方法。这种方法展示了一个明显的优势，即能够更容易地生成能够捕获复杂物理现象的准确数学表达式。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20518", "html_url": "https://arxiv.org/abs/2510.20518", "title": "无线信道中的威胁感知私有推理", "title_en": "Adversary-Aware Private Inference over Wireless Channels", "authors": "Mohamed Seif,Malcolm Egan,Andrea J. Goldsmith,H. Vincent Poor", "background": "无线边缘设备上的AI检测有可能显著增强AI应用，特别是在自主驾驶和环境监测等视觉和感知任务中。AI系统依赖于有效的模型学习和推理。在推理阶段，从前感知识数据中提取的特征被用于预测任务（例如，分类或回归）。在网络边缘中，传感器和模型服务器往往不位于同一位置，这要求特征的通信。由于敏感的个人数据可能由对手重建，因此需要对特征进行变换以降低隐私泄露的风险。虽然差分隐私机制可以保护有限的数据集，但单个特征的保护并未得到解决.", "innovation": "本文提出了一种新型的隐私保护AI感知框架，在数据传输到模型服务器之前，设备会对提取的特征进行变换.", "conclusion": "我们在无线信道中提出了威胁感知的私有推理方法，通过在传输到模型服务器之前对提取的特征进行变换来保护隐私."}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20539", "html_url": "https://arxiv.org/abs/2510.20539", "title": "Blur2seq: 单张运动模糊图像的盲去模糊和相机轨迹估计", "title_en": "Blur2seq: Blind Deblurring and Camera Trajectory Estimation from a Single Camera Motion-blurred Image", "authors": "Guillermo Carbajal,Andrés Almansa,Pablo Musé", "background": "由于相机抖动引起的空间大范围或者旋转运动所导致的运动模糊，是图像恢复中的一个重要挑战。现有的端到端去模糊网络在严重或空间变异性模糊的情况下表现不佳。因此，提出了一种深度学习框架，该框架能够从单一的模糊图像中联合估计潜在的锐利图像和基础的相机运动轨迹。", "innovation": "该方法采用了一种高效的投影运动模糊模型（PMBM），并在现代网络中兼容了一个不同的可微模糊创建模块。神经网络预测一个完整的3D旋转轨迹，该轨迹引导一个端到端训练的模型感知恢复网络，并提供了模块化架构，能够解释导致模糊的相机运动。此外，通过后推理优化轨迹以进一步细化结果，增加模糊输入和恢复输出之间的一致性。这种方法在合成和真实数据集上表现出优越的性能，特别是在严重或空间变异性模糊的情况下。", "conclusion": "大量实验表明，该方法在合成和真实数据集上均达到了最先进的性能，特别是在严重或空间变异性模糊的情况下。此外，通过优化轨迹，增强了恢复效果的一致性。该研究成果提供了处理相机运动模糊的有效工具，且其代码和训练模型已经公开可在指定链接下载。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20513", "html_url": "https://arxiv.org/abs/2510.20513", "title": "解码耳朵：一种通过高效对齐使表达性客观化的框架", "title_en": "Decoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment", "authors": "Zhiyu Lin,Jingwen Yang,Jiale Zhao,Meng Liu,Sunzhu Li,Benyou Wang", "background": "近年来的语音到语音（S2S）模型能够生成可理解的语音，但在自然表达性方面仍然不足，主要原因是缺乏可靠的评估指标。现有方法如主观的MOS评分、低级声学特征和情绪识别成本高、有限或不完整。因此，需要一种新的方法来解决这一问题，即能够将人类对语音表达性的偏好转化为客观评分的框架.", "innovation": "提出了一种名为DeEAR的框架（Decoding the Expressive Preference of eAR），该框架以语音学和心理学为基础，通过三个维度（情感、语调和自发性）评估语音表达性，并通过不到500个标注样本实现了与人类感知的强对齐（Spearman等级相关系数，SRCC=0.86）。DeEAR不仅提供可靠的评分，还支持公平基准测试和目标数据策展，能够区分S2S模型之间的表达性差距，并筛选出14,000个表达性语音片段用于构建ExpressiveSpeech数据库，该数据库使S2S模型的表达得分在100分制上提高了21.4分.", "conclusion": "DeEAR框架不仅提供了一个可靠的评分系统，还促进了S2S模型的公平基准测试和高质量数据集的创建，显著改善了模型的表达性。相关演示和代码可在提供的链接获取."}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20595", "html_url": "https://arxiv.org/abs/2510.20595", "title": "Diffusion Autoencoders with Perceivers for Long, Irregular and Multimodal Astronomical Sequences", "title_en": "Diffusion Autoencoders with Perceivers for Long, Irregular and Multimodal Astronomical Sequences", "authors": "Yunyi Shen,Alexander Gagliano", "background": "自监督学习已成为一种核心策略用于表示学习。然而，用于编码数据的大批量结构大多仅在常规采样的输入如图像、音频和视频上进行了验证。在许多科学研究领域，数据则以长、不规则和多模态序列的形式出现。针对这些数据，需要一种方法来从中提取语义信息。", "innovation": "提出了Diffusion Autoencoder with Perceivers（daep）架构。daep将异构测量数据进行分词、使用Perceiver编码器压缩，再通过Perceiver-IO扩散解码器重建，从而在多种数据设置中实现可扩展的学习。此外，还提出了maep作为基准模型，使用Masked Autoencoder架构，展示了daep在多个光谱和光度天文学数据集上的优势。", "conclusion": "daep在重建误差、隐空间鉴别性和精细结构保持方面表现优于VAE和maep基准模型。这些结果表明，daep是处理实时、异构序列数据的有效框架，特别适用于科学领域，如天文学，其中数据表现为不规则和多模态序列。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20690", "html_url": "https://arxiv.org/abs/2510.20690", "title": "Neural Diversity Regularizes Hallucinations in Small Models", "title_en": "Neural Diversity Regularizes Hallucinations in Small Models", "authors": "Kushal Chakrabarti,Nirmal Balachundhar", "background": "语言模型尽管在参数、计算和数据方面有所增加，仍然会经历幻觉现象。论文探讨了如何通过神经多样性——即 decorrelated 并行表示——作为减少幻觉概率的一种原则性机制，在固定参数和数据预算下实现这一目标。", "innovation": "论文提出了神经多样性这一概念，借鉴组合投资理论的原理，证明幻觉概率由表征相关性限定。通过结合 LoRA 调整器和 Barlow Twins 正则化技术，验证了神经多样性能减少幻觉现象而不降低通用准确性，并且展示了神经多样性在不同任务中需要不同的最优配置。", "conclusion": "研究结果表明，神经多样性作为提升语言模型可靠性的一种新途径，可以在固定预算下作为参数和数据之外的第三种扩展轴来提高可信赖性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20606", "html_url": "https://arxiv.org/abs/2510.20606", "title": "感知偏差对公平选拔的战略成本", "title_en": "Strategic Costs of Perceived Bias in Fair Selection", "authors": "L. Elisa Celis,Lingxiao Huang,Milind Sohoni,Nisheeth K. Vishnoi", "background": "公平选拔系统旨在公正地奖励才能和努力，但不同种族、性别和社会阶层之间的持续差异挑战了这一理想。有些人将其归因于结构性不平等，而其他人则认为是个人选择的影响。作者发展了一个博弈论模型，其中来自不同社会经济群体的候选人在选择努力水平时会根据社会背景有所不同，并且随着AI工具的个性化职业或薪资指导越来越普遍，这种差异也越来越明显。每个候选人都会在其努力成本与其预计收益之间进行平衡，努力转化成可观察到的成就，选择则基于成就。通过分析大型模型中的唯一纳什均衡，作者推导出了明确的公式的具体表现形式，展示了价值差异和机构选择性共同决定了努力、代表性、社会效益和效用。此外，该研究还提出了一种成本敏感的优化框架，以量化减少差距的方法，而不牺牲机构目标。分析表明，当不同群体的选拔后价值感知不同时，这种差异会导致理性地努力水平差异，并通过“公平”选拔过程产生反馈，从而进一步扩大差距。尽管模型是静态的，但它捕捉到了一个更广泛的反馈关联循环的一部分，即感知、激励和结果之间的联系，通过技术社会环境how techno-social environments shape individual incentives in meritocratic systems将理性选择和社会结构解释结合起来，展示了如何在公平选拔系统中塑造个人激励。", "innovation": "该研究发展了一个博弈论模型，将感知价值差异作为影响努力水平和选拔过程的因素，并提出了一种成本敏感的优化框架，以量化减少差距的方法，而不牺牲机构目标。这一模型揭示了感知偏向导致的偏差问题，并通过合理解释结构化不平等，提供了理解无偏机制如何影响个人动力的新视角。", "conclusion": "尽管模型是静态的，但通过分析揭示了合理选择与结构化不平等之间的关系，指出感知价值差异如何通过选择过程产生合理的行为，从而传播并扩大了原有的不平等。研究提出了一个成本敏感的优化框架，帮助机构在不牺牲其目标的情况下，以减少不平等影响的方式调整选择标准和感知价值。这一框架不仅为政策制定者和机构提供了工具，还进一步理解了技术与社会环境如何塑造个体在公平选拔系统的激励机制。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20739", "html_url": "https://arxiv.org/abs/2510.20739", "title": "在 Node.js 包中由动态程序分析报告的污染流分级学习", "title_en": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in Node.js Packages", "authors": "Ronghao Ni,Aidan Z.H. Yang,Min-Chien Hsu,Nuno Sabino,Limin Jia,Ruben Martins,Darion Cassel,Kevin Cheang", "background": "程序分析工具常常生成大量候选漏洞报告，这些报告需要进行昂贵的手动审查。这一过程带来了实际挑战：如何让安全分析师优先审查最有可能是真正漏洞的报告？", "innovation": "该论文探讨了是否可以应用机器学习来优先处理程序分析工具报告的漏洞。研究使用了包括经典模型、图神经网络（GNNs）、大规模语言模型（LLMs）及其结合的混合模型等多种机器学习方法，在基于动态程序分析工具输出的数据上进行训练。结果显示，顶级的语言模型达到了 $F_{1} = 0.915$，而最好的图神经网络和经典机器学习模型的 $F_{1}$ 数值达到了 $0.904$。在低于7%的假阴性率下，领先模型能够从手动审查中排除66.9%的良性包，平均每包耗时约60毫秒。将最佳模型调整为0.8的精确度（即在所有警告中允许20%的假阳性），该方法能够检测99.2%可利用的污染流，而仅错过0.8%，展示了对实际漏洞分级的强大潜力。", "conclusion": "该研究证明了机器学习方法可以有效提高动态程序分析中漏洞优先审查的效率和准确性，可在保持较高检测率的同时大幅减少需要人工检查的包的数量。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20673", "html_url": "https://arxiv.org/abs/2510.20673", "title": "通过权重偏差校正和位级核心采样实现高效的多位量化网络训练", "title_en": "Efficient Multi-bit Quantization Network Training via Weight Bias Correction and Bit-wise Coreset Sampling", "authors": "Jinhee Kim,Jae Jun An,Kang Eun Jeon,Jong Hwan Ko", "background": "多位量化网络能够通过在单一模型中支持多种精度级别来灵活部署深度神经网络。然而，现有的方法由于全数据集更新重复进行每个支持的位宽导致训练开销很大，这种成本随着精度数量成线性增长。此外，为了支持额外或中间的精度选项，还需要进行额外的微调阶段，进一步增加了整体训练负担。因此，需要解决这些问题的方法来减少训练开销同时也保持模型的实用性。这些问题的现有解决方案包括使用权重偏差校正和位级核心采样策略作为解决方案之一。", "innovation": "本文提出的方法包括两种技术来显著减少训练开销而不损害模型的实用性：1. 通过权重偏差校正实现共享批归一化，这可以消除量化偏差对不同位宽的影响，并对激活分布进行对齐；2. 利用基于梯度重要性评分的核心采样策略，每个子模型可以从通过核心采样策略选出的具有信息性的小规模数据集进行训练。该方法在CIFAR-10/100、TinyImageNet和ImageNet-1K数据集上的实验证明了其方法在保持同等或更好准确性的前提下，训练时间最多可以减少7.88倍。", "conclusion": "本文提出的方法通过使用权重偏差校正和位级核心采样技术，成功地降低了多位量化网络的训练开销，在保持模型实用性的同时，提高了训练效率。实验结果表明，该方法在多种数据集和网络架构下都能实现较好的准确性和显著的训练时间减少。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20653", "html_url": "https://arxiv.org/abs/2510.20653", "title": "在推理时LLM反射中寻找甜蜜点：权衡质量和成本与速度", "title_en": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During Inference-Time LLM Reflection", "authors": "Jack Butler,Nikita Kozodoi,Zainab Afolabi,Brian Tyacke,Gaiar Baimuratov", "background": "随着大规模语言模型（LLMs）的发展，实践者在提升推理时性能方面面临越来越多的选择，无需重新训练模型，包括预算调整和多步技术（如自我反思）。尽管这些方法提高了输出质量，但它们在准确度、成本和延迟之间创建了复杂的权衡，这些权衡在不同领域仍然不甚了解。本文系统地比较了自我反思和预算调整在数学推理和翻译任务中的表现，评估了包括Anthropic Claude、Amazon Nova、Mistral系列在内的主要LLMs的表现，并在不同反省深度和计算预算下分析其帕累托最优性能前沿。研究表明，自我反思的有效性在不同领域存在显著差异，数学推理任务上的性能提升高达220%。此外，还研究了反省轮次深度和反馈机制质量对不同模型家族性能的影响。在实际应用场景中，我们在Lounge by Zalando的营销内容本地化系统中部署了自我反思增强系统，结果表明其在不同市场上的效果不同，强调了部署这些技术时的领域特定评估的重要性。实验结果为特定领域和资源限制下的最佳推理策略提供了实操指导。开源了自我反思实现代码以确保可复现性。", "innovation": "本研究系统地对比了自我反思和预算调整在数学推理和翻译任务中的效果，并通过各种反射深度和计算预算下的测试，得出了帕累托最优性能边界。研究发现自我反思的有效性在不同领域存在显著差异，提供了在不同领域和资源限制下的最佳推理策略的实操指导，也强调了部署这些技术时的领域特定评估的重要性。开源了自我反思实现以确保研究结果的可复现性。", "conclusion": "本研究得出，自我反思在不同领域表现差异显著，尤其是在数学推理任务中，性能提升了220%。自我反思效果受反省轮次深度和反馈机制质量的影响。实践表明，技术的有效性因市场而异，因此在部署这些技术时需要进行领域特定评估。研究结果提供了针对特定领域和资源限制的最佳推理策略。开源代码确保了研究结果的可复现性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20787", "html_url": "https://arxiv.org/abs/2510.20787", "title": "通过混合稀疏注意力和上下文感知可学习的token移除缓解线性注意力的健忘问题", "title_en": "Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention and Contextualized Learnable Token Eviction", "authors": "Mutian He,Philip N. Garner", "background": "线性注意力模型能够将整个输入序列压缩到固定大小的循环状态中，从而为Transformer提供一种高效替代方案。然而，这种模型有限的内存容量会导致遗忘效应，影响检索密集型任务的表现。", "innovation": "开发了一系列混合模型，通过恢复对过去token的直接访问来缓解健忘问题。引入了稀疏注意力机制和可学习的token移除方法，结合滑动窗口注意力机制，以适应性地保留每个注意力头的关键KV对，同时保持线性注意力的时间和空间复杂度。提供了高效的稀疏注意力机制密钥三角算子。", "conclusion": "在检索密集型基准上的实证评估表明，所提出的方法是有效的。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20784", "html_url": "https://arxiv.org/abs/2510.20784", "title": "基于共性的一个AGI衡量指标", "title_en": "A Coherence-Based Measure of AGI", "authors": "Fares Fourati", "background": "近年来，\textcitet{hendrycks2025agidefinition}将\textit{人工通用智能}（AGI）定义为认知领域中人类认知的Cattell-Horn-Carroll（CHC）模型衍生出的能力的算术平均值。尽管这一定义很优雅，但它假设某种领域的优异能力可以抵消其他领域的失败。真正的通用智能应反映全面胜任力——即在所有关键领域都保持平衡的技能。", "innovation": "本文提出了一个基于连续补偿指数上广义平均值积分的共性感知的AGI衡量指标。该指标跨越了算术、几何和调和等不同领域，通过计算曲线下面积（AUC）来衡量不同补偿假设下的鲁棒性。与强调专业化的算术平均值不同，该项指标惩罚不平衡，并捕捉不同领域间相互依赖性。", "conclusion": "将广义平均值应用于GPT-4和GPT-5的CHC领域得分，衡量结果表明这些系统在通用技能方面仍存在很大差距，即使它们在算术得分上非常出色（例如，GPT-5为24%）。该方法提供了一个原则性的、可解释的且更为严格的衡量通用智能进步的基础。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20769", "html_url": "https://arxiv.org/abs/2510.20769", "title": "CSU-PCAST：一种用于中期集合降水预报的双分支变压器框架", "title_en": "CSU-PCAST: A Dual-Branch Transformer Framework for medium-range ensemble Precipitation Forecasting", "authors": "Tianyi Xiong,Haonan Chen", "background": "准确的中期降水预报对于水文气象风险管理和灾害减轻至关重要，但对于目前的数值天气预报（NWP）系统来说仍然是具有挑战性的。传统的集合预报系统，如全球集合预报系统（GEFS），在较远的预报时效内难以维持高技能，尤其是在适度和重度降雨预报方面表现尤为不佳。", "innovation": "本研究开发了一种基于深度学习的集合框架，用于多步降水预测，通过联合建模广泛的气象变量集。模型架构采用了基于补丁的SwinTransformer主体，并结合了周期卷积来处理经度连续性。该模型通过条件层标准化整合了时间嵌入和噪声嵌入，并采用双分支解码器来预测总降水量和其他变量。通过冻结编码器-解码器路径进行专门训练，并使用结合连续排名概率评分（CRPS）和加权对数1加1均方误差（log1pMSE）的混合损失进行训练，以平衡概率准确性和水文学上的可靠性。在推断过程中，模型利用全球预报系统（GFS）的实时初始条件自回归地生成15天的预报。与GEFS相比，CSU-PCAST在IMERG数据评估中的关键成功指数（CSI）更高，特别是在中小到中等和重度降雨的预报方面表现出色。", "conclusion": "研究结果表明，CSU-PCAST框架在预测15天内的中等至重度降雨方面显著优于传统的GEFS系统，提高了水文气象风险管理和灾害减轻的准确性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20797", "html_url": "https://arxiv.org/abs/2510.20797", "title": "简单的上下文压缩：均值池化和多比例训练", "title_en": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training", "authors": "Yair Feldman,Yoav Artzi", "background": "在使用长上下文来进行检索增强生成（RAG）和大型语言模型（LLMs）时，常用的技术是软上下文压缩，即将输入序列转换为更短的连续表示形式以减少计算成本。", "innovation": "作者开发了一种轻量级且简单的均值池化方法，这种方法在所有测试中都表现出色，且当训练多个压缩比例时仅出现相对较小的性能下降。同时，他们还研究了训练同一压缩器以输出多个压缩比例的方法。", "conclusion": "总体而言，本文简单均值池化方法的表现最佳，尽管在训练多个压缩比例时略有性能下降，但在不同架构和训练方式下，压缩方法的权衡更为复杂，显示了压缩方法的复杂性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20748", "html_url": "https://arxiv.org/abs/2510.20748", "title": "强化学习与消费储蓄行为", "title_en": "Reinforcement Learning and Consumption-Savings Behavior", "authors": "Brandon Kaplowitz", "background": "本文探讨了强化学习在解释经济下行期间家庭消费行为中的两个不寻常模式的作用。通过发展出一个假设代理商利用神经网络近似进行消费储蓄决策的模型，作者超越了理性预期假设，模拟了两个关键发现：1）失业且前期流动资产较低的家庭，在面对经济刺激转移时，边际消费倾向（MPC）显著高于资产较高的家庭；2）有更多失业经历的家庭在控制了当前经济状况后，也持续维持较低的消费水平，表现出“伤疤效应”。这些发现与现有的基于收入风险信念更新或先验异质性解释不同。", "innovation": "作者通过引入基于强化学习（Q-learning）机制的模型，利用神经网络近似来解决不确定收入下的消费储蓄决策，从而更好地解释数据。这种机制产生了一个新颖的解释，即价值函数逼近错误随经验而演变，这同时解释了较高的边际消费倾向和较低的消费水平。", "conclusion": "模拟结果与实证估计非常接近，表明通过强化学习进行适应性学习提供了一个统一框架，能够解释个人以往经验如何影响当前消费行为，而不仅仅是当前的经济状况所能预测的。这一研究结果挑战了传统的理预期假设，并为消费储蓄行为的模型提出了新的视角。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20795", "html_url": "https://arxiv.org/abs/2510.20795", "title": "使用球体图神经网络从CMB推断原初磁场参数的贝叶斯推断", "title_en": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with Spherical Graph Neural Networks", "authors": "Juan Alejandro Pinto Castro,Héctor J. Hortúa,Jorge Enrique García-Farieta,Roger Anderson Hurtado", "background": "深度学习已成为现代宇宙学中的变革性方法，能够从复杂的天文学数据集中提取有意义的物理信息。本文利用DeepSphere架构中的深度卷积神经网络，在考虑CMB数据的球形几何结构下，直接从模拟的宇宙微波背景（CMB）图中估计原初磁场（PMF）宇宙学中的关键宇宙参数。为超越确定性的点估计并提供稳健的不确定性量化，本文将贝叶斯神经网络（BNNs）引入框架中，从而捕捉反映模型对其预测自信程度的 aleatoric 和 epistemic 不确定性。", "innovation": "提出了一种新颖的贝叶斯图深学习框架，该框架结合了DeepSphere架构和贝叶斯神经网络，能够从模拟的CMB图中准确估计原初磁场参数，并提供可靠的不确定性量化。该方法不仅实现了CMB图中PMF贡献参数估计的高精度（$R^{2}$得分超过0.89），还通过后训练技术如方差缩放和GPNormal获得了准确的不确定性估计，为精密宇宙学时代的稳健宇宙学推断提供了必要的工具。", "conclusion": "提出的DeepSphere-BNNs框架不仅能够从包含PMF贡献的CMB图中准确估计参数，还提供了可靠的不确定性量化，为精确宇宙学时期的稳健宇宙学推断提供了必要的工具。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20771", "html_url": "https://arxiv.org/abs/2510.20771", "title": "AlphaFlow: Understanding and Improving MeanFlow Models", "title_en": "AlphaFlow: Understanding and Improving MeanFlow Models", "authors": "Huijie Zhang,Aliaksandr Siarohin,Willi Menapace,Michael Vasilkovsky,Sergey Tulyakov,Qing Qu,Ivan Skorokhodov", "background": "MeanFlow作为一种新兴的强大框架，在少量步骤的生成建模中表现出色，但其成功的机制尚未完全理解。", "innovation": "提出了一个新的目标族$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\beta}}))))})Flow}\beta}})$，它统一了轨迹流匹配、Shortcut Model和MeanFlow，通过采用从轨迹流匹配平滑过渡到MeanFlow的课程策略，$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\beta}}))))}$-Flow解离了目标间的冲突，实现了更好的收敛效果。", "conclusion": "实验表明，$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\beta}}))))}$-Flow在从零开始训练ImageNet-1K 256x256类别条件数据集时，使用原始DiT骨干网络的一致表现优于MeanFlow，并且最大的$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\beta}}))))}$-Flow-XL/2+模型在使用原始DiT骨干网络的情况下达到新的最佳结果，FID分数分别为2.58（1-NFE）和2.15（2-NFE）。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20807", "html_url": "https://arxiv.org/abs/2510.20807", "title": "基于像素空间空时变换器的动态物理仿真视频预测", "title_en": "Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers", "authors": "Dean L Slack,G Thomas Hudson,Thomas Winterbottom,Noura Al Moubayed", "background": "受自回归大型语言模型性能和扩展性的启发，基于变换器的模型在视觉领域取得了近期成功。本文研究了这种模型对于视频预测的应用，通过简单端到端的方法比较了各种时空自注意力布局。本文针对现有视频生成方法中常见的因果模型物理仿真时间不足的问题，尝试通过物理对象跟踪指标和未监督训练方法对时空推理解耦，提出了一种简单有效的自回归视频变换器模型，利用连续像素空间表示进行视频预测。该方法无需复杂训练策略或潜在特征学习组件，相较于现有潜在空间方法，显著扩展了物理准确预测的时间范围。", "innovation": "本文提出了一种简单有效的自回归视频变换器模型，利用连续像素空间表示进行视频预测，无需复杂训练策略或潜在特征学习组件。该方法在保持视频质量指标竞争性能的同时，显著延长了物理准确预测的时间范围，比现有潜在空间方法提高了50%。", "conclusion": "本文为基于注意机制的时空视频建模提供了一个简单、参数效率且可解释的平台。通过可解释性实验识别网络区域中编码用于PDE仿真参数准确估计的信息，并发现这种能力可以推广到预测非分布外仿真参数。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20808", "html_url": "https://arxiv.org/abs/2510.20808", "title": "机器人领域中的现实差距：挑战、解决方案及最佳实践", "title_en": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices", "authors": "Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos", "background": "机器学习推动了各种机器人领域的显著进展，包括导航、运动和操作。大量成就依赖于模拟技术作为训练和测试机器人系统的一种关键工具。然而，模拟包含了对现实世界的抽象和近似，导致了模拟与现实之间不可避免的差异（现实差距），从而阻碍了从模拟到现实世界的成功过渡。尽管有各种技术（如领域随机化、现实到模拟的过渡、状态和操作的抽象及模拟与现实的协同训练）已取得了一些进展，但仍存在挑战，需进一步了解现实差距的根本原因及其解决方案", "innovation": "本文综述了从模拟到实际环境的过渡（Sim-to-Real）的现状，强调了现实差距的原因、解决方案和评估标准，提供了一个全面的视角。通过总结现有技术手段和研究，为解决现实差距问题提出了新的见解和建议", "conclusion": "本文为机器人领域中的现实差距问题提供了有针对性的综述，包括其根本原因、现有解决方案和评估方法。这有助于推动机器人技术在现实世界的应用，并为未来研究提供了指导。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20818", "html_url": "https://arxiv.org/abs/2510.20818", "title": "VAMOS: 基于视觉-语言-动作的分层导航模型及其能力调节和可控导航", "title_en": "VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation", "authors": "Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta", "background": "机器人导航的核心挑战在于学习能够在多样环境中泛化，同时遵守特定机器人物理限制和能力的策略（例如，四足机器人能够上楼梯，但轮式机器人不能）。为此，需要一种能够分离语义规划与具体机器人实现的层级方法。", "innovation": "本文提出了VAMOS，一种分层的视觉-语言-动作（VLA）模型，通过将一般性的语义规划与机器人特定的物理约束学习解耦。该模型设计了一个接口，使得高级规划器可以直接在图像空间提出候选路径，条件模型随后进行评估和重新排序。实验结果显示，VAMOS在室内外导航中取得更高的成功率，并且具有跨机器人的可移植性。", "conclusion": "VAMOS模型不仅增强了单个机器人导航的可靠性，还实现了跨不同类型的机器人（如腿式和轮式）的导航，并且可以通过自然语言轻松调整。高度专业的模型对于特定机器人的物理匹配至关重要，使得单一高级规划器可以在差异巨大的机器人上广泛应用。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20810", "html_url": "https://arxiv.org/abs/2510.20810", "title": "LLM生成文本的可检测性：确切来讲，什么是LLM生成的文本？", "title_en": "On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?", "authors": "Mingmeng Geng,Thierry Poibeau", "background": "随着大型语言模型（LLMs）的广泛应用，许多研究人员开始关注检测由这些模型生成的文本。然而，对‘LLM生成的文本’这一目标缺乏一致和精确的定义。不同应用场景下的差异及LLM的多样性进一步增加了检测的难度。通常认为的检测目标通常只代表了LLM可能生成文本的一部分。人类对手动生成文本的编辑，以及LLM对使用者的微妙影响，使得区分LLM生成的文本和人类撰写的文本变得模糊。现有的基准测试和评估方法未能充分应对实际应用中的各种情况，导致检测器的数值结果被误解，其重要性也在减少。", "innovation": "本文识别并强调了‘LLM生成的文本’这一概念的模糊性，并指出现有基准测试和评估方法的不足。研究的贡献在于揭示了仅依靠现有定义和方法进行的检测具有局限性，其结果只能作为参考而非决定性指标。", "conclusion": "检测器在特定条件下仍是有用的，但其结果应该仅被解读为参考而非决定性指标。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.08281", "html_url": "https://arxiv.org/abs/2401.08281", "title": "Faiss库", "title_en": "The Faiss library", "authors": "Matthijs Douze,Alexandr Guzhva,Chengqi Deng,Jeff Johnson,Gergely Szilvasy,Pierre-Emmanuel Mazaré,Maria Lomeli,Lucas Hosseini,Hervé Jégou", "background": "随着AI应用的迅速增长，需要存储和索引的嵌入向量的数量也在增加。Faiss库专注于向量相似性搜索，这是向量数据库的核心功能。Faiss提供了一系列索引方法及相关基本功能，用于搜索、聚类、压缩和变换向量。", "innovation": "这篇论文描述了向量搜索的权衡空间以及Faiss的设计原则，包括结构、优化方法和接口。此外，还对库的关键功能进行了基准测试，并讨论了几种选定的应用场景，以突显Faiss的广泛应用性。", "conclusion": "通过研究Faiss库的设计和功能，可以更好地理解向量搜索的技术决策过程，这对于开发高效的向量数据库和搜索引擎具有重要意义。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.11367", "html_url": "https://arxiv.org/abs/2402.11367", "title": "多重任务逆强化学习中的常识奖励", "title_en": "Multi Task Inverse Reinforcement Learning for Common Sense Reward", "authors": "Neta Glazer,Aviv Navon,Aviv Shamsian,Ethan Fetaya", "background": "在复杂的真实环境中应用强化学习的一个挑战是如何提供一个足够详细的奖励函数。奖励与期望行为之间的任何不对齐可能都会导致意外的结果，比如'奖励破解'，即智能体通过非预期的方式最大化奖励。本文研究如何将奖励拆分为两个独立部分：一个特定于任务的简单奖励和一个未知的一般常识奖励。", "innovation": "提出了一种新的方法，通过将奖励拆分为特定任务奖励和通用常识奖励，并通过专家演示来学习通用常识奖励。进一步表明，多任务逆强化学习可以有效解决单任务逆强化学习无法学习有用奖励函数的问题。", "conclusion": "研究结果表明，同时对多个任务进行训练可以解决使用逆强化学习学习有用的奖励函数的问题。这种方法通过利用多个任务的信息，提升了智能体在复杂环境中的性能和适应性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20809", "html_url": "https://arxiv.org/abs/2510.20809", "title": "Real Deep Research for AI, Robotics and Beyond", "title_en": "Real Deep Research for AI, Robotics and Beyond", "authors": "Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang", "background": "随着AI和机器人学研究的迅速增长，每年发表超过10,000篇论文，研究人员面临越来越大的挑战，难以及时跟进最新动向。快速发展的趋势，跨学科工作增多，以及需要探索自身专业领域之外的领域，都加剧了这一问题。", "innovation": "我们提出了一种通用的管道，能够系统地分析任何研究领域：识别新兴趋势、发现跨领域机会，并为新研究提供具体的起点。通过应用到AI和机器人的领域，特别是基础模型和机器人技术的进步，我们还简要扩展了对其他科学领域的分析。", "conclusion": "本文详细介绍了RDR管道的构建过程，附录中列出了每项分析的主题的详细结果。我们希望这项工作能为从事AI及相关领域的研究人员提供指导。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.12087", "html_url": "https://arxiv.org/abs/2405.12087", "title": "通过机器学习在闪电网络中插值通道余额", "title_en": "Channel Balance Interpolation in the Lightning Network via Machine Learning", "authors": "Vincent Davis,Emanuele Rossi,Vikash Singh", "background": "比特币闪电网络是一个第二层支付协议，旨在通过支付渠道实现快速且成本有效的交易来解决比特币的扩展性问题。已有许多研究关注于平衡探测和多路径支付协议，但仅凭节点和通道特征预测通道余额仍是一个未被探索的领域。这篇文章旨在利用机器学习模型来插值闪电网络中的通道余额，并以此优化网络的路径寻找算法。", "innovation": "本文引入了利用机器学习模型来预测闪电网络中通道余额的方法，这在现有研究中尚属首次。该方法通过评价多种机器学习模型的性能，对比基于启发式的基线模型，提高了预测精度。", "conclusion": "在实验评估中，本文提出的方法表现出色，比50/50拆分的基线模型（即两边各分配通道容量的一半）高出10%的预测精度。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.18512", "html_url": "https://arxiv.org/abs/2402.18512", "title": "Log Neural Controlled Differential Equations: The Lie Brackets Make a Difference", "title_en": "Log Neural Controlled Differential Equations: The Lie Brackets Make a Difference", "authors": "Benjamin Walker,Andrew D. McLeod,Tiexin Qin,Yichuan Cheng,Haoliang Li,Terry Lyons", "background": "受控微分方程（CDE）的向量场描述了控制路径与解路径演化的关联。神经CDE（NCDEs）利用神经网络参数化CDE的向量场，并将时间序列数据视为控制路径的观测值。通过这一形式化，NCDEs具有对抗不规则采样率的稳健性，是建模真实世界数据的强大方法。基于神经粗糙微分方程（NRDEs），本文提出了Log-NCDEs方法，通过引入Log-ODE方法，有效且高效地训练NCDEs，而Log-ODE方法源自粗糙路径研究，用于近似CDE的解。Log-NCDEs在多项具有最多50,000个观测值的多变量时间序列数据集上表现优于NCDEs、NRDEs、线性递归单元、S5和MAMBA。", "innovation": "Log-NCDEs结合了NCDEs的模型优势和Log-ODE方法的计算效率，提出了一种新型、有效且高效的训练方法，特别适用于多变量时间序列数据分析。Log-NCDEs的核心在于Log-ODE方法，该方法来源于粗糙路径研究，用于近似CDE的解。", "conclusion": "实验结果显示，Log-NCDEs在多项多变量时间序列数据集上的表现显著优于NCDEs、NRDEs、线性递归单元、S5和MAMBA，特别是在具有最多50,000个观测值的情况下。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.12961", "html_url": "https://arxiv.org/abs/2405.12961", "title": "通过能量排名对齐连续反馈的转换器", "title_en": "Aligning Transformers with Continuous Feedback via Energy Rank Alignment", "authors": "Shriram Chennakesavalu,Frank Hu,Sebastian Ibarraran,Grant M. Rotskoff", "background": "化学空间搜索是一个极其具有挑战性的问题，因为可能的分子数量随着原子数量的增加而指数级增长。大型自回归模型已经在化学化合物数据库上进行训练，生成了强大的生成器，但我们仍然缺乏生成具有所需性质分子的稳健策略。这个分子搜索问题与大型语言模型的“对齐”问题相似，尽管在许多化学任务上我们有一个特定且容易评估的奖励函数。", "innovation": "本文介绍了一种称为能量排名对齐（ERA）的算法，该算法利用显式的奖励函数来生成梯度基的目标，用于优化自回归策略。理论分析表明，该算法与最近代理策略优化（PPO）和直接偏好优化（DPO）密切相关，但具有一个收敛到理想吉布斯-玻尔兹曼分布的优化器，其中奖励扮演能量函数的角色。此外，该算法具有高度可扩展性，不需要强化学习，并且当每对观测的偏好次数较少时，在性能上优于DPO。", "conclusion": "该方法被用来对齐分子变换器和蛋白质语言模型以分别生成具有外部指定特性的分子和蛋白质序列，发现该方法能够稳健地进行搜索，探索化学空间的多样化部分。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.05088", "html_url": "https://arxiv.org/abs/2406.05088", "title": "优化时间序列预测架构：一种分层神经架构搜索方法", "title_en": "Optimizing Time Series Forecasting Architectures: A Hierarchical Neural Architecture Search Approach", "authors": "Difan Deng,Marius Lindauer", "background": "时间序列预测领域的研究快速发展，引入了许多基于深度学习的模块。尽管提出了越来越多的新预测架构，但尚不清楚我们是否充分利用了这些现有模块的全部潜力。为此，本文提出了一种用于时间序列预测任务的新颖分层神经架构搜索方法。", "innovation": "设计了一种分层搜索空间，集合了多种针对预测任务设计的架构类型，允许不同预测架构模块的有效组合。在长时间序列预测任务上的结果表明，该方法可以搜索出适用于不同预测任务的轻量高性能预测架构。", "conclusion": "在长时间序列预测任务上的结果表明，该方法可以搜索出适用于不同预测任务的轻量高性能预测架构。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.14090", "html_url": "https://arxiv.org/abs/2405.14090", "title": "使用成员查询解决具有未知背包约束的0-1整数程序", "title_en": "Solving 0-1 Integer Programs with Unknown Knapsack Constraints Using Membership Oracles", "authors": "Rosario Messana,Rui Chen,Andrea Lodi,Alberto Ceselli", "background": "在解决组合优化问题时，经常面临背包约束未知的问题。通常，这些问题要求在凹凸限制下优化目标值。作者对标记点使用支持向量机（SVM）进行二元分类的主动学习方法进行了反思，并试图改进现有的线性分离方法和采样策略。", "innovation": "作者提出了基于混合整数二次规划的替代采样策略以及一种受凸优化中算法启发的线性分离方法。具体创新点包括：1) 提出了一个新的采样策略，基于混合-整数二次规划；2) 基于凸优化算法设计了一种新的线性分离方法，并用它来解决带有成员查询的0-1整数规划问题。", "conclusion": "作者在经典的组合优化问题及其现实应用的变体上进行了实验，结果表明不同的线性分离方法和采样策略影响了解的质量，包括目标值、对偶界和运行时间。这些结果展示了改进的采样策略和线性分离方法的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.05064", "html_url": "https://arxiv.org/abs/2406.05064", "title": "使用奖励预测前向训练决策转换器进行上下文多任务结构化多臂 bandit 学习", "title_en": "Pretraining Decision Transformers with Reward Prediction for In-Context Multi-task Structured Bandit Learning", "authors": "Subhojyoti Mukherjee,Josiah P. Hanna,Qiaomin Xie,Robert Nowak", "background": "研究多任务结构化 bandit 问题的学习 to learn 学习，目标是最小化累积后悔并学习一个近似最优的算法。任务之间共享结构，算法应利用共享结构以最小化未来未见过的相关测试任务的累积后悔。利用 transformer 作为决策算法，从演示者在一组训练任务实例中收集的数据中学习共享结构。目标是设计一种训练程序，使得 transformer 可以在未见过的测试任务实例中超越演示者的学习算法。在此之前，前向训练决策转换器的工作要么需要特权信息，如访问最优臂，要么无法超越演示者。这些方法之外，我们提出一种前向训练方法，训练 transformer 网络以学习上下文中的近似最优策略，利用任务之间的共享结构，无需访问最优动作，且能够超越演示者。这些主张在多种结构化的 bandit 问题中进行了验证，表明所提出的解决方案具有普遍适用性，并能快速识别未知测试任务的期望奖励，以支持有效的探索。", "innovation": "提出了一种利用共享结构的前向训练方法，通过奖励预测训练 transformer 网络以学习近似最优的策略，该方法能够不依赖于访问最优动作且能超越演示者的表现。", "conclusion": "所提出的解决方案对多种结构化的 bandit 问题具有普遍适用性，并且能够快速有效地探索未知测试任务以学习期望奖励。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.06300", "html_url": "https://arxiv.org/abs/2410.06300", "title": "通过稀疏傅里叶表示计算SHAP值", "title_en": "SHAP values via sparse Fourier representation", "authors": "Ali Gorji,Andisheh Amrollahi,Andreas Krause", "background": "SHAP (SHapley Additive exPlanations) 值是用于可解释人工智能中局部特征归因的一种广泛使用的方法。本文提出了一种高效的两阶段算法，用于在黑盒模型和基于树的模型中计算SHAP值。这种算法利用了现实世界预测器中的频谱偏差，将模型近似为紧凑的傅里叶表示，这对于树模型是精确的，而对于黑盒模型则近似。这样可以实现全局优化，提高模型的泛化能力，从而更好地解释模型的预测结果。", "innovation": "本文提出的方法通过首次利用傅里叶表示将模型近似，利用了现实世界预测器中的频谱偏差，对于树模型进行精确近似，对于黑盒模型进行近似。然后提出了一个闭式公式，使用傅里叶表示精确计算SHAP值。这种方法将计算线性化为简单的加法，并且可以并行化，因为傅里叶近似只需要计算一次。", "conclusion": "通过这种方法，可以实现加速的SHAP值计算，并且可以调节效率和精度之间的权衡。这种方法显著提升了现有方法的效率，同时还能提供更好的解释性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.16482", "html_url": "https://arxiv.org/abs/2412.16482", "title": "Learn2Mix: 使用适应性数据集成训练神经网络", "title_en": "Learn2Mix: Training Neural Networks Using Adaptive Data Integration", "authors": "Shyam Venkatasubramanian,Vahid Tarokh", "background": "在资源受限的环境中，加速模型收敛对于快速且高效的神经网络训练至关重要。传统的训练方法使用固定的类别比例，这可能导致训练过程较慢。因此，需要一种新的训练策略来动态调整类别比例，特别是在类别错误率较高的情况下。", "innovation": "本文提出了一种新的训练策略 learn2mix，该策略能够在训练过程中自适应地调整批次内的类别比例，特别关注错误率较高的类别。与传统方法不同，learn2mix 方法在训练过程中不断调整类别比例，从而加快了模型的收敛速度。实验证明，在资源有限和类别不平衡的情况下，使用 learn2mix 训练的神经网络的收敛速度和分类、回归和重构任务上的性能均优于现有方法。", "conclusion": "实验证明，利用 learn2mix 方法训练的神经网络在分类、回归和重构任务上比现有方法更快地收敛并取得了更好的结果。理论分析支持了我们的实验发现。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.22264", "html_url": "https://arxiv.org/abs/2410.22264", "title": "低秩适应的可证明元学习", "title_en": "Provable Meta-Learning with Low-Rank Adaptations", "authors": "Jacob L. Block,Sundararajan Srinivasan,Liam Collins,Aryan Mokhtari,Sanjay Shakkottai", "background": "基础模型（FMs）因其强大的表征学习能力而具有广泛任务适应性，但这些预训练模型需要额外的训练阶段才能有效应用于下游应用。在多任务场景中，已有研究表明一些高效的微调方法（参数高效微调，PEFT）可以通过特定的元学习方法进行模型准备，从而在参数高效微调方面优于传统重新训练方法，但元学习机制的原理尚未充分探索。因此，研究引入了一个通用的PEFT基础的元学习框架，旨在学习一个能够容易适应未见过任务的模型。特别地，对于使用LoRA的线性模型，证明了传统的重新训练在寻找适应性参数集方面是不可证明的次优解，并且提供了我们提出方法的严格性能保证。", "innovation": "本研究提出了一个通用框架，用于基于低秩适应的元学习，以学习能够轻松适应不常见任务的模型。特别是在使用LoRA的线性模型中，我们证明了传统的重新训练方法在找到适应性参数集方面的局限性，并提供了我们方法的严格性能保证。我们通过使用合成数据和现实数据中的视觉和语言任务验证了这些理论见解，观察到使用我们提出的元学习方案进行重新训练时的显著性能提升，相对于传统的做法，这种方法更为简单易行。", "conclusion": "研究表明，相比于传统的重新训练方法，基于低秩适应的元学习方法能够提供更好的性能保证和显著的性能提升，特别是在线性模型中优化参数高效微调方面。这一发现对于提高基础模型在多任务环境下的适应性具有重要意义。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.07812", "html_url": "https://arxiv.org/abs/2410.07812", "title": "Temporal-Difference Variational Continual Learning", "title_en": "Temporal-Difference Variational Continual Learning", "authors": "Luckeciano C. Melo,Alessandro Abate,Yarin Gal", "background": "在现实世界的应用中，机器学习模型必须不断学习新的任务以适应数据生成分布的变化。然而，在持续学习（Continual Learning, CL）中，模型难以同时平衡新任务的学习（灵活性）和保持先前知识（记忆稳定性）。这导致了灾难性遗忘（Catastrophic Forgetting）现象，即模型在学习新任务时会忘记先前的知识，导致性能下降并降低部署系统的可靠性。在贝叶斯持续学习文献中，变分方法通过采用递归更新后验分布的学习目标来解决这一挑战，同时将后验分布约束在靠近其先前估计。然而，这些方法可能因递归过程中累积的近似误差而失效。", "innovation": "为了缓解这一问题，作者提出了新的学习目标，将多个先前后验估计的正则化效果整合进来，防止个别错误在未来的后验更新中占主导和随时间累积。这些目标与时差方法（Temporal-Difference methods）建立了联系，时差方法是强化学习和神经科学中的流行学习机制。通过在挑战性的持续学习基准测试上的实验，作者证明了这种方法可以有效缓解灾难性遗忘，优于现有的变分持续学习方法。", "conclusion": "本文提出了一种新的学习目标，通过整合多个先前后验估计的正则化效果来有效缓解灾难性遗忘问题，实验结果表明该方法优于现有的变分持续学习方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02770", "html_url": "https://arxiv.org/abs/2502.02770", "title": "Twilight: 采用分层Top-p剪枝的自适应注意力稀疏性", "title_en": "Twilight: Adaptive Attention Sparsity with Hierarchical Top-$p$ Pruning", "authors": "Chaofan Lin,Jiaming Tang,Shuo Yang,Hanshuo Wang,Tian Tang,Boyu Tian,Ion Stoica,Song Han,Mingyu Gao", "background": "利用注意力稀疏性加速长上下文大型语言模型(LLMs)的研究已成为热点。然而，当前算法如稀疏注意力或基于键值(KV)缓存压缩倾向于使用固定的预算，这在实际部署中会带来显著挑战，因为它们未能考虑到实际场景中准确性和效率之间最优平衡的变化。", "innovation": "本文发现将Top-p采样（核采样）引入稀疏注意力可以实现自适应预算。基于此，提出了Twilight框架，无需牺牲准确性即可将自适应稀疏性应用于任何现有的稀疏注意力算法。实验结果表明，Twilight最多可以自适应地修剪98%的冗余标记，导致自我注意力操作加速15.4倍，端到端每个标记的延迟加速3.9倍。", "conclusion": "Twilight框架能够在保持准确性的前提下，自适应地对稀疏注意力算法进行剪枝，显著加速了长上下文LLM的解码过程，展示了其在提升模型效率方面的潜力。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20819", "html_url": "https://arxiv.org/abs/2510.20819", "title": "通用对比和预测潜在扩散桥梁以实现模态转换", "title_en": "Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge", "authors": "Nimrod Berman,Omkar Joglekar,Eitan Kosman,Dotan Di Castro,Omri Azencot", "background": "近年来，生成模型中的扩散模型已被视为从复杂数据分布中采样的领先工具。尽管这些模型在单一模态领域（如图像和音频）上表现出色，但将其能力扩展到模态转换（MT），即在不同感官模态之间进行信息翻译，仍然是一个开放的挑战。现有方法通常依赖于共享维度、高斯先验和特定模态的架构等限制性假设，这限制了它们的通用性和理论依据。", "innovation": "作者提出了一个通用的模态翻译框架，称为潜在去噪扩散桥梁模型（LDDBM），它基于扩散桥梁模型的潜在变量扩展。该方法在共享的潜在空间中操作，无需对齐维度就可以学习任意模态之间的桥梁。引入了对比对齐损失以确保配对样本之间的语义一致性，并设计了领域无关的编码器-解码器架构，专门用于噪声预测。还提出了一种预测损失以指导训练以实现准确的跨域翻译，并探索了多种训练策略以提高稳定性。", "conclusion": "该方法支持任意模态对，并在多种模态转换任务（如多视图到3D形状生成、图像超分辨率和多视图场景合成）上表现出色。全面的实验和切除实验验证了该框架的有效性，建立了通用模态转换的新强劲基准。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.12412", "html_url": "https://arxiv.org/abs/2405.12412", "title": "通过条件一致度评估神经回归器的概率拟合", "title_en": "Assessing the Probabilistic Fit of Neural Regressors via Conditional Congruence", "authors": "Spencer Young,Riley Sinema,Cole Edgren,Andrew Hall,Nathan Dong,Porter Jenkins", "background": "尽管在构建能够表示不确定性的神经网络方面取得了显著进展，深度网络仍然经常表现出过度自信和预测分布不一致的问题。现有的评估这种不一致的方法主要是在校准框架下开发的，常用的指标有期望校准误差(ECE)。然而，校准只能提供概率一致性的边际评估，而不能诊断每个输入在点级上的可靠性，这对于实际决策很重要。已有研究主要关注概率校准，但缺乏一个能够全面评估概率拟合的条件一致性标准。本文即在此背景下提出了一个新的条件一致性标准及其评估指标条件一致性误差(CCE)，该指标可以更准确地评估神经网络的预测分布与实际情况的差距。", "innovation": "提出了一个新的评估神经网络概率拟合的条件一致性标准及其指标条件一致性误差(CCE)，该指标能够评估神经网络在每个点上的预测分布与真实分布之间的距离，具有正确性、单调性、可靠性和鲁棒性等优点。不同于传统的校准方法，CCE可以从点级诊断网络预测的可靠性，为实际决策提供了更好的支持。", "conclusion": "进行了多个高维回归任务的测试，结果表明，条件一致性误差(CCE)具有正确的评估结果、单调性、可靠性和鲁棒性等特性，能够在实际决策中更准确地诊断网络预测的可靠性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.20984", "html_url": "https://arxiv.org/abs/2412.20984", "title": "帕累托最优能量对齐用于设计类似天然的抗体", "title_en": "Pareto-Optimal Energy Alignment for Designing Nature-Like Antibodies", "authors": "Yibo Wen,Chenwei Xu,Jerry Yao-Chieh Hu,Kaize Ding,Han Liu", "background": "该研究提出了一种针对抗体序列-结构共设计的深度学习模型训练框架。通过三个阶段逐步训练模型：首先使用大量抗体序列数据预训练语言模型；接着利用通过的语言模型优化指导扩散模型，实现序列和结构的联合优化；最后通过优化，使模型更倾向于设计出低排斥性且高亲和性的抗体，以此提升设计的合理性和功能性。此外，通过扩展AbDPO（抗体直接偏好优化），模型可以在多重能量对齐目标下向帕累托最优努力。在实际应用中，该方法在生成比基线和先前技术更优质的抗体设计方面表现出了高稳定性和效率。实验结果表明，该方法能够生成具有高亲和力的类似天然的抗体。", "innovation": "1. 提出一种针对抗体序列-结构共设计的三阶段训练框架。\n2. 通过扩展AbDPO，引入帕累托最优能量对齐下的多目标优化方法，指导模型倾向于产生最优平衡的抗体设计。\n3. 引入温度缩放下的迭代学习范式，使模型能够更灵活地利用多样化的在线数据集，无需额外的数据输入。\n4. 通过对比实验展示了该方法在生成具有高亲和力的类似天然抗体方面的优势。", "conclusion": "本研究提出的方法在抗体序列-结构共设计中展示了优越的性能，通过优化后的模型能够生成更高质量的、具有高亲和力的类似天然的抗体。该方法不仅提升了抗体设计的合理性，还提升了设计效率和稳定性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.09805", "html_url": "https://arxiv.org/abs/2412.09805", "title": "在不同协变性水平下的经典GNN作为强基准：平滑性-泛化视角", "title_en": "Making Classic GNNs Strong Baselines Across Varying Homophily: A Smoothness-Generalization Perspective", "authors": "Ming Gu,Zhuonan Zheng,Sheng Zhou,Meihan Liu,Jiawei Chen,Tanyu Qiao,Liangcheng Li,Jiajun Bu", "background": "GNNs在图数据处理上取得了显著成功，但通常被认为在不同水平的协变性图中面临挑战。近期研究发现，通过适当的超参数调优，同质性的GNNs在不同协变性水平的数据集上也能表现出色。然而，其背后的理论支持以及有效的架构设计仍然不清楚。本文旨在推动GNN在不同协变性水平上的普遍性，作者重新探讨了GNN的信息传递机制，揭露了一种新颖的平滑性-泛化矛盾，即增加跳跃数会增强平滑性但会损害泛化能力。这种矛盾妨碍了在高阶同质性邻域和所有异质性邻域中的学习，因为这些邻域中的泛化能力对敏感度高的类别分布至关重要。现有基准和30个模型的对比显示，引入Inceptive Graph Neural Network (IGNN) 有助于缓解这种矛盾，IGNN采用了三条简单有效的设计原则，能实现跳跃级别的泛化能力，并通过自适应平滑度提升整体泛化能力。", "innovation": "本文的创新在于理论重新审视GNN信息传递机制，发现卷积信息如何随距离增加而平滑，揭示了增加跳跃数增强平滑性同时损害泛化能力的矛盾，这一发现对GNN设计提出了挑战。基于这一发现，作者提出了Inceptive Graph Neural Network (IGNN)，通过束级别的泛化实现及自适应平滑度提升性能，针对多种不同聚类层次的数据集，IGNN展示了在某些同质性GNN变体下的显著泛化性能。", "conclusion": "基准测试表明，IGNN不仅在某些特定情况下展示了优越性，还揭示了某些同质性GNN变体存在潜在的泛化普遍性。为此，作者提供了IGNN的代码和数据集，以供进一步研究。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05325", "html_url": "https://arxiv.org/abs/2502.05325", "title": "从反事实到树：模型提取攻击的竞争分析", "title_en": "From Counterfactuals to Trees: Competitive Analysis of Model Extraction Attacks", "authors": "Awa Khouna,Julien Ferry,Thibaut Vidal", "background": "随着机器学习即服务（MLaaS）的发展，模型解释性和安全性的权衡加剧。解释性技术，如反事实解释，会无意中增加模型提取攻击的风险，使未经授权复制专有模型成为可能。", "innovation": "本文从竞争分析的角度首次正式分析了模型提取攻击，提出了一种基础框架来评估其效率。针对基于加性决策树的模型（如决策树、梯度提升和随机森林），引入了新型重建算法，确保达到证明完美忠实度的同时展示了强大的即插即用性能。框架提供了提取基于树模型所需查询复杂性的理论上限，从而揭示了其部署的安全漏洞。", "conclusion": "本文通过竞争分析框架，首次正式分析了模型提取攻击，针对基于加性决策树的模型提出了新的重建算法，提出了提取树模型的查询复杂性理论上限，揭示了其部署中的安全漏洞。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03393", "html_url": "https://arxiv.org/abs/2502.03393", "title": "基于隔室原型预训练的流行病时间序列预测", "title_en": "Pre-training Epidemic Time Series Forecasters with Compartmental Prototypes", "authors": "Zewen Liu,Juntong Ni,Max S. Y. Lau,Wei Jin", "background": "准确的疫情预测对于应对疫情至关重要，但现有的数据驱动模型往往脆弱。它们通常仅基于单一病原体训练，在新的疫情爆发中面临数据不足的挑战，并且在病毒进化或干预措施引起的数据分布转移时会失效。然而，长期以来针对多种疾病的监测数据提供了一个未被充分利用的知识转移来源。为了利用历史经验的集体智慧，我们提出了CAPE，这是第一个开源的预训练模型，用于流行病预测。与忽视流行病学挑战的现有时间序列基础模型不同，CAPE将流行病动态建模为潜在人群状态的混合体，称为间隔原型。它直接从监测数据中发现了一个灵活的间隔原型词典，使每次疫情爆发都可以表示为随时间变化的混合体，将观测到的感染与潜在的人群状态联系起来。为了促进鲁棒泛化，CAPE结合了自我监督的预训练目标和轻量级的流行病意识正则化器，以使学习到的原型与流行病学语义对齐。在涵盖17种疾病和50多个地区的综合基准测试中，CAPE在零样本、少样本和全样本预测中显著优于强大的基线模型。这项工作代表了朝着既具有转移性又具有流行病学基础的预训练流行病模型的理论性进步。", "innovation": "提出了第一个开源的预训练模型CAPE，用于流行病预测。CAPE可以通过监测数据中直接发现的潜在群体状态词典，将疫情爆发表示为随时间变化的混合体，从而实现疫情预测。同时，通过自我监督的预训练目标和轻量级的流行病意识正则化器，使学习到的原型与流行病学语义对齐，以促进模型的鲁棒泛化。", "conclusion": "在涵盖17种疾病和50多个地区的综合基准测试中，CAPE在零样本、少样本和全样本预测中显著优于强大的基线模型，代表了朝着既具有转移性又具有流行病学基础的预训练流行病模型的理论性进步。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09324", "html_url": "https://arxiv.org/abs/2502.09324", "title": "通过辫体排列确定神经网络的深度界限", "title_en": "Depth-Bounds for Neural Networks via the Braid Arrangement", "authors": "Moritz Grillo,Christoph Hertrich,Georg Loho", "background": "在ReLU网络中精确表示所有连续和分段线性函数的隐藏层数量尚是一个开放问题。虽然在特定情况下该问题已经得到了解决，但一般情况下最好的下界仍然是2。本研究专注于与某些多面体复形兼容的神经网络，尤其是与辫扇相关联的网络。对于这些网络，证明了需要非恒定的至少Ω(log log d)隐藏层来准确表示d个数的最大值。此外，在假设下，我们提供了一个组合证明，证明了需要3个隐藏层来计算5个数的最大值，这一直只有通过繁重的计算才能验证。", "innovation": "研究证明了与辫扇相关的神经网络中表示d个数最大值所需的隐藏层数量的下界为Ω(log log d)。在假设条件下，提供了计算5个数最大值需要3个隐藏层的新组合证明。进一步表明，对于maxout网络，最佳已知上限的一般化不准确，一个秩为3的maxout层后接一个秩为2的maxout层足以表示7个数的最大值。", "conclusion": "研究提出了与辫扇相关的神经网络中表示d个数最大值所需的隐藏层数量的下界，并证明了计算5个数最大值需要3个隐藏层。同时指出了maxout网络的最佳已知上限的一般化不是紧的，并给出一个具体的构造证明。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.11564", "html_url": "https://arxiv.org/abs/2502.11564", "title": "连续的语言建模扩散模型", "title_en": "Continuous Diffusion Model for Language Modeling", "authors": "Jaehyeong Jo,Sung Ju Hwang", "background": "扩散模型在离散类别数据建模方面已成为自回归模型的有前途的替代方案。然而，直接在离散数据空间工作的扩散模型无法充分利用迭代细化的全部潜力，因为信号在离散状态之间的转换中丢失。现有的针对离散数据的连续扩散模型不佳，这阻碍了有效扩散模型的开发。目前缺乏两者之间的清晰联系，限制了离散数据上的扩散模型发展。", "innovation": "提出了一个结合了潜在类别分布几何结构的连续扩散模型用于语言建模。建立了离散扩散和统计流形上的连续流动之间的联系，并在此基础上，引入了一种推广现有离散扩散模型的简单扩散过程。进一步提出了基于径向对称的无模拟训练框架，同时提供了一种简单的方法来解决流形上的高维问题。实验结果表明该方法优于现有的离散扩散模型，并接近自回归模型的性能。", "conclusion": "在语言建模基准和其他模态上的全面实验表明，我们的方法优于现有的离散扩散模型，并接近自回归模型的性能。代码可在以下链接获取：this https URL."}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.19670", "html_url": "https://arxiv.org/abs/2502.19670", "title": "通过建模噪声依赖性训练鲁棒的图神经网络", "title_en": "Training Robust Graph Neural Networks by Modeling Noise Dependencies", "authors": "Yeonjun In,Kanghoon Yoon,Sukwon Yun,Kibum Kim,Sungchul Kim,Chanyoung Park", "background": "在现实应用中，图中的节点特征往往包含来自各种来源的噪声，这导致图神经网络（GNN）性能显著下降。尽管已经有多个方法被开发来增强鲁棒性，但这些方法依赖于一个不切实际的假设，即节点特征噪声与图结构和节点标签无关，从而限制了它们的应用范围。", "innovation": "本文引入了一个更实际的噪声模型，即图上的依赖型噪声 (DANG)，其中节点特征噪声创建了一条噪声依赖链，传播到图结构和节点标签。提出了一个新颖的鲁棒GNN，DA-GNN，通过变分推理捕捉DANG的数据生成过程（DGP）中变量之间的因果关系。还提出了新的基准数据集，模拟了DANG，以推动鲁棒GNN的更实际研究。", "conclusion": "广泛的实验表明，在各种噪声场景下，包括DANG和该领域通常考虑的传统噪声模型，DA-GNN都能始终如一地超越现有基准。代码在 this https URL 可用。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.16076", "html_url": "https://arxiv.org/abs/2502.16076", "title": "在任意目标对齐下利用特征共振进行离分布节点检测", "title_en": "Harnessing Feature Resonance under Arbitrary Target Alignment for Out-of-Distribution Node Detection", "authors": "Shenzhi Yang,Junbo Zhao,Sharon Li,Shouqing Yang,Dingyu Yang,Xiaofang Zhang,Haobo Wang", "background": "在图神经网络中检测离分布节点（OOD）非常具有挑战性，特别是当分布内节点（ID）的多类别标签不可用时。因此，该研究集中于特征空间而非标签空间，发现了理想情况下，在优化已知ID样本的过程中，未知ID样本的特征表示变化比OOD样本更加显著，即使模型是被训练去拟合随机目标的，我们将这一现象称为“特征共振”。通过分析局部流形的连续变化，发现即使没有真实标签，局部流形可能仍然表现出平滑共振。", "innovation": "提出了一个新的图神经网络的OOD检测框架——基于共振分离与学习（RSL），该框架包含两个核心模块：(i)一种更实际的微尺度特征共振的代理指标，用于衡量一个训练步骤内特征向量的移动；(ii)整合合成OOD节点策略，以训练有效的OOD分类器。理论分析证明在共振期间OOD节点具有优越的可分离性。实验证明RSL在13个真实世界图数据集上达到了最先进的性能。", "conclusion": "该研究提出了基于共振现象的新型图神经网络OOD检测框架RSL，并通过理论和实验证明其有效性和优越性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.19335", "html_url": "https://arxiv.org/abs/2502.19335", "title": "门卫：通过置信度调整改进模型级联", "title_en": "Gatekeeper: Improving Model Cascades Through Confidence Tuning", "authors": "Stephan Rabanser,Nathalie Rauschmayr,Achin Kulshrestha,Petra Poklukar,Wittawat Jitkrittum,Sean Augenstein,Congchao Wang,Federico Tombari", "background": "大型机器学习模型在许多任务中展现出强大的性能，但同时也伴随着显著的计算和资源限制。为了解决这些挑战，通常会在大型模型旁边部署小型模型，利用路由和分发机制将复杂任务卸载到大型模型。然而，现有的方法往往未能很好地平衡这些模型的能力，导致不必要的分发或资源使用的低效率。本文提出了一种名为Gatekeeper的新损失函数，用于校准级联架构中的小型模型。该方法通过微调较小的模型来自信地处理它可以正确执行的任务，而将复杂的任务分发给更大的模型。此外，该方法还包含一个机制来管理模型性能和分发准确性之间的权衡，并且可以在各种任务和领域中广泛应用于无需任何架构的改变。我们在仅编码器、仅解码器和编码器-解码器架构上评估了我们的方法。实验结果显示，我们的方法显著提高了分发性能。", "innovation": "提出了一种名为Gatekeeper的新损失函数，该方法旨在微调较小的模型以自信地处理其可以正确执行的任务，并将复杂的任务分发给更大的模型，同时通过机制管理模型性能和分发准确性的权衡，且这种方法适用于各种任务和领域无需任何架构修改。", "conclusion": "通过在包括图像分类、语言建模和视觉-语言任务等不同任务中评估Gatekeeper方法，实验结果表明，该方法能够显著提升分发性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.01455", "html_url": "https://arxiv.org/abs/2503.01455", "title": "正则决策树：解决具有任意分割规则的最优决策树问题的公理化框架", "title_en": "Proper decision trees: An axiomatic framework for solving optimal decision tree problems with arbitrary splitting rules", "authors": "Xi He,Max A. Little", "background": "该论文构建了一个公理化的框架来分析决策树的算法性质。该框架通过结构和祖先约束来支持在严格的数学基础上对决策树问题进行分类。焦点是所谓的‘正则决策树’，因为这种类型的决策树既多用途又有效。正则决策树涵盖了包括二叉空间分割树、K-D树和机器学习决策树模型在内的多种著名数据结构。", "innovation": "1. 提出了正则决策树的概念，并证明了只有正则决策树可以被唯一地定义为K排列，而典型的非正则决策树则具有更高的复杂性。\n2. 开发了一种通用的算法方法来解决任意分割规则和目标函数下的最优决策树问题。\n3. 建立了一种通用的动态规划递归算法来精确解决这些问题，但证明了用于存储数据集和子树的备忘化通常在空间复杂性方面是不现实的。\n4. 扩展了分析到几种非正则决策树，如二元特征数据上的决策树、二叉搜索树和矩阵链乘法问题中的树结构，并展示了如何通过对某些公理进行修改或丢弃来解决这些问题。", "conclusion": "该框架进一步考虑了树深度和叶子大小等约束，并利用如稀疏化等技术进行加速。论文还分析了其他一些非正则决策树问题，并展示了这些问题可以通过适当修改或丢弃某些公理来获得解答。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.24123", "html_url": "https://arxiv.org/abs/2503.24123", "title": "CTSketch: 组合张量草图化技术实现可扩展的神经符号学习", "title_en": "CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic Learning", "authors": "Seewon Choi,Alaia Solko-Breslin,Rajeev Alur,Eric Wong", "background": "许多计算任务可以通过将神经网络的组成与离散符号程序相结合来改进。神经符号学习的目标是通过端到端的输入输出标签来训练神经网络。本文基于这种需求，介绍了CTSketch算法，该算法旨在通过将符号程序分解成子程序并通过构建示草图张量来提高神经符号推理的可扩展性。", "innovation": "CTSketch引入了将符号程序分解为子程序并用示草图张量总结每个子程序的技术，允许通过简单的张量操作来近似程序的输出分布。此外，论文通过理论分析提供了最大近似误差的见解，并在神经符号学习文献中的基准测试上评估了CTSketch的表现，结果证明了CTSketch能够推动神经符号学习达到新的规模。", "conclusion": "CTSketch能够使神经符号学习达到前所未有的规模，即使在仅监督最终输出的情况下，神经预测器也能够对具有1000个输入的任务获得高精度。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15846", "html_url": "https://arxiv.org/abs/2504.15846", "title": "基于自适应PCA的多特征时间序列离群点检测方法在空间探测任务中的应用", "title_en": "Adaptive PCA-Based Outlier Detection for Multi-Feature Time Series in Space Missions", "authors": "Jonah Ekelund,Savvas Raptis,Vicki Toy-Edens,Wenli Mo,Drew L. Turner,Ian J. Cohen,Stefano Markidis", "background": "对多特征时间序列数据的分析对于空间探测任务至关重要，能够有效进行事件检测，尤其是实时检测在轨道上的事件，这是实现自动分析的关键。然而，受限于有限的机载计算资源和数据下传限制，需要开发稳健的实时离群点识别方法。", "innovation": "本文提出了一种基于主成分分析（PCA）重建误差的自适应离群点检测算法，该算法专为空间探测任务设计。通过使用增量PCA动态适应不断变化的数据分布，该算法能够在无需先验模型的情况下部署。“预缩放”过程能确保每个特征的幅度归一化，同时保留特征内部的相对变异。", "conclusion": "该算法通过NASA的MMS任务观察数据证明了其在检测空间等离子体事件（不同空间环境、日/夜侧瞬态现象和过渡层）的有效性。该方法还成功应用于NASA的THEMIS数据，证明了通过机载可用测量识别日侧瞬态事件的能力。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.07591", "html_url": "https://arxiv.org/abs/2502.07591", "title": "DMWM: 具有长期想象能力的双心智世界模型", "title_en": "DMWM: Dual-Mind World Model with Long-Term Imagination", "authors": "Lingyi Wang,Rashed Shelim,Walid Saad,Naren Ramakrishnan", "background": "世界模型对于代理学习长期政策至关重要，而现有的基于循环状态空间模型（RSSM）的世界模型依赖于单步统计推断来捕获环境动态，无法进行长期想象任务，因为预测误差会累积，导致无法进行长时间的推理。", "innovation": "本文提出了一个创新的双心智世界模型（DMWM）框架，该框架通过集成逻辑推理以实现逻辑一致性的想象。DMWM 由两个部分组成：基于 RSSM 的直观处理状态转换的系统1（RSSM-S1）和通过分层深入逻辑推理引导想象过程的逻辑综合神经网络系统2（LINN-S2）。系统之间的反馈机制确保想象过程遵循真实环境的逻辑规则。实验结果表明，与最先进的世界模型相比，提出的框架在逻辑连贯性、试验效率、数据效率和长期想象等方面取得了显著改进。", "conclusion": "本文提出的 DMWM 框架在多种 DMControl 基准任务中表现优异，证明了通过逻辑推理融入长期模仿能力的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12801", "html_url": "https://arxiv.org/abs/2504.12801", "title": "从零开始 sparse 训练的 reparameterizing 方法：Sign-In to the Lottery", "title_en": "Sign-In to the Lottery: Reparameterizing Sparse Training From Scratch", "authors": "Advait Gadhikar,Tom Jacobs,Chao Zhou,Rebekka Burkholz", "background": "从零开始训练稀疏神经网络（PaI）与从密集到稀疏训练之间的性能差距是高效深度学习的主要障碍。根据彩票票假说，PaI 关键在于找到特定问题的参数初始化。我们证明，为此目的，确定正确的参数符号是足够的。然而，这些参数符号仍旧是PaI难以解决的问题。", "innovation": "我们提出了Sign-In，这是一种使用动态重参数化的方法，可以证明此方法会导致符号翻转。这类符号翻转与从密集到稀疏训练可以完成的翻转互补，使Sign-In成为一种互补方法。我们的实验和理论表明，这有助于PaI的性能改进，但也指出了将PaI与从密集到稀疏训练之间差距的主要开放挑战。", "conclusion": "尽管我们的实验和理论建议PaI性能改进，但也指出了关闭PaI与从密集到稀疏训练之间差距的主要开放挑战。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.18807", "html_url": "https://arxiv.org/abs/2503.18807", "title": "Markovian Stream-The Fed 的联邦学习", "title_en": "Streaming Federated Learning with Markovian Data", "authors": "Tan-Khiem Huynh,Malcolm Egan,Giovanni Neglia,Jean-Marie Gorce", "background": "联邦学习（FL）已作为实现通信高效协作学习的关键框架而被广泛认可。然而，大多数理论和实证研究均基于客户端能访问预先收集的数据集的假设，较少探讨客户端持续收集数据的情况。在许多实际应用中，尤其是数据由物理或生物过程生成的场景下，客户端的数据流通常被建模为非平稳马尔可夫过程。与标准的独立同分布（i.i.d.）抽样不同，马尔可夫数据流的联邦学习表现由于随时间对客户数据样本的统计依赖性而难以理解。本文探讨在马尔可夫数据流情况下，联邦学习能否支持协作学习，并分析了MiniBatch SGD、Local SGD及其具有动量的变体的表现。在标准假设和光滑非凸客户端目标函数下，样本复杂度与客户端数量的倒数成正比，通信复杂度与i.i.d.情况相当。然而，对于马尔可夫数据流，样本复杂度仍然高于标准抽样情况。", "innovation": "本文分析了在马尔可夫数据流情况下等MiniBatch SGD、Local SGD及其具有动量的变体的性能，揭示了联邦学习在马尔可夫数据流中的表现，并指出在标准假设和光滑非凸客户端目标函数下，样本复杂度与客户端数量的倒数成正比，通信复杂度与i.i.d.情况相当，这为理解联邦学习在马尔可夫数据流中的表现提供了依据。", "conclusion": "在标准假设和光滑非凸客户端目标函数下，联邦学习在马尔可夫数据流中的样本复杂度与客户端数量的倒数成正比，并具有与i.i.d.情况相当的通信复杂度。然而，对于马尔可夫数据流，样本复杂度仍然高于标准抽样情况。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.01618", "html_url": "https://arxiv.org/abs/2505.01618", "title": "不要懒惰：CompleteP 使深度变压器计算高效", "title_en": "Don't be lazy: CompleteP enables compute-efficient deep transformers", "authors": "Nolan Dey,Bin Claire Zhang,Lorenzo Noci,Mufan Li,Blake Bordelon,Shane Bergsma,Cengiz Pehlevan,Boris Hanin,Joel Hestness", "background": "研究了在使用不同参数化（即随着模型大小变化调整模型和优化器超参数的规则）进行大规模语言模型（LLM）训练时的计算效率。不同的参数化可能导致最优基础超参数（如学习率）无法在不同模型深度下进行有效转移，这就要求实践者在扩展模型时重新调整这些超参数（这很耗时），或者在重新调整不可行时接受次优的训练效果。", "innovation": "提出了名为CompleteP的参数化方法，能够在所有层实现深度相关的超参数转移和非懒惰学习。CompleteP使得模型宽度/深度比能够保持计算效率，解锁更适合各种硬件环境和工作场景的模型形状，并相比先前的最佳方法实现12-34%的计算效率提升。", "conclusion": "所有实验均在Cerebras CS-3系统上进行，一种最小实现已在GitHub上提供。CompleteP参数化方法在保持计算效率的同时，有效解决了模型深度和非线性使用的问题，为不同硬件和应用场景提供了更好的模型结构选择。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.04738", "html_url": "https://arxiv.org/abs/2505.04738", "title": "SetONet：一种基于集合的操作网络以解决具有可变输入采样的PDE问题", "title_en": "SetONet: A Set-Based Operator Network for Solving PDEs with Variable-Input Sampling", "authors": "Stepan Tretiakov,Xingjian Li,Krishna Kumar", "background": "深度操作网络（DeepONet）在学习函数空间之间的映射以求解偏微分方程方面表现出潜力。然而，标准的DeepONet需要输入函数在固定位置采样，这限制了其在传感器配置变化或输入存在于非规则网格上的情况下的应用。", "innovation": "提出了Set Operators Network（SetONet），通过修改分支网络以处理输入函数作为无序集合的位置-值对，引入Deep Sets原理确保了不变性同时保持与基准模型相同的参数数量。SetONet具有如下创新：它能够处理自然表示为无序点云（如点源或密度样本）的输入，而不仅仅是固定网格上的值；能够在不进行栅格化或多阶段管道的情况下学习操作符，适用于点源热传导、对流扩散建模化学羽流和密度样本之间的最优传输等具体问题。", "conclusion": "SetONet作为一种DeepONet类架构，以轻量级设计解决了具有变化、不完整或无结构输入数据的问题，显著扩展了操作符学习的应用范围。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.21536", "html_url": "https://arxiv.org/abs/2503.21536", "title": "探索RBM的能量景观：偶极空间视角下的玻色子、分层学习和对称性破缺", "title_en": "Exploring the Energy Landscape of RBMs: Reciprocal Space Insights into Bosons, Hierarchical Learning and Symmetry Breaking", "authors": "J. Quetzalcóatl Toledo-Marin,Anindita Maiti,Geoffrey C. Fox,Roger G. Melko", "background": "生成模型在学习和模拟复杂分布方面的能力使其普及。然而，各种框架之间的关系尚不明确，这阻碍了统一的AI学习理论的发展。本文聚焦于具有离散分布普适逼近能力的受限玻尔兹曼机（RBM），通过引入偶极空间形式，揭示了RBM、扩散过程和耦合玻色子之间的联系。研究表明RBM在初始化时处于鞍点，其局部曲率由奇异值决定，奇异值的分布遵循马尔琴科-帕斯图尔定律并呈现旋转对称性。在训练过程中，这种旋转对称性因分层学习被打破，不同自由度逐步在多个抽象层面上捕捉特征。这一过程导致能量景观中的对称性破缺，类似于朗道理论描述的现象。我们推导了对应的平均场自由能，并展示了在无限大小的RBM中，偶极变量是高斯分布的。研究发现，在这种状态下，存在一定模式使得扩散过程不会收敛于玻尔兹曼分布。利用MNIST数据集训练不同隐层大小的RBM副本以展示研究成果。", "innovation": "通过引入偶极空间形式，揭示了RBM、扩散过程和耦合玻色子之间的联系。证明了RBM在初始化时处在鞍点，其局部曲率由奇异值决定，奇异值的分布遵循马尔琴科-帕斯图尔定律并表现出旋转对称性。在训练过程中，旋转对称性被打破，特征在多层抽象级别上被捕捉。推导了对应的平均场自由能，并展示了偶极变量在无限RBM中的高斯分布。", "conclusion": "研究结果表明在差分模式下，存在某些模式使得扩散过程不会收敛于玻尔兹曼分布。偶极空间观为生成模型的学习过程提供了新的见解，并填补了不同生成框架之间的差距。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08881", "html_url": "https://arxiv.org/abs/2502.08881", "title": "WENDy for Nonlinear-in-Parameters ODEs", "title_en": "WENDy for Nonlinear-in-Parameters ODEs", "authors": "Nic Rummel,Daniel A. Messenger,Stephen Becker,Vanja Dukic,David M. Bortz", "background": "WENDy框架是一种用于参数估计和推断系统的常微分方程（ODEs）的方法。先前的研究表明，WENDy具有鲁棒性、计算效率和准确性，但仅适用于参数线性的ODEs系统。本文进一步扩展了WENDy框架，以适应参数非线性（而非线性-in-参数）的ODEs系统。新的WENDy-MLE算法通过局部非凸优化方法近似最大似然估计器，从而提高了准确性和收敛域，比其他弱形式方法和传统的输出误差最小二乘法更快。此外，该框架还扩展以适应被对数正态噪声污染的数据。WENDy-MLE算法在Julia中得以高效实现。", "innovation": "本文提出了一种创新的WENDy-MLE算法，它能够处理参数非线性的ODEs系统，并提高了准确性和收敛域。此外，该算法还能够处理受对数正态噪声污染的数据，通过局部非凸优化方法近似最大似然估计。与现有方法相比，WENDy-MLE在计算速度和准确性上表现出色。", "conclusion": "我们通过广泛的数值结果证明了新方法在准确性和精确性方面的优越性，以及它在不同的基准ODEs系统上的适用性。WENDy-MLE算法在Julia中的高效实现使得该算法易于应用。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07260", "html_url": "https://arxiv.org/abs/2505.07260", "title": "UMoE：统一注意力和FFN的共享专家架构", "title_en": "UMoE: Unifying Attention and FFN with Shared Experts", "authors": "Yuanhang Yang,Chaozheng Wang,Jing Li", "background": "稀疏混合专家（MoE）架构已成为扩展Transformer模型的有效方法。早期的研究主要将MoE集成到前馈网络（FFN）层中，而最近的探索则将MoE范式扩展到注意力层以提高模型性能。然而，现有的基于注意力的MoE层需要定制实现，并且在性能上不如FFN层的对应物。", "innovation": "本文提出了一种新的注意力机制的重构，揭示了注意力模块中的内在FEF结构，从而提出了UMoE架构。UMoE通过基于注意力的MoE层实现了优于传统FFN层的性能，同时允许FFN和注意力组件之间的高效参数共享。", "conclusion": "UMoE统一了注意力层和FFN层的MoE设计，通过基于注意力的MoE层实现优异的性能，并且促进了FFN和注意力组件之间的高效参数共享。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.12622", "html_url": "https://arxiv.org/abs/2503.12622", "title": "基于可编程门阵列加速的实时在位深度学习细胞分类与排序", "title_en": "Real-Time Cell Sorting with Scalable In Situ FPGA-Accelerated Deep Learning", "authors": "Khayrul Islam,Ryan F. Forelli,Jianzhong Han,Deven Bhadane,Jian Huang,Joshua C. Agar,Nhan Tran,Seda Ogrenci,Yaling Liu", "background": "精准的细胞分类对于生物医学诊断和治疗监测至关重要，特别是用于识别多种疾病中的不同细胞类型。传统的细胞分类技术，例如流量细胞测序，依赖于分子标记，这往往成本高、耗时且会改变细胞完整性。为了克服这些限制，我们提出了一种无需标记的机器学习细胞分类框架，用于使用暗视野显微镜图像进行实时分类应用。这种方法利用教师-学生模型架构并结合了知识蒸馏，实现了不同细胞类型之间的高效率和可扩展性。通过淋巴细胞亚型分类的实际案例，证明了该框架能够准确地分类T4、T8和B细胞类型，并提供了易于适应的开源Python软件包。教师模型在区分T4细胞和B细胞时达到了98%的准确率，在零样本分类中T8和B细胞之间的区分准确率为93%。", "innovation": "我们提出了一种无需标记的机器学习细胞分类框架，利用暗视野显微镜图像进行实时分类应用。该方法使用教师-学生模型架构并结合了知识蒸馏，能够在不同的细胞类型中实现高效率和可扩展性。使用该框架，教师模型实现了T4和B细胞之间的98%区分准确率，T8和B细胞之间零样本分类的准确率为93%。学生模型仅使用教师模型参数的0.02%，并且可以在现场可编程门阵列（FPGA）上部署。利用FPGA加速的学生模型提供极低的推理延迟（14.5μs）和从细胞检测到排序触发的完整时间为24.7μs，分别比最先进的实时细胞分析算法提高了12倍和40倍的推理延迟，同时保持了与教师模型相当的准确性。此框架为淋巴细胞分类提供了可扩展、低成本的解决方案，并且实现了快速识别亚型的SOTA实时细胞排序实现，利用现成的计算硬件进行现场深度学习。", "conclusion": "本框架为淋巴细胞分类提供了一种可扩展且具有成本效益的解决方案，并实现了一种新的SOTA实时细胞排序实现，利用现成计算硬件进行在位深度学习快速识别亚型。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.06520", "html_url": "https://arxiv.org/abs/2505.06520", "title": "PRUNE: 基于补丁修复框架的神经网络可验证删除方法", "title_en": "PRUNE: A Patching Based Repair Framework for Certifiable Unlearning of Neural Networks", "authors": "Xuran Li,Jingyi Wang,Xiaohan Yuan,Peixin Zhang", "background": "通常希望从训练好的神经网络模型中移除特定部分的训练数据。典型的应用场景是为了保护数据持有者的“被遗忘权”，这受到了许多最新法规的提倡。现有的删除方法通常需要使用剩余数据重新训练替代模型，这可能在成本和验证上对数据持有者或第三方审计者来说具有挑战性。本工作提供了新的视角，提出了一种新的删除方法，通过在原始神经网络上施加精心设计的“补丁”，来实现对请求删除的数据进行有针对性的“遗忘”。", "innovation": "研究中提出了一种基于神经网络修复的研究线，明确提出要寻找一个轻量级但具备可验证保证的最小“补丁”，以实现给定数据点的删除成功。为删除大量数据点（或一个整类），提出了一种迭代选择一小部分代表性数据点进行删除的方式，以实现对整个数据集的删除效果。实验结果在多个分类数据集上展示了该方法的有效性，证明了在保留模型性能的同时，该方法在效率和内存消耗上具有竞争力。", "conclusion": "我们的方法在目标删除特定数据的同时保持了模型性能，并且在效率和内存消耗方面与其他基线方法相当甚至更优。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.09131", "html_url": "https://arxiv.org/abs/2505.09131", "title": "公平聚类通过对齐", "title_en": "Fair Clustering via Alignment", "authors": "Kunwoong Kim,Jihu Lee,Sangchul Park,Yongdai Kim", "background": "公平聚类旨在在聚类过程中平衡涉及保护特征的比例。虽然最近开发的公平聚类算法在特定公平约束下优化聚类目标，但这些算法本身的复杂度或近似性往往导致在实践中聚类效用的下降或数值不稳定性。", "innovation": "提出了一种名为Fair Clustering via Alignment (FCA)的新公平聚类算法。该算法通过交替步骤操作：首先找到一个联合概率分布以对齐来自不同保护群体的数据，然后在对齐的空间中优化聚类中心。FCA的关键优势在于，它理论上保证了在任何给定公平水平下都能实现近乎最优的聚类效用，从而在实践中实现高效公平聚类。", "conclusion": "实验表明，FCA在公平性和聚类效用之间达到了更优的折衷，并且能够在不出现数值不稳定的情况下实现近乎完美的公平性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11821", "html_url": "https://arxiv.org/abs/2505.11821", "title": "通过回合级奖励设计强化LLM代理的多轮推理", "title_en": "Reinforcing Multi-Turn Reasoning in LLM Agents via Turn-Level Reward Design", "authors": "Quan Wei,Siliang Zeng,Chenliang Li,William Brown,Oana Frunza,Wei Deng,Anderson Schneider,Yuriy Nevmyvaka,Yang Katie Zhao,Alfredo Garcia,Mingyi Hong", "background": "尽管强化学习（RL）算法如群组相对策略优化（GRPO）和proximal策略优化（PPO）已被广泛应用于训练多轮大型语言模型（LLM）代理，但这些算法通常仅依赖稀疏的结果奖励，并且缺乏多决策步骤中的密集中间信号，这限制了它们在复杂推理任务上的表现。", "innovation": "本文首次系统地研究了多轮RL算法和代理应用中的回合级奖励设计。通过集成回合级奖励，我们将GRPO和PPO扩展到各自的多轮版本，从而实现更细粒度的奖励分配。在多轮推理增强搜索代理案例研究中，精心设计了两种类型的回合级奖励：可验证的和以LLM为法官的。实验表明，引入精心设计的回合级奖励使RL算法显著优于基于轨迹级奖励的基本方法。通过训练和验证奖励曲线表明，该方法实现了更高的稳定性、更快的收敛性和更高的准确性。", "conclusion": "在各种问答数据集中的数值结果进一步表明，本文的方法始终提供最高答案正确性和100%的格式正确性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10465", "html_url": "https://arxiv.org/abs/2505.10465", "title": "Superposition Yields Robust Neural Scaling", "title_en": "Superposition Yields Robust Neural Scaling", "authors": "Yizhou Liu,Ziming Liu,Jeff Gore", "background": "当前大型语言模型（LLMs）的成功依赖于观察到更大的模型表现更好。然而，这种神经网络缩放定律的起源——损失随着模型大小以幂律形式减少——依旧不清楚。本文提出了表示叠加的概念，即LLMs表示的特征数量超过其维度数量，可能是导致损失和神经网络缩放的关键因素。基于 Anthropic 的玩具模型，通过控制叠加的程度，研究了损失随模型规模变化的方式。弱叠加情况下，只有在数据特征频率也呈幂律分布时，损失才遵从幂律规则；而强叠加情况下，损失会与模型维度成反比地变化，适用于广泛的频率分布类型，原因是表示向量之间的几何重叠。开源的LLMs确实运行在强叠加状态下，损失与模型维度成反比，Chinchilla 规律也符合这一行为。", "innovation": "提出了表示叠加的概念，通过控制权重衰减来研究损失随模型规模变化的方式，证明强叠加状态下损失与模型维度成反比地变化，适用于广泛的频率分布类型。这为理解神经网络缩放律提供了新的洞见，解释了何时可以改进缩放律以及何时会失效。", "conclusion": "研究确认开源的LLMs确实运行在强叠加状态下，损失与模型维度成反比，Chinchilla 规律也符合这一行为。这表明表示叠加是神经网络缩放律的核心驱动因素，为未来的研究提供了新的方向。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12149", "html_url": "https://arxiv.org/abs/2505.12149", "title": "通过Woodbury、动量和随机化改进能量自然梯度下降", "title_en": "Improving Energy Natural Gradient Descent through Woodbury, Momentum, and Randomization", "authors": "Andrés Guzmán-Cordero,Felix Dangel,Gil Goldshlager,Marius Zeinhofer", "background": "自然梯度方法显著加快了物理知情神经网络（PINNs）的训练过程，但常常具有很高的计算成本。为了提高Energy Natural Gradient Descent（ENGD）方法在PINNs中的准确性和效率，作者引入了一系列技术改进。这些改进包括利用Woodbury公式大幅减少计算复杂度，采用来自变分蒙特卡洛文献的Subsampled Projected-Increment Natural Gradient Descent算法加速收敛，以及通过随机化算法进一步减少大批次处理的计算成本。", "innovation": "引入了Woodbury公式、Subsampled Projected-Increment Natural Gradient Descent算法和随机化算法来降低Energy Natural Gradient Descent（ENGD）在PINNs中的计算复杂度，提高其准确性和效率。具体创新点包括：利用Woodbury公式显著减少计算复杂度；采用Subsampled Projected-Increment Natural Gradient Descent算法加速收敛；使用随机化算法在大批次处理时进一步减少计算成本。", "conclusion": "实验结果证明，提出的改进方法在低维度问题的早期训练阶段能显著加速进程，而在其他场景下则面临加速的障碍。与先前的方法相比，所提出的方法能够以高达75倍的速度达到相同的$L^2$误差水平。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13358", "html_url": "https://arxiv.org/abs/2505.13358", "title": "基于科恩曼建模的一步离线蒸馏扩散模型", "title_en": "One-Step Offline Distillation of Diffusion-based Models via Koopman Modeling", "authors": "Nimrod Berman,Ilan Naiman,Moshe Eliasof,Hedi Zisling,Omri Azencot", "background": "扩散生成模型在性能上表现出色，但其迭代采样过程仍然计算密集。一种常见的缓解成本的策略是蒸馏，特别是离线蒸馏，它在效率、模块化和灵活性方面具有明显优势。", "innovation": "该研究依托科恩曼理论引入了一种新颖的离线蒸馏方法——科恩曼蒸馏模型（KDM），通过将非线性动态线性化来简化模型。KDM 通过编码噪声输入到嵌入空间，应用学习到的线性操作符进行前向传播，并通过解码器重建清洁样本，实现了单步生成同时保持语义保真度。研究还提供了理论支持：在轻微假设下，学习到的扩散动力学具有有限维柯恩曼表示，并且科恩曼潜空间中的邻近性与生成输出的语义相似性相关。", "conclusion": "KDM 在标准离线蒸馏基准测试中表现出了高度竞争性的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12419", "html_url": "https://arxiv.org/abs/2505.12419", "title": "同构神经网络分类问题中的嵌入原则", "title_en": "Embedding principle of homogeneous neural network for classification problem", "authors": "Jiahan Zhang,Yaoyu Zhang,Tao Luo", "background": "文章研究了同构神经网络（包括全连接和卷积神经网络）关联的最大边际问题的Karush-Kuhn-Tucker (KKT) 点。特别关注不同宽度的网络之间的关系。该研究从KKT点的嵌入角度，探讨神经网络的结构如何影响其优化结果，特别是在网络宽度变化的情况下。", "innovation": "提出了并形式化了KKT点嵌入原则，表明一个同构网络的最大边际问题的KKT点可以被嵌入到较大网络问题的KKT点之中，通过特定的线性等距变换实现。本文严格证明了这一原则在全连接网络的神经元分裂和卷积神经网络的通道分裂中的适用性。该研究还建立了静态嵌入与梯度流训练动力学的关系，表明起点通过适当映射后，训练过程中路径得以保持，并且方向收敛的方向集合也会相应地映射，从而保持动态收敛时的方向对齐。文章通过多项实验验证了路径的保持性，提供了对网络宽度、参数冗余以及不同大小同构网络中找到的解的结构性连接的见解。", "conclusion": "研究发现KKT点的嵌入原则对于理解同构神经网络在不同宽度下的效果至关重要，路径保持和动态方向对齐的理论为优化算法和网络结构的设计提供了新视角，进一步揭示了网络宽度、参数冗余对优化结果的影响。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12944", "html_url": "https://arxiv.org/abs/2505.12944", "title": "CALM-PDE：连续且自适应卷积在时变PDE潜空间建模中的应用", "title_en": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs", "authors": "Jan Hagnberger,Daniel Musekamp,Mathias Niepert", "background": "使用密集的空间领域来解决时变偏微分方程(PDEs)是科学和工程学科中的一个基本问题，包括气候现象和流体动力学建模。然而，在物理空间中直接进行这些计算往往会带来显著的计算成本。为了解决这个问题，已经开发了一些在压缩的潜在空间中操作的神经代理模型来解决PDE。虽然这些方法降低了计算复杂性，但它们经常使用基于Transformer的注意力机制来处理不规则采样领域，从而增加了内存消耗。相比之下，卷积神经网络可以在内存有效编码和解码的同时，但有限于规则的 discret化。受到这些考虑的启发，我们提出了CALM-PDE模型类，能有效地在一个压缩的潜在空间中解决任意 discret化PDEs。我们引入了一个新颖的连续卷积为基础的编码-解码架构，使用了ε-邻域约束内核，并学习适应和优化的查询点应用卷积算子。我们证明了CALM-PDE在具有规则和不规则空间域的PDE数据集上的有效性。与基于Transformer的方法相比，CALM-PDE在内存和推理时间效率方面具有显著改进，同时与其基线方法具有竞争力或更优效果。", "innovation": "我们提出了CALM-PDE模型，这是一种能够高效地在压缩的潜在空间中解决任意 discret化的PDEs的模型类。其创新之处在于引入了一个新颖的连续卷积为基础的编码-解码架构，该架构使用了ε-邻域约束内核，能够学习适应和优化的查询点应用卷积算子。这种设计使得CALM-PDE能够在大大减少内存消耗的同时，保持与基于Transformer的方法相当甚至更优的计算效率和准确性。", "conclusion": "我们展示了CALM-PDE在不同类型的PDE-data集上具有良好的性能，且与现有基线方法相比，CALM-PDE在内存消耗和推理时间上具有明显的优势。此外，CALM-PDE对于规则和不规则空间领域的PDEs都表现出良好的适应性，证明了其在处理复杂PDE问题时的有效性和稳健性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15293", "html_url": "https://arxiv.org/abs/2505.15293", "title": "LLM-Explorer：由大型语言模型驱动的插件强化学习策略探索增强", "title_en": "LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models", "authors": "Qianyue Hao,Yiwen Song,Qingmin Liao,Jian Yuan,Yong Li", "background": "在强化学习（RL）中，策略探索至关重要，现有方法包括贪婪策略、高斯过程等。然而，这些方法使用预定的随机过程，并且不会根据RL任务的特定特征调整。在RL训练过程中，这些随机过程的演变通常是固定的，只包括方差的衰减，缺乏对代理实时学习状态的灵活调整。", "innovation": "受大型语言模型（LLMs）分析和推理能力的启发，设计了LLM-Explorer，这是一种自适应生成特定任务探索策略的模块，增强了RL中的策略探索。LLM-Explorer在特定任务中取样代理学习轨迹，促使LLMs分析代理当前的策略学习状态，并生成未来策略探索的概率分布。通过定期更新概率分布，推导出专门针对特定任务的随机过程，并动态调整以适应学习过程。该设计兼容各种广泛采用的RL算法，包括DQN系列、DDPG、TD3及任何基于它们的变体。", "conclusion": "通过在Atari和MuJoCo基准测试上的广泛实验，证明了LLM-Explorer在强化学习策略探索方面的增强能力，实现了平均性能提高37.27%。代码开源以便再现结果，链接为：this https URL"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15602", "html_url": "https://arxiv.org/abs/2505.15602", "title": "连续时间带有跳跃的随机控制深度学习方法", "title_en": "Deep Learning for Continuous-time Stochastic Control with Jumps", "authors": "Patrick Cheridito,Jean-Loup Dupret,Donatien Hainaut", "background": "该研究旨在解决带有跳跃的连续时间有限 horizons 随机控制问题。传统方法可能在处理这类高维、复杂的控制任务时遇到困难，而现有的深度学习方法多局限于离散时间或不考虑跳跃情况。因此，本文提出了一个基于模型的深度学习方法，以更有效地处理此类问题。", "innovation": "本文创新地提出了一种基于模型的深度学习方法，迭代训练两个神经网络：一个用于表示最优策略，另一个用于近似价值函数。使用连续时间动态规划原理，根据哈密尔顿-雅可比-贝尔曼方程推导出两种不同的训练目标，从而确保网络能够捕捉到潜在的随机动力学。这种方法能够提高对这类复杂控制问题的精确性和可扩展性，特别是在高维情况下。", "conclusion": "通过在不同问题上的实证评估，研究证明了提出方法的有效性和准确度，表明它在解决复杂的高维随机控制任务方面具有显著优势。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13938", "html_url": "https://arxiv.org/abs/2505.13938", "title": "CLEVER: 一个正式验证的代码生成精心构建基准", "title_en": "CLEVER: A Curated Benchmark for Formally Verified Code Generation", "authors": "Amitayush Thakur,Jasper Lee,George Tsoukalas,Meghana Sistla,Matthew Zhao,Stefan Zetzsche,Greg Durrett,Yisong Yue,Swarat Chaudhuri", "background": "该论文背景在于现有代码生成基准的局限性，如依赖于测试用例监督、LLM生成的注释、泄露实施逻辑的规范或者允许空洞解决方案。为此，作者提出了${\rm C{\tiny LEVER}}$，一个高质量且经过精心筛选的基准测试，涵盖了161个问题，旨在进行端到端验证的代码生成任务。每个问题包括生成符合已提取真实规范的规范任务，以及生成证明满足该规范的Lean实现任务。", "innovation": "${\rm C{\tiny LEVER}}$的创新之处在于完全避免了测试用例监督、LLM生成的注释以及泄露实施逻辑或允许空洞解决方案的规范，所有输出都在后验证中通过Lean的类型检查器确保机器可检查的正确性。该基准为程序合成和形式推理提供了一个极具挑战性的边界测试。研究者利用${\rm C{\tiny LEVER}}$评估了一些基于先进语言模型的少样本和代理方法，这些方法在完全验证方面都表现出挑战性，证明${\rm C{\tiny LEVER}}$是一个严谨的基准。", "conclusion": "研究者构建了一个开源的${\rm C{\tiny LEVER}}$基准，可以在GitHub和HuggingFace上找到，所有评估代码也在线上公开，为未来的程序合成和形式推理研究提供了强有力的支持。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16581", "html_url": "https://arxiv.org/abs/2505.16581", "title": "如何通过提炼的策略集合提高强化学习的泛化能力", "title_en": "How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning", "authors": "Max Weltevrede,Moritz A. Zanger,Matthijs T.J. Spaan,Wendelin Böhmer", "background": "在零样本策略迁移的强化学习设定中，目标是在固定的一组训练环境中训练一个代理，使其能够泛化到相似但未见过的测试环境中。之前的研究表明，训练后进行策略提炼有时会生成在测试环境中表现更好的策略。然而，目前尚不清楚为什么会出现这种情况，或应该使用哪些数据来提炼策略。本文在一定假设下证明了训练后策略提炼的泛化界，并提供了两个实用见解：为了提高泛化能力，1) 应该训练多个提炼的策略集合，并且2) 应该尽可能使用更多训练环境的数据来提炼策略。最终，实验证明在更广泛的条件下这些见解依然成立，并展示了在多样数据集上提炼出的策略集合相比原始代理有着显著更好的泛化能力。", "innovation": "本文证明了训练后提炼策略的泛化界，并提供了两个提高泛化的实用见解：通过训练多个策略集合和使用更多训练环境数据提炼策略。此外，通过实验验证了这些策略在多样条件下依然有效，展示了多样数据集提炼策略集合的显著泛化优势。", "conclusion": "本文通过理论分析证明并实验验证了通过提炼策略集合可以提高强化学习中的泛化能力，提出了在策略提炼过程中的一些实际改进策略。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16690", "html_url": "https://arxiv.org/abs/2505.16690", "title": "您的预训练大语言模型其实是一个无监督的置信度校正器", "title_en": "Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator", "authors": "Beier Luo,Shuoyuan Wang,Sharon Li,Hongxin Wei", "background": "预训练语言模型（PLMs）在适应下游任务时需要经过后训练以与人类偏好对齐。尽管PLMs的置信度通常校准良好，但后训练的语言模型（PoLMs）往往会表现出过度自信，将高置信度误判为正确和不正确的输出，这对于关键应用的可靠性构成了威胁。标签数据的稀缺性是校准PoLMs的主要障碍，因为每个下游任务需要大量的标注数据。", "innovation": "本文提出了一种名为DACA（Disagreement-Aware Confidence Alignment）的新型无监督方法，以优化后训练过程中的参数（如温度$\tau$），以校正置信度。DACA的设计基于PLM和PoLM在预测分歧时的不一致问题，通过选择性地仅使用一致样本进行校正，以减少由于分歧样本引起的$\tau$过大问题，从而改善校准性能。", "conclusion": "广泛的实验证明了DACA方法的有效性，相较于开源和API基于的大语言模型（如GPT-4o），在常用基准上的平均ECE（Equal Calibration Error）提高了最多15.08%。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15034", "html_url": "https://arxiv.org/abs/2505.15034", "title": "RL Tango：同时加强生成器和验证器的语言推理", "title_en": "RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning", "authors": "Kaiwen Zha,Zhengqi Gao,Maohao Shen,Zhang-Wei Hong,Duane S. Boning,Dina Katabi", "background": "强化学习（RL）已经成为了增强大型语言模型（LLMs）推理能力的一种具有吸引力的方法。在当前的后训练RL方法中，LLM生成器通常由规则基础或冻结预训练的验证者（奖励模型）引导，或者通过监督微调（SFT）进行训练。然而，这些设计容易受到奖励黑客攻击，并且在训练分布之外的泛化效果不佳。为了克服这些局限性，本文提出了Tango，一种新的框架，它使用RL的同时训练LLM生成器和验证器。中央创新是Tango的生成器过程级LLM验证器，该验证器通过RL训练，并与生成器共同进化。验证器仅根据结果层面的验证正确性奖励进行训练，无需显式的过程级标注。这种通过RL训练的生成器验证器相比确定性和SFT训练的验证器，表现出了更好的鲁棒性和泛化能力，促进了与生成器的有效相互强化。大量的实验表明，Tango的两个组件在7B/8B规模的模型中都达到了最佳水平：生成器在五个竞赛级别的数学基准测试和四个具有挑战性的跨域推理任务中取得了最佳性能，而验证器在ProcessBench数据集中表现最佳。特别地，两个组件在最复杂的数学推理问题上表现出了显著的改进。", "innovation": "Tango框架的创新之处在于其通过RL生成式训练的、与生成器共同进化的过程级LLM验证器。该验证器仅基于结果层面的验证正确性奖励进行训练，无需显式的流程级注释。这种通过RL训练的生成器验证器相比于确定性和SFT训练的验证器，具备更好的鲁棒性和泛化能力，能够促进生成器和验证器之间的有效相互强化。", "conclusion": "Tango框架在7B/8B规模的模型中，生成器通过五项竞争级别的数学基准测试和四项具有挑战性的跨域推理任务达到了最佳性能，并且验证器在ProcessBench数据集上的表现最佳。特别地，两个组件在最复杂的数学推理问题上表现出了显著的改进。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17404", "html_url": "https://arxiv.org/abs/2505.17404", "title": "Wasserstein 转移学习", "title_en": "Wasserstein Transfer Learning", "authors": "Kaicheng Zhang,Sinian Zhang,Doudou Zhou,Yidong Zhou", "background": "转移学习是一种利用源领域知识来增强目标领域学习的强大范式。然而，传统的转移学习方法通常局限于欧几里得空间中的标量或多变量数据，无法有效应用于概率分布等复杂数据结构。因此，本文旨在解决这一局限，提出了一种新的适用于概率分布输出的回归模型的转移学习框架，这些概率分布存在于Wasserstein空间中。当已知具有信息的可转移源领域子集时，提出了一种具有可验证渐近收敛速率的估计器，量化了领域相似性对转移效率的影响。当无法识别具有信息的子集时，开发了一种数据驱动的转移学习方法，以减轻负面转移的影响。", "innovation": "提出了适用于Wasserstein空间中概率分布输出的回归模型的新转移学习框架；提出了一个具有证明渐近收敛速率的估计器，在已知具有信息的可转移源领域子集的情况下，量化领域相似性对转移效率的影响；提出了数据驱动的转移学习程序，缓解未知具有信息的子集情况下的负面影响。", "conclusion": "通过严格理论分析和广泛的模拟及实际应用验证了提出的方法。该研究为复杂数据结构的转移学习提供了新的解决方案，并提供了实用的代码实现。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17866", "html_url": "https://arxiv.org/abs/2505.17866", "title": "DesignX: 适用于黑盒优化的人类竞争级算法设计师", "title_en": "DesignX: Human-Competitive Algorithm Designer for Black-Box Optimization", "authors": "Hongshu Guo,Zeyuan Ma,Yining Ma,Xinglin Zhang,Wei-Neng Chen,Yue-Jiao Gong", "background": "设计有效的黑盒优化器受到限制，源自于对特定问题的知识有限以及大量的手工调节细节，这通常需要数月时间。本文旨在通过对特定黑盒优化问题在几秒内生成有效优化器来解决这一问题，作者提出了一种自动算法设计框架DesignX。", "innovation": "作者通过从几十年的科研工作中收集数百个算法部件，构建了一个全面的模块化算法空间。在此基础上，利用一种新颖的合作训练目标引入了双智能体强化学习系统来协同进行结构和参数设计，实现了大规模元训练。通过几天自主学习，DesignX 生成的优化器在合成测试基准和包括蛋白质对接、自动机器学习和无人机路径规划在内的现实优化场景中均显著超越人工设计的优化器。深入分析进一步表明，DesignX 具备发现超越专家直觉的复杂算法模式的能力，为优化社区提供了宝贵的设计洞察。", "conclusion": "该研究通过设计X（DesignX）突破了手动优化器设计的时间和效能限制，显示了其在合成测试和现实优化场景中的优越性，同时为优化问题提供了新的设计思路。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17190", "html_url": "https://arxiv.org/abs/2505.17190", "title": "Tropical Attention: 植入热带几何的神经推理模型", "title_en": "Tropical Attention: Neural Algorithmic Reasoning for Combinatorial Algorithms", "authors": "Baran Hashemi,Kurt Pasque,Chris Teska,Ruriko Yoshida", "background": "论文探索了代数几何能否通过赋予现代神经推理模型数学支撑的归纳偏置来提高其清晰度、鲁棒性和可解释性。研究引入了Tropical Attention机制，这是一种基于热带几何学的注意力机制，将注意力核提升到热带射影空间，使得推理具有分段线性和1-利普希兹特性，从而保留了组合推理固有的多面体决策结构。", "innovation": "1. 通过将注意力机制与热带几何结合，Tropical Attention机制使推理在热带射影空间中表现为分段线性和1-利普希兹，从而保留了多面体决策结构。2. 证明了Multi-Head Tropical Attention (MHTA)能够无机制地近似热带电路，并通过组合实现热带传递闭包。3. 实验结果表明，Tropical Attention在泛化能力和鲁棒性方面优于Softmax和递归注意力机制，且模型参数更少，推理速度更快。4. 首次将神经算法推理扩展到NP-hard和NP-complete问题，开启了更准确、更具表现力的大型推理模型（LRMs）的新时代。", "conclusion": "基于Tropical Attention的神经算法推理模型在解决复杂组合挑战方面具有更强的泛化能力和鲁棒性，并在数学发现、密码学、粒子物理和系统发育学等领域展现出潜力。这种模型能够处理超越多项式时间复杂度的问题，为大型推理模型的应用提供了新的可能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18781", "html_url": "https://arxiv.org/abs/2505.18781", "title": "几何感知算子变换器作为任意域上偏微分方程的有效且准确的神经代理", "title_en": "Geometry Aware Operator Transformer as an Efficient and Accurate Neural Surrogate for PDEs on Arbitrary Domains", "authors": "Shizheng Wen,Arsh Kumbhat,Levi Lingsch,Sepehr Mousavi,Yizhou Zhao,Praveen Chandrashekar,Siddhartha Mishra", "background": "准确且高效地学习PDEs（偏微分方程）解算子对工程和工业模拟至关重要。尽管存在许多算子学习算法来近似PDEs，但往往准确的模型未必计算高效，反之亦然。", "innovation": "提出了一种几何感知算子变换器（GAOT），结合了新颖的多尺度注意力图神经算子编码器和解码器，以及几何嵌入和（视觉）变换处理器，以准确映射域和输入信息到PDE解的稳健近似。GAOT在实现中的多个创新也确保了计算效率和可扩展性。", "conclusion": "GAOT在多种偏微分方程的学习任务上，尤其是在三个大型三维工业CFD数据集上，展示了在准确性和效率方面的显著提高，优于多个基准模型。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22601", "html_url": "https://arxiv.org/abs/2505.22601", "title": "机器过参数化条件下的机器遗忘", "title_en": "Machine Unlearning under Overparameterization", "authors": "Jacob L. Block,Aryan Mokhtari,Sanjay Shakkottai", "background": "机器遗忘算法旨在去除特定训练样本的影响，理想情况下恢复仅在剩余数据上进行训练的原本模型。以往研究在参数不足的情况下定义了解决方案，即在保留的数据集上损失最小化，但由于在过参数化情况下许多模型可以完美拟合数据，这种定义不再适用，且早期方法基于梯度扰动的算法在这种情况下无效。", "innovation": "在过参数化环境中定义了新的机器遗忘解决方案，即最小复杂度的拟合器，并提出了一种仅需访问模型在保留集上的梯度的新算法框架。通过最小化一个正则化的目标函数，限制扰动与模型梯度正交，这被看作是拟合条件的一阶松弛。", "conclusion": "为不同的模型类提供确切和近似的机器遗忘保证，实验表明该框架的实现优于现有的基准模型。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22389", "html_url": "https://arxiv.org/abs/2505.22389", "title": "基于扰动与融合的双重框架实现持续学习：训练时扰动、推理时融合", "title_en": "Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning", "authors": "Haomiao Qiu,Miao Zhang,Ziyue Qiao,Liqiang Nie", "background": "持续学习（CL）的目标是从一系列任务中连续获取知识，同时避免已学习的信息遗忘。现有持续学习方法依赖最近任务的参数进行推理，使其容易遭受灾难性遗忘。受到模型合并技术成功的启发，该研究提出了Perturb-and-Merge (P\textbf{与}M)，一个创新的持续学习框架，将模型合并技术整合到持续学习范式中，以减轻遗忘问题。", "innovation": "该论文提出了一种新颖的持续学习框架P\textbf{与}M，它通过模型合并来减轻遗忘。P\textbf{与}M 在每次任务训练后，通过形成先前模型与新训练的任务特定模型的凸组合来构建新的模型。此外，还通过正则化项来缓解合并过程中引入的退化，并设计了一种基于任务向量方向的随机扰动策略来实现近似的正则化项，同时无需额外的前向或反向传递。P\textbf{与}M 还与LoRA结合以减少内存开销。", "conclusion": "所提出的方法在多个持续学习基准数据集上达到了最先进的性能。研究结果表明，通过扰动与融合的双重框架，可以在减轻遗忘的同时保持高性能。代码可在提供的链接中访问。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21364", "html_url": "https://arxiv.org/abs/2505.21364", "title": "无需牺牲的可解释性：Mixture of Decoders 的忠实密集层分解", "title_en": "Towards Interpretability Without Sacrifice: Faithful Dense Layer Decomposition with Mixture of Decoders", "authors": "James Oldfield,Shawn Im,Sharon Li,Mihalis A. Nicolaou,Ioannis Patras,Grigorios G Chrysos", "background": "多层感知器（MLPs）是大型语言模型的重要组成部分，但由于其密集表示，使得其难以理解、编辑和指导。最近的方法通过神经级别稀疏性学习可解释的近似值，但无法忠实地重建原始映射，显著增加了模型的下一个标记交叉熵损失。因此，本文提出转向层级别稀疏性，以克服稀疏层 approximation 的精度折衷。通过这一范式，引入了 Mixture of Decoders（MxDs），该模型可以扩展预训练的密集层为几十万个专门的子层，这使得每个激活稀疏的 MxD 子层可以实现满秩权重的线性变换，从而保持原始解码器的表达能力，即使在高度稀疏的情况下也是如此。", "innovation": "本文提出了一种新的稀疏层分解方法 Mixture of Decoders（MxDs），它通过层级别稀疏性克服了传统方法的精度折衷问题。MxDs 通过一种灵活的张量分解，实现每个激活稀疏的 MxD 子层进行满秩权重的线性变换，从而保留了原始解码器的表达能力，无论稀疏程度如何。这种方法在语言模型中（具有多达 30 亿个参数）的表现优于最先进的方法，并且在稀疏探针和功能导向上也展示了与自然语言相同的专门特征，为设计可解释且忠实的分解开辟了新的途径.", "conclusion": "实验结果显示，MxDs 在语言模型的稀疏-精度前沿显著超越了最先进的方法（例如 Transcoders），特别是在具有 30 亿参数的语言模型上。此外，MxDs 还在稀疏探针和特征导向上表现出与自然语言相似的特殊特征，为可解释模型的设计开辟了新的路径。本文还包括了代码，可以在以下网址找到：this https URL."}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21785", "html_url": "https://arxiv.org/abs/2505.21785", "title": "Born a Transformer — Always a Transformer？关于预训练对架构能力的影响", "title_en": "Born a Transformer -- Always a Transformer? On the Effect of Pretraining on Architectural Abilities", "authors": "Mayank Jobanputra,Yana Veitsman,Yash Sarrof,Aleksandra Bakalova,Vera Demberg,Ellie Pavlick,Michael Hahn", "background": "自注意力机制的Transformer虽然在模型规模和预训练数据的增加下表现卓越，但它们在建模某些序列到序列任务时仍存在理论限制，这部分限制的具体影响在大规模的预训练语言模型中尚不明确。研究者对这些限制在实际应用中的表现持怀疑态度，即大型模型和大量的预训练数据是否能够帮助模型克服这些限制。对此，本研究旨在探索在预训练过程中这些架构限制如何表现，研究了一系列基于Liu等人的检索和复制任务，采用Huang等人提出的关于长度泛化的研究框架来提供理论保障。通过这些任务和分析，研究发现模型在检索和复制任务中展示出‘归纳与反归纳’的不对称性，即模型在获取右端的token比左端的token表现更好。这种不对称性可以通过理论上的长度泛化保障被消除，并且研究表明这种不对称性与预训练Transformer内部的‘归纳’和‘反归纳’电路强度差异有关。研究结果表明，预训练对特定的Transformer能力有选择性地增强，但并没有克服基础的长度泛化限制。从而揭示预训练并不像预期那样完美解决了所有预测能力上的限制问题，模型仍有其固有限制。", "innovation": "研究引入了基于Liu等人的检索和复制任务，以及Huang等人的关于长度泛化的研究框架来探索预训练对Transformer架构能力的影响。这项研究通过实验证明了‘归纳与反归纳’的不对称性，并通过机制分析揭示了这是由预训练Transformer内部电路的强弱差异引起的现象。研究结果表明，在模型预训练后，某些能力会得到提升，但仍然存在难以克服的限制，这为理解模型的实际应用提供了新的视角。", "conclusion": "最终研究结论显示，预训练有选择性地增强了特定的Transformer能力，但是基本的长度泛化限制仍然存在。模型在特定任务上的表现并不是完全理想的，仍有可研究的空间。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24261", "html_url": "https://arxiv.org/abs/2505.24261", "title": "驯服数据归因中的超参数敏感性：无需重新训练的实用选择", "title_en": "Taming Hyperparameter Sensitivity in Data Attribution: Practical Selection Without Costly Retraining", "authors": "Weiyi Wang,Junwei Deng,Yuzheng Hu,Shiyuan Zhang,Xirui Jiang,Runting Zhang,Han Zhao,Jiaqi W. Ma", "background": "数据归因方法量化了单个训练数据点对机器学习模型的影响，近年来在现代AI的数据中心应用中变得越来越受欢迎。尽管这个领域最近出现了许多新方法，但对于超参数调优对这些方法的影响仍然了解不足。本文旨在通过大规模实证研究来理解常见数据归因方法的超参数敏感性。", "innovation": "本文首次进行大规模实证研究，探讨常见数据归因方法的超参数敏感性。发现大多数方法对某些关键超参数敏感，而且在调优这些度量时通常需要重新训练模型，这使得成本变得非常高昂。因此，本文提倡通过更好的理论理解超参数行为来指导高效的调优策略，并通过理论分析，提出了一种无需重新训练模型即可选择正则化值的轻量级方法，在数据归因基准测试中验证其有效性。", "conclusion": "本文确认了一个在数据归因实际应用中基本但被忽视的挑战，并强调在今后的新方法开发中进行详尽的超参数选择讨论的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01665", "html_url": "https://arxiv.org/abs/2506.01665", "title": "利用解析梯度在证明安全的强化学习中应用", "title_en": "Leveraging Analytic Gradients in Provably Safe Reinforcement Learning", "authors": "Tim Walter,Hannah Markgraf,Jonathan Külz,Matthias Althoff", "background": "在安全性至关重要的应用中部署自主机器人需要提供安全保证。目前，通过使用防护措施以证明安全的强化学习成为研究热点。这些防护措施应在训练期间集成，以减少模拟到现实世界的差距。虽然对于基于采样的强化学习已经有一些防护方法，但在基于解析梯度的强化学习中还未有防护措施，而后者常常能从较少的环境交互中学到更好的性能。", "innovation": "本研究填补了基于解析梯度的强化学习防护措施的空白，开发了首个有效的防护策略。通过分析现有的可微分防护措施、修改映射及梯度公式将其适应，将这些防护措施整合进最先进的学习算法和可微分模拟中。通过在三个控制任务上的数值实验评估了不同防护措施对学习的影响，并展示了防护训练不降低性能的结果。", "conclusion": "防护训练不会牺牲性能，为基于解析梯度的强化学习提供了一种有效的方式，并提供了进一步的可视化结果。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00744", "html_url": "https://arxiv.org/abs/2506.00744", "title": "在混合二次线性变换器中融合互补性记忆系统", "title_en": "Blending Complementary Memory Systems in Hybrid Quadratic-Linear Transformers", "authors": "Kazuki Irie,Morris Yau,Samuel J. Gershman", "background": "本文探讨了结合了二次变换器和线性变换器核心原则的混合记忆架构，旨在为通用序列处理神经网络提供高效的支持。KV-memory采用了基于softmax注意力的关键值记忆，而FW-memory利用动态突触调制实现了快速权重记忆。这两种记忆系统各自具备互补的特性，但也有各自的局限性，研究者们希望找到一种方法将它们融合为一个系统以充分发挥各自的优点。", "innovation": "本文提出了三种融合KV-memory和FW-memory的方法，旨在通过调整输入信息的传递时间和方式来优化这两种记忆系统的协同工作。研究者们利用这些方法训练了不同参数规模的模型，并在一系列任务中评估了它们的性能。此外，还特别设计了合成的算法任务以更精确地展示某些混合方法的优势。研究者还探讨了在部分可观测环境中的强化学习任务，结果显示，合理设计的混合系统可以克服单一组件的局限，为神经记忆系统的设计提供新的见解。", "conclusion": "研究证明，精心设计的混合系统可以克服单一组件的局限性，展示了在特定任务中混合记忆系统的设计能力。研究提供了关于神经记忆系统设计原则的新见解。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04432", "html_url": "https://arxiv.org/abs/2506.04432", "title": "KOALA++: 使用梯度方差积的高效卡尔曼神经网络优化", "title_en": "KOALA++: Efficient Kalman-Based Optimization of Neural Networks with Gradient-Covariance Products", "authors": "Zixuan Xia,Aram Davtyan,Paolo Favaro", "background": "在神经网络训练中，优化算法需要平衡准确性和计算效率。现有方法如二阶优化算法依赖于昂贵的二阶梯度计算，这降低了计算效率；而一阶优化算法忽视了梯度不确定性，可能无法充分利用参数之间的相关性。", "innovation": "我们提出了一种名为 KOALA++ 的可扩展卡尔曼优化算法，该算法通过递归更新紧凑的梯度方差积直接估计参数协方差矩阵，从而捕捉更丰富的不确定性结构而不会存储完整的协方差矩阵，避免了大规模矩阵倒数运算。与现有方法相比，它在各种任务中，如图像分类和语言建模，达到了与最先进的一阶和二阶优化器相当或更好的准确度，同时保持了一阶方法的计算效率。", "conclusion": "通过实验表明，KOALA++在计算效率和准确性方面都表现出色，是一种有效的神经网络优化方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06045", "html_url": "https://arxiv.org/abs/2506.06045", "title": "基于扩散的分层图神经网络在模拟非线性固体力学中的应用", "title_en": "Diffusion-Based Hierarchical Graph Neural Networks for Simulating Nonlinear Solid Mechanics", "authors": "Tobias Würth,Niklas Freymuth,Gerhard Neumann,Luise Kärger", "background": "基于图的学习模拟器在使用非结构化网格模拟物理系统方面显示出潜力，但往往难以捕捉全局现象，如弯曲或长程相关性，并且依赖局部消息传递和直接下一步预测导致长时间序列的错误累积。", "innovation": "提出了Rolling Diffusion-Batched Inference Network (ROBIN)，通过引入两种创新：(i) Rolling Diffusion-Batched Inference (ROBI)，一种并行化推断方案，通过在时间窗口内重叠去噪步骤，在物理时间步长上分摊基于扩散的细化成本。(ii) 基于代数多重网格细化的分层图神经网络，实现不同网格分辨率下的多尺度消息传递。", "conclusion": "ROBIN在2D和3D固体力学基准测试中表现出色，且显著优于现有的一步预测学习模拟器，与标准扩散模拟器相比，推理时间最多减少了一个数量级。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.07584", "html_url": "https://arxiv.org/abs/2506.07584", "title": "MIRA：针对实际健康数据的医疗时间序列基础模型", "title_en": "MIRA: Medical Time Series Foundation Model for Real-World Health Data", "authors": "Hao Li,Bowen Deng,Chang Xu,Zhiyuan Feng,Viktor Schlegel,Yu-Hao Huang,Yizheng Sun,Jingyuan Sun,Kailai Yang,Yiyao Yu,Jiang Bian", "background": "现有的通用时间序列基础模型难以处理具有不规则间隔、异质抽样速率和频繁缺失值等挑战的医疗时间序列数据。因此，迫切需要一种专门针对医疗时间序列预测的统一基础模型。", "innovation": "MIRA是一种专门为医疗时间序列预测设计的统一基础模型，它包含持续时间旋转位置编码、频率特定的专家混合层以及基于神经ODE的持续动力学外推块。MIRA在来自多个公开数据集的大型和多样化的医疗语料库上进行预训练，以提高其在不同上下文中的预测准确性。", "conclusion": "MIRA相较于零样本和微调基准，在不同分布场景中分别实现了10%和7%的预测误差减少。此外，还引入了一个全面的下游临床任务基准，为未来在医疗时间序列建模方向的研究奠定了基础。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09018", "html_url": "https://arxiv.org/abs/2506.09018", "title": "Edit Flows: 使用编辑操作的流动匹配", "title_en": "Edit Flows: Flow Matching with Edit Operations", "authors": "Marton Havasi,Brian Karrer,Itai Gat,Ricky T. Q. Chen", "background": "自回归生成模型能够自然地生成可变长度序列，而非自回归模型则难以胜任，常常需要施加刚性的、以token为单位的结构。已有模型难以捕捉序列数据的结构特性，导致生成效果不尽如人意。", "innovation": "提出了一种名为 Edit Flows 的非自回归模型，它通过定义在序列上的编辑操作（插入、删除、替换），在连续时间马尔可夫链的框架下模拟能够灵活、位置相对地生成序列数据，以克服现有模型的限制。通过引入扩展的状态空间和辅助变量，使模型训练过程高效、易于计算。", "conclusion": "实验结果显示，Edit Flows 在图像字幕生成任务上的表现优于自回归模型和遮蔽模型，在文本和代码生成任务上也显著优于现有的遮蔽构建方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10948", "html_url": "https://arxiv.org/abs/2506.10948", "title": "执行指导下的逐行代码生成", "title_en": "Execution Guided Line-by-Line Code Generation", "authors": "Boaz Lavon,Shahar Katz,Lior Wolf", "background": "虽然大型语言模型（LLMs）在代码生成方面展现了出色的性能，但在推理过程中它们通常不利用执行反馈这一关键信号，而人类程序员会频繁利用这种反馈进行编程。该研究提出了一个名为Execution-Guided Classifier-Free Guidance (EG-CFG)的新方法，该方法动态地将执行信号融入到代码生成过程中，提供逐行反馈来引导生成过程向可执行的解决方案发展。", "innovation": "该方法通过多阶段过程，首先使用束搜索来为每一行代码抽取候选程序补全，接着执行这些候选代码并提取执行信号，最后将这些信号纳入生成过程的提示中。这种方法保持了行内信号的一致性，在行边界处重新生成信号，从而提供连贯的指导，同时保留了语法结构。此外，该方法在任务级别上自然支持多智能体的并行处理，多个智能体平行探索多样化的推理路径，集体生成广泛的候选解决方案。该研究在各种编码任务上的实验表明，EG-CFG 显著提高了代码生成的性能，达到了各复杂度层次的最先进的效果。", "conclusion": "该研究展示了EG-CFG方法在代码生成中的优势，通过集成执行信号，该方法显著提高了代码生成性能，并在复杂度不同的编码任务中达到了最先进的水平。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06644", "html_url": "https://arxiv.org/abs/2506.06644", "title": "Spark Transformer: 在FFN和注意机制中重新激活稀疏性", "title_en": "Spark Transformer: Reactivating Sparsity in FFN and Attention", "authors": "Chong You,Kan Wu,Zhipeng Jia,Lin Chen,Srinadh Bhojanapalli,Jiaxian Guo,Utku Evci,Jan Wassenberg,Praneeth Netrapalli,Jeremiah J. Willcock,Suvinay Subramanian,Felix Chern,Alek Andreev,Shreya Pathak,Felix Yu,Prateek Jain,David E. Culler,Henry M. Levy,Sanjiv Kumar", "background": "在训练的Transformer中，发现几乎所有前馈网络（FFN）中的神经元在每个标记处都是不活跃的，这激发了对激活稀疏性的研究，以提高大型模型的效率。尽管在将稀疏性转化为实际时间收益方面取得了显著进展，但现代Transformer已经远离了这种现象中至关重要的ReLU激活函数。现有的重新引入激活稀疏性的努力往往会降低模型质量，增加参数数量，复杂化或减慢训练过程。稀疏注意力机制的应用也遇到了类似的问题。", "innovation": "本论文提出了一种名为Spark Transformer的新架构，它在FFN和注意机制中实现了高度的激活稀疏性，同时保持了模型质量、参数数量和标准训练程序。通过top-k掩码实现明确的稀疏性控制，并引入了一种硬件加速器友好的、近线性时间的统计top-k算法，避免了成本高昂的排序操作并减少了标准top-k算子带来的显著训练速度慢问题。此外，Spark Transformer重新分配了现有的FFN参数和注意键嵌入，形成一个低成本预测器来识别激活条目。这种设计不仅缓解了强制稀疏性带来的质量损失，还增强了实际时间收益。", "conclusion": "使用Gemma-2食谱预训练的Spark Transformer在标准基准测试中表现出竞争力，同时展示出了显著的稀疏性：FFN神经元只有8%是激活的，每个标记最多关注256个标记。这种稀疏性导致浮点运算次数减少了2.5倍，CPU解码实际时间加速了1.79倍，GPU加速了1.40倍。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14167", "html_url": "https://arxiv.org/abs/2506.14167", "title": "Thermodynamic Kolmogorov-Arnold Model for Structured Generative Modeling", "title_en": "Structured Generative Modeling with the Thermodynamic Kolmogorov-Arnold Model", "authors": "Prithvi Raj", "background": "能源模型（EBM）在顶层生成模型的潜空间中学习提供了一个跨多种数据模态生成的灵活框架，但仍不清楚其可解释性如何指导模型设计、提高生成质量和减少训练时间。此外，依赖于Langevin蒙特卡洛（LMC）采样带来了效率和采样多模态潜分布的挑战。", "innovation": "提出了一种Kolmogorov-Arnold表示定理的新适应方法，并引入了Thermodynamic Kolmogorov-Arnold Model (T-KAM) 利用结构和归纳偏差。通过约束先验到单变量关系，T-KAM 能通过反变换方法实现快速且精确的推理。此外，探讨了一种新的基于人口的LMC策略，通过细化分布序列来增强多模态采样。", "conclusion": "T-KAM 平衡了生成建模中常见的权衡，提供快速推理、可解释性和稳定训练，同时自然适合未来的Zettascale Computing Corp.硬件。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14291", "html_url": "https://arxiv.org/abs/2506.14291", "title": "处处无处不在：图基元模型的配方", "title_en": "Equivariance Everywhere All At Once: A Recipe for Graph Foundation Models", "authors": "Ben Finkelshtein,İsmail İlkan Ceylan,Michael Bronstein,Ron Levie", "background": "图机器学习架构通常针对特定任务和特定数据集进行定制，限制了其更广泛的适用性。因此，一个新的研究方向在于如何构建能够在任意图和特征上进行泛化的图基元模型？本文从基本原理出发，介绍了一种设计节点级别任务的图基元模型的方法。关键在于系统性地研究图基元模型必须遵守的对称性。文章认为标签置换等变性和特征置换不变性在常节点置换等变性之外是必要的。", "innovation": "本文提出了一种基于对称性系统研究的设计图基元模型的方法，其中的关键是标签置换等变性和特征置换不变性。通过这种方式，确定了适用于遵守这些对称性的多集空间中的线性变换，并证明了这种网络是通用近似器。通过这种方法，提出了用于节点属性预测的类图基元模型。本文通过在29个真实世界的节点分类数据集上的广泛实验，验证了方法的有效性和性能提升。", "conclusion": "本文验证了通过如此设计得到的图基元模型，在29个真实世界的节点分类数据集上具有强大的零样本实验性能，并且当训练图的数量增加时具有持续的性能改进。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13688", "html_url": "https://arxiv.org/abs/2506.13688", "title": "损失 plateau 期间发生了什么？理解 Transformers 的突兀学习", "title_en": "What Happens During the Loss Plateau? Understanding Abrupt Learning in Transformers", "authors": "Pulkit Gopalani,Wei Hu", "background": "在训练 Transformer 处理算法任务时，经常会出现一个有趣的突兀学习现象：经过较长一段时间的稳定性能（ plateau ），随后会出现突然显著提升。这篇文章主要探讨浅层 Transformer 中这种动态机制，尤其是在损失 plateau 期间的表现。研究表明，在 plateau 期间，模型通常会发展出可解释的部分解，同时在输出上表现出强烈的重复偏见。这种输出的退化伴随内部表示的崩溃，即不同标记的隐藏状态变得几乎平行。此外，还发现最优注意力图的缓慢学习是关键瓶颈。在 plateau 期间，注意力配置的潜在进步导致最终的快速收敛，并且直接干预注意力可以显著改变 plateau 的持续时间和重复偏见及表示崩溃的严重程度。验证结果表明，这些现象（重复偏见和表示崩溃）不仅仅限于玩具设置，在大型语言模型（如 Pythia 和 OLMo 的早期预训练阶段）中也有所体现。", "innovation": "文章揭示了在 plateau 期间，模型逐渐发展出可解释的部分解和强烈重复偏见的现象，并指出最优注意力图的缓慢学习是瓶颈。进一步研究发现，直接干预注意力可以显著改变 plateau 的持续时间和重复偏见及表示崩溃的严重程度。这些发现不仅适用于浅层 Transformer，也适用于大型语言模型的早期阶段，提供了对突兀学习现象更深刻的理解，这对于优化训练过程具有重要价值。", "conclusion": "研究结果表明， plateau 期间的重复偏见和表示崩溃并不是玩具设置的缺陷，而是在大型语言模型中也存在。通过该研究，我们更深入地理解了浅层 Transformer 和大型语言模型在损失 plateau 期间的动态行为，为优化训练过程提供了新的见解。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14436", "html_url": "https://arxiv.org/abs/2506.14436", "title": "MoORE: SVD-based Model MoE-ization for Conflict- and Oblivion-Resistant Multi-Task Adaptation", "title_en": "MoORE: SVD-based Model MoE-ization for Conflict- and Oblivion-Resistant Multi-Task Adaptation", "authors": "Shen Yuan,Yin Zheng,Taifeng Wang,Binbin Liu,Hongteng Xu", "background": "在多任务场景中，大规模基础模型的适应性往往受到任务冲突和遗忘的问题。现有技术如低秩适应（LoRA）及其MoE变种虽然在一定程度上缓解了这些问题，但它们无法完全保证专家的正交性和保持原权重矩阵的列空间，因此可能仍然导致新任务之间的冲突以及对原有任务的遗忘。", "innovation": "本文提出了一种新的'模型MoE-化'策略——MoORE，它通过SVD对预训练模型的权重矩阵进行分解，并引入一个可学习的路由器来调整其奇异值，基于任务和样本来构造MoORE混合模型。MoORE保证了专家的正交性并维持了原始权重矩阵的列空间，从而显著提高了模型适应新任务的能力，减少了任务间的冲突和对原有任务的遗忘问题。实验结果表明，MoORE在各种数据集上均优于现有的多任务适应方法，显示出其在冲突和遗忘抵抗方面的优越性。", "conclusion": "MoORE通过引入新的MoORE混合模型策略，实现了对新任务的快速适应和对原有任务的保持。实验结果证明了其在多任务场景中的优越性能，表明该方法有效缓解了任务冲突和遗忘问题。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13992", "html_url": "https://arxiv.org/abs/2506.13992", "title": "AssistedDS: 评估外部领域知识如何辅助LLMs在自动化数据科学中的表现", "title_en": "AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science", "authors": "An Luo,Xun Xian,Jin Du,Fangqiao Tian,Ganghua Wang,Ming Zhong,Shengchun Zhao,Xuan Bi,Zirui Liu,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Mingyi Hong,Jie Ding", "background": "大型语言模型（LLMs）已经在自动化数据科学工作流程中取得了进步，但目前还不清楚它们是否能够像人类数据科学家那样，有效地利用外部领域知识。为了回答这个问题，本文提出了AssistedDS（辅助数据科学）基准，该基准系统地评估LLMs在表格预测任务中处理领域知识的能力。AssistedDS结合了带有明确生成机制的合成数据集和真实的 Kaggle 竞赛，每种都附带了精选的有助于学习和对抗性文档，这些文档提供了关于数据清洗、特征工程和模型选择的专业指导。评估结果显示，当前的模型在处理领域知识时存在一些重要问题，包括无批判地接受信息，对抗性信息的负面影响，以及在处理时间序列数据、特征工程和解释分类变量方面存在的错误。这些结果突显了现有模型评估和利用专家知识能力的不足，指出了未来研究的方向。", "innovation": "引入了AssistedDS基准，旨在系统性评估LLMs在表格预测任务中处理领域知识的能力。该基准结合了合成数据集和真实世界Kaggle竞赛，提供了有助于学习和对抗性文档，评估LLMs的能力包括被批判性地处理和应用有益还是有害的领域知识，提交的有效性，信息检索和预测性能。通过这种方法，研究团队发现了当前模型在应对领域知识方面的不足，并提出了一种新的研究方向，即开发更 robust 和知识敏感的自动化数据科学系统。", "conclusion": "研究发现，当前的LLMs在处理领域知识时存在严重问题，主要表现为无批判性地接受信息，对抗性信息的负面影响和时间序列数据、特征工程和分类变量处理中出现的错误。这些发现揭示了当前模型评估和利用领域知识的有效性的局限性，指出了新的研究方向和发展更 robust、知识敏感的自动化数据科学系统的重要性。研究数据和代码已公开，可供进一步研究使用。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.16349", "html_url": "https://arxiv.org/abs/2506.16349", "title": "自回归图像生成模型的水印", "title_en": "Watermarking Autoregressive Image Generation", "authors": "Nikola Jovanović,Ismail Labiad,Tomáš Souček,Martin Vechev,Pierre Fernandez", "background": "生成模型的输出水印化作为一种追踪生成模型来源的有效手段引起了广泛关注，尤其是在自回归图像生成模型的滥用风险日益增大时。然而，至今没有研究尝试在自回归生成模型的输出层面进行标记（token层面）。这一领域的空白正是本文填补的对象。", "innovation": "文章创新性地将语言模型水印技术应用于自回归图像生成模型的输出标记中。面对生成图像的token化逆向一致性（RCC）问题，即重新token化显著改变了token序列的问题，文章首次提出了一种自定义的tokenizer-detokenizer微调方法以提升RCC，并引入了一种水印同步层，使方法能够抵御常见的图像变换、神经压缩及去除攻击，从而实现了理论上可证实的p值的可靠和稳健的水印检测。", "conclusion": "实验结果表明，本文提出的方法可以实现可靠且抗攻击的水印检测。该方法的相关代码与模型已公开。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23751", "html_url": "https://arxiv.org/abs/2505.23751", "title": "REOrdering Patches Improves Vision Models", "title_en": "REOrdering Patches Improves Vision Models", "authors": "Declan Kutscher,David M. Chan,Yutong Bai,Trevor Darrell,Ritwik Gupta", "background": "序列模型如变压器需要将输入表示为一维序列。在视觉领域，这通常涉及使用固定顺序（如逐行扫描）展平图像。虽然全自注意机制具有置换不变性，但现代长序列变压器越来越多地依赖于破坏这种不变性并使模型对块顺序敏感的架构近似方法。研究表明，在这种情况下，块顺序对模型性能有显著影响，简单的替代方案如列优先或海利伯特曲线能显著改善准确性。鉴于此，提出了一种两阶段框架REOrder用于发现任务最优的块排序。该框架首先通过评估不同块序列的可压缩性来推导信息论先验，接着通过基于REINFORCE优化Plackett-Luce策略学习一个置换政策。这种方法能使模型在组合置换空间中有效学习。", "innovation": "提出了REOrder，这是一种两阶段框架，用于发现任务最优的块排序。该框架首先通过评估不同块序列的可压缩性来推导信息论先验，然后通过基于REINFORCE优化Plackett-Luce策略学习一个置换政策，从而实现模型在组合置换空间中的高效学习。此方法在ImageNet-1K和Functional Map of the World上的表现明显优于行优先排序，分别提高了3.01%和13.35%的顶级精度。", "conclusion": "REOrder通过优化块排序提高了视觉模型的性能，在ImageNet-1K和Functional Map of the World上的表现分别比行优先排序提高了3.01%和13.35%的顶级精度。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23679", "html_url": "https://arxiv.org/abs/2506.23679", "title": "使用变换器学习模幂运算", "title_en": "Learning Modular Exponentiation with Transformers", "authors": "David Demitri Africa,Sara M. Kapoor,Theo Simon Sorg,Challenger Mishra", "background": "模幂运算在数论与密码学中至关重要，但在机制可解释性方面尚未得到充分探索。本文利用4层编码器-解码器Transformer模型来执行模幂运算，并研究训练过程中数理推理能力的涌现。", "innovation": "通过采用原则性的采样策略、基于PCA的嵌入分析和激活补丁，本文探究了模型中数论性质的编码方式。研究发现，逆操作数训练能带来显著性能提升，模型在相关模基数间的泛化能力增强。此外，最后一层中的一个注意力子图足以完成常规幂运算，表明Transformer模型通过专门的计算电路学习模算术，为更可解释和高效的模幂运算神经方法铺平了道路。", "conclusion": "本文展示的模型通过特定的计算电路学习模算术，揭示了Transformer模型在模幂运算中的新机制，有助于提升该领域的理解和效率。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18631", "html_url": "https://arxiv.org/abs/2506.18631", "title": "ReDit：改进LLM策略优化的奖励抖动方法", "title_en": "ReDit: Reward Dithering for Improved LLM Policy Optimization", "authors": "Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu", "background": "DeepSeek-R1通过规则基础上的奖励系统成功增强了大型语言模型的推理能力，尽管这种奖励系统在减轻奖励作弊方面表现得‘完美’，但仍往往是离散的。实验观察表明，离散奖励会导致梯度异常、优化不稳定以及收敛速度慢的问题。", "innovation": "提出了一种名为ReDit的方法，通过在离散的奖励信号中添加简单的随机噪声来进行奖励抖动。这种方法提供了探索性的梯度，使梯度更新更加平滑并加速了收敛。注入的噪声还将随机性引入平坦的奖励区域，鼓励模型探索新的策略并逃脱局部最优。", "conclusion": "在多项任务实验中，ReDit显示出了其有效性和效率。平均来说，ReDit在训练步骤减少约10%的情况下能达到与纯GRPO相同的性能，并且在相同训练时间内还比纯GRPO提高了4%的性能。可视化结果进一步证实了ReDit在缓解梯度问题方面的显著效果。理论分析进一步验证了这些优势。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17065", "html_url": "https://arxiv.org/abs/2506.17065", "title": "基于流的方法用于具有非高斯或异方差噪音的动态时间因果模型", "title_en": "Flow based approach for Dynamic Temporal Causal models with non-Gaussian or Heteroscedastic Noises", "authors": "Abdellah Rahmani,Pascal Frossard", "background": "理解多变量时间序列中的因果关系在许多场景中至关重要，如金融或神经科学研究。这类时间序列通常呈现多个阶段，即具有未知边界的连续时间段，每个阶段具有独特的因果结构。识别因果依赖性和阶段转变对于分析基础过程至关重要。然而，这种设置下的因果结构学习面临挑战，因为（1）各阶段可能有不同的因果图和混合函数，导致非平稳性；（2）噪音分布可能非高斯或异方差。现有的因果发现方法无法解决这些问题，因为通常假设平稳性或高斯噪音与恒定方差。因此，提出了FANTOM框架，它统一处理非平稳过程及其非高斯和异方差噪音。", "innovation": "FANTOM框架是一个统一框架，能够处理非平稳过程和非高斯、异方差噪音，同时推断出阶段数量及其对应索引，学习每个阶段的有向无环图（DAG）。它使用贝叶斯期望最大化算法，最大化数据对数似然的证据下界。理论证明了在平稳和非平稳条件下，基于FANTOM模型的时变异方差因果模型在参数识别上是可识别的。实验结果显示，FANTOM在合成数据和真实数据上的表现优于现有方法。", "conclusion": "FANTOM是一个统一而有效的框架，能够处理时间序列中的非平稳性、非高斯噪音和异方差性。该方法是通过优化数据对数似然的证据下界，并通过贝叶斯期望最大化算法来识别每个阶段的独特因果结构。此外，该方法在不同类型的数据集上都表现出了较高的准确性，证明了其在因果结构学习方面的优越性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10998", "html_url": "https://arxiv.org/abs/2507.10998", "title": "为表格数据打造隐形于原数据流上的对抗攻击", "title_en": "Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data", "authors": "Zhipeng He,Alexander Stevens,Chun Ouyang,Johannes De Smedt,Alistair Barros,Catarina Moreira", "background": "表格数据因其混合型特征（混合了分类和数值特征）而带来了独特的挑战。攻击者的挑战在于，表格数据缺乏直观的相似度度量，因此很难定义不可察觉的修改。传统的基于梯度的方法通常只关注于$\bar{p}$范数约束，这常常导致生成的对抗样本与原始数据分布发生偏离。本文背景是探讨如何利用混合输入变分自编码器（VAE）创建统计一致性较高的对抗样本。", "innovation": "提出了一种使用混合输入变分自编码器（VAE）的潜在空间扰动框架，将分类嵌入和数值特征整合到统一的潜在流形中，为对抗样本的生成提供了一种新的方法。作者引入了内部分布成功率（IDSR）来共同评估攻击效果和分布均匀性。实验结果显示，在六个公开数据集和三种模型架构上，该方法取得了显著低于传统输入空间攻击及其他基于图像领域的VAE方法的异常值率，并且具有更高的IDSR。", "conclusion": "通过全面分析超参数敏感性、稀疏控制和生成架构的有效性，研究证明，基于VAE的对抗攻击方法的效用和稳定性取决于重构质量以及充足的训练数据。当这些条件满足时，提出的方法相比输入空间方法具有更优秀的效果和稳定性。这项工作强调了在表格领域生成真实且鲁棒的对抗样本时保持沿流形上扰动的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22766", "html_url": "https://arxiv.org/abs/2507.22766", "title": "使用高斯过程作为代理模型的基于贝叶斯优化的传感器排序系统工艺参数优化方法", "title_en": "Bayesian Optimization of Process Parameters of a Sensor-Based Sorting System using Gaussian Processes as Surrogate Models", "authors": "Felix Kronenwett,Georg Maier,Thomas Längle", "background": "基于传感器的分拣系统能够物理分离物料流，实现物料的两部分分类。分拣决策基于所使用传感器的图像数据评估，并通过执行机构进行。工艺参数设置需根据物料流特性、系统配置和所需的分拣精度来确定，但因要求和物料组成的变化，持续验证和调整是必要的。本文提出了一个通过贝叶斯优化实现传感器分拣系统工艺参数优化、反复监控和调整的方法。方法采用高斯过程回归模型作为代理模型，结合不确定性因素，确保系统行为符合特定要求，同时最小化实验需求，并同时考虑两个物料输出流的要求。", "innovation": "该方法使用了贝叶斯优化和高斯过程回归模型作为代理模型，以最小化实验需求的同时，考虑系统行为所需的具体要求及由此带来的不确定性，还同时兼顾两个物料输出流的要求。", "conclusion": "本研究通过对三个示例工艺参数的评估，展示了使用高斯过程作为代理模型的基于贝叶斯优化方法的有效性和优势，从而提出了一个处理分拣系统工艺参数优化的新方法，该方法在考虑不确定性的条件下，优化工艺参数，同时满足系统的特定行为要求。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07101", "html_url": "https://arxiv.org/abs/2507.07101", "title": "语言模型的小批量训练：为什么简单的SGD有效，以及梯度累积为何有浪费", "title_en": "Small Batch Size Training for Language Models: When Vanilla SGD Works, and Why Gradient Accumulation Is Wasteful", "authors": "Martin Marek,Sanae Lotfi,Aditya Somasundaram,Andrew Gordon Wilson,Micah Goldblum", "background": "传统的做法是认为小批量尺寸会导致语言模型的预训练和微调不稳定，因此人们采用梯度累积的方法，通过增加批量尺寸来提高训练稳定性。通常会降低学习率以适应小批量尺寸，但其他超参数则保持不变。本文重新审视了小批量尺寸的问题，甚至从单个样本的小批量尺寸开始，提出了针对小批量尺寸调整Adam超参数的方法。研究表明，小批量尺寸训练时（1）能够稳定训练，（2）对超参数选择更加稳健，（3）在每FLOP性能方面甚至优于大规模批量尺寸，（4）即使不用动量也没有存储优化器状态也能够实现稳定的语言模型训练。基于这些结果，文章还提供了一些建议：选择合适的批量尺寸和设置优化器超参数，不必总是依赖梯度累积，除非在多个设备上训练多个模型副本。同时，指出小批量结合小型优化器状态能够提供全微调的性能优势，同时保持与LoRA类似的内存占用。", "innovation": "提出了一种调整Adam超参数的方法，使训练变得稳定；验证了小批量尺寸对于优化器状态和梯度累积的不需要或有限依赖；展示了即使是简单的SGD也能够在小批量尺寸下有效，尤其是在不需要动量的情况下；证明了小批量尺寸可以提供与全微调相当的性能，同时保持类似LoRA的内存占用。", "conclusion": "小批量尺寸训练环境下，即使是简单的SGD也能够有效进行，且可能比梯度累积更具优势。无需动量情况下的小批量尺寸训练能够提供稳定性和性能上的良好表现，且优化器状态较小，节省了内存。梯度累积除非在多设备多模型复制情况下其他时候效率不高。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02753", "html_url": "https://arxiv.org/abs/2508.02753", "title": "DMSC: 动态多尺度协调框架在时间序列预测中的应用", "title_en": "DMSC: Dynamic Multi-Scale Coordination Framework for Time Series Forecasting", "authors": "Haonan Yang,Jianchao Tang,Zhuo Li,Long Lan", "background": "时间序列预测（TSF）在建模不同尺度下的复杂时间依赖关系方面仍面临持续性的挑战。尽管近期有一些利用不同的分解操作和基于CNN、MLP或Transformer的新模型取得了进展，但现有的方法仍然在依赖于固定的分解策略、碎片化的依赖建模以及不灵活的融合机制方面存在局限，这限制了其建模复杂时间依赖关系的能力。", "innovation": "本文提出了一种新的动态多尺度协调框架（DMSC），包括多尺度片段分解模块（EMPD）、三元互动块（TIB）和自适应尺度路由MoE模块（ASR-MoE）。该框架首先通过输入自适应片段调整动态将序列片段成层次结构，使用TIB分别对片段内、片段间和跨变量依赖关系进行建模，并通过门控路径在多层渐进级联结构中使不同层次的表示进行自适应引导。此外，ASR-MoE模块通过利用特定于全局和局部的专家并结合时间感知的加权进行动态多尺度预测融合。", "conclusion": "在十三个实际基准测试上进行的全面实验表明，DMSC保持了时间序列预测任务中的最新性能（SOTA）并具有优越的计算效率。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02844", "html_url": "https://arxiv.org/abs/2509.02844", "title": "带变点的时间序列预测的可信区间预测", "title_en": "Conformal Prediction for Time-series Forecasting with Change Points", "authors": "Sophia Sun,Rose Yu", "background": "已有关于时间序列的可信区间预测方法展现出了一般性和高效性，但现有方法在处理包含变点（即数据生成过程中的突然变化）的时间序列数据时存在局限性。", "innovation": "提出了一个新的CPTC算法，通过结合预测潜在状态的模型和在线可信区间预测来处理非平稳时间序列中的不确定性和变点问题，该算法在最小假设下证明了其有效性和适应性。", "conclusion": "研究结果表明，CPTC算法在6个合成数据集和真实世界数据集上都表现出比当前最先进的基准算法更好的有效性和适应性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10053", "html_url": "https://arxiv.org/abs/2508.10053", "title": "xRFM: 准确、可扩展且具有解释性的表格数据特征学习模型", "title_en": "xRFM: Accurate, scalable, and interpretable feature learning models for tabular data", "authors": "Daniel Beaglehole,David Holzmüller,Adityanarayanan Radhakrishnan,Mikhail Belkin", "background": "表格数据是现代技术与科学的基础，通常包含分类和连续变量的矩阵形式。尽管AI的其他领域经历了巨大变革，但在这些预测任务的最佳实践中，主要仍依赖于梯度提升决策树（GBDT）变体的方法。最近，基于神经网络和特征学习方法的进步，出现了新的方法来处理表格数据。", "innovation": "提出了一种名为xRFM的算法，结合了特征学习核机器和树结构，能够适应数据的局部结构，并可扩展到几乎无限的训练数据量。xRFM在100个回归数据集上表现出最佳性能，并在200个分类数据集上与最佳方法竞争，优于GBDT。此外，xRFM还能通过平均梯度外积提供内置的解释性。", "conclusion": "xRFM算法在表格数据处理中表现出色，既准确又可扩展，还具有内在的解释性，相较于GBDT有更好的性能表现。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01257", "html_url": "https://arxiv.org/abs/2509.01257", "title": "无线边缘网络中的任务卸载的多智能体强化学习", "title_en": "Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks", "authors": "Andrea Fox,Francesco De Pellegrini,Eitan Altman", "background": "在边缘计算系统中，自主智能体需要在有限的可观测性和通信约束下做出快速的本地决策并争夺共享资源。现有方法通常依赖集中式评论家或者频繁的通信，这在上述条件下是无效的。", "innovation": "提出了一种去中心化框架，每个智能体解决有约束的马尔可夫决策过程（CMDP），并通过共享约束向量隐式协调。针对卸载任务的特定情况，约束防止负载共享服务器资源。这些约束会定期更新，并作为轻量级协调机制使用。它们使智能体能够与全球资源使用目标保持一致，但需要较少的直接通信。利用安全的强化学习，智能体学习满足本地和全球目标的策略。", "conclusion": "在温和假设下建立了理论保证，并通过实验验证了方法的有效性，与中心化和独立基线相比，特别是在大规模设置中，显示了更好的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.06863", "html_url": "https://arxiv.org/abs/2509.06863", "title": "floq：通过流匹配训练批评者以扩展值基于强化学习中的计算能力", "title_en": "floq: Training Critics via Flow-Matching for Scaling Compute in Value-Based RL", "authors": "Bhavya Agrawalla,Michal Nauman,Khush Agrawal,Aviral Kumar", "background": "现代大规模机器学习技术的一个特征是使用密集监督训练目标，如语言模型中的教师强制传递下一个标记或扩散模型中的逐步降噪。这使模型能够以通用的方式学习复杂的函数。受到这一观察的启发，本文研究了迭代计算在强化学习（RL）中的时差（TD）方法中的益处。传统的TD方法通常以整体方式表示价值函数，没有迭代计算。", "innovation": "本文提出了floq（流匹配Q函数），一种使用流场参数化Q函数的方法，并使用流匹配技术进行训练，这通常用于生成建模。流场下的Q函数使用TD学习目标进行训练，该目标从通过多次数值积分运行计算的目标流场产生的值进行扶持。floq通过适当设置积分步骤，比整体架构提供了更精细的Q函数容量控制和扩展。在一系列具有挑战性的离线RL基准和在线微调任务中，floq提高了接近1.8倍的性能，揭示了迭代计算在价值学习中的潜在优势。", "conclusion": "floq在容量扩展能力方面远超标准的TD学习架构，突显了迭代计算在价值学习中的潜力。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02279", "html_url": "https://arxiv.org/abs/2510.02279", "title": "自然语言生成中不确定性评估方法评估中的缺陷及其解决", "title_en": "Addressing Pitfalls in the Evaluation of Uncertainty Estimation Methods for Natural Language Generation", "authors": "Mykyta Ielanskyi,Kajetan Schweighofer,Lukas Aichberger,Sepp Hochreiter", "background": "大型语言模型（LLMs）中的幻觉问题影响了其可靠性。近期研究表明，一种特定的幻觉现象，即错编现象（Confabulations），由LLMs的预测不确定性引起。当前，通过与生成文本正确性的相关性来评估不确定性估计方法（UE方法），通常使用问答（QA）数据集作为基准测试。然而，常用的大致正确性函数之间存在显著差异，从而影响评估结果的可靠性。", "innovation": "论文提出使用多种替代风险指标来改进不确定性估计方法（UE方法）在自然语言生成中的实证评估；通过对多版LLM（作为评委）进行归一化，减少了评估偏见；探讨结构化任务和异常检测任务以提供稳定和可控的风险指标；使用不确定性估计方法的Elo排名来客观汇总广泛的评估设置，从而提高评估的稳健性。", "conclusion": "该研究利用多种替代风险指标改进不确定性估计方法在自然语言生成中的评估，通过标准化LLM作为评委减少评估偏差，探索结构化和异常检测任务作为稳定的风险指标，并提出使用Elo排名进行客观总结，总体提高了UE方法在广泛评估设置下的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04008", "html_url": "https://arxiv.org/abs/2510.04008", "title": "用锐化的角度相似性替换softmax相似性：扩展到具有亿级上下文的注意机制的理论与实践", "title_en": "Replacing Softmax Similarity with a Sharpened Angular Similarity: Theory and Practice of Scaling To Billion-Context Attention", "authors": "Sahil Joshi,Agniva Chowdhury,Amar Kanakamedala,Ekam Singh,Evan Tu,Anshumali Shrivastava", "background": "softmax注意力机制的时间复杂度为平方级别，这在面对长上下文时变得难以处理，即使是高度优化的GPU内核也无法应对。例如，在NVIDIA GH200 GPU上，FlashAttention（softmax注意力机制的精确GPU优化实现）一旦上下文超过约400万标记就无法完成一次前向-后向传递。因此，需要一种线性于序列长度和嵌入维度的新方法来提高长上下文处理能力，同时保持准确率和降低资源消耗.", "innovation": "RACE注意力机制，它通过锐化角度相似性替代了指数级内核，并通过随机投影和软局部敏感哈希（LSH）近似注意输出，实现了线性于序列长度和嵌入维度的效果。该方法在语言模型、掩码语言模型和文本分类中表现出了与强基线相当的准确率，同时显著提高了运行时间和内存效率。实验显示，RACE注意力机制在NVIDIA GH200 GPU上可以处理高达1200万标记，在Intel Xeon Gold 5220R CPU上可以处理高达7500万标记，远超当前最新技术的实际上限，因此提供了一种量化长上下文的实用且理论有力的方法.", "conclusion": "RACE注意力机制提供了一种实用的有效机制，即使在现有硬件上也能处理异常长的上下文窗口。我们希望这项技术能在实践中被采用和应用."}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06377", "html_url": "https://arxiv.org/abs/2510.06377", "title": "关系变换器：通往关系数据零样本基础模型的道路", "title_en": "Relational Transformer: Toward Zero-Shot Foundation Models for Relational Data", "authors": "Rishabh Ranjan,Valter Hudovernik,Mark Znidar,Charilaos Kanatsoulis,Roshan Upendra,Mahmoud Mohammadi,Joe Meyer,Tom Palczewski,Carlos Guestrin,Jure Leskovec", "background": "预训练的变换器在新的序列建模任务中可以不进行任何调整地使用零样本提示进行适应，但针对关系领域的架构仍然没有能够在不同的数据集和任务间进行迁移的能力。核心挑战在于关系数据的多样性，包括不同的异构模式、图形结构和函数依赖关系。", "innovation": "提出了一种关系变换器（RT）架构，该架构可以在多样化的关系数据库上进行预训练，并且可以在未见过的数据集和任务中直接应用，而无需针对特定的任务或数据集进行微调，或检索上下文示例。RT 结构包括：(i) 使用表/列元数据对单元格进行标记化；(ii) 通过掩码标记预测进行预训练；(iii) 利用一种新的关系注意力机制，涵盖列、行和主外键连接。在覆盖诸如流失和销售预测等任务的RelBench数据集上进行预训练，RT 实现了强大的零样本性能，平均在一个22M参数模型的单次前向传播中达到93%的完全监督AUC ROC，而27B参数的大语言模型仅为84%。", "conclusion": "我们的实验表明，RT 的零样本迁移利用了任务-表上下文、关系注意力模式和模式语义。总体而言，RT 为关系数据提供了实现基础模型的一种实用途径。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09114", "html_url": "https://arxiv.org/abs/2510.09114", "title": "关于隐私保护的公平性：测量和减轻差异化隐私机器学习中组隐私风险差异", "title_en": "On the Fairness of Privacy Protection: Measuring and Mitigating the Disparity of Group Privacy Risks for Differentially Private Machine Learning", "authors": "Zhi Yang,Changwu Huang,Ke Tang,Xin Yao", "background": "尽管在传统公平性机器学习和差异隐私机器学习方面已经取得了显著进展，但不同群体的隐私保护公平性仍然未被充分研究。现有的方法侧重于评估数据记录的平均隐私风险，这可能导致低估群体隐私风险差异。此外，现有评估数据记录最坏情况隐私风险的方法耗时较长，限制了其实用性。", "innovation": "提出了一种新的成员推理游戏，可以高效地审计数据记录的近似最坏情况隐私风险。通过结合差异隐私审计研究中的“金丝雀”策略，增强标准的DP-SGD算法，提出了一个自适应的群体特定梯度裁剪策略，从而有效减少了组间隐私风险差异，提升了差异化隐私机器学习中的隐私保护公平性。", "conclusion": "实验结果表明，该方法能更严格地量化群体隐私风险，提供对群体隐私风险差异的可靠评估。结合这一方法和自适应群体特定梯度裁剪策略，能有效地减少群体间的隐私风险差异，提高差异化隐私机器学习中的隐私保护公平性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08141", "html_url": "https://arxiv.org/abs/2510.08141", "title": "任意熵策略优化：熵在强化微调中是可控的", "title_en": "Arbitrary Entropy Policy Optimization: Entropy Is Controllable in Reinforcement Fine-tuning", "authors": "Chen Wang,Zhaochun Li,Jionghao Bai,Yuzhi Zhang,Shisheng Cui,Zhou Zhao,Yue Wang", "background": "强化微调(RFT)对于提升大型语言模型(LLM)的推理能力至关重要，然而目前广泛使用的组相对策略优化(GRPO)面临着熵崩溃的问题，即熵单调递减、探索性消失、策略过早收敛。现有的熵正则化方法虽部分缓解了这一问题，但引入了偏见和不稳定性，使得熵控制仍未得到解决，熵、探索性和性能之间的关系也未能阐明。", "innovation": "提出了任意熵策略优化(AEPO)方法，通过将熵奖金更换为温度调整后的分布上的REINFORCE策略梯度，并通过温度调节稳定熵，AEPO综合了三重设计：策略梯度、分布和REINFORCE作为正则化手段，实现了精准的熵控制而不扭曲优化。AEPO实现了如下贡献：（1）在任意目标水平稳定熵，有效消除GRPO中的熵崩溃；（2）揭示了非单调关系，即性能在熵增加时先提高后降低，阐明了熵、探索性和推理之间的联系；（3）超越熵的局限，为强化微调提供了一个更广泛的框架，其中优越的分布可以作为REINFORCE正则化器。", "conclusion": "AEPO通过采用REINFORCE策略梯度和温度调节，成功解决了熵崩溃问题，揭示了熵、探索性和性能之间的非单调关系，并提供了一种更广泛、更灵活的RFT范式，为提升LLM的推理能力提供了新的策略。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08396", "html_url": "https://arxiv.org/abs/2510.08396", "title": "FlyLoRA：通过隐式等级混合专家增强任务解耦和参数效率", "title_en": "FlyLoRA: Boosting Task Decoupling and Parameter Efficiency via Implicit Rank-Wise Mixture-of-Experts", "authors": "Heming Zou,Yunliang Zang,Wutong Xu,Yao Zhu,Xiangyang Ji", "background": "低秩适应（LoRA）是一种广泛使用的基础模型参数高效微调方法，但存在参数干扰问题，导致性能不佳。虽然基于Mixture-of-Experts（MoE）的LoRA变体在单任务指令微调中缓解了任务内部相关性方面表现出潜力，但在多任务模型合并中，任务间干扰依然存在，这些变体引入了额外的路由参数，并且仍然无效。", "innovation": "受苍蝇嗅觉电路启发，提出了一种名为FlyLoRA的隐式MoE LoRA变体，引入了（1）在上投影矩阵中的分级专家激活，和（2）隐式路由器，将专家路由和下投影统一起来。FlyLoRA通过冻结稀疏随机投影矩阵替代传统的密集可训练版本，消除了显式路由的需求，同时由于随机矩阵的正交性质，隐含消除了任务间干扰。FlyLoRA在四个领域——通用知识理解、科学问答、数学推理和代码生成中进行广泛实验，表明其在现有方法上的性能改进。FlyLoRA突显了生物结构如何启发AI技术的创新。", "conclusion": "广泛的实验证明，FlyLoRA 在涉及多个任务的模型集成中能够有效减少任务间干扰，并提高参数效率和任务解耦能力。通过结合受生物启发的设计，FlyLoRA 提高了基础模型的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12405", "html_url": "https://arxiv.org/abs/2510.12405", "title": "连续性唯一性和新颖性度量在无机晶体生成建模中的应用", "title_en": "Continuous Uniqueness and Novelty Metrics for Generative Modeling of Inorganic Crystals", "authors": "Masahiro Negishi,Hyunsoo Park,Kinga O. Mastej,Aron Walsh", "background": "随着气候变化等紧迫的科学挑战，研究人员正在开发越来越复杂的人工智能生成模型，这些模型能够高效地探索可能的功能材料的化学空间，快速生成新的化学组成及其晶体结构。然而，现有的唯一性和新颖性评估指标通常依赖于选择的晶体距离函数，而最常见的距离函数存在四个问题：无法量化物质之间的相似度、无法区分成分差异和结构差异、缺乏原子坐标平移的Lipschitz连续性，并且生成样本的唯一性度量不是不变的。", "innovation": "本文提出使用两个连续的距离函数来评估唯一性和新颖性，理论上能够克服上述四个限制。与传统距离函数相比，这些距离函数能揭示更多值得关注的细节，提供更可靠的依据来评估和比较生成模型对于无机晶体的使用效果。", "conclusion": "实验结果表明，新提出的连续距离函数能够更好地识别和评估生成的新颖性和独特性，提供了一种更可靠的方法来评估和比较生成模型在无机晶体模拟中的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.16300", "html_url": "https://arxiv.org/abs/2509.16300", "title": "ROOT: Rethinking Offline Optimization as Distributional Translation via Probabilistic Bridge", "title_en": "ROOT: Rethinking Offline Optimization as Distributional Translation via Probabilistic Bridge", "authors": "Manh Cuong Dao, TheHung Tran,Phi Le Nguyen,Thao Nguyen Truong,Trong Nghia Hoang", "background": "该论文研究黑盒优化任务，即使用已观察到的输入-输出对来寻找黑盒函数的最大值。这通常通过学习一种代理函数并在离线数据上优化来实现。此外，也可以将其视为逆向建模任务，将期望性能映射到能够实现该性能的潜在输入候选者。这两个方法都受限于离线数据的有限数量。论文提出了一种新视角，即将离线优化视为分布转换任务，目标是通过学习一种概率桥梁，将价值较低的输入隐式分布转换为价值较高的输入分布。这种概率桥梁可以通过从与目标函数类似的合成函数中采样低值和高值输入来进行学习。由于合成函数根据多组高斯过程拟合结果构建，这缓解了数据瓶颈问题。", "innovation": "论文引入了一种新的方法，即将离线优化任务重新定义为分布转换任务，并使用概率桥梁连接低价值输入分布和高价值输入分布。具体来说，这种方法利用了模拟函数构建，这些模拟函数是根据不同的参数化拟合多个高斯过程的结果，从而利用给出的离线数据来生成新的高价值输入，从而显著改善了黑盒优化问题的性能。这种方法通过广泛的基准测试对该方法的有效性进行了验证，并在多个最新方法中取得了显著提高的最佳结果。", "conclusion": "所提出的方法在广泛的基准测试中表现出显著改善，并且达到了最新技术的领先水平。该论文通过在分布转换视角下的研究，为离线优化问题提供了一种新的解决方式，不仅扩展了现有的研究边界，也为未来研究开启了新的方向。相关代码已经公开。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.13087", "html_url": "https://arxiv.org/abs/2510.13087", "title": "DeepCausalMMM：一种结合因果推断的深度学习市场营销组合模型框架", "title_en": "DeepCausalMMM: A Deep Learning Framework for Marketing Mix Modeling with Causal Inference", "authors": "Aditya Puttaparthi Tirumala", "background": "市场营销组合模型（Marketing Mix Modeling, MMM）是一种统计技术，用于估计市场营销活动对销售、收入或客户访问等业务成果的影响。传统的方法通常依赖线性回归或贝叶斯层次模型，这些方法假设各个营销渠道之间的独立性，难以捕捉复杂的时序动态和非线性的饱和效应。因此，需要一种能够综合深度学习、因果推断和现代市场营销科学的方法来改进现有的MMM模型。", "innovation": "DeepCausalMMM 是一个基于 Python 的包，通过结合深度学习、因果推断和高级市场营销科学来解决上述限制。该包使用门控递归单元（GRUs）自动学习时序模式（如广告延续效应和时间滞后），同时通过有向无环图（DAG）学习方法学习营销渠道之间的统计依赖性和潜在因果结构。此外，DeepCausalMMM 还通过 Hill 方程基于的饱和曲线来建模边际效益递减效应和优化预算分配。", "conclusion": "DeepCausalMMM 主要特色在于：数据驱动的设计，即超参数和转换（例如广告延续效应和饱和曲线）是从数据中学习或估计的，而不是需要固定的启发式规则或手动指定；支持多区域建模，可以有共享和区域特定参数；采用鲁棒的统计方法，包括 Huber 损失和高级正则化；提供了全面的响应曲线分析，以便了解渠道的饱和度。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.15382", "html_url": "https://arxiv.org/abs/2510.15382", "title": "向量稳健零样本强化学习", "title_en": "Towards Robust Zero-Shot Reinforcement Learning", "authors": "Kexin Zheng,Lauriane Teyssier,Yinan Zheng,Yu Luo,Xianyuan Zhan", "background": "近期，零样本强化学习（RL）的发展为学习能够以零样本方式适应任意新任务的通用政策开辟了一条新途径。虽然流行的正向-反向表示（FB）及其相关方法在零样本RL中展示了潜力，但在离线学习过程中，由于动作投射错误造成的跨分布（OOD）问题有时会导致表示偏差，从而影响最终表现。", "innovation": "本文提出了一种增强表达性的行为正则化零样本RL框架BREEZE，该框架同时提升了学习稳定性、政策提取能力和表示学习质量。BREEZE通过引入零样本RL政策训练中的行为正则化，将策略优化转化为一个稳定的样本内学习范式。此外，BREEZE利用一个任务条件下的扩散模型来提取政策，能够在零样本RL环境中生成高质量和多模态动作分布。BREEZE还使用了表达性的基于注意力的结构来建模表示，以捕捉环境动力学之间的复杂关系。", "conclusion": "通过在ExORL和D4RL厨房场景上的广泛实验，BREEZE实现了最优或接近最优性能，并且表现出了优于先前离线零样本RL方法的稳健性。相关的开源实现可在此处获取：this https URL."}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.14449", "html_url": "https://arxiv.org/abs/2510.14449", "title": "梯度下降优化和L1稀疏约束的一对多逻辑回归特征选择与正则化：一个多类分类的实证研究", "title_en": "Feature Selection and Regularization in Multi-Class Classification: An Empirical Study of One-vs-Rest Logistic Regression with Gradient Descent Optimization and L1 Sparsity Constraints", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel", "background": "多分类葡萄酒分类展示了模型准确性、特征维度和可解释性之间的重要权衡，这是在分析化学中实现生产部署的关键因素。本文探讨了在UCI Wine数据集（包含178个样本、3个品种和13个化学特征）上使用一对一逻辑回归的方法，对比了从零开始实现的梯度下降与scikit-learn优化求解器，并评估了L1正则化对特征稀疏性的影响。", "innovation": "文章详细地比较了手动实现的梯度下降与scikit-learn优化求解器之间的效率和准确性差异，验证了理论基础，并展示了L1正则化在降低特征数量的同时保持较高准确性的效果。还提出了一个最优的5个特征子集，可以通过减少成本和时间来实现高效部署，并通过统计验证确认了其在实际应用中的稳健泛化能力。", "conclusion": "实验结果表明，基于5个特征的子集可以通过降低成本、提供可解释性以及减少时间消耗来实现高效的部署。统计验证确认了该方法在实际应用中的实现实时质量控制所需的响应速度。文章提供了在资源受限环境中实现全面化学分析与目标特征测量之间平衡的实用指导。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16171", "html_url": "https://arxiv.org/abs/2510.16171", "title": "连接对称性与鲁棒性：特征不变性在提升对抗鲁棒性中的作用", "title_en": "Bridging Symmetry and Robustness: On the Role of Equivariance in Enhancing Adversarial Robustness", "authors": "Longwei Wang,Ifrat Ikhtear Uddin,KC Santosh,Chaowei Zhang,Xiao Qin,Yang Zhou", "background": "对抗样本通过利用深度神经网络对微不可感知输入扰动的敏感性揭示了其关键脆弱性。尽管对抗训练是主流的防御策略，但它通常需要大量的计算成本，并且可能会损害clean数据的准确性。", "innovation": "本文探讨了一种架构方法来增强对抗鲁棒性，通过将旋转和尺度不变卷积层嵌入到标准卷积神经网络（CNNs）中。这些层编码了对称先验，使模型行为与输入空间中的结构化变换保持一致，从而促进更平滑的决策边界和对抗攻击的更强韧性。本文提出并评估了两种对称性感知的架构：并行设计和级联设计。理论分析表明，这些模型可以减少假设空间的复杂性，规范化梯度，并在CLEVER（交叉Lipschitz极端值网络鲁棒性）框架下获得更严格的认证鲁棒性边界。实验结果表明，相比传统的对抗训练方法，本文的方法在CIFAR-10、CIFAR-100和CIFAR-10C上提高对抗鲁棒性和泛化能力，且无额外的对抗训练需求。", "conclusion": "本文的研究表明，具有对称性约束的架构可能是数据增强等防御策略的有效且有原则的替代方案。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.06213", "html_url": "https://arxiv.org/abs/2509.06213", "title": "基于复杂隐藏规则环境的强化学习标准构建：对象中心与特征中心表示策略", "title_en": "Toward a Metrology for Artificial Intelligence: Hidden-Rule Environments and Reinforcement Learning", "authors": "Christo Mathew,Wentian Wang,Jacob Feldman,Lazaros K. Gallos,Paul B. Kantor,Vladimir Menkov,Hao Wang", "background": "本文研究了强化学习在Game Of Hidden Rules （GOHR）环境中的应用，GOHR环境是一个复杂的谜题，其中智能体必须通过将游戏棋子放置在桶中来推断并执行隐藏规则来清除6×6的棋盘。我们探索了两种状态表示策略：特征中心(FC)和对象中心(OC)。我们采用基于Transformer的Advantage Actor-Critic (A2C) 算法进行训练。智能体只能获得部分观察信息，必须同时推断规则并从经验中学习最优策略。我们通过多个基于规则和基于列表的实验设置评估了我们的模型，分析了转移效应和表示形式对学习效率的影响。", "innovation": "本文的创新在于：1) 研究GOHR这一复杂隐藏规则环境下的强化学习问题；2) 探索特征中心和对象中心这两种不同的状态表示策略；3) 使用基于Transformer的Advantage Actor-Critic (A2C) 算法进行训练；4) 通过多个实验设置评估模型并分析转移效应和表示形式对学习效率的影响。", "conclusion": "通过实验，本文在复杂隐藏规则环境下评估了两种不同的状态表示策略，并且证实了在特定环境下对象中心表示可能更加有效。同时，基于Transformer的A2C算法也表现出了较好的学习性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03738", "html_url": "https://arxiv.org/abs/2509.03738", "title": "函数空间中的稀疏自编码器神经算子：模型恢复", "title_en": "Sparse Autoencoder Neural Operators: Model Recovery in Function Spaces", "authors": "Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar", "background": "尽管经典的Platonic Representation Hypothesis提出，神经网络在网络架构方面收敛于相似的表示，但大神经算子(NO)的表征属性尚未得到充分探索，尽管其在科学计算中的重要性不断提升。在研究过程中，对比了稀疏自编码器(SAEs)、提升的SAEs(lifted-SAE)以及SAE神经算子的推断和训练动态，识别了提升和算子模块带来的有益归纳偏差，能够加速表示恢复、提高平滑概念的恢复质量和抵抗不同分辨率的推断不一致性，后两者是神经算子的独有特性。", "innovation": "该研究将统一表示问题框架化为稀疏模型恢复的问题，并提出了将稀疏自编码器扩展到提升空间和无限维函数空间的框架，进而实现大神经算子的因果解释性。通过与标准的稀疏自编码器和稀疏自编码器神经算子的对比研究，展示了提升和算子模块引入了有益的归纳偏差，促进了表示的快速恢复、提升了对平滑概念的恢复效果，并且实现了在不同分辨率下更为稳健的推断结果，这是神经算子独特的优势。", "conclusion": "该研究表明通过提升稀疏自编码器的概念可以显著提高神经算子的表示恢复能力和对复杂概念的理解，特别在不同分辨率下的适应能力更强。这项工作不仅提供了理论上的新洞见，而且为未来开发高效率和高可信度的神经算子方法提供了重要的指导。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16807", "html_url": "https://arxiv.org/abs/2510.16807", "title": "通过第一层值头的跳连改进模型表示并减少KV缓存", "title_en": "Improving Model Representation and Reducing KV Cache via Skip Connections with First Value Heads", "authors": "Zhoutong Wu,Yuan Zhang,Yiming Dong,Chenheng Zhang,Cong Fang,Kun Yuan,Zhouchen Lin", "background": "Transformer模型在各种语言任务中取得了突破，主要是由于其强大的能力能够学习丰富的上下文表示。然而，为了改进表示，扩大Transformer模型往往需要大量内存和计算资源，例如自回归解码期间使用的Key-Value (KV) 缓存。尽管跳连结构被证明能够改善表示而不增加资源使用量，大部分先前的工作要么在保持KV成本不变的情况下提升模型的表达性，要么通过减少内存来牺牲表示强度。研究背景总结了在提高模型表示性能的同时如何有效减少KV缓存的需求。", "innovation": "本文提出了SkipV1Former，这是一种使用第一层值头的跳连变体，以增强模型表示并减少KV缓存。SkipV1Former从第二块开始，每层都重用第一层一半的值头，并用另一半进行常规计算，从而将值投影和V缓存减少了近一半。理论上，研究证明了路由未压缩的第一层值到更深的层可以恢复由压缩所丢失的信息，并加速模型的隐式表征优化——这是Transformer在自回归任务中的关键模式。实证结果显示，SkipV1Former在不同规模的模型上实现了相对于常规多头注意力（MHA）Transformer和一些变体约25％的KV缓存减少，同时提高了困惑度。此外，还提出了一种仅为10-15％额外计算的现有MHA Transformer检查点上转换为SkipV1Former的食谱。此外，SkipV1Former可以无缝结合如组查询注意和多潜在注意等高级方法，以实现进一步的KV缓存节省和性能提升。当与YOCO结合使用时，KV缓存大小减少了近50%，同时仍能提高性能。", "conclusion": "本文提出的SkipV1Former通过第一层值头的跳连有效减少了模型的KV缓存，同时保持了或改进了模型的表示性能和计算效率。此外，它还提供了一种简单有效的上转换现有MHA Transformer检查点的方法，并且能够与其他高级方法结合使用，以进一步提高KV缓存效率和模型性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17385", "html_url": "https://arxiv.org/abs/2510.17385", "title": "TabR1：用于表格推理的GRPO", "title_en": "TabR1: Taming GRPO for tabular reasoning LLMs", "authors": "Pengxiang Cai,Zihao Gao,Jintai Chen", "background": "传统上，表格预测依赖于梯度提升决策树和专门的深度学习模型，这些模型在特定任务上表现出色，但可解释性较差且跨表格迁移能力较弱。大型语言模型（LLMs）提供了跨任务的适应性和透明的推理轨迹，但它们在表格数据上的潜力尚未完全实现。TabR1是第一个专为表格预测的多步推理设计的推理LLM。其核心是Permutation Relative Policy Optimization (PRPO)，这是一种简单且高效的强化学习方法，它将列置换不变性作为结构先验进行编码。PRPO通过在样本内和样本间构建多个标签保持的置换来估计优势，从而将稀疏的奖励信号转化为密集的学习信号，提高了泛化能力。在少量监督下，PRPO可以激活LLMs的推理能力，增强少量和零样本性能，同时也提高了可解释性。实验表明，在全监督调优下，TabR1达到了与强大基线相近的性能。在零样本情境下，TabR1在32样本的情况下接近32个样本基线的性能。此外，TabR1在各种任务上显著优于大型LLM，相较于DeepSeek-R1（685B），性能提升了53.17%。", "innovation": "TabR1的核心是Permutation Relative Policy Optimization (PRPO)，这是一种简单且高效的强化学习方法，通过将列置换不变性作为结构先验进行编码，解决了可解释性和跨表格迁移能力的问题。PRPO通过在多个标签保持的置换中估计优势，将稀疏的奖励信号转化为密集的学习信号，从而提高了泛化能力。在少量监督下，TabR1能够激活LLMs的推理能力，增强少量和零样本性能，同时也提高了可解释性。", "conclusion": "TabR1在全监督调优下的性能与强大基线相近。在零样本情境下，TabR1在32个样本的情况下接近32个样本基线的性能。此外，TabR1在各种任务上显著优于大型LLM，相较于DeepSeek-R1（685B），性能提升了53.17%。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19266", "html_url": "https://arxiv.org/abs/2510.19266", "title": "通过注意力桥的数据高效任意Transformer到Mamba蒸馏", "title_en": "Data Efficient Any Transformer-to-Mamba Distillation via Attention Bridge", "authors": "Penghao Wang,Yuhao Zhou,Mengxuan Wu,Panpan Zhang,Zhangyang Wang,Kai Wang", "background": "状态空间模型（SSMs）已经成为序列建模中高效替代Transformer的选择，通过其递归结构实现了更好的扩展性。然而，它们的训练仍然非常昂贵，周围生态系统的成熟度远不如Transformer。此外，SSMs和Transformer在结构多样性方面的差异使从预训练注意力模型高效提取知识变得具有挑战性。", "innovation": "本文提出了注意力桥（Attention Bridge，AB）跨架构蒸馏（Cross-architecture distillation via Attention Bridge，CAB），这是一种新颖的数据高效蒸馏框架，它通过一个轻量级的桥和灵活的层间对齐，将Transformer教师模型的注意力知识高效转移到状态空间学生模型中。与传统的仅在输出层面传输知识的知识蒸馏不同，CAB支持针对字符层面的监督，同时提高了效率和可移植性。为了适应教师和学生之间架构的差异，本文还引入了灵活的层间对齐策略。", "conclusion": "广泛的实验表明，我们的方法在视觉和语言领域的一系列场景中能够一贯地提高状态空间模型的性能，即使在训练数据有限的情况下也优于标准和跨架构蒸馏方法。我们的研究结果表明，基于注意力的知识可以有效地转移到递归模型中，从而加速了Transformer专长的快速利用，推动了更强的SSM社区形成。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19705", "html_url": "https://arxiv.org/abs/2510.19705", "title": "通过分层推测性解码实现快速推断", "title_en": "Fast Inference via Hierarchical Speculative Decoding", "authors": "Clara Mohri,Haim Kaplan,Tal Schuster,Yishay Mansour,Amir Globerson", "background": "现有的Transformer语言模型在生成文本时采用自回归的方式，导致推理延迟与生成的字令牌数量成正比。推测性解码通过使用较小的草稿模型提出可能的字令牌，并由较大的目标模型并行验证，从而减少了延迟。然而，不同的草稿模型可能存在速度和准确性的权衡。", "innovation": "本文提出了分层推测性解码（HSD）算法，将不同的草稿模型组织成层次结构，每个模型自行提出并由较大模型验证，最终由目标模型进行最终验证。此外，作者还推导出了层次结构预期延迟的表达式，并证明选择最优延迟的层次结构可以在多项式时间内完成。实验结果表明，HSD相比最好的单一草稿基线提供了最多1.2倍的加速，证明了该算法在减少生成延迟方面具有实用性。", "conclusion": "分层推测性解码能够有效减少推理延迟，同时不影响文本生成质量，是减少较大语言模型推理时间的有效方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19507", "html_url": "https://arxiv.org/abs/2510.19507", "title": "将大语言模型组合以检测和缓解幻觉", "title_en": "Teaming LLMs to Detect and Mitigate Hallucinations", "authors": "Demian Till,John Smeaton,Peter Haubrick,Gouse Saheb,Florian Graef,David Berman", "background": "近期的研究展示了通过一致性方法检测和缓解大语言模型（LLM）幻觉的最新成果，这些方法涉及从单个LLM为给定提示获取的多个响应中进行聚合。这些方法有助于抵消训练LLM时 imperfect 数据带来的限制，例如偏差和信息不足等问题，这些问题可能导致幻觉。", "innovation": "本文展示了将单模型一致性方法扩展到结合具有不同训练数据、训练方案和模型架构的多个LLM响应，可以在超越单模型一致性方法的情况下进一步提高幻觉检测和缓解能力。评估了这种“联盟一致性”方法，并探讨了在什么条件下以这种方式组合不同的LLM是有益的。进一步展示这些性能提升通常伴随着推理成本的减少，从而抵消了单模型一致性方法的主要缺点。", "conclusion": "联盟一致性方法在多个LLM团队中表现出更好的性能，并且常常伴随着较低的推理成本，从而显著改进了幻觉检测和缓解能力。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18934", "html_url": "https://arxiv.org/abs/2510.18934", "title": "关于深度学习中许多泛化度量的脆弱性", "title_en": "Position: Many generalization measures for deep learning are fragile", "authors": "Shuofeng Zhang,Ard Louis", "background": "许多泛化度量已经被应用于深度神经网络（DNNs），尽管获取严谨的界限仍然具有挑战性，人们通常假设这些度量能够反映泛化的定性趋势。然而，这项观点论文指出，许多计算在训练后网络上的泛化度量（即，在训练后计算的度量）是非常脆弱的，即使是细微的训练修改也会大幅改变这些度量的值、趋势或缩放行为。例如，对学习率的调整或其他SGD变种的选择可以反转向来广泛使用的泛化度量（如路径范数）的学习曲线的斜率。文章还揭示了更微妙的脆弱性形式，比如PAC-Bayes起源度量被认为是可靠的，但在数据复杂性方面并不能捕捉到学习曲线之间的差异。这与基于函数的边际似然PAC-Bayes边界不同，后者确实能捕捉到数据复杂度的变化，包括缩放行为，但不是一个后验度量。尽管证明了很多边界（如路径范数、谱范数、Frobenius范数、平坦度代理和确定性PAC-Bayes代理）是脆弱的，文章还强调开发者应该显式地审计新度量的脆弱性。", "innovation": "研究者指出，许多在训练后网络上计算的泛化度量是非常脆弱的，即使是细微的训练修改也会大幅改变这些度量的值、趋势或缩放行为。文章不仅证明了很多常用的泛化度量（如路径范数、谱范数、Frobenius范数、平坦度代理和确定性PAC-Bayes代理）是脆弱的，还提出开发者应该显式地审计新度量的脆弱性。此外，文章引入了对PAC-Bayes起源度量和PAC-Bayes边界（基于函数的边际似然）的细化讨论，明确了它们在数据复杂性方面的区别，尽管它们表现出不同的脆弱性特征。", "conclusion": "本文主要强调，许多在训练后网络上计算的泛化度量是非常脆弱的，并提出了挑战现有泛化度量可靠性的观点。研究者认为，开发者在开发新的泛化度量时，应该显式地审计它们的脆弱性，以确保新度量的稳定性和可靠性。这种脆弱性不仅存在于常用的泛化度量中，还存在于诸如Path Norm、Spectral Norm、Frobenius Norm、Flatness Proxies和Deterministic PAC-Bayes Surrogates等度量中。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19338", "html_url": "https://arxiv.org/abs/2510.19338", "title": "每一种注意力都重要：为长上下文推理设计的高效混合架构", "title_en": "Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning", "authors": "Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou", "background": "该论文背景是介绍了Ring-linear模型系列，包括Ring-mini-linear-2.0和Ring-flash-linear-2.0。这些模型通过结合线性注意力和softmax注意力机制，显著降低了长上下文推理中的输入/输出和计算开销。与320亿参数的密集模型相比，这些模型将推理成本降低了10倍以上，并且与原始的Ring系列相比，成本也减少了近50%。此外，通过对混合架构中不同注意力机制的比例进行了系统性探索，确定了目前最优的模型结构。通过使用自主研发的高性能FP8操作库linghe，整体训练效率提高了50%。这种高度匹配的训练和推理引擎操作使得模型在强化学习阶段能够长时间保持高效和稳定的优化，而这种优化能够持续保持在多个复杂的推理基准上的SOTA性能。", "innovation": "本研究的创新点在于提出了一种高效的混合架构模型Ring-linear，该模型结合了线性注意力和softmax注意力，显著降低长上下文推理的I/O和计算开销。同时，通过优化不同注意力机制的比例并使用自研的高性能FP8操作库，进一步提高了训练效率，使模型在多种复杂推理任务中保持SOTA性能。此外，该模型在长期稳定优化方面表现突出，具有显著的成本效益。", "conclusion": "本系列模型在保持高性能的同时，极大地降低了计算和资源成本，通过高效的混合架构设计和性能优化，实现了长上下文推理任务的高效运行，尤其是在复杂推理基准中持续保持了SOTA的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19754", "html_url": "https://arxiv.org/abs/2510.19754", "title": "CONFEX: 带有置信区间保证的不确定性意识反事实解释", "title_en": "CONFEX: Uncertainty-Aware Counterfactual Explanations with Conformal Guarantees", "authors": "Aman Bilkhoo,Mehran Hosseini,Milad Kazemi,Nicola Paoletti", "background": "反事实解释（CFXs）为模型预测提供人类可理解的说明，有助于产生可行动的补救措施并提高解释性。为了可靠，CFXs 必须避免高预测不确定性区域，在这些区域中解释可能会误导或不适用。然而，现有方法通常忽视不确定性或缺乏能够将其纳入并提供正式保证的机制。对于这一问题，本文介绍了一种新的方法CONFEX，使用一致性预测（CP）和混合整数线性规划（MILP）生成具有不确定性意识的反事实解释，以提供局部覆盖保证并解决CFX生成违反可交换性的问题。通过一个基于树的输入空间分区的新型局部化一致性预测过程并利用线性整数编码方法，CONFEX生成的反事实解释具有严格保证的预测不确定性和最优性，提高了解释的可靠性和合理性。", "innovation": "CONFEX方法引入了结合了混合整数线性规划和一致性预测（Conformal Prediction, CP）的机制来生成具有明确的不确定性和最优性保证的反事实解释。这种方法不仅提供了局部覆盖的保证，还解决了CFX生成中违反可交换性的问题。通过利用空间分区技术，能够高效地编码和优化反事实解释的过程，从而确保解释的质量和可靠性。", "conclusion": "通过广泛的基准测试和评估，CONFEX方法展示出其不确定性意识的解释方式具有稳健性和可信度，相比现有最先进的算法方法，CONFEX在多维度指标下能够提供更加可靠和实际的反事实解释。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19755", "html_url": "https://arxiv.org/abs/2510.19755", "title": "关于扩散模型中缓存方法的综述：迈向高效的多模态生成", "title_en": "A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation", "authors": "Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang", "background": "扩散模型因其出色的生成质量和可控性已成为现代生成人工智能的核心。然而，它们固有的多步迭代和复杂的骨干网络导致了计算开销和生成延迟的显著增加，成为实时应用的主要瓶颈。尽管已经存在一些加速技术，但它们仍面临适用性有限、高训练成本或质量下降等挑战。背景总结了扩散模型的应用挑战及其现有的技术限制。", "innovation": "Diffusion Caching 提出了一种无需训练、架构独立且高效的推理范式。其核心机制在于识别和重用扩散过程中固有的计算冗余，通过在特征级别实现跨步骤和跨层重用，减少了计算量而不修改模型参数。此外，它还从静态重用来动态预测演变，增强了缓存的灵活性，并能够与采样优化和模型蒸馏等其他加速技术集成，为未来多模态和交互应用提供了一个统一高效的推理框架。创新点强调了Diffusion Caching的技术优势及其在未来的发展潜力。", "conclusion": "我们建议，这种范式将成为实现高效生成人工智能的关键使能器，为理论和实践中的高效生成智能注入新的活力。结论总结了Diffusion Caching在未来实时应用中的重要性及其对生成智能的新方向。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.09567", "html_url": "https://arxiv.org/abs/2406.09567", "title": "预测模型的因果后处理", "title_en": "Causal Post-Processing of Predictive Models", "authors": "Carlos Fernández-Loría,Yanfang Hou,Foster Provost,Jennifer Hill", "background": "组织越来越依赖预测模型来决定哪些对象应该被针对进行干预，例如营销活动、客户保留优惠或医疗治疗。然而，这些模型通常用于预测结果（如购买可能性或退出率），而非干预的实际影响。因此，它们产生的评分（预测值）往往是不完全可靠的资源分配指南。随机实验可以估计因果效应，但实验成本高、规模有限且与特定行动相关。我们提出了因果后处理（CPP），这是一种使用有限实验数据来细化预测模型输出的技术，使其更符合因果决策。", "innovation": "CPP 系列技术通过权衡灵活性和数据高效性，统一了现有方法并激发了新的方法。研究表明，在预测模型捕捉到一个有用但不完美的因果信号时，CPP 可以提高干预决策的效果。", "conclusion": "组织可以通过结合预测建模与实验证据来实现更有效和可扩展的干预决策。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.07715", "html_url": "https://arxiv.org/abs/2305.07715", "title": "残差网络中的最优信号传播场论", "title_en": "Field theory for optimal signal propagation in ResNets", "authors": "Kirsten Fischer,David Dahmen,Moritz Helias", "background": "研究表明，残差网络在深度较深的情况下，相较于前馈网络，其训练效果和性能更好，这主要得益于引入了跳跃连接，促进了信号向更深层的传递。先前的研究发现，在残差分支中增加缩放参数可以进一步提高泛化性能，尽管已经识别出这一参数的一个特别有效的范围，但其性能改进和跨网络超参数的普遍性尚未被明确理解。在此之前，对于前馈网络的研究已经通过有限尺寸理论对信号传播和超参数调优提供了重要的见解。", "innovation": "本文推导出了一种针对残差网络的系统有限尺寸场论，用来研究信号传播及其相对于残差分支缩放的依赖性。通过这种方法，本文得到了响应函数的解析表达式，这是一个衡量网络对输入敏感性的度量，并证明在深层网络中，实验发现的缩放参数值位于最大敏感性的范围内。此外，还得到了一个仅弱依赖于其他网络超参数（如权重方差）的最优缩放参数的解析表达式，从而解释了其在超参数上的普遍性。", "conclusion": "综上所述，本文提供了一个理论框架来研究有限尺寸下的残差网络。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2110.07583", "html_url": "https://arxiv.org/abs/2110.07583", "title": "通过流形凸性实现近最优样本复杂性：矩阵和张量正态模型", "title_en": "Near optimal sample complexity for matrix and tensor normal models via geodesic convexity", "authors": "Cole Franks,Rafael Oliveira,Akshay Ramachandran,Michael Walter", "background": "矩阵正态模型是一种用于建模矩阵变量数据的高斯矩阵变量分布族，其中协方差矩阵是两个低维因子的克罗内克积。张量正态模型将这一家族扩展到三个或更多因素的克罗内克积。本文研究了这些模型下协方差矩阵的克罗内克因子的估计问题。已有研究表明，在这些模型下，最大似然估计（MLE）几乎达到非渐近样本复杂度和近似精确误差率的最佳状态，这一结论不受因素条件良好或稀疏的约束，也不需要准确的初始猜测。对于矩阵正态模型，所有估计均达到对数因素的最小极大最优性；对于张量正态模型，估计协方差矩阵和最大因子时达到常数因子的最小极大最优性，前提是样本数量足够多，使任何估计方法都能获得常数范数误差。在样本复杂性相同范围下，文中还证明了一种实际过程广泛使用的迭代计算MLE的翻转算法，以高概率呈线性收敛。", "innovation": "本文主要技术洞察是，在样本数量足够的情况下，负对数似然函数在由Fisher信息度量诱导的正定矩阵几何结构上高度地理凸性。这种高度凸性由某些随机量子信道的展开决定。这项研究为矩阵和张量正态模型提供了近最优的样本复杂性，而不依赖于因素的条件良好性或稀疏性，且不需要初始猜测的准确性。", "conclusion": "研究结果表明，在满足特定样本复杂性条件的情况下，最大似然估计和翻转算法能实现较高的估计精确性和收敛性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.11666", "html_url": "https://arxiv.org/abs/2406.11666", "title": "ROTI-GCV: 广义交叉验证方法用于右旋不变数据", "title_en": "ROTI-GCV: Generalized Cross-Validation for right-ROTationally Invariant Data", "authors": "Kevin Luo,Yufan Li,Pragya Sur", "background": "在高维正则化回归中，关键任务包括调整正则化强度以获得准确的预测以及估计未样本风险。传统的 $k$ 折交叉验证在现代高维设置下是不一致的。留一交叉验证和广义交叉验证在某些高维情况下是保持一致的，但在样本相关或包含重尾协变量时则会失效。为了建模样本的结构依赖和重尾分布，本文采用右旋转不变协变量分布的概念，这是一种从压缩感知领域引入的重要概念。在特征数和样本数以相同比例增长的分比例渐近情形下，引入了新的框架——ROTI-GCV，以在这些具有挑战性的情况下可靠地进行交叉验证。在此过程中，还提出了信号与噪声比的新估计器以及噪声方差的新估计器。实验结果表明，在不同合成和半合成设置中，该方法的准确性很高。", "innovation": "提出了ROTI-GCV框架，这是一个新的框架，可以在特征和样本数量以相同比例增长的分比例渐近情形下可靠地进行交叉验证。引入了右旋转不变协变量分布的概念，并提出了信号与噪声比的新估计器以及噪声方差的新估计器。", "conclusion": "实验结果证明了该方法在各种合成和半合成设置中的准确性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.05854", "html_url": "https://arxiv.org/abs/2408.05854", "title": "关于内核拟合优度检验的鲁棒性", "title_en": "On the Robustness of Kernel Goodness-of-Fit Tests", "authors": "Xing Liu,François-Xavier Briol", "background": "拟合优度检验经常因为缺乏实际意义而受到批评，因为所有的模型都含有错误，因此随着样本量的增长，模型完全符合数据的零假设最终总会被拒绝。尽管如此，概率模型仍然被广泛使用，更具相关性的问题是模型是否“足够好”以满足任务需求。将此问题形式化，作为鲁棒性检验问题，即检查数据是否来自与模型仅为轻微扰动的分布。现有内核拟合优度检验方法在普遍鲁棒性概念下不具备鲁棒性，包括定性鲁棒性和定量鲁棒性。倾斜内核的稳健化技术虽然在参数估计文献中有效，但在检验场景下却无法同时确保两种鲁棒性。", "innovation": "提出了第一个鲁棒内核拟合优度检验方法，通过利用内核Stein差异(KSD)球来解决这一开放问题，该框架涵盖了包括Huber污染和密度带模型在内的许多广为人知的扰动模型，从而解决了现有内核拟合优度检验方法在鲁棒性方面的不足。", "conclusion": "研究表明，现有的内核拟合优度检验方法既不满足定性鲁棒性和定量鲁棒性，现有的倾斜内核稳健化技术也不适用于检验场景。为了填补这一空白，作者提出了一个新的鲁棒性概念，运用内核Stein差异(KSD)球来构建鲁棒内核拟合优度检验方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.14144", "html_url": "https://arxiv.org/abs/2406.14144", "title": "从安全神经元的机制角度来看理解安全性对齐", "title_en": "Towards Understanding Safety Alignment: A Mechanistic Perspective from Safety Neurons", "authors": "Jianhui Chen,Xiaozhi Wang,Zijun Yao,Yushi Bai,Lei Hou,Juanzi Li", "background": "大语言模型（LLMs）在各种能力方面表现出色，但同时也带来了安全风险，如生成有害内容和虚假信息等。即使经过安全性对齐，这些风险依然存在。本文通过机制可解释性来探索安全对齐的内在机制，重点关注识别和分析对安全行为负责的安全神经元，并提出推理时激活对比方法来定位这些神经元，并通过动态激活补丁来评估它们的因果效应对模型安全性的影响。实验表明，可以通过仅修补这些神经元的激活来恢复超过90%的安全性能，而不会影响一般能力。这一发现也揭示了安全性「对齐税」现象，即负责模型安全性和有用性的关键神经元有显著重叠，但它们需要不同的激活模式以实现相同的神经元作用。", "innovation": "研究通过机制可解释性视角探讨了安全对齐机制，提出了推理时激活对比方法来识别安全神经元，并通过动态激活补丁评估其对安全的影响，实验结果表明可以显著提升模型安全性。研究发现还解释了「对齐税」现象，揭示了安全性和有用性的重叠以及不同的激活模式需求。", "conclusion": "本文通过识别和评估安全神经元，展示了在生成前检测不安全输出的应用，仅通过修补激活即可恢复超过90%的安全性，且不影响模型的一般能力。研究结果不仅提升了大语言模型的安全性，也进一步解释了「对齐税」现象。相关源代码可通过提供的链接获取。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.14621", "html_url": "https://arxiv.org/abs/2410.14621", "title": "JAMUN: 借助平滑分子动力学和得分学习桥接构象集合", "title_en": "JAMUN: Bridging Smoothed Molecular Dynamics and Score-Based Learning for Conformational Ensembles", "authors": "Ameya Daigavane,Bodhi P. Vani,Darcy Davidson,Saeed Saremi,Joshua Rackers,Joseph Kleinhenz", "background": "蛋白质构象组合在理解蛋白质功能和新药发现方面（如隐秘口袋）非常重要。当前的技术如分子动力学（MD）采样构象组合在计算上效率低下，而许多最近的机器学习方法不能转移到训练数据以外的系统。", "innovation": "JAMUN利用走-跳跃采样框架在所有原子3D构象的平滑噪声空间中进行MD，从而能够以比传统分子动力学快几个数量级的速度生成小肽的构象组合。JAMUN中的物理先验使模型能够在训练数据之外的系统（甚至更长的肽）上实现迁移。", "conclusion": "JAMUN模型、代码和权重可在给定链接中获取，它显著提升了构象组合的生成速度和跨系统迁移能力。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.16892", "html_url": "https://arxiv.org/abs/2408.16892", "title": "Tex-ViT：一种通用、鲁棒的基于纹理的双分支交叉注意深伪检测器", "title_en": "Tex-ViT: A Generalizable, Robust, Texture-based dual-branch cross-attention deepfake detector", "authors": "Deepak Dagar,Dinesh Kumar Vishwakarma", "background": "深伪技术通过生成高度逼真的面部修改而被广泛视为主流方法。传统卷积神经网络能够识别虚假媒体，但在不同数据集上的表现较差，且容易受到对抗性攻击的影响，缺乏鲁棒性。尽管视觉变换器在图像分类问题上具有潜力，但需要充足的训练数据。鉴于这些限制，本文提出了一种结合ResNet和视觉变换器的模型——Tex-ViT，通过在ResNet特征图之前并行处理纹理模块，增强了CNN特征，专注于提高全局纹理模块的功能，以提取特征图的相关性。实验结果表明，假图像在操纵过程中表现出平滑的纹理特征，但在长时间跨度上不一致。实验结果证实了该模型在多种数据集和各种预处理情况下的鲁棒性和泛化能力，特别是在跨域场景中达到了98%的准确率，表明其能够学习伪造样本中的共享区别性纹理特征，适用于多种情况并能抵御多种后处理程序。", "innovation": "提出了一种结合ResNet和视觉变换器的模型——Tex-ViT，通过在ResNet特征图之前并行处理纹理模块，增强了CNN特征。该模型专注于改进全局纹理模块，以提取特征图的相关性。实验结果显示，该模型在跨域场景中的泛化性能显著优于现有模型，能够捕捉共享区别性纹理特征，并且对多种后处理程序具有鲁棒性。", "conclusion": "Tex-ViT在跨域场景中实现了98%的准确率，证明了其在识别深伪中的能力和对各种数据集以及后处理情况的鲁棒性。该模型展示了区分纹理特征的学习能力，并在多种情况下具有广泛的应用潜力。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.05500", "html_url": "https://arxiv.org/abs/2410.05500", "title": "增强深度学习的剩余柯尔莫哥洛夫-阿诺尔德网络", "title_en": "Residual Kolmogorov-Arnold Network for Enhanced Deep Learning", "authors": "Ray Congrui Yu,Sherry Wu,Jiang Gui", "background": "尽管深度卷积神经网络（CNNs）在许多任务上取得了巨大成功，但由于网络深度中的数百层，这些网络往往难以优化且训练成本高昂。传统的卷积操作基于它们的线性和固定激活方式，在数据中学习有意义的模式需要许多层。这些网络的巨大规模使得这种方法在计算上效率低下，尤其是在小数据集上，这还会带来过拟合或梯度爆炸的风险。因此，我们介绍了“插件”模块，称为余项柯尔莫哥洛夫-阿诺尔德网络（RKAN）。", "innovation": "RKAN模块非常紧凑，可以轻松嵌入传统深度网络的任何阶段（级别），它被设计用来学习整合支持的多项式特征转换到现有的卷积框架中。在不同的视觉任务和广泛测试的基准测试中，RKAN在基线模型上带来了持续的改进，并达到了顶尖的性能。", "conclusion": "RKAN通过提供在不同视觉任务中的一致改进，并在广泛测试的基准测试中实现顶尖性能，证明了其在改善深度学习任务效率和效果方面的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.00538", "html_url": "https://arxiv.org/abs/2412.00538", "title": "动态任务严重程度下机械臂预知性框架", "title_en": "Prognostic Framework for Robotic Manipulators Operating Under Dynamic Task Severities", "authors": "Ayush Mohanty,Jason Dekarske,Stephen K. Robinson,Sanjay Joshi,Nagi Gebraeel", "background": "机器人操作器在许多应用中至关重要，但随着时间的推移会退化。退化的过程受机器人执行任务的性质影响。高严重性任务，如搬运重载荷，会加速退化进程。退化的一个表现是在机器人末端执行器的位置精度降低。", "innovation": "本文提出了一种预测机械臂剩余有用寿命(RUL)的预知性建模框架，该框架考虑了任务严重性的影响。通过将机器人位置精度表示为具有由任务严重性影响的随机漂移参数的布朗运动过程，并使用连续时间马尔可夫链(CTMC)建模任务严重性的动态性。文中讨论了两种评估RUL的方法——新颖的残余寿命分布(RLD)的封闭式表达式和蒙特卡洛模拟，从而建立了这两种RUL计算方法之间的等效性。实验使用了两种不同物理基础的模拟器验证了框架的有效性。", "conclusion": "结果显示，在两类机器人队列中，处理更高比例的高严重性任务会导致更短的RUL。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18469", "html_url": "https://arxiv.org/abs/2410.18469", "title": "迭代自调优LLM以增强越狱能力", "title_en": "Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities", "authors": "Chung-En Sun,Xiaodong Liu,Weiwei Yang,Tsui-Wei Weng,Hao Cheng,Aidan San,Michel Galley,Jianfeng Gao", "background": "近期研究显示，大型语言模型（LLMs）易受自动化越狱攻击，即通过算法生成的危害性查询后面的对抗后缀绕过安全校准，触发意外响应。当前生成这些后缀的方法计算成本高且成功率低（ASR低），尤其对如Llama2和Llama3这类校准良好的模型效果不佳。因此，现有的方法存在一些局限性，需要改进以提升其效果和效率。", "innovation": "本文提出了ADV-LLM，一种迭代自调优过程，能够生成具有增强越狱能力的对抗性LLM。该框架大幅降低了生成对抗后缀的计算成本，并在各种开源LLM上实现了近100%的成功率。此外，ADV-LLM在闭源模型中也展现出强大的攻击可移植性，在GPT-3.5上达到了99%的成功率，GPT-4为49%，而仅在Llama3上进行了优化。通过提供用于研究LLM安全的大规模数据集，ADV-LLM为未来的安全校准研究提供了重要的见解和工具。", "conclusion": "本文介绍的ADV-LLM框架显著降低了对抗后缀生成的计算成本，并在多种LLM上实现了极高的攻击成功率。此外，该框架在闭源模型上的可移植性也得到了验证。这项工作不仅提高了LLM的越狱能力，同时也为未来研究LLM的安全性提供了有价值的数据集和方法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.08457", "html_url": "https://arxiv.org/abs/2410.08457", "title": "Unity is Power: Semi-Asynchronous Collaborative Training of Large-Scale Models with Structured Pruning in Resource-Limited Clients", "title_en": "Unity is Power: Semi-Asynchronous Collaborative Training of Large-Scale Models with Structured Pruning in Resource-Limited Clients", "authors": "Yan Li,Xiao Zhang,Mingyi Li,Guangwei Xu,Feng Chen,Yuan Yuan,Yifei Zou,Mengying Zhao,Jianbo Lu,Dongxiao Yu", "background": "本文研究了如何利用大规模异构弱计算能力，在分散的数据集上共同训练大规模模型。为了解决资源适应性共同学习在效率和准确性上的问题，本文考虑了未结构化剪枝、可变子模型架构、知识损失和节点失效等挑战，提出了一种半异步协同训练框架，名为Co-S2P，并提供了该框架可以实现渐近最佳收敛速率为O(1/√(N*EQ))的理论证明。", "innovation": "本文创新性地提出了名为Co-S2P的半异步协同训练框架。该框架包括数据分布感知的结构化剪枝和跨块的知识转移机制，旨在同时解决未结构化剪枝、可变子模型架构、知识损失和节点失效等挑战。此外，该框架还证明了可实现渐近最佳的收敛速率}", "conclusion": "通过在真实硬件测试床上进行的广泛实验表明，与现有最佳方法相比，Co-S2P可以在所有资源受限设备上提高多达8.8％的准确性和高达1.2倍的资源利用率，同时减少约22％的内存消耗和约24％的训练时间。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.00565", "html_url": "https://arxiv.org/abs/2501.00565", "title": "低维空间中通过反向扩散实现多项式查询复杂度的多模态分布采样", "title_en": "Sampling from multi-modal distributions with polynomial query complexity in fixed dimension via reverse diffusion", "authors": "Adrien Vacher,Omar Chehab,Anna Korba", "background": "即使是低维空间内，从多模态分布中进行采样也是一项具有挑战性的任务。目前对于各种类型的多模态分布采样算法，其查询复杂度通常较高，无法提供有效的多项式时间复杂度。尽管已有的采样方法有所改善，但它们往往依赖于预先知道模态位置的信息，或者需要满足特定条件（如log平滑性假设），这排除了一些常见的分布类型，如一般的高斯混合分布，使得这些方法在应用上受到限制。本文旨在通过引入一种新的反向扩散过程来解决这些问题，提出了一个查询复杂度为多项式的采样算法，适用于包括所有高斯混合在内的广泛分布类别，并且不要求对模态位置有先验知识。", "innovation": "本文的主要创新在于提出了一种新的采样算法，该算法通过模拟时间反转的扩散过程来进行采样，并通过自规范化蒙特卡洛估计器来估计中间得分函数。这项创新避免了模态的不稳定性，不需要预先知道模态位置，并且废除了对log平滑性假设的要求。这使得新的采样方法能够有效处理以前难以处理的高斯混合等广义分布。", "conclusion": "本文提供的采样算法能够为多个广泛分布类别提供多项式查询复杂度的采样方式，在低维空间内显著提升了采样的效率和适用性，减轻了先前方法的局限性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03297", "html_url": "https://arxiv.org/abs/2502.03297", "title": "IRIS: 具有沉浸式交互功能的机器人系统", "title_en": "IRIS: An Immersive Robot Interaction System", "authors": "Xinkai Jiang,Qihao Yuan,Enes Ulas Dincer,Hongyi Zhou,Ge Li,Xueyin Li,Xiaogang Jia,Timo Schnizer,Nicolas Schreiber,Weiran Liao,Julius Haag,Kailai Li,Gerhard Neumann,Rudolf Lioutikov", "background": "现有的基于扩展现实（XR）的数据收集系统虽然高效，但往往难以复现和重用，主要是因为它们需要特定的机器人、物体、模拟器和环境支持。", "innovation": "IRIS通过支持跨不同模拟器和现实世界场景的沉浸式交互和数据收集，解决了这些难题。它能够可视化任意刚性或变形物体，模拟中的机器人，并集成实时传感器生成的点云数据，适用于实际应用。此外，IRIS还增强了协作能力，允许多个用户在同一虚拟场景中同时进行交互。", "conclusion": "IRIS在模拟和现实世界中均能提供高效直观的数据收集。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.18897", "html_url": "https://arxiv.org/abs/2501.18897", "title": "生成模型比较中的统计推断", "title_en": "Statistical Inference for Generative Model Comparison", "authors": "Zijun Gao,Yan Sun,Han Su", "background": "生成模型在各种应用中取得了显著的成功，但它们的评估依然缺乏基本原则性的不确定性量化。本文旨在开发一种方法来比较不同生成模型与测试样本基础分布的接近程度。方法使用Kullback-Leibler（KL）散度来衡量生成模型与未知测试分布之间的距离，因为KL散度不需要像RKHS基距一样进行参数调整，且它是唯一可以实现关键消减的f-散度，从而使得不确定性量化成为可能。此外，该方法还被扩展应用于比较条件生成模型，并利用Edgeworth展开式来解决有限数据的问题。在具有已知真实值的模拟数据集中，研究发现该方法实现了有效的覆盖率，并且在处理能力上优于基于核的方法。应用于图像和文本数据集的生成模型时，该过程得出的结论与基准度量一致，但具有统计置信度。", "innovation": "本文提出了一种使用Kullback-Leibler（KL）散度的方法来比较不同生成模型与未知测试分布之间的距离，此方法利用了KL散度无需调参的特点且是唯一一种适用于不确定性量化并可实现关键消减的f-散度，该方法还扩展应用于条件生成模型的比较和有限数据情况的解决。", "conclusion": "在已知真实值的模拟数据集上，该方法实现了有效的覆盖率，并且在处理能力上优于基于核的方法。在图像和文本数据集的生成模型应用中，该过程得出的结论与基准度量一致，但具有统计置信度。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06753", "html_url": "https://arxiv.org/abs/2502.06753", "title": "SMRS：在人工智能时代倡导统一的代理模型报告标准", "title_en": "SMRS: advocating a unified reporting standard for surrogate models in the artificial intelligence era", "authors": "Elizaveta Semenova,Alisa Sheinkman,Timothy James Hitge,Siobhan Mackenzie Hall,Jon Cockayne", "background": "代理模型在科学和工程中被广泛用于近似复杂系统，以降低计算成本。尽管它们被广泛应用，但在建模管道的关键阶段，如数据采样、模型选择、评估和下游分析，缺乏标准。这种缺乏标准导致了复现性和跨领域应用的限制。随着人工智能驱动的代理模型的迅速普及，这一挑战变得更加突出。", "innovation": "该论文提出了一项重要的创新——制定一个结构化的报告标准，即Surrogate Model Reporting Standard (SMRS)，该标准系统地捕捉到关键的设计和评估选择，同时对实现细节保持中立。通过推动一个标准化但灵活的框架，作者旨在提高代理建模的可靠性，促进跨学科的知识转移，并最终在人工智能时代加速科学发展。", "conclusion": "通过制定SMRS标准，作者希望改善代理建模的可靠性，促进跨学科知识的转移，最终在AI时代加速科学进步。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06536", "html_url": "https://arxiv.org/abs/2502.06536", "title": "从数据到概念的高效学习：无需干预的理论保证", "title_en": "Sample-efficient Learning of Concepts with Theoretical Guarantees: from Data to Concepts without Interventions", "authors": "Hidde Fokkema,Tim van Erven,Sara Magliacane", "background": "机器学习在许多实际系统中起着至关重要的作用，但人们对黑盒AI系统的可解释性、透明度和鲁棒性仍存在一些担忧。概念瓶颈模型（CBM）通过从高维数据（如图像）中学习可解释的概念来解决这些问题，进而预测标签。然而，概念之间的虚假相关问题在CBM中是一个重要问题，会导致学习了“错误”的概念。当前的缓解策略都具有较强的假设条件，需要统计独立性假设或要求大量的干预和标签提供。本文探讨了一种新的框架，旨在解决这些问题。", "innovation": "本文提出了一个框架，该框架可以在无需任何干预的情况下提供关于所学概念正确性的理论保证，并在数据标签有限的情况下解决这一问题。该框架利用因果表征学习（CRL）方法从高维观察中学习潜在因果变量，然后用少量的概念标签将这些变量与可解释的概念对齐。文中提出了一种线性和非参数估计器来实现这种映射，并通过合成数据和图像基准测试验证了此方法的效果。", "conclusion": "通过本文的方法，所学的概念具有更少的杂质且在某些情况下比其他CBM更准确，即使在概念之间存在强相关性的情况下也是如此。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05094", "html_url": "https://arxiv.org/abs/2502.05094", "title": "非线性蒙特卡洛问题的量子加速", "title_en": "Quantum speedup of non-linear Monte Carlo problems", "authors": "Jose Blanchet,Yassine Hamoudi,Mario Szegedy,Guanyang Wang", "background": "随机变量的期望值可被视为概率分布空间上的线性泛函。量子计算已知能够比经典蒙特卡罗方法在均值估计上提供二次加速。本文研究了是否可以实现类似的二次加速来进行非线性概率分布函数的估计。文章提出了一个适用于广义非线性估计问题的量子内部量子蒙特卡罗算法，该算法包括嵌套条件期望和随机优化问题，并改进了An等（2021年）提出的量子多级蒙特卡罗算法。现有的下界表明，该算法在多项对数因子上最优。关键创新在于为量子计算设计的一种新的多级蒙特卡罗近似序列，对算法改善性能至关重要。", "innovation": "提出了一种适用于广义非线性估计问题的量子内部量子蒙特卡罗算法，特别是设计了一种新的多级蒙特卡罗近似序列，该序列对算法的改善性能至关重要，相比之前的量子多级蒙特卡罗算法，该算法解决了更广泛的非线性估计问题，这也表明算法在多项对数因子上的优化效果最佳。", "conclusion": "该算法克服了直接应用An等（2021年）提出的量子多级蒙特卡罗算法的局限，使其能够在多项对数因子上实现最优的二次加速，实现了对包括嵌套条件期望和随机优化等广义非线性估计问题的量子加速。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.00470", "html_url": "https://arxiv.org/abs/2502.00470", "title": "CoCoA 是 ADMM：在这两个分布式优化范式中统一两个方法", "title_en": "CoCoA Is ADMM: Unifying Two Paradigms in Distributed Optimization", "authors": "Runxiong Wu,Dong Liu,Xueqin Wang,Andi Wang", "background": "本文探讨了分布式环境下一般经验风险最小化问题中的对偶算法。重点研究了两个关键类别的算法：基于坐标上升法的通信效率分布式双坐标上升（CoCoA）算法，和交替方向乘子法（ADMM），包括共识ADMM、近端ADMM和线性化ADMM。作者发现这两类算法可以统一到一个只涉及原始变量和对偶变量的更新形式。这一发现揭示了这两种类算法之间的关键联系：CoCoA 可以被解释为解决对偶问题时的近端ADMM的特殊情况，而共识ADMM等同于一个近端ADMM算法。这些发现提供了如何通过调整增广拉格朗日参数轻松使ADMM变体超越CoCoA变体的方法。进一步地，作者还探讨了ADMM变体的线性化版本，并分析在分布式设置中调整参数对这些ADMM变体的影响。广泛的仿真实验和真实数据的分析支持了理论发现。", "innovation": "作者证明了两大类算法可以统一为一种只涉及原始和对偶变量的更新形式，揭示了CoCoA和ADMM之间的密切关系。特别地，CoCoA可以被视为近端ADMM的一个特殊情况，而共识ADMM等同于一个近端ADMM算法。这一发现提供了一种方法来使ADMM变体超越CoCoA变体，只需调整增广拉格朗日乘子参数。此外，作者还探索了ADMM变体的线性化版本，并分析了在分布式设置中调整参数的影响。", "conclusion": "研究结果证实了在分布式优化背景下，CoCoA和ADMM这两类算法之间存在密切关系。通过简单调整增广拉格朗日参数，ADMM的变体可以优于CoCoA的变体。此外，对线性化ADMM变体的分析和参数对这些变体影响的探索为实际应用中的优化提供了坚实的基础。通过广泛的仿真实验和真实数据的分析，证实了理论发现的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18162", "html_url": "https://arxiv.org/abs/2410.18162", "title": "高维空间中多峰值张量PCA的随机梯度下降", "title_en": "Stochastic gradient descent in high dimensions for multi-spiked tensor PCA", "authors": "Gérard Ben Arous,Cédric Gerbelot,Vanessa Piccolo", "background": "该研究讨论了多峰值张量模型下在线随机梯度下降（SGD）的高维动力学。多索引模型源于带有多个峰值的张量主成分分析（PCA）问题，目标是从噪声观测中的p-张量中通过最大似然估计来估计N维单位球内的r个未知信号向量。研究确定了从自然随机初始化有效恢复未知峰值所需的样本数量和信噪比（SNR）条件。研究展示了在样本数量按N^(p-2)缩放时，所有峰值都能被完全恢复，这与单一索引情况下识别的算法阈值相符。通过详细分析描述估计器与峰值间关联演变的低维系统，控制噪声在动态中的影响来获得结果。研究发现峰值是通过“顺序消除”过程被逐步恢复的，这意味着一旦某个关联超出临界阈值，共用行或列索引的其它关联变得足够小，从而允许下一个关联增长并成为宏观量。关联转变为宏观量的顺序取决于它们的初始值和相应的SNR，从而导致完全恢复或峰值的某种排列恢复。在矩阵情况下，当p=2时，如果SNR足够分开，则可实现峰值的完全恢复，同时SNR相等则仅恢复它们所张成的子空间。", "innovation": "该研究创新性地分析了高维多重峰值张量PCAP的随机梯度下降动态，并展示了在适当条件下可以完全恢复所有峰值，这一结论与单一索引情况下的算法阈值相匹配。通过低维系统的详细分析来控制噪声在动态中的影响，并提出了“顺序消除”过程来解释峰值恢复的机制。此外，还探讨了在不同SNR情况下恢复的差异性结果，为进一步理解高维张量PCA提供了新的视角。", "conclusion": "研究证明了在适当数量的样本和SNR条件下，可以使用在线SGD有效地恢复多重峰值张量PCAP中的未知峰值。发现“顺序消除”过程在峰值恢复中起到了关键作用，揭示了恢复顺序受初始步骤和SNR影响的过程机制。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08416", "html_url": "https://arxiv.org/abs/2502.08416", "title": "Multifidelity Simulation-based Inference for Computationally Expensive Simulators", "title_en": "Multifidelity Simulation-based Inference for Computationally Expensive Simulators", "authors": "Anastasia N. Krouglova,Hayden R. Johnson,Basile Confavreux,Michael Deistler,Pedro J. Gonçalves", "background": "在许多科学领域中，随机模型是理解与实证观测数据相符的机制的重要工具。模型可以有不同的详细程度和准确性，高保真模型（即，高准确性）通常更受青睐。然而，通过基于模拟的推断来反推高保真模型的参数是具有挑战性的，尤其是当模拟器计算成本高时。现有方法难以在保证准确性的同时有效地利用廉价的低保真模拟数据来反推高保真模拟器的参数。", "innovation": "本文引入了MF-(TS)NPE方法，这是一种利用转移学习结合廉价低保真模拟以高效反推高保真模拟器参数的多保真方法。MF-(TS)NPE不仅在常模和非常模神经后验估计中应用了多保真方案，还通过引入A-MF-TSNPE方法进一步提高了仿真效率，该方法使用一个针对密度估计预测不确定性目标的获取函数选择高保真参数。测试表明，本文提出的方法比当前方法所需的高保真模拟次数少了一个或两个数量级，且性能相当。这为昂贵的计算模拟器上高效贝叶斯推断提供了新的可能性。", "conclusion": "本文提出的方法为昂贵的计算模拟器上高效贝叶斯推断提供了新的可能性。在基准测试和神经科学任务中，使用本文提出的方法仅需当前方法的高保真模拟次数的一小部分即可实现相似的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.13085", "html_url": "https://arxiv.org/abs/2502.13085", "title": "一种神经熵差估计器用于互信息估计", "title_en": "A Neural Difference-of-Entropies Estimator for Mutual Information", "authors": "Haoran Ni,Martin Lotz", "background": "在高维情况下，准确估计互信息（MI），衡量随机量之间依赖性的关键指标，是一个具有挑战性的任务，因为需要避免特定的建模假设。本文讨论了使用归一化流参数化条件密度以利用块自回归结构在标准基准任务中实现更好的偏差-方差折衷的问题背景。", "innovation": "本文提出了基于归一化流参数化条件密度的新型互信息估计器，归一化流作为一种近年来广受欢迎的生成模型，利用块自回归结构在标准基准任务中获得更好的偏差-方差折衷，这是论文的创新点。", "conclusion": "本文提出的互信息估计方法通过利用归一化流和块自回归结构，能在高维情况下更准确地估计互信息，提升了偏差-方差折衷。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.19634", "html_url": "https://arxiv.org/abs/2412.19634", "title": "深度连续时间状态空间模型在标记事件序列中的应用", "title_en": "Deep Continuous-Time State-Space Models for Marked Event Sequences", "authors": "Yuxin Chang,Alex Boyd,Cao Xiao,Taha Kass-Hout,Parminder Bhatia,Padhraic Smyth,Andrew Warrington", "background": "标记时间点过程（MTPPs）模型用于描绘不规则时间间隔发生的事件序列，广泛应用于医疗、金融和社会网络等领域。现有的MTPP模型存在一些限制，而深度状态空间模型（SSMs）提供了新的工具来克服这些限制。本文基于经典的线性霍克斯过程构造了一个新的模型，旨在解决这些限制问题并在连续时间事件序列的表达能力上超越现有离散序列模型（如RNN和变压器）.", "innovation": "本文提出了状态空间点过程（S2P2）模型。该模型融合了现代深度SSMs的技术，同时为连续时间事件序列提供了强诱导偏置，这些偏置是其他离散序列模型无法捕捉的。S2P2模型使用随机跳跃微分方程和非线性操作创建了一个高强度的基础MTPP模型，没有严格的强度参数假设。这种架构使训练和推理通过并行扫描实现高效，保持了线性复杂度并实现了次线性缩放，同时保持了MTPPs的表达能力。实验证明，S2P2在八个实际数据集上的预测似然度达到了最先进的性能，平均提高了33%。", "conclusion": "本文提出了S2P2模型，并展示了其在预测MTPPs性能上的优越性，尤其是在多个实际数据集上表现出了显著优于现有方法的结果。该模型通过高效的并行推理，保持了模型的表达性，并在连续时间事件序列建模方面做出了创新贡献。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17213", "html_url": "https://arxiv.org/abs/2502.17213", "title": "深度学习驱动的电脑信号分析：推动神经诊断的进步", "title_en": "Deep Learning-Powered Electrical Brain Signals Analysis: Advancing Neurological Diagnostics", "authors": "Jiahe Li,Xin Chen,Fanqi Shen,Junru Chen,Yuxin Liu,Daoze Zhang,Zhizhang Yuan,Fang Zhao,Meng Li,Yang Yang", "background": "神经系统疾病构成了重大的全球健康挑战，促进了脑信号分析的进步。头皮脑电图（EEG）和颅内脑电图（iEEG）广泛用于诊断和监测。然而，数据集的异质性和任务的变化阻碍了稳健的深度学习解决方案的发展。", "innovation": "本文系统地回顾了近年来基于EEG/iEEG的深度学习方法在神经诊断中的应用进展，覆盖了包括7种神经系统疾病在内的46个数据集。重点介绍了代表性方法及其量化结果，整合了性能比较与数据分析、模型设计和任务特定适应性分析，并强调了多任务预训练模型在实现可扩展和可泛化的解决方案中的作用。", "conclusion": "最后，本文提出了一个标准化基准来评估跨多种数据集的模型性能，以提高再现性，并指出最近的创新正在推动神经诊断向智能化、适应性强的健康护理系统的转变。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.16247", "html_url": "https://arxiv.org/abs/2503.16247", "title": "OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection", "title_en": "OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection", "authors": "Max Gutbrod,David Rauber,Danilo Weber Nunes,Christoph Palm", "background": "随着在医疗健康等关键领域对人工智能（AI）的依赖增加，确保这些系统的可信性变得至关重要，尤其是在面对意外或异常输入时。现有研究发现，来自自然图像领域的广泛OOD基准结果不适用于医疗应用，因此需要专门针对医疗图像的基准测试框架。", "innovation": "该论文提出了OpenMIBOOD，这是一个全面评估医学图像上下文内外异常检测方法的框架，包括三个不同医学领域的基准，涵盖了14个数据集，并分为条件偏移的内分布、接近OOD和远离OOD类别。评估了24种后续方法，为促进OOD检测方法的研发和公平比较提供了标准化的参考。", "conclusion": "通过减轻AI模型面对训练分布外输入的风险，OpenMIBOOD旨在支持医疗领域可靠和可信的人工智能系统的进步。该研究结果表明，广域自然图像领域的OOD基准结果不能直接应用于医学应用，强调了在医学领域建立专门基准测试框架的必要性。该框架的代码库可在此链接访问。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09933", "html_url": "https://arxiv.org/abs/2502.09933", "title": "MIR-Bench：你的大语言模型能否通过多示例上下文推理来识别复杂的模式？", "title_en": "MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?", "authors": "Kai Yan,Zhan Ling,Kang Liu,Yifan Yang,Ting-Han Fan,Lingfeng Shen,Zhengyin Du,Jiecao Chen", "background": "模式识别和应用是从例子中识别模式并将其应用到新的场景中的基本能力，这一能力被心理学和人工智能研究者广泛研究。虽然已经提出了多种基准来衡量大型语言模型（LLM）的这种能力，但这些基准主要集中在少量示例（通常少于10个）的设置上，且缺乏对从长上下文中聚合信息的评估。另一方面，LLM的日益增长的上下文长度催生了新型的多示例上下文学习（many-shot In-Context Learning，ICL）范式，该范式可以通过成百上千个示例解决新任务，而不需要昂贵且低效的微调。然而，多示例评估通常侧重于分类，而流行的大上下文LLM任务如Needle-In-A-Haystack（NIAH）通常不需要整合大量信息的复杂智能。", "innovation": "提出了MIR-Bench基准，这是第一个用于模式识别的多示例上下文推理基准，要求LLM通过输入输出示例预测来自具有多种数据格式的底层函数。基于MIR-Bench，研究了许多关于多示例上下文推理的新问题，并获得了包括缩放效应、鲁棒性、归纳推理 vs. 归纳推理、检索增强生成（RAG）、编码用于归纳推理、跨域泛化性等众多深入见解。", "conclusion": "通过MIR-Bench，我们研究了多示例上下文推理中的许多新问题，并获得了一系列见解，包括规模效应、鲁棒性、归纳推理 vs. 归纳推理、检索增强生成（RAG）、编码用于归纳推理、跨域泛化性等。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.08125", "html_url": "https://arxiv.org/abs/2505.08125", "title": "分布式联邦学习中精确的高斯逼近", "title_en": "Sharp Gaussian approximations for Decentralized Federated Learning", "authors": "Soham Bonnerjee,Sayar Karmakar,Wei Biao Wu", "background": "联邦学习在隐私敏感的合作环境中得到了广泛应用，局部随机梯度下降（local SGD）是去中心化环境中的一种关键优化方法。尽管对其收敛性已有深入研究，但关于收敛性之外的渐近统计保证仍然有限。", "innovation": "本文提出了局部随机梯度下降（local SGD）的两种通用高斯逼近结果。首先，证明了终局局部SGD迭代的Berry-Esseen定理，使有效的乘子布特斯特龙程序成为可能。其次，为了考虑鲁棒性，提出了两种独特的时间统一高斯逼近，这些逼近支持基于高斯布特斯特龙的对抗攻击检测测试。", "conclusion": "本文提供了大量模拟结果来支持理论分析。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.02439", "html_url": "https://arxiv.org/abs/2505.02439", "title": "基于集成学习的大规模多情境楼宇HVAC控制的机器学习模型预测控制", "title_en": "Towards Machine Learning-based Model Predictive Control for HVAC Control in Multi-Context Buildings at Scale via Ensemble Learning", "authors": "Yang Deng,Yaohui Liu,Rui Liang,Dafang Zhao,Donghua Xie,Ittetsu Taniguchi,Dan Wang", "background": "建筑热力学模型可以预测在潜在的暖通空调（HVAC）控制操作下室内温度的实时变化，这对于优化楼宇的暖通空调控制至关重要。虽然一些先驱研究已经尝试为各种建筑环境开发此类模型，但这些模型通常需要较长的数据收集期，并且很大程度上依赖于专家知识，这使得建模过程效率低下，限制了模型的再利用。", "innovation": "本文提出了一个基于集成学习的方法，利用现有开发的模型来作为基础模型以服务目标建筑环境，从而提供准确的预测并减少相关的努力。此外，还提出了一种层次强化学习（HRL）方法，以动态选择和加权基础模型，处理建筑数据流的非平稳性和基础模型数量增加的问题。", "conclusion": "通过对离线实验和现场案例研究进行了充分的评估，实验证明了我们所提出的方法的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15275", "html_url": "https://arxiv.org/abs/2504.15275", "title": "停止求和：过程奖励模型所需的最小形式信用分配", "title_en": "Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning", "authors": "Jie Cheng,Gang Xiong,Ruixi Qiao,Lijun Li,Chao Guo,Junle Wang,Yisheng Lv,Fei-Yue Wang", "background": "过程奖励模型（PRMs）已被证明在大型语言模型（LLMs）的测试时间扩展中对于挑战性的推理任务非常有效。然而，PRMs引起的奖励作弊问题限制了它们在强化微调中的成功应用。主要原因是强化学习（RL）中的经典累积信用分配形式，这将价值定义为未来折现奖励的累积值，容易导致LLMs作弊，以获取高奖励的步骤。因此，需要一种新的解决方案来解决这个问题并改善现有的PRMs应用效果。", "innovation": "本文提出了一种名为纯粹（PURE）的新方法，通过采用最小形式的信用分配，将价值函数定义为未来奖励的最小值，该方法显著减轻了奖励作弊问题。与传统的求和形式信用分配方法相比，PURE不仅可以避免训练崩溃，还能在更少的步骤内实现与可验证奖励方法相当的推理性能。此外，还展示了通过少量验证奖励可以进一步缓解奖励作弊并提高微调模型的性能。", "conclusion": "通过广泛的实验发现，使用最小形式信用分配的方式，基于PRM的最小形式方法能够在仅30%的步骤内获得与验证奖励方法相当的推理性能。进一步地，加入少量的验证奖励可以优化模型性能，获得最佳的微调模型。此外，还对奖励作弊案例进行了总结，并分析了训练崩溃的原因。最后，本文将代码和模型权重进行了公开。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20612", "html_url": "https://arxiv.org/abs/2505.20612", "title": "Roboflow100-VL: 多领域多模态目标检测基准数据集", "title_en": "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models", "authors": "Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri", "background": "基于互联网规模数据训练的视觉语言模型（VLMs）在零样本检测中表现出色，能够检测常见的对象如汽车、卡车和行人。然而，最先进的模型仍然难以泛化到预训练中通常找不到的分布外类别、任务和成像模态。本文讨论了传统的训练方法（仅对模型进行更多视觉数据的训练）存在的局限性，提出了通过使用包含少量视觉示例和丰富文本描述的注释说明来对齐VLMs到新概念的方法。", "innovation": "引入了Roboflow100-VL，这是一个大规模的多模态目标检测数据集集合，涵盖了在VLM预训练中不常见的多样化概念。该数据集用于评估最新模型在零样本、少样本、半监督和全监督设置下的表现，以比较不同的数据情况。通过这种方法，研究发现VLMs在具有挑战性的医学成像数据集上的零样本精度低于2%，表明了少样本概念对齐的需求。", "conclusion": "本文还讨论了最近的CVPR 2025 Foundational FSOD竞赛，并分享了社区的见解。获胜团队在我们的基线基础上取得了显著的17 mAP提升。有关代码和数据集的信息可以在提供的链接中找到。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21994", "html_url": "https://arxiv.org/abs/2505.21994", "title": "基于分解的稳健训练的物理信息神经网络方法在近不可压缩线性弹性问题中的应用", "title_en": "A decomposition-based robust training of physics-informed neural networks for nearly incompressible linear elasticity", "authors": "Josef Dick,Seungchan Ko,Quoc Thong Le Gia,Kassem Mustapha,Sanghyeon Park", "background": "低阶一致有限元方法在近不可压缩弹性方程中的泊松比ν接近1/2时，由于发散不稳定性，其精度会恶化。尽管进行了广泛的研究，这一现象（被称为锁定或非鲁棒性）仍不完全理解。最近，物理信息神经网络（PINNs）在这些问题中的应用也遇到类似的问题。", "innovation": "本研究提出了一个基于分解的稳健PINN框架，该框架通过将弹性方程重新分解为平衡子系统来解决发散不稳定性问题，并能同时解决前向和逆向问题以恢复分解后的场变量及其外部条件。此外，还进行了收敛性分析，以进一步增强方法的可靠性。", "conclusion": "通过各种数值实验，包括常量、变量和参数Lamé系数，证明了所提议方法的有效性。该方法克服了近不可压缩弹性问题中准确性下降和收敛问题等挑战。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18651", "html_url": "https://arxiv.org/abs/2505.18651", "title": "关于词语嵌入中线性类比结构的产生", "title_en": "On the Emergence of Linear Analogies in Word Embeddings", "authors": "Daniel J. Korchinski,Dhruva Karkada,Yasaman Bahri,Matthieu Wyart", "background": "词嵌入模型，如Word2Vec和GloVe，根据词对$i$和$j$在语料库中的共现概率$P(i,j)$构建词嵌入。这些模型中产生的词向量$W_i$不仅将语义相似的词分组，还展现出令人惊讶的线性类比结构，例如$W_{\\text{king}} - W_{\\text{man}} + W_{\\text{woman}} \\approx W_{\\text{queen}}$。尽管观察到这些类比结构出现了相当长的时间，其理论基础仍不清楚。之前的观察表明，这些类比结构在词矩阵$M(i,j) = P(i,j) / P(i)P(j)$的前几个特征向量中已经表现出来，并且随着特征向量数目的增加而增强，当使用$\text{log} M(i,j)$代替$M(i,j)$时会放大这种现象，且即使删除了特定类比关系（如king-queen，man-woman）的词对，它们也仍然存在。", "innovation": "本文提出了一种基于二元语义属性的理论生成模型，解释了这些现象。这种模型通过语义属性的相互作用推导出共现概率，能够以解析方式重现线性类比结构的出现，并自然解释了上述属性(i)-(iv)。该模型能够对每次增加的嵌入维度的角色提供精细分辨率，并且对不同形式的噪声具有鲁棒性，与Wikipedia和Mikolov等人引入的类比基准上的共现统计数据相匹配。", "conclusion": "综上所述，该研究表明基于二元语义属性的理论模型是理解词语嵌入中线性类比结构背后的机制的有效方法。这一研究为解释这些类比结构提供了理论基础，并展示了每增加一个嵌入维度的作用。此外，模型的鲁棒性以及与实际数据的一致性表明了其有效性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21441", "html_url": "https://arxiv.org/abs/2505.21441", "title": "随机森林自编码", "title_en": "Autoencoding Random Forests", "authors": "Binh Duc Vu,Jan Kapar,Marvin Wright,David S. Watson", "background": "该研究基于非参数统计和谱图理论的初步成果，提出了一个有原则的自编码方法，用于使用随机森林进行数据建模。这种方法旨在学习一个低维嵌入，以最佳地表示数据中的关系。研究还提供了解码问题的精确和近似解决方案，通过约束优化、分隔重新标记和最近邻回归来实现。这些方法能够反转压缩管道，从而建立从嵌入空间到输入空间的映射，使用学习的森林组件树的分割。", "innovation": "提出了一种新的自编码方法，融合了随机森林和非参数统计及谱图理论的成果；提供了解码问题的精确和近似解决方案；能够反转压缩管道，提供了从嵌入空间回溯到输入空间的映射方法；所提出的算法对常见的正则性假设下的解码器具有普遍一致性，并能在监督或非监督模型中工作。", "conclusion": "该研究展示了此自编码方法的各种应用，包括强大的新工具，用于可视化、压缩、聚类和降噪。实验结果证明了该方法在各种场景中的便捷性和实用性，适用于表型、图像和基因组数据。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17203", "html_url": "https://arxiv.org/abs/2505.17203", "title": "Transfer更快，定价更聪明：跨市场偏好转移下的最小二乘动态定价", "title_en": "Transfer Faster, Price Smarter: Minimax Dynamic Pricing under Cross-Market Preference Shift", "authors": "Yi Zhang,Elynn Chen,Yujun Yan", "background": "本文研究目标市场可以利用K个辅助市场——线下日志或并发流——在这种情况下，辅助市场的平均效用由结构化的偏好偏移差异。本研究填补了现有动态定价算法在处理模型转移问题方面的空白，旨在寻找一种算法能够处理这种模型偏移，并在不同类型的效用模型（包括线性和非参数）下实现最小二乘最优的后悔值。研究通过理论分析和实验证明，该算法在各种条件下的表现优于传统的单一市场定价方法，尤其是在降低累积后悔值和加速学习速度方面。研究表明，通过结合转移学习、稳健聚合和收益优化的方法，该算法能够帮助市场更快地转移偏好，更智能地定价。", "innovation": "本文提出了一种新的算法Cross-Market Transfer Dynamic Pricing (CM-TDP)，这是第一个在跨市场偏好转移背景下实现最小二乘最优后悔值的算法。对于线性效用模型，当源任务和目标任务之间系数的差异是$s_{0}$稀疏的，CM-TDP可以获得$\tilde{O}((dK^{-1} + s_0)\text{log}T)$的后悔值。对于非线性需求位于具有效度维$\beta$、复杂性$\beta$和任务相似参数$H$的再生核希尔伯特空间中的情况，CM-TDP获得了$\tilde{O}\big(K^{-2\frac{\beta\beta}{2\beta+1}} T^{\frac{1}{2\beta+1}} + H^{\frac{2}{2\beta+1}} T^{\frac{1}{2\beta+1}}\big)$的后悔值，这个结果达到了信息论最小下界的对数因子，这是跨市场定价领域的一项创新。此外，实验证明了该算法在降低累计后悔值和加速学习速度方面的优势。", "conclusion": "本文提出的Cross-Market Transfer Dynamic Pricing (CM-TDP)算法能够在跨市场偏好转移的背景下有效降低后悔值，无论是线性还是非参数效用模型，都达到了最优的程度。该算法通过结合转移学习、稳健聚合和收益优化的方法，在不同类型的市场数据中提供了更快、更智能的定价策略。未来可以通过进一步研究和验证，将该算法应用于更多实际的市场定价问题中，推动市场定价决策技术的进步。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22651", "html_url": "https://arxiv.org/abs/2505.22651", "title": "Sherlock: 自视语言模型的自我纠正推理", "title_en": "Sherlock: Self-Correcting Reasoning in Vision-Language Models", "authors": "Yi Ding,Ruqi Zhang", "background": "视觉语言模型（VLMs）在复杂多模态任务上表现出色，但依然面临挑战：对推理错误非常敏感，需要大量标注数据或准确的验证者，并且难以在特定领域之外泛化。因此，本文探讨了自我纠正策略如何提升推理型VLMs的表现，并通过深入分析其自我纠正能力识别关键缺失。", "innovation": "本文提出了Sherlock，一种自我纠正与自我改进训练框架。Sherlock引入了轨迹级自纠正目标，基于视觉扰动的偏好数据构建方法，以及动态$\beta$用于偏好调整。通过仅使用20000条随机抽取的标注数据，模型获得了自我纠正能力，并在没有外部监督的情况下继续自我改进。它基于Llama3.2-Vision-11B模型，在八个基准测试中取得了显著成果，直接生成的准确率为64.1%，自纠正后的准确率为65.4%，并优于其他模型如LLaVA-CoT (63.2)、Mulberry (63.9) 和 LlamaV-o1 (63.4)，同时使用的标注数据量不到20%。", "conclusion": "通过引入Sherlock，实现了在多个基准测试中的卓越性能，并展示了在少量标注数据条件下，对推理错误的高度鲁棒性和较强自我纠正能力。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23946", "html_url": "https://arxiv.org/abs/2505.23946", "title": "所学知识：一种代码LLM学习和改进的多代理框架", "title_en": "Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve", "authors": "Yuanzhe Liu,Ryan Deng,Tim Kaler,Xuhao Chen,Charles E. Leiserson,Yao Ma,Jie Chen", "background": "近期研究表明，大型语言模型（LLMs）在不同的技能和任务方面存在差异。实际上，观察到这些差异性表现为不同级别。例如，在代码优化任务中，代码LLMs在不同的优化类别中表现出色，但没有一个占据主导地位。这一观察引发了如何利用多个LLM代理来解决编码问题的问题，尤其是在不知道它们各自的互补优势之前。研究表明，通过分享知识和经验，团队可以改进各自的表现。因此，提出了基于知识共享的一个团队协作框架，并设计了知识收集、存档和选择机制，证明即使是由小型LLM组成的团队也能学习到的经验知识能够超越较为庞大的LLM，并且与其他多LLM协作方法相比也表现更好。", "innovation": "提出了一个基于知识共享的多代理协作框架，设计了知识收集、存档和选择机制，证明了小型LLM团队能通过学习行为超越大模型并且在多LLM协作任务中表现出色。", "conclusion": "团队中的小型LLM代理通过互相学习对方的成功和失败，可以改进自己的表现。知识共享机制使得团队可以在多种编码任务中表现出色，即使是由小型LLM组成的团队也能够克服单一LLM的限制，实现更好的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24161", "html_url": "https://arxiv.org/abs/2505.24161", "title": "代理目标：离散脉冲神经网络与连续控制之间的桥梁", "title_en": "Proxy Target: Bridging the Gap Between Discrete Spiking Neural Networks and Continuous Control", "authors": "Zijie Xu,Tong Bu,Zecheng Hao,Jianhao Ding,Zhaofei Yu", "background": "脉冲神经网络（SNNs）在神经形态硬件上提供了低延迟和节能的决策能力，使其成为资源受限边缘设备上强化学习（RL）的潜在选项。然而，大多数用于连续控制的RL算法都是为人工神经网络（ANNs）设计的，特别是目标网络软更新机制，这与脉冲神经元的离散和非可微分动态相冲突。这种不匹配导致SNN训练不稳定，性能降低。", "innovation": "提出了一种新的代理目标框架来弥合离散SNN与连续控制算法之间的差距。该代理网络引入了连续和可微分的动力学，使得目标更新变得平滑，从而稳定学习过程。代理网络仅在训练过程中运行，因此部署的SNN仍保持完全节能，没有额外的推理开销。实验结果显示，该框架在各种SNN模型上提高了稳定性，总体上提高了高达32%的性能。特别地，这是第一个使使用泄漏积分与放电（LIF）神经元的SNN能够超越其ANN对手进行连续控制的方法。", "conclusion": "这项工作强调了为SNN定制的RL算法的重要性，并为高性能与低功耗相结合的神经形态代理铺平了道路。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23883", "html_url": "https://arxiv.org/abs/2505.23883", "title": "BioCLIP 2: 从分层对比学习规模化训练中涌现的特性", "title_en": "BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning", "authors": "Jianyang Gu,Samuel Stevens,Elizabeth G Campolongo,Matthew J Thompson,Net Zhang,Jiaman Wu,Andrei Kopanev,Zheda Mai,Alexander E. White,James Balhoff,Wasila Dahdul,Daniel Rubenstein,Hilmar Lapp,Tanya Berger-Wolf,Wei-Lun Chao,Yu Su", "background": "大规模训练的基础模型表现出非凡的自涌现行为，可以在初始训练目标之外学习新的能力。我们通过大规模的对比视图-语言训练发现生物视觉模型中也存在这种情况。为此我们首先构建了一个包含2.14亿张生物图像的大型多样图像数据集TreeOfLife-200M，然后在该数据集上训练了BioCLIP 2模型以区分不同物种。尽管训练目标较为狭窄，BioCLIP 2在各种生物视觉任务中表现出极高的准确性，如栖息地分类和特征预测。我们还在BioCLIP 2学习到的嵌入空间中发现了这些自涌现属性的证据，特别是在物种内部层面，生物物种内类似的变异性（如生命周期阶段和性别）得以保留和更好地分离，且未被物种间区分所稀释。", "innovation": "此研究通过构建最大的生物学生物图像数据集TreeOfLife-200M，并利用分层次对比学习方法训练BioCLIP 2，首次揭示了模型意外地以物种功能和生态意义为基础进行区分，且生物内的个体变异性（如生命周期阶段和性别）在物种外区分空间保持并分离得更明显。我们还提供了形式上的证明和分析来解释问题认为的层次监督及对比学习目标如何促进这些自涌现属性的出现。并且随着大规模训练数据的增加，这些自涌现属性变得越来越重要，生成了一个具有生物学意义的嵌入空间。", "conclusion": "我们的研究结果表明，大规模的训练数据对于生成具有生物学意义的嵌入空间至关重要，体现了层次监督和对比学习目标对自涌现属性表示的重要性，并进一步验证了BioCLIP 2在生物视觉任务上的卓越性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02945", "html_url": "https://arxiv.org/abs/2506.02945", "title": "定量的大规模语言模型评估者", "title_en": "Quantitative LLM Judges", "authors": "Aishwarya Sahoo,Jeevana Kruthi Karnuthala,Tushar Parmanand Budhwani,Pranchal Agarwal,Sankaran Vaidyanathan,Alexa Siu,Franck Dernoncourt,Jennifer Healey,Nedim Lipka,Ryan Rossi,Uttaran Bhattacharya,Branislav Kveton", "background": "大规模语言模型（LLM）在生成定性文本评估方面表现出色，但在预测人类偏好和数值评分方面经常遇到困难。为了提高现有LLM评估者的评分与人类评估的一致性，本文提出了定量的大规模语言模型评估者。这些评估者使用回归模型对特定领域内的评估分数进行校准，并通过对原评估者的理由和评分进行改进，提高其评分结果的一致性。本文展示了四种针对不同类型绝对和相对反馈的定量评估者，证明了该框架的通用性和灵活性。特别是在人类反馈有限的情况下，这种方法的统计效率更高，符合实际情况。", "innovation": "提出了定量的大规模语言模型评估者，一种使用回归模型将现有LLM评估者的评分与人类评估结果进行校准的方法。通过改进原评估者的理由和评分，增强其评分结果的一致性，并在其原始评估者的基础上通过后处理建模提高其预测能力。这种方法相比监督微调更为计算高效，并且在人类反馈有限的情况下表现出更高的统计效率。", "conclusion": "本文通过在四个数据集上使用两种基础评估者进行实验，验证了定量的大规模语言模型评估者能够通过后处理建模提高现有评估者的预测能力，并且在计算效率和统计效率方面表现优异。这种方法展示了其在实际应用中的潜力，特别是在资源有限的场景下。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19923", "html_url": "https://arxiv.org/abs/2506.19923", "title": "Prover Agent: 基于代理的正式数学证明框架", "title_en": "Prover Agent: An Agent-Based Framework for Formal Mathematical Proofs", "authors": "Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai", "background": "该论文提出了Prover Agent，这是一种新型的AI代理，用于自动化定理证明。它将大型语言模型（LLMs）与形式证明助手Lean结合在一起。Prover Agent将非正式推理的LLM、形式证明模型以及来自Lean的反馈进行了协调，并生成辅助定理。辅助定理不仅限于形式证明中的子目标，也可能包括从假设中推导出的特殊案例或可能有用的事实，这些事实有助于发现可行的证明策略。", "innovation": "Prover Agent 通过结合非正式和正式的推理方法以及生成辅助定理，显著提高了自动化定理证明的成功率。它在MiniF2F基准测试中达到了88.1%的成功率，这是使用小型语言模型（SLMs）的方法中的新记录，且比之前的方法使用了更低的数据量", "conclusion": "该论文通过理论分析和案例研究，说明了生成的辅助定理如何帮助解决复杂问题。所有代码都可以在提供的网址上公开获取。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.20114", "html_url": "https://arxiv.org/abs/2506.20114", "title": "从树集合中提取可解释模型：计算和统计视角", "title_en": "Extracting Interpretable Models from Tree Ensembles: Computational and Statistical Perspectives", "authors": "Brian Liu,Rahul Mazumder,Peter Radchenko", "background": "树集合是非参数方法，因其高预测准确性和能够捕捉复杂交互的能力而受到广泛认可。尽管这些模型在预测方面表现出色，但它们难以解释，并且可能无法揭示数据中的有用关系。", "innovation": "提出了一种用于从树集合中提取紧凑的决策规则集的估计器。该估计器的一个关键新颖之处在于它可以灵活地同时控制提取的规则数量和每个规则的交互深度，从而提高准确性。开发了专门精确算法来高效解决估计器背后的优化问题，并开发了近似算法来计算正则化路径，即相应于不同模型大小的一系列解。还建立了新型非渐近预测误差界，将该方法与遵守相同复杂性约束的最佳数据相关线性规则组合的oracle进行比较。证明了在大样本预测表现上，估计器与oracle相当。", "conclusion": "通过实验，证明该估计器在规则提取方面优于现有算法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04602", "html_url": "https://arxiv.org/abs/2506.04602", "title": "MVP-Shapley: 基于特征建模的篮球最有价值球员评估方法", "title_en": "MVP-Shapley: Feature-based Modeling for Evaluating the Most Valuable Player in Basketball", "authors": "Haifeng Sun,Yu Xiong,Runze Wu,Kai Wang,Lan Zhang,Changjie Fan,Shaojie Tang,Xiang-Yang Li", "background": "电子竞技和多人在线游戏社区的迅速增长突显了评估最有价值球员（MVP）的重要性。撰写MVP评价方法，尤其是需要可解释且实用的评价方法，面临着诸多挑战。本研究聚焦于比赛过程中的详细数据，如助攻和得分记录，旨在通过引入一种基于Shapley值的新MVP评价框架（\textbackslash{oursys}）来解决这一挑战。该框架包括特征处理、胜败模型训练、Shapley值分配和基于球员贡献的MVP排名确定。最终，通过使用NBA和Dunk City Dynasty数据集验证方法的有效性并将其在线部署到工业领域，证明了该方法的有效性。", "innovation": "提出了基于Shapley值的MVP评价框架（\textbackslash{oursys}），该框架涉及特征处理、胜败模型训练、Shapley值分配和基于球员贡献的MVP排名确定。该方法还优化了算法以与专家投票结果从因果角度进行对齐。通过使用NBA和Dunk City Dynasty数据集验证了该方法的有效性，并在工业中进行了在线部署。", "conclusion": "通过引入一个基于Shapley值的MVP评价框架\textbackslash{oursys}，解决了传统方法在解释性和实用性方面的挑战。该研究验证了方法的有效性并在工业中进行了部署，证明了其实际应用价值。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23396", "html_url": "https://arxiv.org/abs/2506.23396", "title": "AICO：监督学习中的特征显著性检验", "title_en": "AICO: Feature Significance Tests for Supervised Learning", "authors": "Kay Giesecke,Enguerrand Horel,Chartsiri Jirachotkulthorn", "background": "机器学习已经成为科学、工业和政策领域的核心工具。算法现在可以识别化学特性、预测疾病风险、筛选借款人，并指导公共干预措施。然而，这种预测能力通常以透明度为代价：我们很少知道哪些输入特征真正驱动了模型的预测。缺乏这种理解，研究者无法得出可靠的科学结论，实践者无法确保公平或问责制，政策制定者也无法信任或治理基于模型的决策。尽管如此，现有的特征影响评估工具仍然有限——大多数工具缺乏统计保证，许多还需要重新训练或建立代理模型，使其不适用于现代大型模型。", "innovation": "我们引入了AICO，这是一种广泛适用的框架，将模型解释性转化为有效的统计练习。AICO 对于任何训练过的回归或分类模型，都会问每个特征是否真正提高了模型性能。它通过掩蔽特征的信息并测量由此引起的性能变化来实现这一目标。该方法提供了精确、有限样本推断——精确的特征p值和置信区间——无需任何重新训练、代理建模或分布假设，使其适用于当今的大型算法。", "conclusion": "在受控实验和实际应用中——从信用评分到抵押行为预测——AICO 一致地指出了驱动模型行为的变量，为透明和值得信赖的机器学习提供了一条快速可靠的路径。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06795", "html_url": "https://arxiv.org/abs/2507.06795", "title": "ixi-GEN: 通过领域适应连续预训练实现高效工业级小语言模型", "title_en": "ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining", "authors": "Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon", "background": "开源大型语言模型（LLMs）为企业应用提供了机会，但许多组织缺乏部署和维护大型模型的基础设施。因此，小语言模型（sLLMs）成为实践中的替代方案，尽管存在性能限制。虽然已经探索了领域适应连续预训练（DACP），但其在商业环境中的实用性尚未得到充分验证。", "innovation": "该研究验证了DACP方法在不同基础模型和服务领域的有效性，并通过这种方法生成了ixi-GEN模型。ixi-GEN模型在目标领域性能方面取得了显著改善，同时保持了通用能力，提供了一种成本低且可扩展的工业级部署解决方案，弥补了DACP在商业应用中的不足。", "conclusion": "实验证明，ixi-GEN模型在目标领域的性能有了显著提升，同时保留了通用能力，为企业的高效部署提供了一种成本效益高且可扩展的方案。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03220", "html_url": "https://arxiv.org/abs/2507.03220", "title": "共生：多适配器推理与微调", "title_en": "Symbiosis: Multi-Adapter Inference and Fine-Tuning", "authors": "Saransh Gupta,Umesh Deshpande,Travis Janssen,Swami Sundararaman", "background": "PEFT技术已经广泛应用于大型语言模型的微调，并发展了大量适应器。现有框架在支持使用多个适应器进行推理或微调时存在缺陷，如消耗大量GPU内存、不支持资源共享、缺乏独立资源管理和异构加速器利用能力，以及提供用户隐私保护不足等问题。", "innovation": "Symbiosis通过使基础模型作为服务进行部署，使得基础模型层可以在多个推理或微调过程中共享。分执行技术将客户特定的适应器和层的执行与冻结的基础模型层解耦，提供灵活的资源管理、不同的微调方法选择和性能目标实现。这种方法对大多数transformers库中的模型是透明的，并且可以直接使用。Symbiosis使得可以同时在8个GPU上对20个Gemma2-27B适应器进行微调。", "conclusion": "Symbiosis通过提供资源共享、灵活的执行控制、支持多种微调方法灵活性和性能目标以及确保用户隐私，解决了现有框架无法有效支持多适应器同时推理和微调的问题。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14757", "html_url": "https://arxiv.org/abs/2508.14757", "title": "分布对抗攻击与深度对冲中的训练", "title_en": "Distributional Adversarial Attacks and Training in Deep Hedging", "authors": "Guangyi He,Tobias Sutter,Lukas Gonon", "background": "本文研究了在输入分布变化时经典深度对冲策略的鲁棒性，利用对抗攻击的概念。研究表明，标准的深度对冲模型在遇到输入分布的小变化时表现会显著下降。这种脆弱性促使作者提出了一种针对提升对冲策略鲁棒性的对抗训练框架。该框架将对抗攻击从点攻击推广到分布攻击，并重新定义了在Wasserstein球上的对抗优化问题，使得鲁棒的对冲策略能够更有效地训练。", "innovation": "本文的创新在于引入了一种针对提升对冲策略鲁棒性的对抗训练框架，该框架将对抗攻击从点攻击推广到了分布攻击，并重新定义了对抗优化问题，在Wasserstein球上进行了重新表述，这使得对抗训练变得更加高效。实验证明，对抗训练后的深度对冲策略在样本外表现和对模型误规定的鲁棒性上，优于经典策略。而且，鲁棒策略在实际市场数据和市场变动期都表现出稳定的表现", "conclusion": "本文的研究结果表明，通过对抗训练建立了一个实用且有效的框架，用于在现实市场不确定性下实现深度对冲的鲁棒性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.16451", "html_url": "https://arxiv.org/abs/2509.16451", "title": "适应性鲁棒优化中的过拟合问题", "title_en": "Overfitting in Adaptive Robust Optimization", "authors": "Karl Zhu,Dimitris Bertsimas", "background": "适应性鲁棒优化（ARO）扩展了静态鲁棒优化，允许决策依赖于实际的不确定性，但是在实际不确定性集之外的实现情况下，可能会出现新的不可行性。这种适应性策略脆弱性的现象类似于机器学习中的过拟合。", "innovation": "提出了为特定约束分配特定的不确定性集合大小的方法，对于更困难的约束给予更强的统计保证。从过拟合的角度来看，这种方法起到了正则化的功能: 更严格的保证会使适应性系数收缩以确保稳定性，而较宽松的保证则保留有用的操作灵活性。这种方法为平衡鲁棒性和适应性提供了有指导意义的方法。", "conclusion": "提出的方法为设计同时确保鲁棒性和适应性的不确定性集合提供了一种有条理的指导思想。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16068", "html_url": "https://arxiv.org/abs/2507.16068", "title": "使用大语言模型实现多机器人团队组成的协调", "title_en": "Compositional Coordination for Multi-Robot Teams with Large Language Models", "authors": "Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme", "background": "传统的多机器人协调依赖于任务特定和专家主导的流程，其中使用自然语言描述的任务被手动翻译成数学公式、算法设计和可执行代码。这一过程劳动力密集、非专家难以参与且不灵活以适应任务需求的变化。现有解决方案的这种缺点使得需要一种新的方法来简化和通用化这一流程，提高多机器人系统的协调能力，减少手动工程量并支持跨不同任务类型的广泛泛化能力。因此，本文提供了一种新的框架LAN2CB（从语言到集体行为），以大语言模型（LLMs）为基础，用于简化和通用化多机器人协调的流程。", "innovation": "LAN2CB框架通过两个核心模块将自然语言任务描述转化为可执行的多机器人系统的Python代码：(1)任务分析模块，解析任务描述生成行为树；(2)代码生成模块，结合行为树和结构化的知识库生成机器人控制代码。这篇论文进一步介绍了一个自然语言任务数据集来支持开发和基准测试。实验结果证明了LAN2CB可以实现基于自然语言的稳健且灵活的多机器人协调，显著减少了手动工程量，能够支持跨不同任务类型的应用。", "conclusion": "通过使用大语言模型，LAN2CB框架极大地简化了自然语言任务描述向可执行多机器人系统代码的转换过程，使得非专家也能参与其中。实验结果证明，该方法能够显著提高多机器人系统的协调灵活性和可扩展性，为未来的多机器人系统应用提供了新的可能性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16027", "html_url": "https://arxiv.org/abs/2508.16027", "title": "通过Transformer实现非平稳强化学习中的最优动态遗憾", "title_en": "Optimal Dynamic Regret by Transformers for Non-Stationary Reinforcement Learning", "authors": "Baiyuan Chen,Shinji Ito,Masaaki Imaizumi", "background": "Transformer模型在众多领域取得了显著的性能，尤其是在上下文进行强化学习方面，已有理论和实验证明了其有效性。然而，它们在非平稳环境中的表现还不是很明确。因此，此研究致力于填补这一空白，展示了Transformer能够实现近乎最优的动态遗憾边界，并能够在非平稳环境中学习和运用相应的策略。", "innovation": "该研究证明了Transformer模型能够在非平稳环境下实现最优动态遗憾边界，展示了其逼近和学习处理非平稳环境策略的能力，并且在实验中证实了Transformer能够与现有的专家算法竞争甚至超越它们的表现。", "conclusion": "研究结果表明，Transformer能够在非平稳强化学习环境中表现优异，能够通过近似策略学习来实现最优的动态遗憾。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.19271", "html_url": "https://arxiv.org/abs/2509.19271", "title": "WolBanking77: Wolof Banking Speech Intent Classification Dataset", "title_en": "WolBanking77: Wolof Banking Speech Intent Classification Dataset", "authors": "Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione", "background": "近年来，意图分类模型取得了显著的进步，但大多数研究主要集中在高资源语言数据集上，导致低资源语言和高文盲率地区（如几内亚比绍，沃洛夫语被90%人口使用，但识字率仅为42%）的差距问题。这些地区主要使用口文字而少有书面文字。本文探讨了针对沃洛夫语开发意图分类数据集的必要性和背景。", "innovation": "文章介绍了Wolof Banking Speech Intent Classification Dataset (WolBanking77)，该数据集包含9,791条文本句子和超过4小时的语音样本，特别针对银行领域。文章还对多种基于文本和语音的先进模型进行了实验，并展示了其在当前数据集上的表现。通过对WolBanking77数据集的深入内容分析，研究提出了更新的基线F1分数和词错误率再NLP和ASR模型的比较结果。", "conclusion": "研究结果显示WolBanking77数据集在当前的实验中表现非常有前景。同时，作者提供了数据集和用于实验的代码，以促进学术研究。该数据集为研究提供了新的视角，旨在填补低资源语言领域中的空白。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.24544", "html_url": "https://arxiv.org/abs/2509.24544", "title": "经过训练的单层神经网络到高斯过程的定量收敛", "title_en": "Quantitative convergence of trained single layer neural networks to Gaussian processes", "authors": "Eloy Mosig,Andrea Agazzi,Dario Trevisan", "background": "尽管以往研究已经建立了广泛的条件下的定性收敛性，但有限宽度网络的具体、有限宽度估计仍然有限，尤其是在训练过程中。本文旨在提供网络输出与其高斯逼近之间的二次 Wasserstein 距离的显式上界，展示网络宽度的多项式衰减。", "innovation": "本文提供了网络输出和其高斯逼近之间二次 Wasserstein 距离的显式上界，展示了网络宽度的多项式衰减。并且揭示了如宽度和输入维度等结构参数如何影响收敛速度，以及训练动力学如何影响逼近误差的变化情况。", "conclusion": "本文揭示了单层神经网络在无限宽度极限下，通过梯度下降训练时，其输出向高斯过程收敛的定量关系，强调了网络架构和训练动态对收敛的影响。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.11508", "html_url": "https://arxiv.org/abs/2509.11508", "title": "SafeDiver: 通过多智能体强化学习方法进行海上无人潜水艇-无人水面艇协作潜水员通信", "title_en": "SafeDiver: Cooperative AUV-USV Assisted Diver Communication via Multi-agent Reinforcement Learning Approach", "authors": "Tinglong Deng,Hang Tao,Xinxiang Wang,Yinyan Wang,Hanjiang Luo", "background": "随着水下人类活动的增加，对水下通信服务的需求面临着显著的挑战。现有的水下潜水员通信方式由于固有的局限性和复杂的水下环境而面临障碍。为了解决这一问题，我们提出了一种利用海上无人驾驶系统协助潜水员进行可靠和高速通信的方案。通过使用多自主水下航行器分配具有光学和声学多模式通信装置的待机节点，并根据潜水员活动区域的变化提供自适应通信服务。利用多智能体强化学习方法控制AUV的协同运动，实现潜水员之间高速和可靠的通信传输。同时，通过无人水面艇（USV）的应用作为表面待机节点，协调和转发来自AUV的信息，并控制AUV自适应地选择待机USV节点以进行数据传输，实现潜水员与表面平台之间的高质量通信。通过模拟验证，提出的方案能够有效实现潜水员的可靠和高速通信。", "innovation": "利用多自主水下航行器与无人水面艇的协作，结合多智能体强化学习方法，实现了潜水员之间的高速和可靠的通信。通过自适应选择待机节点，提高了通信质量。此外，利用无人水面艇的灵活性和广覆盖优势，协调信息转发，优化了整体通信效率。", "conclusion": "提出的SafeDiver方案能够有效解决水下通信难题，提供可靠和高速的潜水员通信服务，这种合作模式和通信策略能够适应复杂多变的水下环境。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14203", "html_url": "https://arxiv.org/abs/2509.14203", "title": "平均收益鲁棒马尔可夫决策过程的贝尔曼优化性", "title_en": "Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain", "authors": "Shengbo Wang,Nian Si", "background": "学习与最优控制在鲁棒马尔可夫决策过程（MDPs）下的研究逐渐受到关注，现有的大多数理论、算法和应用主要集中在有限时区或贴现模型上。而平均收益的长期标准在许多运筹学和管理领域自然适用，但其理论探讨和应用相对不足，主要原因是其动态规划基础的技术挑战及其理解尚不充分，存在许多基本问题未解决。该项研究旨在通过分析常增益设置下的鲁棒MDPs，构建一个较为通用的框架，专注于平均收益鲁棒控制问题，特别是考虑信息不对称的情况下，探索常增益鲁棒贝尔曼方程解的存在性及其与最优平均收益和站定策略的关系。", "innovation": "该研究提出了平均收益鲁棒MDPs（常增益设置）的一般框架，分析了可能存在控制者和S-矩形对手信息不对称情况下的问题。研究重点在于常增益的鲁棒贝尔曼方程的存在性和与最优平均收益及稳定策略的关系，提出了确保方程解存在的单向弱通信条件，这扩展了平均收益鲁棒MDPs的动态规划理论，为在长期平均标准下的鲁棒动态决策提供了基础。", "conclusion": "该研究丰富了动态规划理论在鲁棒MDPs中的应用，特别是平均收益方面，为在运营环境中实现鲁棒动态决策提供了新的理论基础，尤其是在存在信息不对称的情况下。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05013", "html_url": "https://arxiv.org/abs/2510.05013", "title": "机器人通过自我探索实现动作与语言的好奇驱动发展", "title_en": "Curiosity-Driven Development of Action and Language in Robots Through Self-Exploration", "authors": "Theodore Jerome Tinker,Kenji Doya,Jun Tani", "background": "人类婴儿通过逐渐发展，仅从少量学习示例中获得语言和动作的广泛化能力。相比之下，最近的大规模语言模型需要数以亿计的训练令牌才能达到这种广泛化。探究人类如何实现这样高效的发育式学习机制是本研究的背景。研究通过机器人进行模拟实验，学习对应指令（比如“推红色立方体”）的各种动作，以探索这种机制。利用主动推理框架与强化学习相结合的方法，引导好奇心驱动的发育式学习。", "innovation": "该研究将主动推理框架与强化学习相结合，实现了好奇心驱动的发育式学习，通过自我引导的探索使机器人学会执行各种动作。结果显示，随着组合元素数量的增加，泛化能力大大提升；好奇心探索与运动噪声结合显著优于单纯学习；单纯句与动作配对发生在组合泛化之前；更简单的动作如预备动作在早期出现，而涉及这些预备动作的复杂动作则在后期发展。", "conclusion": "研究结果为高效发育式学习在婴儿中的潜在机制提供了可能的解释，并为发展心理学中的发现提供了计算上的类比。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08609", "html_url": "https://arxiv.org/abs/2510.08609", "title": "减少过时和漏洞依赖项：锁定与漂浮哪个更好？", "title_en": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?", "authors": "Imranur Rahman,Jill Marley,William Enck,Laurie Williams", "background": "开发人员经常使用版本约束来指定项目依赖项的可接受版本。锁定依赖项可以减少破坏性变更的风险，但需要手动管理过时和易受攻击依赖项的替换。漂浮方法可自动获取错误修复和安全修复，但存在破坏性变更的风险。安全从业人员推荐锁定依赖项来防止软件供应链攻击，如恶意包更新。然而，锁定是紧致的版本约束，因此它是最可能导致依赖项过时的原因。本研究旨在通过大规模实证评估，在各种版本约束类型下依赖项变得过时或易受攻击的可能性，以帮助开发人员做出知情的决策.", "innovation": "该研究首次通过实证方法评估了在锁定和其他版本约束类型下依赖项变得过时或易受攻击的可能性的变化，揭示了不同约束类型下依赖项状态转换的趋势，并提出了漂浮依赖项相比锁定依赖项可能更好地减少过时和易受攻击依赖项。", "conclusion": "研究结果表明，漂浮-次要是最常使用的版本约束类型，其次是锁定。此外，研究发现漂浮-主要是最不可能导致依赖项过时，而漂浮-次要是最不可能导致依赖项易受攻击。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02253", "html_url": "https://arxiv.org/abs/2510.02253", "title": "DragFlow: 利用区域监督释放DiT先验的拖动编辑", "title_en": "DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag Editing", "authors": "Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong", "background": "拖动基的图像编辑长期存在目标区域失真的问题，主要是因为早期基础模型（如Stable Diffusion）的先验条件不足以将优化的潜在空间映射回自然图像流形。随着从基于UNet的DDPMs向DiT（特别是SD3.5和FLUX）的转变，生成先验变得更强，这使得各种编辑任务都取得了进展。但是，拖动基编辑尚未从这些强先验中受益。该研究提出了首个搭载FLUX丰富先验进行拖动编辑的框架，名为DragFlow，相比基准模型，该框架取得了显著进步。", "innovation": "DragFlow 引入了基于区域的编辑范式，通过仿射变换提供更丰富、更一致的特征监督。同时，它集成了预训练的开放式领域个性化适配器来增强主题一致性，并通过梯度蒙版约束保持背景的准确性。此外，还利用了多模态大型语言模型来解决任务的模糊性。DragFlow通过创建定义明确的区域指令基准（ReD Bench）进行评估。在DragBench-DR和ReD Bench上的实验结果表明，DragFlow超越了基于点的和基于区域的基准模型，设立了新的拖动编辑的最先进技术状态。", "conclusion": "DragFlow 通过利用DiT的丰富先验并结合区域监督，显著改进了拖动编辑效果。它有效地优化了FLUX的先验以进行拖动编辑，并通过集成各种技术增强了编辑性能。实验结果表明，DragFlow 在不同基准上均表现出色，达到最佳性能。此外，DragFlow 的代码和数据集将在发表后公开。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06259", "html_url": "https://arxiv.org/abs/2510.06259", "title": "超越静态知识信使：迈向医疗人工智能的自适应、公平和可扩展的联邦学习", "title_en": "Beyond Static Knowledge Messengers: Towards Adaptive, Fair, and Scalable Federated Learning for Medical AI", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel,Iftekhar Haider", "background": "医疗人工智能在保护隐私的同时进行协作学习面临着挑战，尤其是在确保跨不同医疗机构的公平性方面。当前的联邦学习方法存在静态架构、收敛速度慢（45-73轮）、机构间不公平性及可扩展性限制等问题。", "innovation": "本文提出了自适应公平联邦学习（AFFL），通过三个方面进行创新：（1）自适应知识信使根据异质性和任务复杂性动态调整容量；（2）公平意识蒸馏采用了影响加权聚合；（3）课程引导加速降低了60-70%的轮数。理论分析提供了以ε公平性为界的收敛保证，实现了O(T^{-1/2}) + O(H_max/T^{3/4})的速度率。预测结果显示了55-75%的通信减少、56-68%的公平性提升、34-46%的能量节省以及支持100多个机构的能力。", "conclusion": "该框架实现了影像、基因组学、电子健康记录及传感器数据的多模态整合，同时保持了HIPAA/GDPR合规性。还提出了用于跨六个健康照护维度标准化评估的MedFedBench基准套件，经济评估表明农村医院ROI增加400-800%，学术中心性能提升15-25%。这项工作提出了七个研究议程、为期24个月的实施规划，并指明了医疗人工智能民主化的途径。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12988", "html_url": "https://arxiv.org/abs/2510.12988", "title": "行为生物特征识别在虚拟现实用户熟悉度自动检测中的应用", "title_en": "Behavioral Biometrics for Automatic Detection of User Familiarity in VR", "authors": "Numan Zafar,Priyo Ranjan Kundu Prosun,Shafique Ahmad Chaudhry", "background": "随着虚拟现实（VR）设备日益融入日常生活场景，越来越多的用户将首次尝试使用VR系统。自动检测用户的VR熟悉度可以实现实时、自动的培训和界面调整，减少用户挫败感，并提高任务性能。", "innovation": "本文研究通过分析基于密码的门开启任务中手部运动模式来自动检测VR熟悉度的方法。研究使用先进的深度分类器实现了最高的手部追踪和控制器交互准确率分别为92.05%和83.42%；跨设备评估中，基于控制器数据训练的分类器测试在手部追踪数据上的准确性为78.89%；混合设备评估中两种模式结合的准确性为94.19%。研究证明了手部运动生物特征在关键时刻的VR应用中实时检测用户熟悉度的潜力。", "conclusion": "本研究结果表明，通过手部运动生物特征可以实时检测关键VR应用中的用户熟悉度，为个性化和自动适应的VR体验铺平道路。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25271", "html_url": "https://arxiv.org/abs/2509.25271", "title": "RADAR：一种基于角色专业化协作的风险感知动态多代理框架，用于大规模语言模型安全性评估", "title_en": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "authors": "Xiuyuan Chen,Jian Zhao,Yuchen Yuan,Tianle Zhang,Huilin Zhou,Zheng Zhu,Ping Hu,Linghe Kong,Chi Zhang,Weiran Huang,Xuelong Li", "background": "现有的大型语言模型（LLMs）的安全评估方法存在固有的局限性，包括评估者偏见和由于模型同质性导致的检测失败等问题，这些问题共同削弱了风险评估过程的稳定性。现有方法在很大程度上依赖于单一的评估者和固定的评估框架，无法全面覆盖显性和隐性风险，并且容易受到评估者偏见的影响。为此，需要重新审视风险评估模式，引进新的理论框架来修复和改进这些问题。这项研究试图通过引入理论框架来重建风险概念空间，解决了现有评估方法中难以克服的问题，为大规模语言模型的安全评估带来了新的视角与可能。这种方法能够涵盖显性和隐性风险，同时减少评估者的偏见，提升评估的准确性和稳定性。", "innovation": "这项研究提出了RADAR（一种基于角色专业化协作的风险感知动态多代理框架），通过引入多轮辩论机制和动态更新机制，将隐性风险概念空间分解为三个互斥子空间：显性风险子空间（直接违反安全指导方针的行为）、隐性风险子空间（需要上下文推理才能识别的潜在恶意内容）以及非风险子空间。RADAR框架能够更全面地评估模型的安全性，并具备自我进化功能，实现风险概念分布的动态调整，从而显著提高了对风险的识别能力，满足了对复杂模型安全性的多维度评估需求。本次研究进行了大规模实验，证明了RADAR在评估准确性、稳定性和自我评价风险敏感性等多个方面的优越性，相较于现有的最佳基线方法，RADAR在风险识别准确率上提高了28.87%。这项创新方法显著提升了大规模语言模型安全评估的效率和准确性，为未来研究提供了新的思路和技术支持。", "conclusion": "RADAR框架在此研究中通过理论创新和方法改进，解决了现有评估方法中的关键问题，显著提升了对大规模语言模型潜在风险的整体评估质量。研究充分验证了RADAR在多个维度（准确度、稳定性和自我评估风险敏感度）上的优异表现，研究成果对大规模语言模型的安全评估及安全管理具有重要意义。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08872", "html_url": "https://arxiv.org/abs/2510.08872", "title": "GTAlign：大型语言模型助手中的博弈论对齐以实现互惠", "title_en": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare", "authors": "Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You", "background": "尽管大型语言模型在推理能力方面取得了显著进步，但在写作、信息查询或提供实用指导等任务中，有时会生成用户认为质量较差的回复。传统的对齐实践通常认为最大化模型奖励同时最大化用户福利，但在实际应用中这种假设往往无法成立。模型可能过度详尽地解释其推理过程，从而按照用户的需求比较简短回答时显得过于冗长。其背后的原因类似于囚徒困境，即个人理性选择导致社会结果不理想。面临着LLM与用户双方共赢决策机制缺失的挑战。", "innovation": "本文提出了博弈论对齐（GTAlign），这是一种将博弈论决策机制整合到推理和训练中的对齐框架。在推理过程中，模型明确地将用户-LLM交互视为战略性博弈，构建评价矩阵来估算双方的福利，并选择互惠收益最大化的行为。此外，通过引入反映合作响应的重合价值奖励，模型行为与社会效益化的结果保持一致。同时，引入了一种利用博弈论推理动态适应LLM响应的推断方法，特别是在LLM服务的价格策略发生变化时。广泛的实验表明，相比于基准方法，GTAlign在各种任务中显著提高了推理效率、回答质量和互惠效果。", "conclusion": "实验结果表明，与基准方法相比，GTAlign在推理效率、回答质量和双向福利方面表现显著提升，表明博弈论对齐框架在提升大型语言模型与用户互惠共赢的合作效果方面的有效性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.13894", "html_url": "https://arxiv.org/abs/2510.13894", "title": "贝叶斯还是海森堡：谁（们）统治？", "title_en": "Bayes or Heisenberg: Who(se) Rules?", "authors": "Volker Tresp,Hang Li,Federico Harjes,Yunpu Ma", "background": "虽然量子系统通常用量子态向量来描述，但我们展示了某些情况下它们的测量过程可以归结为用概率态向量表达的概率方程。这些概率表示可以进一步通过张量脑（TB）模型的神经网络动态来近似。张量脑是一种最近提出的框架，用于模拟大脑的感知和记忆，提供了生物学启发的机制，用于高效地将生成的符号表示融入推理过程之中。", "innovation": "提出了将量子系统的测量过程通过概率态向量表达，并近似为张量脑模型的神经网络动态。张量脑模型提供了一种生物学启发的方法，用于将生成的符号表示高效地融入推理过程。", "conclusion": "研究显示，某些情况下可以将量子系统的测量过程通过概率态向量表达，这种方式可以通过张量脑模型的神经网络动态来近似实现。这标志着一种新的对量子测量过程的理解和模拟方式，进一步促进了量子理论与神经科学之间的融合。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11824", "html_url": "https://arxiv.org/abs/2510.11824", "title": "在协同多智能体强化学习中的稳健性和韧性经验研究", "title_en": "Empirical Study on Robustness and Resilience in Cooperative Multi-Agent Reinforcement Learning", "authors": "Simin Li,Zihao Mao,Hanxiao Li,Zonglei Jing,Zhuohang bian,Jun Guo,Li Wang,Zhuoran Han,Ruixiao Xu,Xin Yu,Chengdong Ma,Yuqing Ma,Bo An,Yaodong Yang,Weifeng Lv,Xianglong Liu", "background": "在协同多智能体强化学习(MARL)中，通常在理想的模拟环境中调整超参数以最大化合作性能。然而，经过合作优化的策略在面对现实世界不确定性的稳定性较差。建立可信赖的MARL系统需要对稳健性和韧性有深刻的理解，这两者分别确保在不确定条件下系统的稳定性和使系统在受到干扰后能够恢复的能力。稳健性和韧性很少在MARL中得到研究，尽管这两个概念在控制系统中得到了广泛研究。", "innovation": "本文进行了一个大规模的经验研究，包括超过82,620次实验，评估了4个真实世界的环境、13种不确定类型和15种超参数下的协同、稳健性和韧性。研究发现：（1）在轻度不确定条件下，优化协同性能可以提高稳健性和韧性，但这一联系会随着干扰的增强而减弱，且稳健性和韧性也会因算法和不确定类型的不同而有所不同。（2）稳健性和韧性不能跨不确定模态或智能体范围进行泛化：可以抵抗所有智能体的行动噪声的策略可能在单个智能体的观测噪声下失效。（3）超参数调整是可靠MARL的关键：标准实践如参数共享、GAE和PopArt可能会损害稳健性，而提前停止、高的批评学习率和Leaky ReLU则始终有益。通过仅优化超参数，我们观察到在所有MARL架构中协同、稳健性和韧性的显著提升，并发现在这些架构中的稳健MARL方法也有类似的泛化能力。", "conclusion": "研究表明在MARL系统中优化超参数可以显著提升模型的协同、稳健性和韧性。这种优化方法对不同MARL架构都适用，而且在稳健MARL方法中也有类似的泛化效果。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25033", "html_url": "https://arxiv.org/abs/2509.25033", "title": "VT-FSL: 通过LLMs桥接视觉与文本的少样本学习", "title_en": "VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning", "authors": "Wenhao Li,Qiangchang Wang,Xianjing Meng,Zhibin Wu,Yilong Yin", "background": "少样本学习(FSL)的目标是从少量标记的支持样本中识别新的概念。近年来的研究通过引入附加的语义信息或设计复杂的语义融合模块来增强支持特征。然而，这些方法仍然存在由于缺乏实例上的语义锚定而产生的语义幻觉问题，导致指导信号嘈杂且需要昂贵的修正。", "innovation": "提出了一种新的框架VT-FSL（Vision and Text with LLMs for Few-Shot Learning），该框架通过大型语言模型构建精确的跨模态提示，并结合支持图像，通过几何感知对齐无缝地整合它们。该框架主要由跨模态迭代提示(CIP)和跨模态几何对齐(CGA)组成。CIP条件化大型语言模型使其同时基于类名称和支持图像，以在单一结构推理过程中生成精确的类描述。这些描述不仅丰富了新型类别的语义理解，还允许零样本合成语义一致的图像。CGA通过最小化所跨越的三维平行otope的核体积，联合对齐融合的文本、支持和合成视图表示，捕捉全球和非线性关系，实现结构化和一致的多模态整合。", "conclusion": "提出的VT-FSL方法在包括标准、跨域和细粒度少样本学习场景在内的十个不同的基准上建立了新的最先进的性能。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17111", "html_url": "https://arxiv.org/abs/2510.17111", "title": "高效视觉-语言-行动模型在嵌入式操作中的系统性综述", "title_en": "Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey", "authors": "Weifan Guan,Qinghao Hu,Aosheng Li,Jian Cheng", "background": "视觉-语言-行动（VLA）模型通过将自然语言指令和视觉观察映射到机器人行动，扩展了视觉-语言模型到实体控制。尽管具有强大的能力，VLA系统由于其庞大的计算和内存需求，面对边缘平台如车载移动 manipulators 的实时性能要求挑战显著。", "innovation": "本文综述了提高VLA系统效率的方法，特别关注减少延迟、内存足迹以及训练和推理成本，将现有解决方案分类为四个方面：模型架构、感知特征、行动生成和训练/推理策略，概述了每个类别内的代表技术。", "conclusion": "最后，讨论了未来趋势和开放挑战，强调了发展高效嵌入式智能的方向。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.15786", "html_url": "https://arxiv.org/abs/2510.15786", "title": "DexCanvas：从人类示范到机器人灵巧操作学习的桥梁", "title_en": "DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation", "authors": "Xinyue Xu,Jieqiang Sun,Jing(Daisy)Dai,Siyuan Chen,Lanjie Ma,Ke Sun,Bin Zhao,Jianbo Yuan,Sheng Yi,Haohua Zhu,Yiwen Lu", "background": "目前缺乏大规模、系统性覆盖各种灵巧操作技能、且包含物理验证的接触力标注的灵巧操作数据集。机器人灵巧操作学习需要大量高质量的数据来训练模型，现有数据集在实际应用中存在不足，如数据量不足、操作类型不全面等。", "innovation": "DexCanvas 是首个结合大规模真实操作示范、基于已建立分类体系的系统性技能覆盖及物理验证的接触力标注的数据集。通过结合实时多视角 RGB-D 视频、高精度 mocap 数据和 MANO 手形参数，以及每帧的接触点与物理一致的力剖面，DexCanvas 提供了一个全面的数据集来支持机器人灵巧操作学习、接触丰富的控制和跨手型技能转移的研究。", "conclusion": "通过物理仿真和强化学习，DexCanvas 实现了真实演示到仿真的转换，训练了控制机械手执行真实演示并发现导致物体运动的接触力的策略。DexCanvas 为机器人灵巧操作学习研究提供了宝贵的资源，推动了该领域的技术水平。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.15530", "html_url": "https://arxiv.org/abs/2510.15530", "title": "VO-DP: 仅视觉语义几何自适应扩散策略的机器人操作", "title_en": "VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation", "authors": "Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He", "background": "在模仿学习的背景下，基于视觉运动的扩散策略学习在机器人操作中是一个主要方向。目前大多数方法依赖于点云作为观测输入，并通过点云特征学习构建场景表示，这使得它们在精确度方面取得了显著的成绩。然而，现有文献对仅依赖视觉感官的解决方案探索不足，而这些方案具有巨大潜力。", "innovation": "本文提出了一种基于预训练视觉基础模型的仅视觉视角和单视图扩散策略学习方法VO-DP，该方法利用了从VGGT提取的中间特征，结合DINOv2的语义特征和交替注意力块的几何特征。特征通过跨注意力连接和利用CNN的空间压缩形成策略头部的输入。实验表明，VO-DP不仅在视觉基线DP上表现出色，还在模拟任务中的成功率平均为64.6%，与DP3的64.0%相当，并大幅高于DP的34.8%；在现实世界任务中，成功率达到了87.9%，远超DP3的67.5%和DP的11.2%。VO-DP还具有高度的鲁棒性，无论颜色、大小、背景或光照条件如何变化，其性能都非常稳定。", "conclusion": "VO-DP源代码开源，基于Accelerate构建，支持多机器和多GPU并行训练及混合精度训练，适用于包括DP、DP3和VO-DP的视觉运动策略，并兼容RoboTwin模拟器。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16013", "html_url": "https://arxiv.org/abs/2510.16013", "title": "AGNES: 自适应图神经网络和动态规划混合框架实现实时纳米孔种子链接", "title_en": "AGNES: Adaptive Graph Neural Network and Dynamic Programming Hybrid Framework for Real-Time Nanopore Seed Chaining", "authors": "Jahidul Arafat,Sanjaya Poudel", "background": "纳米孔测序能够实现超过10千碱基的长读长DNA测序，但其固有的12-15%的错误率带来了显著的读取对齐计算挑战。种子链接这一步骤是关键，它需要在读取和参考基因组之间建立精确k-mer匹配，同时过滤伪匹配。现有方法依赖固定间隔惩罚函数，无法适应包括串联重复和结构变异在内的不同基因组背景。", "innovation": "本文提出了一种结合图神经网络（GNN）和传统动态规划的混合框架，称为RawHash3，用于自适应种子链接。该框架维持实时性能，同时提供统计保证。通过使用三层EdgeConv GNN以及基于置信度的方法选择，系统能够动态切换到学习指导和算法备份。在综合评估中，RawHash3达到99.94%的精度和40.07%的召回率，相对于基线在p<0.001时提高了25.0%的相对性能。", "conclusion": "该系统在中位推理延迟为1.59ms的情况下满足了实时约束，甚至在20%的标签损坏情况下成功率为100%，而基线下降到30.3%。交叉验证表明稳定性，显示图神经网络在生产基因组管道中的可行性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17697", "html_url": "https://arxiv.org/abs/2510.17697", "title": "多智能体强化学习中的目标干预原则", "title_en": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "authors": "Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang", "background": "在大规模协作多智能体强化学习（MARL）中，引导多智能体系统的整体行为尤其具有挑战性，当从人类获取全面指导不实际时，尤其如此。同时，设计外部分配机制（例如内在奖励和人类反馈）来协调多智能体的绝大部分研究依赖于经验研究，欠缺一款易于使用的研究工具。", "innovation": "本文采用多智能体影响图（MAIDs）作为图形框架来解决上述问题。首先，引入了MARL交互范式的概念，使用MAIDs分析和可视化无引导的自组织和全局指导机制。然后，设计了一个仅应用于单个目标智能体的新MARL交互范式，称为目标干预范式，以此来减轻全局指导问题。实施中引入了一种因果推理技术，称为先策略干预（PSI），实现目标干预范式。因果图的捆绑相关性图分析提供了评估MARL交互范式下MARL学习范式可行性的工具。", "conclusion": "实验结果展示了我们提出的目标干预的有效性，并验证了相关图分析的结果。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18161", "html_url": "https://arxiv.org/abs/2510.18161", "title": "借助推理意识的政策优化击败胜者诅咒", "title_en": "Beating the Winner's Curse via Inference-Aware Policy Optimization", "authors": "Hamsa Bastani,Osbert Bastani,Bryce McLaughlin", "background": "近年来，自动学习策略以针对个体丰富协变量进行治疗决策的兴趣激增。常用的方法是训练机器学习模型预测反事实结果，然后选择优化预测目标值的策略。然而，由于优化过程可能会利用预测误差而非实际改进，导致预测性能提升往往在下游政策优化中并未得到证实。本文探讨了这一挑战。", "innovation": "本文提出了一种新策略，称为推理意识的政策优化，该策略通过考虑政策在下游如何被评估来修改策略优化过程。具体而言，优化不仅考虑估计的目标值，还考虑策略相对于所用观测政策在统计上显著更好的概率。根据这个权衡，设计了一种使用机器学习预测反事实结果并估计帕累托前沿的策略优化算法。", "conclusion": "该研究通过仿真展示了该方法的有效性。其主要结论是，通过以推理意识的方式来优化政策，可以有效应对胜者诅咒，确保所学习的策略在性能上优于现有政策。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17451", "html_url": "https://arxiv.org/abs/2510.17451", "title": "参数化的VC维计算复杂性", "title_en": "The Parameterized Complexity of Computing the VC-Dimension", "authors": "Florent Foucaud,Harmender Gahlawat,Fionn Mc Inerney,Prafullkumar Tale", "background": "VC维是集合系统（或超图）的一个广泛研究和基本的复杂性度量指标，对机器学习等多个领域至关重要。本文研究了计算VC维的复杂性，尤其是在给定超图\\(\\mathcal{H}=(\\mathcal{V},\\mathcal{E})\\)的情况下，探讨了计算该值的算法及其复杂性上界。", "innovation": "本文提出了几个新的研究成果，证明了一个简单的\\(2^{\\mathcal{O}(|\\mathcal{V}|)}\\)算法在最坏情况下是紧致的（基于指数时间假设）。然后证明了该问题在最大度数和维数参数化下的固定参数近似算法，且这些是目前仅有的可利用的结构参数。此外，作者通过图的形式对问题进行了一般化，设计了适用于树分解宽度的小多重度多项式时间算法，这与相关问题相比具有更优的时间复杂性表现（在假定存在指数时间假设的情况下）", "conclusion": "本文主要结论是：对于超图的VC维计算问题，在特定参数化下存在高效的固定参数算法；并且通过图的形式研究了更广泛的实际应用场景，同时提出了解决此一般化问题的时间复杂性算法。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17472", "html_url": "https://arxiv.org/abs/2510.17472", "title": "Certified Self-Consistency: Statistical Guarantees and Test-Time Training for Reliable Reasoning in LLMs", "title_en": "Certified Self-Consistency: Statistical Guarantees and Test-Time Training for Reliable Reasoning in LLMs", "authors": "Paula Cordero-Encinar,Andrew B. Duncan", "background": "近年来，如自我一致性（self-consistency）和测试时强化学习（TTRL）等技术显著提升了大语言模型（LLMs）的可靠性，但这些技术背后的机制及其统计保证仍不明确。研究者们需要一个统一框架来理解这些机制，并提供可靠的理由保证。这项研究通过引入一致的推理确定性框架来填补这一空白。", "innovation": "这项研究提出了一个统一的框架，称为「一致的推理确定性」框架，该框架利用多数表决提供了一种统计上的自我一致性证明。此框架还提出了基于鞅的多数证书（Martingale Majority Certificate, MMC）逐步停止规则，动态确定所需样本数量。此外，该研究还揭示了无监督后训练技术，如TTRL，通过使其答案分布转向其模式而隐式增加精确度，从而减少认证所需的样本数。基于此，研究者还提出了新的后训练目标，优化精确度和偏差之间的权衡。这些方法解释并统一了自我一致性与TTRL这两种核心测试时间扩增策略，共同提供了无标签增强认证的大语言模型可靠性统计框架。", "conclusion": "研究证明了多种机制并使用量化工具提供统计支持，解释了自我一致性和TTRL这两种策略，并提出了新的后训练目标。这为未来的大语言模型开发提供了统计保证和方法论框架，以实现可靠的推理与兼容的可验证性。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18254", "html_url": "https://arxiv.org/abs/2510.18254", "title": "在开放任务中反映推理的幻象：大型语言模型在反映性推理方面的系统性失败", "title_en": "Illusions of reflection: open-ended task reveals systematic failures in Large Language Models' reflective reasoning", "authors": "Sion Weatherhead,Flora Salim,Aaron Belbasis", "background": "当前的大型语言模型在完成推理任务时能够生成基于规则的文本，并表现出某种形式的“自我反思”，但在开放性任务中是否能够真正产生功能等同于人类反思推理的自我纠正能力尚不清楚。已有研究多集中于封闭任务，这些任务具有明确且外显的正确性信号，可能会掩盖语言模型自我纠正的实际局限。", "innovation": "本文通过在开放但有规则限制的任务上测试多种前沿模型，表明大型语言模型的“自我反思”能力缺乏类似人类的主动、目标驱动的监测机制，即在任务的第一遍表现不佳，尽管进行了反射性修正，产生的结果往往依靠运气，而不是实际错误检测和原则性的、对约束敏感的修复。研究进一步指出，具有“推理”标签的语言模型并未显示任何优势，并且性能在任务开放性增加时会下降。", "conclusion": "当前的大型语言模型在“自我反思”方面的表现缺乏功能性的证据，表明人类在任务初始阶段即使不依赖结构性外来的提示也能更好地遵守约束。要确保可靠的操作性能，需要在模型内部嵌入此类监测机制，或者依赖外部结构来强制遵守约束。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19315", "html_url": "https://arxiv.org/abs/2510.19315", "title": "变换器本质上是简洁的", "title_en": "Transformers are Inherently Succinct", "authors": "Pascal Bergsträßer,Ryan Cotterell,Anthony W. Lin", "background": "该研究背景在于考察变换器模型在表达概念时的简洁性。以往的研究通常采用有限状态自动机和线性时序逻辑（LTL）等传统表示方式来描述和验证语言或逻辑公式，但这些方法在表达上可能不够简洁。因此，需要提出新的方法和概念来评估变换器的表达能力，特别关注它们在描述概念时的简洁性是否超越传统的表示方法，并研究基于变换器模型验证相关属性的复杂性问题。", "innovation": "该研究的创新点在于将'简洁性'作为评价变换器表达能力的一个指标，通过证明变换器能够以比传统表示方式（如有限状态自动机和LTL公式）更为简洁的方式表示形式语言，从而展示了变换器的高表达能力。同时，研究还揭示了基于变换器模型验证属性的问题是计算上不可解决的（EXPSpace完全问题）。", "conclusion": "该研究证实了变换器在表达形式语言方面具有高度简洁性和强大的表达能力，同时也表明基于变换器的属性验证问题具有很高的计算复杂性，属于EXPSpace完全问题。这为理解变换器在自然语言处理、程序理解和自动验证等领域的应用提供了新的视角和理论支持。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19733", "html_url": "https://arxiv.org/abs/2510.19733", "title": "Zhyper: 因子超网络用于条件化大型语言模型微调", "title_en": "Zhyper: Factorized Hypernetworks for Conditioned LLM Fine-Tuning", "authors": "M. H. I. Abdalla,Zhipin Wang,Christian Frey,Steffen Eger,Josif Grabocka", "background": "大型语言模型（LLM）的条件化是指指导LLM按照特定文化规范、政治倾向或其他指定语义条件生成内容。虽然提示工程技术有助于控制LLM的行为，但由于预训练和对齐数据集的归纳偏见，这种方法并不总能达到预期的条件化效果。先前的研究主要集中在通过直接调节LoRA权重对LLM进行微调，但这种方法会引入大量参数。因此，需要一种更高效的微调方法。", "innovation": "我们提出了一种称为Zhyper的参数高效因子超网络框架，可以从文本描述中生成上下文感知的LoRA适配器。实验表明，Zhyper在多个基准测试中实现了与最先进的基线模型相当的性能，但参数数减少最多可达26倍。此外，我们还扩展了Zhyper到文化对齐，展示了其在处理领域外设置时更好的泛化能力和对细微上下文价值更好的捕捉能力。", "conclusion": "Zhyper通过高效的因素超网络框架实现了对LLM的条件化微调，与现有先进模型相比，参数数量大幅减少同时保持了良好的性能，特别是在处理细微的上下文价值和跨域泛化方面表现更好。"}
{"llm_update_time": "20251026", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19788", "html_url": "https://arxiv.org/abs/2510.19788", "title": "基准测试世界模型学习", "title_en": "Benchmarking World-Model Learning", "authors": "Archana Warrier,Dat Nguyen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares", "background": "当前方法学习和评估世界模型与实现这一目标相偏离：训练和评估都锚定在下一帧预测，并通过在相同环境中最大化奖励来评估成功。世界模型应该支持多种下游任务和推理，包括预测未观察到的状态、估计近/远期行动后果、规划行动序列和检测动力学变化。然而，现有方法以帧预测为中心，这限制了其应用范围和灵活性，未能全面评估模型在不同任务上的表现和适应性。因此，需要一种新的评估协议来衡量模型在不同任务上的适应性和学习能力，以促进更广泛的应用和发展。", "innovation": "作者提出WorldTest协议，将无奖励交互与评分测试阶段分离，并在不同但相关的环境中进行。WorldTest是开放式的，模型应支持多种未来不可知的任务，并且与模型表示无关，这允许不同方法之间的比较。作者通过AutumnBench实证了这一协议，这是一个包含43个互动网格世界环境和129个任务的综合套件，涵盖了遮罩帧预测、规划和因果动力学变化预测。作者还比较了517名人类参与者和三个前沿模型，并发现人类表现优于模型，算力放大仅在某些环境中提升了模型性能。", "conclusion": "WorldTest提供了一个新的模板——无奖励探索、导出测试和基于行为的评分，用于评估代理对环境动力学的了解。AutumnBench揭示了世界模型学习还有很大的提升空间，为未来研究提供了重要参考。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19868", "html_url": "https://arxiv.org/abs/2510.19868", "title": "知识引导的多智能体框架在应用级软件代码生成中的应用", "title_en": "Knowledge-Guided Multi-Agent Framework for Application-Level Software Code Generation", "authors": "Qian Xiong,Bo Yang,Weisong Sun,Yiran Zhang,Tianlin Li,Yang Liu,Zhi Jin", "background": "自动化代码生成由大型语言模型 (LLMs) 驱动提高了开发效率，但生成复杂的应用级软件代码仍具挑战性。现有的多智能体框架有潜力，但在大规模应用级软件代码生成中表现不足，无法确保项目代码的合理组织结构，使代码生成过程难以维护。", "innovation": "本文提出了一种名为 KGACG 的知识引导的应用级代码生成框架，通过结合代码组织与规划代理 (COPA)、编码代理 (CA) 和测试代理 (TA) 的协作闭环，以及反馈机制，旨在将软件需求规范和架构设计文档转换为可执行代码，解决现有方法的不足，提高应用级软件开发的自动化水平。", "conclusion": "KGACG 致力于促进应用级软件开发的自动化，并通过在 Java 坦克战游戏案例研究中展示代理的协作过程，来应对挑战，实现更好的代码生成效率和可维护性。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19864", "html_url": "https://arxiv.org/abs/2510.19864", "title": "SODBench: 利用大型语言模型记录电子表格操作的方法", "title_en": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations", "authors": "Amila Indika,Igor Molybog", "background": "在商业、会计和金融领域，许多知识工作者使用电子表格。然而，缺乏系统的电子表格文档方法阻碍了自动化、协作和知识转移，这可能引起机构重要知识的流失。", "innovation": "本文介绍了电子表格操作文档化（SOD），这是一个使用AI自动生成电子表格操作的人类可读解释的任务。研究利用了大型语言模型（LLMs）来生成电子表格操作代码，但将这些代码翻译为自然语言进行SOD仍是一个较少探索的领域。为了应对这一挑战，本文提出了一个包含111个电子表格操作代码片段的基准，每个代码片段都有相应的自然语言总结。评估了五个LLMs模型：GPT-4o、GPT-4o-mini、LLaMA-3.3-70B、Mixtral-8x7B和Gemma2-9B，使用BLEU、GLEU、ROUGE-L和METEOR等指标进行评估。", "conclusion": "研究发现LLMs可以生成准确的电子表格文档，使SOD成为增强电子表格中可再现性、维护性和协作工作流的一个可行的前提步骤，尽管仍存在需要解决的挑战。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19984", "html_url": "https://arxiv.org/abs/2510.19984", "title": "关于灰盒模糊测试中的相互作用效应", "title_en": "On Interaction Effects in Greybox Fuzzing", "authors": "Konstantinos Kitsios,Marcel Böhme,Alberto Bacchelli", "background": "灰盒模糊器是一种自动软件测试工具，通过在随机序列中应用随机选择的突变器（例如，翻转位或删除字节块）来生成新的测试输入，并将所有增加覆盖的新输入添加到种子输入的库中。现有研究表明，种子输入上突变器的应用顺序可能影响灰盒模糊器的效果。", "innovation": "该研究假设，种子输入上突变器的应用顺序会影响灰盒模糊器的效果。通过实验发现，突变器对不同顺序的相互作用效应与预期相符。为此，提出了一种名为MuoFuzz的灰盒模糊器，它能够学习并选择最有可能产生有趣输入的突变器序列，从而提高模糊测试的效率。", "conclusion": "在FuzzBench和MAGMA基准测试上的实验结果表明，MuoFuzz实现了最高的代码覆盖率，并发现了一些AFL++或MOPT没有发现的漏洞。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19898", "html_url": "https://arxiv.org/abs/2510.19898", "title": "BugPilot：复杂错误生成以提高SWE技能学习的效率", "title_en": "BugPilot: Complex Bug Generation for Efficient Learning of SWE Skills", "authors": "Atharv Sonwane,Isadora White,Hyunji Lee,Matheus Pereira,Lucas Caccia,Minseon Kim,Zhengyan Shi,Chinmay Singh,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan", "background": "高质量的错误对于训练基于语言模型的软件工程(SWE)代理至关重要。以往的方法在生成错误时经常使用故意引入局部代码扰动的方式，这与实际开发过程不符。因此，研究人员需要一种新方法来生成更贴近人类代码修改模式的复杂且多样的错误，从而更有效地训练SWE代理系统。", "innovation": "提出了一种新颖的方法来生成复杂的和多样化的合成错误，该方法指导SWE代理在代码中引入新特性，从而无意中破坏测试，导致错误的生成。这种方法更好地反映了人类编写的更改模式，相比以往故意生成错误的方法，能够提供更有效的监督微调训练数据，并且在使用一半错误数据的情况下比其他错误数据集表现更好。", "conclusion": "通过使用新生成的错误和现有的错误数据集训练，FrogBoss模型在SWE-bench任务上的表现达到了32B参数的最新水平，达到了54.6%的pass@1。同样，FrogMini模型也达到了14B参数的最新水平，达到45.3%的pass@1表现，这些结果是在三次种子实验中得出的平均结果。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19860", "html_url": "https://arxiv.org/abs/2510.19860", "title": "E-Test: 持续优化的测试套件", "title_en": "E-Test: E'er-Improving Test Suites", "authors": "Ketai Qiu,Luca Di Grazia,Leonardo Mariani,Mauro Pezzè", "background": "测试套件是不完美的，测试者总是能够通过添加新的测试用例来提升测试套件的质量，从而提高目标软件系统的可靠性。然而，在大型测试套件的长期管理中，识别超出现有测试套件范围的执行场景来探索新的执行路径是非常具有挑战性和劳动密集型的。为此，本文提出了一种名为E-Test的方法，旨在通过利用生产场景中的新执行场景来补充测试套件，从而缩小实际测试中探索的执行空间与测试后的实际执行空间之间的差距。E-Test通过监控生产场景中的大量情景，识别尚未被测试的执行场景，并基于此生成新的测试用例来增强测试套件。这种方法利用了大型语言模型（LLMs）来识别当前测试套件未能充分覆盖的执行场景，并以这些场景为依据生成新的测试用例，从而扩展测试套件的测试覆盖范围。", "innovation": "E-Test方法通过利用生产场景中的新执行场景来更新测试套件，利用了大型语言模型（LLMs）来识别尚未被现有测试套件覆盖的执行场景，并生成新的测试用例以增强测试套件。通过实验证明，E-Test在识别未被测试的执行场景方面比当前最先进的方法（最高F1分为0.34）和基础语言模型（最高F1分为0.39）更有效，达到了0.55的F1分，显示出对测试套件的有效增强及其在减少手动管理工作量方面的重要性。", "conclusion": "本文提出的E-Test方法通过利用生产场景中的新执行场景来提升测试套件的测试覆盖率，通过实验证明E-Test方法能够显著提高测试套件在未被测试执行场景中的覆盖能力，从而减少手动维护测试套件的工作量。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19997", "html_url": "https://arxiv.org/abs/2510.19997", "title": "A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE),", "title_en": "A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE)", "authors": "Abraham Itzhak Weinberg", "background": "GenAI技术为组织带来了变革性的机会，但不同规模的组织在采用过程中面临不同的挑战。中型企业受到资源限制和AI专业知识不足的影响，而大型企业则面临组织复杂性和协调挑战。现有技术采纳框架（如TAM技术接受模型、TOE技术组织环境模型和DOI创新扩散理论）缺乏针对GenAI实施的具体指导，这在不同组织背景下造成了重大差距。这篇论文提出了一种名为FAIGMOE（中型企业和企业的生成人工智能采纳和集成框架）的概念性框架，旨在涵盖这两种组织类型的独特需求。", "innovation": "FAIGMOE框架结合了技术采纳理论、组织变革管理和创新扩散视角，分为四个相互关联的阶段：战略评估、规划和用例开发、实施和集成、运营化和优化。这一框架特别考虑了GenAI的特定因素，如提示工程、模型编排和幻觉管理，使其不同于通用技术采纳框架。该框架提供了可扩展的指导，适应不同组织规模和复杂性，提供了实施协议、评估工具和治理模板，需要未来研究进行实证验证。", "conclusion": "FAIGMOE是第一个明确针对中型企业和企业组织中GenAI采纳的综合概念框架，提供了可操作的实施协议、评估工具和治理模板，为未来研究提供了实证验证需求。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20041", "html_url": "https://arxiv.org/abs/2510.20041", "title": "构建系统降级的成本：Kubernetes案例研究", "title_en": "The Cost of Downgrading Build Systems: A Case Study of Kubernetes", "authors": "Gareema Ranjan,Mahmoud Alfadel,Gengyi Sun,Shane McIntosh", "background": "开发人员频繁调用构建系统，其性能会影响到生产力。现代的基于 Artifact 的构建工具能够加速构建过程，然而先前的研究表明，团队可能会因维护简便性原因而放弃这些工具，选择替代选项。虽然已有研究解释了为什么会发生这种降级，但是降级对团队的影响还没有被充分探讨。本文的研究背景即在于填补这一研究空白，对 Kubernetes 项目从基于 Artifact 的构建工具（Bazel）降级为特定语言解决方案（Go Build）进行研究并分析其影响。", "innovation": "研究创新之处在于，通过分析 Kubernetes 项目从 Bazel 到 Go Build 的全周期和增量构建过程，揭示了 Bazel 构建比 Go Build 更快，但同时会消耗更多的内存和 CPU 资源。研究还进一步探讨了这一现象在其他四个从 Bazel 降级的项目中的普遍性。通过这些分析，研究提供了关于构建工具降级可能导致的成本提升，推动了在构建工具采用过程中权衡因素的研究。", "conclusion": "本文的研究结论是，尽管有维护简便性的优势，在大型项目中放弃基于 Artifact 的构建工具往往会带来显著的性能成本。这些观察结果有助于利益相关者更好地权衡在构建工具采用过程中的成本与效益。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20340", "html_url": "https://arxiv.org/abs/2510.20340", "title": "Classport：设计用于Java的运行时依赖反省", "title_en": "Classport: Designing Runtime Dependency Introspection for Java", "authors": "Serena Cofano,Daniel Williams,Aman Sharma,Martin Monperrus", "background": "软件供应链安全的关键在于能够观察程序执行期间正在使用的依赖关系。然而，Java语言本身并不支持这一特性。", "innovation": "Classport系统通过嵌入依赖信息到Java类文件中，实现了在运行时检索依赖信息的功能，从而解决了Java不支持这一特性的缺陷。", "conclusion": "Classport在六个实际项目上进行了评估，展示了运行时识别依赖关系的可能性。Classport打开了在运行时进行完整性和校验的重要途径。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20121", "html_url": "https://arxiv.org/abs/2510.20121", "title": "开发一种用于将PL/SQL触发器迁移到Java的模型驱动重构方法：一次实践经验", "title_en": "Developing a Model-Driven Reengineering Approach for Migrating PL/SQL Triggers to Java: A Practical Experience", "authors": "Carlos J. Fernandez-Candel,Jesus Garcia-Molina,Francisco Javier Bermudez Ruiz,Jose Ramon Hoyos Barcelo,Diego Sevilla Ruiz,Benito Jose Cuesta Viera", "background": "模型驱动的软件工程（MDE）技术不仅在向前工程场景中，而且在现有系统演进中也非常有用。RAD平台在20世纪90年代兴起，由于现代软件技术的成功，许多企业开始迁移他们的RAD应用程序，例如Oracle Forms。我们的研究小组与一家软件公司合作，开发了一种将Forms触发器中的PL/SQL单体代码迁移到Java代码、分层保存的方法。", "innovation": "本文提出了一个模型驱动的重构过程，利用类似TDD的方法增量开发模型转换，并对生成的代码进行三种类型的验证。并且详细解释了重构方法的实现和验证，以及在应用MDE方面的一些问题评价。", "conclusion": "本文展示了从PL/SQL触发器到Java的迁移过程以及模型驱动的重构方法的具体实现和验证过程，同时评估了在应用MDE技术中的问题。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20403", "html_url": "https://arxiv.org/abs/2510.20403", "title": "基于FMI的增强安全性和知识产权保护的分布式协同仿真", "title_en": "FMI-Based Distributed Co-Simulation with Enhanced Security and Intellectual Property Safeguards", "authors": "Santiago Gil,Ecem E. Baş,Christian D. Jensen,Sebastian Engelsgaard,Giuseppe Abbiati,Cláudio Gomes", "background": "分布式协同仿真在不同利益相关者之间实现协作建模和仿真时起着关键作用，同时保护其知识产权（IP）。虽然协同仿真提供了隐式的IP保护，但在没有暴露于潜在黑客攻击的情况下，如何进行连续时间和混合系统的分布式协同仿真仍缺乏明确指南。", "innovation": "提出了一种基于UniFMU的增强型网络安全和知识产权保护的分布式协同仿真方法，确保连接由客户端发起，并且模型和二进制文件保存在受信任的平台上。", "conclusion": "通过在四种不同的网络设置中使用两个协同仿真示例展示了该方法的功能，并分析了IP保护下的分布与性能效率之间的权衡。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20389", "html_url": "https://arxiv.org/abs/2510.20389", "title": "软件平台中的对称性作为架构原则", "title_en": "Symmetry in Software Platforms as an Architectural Principle", "authors": "Bjorn Remseth", "background": "软件平台通常扮演着结构保持系统的作用。它们提供一致的接口和行为，在特定的变换过程中保持稳定，这些变换我们称为对称性。本文探讨了通过强制执行此类结构规律来实现架构稳健性的理念，这些规律确保在不同变换下软件平台的一致性和稳定性是关键.", "innovation": "提出了将对称性作为软件平台架构的一个核心原则，通过强制执行结构性规律来增强系统的稳健性，使之在面对特定变换时保持一致性和稳定性.", "conclusion": "本文研究了软件平台中的对称性，并将其作为架构的一个关键原则，以便系统能够在面对特定变换时保持一致性和稳健性."}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20514", "html_url": "https://arxiv.org/abs/2510.20514", "title": "面向实际应用的演绎验证：来自工业和学术界的定性调查启示", "title_en": "Toward Practical Deductive Verification: Insights from a Qualitative Survey in Industry and Academia", "authors": "Lea Salome Brugger,Xavier Denis,Peter Müller", "background": "演绎验证是确保给定系统显示预期行为的有效方法。尽管在选定项目中证明了其有用性和可行性，但演绎验证尚未成为主流技术。本文通过半结构化访谈30名来自工业和学术界的验证从业者，利用主题分析方法系统地分析数据，探讨了促进演绎验证成功应用的因素以及阻止更广泛应用的潜在问题。", "innovation": "研究揭示了几个未被充分探索的障碍，如证明维护、自动化控制不足和可用性问题，并据此提取了演绎验证的促进因素和障碍，为从业者、工具开发者和研究人员提供了具体建议，包括易用性、自动化和与现有工作流程的整合原则等。", "conclusion": "通过数据的实证研究确认了已知挑战，并进一步指出了新的障碍，为普及演绎验证奠定了基础。提出了具体的建议，促进其在更广泛领域的应用。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20211", "html_url": "https://arxiv.org/abs/2510.20211", "title": "基于AI代理的自动化云基础设施即代码校正", "title_en": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "authors": "Zhenning Yang,Hui Guan,Victor Nicolet,Brandon Paulsen,Joey Dodds,Daniel Kroening,Ang Chen", "background": "传统的云基础设施管理通过云控制台、命令行接口（CLI）和软件开发工具包（SDK）进行。最近，Infrastructure-as-Code/IaC框架（例如Terraform）越来越受欢迎。然而，当IaC与控制台、CLI或SDK结合使用时，可能会失去对外部更改的可见性，导致基础设施漂移，配置过时。之后的IaC操作可能会撤销有效的更新或触发错误。因此，需要一种自动化系统来解决IaC的漂移问题，将外部更改重新同步到IaC程序中。NSync正是为了解决这个问题而设计的系统，旨在提高基础设施管理的准确性和效率。", "innovation": "NSync是一个自动化的IaC校正系统，使用AI代理从云API调用痕迹中检测不一致变化，并更新IaC配置以反映这些变化。其创新之处在于使用人工智能代理架构，通过语言模型推断高阶意图，使用专门的工具合成交正后的IaC更新，并通过自我进化积累的知识库不断改进。此外，NSync还引入了一个新的评估管道，用于模拟现实世界的漂移场景，评估校正性能。", "conclusion": "研究结果表明，NSync在准确性和字节效率方面均优于基线。在五个真实世界Terraform项目的测试中，准确率从0.71提高到0.97，并且性能提升了1.47倍。这证明了NSync在自动校正IaC漂移方面具有强大的技术潜力和实际应用价值。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20692", "html_url": "https://arxiv.org/abs/2510.20692", "title": "探索大型语言模型在访问控制策略合成与总结方面的应用", "title_en": "Exploring Large Language Models for Access Control Policy Synthesis and Summarization", "authors": "Adarsh Vatsa,Bethel Hall,William Eiers", "background": "随着云计算的普及，越来越多的服务被托管在云端。传统的云计算系统允许管理员通过编写策略来实施访问控制规则，但这些策略需要手动编写且往往复杂易错，难以精确分析。最近，大型语言模型（LLMs）在自动化代码合成和总结方面取得了很好的效果，这使得它们有可能被用于自动生成访问控制策略或辅助理解现有策略。", "innovation": "研究了LLMs在访问控制策略合成和总结方面的有效性，发现尽管LLMs可以有效生成语法正确的策略，但它们在策略的宽容度方面存在问题，特别是当结合逻辑推理时，可达性问题更为严重。除此之外，引入了一种基于语义的请求总结方法，利用LLMs生成策略允许请求的精确描述，展示了在与符号方法结合分析现有策略方面取得了显著成果，尽管在自动化策略生成方面存在挑战，但与符号方法相结合时展示了有前景的结果。", "conclusion": "虽然凭空利用LLMs进行自动化策略生成面临诸多挑战，但在现有策略的分析中结合符号方法时展示了令人鼓舞的结果。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19877", "html_url": "https://arxiv.org/abs/2510.19877", "title": "政策治理指导下的RAG架构 - 研究设计研究", "title_en": "Policy-Governed RAG - Research Design Study", "authors": "Jean-Marie Le Ray", "background": "该论文背景聚焦于监管工作流程中的审计准备生成。在受监管的环境中，确保生成内容符合法律和内部政策的要求、保留可验证的来源证据以确保可追溯性，以及为审计员提供最终的、可携带的合规证明是至关重要的。", "innovation": "该研究提出了一个由三部分组成的政策治理RAG架构：（I）合同/控制（类似于SHRDLU），用于指导输出遵循法律和内部政策；（II）清单/路径（类似于Memex），通过加密锚定所有引用的来源证据以确保可验证的来源；（III）收据/验证（类似于Xanadu），提供最终、可携带的合规证明以供审计员使用。这一设计还补充了现有的RAG/防护栏，使政策检查可审计、可再现，并带有收据支持。", "conclusion": "本研究的目标领域包括制药行业、医疗器械、金融机构、法律界和公共部门，在这些领域内，错误的成本可能超过数千欧元，并且需要根据欧盟AI法案等法规保留审计轨迹。未来的研究可能会提前承诺发布负面结果，当任何实例不达标时。研究的指标包括至少减少20％的确定错误、p95延迟不超过900毫秒，以及不超过2.2倍的供应成本。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19938", "html_url": "https://arxiv.org/abs/2510.19938", "title": "设计一种安全且具有韧性的分布式智能手机参与者数据收集系统", "title_en": "Designing a Secure and Resilient Distributed Smartphone Participant Data Collection System", "authors": "Foad Namjoo,Neng Wan,Devan Mallory,Yuyi Chang,Nithin Sugavanam,Long Yin Lee,Ning Xiong,Emre Ertin,Jeff M. Phillips", "background": "现实世界中的健康研究需要从移动和可穿戴设备中持续且安全地收集数据。现有的数据收集方法通常依赖于用户的频繁参与，这对数据的连续性构成了挑战。MotionPI是一款基于智能手机的数据收集系统，旨在通过传感器和调查问卷在最少用户互动的情况下收集行为和健康数据。该系统结合了被动数据收集（如GPS和手腕运动数据）和生态时刻评估（EMA）调查，这两种数据收集方法可以随机触发或基于身体活动触发。MotionPI设计时考虑了现实生活中的限制，包括电池寿命有限、网络连接时断时续以及用户监督不足等问题。", "innovation": "MotionPI创新之处在于，它能够同时收集被动数据和主动响应数据，通过BLE与可穿戴设备集成，能够在弱网络环境下可靠地传输数据。此外，系统设计使得数据既能在本地存储，也能安全地上传到云服务器，并且所有数据的传输和存储都进行了加密处理。这些特性共同确保了数据的安全性和系统在复杂环境下的鲁棒性。", "conclusion": "MotionPI展示了在实际环境下进行安全管理的移动数据收集的有效解决方案，特别适用于网络物理健康研究。这个系统克服了现实生活中常见的技术挑战，保障了数据的安全性和系统的可扩展性，提供了一种改进数据收集的实用方法。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19979", "html_url": "https://arxiv.org/abs/2510.19979", "title": "SecureInfer：用于大规模语言模型部署的异构TEE-GPU架构以保护隐私关键张量", "title_en": "SecureInfer: Heterogeneous TEE-GPU Architecture for Privacy-Critical Tensors for Large Language Model Deployment", "authors": "Tushar Nayan(1),Ziqi Zhang(2),Ruimin Sun(1) ((1) Florida International University, (2) University of Illinois Urbana-Champaign)", "background": "随着大型语言模型（LLMs）在移动和边缘平台上部署的增加，如何保护这些模型免受模型提取攻击已成为紧迫的议题。然而，保护模型的隐私同时又不牺牲由不可信加速器（如GPU）带来的性能优势，这一需求带来了具有挑战性的权衡取舍。", "innovation": "SecureInfer是一种混合框架，其特点是利用异构的信任执行环境（TEEs）-GPU架构来隔离隐私关键组件，同时将计算密集型操作卸载到不可信的加速器上。通过外包方案，SecureInfer采用信息论和威胁导向的分割策略：安全敏感的组件在SGX可信环境中执行，其他线性操作（矩阵乘法）在GPU上进行加密并安全恢复在可信环境中。该框架在LLaMA-2模型上实现了一个原型，并通过性能和安全指标进行了评估。结果显示，SecureInfer提供了强有力的安全保障，同时保持了合理的性能，为设备上安全的模型推理提供了一个实用的解决方案。", "conclusion": "SecureInfer通过异构TEE-GPU架构，为大规模语言模型的隐私保护提供了一种实践性解决方案，平衡了隐私与性能之间的关系。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20739", "html_url": "https://arxiv.org/abs/2510.20739", "title": "学习分级动态程序分析中报告的Node.js包中的污染流", "title_en": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in Node.js Packages", "authors": "Ronghao Ni,Aidan Z.H. Yang,Min-Chien Hsu,Nuno Sabino,Limin Jia,Ruben Martins,Darion Cassel,Kevin Cheang", "background": "程序分析工具会产生大量候选漏洞报告，这些报告需要人工审查，这给安全分析师带来了成本高昂的挑战。如何优先处理最有可能是真实漏洞的报告是一个亟待解决的问题。", "innovation": "该论文研究了是否可以利用机器学习技术来优先处理程序分析工具报告的漏洞。论文重点关注Node.js包，并收集了包含1,883个包的基准数据集，每个包包含一个报告的ACE或ACI漏洞。论文评估了多种机器学习方法，包括经典模型、图神经网络（GNN）、大型语言模型（LLM）和结合了GNN和LLM的混合模型。基于动态程序分析工具的输出训练数据，取得了显著效果。", "conclusion": "最佳大型语言模型的F1值达到0.915，而最好的图神经网络和经典机器学习模型的F1值为0.904。领先模型在假负率低于7%的情况下，可以消除66.9%的无害包，处理每个包大约需要60毫秒。当模型调整为精确度为0.8（即所有警告中有20%的假阳性）时，可以检测出99.2%可利用的污染流，同时仅错过0.8%，显示出在真实的漏洞分级中具有强大的应用潜力。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20036", "html_url": "https://arxiv.org/abs/2510.20036", "title": "ToolScope: 通过工具合并和上下文感知筛选提高大语言模型代理工具使用", "title_en": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering", "authors": "Marianne Menglin Liu,Daniel Garcia,Fjona Parllaku,Vikas Upadhyay,Syed Fahad Allam Shah,Dan Roth", "background": "大型语言模型(LLM)代理依赖外部工具解决复杂任务，但实际工具集中往往包含冗余且命名和描述相似的工具，导致选择时出现混淆，降低了选择准确性。此外，LLMs面临严格的输入上下文限制，这妨碍了对大型工具集的有效考虑。", "innovation": "提出了ToolScope，它包括：(1) ToolScopeMerger带有自动校正的功能，用于自动审核和修复工具合并，减少冗余；(2) ToolScopeRetriever用于按查询排序和仅选择最相关的工具，压缩工具集以适应上下文限制，且不牺牲准确性。", "conclusion": "对三种最先进的LLMs和三种开源工具使用基准测试表明，ToolScope在工具选择准确性方面可带来8.38%到38.6%的提升，证明其在增强LLM工具使用方面具有有效性。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2403.17382", "html_url": "https://arxiv.org/abs/2403.17382", "title": "开发团队多久更新其易受攻击的依赖项？", "title_en": "How Quickly Do Development Teams Update Their Vulnerable Dependencies?", "authors": "Imranur Rahman,Ranindya Paramitha,William Enck,Laurie Williams", "background": "随着软件中包含的第三方依赖项版本出现漏洞，行业实践者越来越关注直接和间接包含的这些漏洞版本。为此，鼓励项目迅速更新到非漏洞版本，并且在选择要使用的依赖项时要谨慎。研究人员已经提出了测量开发团队在维护依赖项更新方面响应性的度量方法：平均更新时间（MTTU）和平均修复时间（MTTR）。然而，现有指标未能捕捉到诸如考虑浮动版本和优先考虑近期更新等重要细微之处，导致对开发团队的更新实践的反映不够准确。", "innovation": "本文提出了两个新的度量指标，即依赖项更新时间和易受攻击依赖项的修复时间（MTTR），以克服现有指标的局限性。通过163,207个npm（117,129个）、PyPI（42,777个）和Cargo（3,301个）包的实证研究，探讨生态系统在更新时间方面的差异以及哪些包特征会影响更新时间。", "conclusion": "大多数包的依赖项更新实践相对较快。我们进一步研究了在缺乏漏洞数据的情况下，MTTU是否可以作为MTTR的替代指标。尽管没有足够的统计证据表明MTTU是MTTR的一个有效替代指标，但我们的发现表明，在缺乏漏洞数据时，MTTU只能部分地（可能使用，但需要谨慎）用作MTTR的替代指标。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20521", "html_url": "https://arxiv.org/abs/2510.20521", "title": "大规模语言模型在故障定位中的应用：一项实证研究", "title_en": "Large Language Models for Fault Localization: An Empirical Study", "authors": "YingJian Xiao,RongQun Hu,WeiWei Gong,HongWei Li,AnQuan Jie", "background": "大规模语言模型（LLMs）已经在代码相关的任务中展现出了显著的能力，特别是在自动程序修复方面。然而，修复的效果高度依赖于上游故障定位的表现，而这一方面的全面评估目前仍然缺乏。本文对LLMs在语句级代码故障定位任务中进行了系统性实证研究，评估了开源模型（Qwen2.5-coder-32b-instruct, DeepSeek-V3）和闭源模型（GPT-4.1 mini, Gemini-2.5-flash）在HumanEval-Java和Defects4J数据集上的故障定位能力。研究还调查了不同提示策略（包括标准提示、少量示例提示和链式推理提示）对模型性能的影响，主要从准确性、时间效率和经济成本维度进行分析。", "innovation": "研究发现，结合错误报告上下文显著提升了模型性能。少量示例学习在性能提升上表现出潜力但边际回报逐渐减少，而链式推理的有效性高度依赖于模型本身的推理能力。这项研究不仅揭示了不同类型模型在故障定位任务中的性能特征和权衡，还为提高故障定位效果提供了有价值的策略指导。", "conclusion": "本文系统研究了LLMs在语句级代码故障定位中的表现，比较了开源和闭源模型的性能，并探讨了不同提示策略对模型性能的影响。研究结果表明，结合错误报告上下文可以显著提升模型性能。此外，少量示例学习和链式推理在一定程度上可以改善性能，但其效果受到模型自身推理能力的影响。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.09601", "html_url": "https://arxiv.org/abs/2506.09601", "title": "LLMs在自动SATD分类构建中的进展如何？", "title_en": "How Far Have LLMs Come Toward Automated SATD Taxonomy Construction?", "authors": "Sota Nakashima,Yuta Ishimoto,Masanari Kondo,Tao Xiao,Yasutaka Kamei", "background": "技术债务是指代码质量低下的问题，当开发者故意引入这种债务时，被称为自我承认的技术债务（SATD）。SATD会阻碍软件维护，因此识别其类别对于发现质量问题至关重要。传统的分类构建需要手动检查SATD注释及其周围的代码，这既耗时又耗力，由于注释者的主观性，结果往往不一致。", "innovation": "研究使用了大型语言模型（LLMs）来生成SATD分类，设计了一个结构化的、LLM驱动的流水线来模拟研究人员通常遵循的分类构建步骤。该流水线在量子软件、智能合约和机器学习三个领域的SATD数据集上进行了评估，成功恢复了先前研究中报告的特定领域类别，并在两小时内生成分类，成本低于1美元，甚至在最大数据集上也是如此。", "conclusion": "研究表明，尽管完全自动化仍然具有挑战性，但LLMs可以支持半自动SATD分类构建。此外，这项工作为未来研究自动分类生成开辟了新途径，例如在其他领域自动生成分类。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2410.05641", "html_url": "https://arxiv.org/abs/2410.05641", "title": "为神经策略合成高效且允许的程序化运行时盾牌", "title_en": "Synthesizing Efficient and Permissive Programmatic Runtime Shields for Neural Policies", "authors": "Jieke Shi,Junda He,Zhou Yang,Đorđe Žikelić,David Lo", "background": "由于神经网络策略在控制系统中的应用日益广泛，确保其安全性和可靠性已成为关键的软件工程任务。现有方法生成的程序化运行时盾通常要么计算成本高，要么不够宽松，导致系统开销高且不必要的干预增加。为此，本研究旨在通过引入Aegis框架来解决上述挑战。Aegis通过将寻找运行时盾的问题转化为草图程序合成问题，并提出一种结合反例引导归纳合成和贝叶斯优化的新方法来解决这一问题。Aegis合成的程序化运行时盾可以帮助纠正神经策略中的所有不安全指令，同时减少系统开销，并提供更好的宽松度。", "innovation": "Aegis框架通过将寻找运行时盾的问题转化为草图程序合成问题，并提出一种结合反例引导归纳合成和贝叶斯优化的新方法来解决这一问题。这种方法能够生成轻量且宽松的程序化运行时盾，有效减少了系统开销和不必要的干预次数，相比现有最先进的方法，Aegis实现了显著的性能提升，包括减少2.2倍的时间开销和3.9倍的内存使用，同时平均减少了1.5倍的干预次数，从而更好地保证系统的允许性。", "conclusion": "研究结果表明，通过Aegis合成的程序化运行时盾能够纠正所有来自神经策略的不安全指令，确保系统在所有时间点都不违反任何期望的安全属性。与现有最先进的方法相比，Aegis的盾牌在时间开销和内存使用方面分别实现了2.2倍和3.9倍的降低，显示了它们的轻量性。此外，Aegis的盾牌平均较少1.5倍的干预次数，体现了更好的允许性。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20679", "html_url": "https://arxiv.org/abs/2510.20679", "title": "Java除冗余工具的正确性和精确性基准测试", "title_en": "A Soundness and Precision Benchmark for Java Debloating Tools", "authors": "Jonas Klauke,Tom Ohlmer,Stefan Schott,Serena Elisa Ponta,Wolfram Fischer,Eric Bodden", "background": "现代软件开发中，代码通过引入库作为依赖项来复用。软件项目通常包含约36个依赖项，其中80%是传递依赖项。研究显示只有一小部分依赖项在运行时是必需的，并且甚至在这些必需的依赖项中，许多程序结构仍然未被使用，增加了不必要的代码量。这种现象导致了除冗余工具的发展，这些工具可以在精确性和完整性的平衡中移除不需要的依赖项和程序结构。为了系统地评估这一权衡，研究者们开发了Deblometer，这是一个由59个测试用例组成的微基准，这些测试用例旨在评估除冗余工具对多种Java语言特性的支持。这些测试用例包括手动编写的完整准确性的基准，使得能够精确测量正确性和精确性。使用Deblometer，研究者们评估了三种流行的Java除冗余工具：Deptrim、JShrink和ProGuard。评估结果表明所有工具都移除了必要的程序结构，这导致了语义上的改变或执行失败。这一体现了动态类加载特性在所有评估工具中引入了不正确性。比较结果显示Deptrim保留了更多带有冗余代码的类和方法，而ProGuard则删除了更多的必要构造。JShrink在处理注解的支持方面有限，导致除冗余后的结果被损坏。这些正确性问题强调了需要改进除冗余工具以确保稳定的和可靠的除冗余软件的必要性。", "innovation": "开发了Deblometer，这是一种微基准测试，包含59个测试用例，可以评估Java除冗余工具对多种Java语言特性的支持。每个测试用例都包括一个手动编写的基准，以精确测量正确性和精确性。此外，该研究探讨了三种流行的Java除冗余工具的不正确性问题，特别是在处理动态类加载和注解支持方面。", "conclusion": "所有Java除冗余工具都移除了必要的程序结构，这可能导致脚本语义上的改变或执行失败。这些工具在处理动态类加载和注解支持方面存在不正确性问题，显示了需要改善除冗余工具以确保除冗余后的软件稳定性和可靠性。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2401.08281", "html_url": "https://arxiv.org/abs/2401.08281", "title": "Faiss库", "title_en": "The Faiss library", "authors": "Matthijs Douze,Alexandr Guzhva,Chengqi Deng,Jeff Johnson,Gergely Szilvasy,Pierre-Emmanuel Mazaré,Maria Lomeli,Lucas Hosseini,Hervé Jégou", "background": "当前AI应用程序正在快速增长，因此需要存储和索引的嵌入向量的数量也在增加。Faiss库专门用于向量相似性搜索，这是向量数据库的核心功能。Faiss是一个用于索引、搜索、聚集、压缩和转换向量的工具包，用于处理大量嵌入向量的数据管理任务", "innovation": "本文描述了向量搜索的权衡空间，并详细说明了Faiss的设计原则，包括其结构、优化方法以及接口设计。并通过基准测试关键功能，并讨论了一些选定的应用场景，以突出其广泛应用性", "conclusion": "文章结尾总结了Faiss图书馆的关键特性及其广泛应用，强调了其在处理大规模嵌入向量数据方面的效果"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08609", "html_url": "https://arxiv.org/abs/2510.08609", "title": "在减少依赖过时和漏洞方面，固定版本还是浮动版本更好？", "title_en": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?", "authors": "Imranur Rahman,Jill Marley,William Enck,Laurie Williams", "background": "开发者经常使用版本约束来指定项目所需的依赖项的可接受版本。固定版本可以降低变更风险，但需要手动管理过时和脆弱依赖项的替换。而浮动版本可以自动获得错误修复和安全更新，但存在变更风险。安全从业者建议固定版本以防止软件供应链攻击，如恶意包更新。尽管固定版本是最紧的版本约束类型，它最可能导致依赖项过时。然而，不同版本约束类型导致依赖项过时或脆弱的概率变化尚不清楚。", "innovation": "本研究通过大规模实证评估，探讨不同版本约束类型对依赖项过时或脆弱概率的影响，发现最常用的版本约束类型是浮动次要版本，固定版本是其次。同时，研究发现较大版本浮动是最不可能导致依赖项过时，较小版本浮动是最不可能导致依赖项脆弱。", "conclusion": "本研究通过实证方法，揭示了不同版本约束类型对软件依赖项的更新和脆弱性影响的规律，有助于开发者根据具体情况做出更合理的版本约束选择。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.19271", "html_url": "https://arxiv.org/abs/2507.19271", "title": "多语言语言模型在代码审查中的微调：工业C#项目的实证研究", "title_en": "Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects", "authors": "Igli Begolli,Meltem Aksoy,Daniel Neider", "background": "代码审查对于维护软件质量至关重要，但在工业环境中往往耗时且认知压力大。recent advancements in language models (LMs) recently为代码审查任务的自动化开辟了新途径。本研究通过实验评估了一种方法，即在开源语言模型上进行单语微调，针对工业环境中关键的三个代码审查任务，即代码变化质量估计、审查评论生成和代码优化。研究基于C#特定的数据集进行模型微调，并探索不同的编程语言和自然语言配置对模型性能的影响，特别是在评论生成方面的表现。同时，将微调后的模型与软件分析工具和人类审查员进行比较，以评估它们在实际环境中的实用性。研究结果显示，单语微调相较于多语言基线能提高模型的准确性和相关性。尽管语言模型在支持代码审查流程方面非常有效，特别是在处理重复性任务时，人类审查员仍在这方面表现更优，特别是在复杂的语义变化处理方面。研究强调了语言对齐和任务特定适应对优化自动化代码审查的重要性。", "innovation": "通过单语微调工业化C#项目的开源语言模型，实验评估其在三个关键代码审查任务上的性能。研究探索了训练数据中不同编程语言和自然语言配置对模型性能的影响，特别是评论生成任务，同时也将微调后的模型与现有自动化软件分析工具和人类审查员进行相比，评估它们的实用性和有效性。该研究展示了单语微调方法在提高模型准确性和相关性方面优于多语言基线模型。", "conclusion": "单语微调方法可以显著改善开源语言模型在代码审查自动化中的性能，尤其是对于代码变化质量估计、评论生成和代码优化等任务。尽管语言模型在处理重复性任务时非常有效，但在处理复杂的语义变化时依然不如人类审查员。研究强调了语言对齐和任务特定适应对于优化语言模型在自动化代码审查中的重要性。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.03712", "html_url": "https://arxiv.org/abs/2510.03712", "title": "在高性能软件系统中检测和预防潜隐藏险积累", "title_en": "Detecting and Preventing Latent Risk Accumulation in High-Performance Software Systems", "authors": "Jahidul Arafat,Kh.M. Moniruzzaman,Shamim Hossain,Fariha Tasmin", "background": "现代分布式系统采用激进的优化策略，这些策略创建了隐含风险——这些风险在特殊情况下的高性能会隐藏严重的脆弱性，直到缓存故障时负载放大100倍并导致级联崩溃。当前可靠性工程主要关注响应性事故处理，而非预防优化引起的脆弱性。", "innovation": "本文提出了第一个全面框架，通过集成数学建模、智能扰动测试和风险意识的性能优化来系统地检测、预防和优化潜在风险。引入了潜隐藏险指数（LRI），其与事故严重性高度相关（r=0.863，p<0.001）。框架结合了三个系统：HYDRA使用六种优化意识的扰动策略，发现89.7%的风险；RAVEN提供92.9%精度和93.8%召回率的连续生产监控；APEX实现风险意识优化，保持96.6%的基线性能，降低59.2%的潜在风险。评估显示统计验证强（Cohen d>2.0），高度可重复（r>0.92）。生产部署在24周内降低了69.1%的平均恢复时间，78.6%的事故严重性，预防了81次事故，年平均经济收益1.44M美元，投资回报率为3.2个月。", "conclusion": "这种做法将可靠性工程从被动事故管理转变为预防性风险意识优化。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.13938", "html_url": "https://arxiv.org/abs/2505.13938", "title": "CLEVER: 一个正式验证代码生成的精心编排基准", "title_en": "CLEVER: A Curated Benchmark for Formally Verified Code Generation", "authors": "Amitayush Thakur,Jasper Lee,George Tsoukalas,Meghana Sistla,Matthew Zhao,Stefan Zetzsche,Greg Durrett,Yisong Yue,Swarat Chaudhuri", "background": "随着自然语言模型（LLMs）的快速发展，端到端的代码生成验证变得更加重要。然而，当前的基准测试可能存在问题，如监督测试案例、LLM生成的注释、泄露实施逻辑的规范或允许空洞解决方案的情况。这种背景下，需要一个高质量且精心编排的基准来评估不同模型在正式验证代码生成方面的性能。", "innovation": "提出了一种名为${\rm C{\rm LEVER}}$的高质量、精心编排的基准，包含161个问题。每个问题都包括生成与已知规范匹配的规范任务和生成满足此规范的Lean实现任务。与以前的基准不同，${\rm C{\rm LEVER}}$避免了上述问题，所有输出均使用Lean的类型检查器进行事后验证，确保机器可检查的正确性。使用此基准评测了一些基于先进语言模型的少量提示和代理方法，并确立了它作为程序合成和形式推理挑战性前沿基准的地位。", "conclusion": "${\rm C{\rm LEVER}}$基准测试可在GitHub和HuggingFace上找到，所有评估代码也已公开。这些结果显示现有的方法在实现全面验证方面仍然存在挑战。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.14856", "html_url": "https://arxiv.org/abs/2509.14856", "title": "CodeFuse-CR-Bench: 适用于 Python 项目全面代码审查评估的基准", "title_en": "CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects", "authors": "Hanyang Guo,Xunjin Zheng,Zihan Liao,Hang Yu,Peng DI,Ziyin Zhang,Hong-Ning Dai", "background": "自动化代码审查（CR）是大语言模型（LLMs）的关键应用，但由于“现实差距”的阻碍，进步受限：现有的基准测试评估模型在孤立的子任务上使用简化和上下文贫乏的数据。这未能反映真实的全面丰富的代码审查性质。为了弥合这一差距，我们引入了CodeFuse-CR-Bench，这是首个用于代码仓库级代码审查评估的全面性意识基准。该基准包含来自70个Python项目的601个高质量示例，涵盖了九个拉取请求（PR）问题领域，每个示例都提供了丰富的多维度上下文，包括关联问题、PR详细信息和仓库状态，使得可以实现端到端的评估。除了一些表面的度量，我们还提出了一种新的评估框架，该框架结合了基于规则的检查和模型判断的审查质量。", "innovation": "我们提出了CodeFuse-CR-Bench，这是首个全面性意识基准，用于代码仓库级别的代码审查评估。该基准包含来自70个Python项目的601个高质量示例，覆盖了九个拉取请求（PR）问题领域，每个示例都提供了丰富的、多维度的上下文。此外，我们提出了一种新的评估框架，结合了基于规则的检查和基于模型的审查质量判断。这是对最先进的LLM在全面的代码审查任务上的首次大规模评估，结果设置了重要的基线，揭示了不同LLM在各个方面的表现差异，并强调了对一个全面、多维度评估的必要性。", "conclusion": "研究结果确立了关键的基线，并揭示了：（1）没有单一的LLM在代码审查的所有方面都表现出色；（2）Gemini 2.5 Pro在全面性能上表现最好；（3）不同的LLM对冗余上下文的鲁棒性不同。这些发现突显了全面、多维度评估的必要性，并为推进真正智能但又实际的代码审查助手提供了可操作的洞察。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09721", "html_url": "https://arxiv.org/abs/2510.09721", "title": "LLM赋能的智能软件工程中的基准与解决方案综述", "title_en": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "authors": "Jiale Guo,Suizhi Huang,Mei Li,Dong Huang,Xingsheng Chen,Regina Zhang,Zhijiang Guo,Han Yu,Siu-Ming Yiu,Pietro Lio,Kwok-Yan Lam", "background": "大型语言模型（LLMs）在软件工程中的整合推动了从传统基于规则的系统向自主代理系统的转变，这些代理系统能够解决复杂的工程技术问题。然而，系统性进展受到缺乏对基准和解决方案之间相互关系的全面理解的阻碍。本综述填补了这一空白，提供了关于LLM驱动软件工程的第一个全面分析，涵盖了评估方法和解决方案范式，并通过详细审查了150多篇最新论文揭示了解决方案从简单的提示工程向具备规划、推理、记忆机制和工具增强能力的高级智能系统的演变。", "innovation": "本综述提出了一个涵盖两方面关键维度的分类体系：（1）解决方案，分为提示驱动、微调驱动和代理驱动范式；（2）基准，包括代码生成、翻译和修复等任务。此外，该综述通过统一的工作流程图明确了任务规定到成果交付的所有步骤，详细说明了不同解决方案范式如何应对各种复杂程度的挑战。不同于以往侧重单一方面的综述，本研究将50多个基准与相应的解决方案策略联系起来，使研究者能够根据多种评估标准识别最优方法。同时也指出了关键的研究缺口，并提出了未来方向，包括多代理协作、自我进化的系统和形式验证的整合。", "conclusion": "本综述作为一个基础指南，促进了LLM驱动软件工程的发展。我们维护着一个GitHub存储库，持续更新审查和相关论文，请访问https://this.is/repository/continuous-updates。"}
{"llm_update_time": "20251026", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.23946", "html_url": "https://arxiv.org/abs/2505.23946", "title": "学习所得：一种用于代码LLM的学习与改进多代理框架", "title_en": "Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve", "authors": "Yuanzhe Liu,Ryan Deng,Tim Kaler,Xuhao Chen,Charles E. Leiserson,Yao Ma,Jie Chen", "background": "近期研究表明，LLMs在不同类型的任务中表现出不同的技能，并且在性能上的差异性表现为不同的细粒度层次。例如，在代码优化任务中，不同的代码LLMs在不同的优化类别中表现各异，没有一个能够完全胜过其他模型。基于此观察，提出了如何在不了解每个代理模型长处的情况下利用多个LLM代理解决编程问题的方法。研究者认为，通过团队学习，每个代理能够从他人的成功和失败中吸取经验，从而提高整体性能。因此，提出了一种基于学习的知识共享合作框架。", "innovation": "提出了一个基于学习的知识共享合作框架，并设计了学习请求-存储-选择机制。该研究展示了通过这种机制，一个小型LLM团队通过学习集体经验，可以优于单一较大的LLM，甚至其他多LLM合作方法，从而有效提高代码相关任务的整体性能。", "conclusion": "通过团队合作学习机制，多个LLM代理能够相互学习并提高各自的整体性能，小型LLM团队通过更有针对性的学习可以达到甚至超越单一庞大或其它多LLM合作方法的效果。"}
