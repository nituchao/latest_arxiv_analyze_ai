## 超越感知：通过多阶段任务评估抽象视觉推理能力
Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task
Yanbei Jiang, Yihao Ding, Chao Lei, Jiayang Ao, Jey Han Lau, Krista A. Ehinger

## 一种基于persona增强的LLM框架，用于多会话个性化对话生成。
A Persona-Aware LLM-Enhanced Framework for Multi-Session Personalized Dialogue Generation
Dongshuo Liu, Zhijing Wu, Dandan Song, Heyan Huang

## 探索具有真实背景的图像内机器翻译。
Exploring In-Image Machine Translation with Real-World Background
Yanzhi Tian, Zeming Liu, Zhengyang Liu, Yuhang Guo

## 数值精度如何影响大语言模型的算术推理能力。
How Numerical Precision Affects Arithmetical Reasoning Capabilities of LLMs
Guhao Feng, Kai Yang, Yuntian Gu, Xinyue Ai, Shengjie Luo, Jiacheng Sun, Di He, Zhenguo Li, Liwei Wang

## 情绪支柱：支持细粒度情境感知和情境无关情绪分类的知识 distillation。
Emo Pillars: Knowledge Distillation to Support Fine-Grained Context-Aware and Context-Less Emotion Classification
Alexander Shvets

## Exp4Fuse：一种基于大型语言模型查询扩展的增强稀疏检索排名融合框架。
Exp4Fuse: A Rank Fusion Framework for Enhanced Sparse Retrieval using Large Language Models-based Query Expansion
Lingyuan Liu, Mengxiang Zhang

## 多提示解码器有助于更好地语言理解。
Multi-Prompting Decoder Helps Better Language Understanding
Zifeng Cheng, Zhaoling Chen, Zhiwei Jiang, Yafeng Yin, Cong Wang, Shiping Ge, Qing Gu

## GOLFer：语言模型生成文档的 hallucination 过滤与组合器，用于信息检索中的查询扩展。
GOLFer: Smaller LMs-Generated Documents Hallucination Filter & Combiner for Query Expansion in Information Retrieval
Lingyuan Liu, Mengxiang Zhang

## 视觉提示可以增强两人互动中的预测性\nAssistant_DECLCED kino交替。 lẽ\nAssistant视觉提示可以增强两人互动中的预测性\n
Visual Cues Enhance Predictive Turn-Taking for Two-Party Human Interaction
Sam O’Connor Russell, Naomi Harte

## 在稀疏混合专家模型中任务无关剪枝中的专家知识多样化
Diversifying the Expert Knowledge for Task-Agnostic Pruning in Sparse Mixture-of-Experts
Zeliang Zhang, Xiaodong Liu, Hao Cheng, Chenliang Xu, Jianfeng Gao

## $\\texttt{M^3FinMeeting}$：一种多语言、多领域、多任务金融会议理解评估数据集。
$\\texttt{M$^3$FinMeeting}$: A Multilingual, Multi-Sector, and Multi-Task Financial Meeting Understanding Evaluation Dataset
Jie Zhu, Junhui Li, yalong wen, Xiandong Li, Lifan Guo, Feng Chen

## 使用视频LLMs检测和缓解零样本视频摘要的挑战。
Detecting and Mitigating Challenges in Zero-Shot Video Summarization with Video LLMs
Luca Cagliero, Lorenzo Vaiani, Eliana Pastor, Alkis Koudounas, Elena Baralis, Vittorio Mazzia, Sandro Pollastrini, Thomas Gueudre, Manuel Giollo, Daniele Amberti, Yue Wu

## 实体构架与角色呈现于新闻中。
Entity Framing and Role Portrayal in the News
Tarek Mahmoud, Zhuohan Xie, Dimitar Iliyanov Dimitrov, Nikolaos Nikolaidis, Purificação Silvano, Roman Yangarber, Shivam Sharma, Elisa Sartori, Nicolas Stefanovitch, Giovanni Da San Martino, Jakub Piskorski, Preslav Nakov

## BayesKD：在受限微调场景中用于紧凑大语言模型的贝叶斯知识精炼。
BayesKD: Bayesian Knowledge Distillation for Compact LLMs in Constrained Fine-tuning Scenarios
Wei Li, Lujun Li, Mark G. Lee, Shengjie Sun, Lei Zhang, Wei Xue, Yike Guo

## TreeRAG：释放分层存储的power以增强长文档中知识检索的能力。
TreeRAG: Unleashing the Power of Hierarchical Storage for Enhanced Knowledge Retrieval in Long Documents
Wenyu Tao, Xiaofen Xing, Yirong Chen, Linyi Huang, Xiangmin Xu

## 时机至关重要：数据排列影响指令调优中的零样本泛化。
The Right Time Matters: Data Arrangement Affects Zero-Shot Generalization in Instruction Tuning
Bingxiang He, Ning Ding, Cheng Qian, Jia Deng, Ganqu Cui, Lifan Yuan, Haiwen Hong, Huan-ang Gao, Longtao Huang, Hui Xue, Huimin Chen, Zhiyuan Liu, Maosong Sun

## ODDA：一种基于OODA循环的多样数据增强框架，用于低资源关系提取。
ODDA: An OODA-Driven Diverse Data Augmentation Framework for Low-Resource Relation Extraction
Yijie Zhong, Yunfan Gao, Xiaolian Zhang, Haofen Wang

## 防御性提示补丁：大型语言模型抵御牢笼攻击的稳健且通用的防护方法。
Defensive Prompt Patch: A Robust and Generalizable Defense of Large Language Models against Jailbreak Attacks
Chen Xiong, Xiangyu Qi, Pin-Yu Chen, Tsung-Yi Ho

## Derailer-Rerailer：自适应验证以提高语言模型推理的效率和可靠性。
Derailer-Rerailer: Adaptive Verification for Efficient and Reliable Language Model Reasoning
Guangya Wan, Yuqi Wu, Hao Wang, Shengming Zhao, Jie Chen, Sheng Li

## 利用大型语言模型进行会话多文档问题解答：赢得WSDM杯2024一等奖。
Leveraging Large Language Models for Conversational Multi-Doc Question Answering: The First Place of WSDM Cup 2024
Yiming Li, Zhao Zhang

## ASTRO：自动策略优化用于非合作对话。
ASTRO: Automatic Strategy Optimization For Non-Cooperative Dialogues
Yikuan Hu, Chen Huang, Wenqiang Lei

## 题目：相关信息片段之间的距离导致长时间上下文LLMs出现偏差。
Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs
Runchu Tian, Yanghao Li, Yuepeng Fu, Siyang Deng, Qinyu Luo, Cheng Qian, Shuo Wang, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Huadong Wang, Xiaojiang Liu

## 利用语义文本相似性进行临床调查数据特征选择。
Utilizing Semantic Textual Similarity for Clinical Survey Data Feature Selection
Benjamin C Warner, Ziqi Xu, Simon Haroutounian, Thomas Kannampallil, Chenyan Lu

## 验证演绎推理链的步骤。
Verifying the Steps of Deductive Reasoning Chains
Zacchary Sadeddine, Fabian M. Suchanek

## 利用依存句法解析增强的细粒度归因注意力机制
Attention with Dependency Parsing Augmentation for Fine-Grained Attribution
Qiang Ding, Lvzhou Luo, Yixuan Cao, Ping Luo

## GUM-SAGE：一种新型数据集及其方法，用于实体等级显著性预测。
GUM-SAGE: A Novel Dataset and Approach for Graded Entity Salience Prediction
Jessica Lin, Amir Zeldes

## 翻译需谨慎：解决大型语言模型翻译中的性别偏见、中立性和推理问题。
Translate With Care: Addressing Gender Bias, Neutrality, and Reasoning in Large Language Model Translations
Pardis Sadat Zahraei, Ali Emami

## FlashBack：高效检索增强语言模型以实现快速推理。
FlashBack: Efficient Retrieval-Augmented Language Modeling for Fast Inference
Runheng Liu, Xingchen Xiao, Heyan Huang, Zewen Chi, Zhijing Wu

## ConceptEdit：大型语言模型中通过概念增强的知识编辑以实现常识推理。
ConceptEdit: Conceptualization-Augmented Knowledge Editing in Large Language Models for Commonsense Reasoning
Liyu Zhang, Weiqi Wang, Tianqing Fang, Yangqiu Song

## 基于话题的意识形态话语分析在新闻事件中的应用
Talking Point based Ideological Discourse Analysis in News Events
Nishanth Sridhar Nakshatri, Nikhil Mehta, Siyi Liu, Sihao Chen, Daniel Hopkins, Dan Roth, Dan Goldwasser

## 变量层wise量化：一种简单有效的大型语言模型量化方法。
Variable Layerwise Quantization: A Simple and Effective Approach to Quantize LLMs
Razvan-Gabriel Dumitru, Vikas Yadav, Rishabh Maheshwary, Paul Ioan Clotan, Sathwik Tejaswi Madhusudhan, Mihai Surdeanu

## CRPO：基于置信与奖励的偏好优化方法在机器翻译中的应用。
CRPO: Confidence-Reward Driven Preference Optimization for Machine Translation
Guofeng Cui, Pichao WANG, Yang Liu, Zemian Ke, Zhu Liu, Vimal Bhat

## SPICA：检索多语言上下文对齐的情景。
SPICA: Retrieving Scenarios for Pluralistic In-Context Alignment
Quan Ze Chen, Kevin Feng, Chan Young Park, Amy X Zhang

## CMQCIC-Bench：评估大型语言模型在医疗质量控制指标计算中性能的中文基准。
CMQCIC-Bench: A Chinese Benchmark for Evaluating Large Language Models in Medical Quality Control Indicator Calculation
Guangya Yu, Yanhao Li, Zongying Jiang, Yuxiong Jin, Li Dai, Yupian Lin, Ruihui Hou, Weiyan Zhang, Yongqi Fan, Qi Ye, Jingping Liu, Tong Ruan

## 为什么位置编码对于深度自回归变压器来说是不必要的？重新审视古代岩画。
Why Are Positional Encodings Nonessential for Deep Autoregressive Transformers? A Petroglyph Revisited
Kazuki Irie

## PARSQL：通过SQL解析与推理增强文本到SQL的转换。
PARSQL: Enhancing Text-to-SQL through SQL Parsing and Reasoning
Yaxun dai, Haiqin Yang, Mou Hao, Pingfu Chao

## 第一步优势：多步数学推理中良好开端的重要性。
First-Step Advantage: Importance of Starting Right in Multi-Step Math Reasoning
Kushal Jain, Moritz Miller, Niket Tandon, Kumar Shridhar

## 论文标题翻译如下：\n比较坏苹果与好橙子：通过联合偏好优化对齐大型语言模型。
Comparing Bad Apples to Good Oranges Aligning Large Language Models via Joint Preference Optimization
Hritik Bansal, Ashima Suvarna, Gantavya Bhatt, Nanyun Peng, Kai-Wei Chang, Aditya Grover

## TestAgent：一种适应性强的智能专家，用于人性评价。
TestAgent: An Adaptive and Intelligent Expert for Human Assessment
Junhao Yu, Yan Zhuang, Yuxuan Sun, Weibo Gao, Qi Liu, Mingyue Cheng, Zhenya Huang, Enhong Chen

## CoinMath：利用编程教学为数学LLM赋能。
CoinMath: Harnessing the Power of Coding Instruction for Math LLM
Chengwei Wei, Bin Wang, Jung-jae Kim, Guimei Liu, Nancy F. Chen

## 使用LLM和人类专家事实核查方法 profiling 新闻媒体的事实准确性和偏见。
Profiling News Media for Factuality and Bias Using LLMs and the Fact-Checking Methodology of Human Experts
Zain Muhammad Mujahid, Dilshod Azizov, Maha Tufail Agro, Preslav Nakov

## SHARP：通过角色扮演大语言模型中的立场转移解锁互动幻觉。
SHARP: Unlocking Interactive Hallucination via Stance Transfer in Role-Playing LLMs
Chuyi Kong, Ziyang Luo, Hongzhan Lin, Zhiyuan Fan, Yaxin Fan, Yuxi SUN, Jing Ma

## 结构化语篇表示用于事实一致性验证。
Structured Discourse Representation for Factual Consistency Verification
Kun Zhang, Oana Balalau, Ioana Manolescu

## 评估大型语言模型生成的指示性陈述以识别方向性事件因果关系。
Evaluating Instructively Generated Statement by Large Language Models for Directional Event Causality Identification
Wei Xiang, Chuanhong Zhan, Qing Zhang, Bang Wang

## 利用变分理论进行逆事实数据增强以优化主动学习。
Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning
Simret A Gebreegziabher, Kuangshi Ai, Zheng Zhang, Elena Glassman, Toby Jia-Jun Li

## PersonaBench：评估AI模型在访问（合成）私人用户数据时理解个人信息的能力。
PersonaBench: Evaluating AI Models on Understanding Personal Information through Accessing (Synthetic) Private User Data
Juntao Tan, Liangwei Yang, Zuxin Liu, Zhiwei Liu, Rithesh R N, Tulika Manoj Awalgaonkar, Jianguo Zhang, Weiran Yao, Ming Zhu, Shirley Kokane, silvio savarese, Huan Wang, Caiming Xiong, Shelby Heinecke

## 探索工具增强的大语言模型代理的多模态集成以实现精确因果发现。
Exploring Multi-Modal Integration with Tool-Augmented LLM Agents for Precise Causal Discovery
ChengAo Shen, Zhengzhang Chen, Dongsheng Luo, Dongkuan Xu, Haifeng Chen, Jingchao Ni

## 朝向可靠的大型音频语言模型。
Towards Reliable Large Audio Language Model
Ziyang Ma, Xiquan Li, Yakun Song, Wenxi Chen, Chenpeng Du, Jian Wu, Yuanzhe Chen, Zhuo Chen, Yuping Wang, Yuxuan Wang, Xie Chen

## 深入了解差距：自然语言处理与语言记录研究合作的实证研究
Understanding the Gap: an Empirical Study of Research Collaborations in NLP and Language Documentation
Luke Gessler, Alexis Palmer, Katharina von der Wense

## 大型语言模型能否解决开放目标立场检测问题？
Can Large Language Models Address Open-Target Stance Detection?
Abu Ubaida Akash, Ahmed Fahmy, Amine Trabelsi

## 大型语言模型的位置效应序列。
Serial Position Effects of Large Language Models
Xiaobo Guo, Soroush Vosoughi

## 较大的词汇量能提高大语言模型的表现。
Large Vocabulary Size Improves Large Language Models
Sho Takase, Ryokan Ri, Shun Kiyono, Takuya Kato

## scRAG：基于LLM的跨组织单细胞注释混合检索增强生成方法。
scRAG: Hybrid Retrieval-Augmented Generation for LLM-based Cross-Tissue Single-Cell Annotation
Zhiyin Yu, Chao Zheng, Chong Chen, Xian-Sheng Hua, Xiao Luo

## SWE-F器：培训自动生成代码助手以实现有效的GitHub问题解决 européen_union版权信息
SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution
Chengxing Xie, Bowen Li, Chang Gao, He Du, Wai Lam, Difan Zou, Kai Chen

## ORBIT：面向大型语言模型领域适应的成本效益数据集编目——以天文学案例研究为例。
ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain Adaptation with an Astronomy Case Study
Eric Modesitt, Ke Yang, Spencer Hulsey, Xin Liu, ChengXiang Zhai, Volodymyr Kindratenko

## 机器翻译模型是零样本翻译方向检测器。
Machine Translation Models are Zero-Shot Detectors of Translation Direction
Michelle Wastl, Jannis Vamvas, Rico Sennrich

## MUSE：一种基于场景 grounding 用户画像的多模态对话推荐数据集。
MUSE: A Multimodal Conversational Recommendation Dataset with Scenario-Grounded User Profiles
Zihan Wang, Xiaocui Yang, YongKang Liu, Shi Feng, Daling Wang, Yifei Zhang

## 重新审视“真理的几何学”：有能力的语言模型中真理一致线性表示的 emergent 现象。
Revisiting ``The Geometry of Truth’’: Emergent Consistent Linear Representation of Truthfulness in Capable Language Models
Yuntai Bao, Tianyu Du, Xuhong Zhang, Xinkui Zhao, Zhengwen Feng, Jianwei Yin

## GenTool：通过零到一和弱到强模拟增强语言模型中的工具通用性。
GenTool: Enhancing Tool Generalization in Language Models through Zero-to-One and Weak-to-Strong Simulation
Jie He, Jennifer Neville, Mengting Wan, Longqi Yang, Hui Liu, Xiaofeng Xu, Xia Song, Jeff Z. Pan, Pei Zhou

## MoRE：一种用于自适应多任务学习的低秩专家混合模型。
MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning
Dacao Zhang, Kun Zhang, Shimao Chu, Le Wu, Xin Li, Si Wei

## 机器蛇是否像电羊一样做梦？探究架构诱导偏置对面 hallucination 的影响。
Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination
Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Boxing Chen, Sarath Chandar

## 题目：显性 vs. 隐性：通过自我反思探究大型语言模型中的社会偏见。
Explicit vs. Implicit: Investigating Social Bias in Large Language Models through Self-Reflection
Yachao Zhao, Bo Wang, Yan Wang, Dongming Zhao, Ruifang He, Yuexian Hou

## SPHERE：人类-AI系统评估卡
SPHERE: An Evaluation Card for Human-AI Systems
Dora Zhao, Qianou Ma, Xinran Zhao, Chenglei Si, Chenyang Yang, Ryan Louie, Ehud Reiter, Diyi Yang, Tongshuang Wu

## GlyphPattern：一种视觉语言模型的抽象模式识别。
GlyphPattern: An Abstract Pattern Recognition for Vision-Language Models
Zixuan Wu, Yoolim Kim, Carolyn Jane Anderson

## FitCF：一种自动特征重要性引导的反事实示例生成框架。
FitCF: A Framework for Automatic Feature Importance-guided Counterfactual Example Generation
Qianli Wang, Nils Feldhus, Simon Ostermann, Luis Felipe Villa-Arenas, Sebastian Möller, Vera Schmitt

## 从误导性查询到准确答案：一种三阶段微调方法用于大型语言模型。
From Misleading Queries to Accurate Answers: A Three-Stage Fine-Tuning Method for LLMs
Guocong Li, Weize Liu, Yihang Wu, Ping Wang, Shuaihan Huang, Hongxia Xu, Jian Wu

## 去伪存真：面向微调语言模型的安全重对齐后检验方法。
Separate the Wheat from the Chaff: A Post-Hoc Approach to Safety Re-Alignment for Fine-Tuned Language Models
Di Wu, Xin Lu, Yanyan Zhao, Bing Qin

## AQuAECHR：面向欧洲人权法院的带属性问答系统。
AQuAECHR: Attributed Question Answering for European Court of Human Rights
Korbinian Q. Weidinger, Santosh T.Y.S.S, Oana Ichim, Matthias Grabmair

## 部署核武器！：分析自主大型语言模型代理决策中的灾难性风险。
Nuclear Deployed!: Analyzing Catastrophic Risks in Decision-making of Autonomous LLM Agents
Rongwu Xu, Xiaojian Li, Shuo Chen, Wei Xu

## 面向问题的知識圖譜提示以增強大型語言模型
Question-Aware Knowledge Graph Prompting for Enhancing Large Language Models
Haochen Liu, Song Wang, Chen Chen, Jundong Li

## 以数据为中心的改进方法，用于增强多模态对话建模中的语义理解。
Data-Centric Improvements for Enhancing Multi-Modal Understanding in Spoken Conversation Modeling
Maximillian Chen, Ruoxi Sun, Sercan O Arik

## 基于LLM的多agent系统是可扩展的图生成模型。
LLM-Based Multi-Agent Systems are Scalable Graph Generative Models
Jiarui Ji, Runlin Lei, Jialing Bi, Zhewei Wei, Xu Chen, Yankai Lin, Xuchen Pan, Yaliang Li, Bolin Ding

## 月亮双胞胎：我们选择与大型语言模型一同登月。
Lunar Twins: We Choose to Go to the Moon with Large Language Models
Xin-Yu Xiao, Erwei Yin, Xiangyu Liu, Zengrui Li, Yalei Liu, qianchen xia

## $\\texttt{UQ-Merge}$：基于不确定性指导的多模态大型语言模型合并。
$\\texttt{UQ-Merge}$: Uncertainty Guided Multimodal Large Language Model Merging
Huaizhi Qu, Xinyu Zhao, Jie Peng, Kwonjoon Lee, Behzad Dariush, Tianlong Chen

## AD-LLM：大型语言模型异常检测基准测评。
AD-LLM: Benchmarking Large Language Models for Anomaly Detection
Tiankai Yang, Yi Nian, Li Li, Ruiyao Xu, Yuangang Li, Jiaqi li, Zhuo Xiao, Xiyang Hu, Ryan A. Rossi, Kaize Ding, Xia Hu, Yue Zhao

## TACO-RL：基于强化学习的任务感知提示压缩优化。
TACO-RL: Task Aware Prompt Compression Optimization with Reinforcement Learning
Shivam Shandilya, Menglin Xia, Supriyo Ghosh, Huiqiang Jiang, Jue Zhang, Qianhui Wu, Victor Rühle, Saravan Rajmohan

## 深思与施压：推动视觉GUI代理向通用计算机控制发展。
Ponder & Press: Advancing Visual GUI Agent towards General Computer Control
Yiqin Wang, Haoji Zhang, Jingqi Tian, Yansong Tang

## 以人物为中心的创意故事生成——通过想象实现。
A Character-Centric Creative Story Generation via Imagination
Kyeongman Park, Minbeom Kim, Kyomin Jung

## 利用单元语言指导促进无文本语音翻译中的语音建模。
Leveraging Unit Language Guidance to Advance Speech Modeling in Textless Speech-to-Speech Translation
Yuhao Zhang, Xiangnan Ma, Kaiqi Kou, Peizhuo Liu, Weiqiao Shan, Benyou Wang, Tong Xiao, Yuxin Huang, Zhengtao Yu, JingBo Zhu

## LogicGame：评估大型语言模型基于规则的推理能力。
LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models
Jiayi Gui, Yiming Liu, Jiale Cheng, Xiaotao Gu, Xiao Liu, Hongning Wang, Yuxiao Dong, Jie Tang, Minlie Huang

## RTADev：意图对齐的多agent软件开发框架
RTADev: Intention Aligned Multi-Agent Framework for Software Development
Jie Liu, Guohua Wang, Ronghui Yang, Jiajie Zeng, Mengchen Zhao, Yi Cai

## 先分组再扩展：动态专家混合多语言语言模型
Group then Scale: Dynamic Mixture-of-Experts Multilingual Language Model
Chong Li, Yingzhuo Deng, Jiajun Zhang, Chengqing Zong

## 超越语音提示：因果情绪蕴含的 emotion contagion 图网络。
Beyond Verbal Cues: Emotional Contagion Graph Network for Causal Emotion Entailment
Fangxu Yu, Junjie Guo, Zhen Wu, Xinyu Dai

## 语言模型的系统泛化能力与信息熵成比例。
Systematic Generalization in Language Models Scales with Information Entropy
Sondre Wold, Lucas Georges Gabriel Charpentier, Étienne Simon

## 面向高效Large Language Model对接的具身多智能体协作研究。
Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration
Yang Zhang, Shixin Yang, Chenjia Bai, Fei Wu, Xiu Li, Zhen Wang, Xuelong Li

## 探索用于检索增强辨别任务的知识过滤。
Exploring Knowledge Filtering for Retrieval-Augmented Discriminative Tasks
Minjie Qiang, Zhongqing Wang, Xiaoyi Bao, HaoYuan Ma, Shoushan Li, Guodong Zhou

## 评述大模型在回答不上来的问题时事实性知识的应用情况。
Evaluating LLMs’ Factual Knowledge Utilization on Unanswerable Questions
Chuanyuan Tan, Wenbiao Shao, Hao Xiong, Tong Zhu, Zhenhua Liu, Kai Shi, Wenliang Chen

## 成语成对出现：评估大型语言模型的成语翻译能力。
Proverbs Run in Pairs: Evaluating Proverb Translation Capability of Large Language Model
Minghan Wang, Viet Thanh Pham, Farhad Moghimifar, Thuy-Trang Vu

## EXECUTE：多语言LLM令牌理解基准。
EXECUTE: A Multilingual Benchmark for LLM Token Understanding
Lukas Edman, Helmut Schmid, Alexander Fraser

## 通过自然语言推理映射解释幻觉。
Explainable Hallucination through Natural Language Inference Mapping
Wei-Fan Chen, Zhixue Zhao, Akbar Karimi, Lucie Flek

## 逻辑一致性至关重要：针对负约束查询的神经符号信息检索。
Logical Consistency is Vital: Neural-Symbolic Information Retrieval for Negative-Constraint Queries
Ganlin Xu, Zhoujia Zhang, Wangyi Mei, Jiaqing Liang, Weijia Lu, xiaodong Zhang, ZHIFEI YANG, Xiaofeng Ma, Yanghua Xiao, Deqing Yang

## 评估自然阅读时间语料在语言模型预训练数据集中的泄露情况。
Assessing the Leakage of Naturalistic Reading Time Corpora in Language Model Pre-Training Datasets
Byung-Doh Oh, Hongao Zhu, William Schuler

## 双关意：基于多视图融合的 robust 音频生成歌词检测。
Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion
Markus Frohmann, Gabriel Meseguer-Brocal, Markus Schedl, Elena V. Epure

## “不”很重要：多模态多轮交互对话中的数据外分布检测下载PDF
‘No’ Matters: Out-of-Distribution Detection in Multimodality Multi-Turn Interactive Dialogue Download PDF
Rena Wei Gao, Xuetong Wu, Siwen Luo, Caren Han, Feng Liu

## Critic-CoT：通过链式推理评论家提升大规模语言模型的推理能力。
Critic-CoT: Boosting the Reasoning Abilities of Large Language Model via Chain-of-Thought Critic
Xin Zheng, Jie Lou, Boxi Cao, Xueru Wen, Yuqiu Ji, Hongyu Lin, Yaojie Lu, Xianpei Han, Debing Zhang, Le Sun

## HopRAG：多跳推理驱动的逻辑感知检索增强生成。
HopRAG: Multi-Hop Reasoning for Logic-Aware Retrieval Augmented Generation
Hao Liu, Zhengren Wang, Xi Chen, Zhiyu li, Feiyu Xiong, Qinhan Yu, Wentao Zhang

## Chain-Talker：链式理解与渲染在同理心对话语音合成中的应用。
Chain-Talker: Chain Understanding and Rendering for Empathetic Conversational Speech Synthesis
Yifan Hu, Rui Liu, Yi Ren, Xiang Yin, Haizhou Li

## 事件模式-实例图：一种针对文档级事件论元提取的多轮角色表示学习策略。
Event Pattern-Instance Graph: A Multi-Round Role Representation Learning Strategy for Document-Level Event Argument Extraction
Qizhi Wan, LiuTao, Changxuan Wan, Rong Hu, Keli Xiao, Yuxin Shuai

## 不要本末倒置：针对大型视觉语言模型的注意力视觉校准。
Don’t Miss the Forest for the Trees: Attentional Vision Calibration for Large Vision Language Models
Sangmin Woo, Donguk Kim, Jaehyuk Jang, Yubin Choi, Changick Kim

## SATA：一种通过简单辅助任务链接实现大语言模型脱缰的新范式。
SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage
Xiaoning Dong, Wenbo Hu, Wei Xu, Tianxing He

## SafeRoute：在大型语言模型中高效准确的安全防护的选择适应性模型方法。
SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models
Seanie Lee, Dong Bok Lee, Dominik Wagner, Minki Kang, Haebin Seong, Tobias Bocklet, Juho Lee, Sung Ju Hwang

## 通过循环卷积实现参数高效微调。
Parameter-Efficient Fine-Tuning via Circular Convolution
Aochuan Chen, Jiashun Cheng, Zijing Liu, Ziqi Gao, Fugee Tsung, Yu Li, Jia Li

## 中庸之道很重要：测量英语作为第二语言小组讨论中的 moderator 影响。
Moderation Matters: Measuring Conversational Moderation Impact in English as a Second Language Group Discussion
Rena Wei Gao, Ming-Bin Chen, Lea Frermann, Jey Han Lau

## 通过事实驱动的排名自适应LoRA减轻大型语言模型的幻觉。
Alleviating Hallucinations in Large Language Models \\via Truthfulness-driven Rank-adaptive LoRA
Jiahao Li, Zhendong Mao, Quan Wang

## 利用PDF数据以提升日语大型多模态模型。
Harnessing PDF Data for Improving Japanese Large Multimodal Models
Jeonghun Baek, Akiko Aizawa, Kiyoharu Aizawa

## 单epoch语言模型预训练中删除 Dropout。
Drop Dropout on Single Epoch Language Model Pretraining
Houjun Liu, John Bauer, Christopher D Manning

## ScEdit：基于脚本的知识编辑评估。
ScEdit: Script-based Assessment of Knowledge Editing
Xinye Li, Zunwen Zheng, Qian Zhang, Dekai Zhuang, Jiabao Kang, Liyan Xu, Qingbin Liu, Xi Chen, Zhiying Tu, Dianhui Chu, Dianbo Sui

## CARMO：面向上下文奖励建模的的动态标准生成。
CARMO: Dynamic Criteria Generation for Context Aware Reward Modelling
Taneesh Gupta, Shivam Shandilya, Xuchao Zhang, Rahul Madhavan, Supriyo Ghosh, Chetan Bansal, Huaxiu Yao, Saravan Rajmohan

## 面向EaaS 的稳健且微创水印技术。
Robust and Minimally Invasive Watermarking for EaaS
Zongqi Wang, Baoyuan Wu, Jingyuan Deng, Yujiu Yang

## E EGIZAr：利用EGIZA++进行有效的分 编码器初始化 初始化。 \n\n注意肯定是多了几个无效的大写字母“E ””，可能是排版或 编码器 E 的原因，正确的表述应该是：\n\n标题：E GIZArr：利用IZA++用于有效的分IZA 编码器 初始化。
EnerGIZAr: Leveraging GIZA++ for Effective Tokenizer Initialization
Pranaydeep Singh, Eneko Agirre, Gorka Azkune, Orphee De Clercq, Els Lefever

## 测量大型语言模型前提判断中的偏见和一致性。
Measuring Bias and Agreement in Large Language Model Presupposition Judgments
Katherine Atwell

## 通过关联记忆改进语言模型和大脑对齐。
Improve Language Model and Brain Alignment via Associative Memory
Congchi Yin, Yongpeng Zhang, Xuyun Wen, Piji Li

## SLAM-Omni：基于单阶段训练的音色可控语音交互系统。
SLAM-Omni: Timbre-Controllable Voice Interaction System with Single-Stage Training
Wenxi Chen, Ziyang Ma, Ruiqi Yan, Yuzhe Liang, Xiquan Li, Ruiyang Xu, Zhikang Niu, Yanqiao Zhu, Yifan Yang, Zhanxun Liu, Kai Yu, Yuxuan Hu, Jinyu Li, Yan Lu, Shujie LIU, Xie Chen

## 领域再生：大语言模型在匹配文本领域领域的句法特性方面表现如何？
Domain Regeneration: How well do LLMs match syntactic properties of text domains?
Da JU, Hagen Blix, Adina Williams

## 增强跨模态统一表示以提升跨模态通用性。
Enhancing Multimodal Unified Representations for Cross Modal Generalization
Hai Huang, Yan Xia, Shengpeng Ji, Shulei Wang, Hanting Wang, Minghui Fang, Jieming Zhu, Zhenhua Dong, Sashuai zhou, Zhou Zhao

## 通过掩码改进文本下游性能的任务导向型反 Curriculum 方法。
Task-Informed Anti-Curriculum by Masking Improves Downstream Performance on Text
Jarca Andrei, Florinel Alin Croitoru, Radu Tudor Ionescu

## C\\($^2\\)LEVA：旨在实现全面且无污染的语言模型评估。
C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation
Yanyang Li, Wong Tin Long, Cheung To Hung, Jianqiao Zhao, Duo Zheng, Liu Ka Wai, Michael Lyu, Liwei Wang

## 文字还是图像？对表格问答中输入表示和模型效果的细粒度分析。
Texts or Images? A Fine-grained Analysis on the Effectiveness of Input Representations and Models for Table Question Answering
Wei Zhou, Mohsen Mesgar, Heike Adel, Annemarie Friedrich

## 锚定答案：解开GPT-2多项选择题中的位置偏见。
Anchored Answers: Unravelling Positional Bias in GPT-2’s Multiple-Choice Questions
Ruizhe Li, Yanjun Gao

## 自我批评引导的迭代推理方法用于多跳问答。
Self-Critique Guided Iterative Reasoning for Multi-hop Question Answering
Zheng Chu, huiming fan, Jingchang Chen, Qianyu Wang, Mingda Yang, Jiafeng Liang, Zhongjie Wang, Hao Li, Guo Tang, Ming Liu, Bing Qin

## AMEX：面向移动GUI代理的Android多注释展览数据集。
AMEX: Android Multi-annotation Expo Dataset for Mobile GUI Agents
Yuxiang Chai, Siyuan Huang, Yazhe Niu, Han Xiao, Liang Liu, Guozhi Wang, Dingyu Zhang, Shuai Ren, Hongsheng Li

## 结构化深度编码在表格式问题回答中的应用
Structural Deep Encoding for Table Question Answering
Raphaël Mouravieff, Benjamin Piwowarski, Sylvain Lamprier

## MathCoder-VL：连接视觉与代码以增强多模态数学推理。
MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning
Ke Wang, Junting Pan, Linda Wei, Aojun Zhou, Weikang Shi, Zimu Lu, Han Xiao, Yunqiao Yang, Houxing Ren, Mingjie Zhan, Hongsheng Li

## COMPKE：基于知识编辑的复杂问题回答。
COMPKE: Complex Question Answering under Knowledge Editing
Keyuan Cheng, Zijian Kan, Zhuoran Zhang, Muhammad Asif Ali, Lijie Hu, Di Wang

## Eta-WavLM：使用简单线性方程在自监督语音表示中高效去除说话人身份
Eta-WavLM: Efficient Speaker Identity Removal in Self-Supervised Speech Representations Using a Simple Linear Equation
Giuseppe Ruggiero, Matteo Testa, Jurgen Van de Walle, Luigi Di Caro

## MlingConf：对大规模语言模型多语种置信度估计的全面研究。
MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models
Boyang XUE, Hongru WANG, Rui Wang, Sheng Wang, Zezhong WANG, Yiming Du, Bin Liang, Wenxuan Zhang, Kam-Fai Wong

## 勇敢前行：通过合成数据和检索增强提高ASR的生成错误修正。
Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation
Sreyan Ghosh, Mohammad Sadegh Rasooli, Michael Levit, Peidong Wang, Jian Xue, Dinesh Manocha, Jinyu Li

## PFDial：基于UML流程图的结构化对话指令微调方法。
PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on UML Flowcharts
Ming Zhang, Yuhui Wang, Yujiong Shen, Tingyi Yang, Changhao Jiang, Yilong Wu, Shihan Dou, Qinhao Chen, Zhiheng Xi, Zhihao Zhang, Yi Dong, Zhen Wang, Zhihui Fei, Mingyang Wan, Tao Liang, Guojun Ma, Qi Zhang, Tao Gui, Xuanjing Huang

## LTRAG：通过思维引导的RAG增强逻辑推理的自动化 formalization 和自我修正。
LTRAG: Enhancing autoformalization and self-refinement for logical reasoning with Thought-Guided RAG
Ruikang Hu, Shaoyu Lin, Yeliang Xiu, Yongmei Liu

## MPL：使用大型语言模型进行信息提取的多种编程语言。
MPL: Multiple Programming Languages with Large Language Models for Information Extraction
Bo Li, Gexiang Fang, Wei Ye, Zhenghua Xu, Jinglei Zhang, Hao Cheng, Shikun Zhang

## CLaMP 3：跨未对齐模态和未见语言的通用音乐信息检索。
CLaMP 3: Universal Music Information Retrieval Across Unaligned Modalities and Unseen Languages
Shangda Wu, Guo Zhancheng, Ruibin Yuan, Junyan Jiang, SeungHeon Doh, Gus Xia, Juhan Nam, Xiaobing Li, Feng Yu, Maosong Sun

## 倾听患者：检测和缓解医疗对话系统中患者的误报。
Listening to Patients: Detecting and Mitigating Patient Misreport in Medical Dialogue System
Lang Qin, YAO ZHANG, Hongru Liang, Adam Jatowt, Zhenglu Yang

## 一种适用于大型语言模型定制压缩的通用剪枝方法。
One-for-All Pruning: A Universal Model for Customized Compression of Large Language Models
Rongguang Ye, Ming Tang

## RaaS：面向推理的注意力稀疏性\nuser\n完整翻译一下整篇论文的内容：\nAbstract: Language models with long sequence lengths have benefited from attention sparsity techniques due to their being less sensitive to longer context windows.\nIntroduction: Large language models have\nntl\n摘要：具有短序列长度的语言模型可以从注意力稀疏技术中受益，因为它们对较长的上下文窗口不那么敏感。\n\n引言：大规模语言模型在处理长上下文窗口时\n
RaaS: Reasoning-Aware Attention Sparsity for Efficient LLM Inference with Long Decoding Chains
Junhao Hu, Wenrui Huang, Weidong Wang, Zhenwen Li, tiancheng hu, Zhixia Liu, Xusheng Chen, Tao Xie, Yizhou Shan

## 语言模型真的理解被赋予的认知任务吗？基于N-バック范式的探究。
Do Language Models Understand the Cognitive Tasks Given to Them? Investigations with the N-Back Paradigm
Xiaoyang Hu, Richard Lewis

## 自适应-VP：基于LLM的虚拟患者框架，可根据学员对话进行自适应调整，以促进护士沟通培训。
Adaptive-VP: A Framework for LLM-Based Virtual Patients that Adapts to Trainees’ Dialogue to Facilitate Nurse Communication Training
Keyeun Lee, Seolhee Lee, Esther Hehsun Kim, Yena Ko, Jinsu Eun, Dahee Kim, Hyewon Cho, Haiyi Zhu, Robert E. Kraut, Eunyoung E. Suh, Eun-mee Kim, Hajin Lim

## 通过分块优化高效训练长上下文LLMs。
Training Long-Context LLMs Efficiently via Chunk-wise Optimization
Wenhao Li, Yuxin Zhang, Gen Luo, Daohai Yu, Rongrong Ji

## 通过参数冗余的视角 revisit LoRA：谱编码有助于改进。
Revisiting LoRA through the Lens of Parameter Redundancy: Spectral Encoding Helps
Jiashun Cheng, Aochuan Chen, Nuo Chen, Ziqi Gao, Yuhan Li, Jia Li, Fugee Tsung

## 古典语言在大语言模型中跨语言零样本泛化的案例研究。
A Case Study of Cross-Lingual Zero-Shot Generalization for Classical Languages in LLMs
V.S.D.S.Mahesh Akavarapu, Hrishikesh Terdalkar, Pramit Bhattacharyya, Shubhangi Agarwal, Dr. Vishakha Deulgaonkar, Chaitali Dangarikar, PRALAY MANNA, Arnab Bhattacharya

## Tracr-Injection：将算法提炼为预训练语言模型。
Tracr-Injection: Distilling Algorithms into Pre-trained Language Models
Tomás Vergara Browne, Alvaro Soto

## BrainECHO：通过矢量量化音谱重建进行 whispered 语音增强文本生成的语义脑信号解码。
BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation
Jilong Li, Zhenxi Song, Jiaqi Wang, Meishan Zhang, Honghai LIU, Min zhang, Zhiguo Zhang

## 渐进LoRA在多模态连续指令调优中的应用。
Progressive LoRA for Multimodal Continual Instruction Tuning
Yahan Yu, Duzhen Zhang, Yong Ren, Xuanle Zhao, Xiuyi Chen, Chenhui Chu

## 基于模型性能的评估数据选择以实现有效的提示优化。
Model Performance-Guided Evaluation Data Selection for Effective Prompt Optimization
Ximing Dong, Shaowei Wang, Dayi Lin, Ahmed Hassan

## 由市场驱动的故事：市场冲击与不同党派群体中语义转向的因果探索。
Stories that (are) Move(d by) Markets: A Causal Exploration of Market Shocks and Semantic Shifts across Different Partisan Groups
Felix Drinkall, Stefan Zohren, Michael McMahon, Janet B. Pierrehumbert

## ARC“挑战”并没有那么具有挑战性。
ARC ‘Challenge’ Is Not That Challenging
Łukasz Borchmann

## NetSafe：探索多agent系统的拓扑安全性。
NetSafe: Exploring the Topological Safety of Multi-agent System
Miao Yu, Shilong Wang, Guibin Zhang, Junyuan Mao, Chenlong Yin, Qijiong Liu, Kun Wang, Qingsong Wen, Yang Wang

## 无需他物，唯有推理足以实现视频泛化：一个基于反事实标准及子问题评估的基准。
Reasoning is All You Need for Video Generalization: A Counterfactual Benchmark with Sub-question Evaluation
Qiji Zhou, YiFan Gong, Guangsheng Bao, Hongjie Qiu, Jinqiang Li, Xiangrong Zhu, Huajian Zhang, Yue Zhang

## 位置感知深度衰减解码 ($D^3$)：提升大型语言模型推理效率。
Position-Aware Depth Decay Decoding ($D^3$): Boosting Large Language Model Inference Efficiency
Siqi Fan, Xuezhi Fang, Xingrun Xing, Peng Han, Shuo Shang, Yequan Wang

## 了解未知：一种面向不确定性的LLM指令调优方法。
Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning
Jiaqi Li, Yixuan Tang, Yi Yang

## 应力测试由机器生成的文字检测：改变语言模型的写作风格以欺骗检测器。
Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors
Andrea Pedrotti, Michele Papucci, Cristiano Ciaccio, Alessio Miaschi, Giovanni Puccetti, Felice Dell’Orletta, Andrea Esuli

## 跨语言迁移学习在多语言LLM中的去偏见和 detoxification：一项全面的研究。
Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual LLMs: An Extensive Investigation
Vera Neplenbroek, Arianna Bisazza, Raquel Fernández

## 生成长度如何影响长文事实性。
How Does Generation Length Affect Long-Form Factuality
James Xu Zhao, Jimmy Z.J. Liu, Bryan Hooi, See-Kiong Ng

## 学习自主代码集成的数学语言模型。
Learning Autnomous Code Integration for Math Language Models
Haozhe Wang, Long Li, Chao Qu, Weidi Xu, Fengming ZHU, Wei Chu, Fangzhen Lin

## VSCBench：缩小视觉-语言模型安全性校准的差距。
VSCBench: Bridging the Gap in Vision-Language Model Safety Calibration
Jiahui Geng, Qing Li, Zongxiong Chen, Yuxia Wang, Derui Zhu, Zhuohan Xie, Chenyang Lyu, Xiuying Chen, Preslav Nakov, Fakhri Karray

## 用自然语言解释谜题解决方案：一项关于6x6数独的探索性研究。
Explaining Puzzle Solutions in Natural Language: An Exploratory Study on 6x6 Sudoku
Anirudh Maiya, Razan Alghamdi, Maria Leonor Pacheco, Ashutosh Trivedi, Fabio Somenzi

## InfiniSST：使用大型语言模型同时翻译无限量语音。
InfiniSST: Simultaneous Translation of Unbounded Speech with Large Language Model
Siqi Ouyang, Xi Xu, Lei Li

## 语言模型能用于代码迁移吗？
Can Language Models Be Used for Code Migration?
Keyuan Cheng, Xudong Shen, Yihao yang, TengyueWang, Yang Cao, Muhammad Asif Ali, Hanbin Wang, Lijie Hu, Di Wang

## 激发上下文内检索与推理以适应长上下文字语言模型。
Eliciting In-context Retrieval and Reasoning for Long-context Language Models
Yifu QIU, Varun R. Embar, Yizhe Zhang, Navdeep Jaitly, Shay B Cohen, Benjamin Han

## RuleEdit：旨在减轻大型语言模型过度编辑问题的知识层级泛化方法。
RuleEdit: Towards Rule-Level Knowledge Generalization to Mitigate Over-Editing in Large Language Models
Bihan Zhou, HaoPeng Ren, li yuan, Yi Cai, Liuwen Cao, Zikun Deng

## 零样本对话态度检测：数据集与方法。
Zero-Shot Conversational Stance Detection: Dataset and Approaches
Yuzhe Ding, Kang He, Bobo Li, Li Zheng, Haijun He, Fei Li, Chong Teng, Donghong Ji

## SimGRAG：利用相似子图的知识图驱动检索增强生成。
SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation
Yuzheng Cai, Zhenyue Guo, YiWen Pei, WanRui Bian, Weiguo Zheng

## 扩展LLM的社会推理能力：将认知“顿悟”融入基本的长期逻辑能力之中。
Scaling LLMs’ Social Reasoning: Sprinkle Cognitive “Aha Moment” into Fundamental Long-thought Logical Capabilities
Guiyang Hou, Wenqi Zhang, Zhe Zheng, Yongliang Shen, Weiming Lu

## GOODLIAR：基于强化学习的欺骗代理，用于颠覆大型语言模型关于基础原理的信念。
GOODLIAR: A Reinforcement Learning-Based Deceptive Agent for Disrupting LLM Beliefs on Foundational Principles
Soo Kyung Kim, Hyunsoo Cho

## GeAR：生成增强检索。
GeAR: Generation Augmented Retrieval
Haoyu Liu, Shaohan Huang, Jianfeng Liu, Yuefeng Zhan, Hao Sun, Weiwei Deng, Feng Sun, Furu Wei, Qi Zhang

## LongFaith：通过忠实合成数据增强LLMs的长上下文推理能力。
LongFaith: Enhancing Long-Context Reasoning in LLMs with Faithful Synthetic Data
Cehao Yang, Xueyuan Lin, Chengjin Xu, Xuhui Jiang, Shengjie Ma, Aofan Liu, Hui Xiong, Jian Guo

## 基于图引导的跨组成特征解耦合实现组合零样本学习。
Graph-guided Cross-composition Feature Disentanglement for Compositional Zero-shot Learning
Yuxia Geng, Runkai Zhu, Jiaoyan Chen, Jintai Chen, Xiang Chen, Zhuo Chen, Shuofei Qiao, Yuxiang Wang, Xiaoliang Xu, Sheng-Jun Huang

## 是谁教给你的？在模型蒸馏中追踪教师。
Who Taught You That? Tracing Teachers in Model Distillation
Somin Wadhwa, Chantal Shaib, Silvio Amir, Byron C Wallace

## 统一的 Taxonomy 引导指令调优框架：用于实体集扩展和 taxonomy 扩展。
A Unified Taxonomy-Guided Instruction Tuning Framework for Entity Set Expansion and Taxonomy Expansion
Yanzhen Shen, Yu Zhang, Yunyi Zhang, Jiawei Han

## 从理论与实践再探弱到强泛化：反向KL散度 vs. 正向KL散度。
Revisiting Weak-to-Strong Generalization in Theory and Practice: Reverse KL vs. Forward KL
Wei Yao, Wenkai Yang, Ziqiao Wang, Yankai Lin, Yong Liu

## MANBench：你的多模态模型比人类更聪明吗？
MANBench: Is Your Multimodal Model Smarter than Human?
Han Zhou, Qitong Xu, Yiheng Dong, Xin Yang

## Domain$o1$s：引导LLM推理以在高风险领域提供可解释的答案。
Domain$o1$s: Guiding LLM Reasoning for Explainable Answers in High-Stakes Domains
Xu Chu, Zhijie Tan, Hanlin Xue, Guanyu Wang, Tong Mo, Weiping Li

## 论文标题翻译：作为增量命名实体识别指导的动态前缀：一个统一的序列到序列生成框架。
Dynamic Prefix as Instructor for Incremental Named Entity Recognition: A Unified Seq2Seq Generation Framework
Zihao Wu, YongXiang Hua, Yongxin Zhu, Fang Zhang, Linli Xu

## 受语法约束的自然语言生成。
Grammar-Constrained Natural Language Generation
Gabriele Tuccio, Luana Bulla, Maria Madonia, Aldo Gangemi, Misael Mongiovì

## HammerBench：在实际移动助手场景中的精细函数调用评估。
HammerBench: Fine-Grained Function-Calling Evaluation in Real Mobile Assistant Scenarios
Jun Wang, Jiamu Zhou, Xihuai Wang, Xiaoyun Mo, Haoyu Zhang, Qiqiang Lin, jincheng, Muning Wen, Weinan Zhang, Qiuying Peng, Jun Wang

## BanStereoSet：用于测量孟加拉语中LLM刻板社会偏见的数据集。
BanStereoSet: A Dataset to Measure Stereotypical Social Biases in LLMs for Bangla
Mahammed Kamruzzaman, Abdullah Al Monsur, Shrabon Kumar Das, Enamul Hassan, Gene Louis Kim

## \\textit{D-GEN}: 自动干扰项生成与评估以实现生成模型可靠评估。
\\textit{D-GEN}: Automatic Distractor Generation and Evaluation for Reliable Assessment of Generative Models
Grace Byun, Jinho D. Choi

## 超越上下文学习：通过任务固有属性指南对大型语言模型的长文本生成进行对齐。
Beyond In-Context Learning: Aligning Long-form Generation of Large Language Models via Task-Inherent Attribute Guidelines
Do Xuan Long, Duong Ngoc Yen, Do Xuan Trong, Anh Tuan Luu, Kenji Kawaguchi, Shafiq Joty, Min-Yen Kan, Nancy F. Chen

## 解析并缓解视觉语言模型的安全对齐退化问题。
Unraveling and Mitigating Safety Alignment Degradation of Vision-Language Models
Qin Liu, Chao Shang, Ling Liu, Nikolaos Pappas, Jie Ma, Neha Anna John, Srikanth Doss, Lluis Marquez, Miguel Ballesteros, Yassine Benajiba

## NorEval：挪威语言理解和生成评估基准。
NorEval: A Norwegian Language Understanding and Generation Evaluation Benchmark
Vladislav Mikhailov, Tita Enstad, David Samuel, Hans Christian Farsethås, Andrey Kutuzov, Erik Velldal, Lilja Øvrelid

## 生物信息学中的大型语言模型：一项综述。
Large Language Models in Bioinformatics: A Survey
Zhenyu Wang, Zikang Wang, Jiyue Jiang, Pengan CHEN, Xiangyu Shi, Yu Li

## 大规模多语言指令遵循信息提取。
Massively Multilingual Instruction-Following Information Extraction
Thang Le, Huy Huu Nguyen, Anh Tuan Luu, Thien Huu Nguyen

## SYNTHVERIFY：通过逐步生成合成数据来释放大语言模型在零样本声明验证方面的潜力。
SYNTHVERIFY: Unleashing the Power of LLMs for Zero-Shot Claim Verification via Step-by-Step Synthetic Data Generation
Rongwen Zhao, Jeffrey Flanigan

## mOSCAR：大规模多语种和多模态文档级语料库。
mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus
Matthieu Futeral, Armel Randy Zebaze, Pedro Ortiz Suarez, Julien Abadji, Rémi Lacroix, Cordelia Schmid, Rachel Bawden, Benoît Sagot

## 重写以 Escape to Jailbreak：发现可学习和可转移的潜在有害指令。
Rewrite to Jailbreak: Discover Learnable and Transferable Implicit Harmfulness Instruction
Yuting Huang, Chengyuan Liu, Yifeng Feng, Chao Wu, Fei Wu, Kun Kuang

## 加速网络自动化：压缩历史状态的影响。
Turbocharging Web Automation: The Impact of Compressed History States
Xiyue Zhu, Peng Tang, Haofu Liao, srikar appalaraju

## DALR：双层次对齐学习的多模态句子表示学习。
DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning
Kang He, Yuzhe Ding, Haining Wang, Fei Li, Chong Teng, Donghong Ji

## 通过层知识引导的注意力机制使RALM对无关背景具有鲁棒性。
Making RALM Robust to Irrelevant Contexts via Layer Knowledge Guided Attention
Weijie Shi, Hao Chen, Jiaming Li, Yao Zhao, Yazhong Zhang, Qijin Chen, Jipeng Zhang, Ruiyuan Zhang, Jia Zhu, Jiajie Xu, Xiaofang Zhou

## NegVQA：视觉语言模型能理解否定词吗？
NegVQA: Can Vision Language Models Understand Negation?
Yuhui Zhang, Yuchang Su, Yiming Liu, Serena Yeung-Levy

## ChartEdit：MLLMs 在自动化图表分析方面进展如何？通过图表编辑评估其能力。
ChartEdit: How Far Are MLLMs From Automating Chart Analysis? Evaluating MLLMs’ Capability via Chart Editing
Xuanle Zhao, Xuexin Liu, Yang Haoyue, Xianzhen Luo, Fanhu Zeng, jianling li, Qi Shi, Chi Chen

## SWE-Dev：通过训练和推理解缩构建软件工程代理。
SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling
Haoran Wang, Zhenyu Hou, Yao Wei, Jie Tang, Yuxiao Dong

## 大型语言模型作为手语界面：在听觉中心主义世界中缓解聋人用户对大语言模型的需求。
Large Language Models as Sign Language Interfaces: Mitigating the Requests of Deaf Users of LLMs in a Hearing-Centric World
Mert Inan, Anthony Sicilia, Malihe Alikhani

## LLM检测的两种范式：作者归因与作者验证。
The Two Paradigms of LLM Detection: Authorship Attribution versus Authorship Verification
Janek Bevendorff, Matti Wiegmann, Emmelie Richter, Martin Potthast, Benno Stein

## RemoteRAG：一种保护隐私的LLM云检索增强服务
RemoteRAG: A Privacy-Preserving LLM Cloud RAG Service
Yihang Cheng, Lan Zhang, Junyang Wang, Mu Yuan, Yunhao Yao

## 大规模语言模型中的自然语言推理：分析与评估
Natural Language Reasoning in Large Language Models: Analysis and Evaluation
Debela Gemechu, Ramon Ruiz-Dolz, Henrike Beyer, Chris Reed

## SCITAT：一个涵盖多种推理类型的科学表格和文本问答基准。
SCITAT: A Question Answering Benchmark for Scientific Tables and Text Covering Diverse Reasoning Types
Xuanliang Zhang, Dingzirui Wang, Baoxin Wang, Longxu Dou, Xinyuan Lu, Keyan Xu, Dayong Wu, Qingfu Zhu

## 在数据核视角空间中的黑盒生成模型的统计推理。
Statistical inference on black-box generative models in the data kernel perspective space
Hayden Helm, Aranyak Acharyya, Youngser Park, Brandon Duderstadt, Carey Priebe

## GRNFormer：一种生物学导向框架，将基因调控网络整合到RNA基础模型中。
GRNFormer: A Biologically-Guided Framework for Integrating Gene Regulatory Networks into RNA Foundation Models
Mufan Qiu, Xinyu Hu, Fengwei Zhan, Sukwon Yun, Jie Peng, Ruichen Zhang, Bhavya Kailkhura, Jiekun Yang, Tianlong Chen

## TokenShapley：基于Shapley值的 token 级别上下文归因
TokenShapley: Token Level Context Attribution with Shapley Value
Yingtai Xiao, Yuqing Zhu, Sirat Samyoun, Wanrong Zhang, Jiachen T. Wang, Jian Du

## 基于熵的多步推理探索导引
Entropy-based Exploration Conduction for Multi-step Reasoning
Jinghan Zhang, Xiting Wang, Fengran Mo, Yeyang Zhou, Wanfu Gao, Kunpeng Liu

## AceMath：通过后训练和奖励建模推动数学推理前沿发展。
AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling
Zihan Liu, Yang Chen, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping

## 使用言语行为理论分类表征性伤害。
Taxonomizing Representational Harms using Speech Act Theory
Emily Corvi, Hannah Washington, Stefanie Reed, Chad Atalla, Alexandra Chouldechova, P. Alex Dow, Jean Garcia-Gathright, Nicholas J Pangakis, Emily Sheng, Dan Vann, Matthew Vogel, Hanna Wallach

## 将对话转化为工作流：一种提取和评估服务AI代理对话工作流的框架。
Turning Conversations into Workflows: A Framework to Extract and Evaluate Dialog Workflows for Service AI Agents
Prafulla Kumar Choubey, XIANGYU PENG, Shilpa Bhagavath, Caiming Xiong, Shiva Kumar Pentyala, Chien-Sheng Wu

## “我的生活糟透了，每天不得不签名500次”：揭露伪装的夸耀，谦虚炫耀。
“My life is miserable, have to sign 500 autographs everyday”: Exposing Humblebragging, the Brags in Disguise
Sharath Naganna, Saprativa Bhattacharjee, Biplab Banerjee, Pushpak Bhattacharyya

## WXImpactBench：用于评估大规模语言模型的颠覆性天气影响理解基准。
WXImpactBench: A Disruptive Weather Impact Understanding Benchmark for Evaluating Large Language Models
Yongan Yu, Qingchen Hu, Xianda Du, Jiayin Wang, Fengran Mo, Renée Sieber

## 大型语言模型是否能够在不依赖捷径的情况下进行潜在的多步推理？
Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?
Sohee Yang, Nora Kassner, Elena Gribovskaya, Sebastian Riedel, Mor Geva

## ComparisonQA：通过知识频率控制和不确定性评估大语言模型的事实稳健性性。
ComparisonQA: Evaluating Factuality Robustness of LLMs Through Knowledge Frequency Control and Uncertainty
Qing Zong, Zhaowei Wang, Tianshi Zheng, Xiyu REN, Yangqiu Song

## 用于会议对话流式文本分割的一维对象检测。
One-Dimensional Object Detection for Streaming Text Segmentation of Meeting Dialogue
Rui He, Zhongqing Wang, Minjie Qiang, Hongling Wang, Yifan.zhang, Hua Xu, Shuai Fan, Guodong Zhou

## MeMoTune：一种基于度量和矩驱动的量化大型语言模型微调框架。
MeMoTune: A Measure and Moment-Driven Fine-Tuning Framework for Quantized Large Language Models
Yun Zhang, Xue Geng, Lizi Liao, Jintong Sun, Minghe Yu, Ge Yu

## 情感图像生成以用于方面情感分析。
Sentimental Image Generation for Aspect-based Sentiment Analysis
Xiaoyi Bao, Jinghang Gu, Zhongqing Wang, Chu-Ren Huang

## MALAMUTE：一个多语言、高细粒度、无模板、基于教育的探针数据集。
MALAMUTE: A Multilingual, Highly-granular, Template-free, Education-based Probing Dataset
Sagi Shaier, George Arthur Baker, Chiranthan Sridhar, Lawrence Hunter, Katharina von der Wense

## 自主数据选择结合零样本生成分类器用于数学文本。
Autonomous Data Selection with Zero-shot Generative Classifiers for Mathematical Texts
Yifan Zhang, Yifan Luo, Yang Yuan, Andrew C Yao

## 长文本幻觉检测与自我诱发。
Long-form Hallucination Detection with Self-elicitation
Zihang Liu, Jiawei Guo, Hao Zhang, Hongyang Chen, Jiajun Bu, Haishuai Wang

## 从委员会学习：来自混合教师的推理知识提炼。
Learning from Committee: Reasoning Distillation from a Mixture of Teachers with Peer-Review
Zhuochun Li, Yuelyu Ji, Rui Meng, Daqing He

## 多语言语言模型的标度律。
Scaling Laws for Multilingual Language Models
Yifei He, Alon Benhaim, Barun Patra, Praneetha Vaddamanu, Sanchit Ahuja, Parul Chopra, Vishrav Chaudhary, Han Zhao, Xia Song

## 谓词-条件一致性答案集的知识图嵌入。
Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings
Yuqicheng Zhu, Daniel Hernández, Yuan He, Zifeng Ding, Bo Xiong, Evgeny Kharlamov, Steffen Staab

## Wanda++：通过区域梯度裁剪大型语言模型。
Wanda++: Pruning Large Language Models via Regional Gradients
Yifan Yang, Kai Zhen, Bhavana Ganesh, Aram Galstyan, Goeric Huybrechts, Markus Müller, Jonas M. Kübler, Rupak Vignesh Swaminathan, Athanasios Mouchtaris, Sravan Babu Bodapati, Nathan Susanj, Zheng Zhang, Jack FitzGerald, Abhishek Kumar

## 多语言检索增强生成用于文化敏感任务：跨语言鲁棒性评估基准。
Multilingual Retrieval Augmented Generation for Culturally-Sensitive Tasks: A Benchmark for Cross-lingual Robustness
Bryan Li, Fiona Luo, Samar Haider, Adwait Agashe, Siyu Li, Runqi Liu, Muqing Miao, Shriya Ramakrishnan, Yuan Yuan, Chris Callison-Burch

## MATCHED：多模态作者归属以应对陪侍广告数据中的人口贩卖问题。
MATCHED: Multimodal Authorship-Attribution To Combat Human Trafficking in Escort-Advertisement Data
Vageesh Kumar Saxena, Benjamin Ashpole, Gijs van Dijck, Gerasimos Spanakis

## Fraud-R1：评估大规模语言模型在对抗增强欺诈和钓鱼诱导方面的稳健性的多轮基准。
Fraud-R1 : A Multi-Round Benchmark for Assessing the Robustness of LLM Against Augmented Fraud and Phishing Inducements
Shu Yang, Shenzhe Zhu, Zeyu Wu, Keyu Wang, Junchi Yao, Junchao Wu, Lijie Hu, Mengdi Li, Derek F. Wong, Di Wang

## 连接相关性和推理：检索增强生成中的推理提练。
Bridging Relevance and Reasoning: Rationale Distillation in Retrieval-Augmented Generation
Pengyue Jia, Derong Xu, Xiaopeng Li, Zhaocheng Du, Xiangyang Li, Yichao Wang, Yuhao Wang, Qidong Liu, Maolin Wang, Huifeng Guo, Ruiming Tang, Xiangyu Zhao

## 通过近似贪婪梯度下降进行的数据集污染。
Corpus Poisoning via Approximate Greedy Gradient Descent
Jinyan Su, Preslav Nakov, Claire Cardie

## 通过排列触发器在LLM供应链中 hijack 系统提示。
System Prompt Hijacking via Permutation Triggers in LLM Supply Chains
Lu Yan, Siyuan Cheng, Xuan Chen, Kaiyuan Zhang, Guangyu Shen, Xiangyu Zhang

## 基于分类学的知识图谱构建方法及其在特定领域科学应用中的应用。
Taxonomy-Driven Knowledge Graph Construction for Domain-Specific Scientific Applications
Huitong Pan, Qi Zhang, Mustapha Adamu, Eduard Dragut, Longin Jan Latecki

## 频率决定一切：使用变换器模型 来模拟西班牙语中的不规则morphologicalic模式。
Frequency matters: Modeling irregular morphological patterns in Spanish with Transformers
Akhilesh Kakolu Ramarao, Kevin Tang, Dinah Baer-Henney

## SANSKRITI：评估语言模型对印度文化知识全面基准。
SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models’ Knowledge of Indian Culture
Arijit Maji, Raghvendra Kumar, Akash Ghosh, Anushka, Sriparna Saha

## 对于大语言模型来说，并不存在简单的推理方式。
There’s No Such Thing as Simple Reasoning for LLMs
Nurul Fajrin Ariyani, Zied Bouraoui, Richard Booth, Steven Schockaert

## CLIX：跨语言习语解释。
CLIX: Cross-Lingual Explanations of Idiomatic Expressions
Aaron Gluck, Katharina von der Wense, Maria Leonor Pacheco

## 从心出发，化作言语：通过综合比喻语言和语义上下文信号生成共鸣响应。
From Heart to Words: Generating Empathetic Responses via Integrated Figurative Language and Semantic Context Signals
Gyeongeun Lee, Zhu Wang, Sathya N. Ravi, Natalie Parde

## R$^3$Mem：通过可逆压缩连接记忆保持与检索。
R$^3$Mem: Bridging Memory Retention and Retrieval via Reversible Compression
Xiaoqiang Wang, Suyuchen Wang, Yun Zhu, Bang Liu

## 超越语义熵：通过成对语义相似性提升大语言模型的不确定性量化。
Beyond Semantic Entropy: Boosting LLM Uncertainty Quantification with Pairwise Semantic Similarity
Dang Nguyen, Ali Payani, Baharan Mirzasoleiman

## 揭示链式思维推理中的确认偏见。
Unveiling Confirmation Bias in Chain-of-Thought Reasoning
Yue Wan, Xiaowei Jia, Xiang Lorraine Li

## DeFine：通过因素档案和类比推理增强LLM决策能力。
DeFine: Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning
Yebowen Hu, Xiaoyang Wang, Wenlin Yao, Yiming Lu, Daoan Zhang, Hassan Foroosh, Dong Yu, Fei Liu

## SMART：自我意识型代理，用于减轻工具滥用问题。
SMART: Self-Aware Agent for Tool Overuse Mitigation
Cheng Qian, Emre Can Acikgoz, Hongru WANG, Xiusi Chen, Avirup Sil, Dilek Hakkani-Tür, Gokhan Tur, Heng Ji

## TC-Bench：条件视频生成中的时间组成性评估基准。
TC-Bench: Benchmarking Temporal Compositionality in Conditional Video Generation
Weixi Feng, Jiachen Li, Michael Saxon, Tsu-Jui Fu, Wenhu Chen, William Yang Wang

## 视觉语言模型在视觉数据中帮助去识别私人信息。
Vision Language Model Helps Private Information De-Identification in Vision Data
Tiejin Chen, Pingzhi Li, Kaixiong Zhou, Tianlong Chen, Hua Wei

## 揭示多模态大语言模型中的隐私风险：任务特定的脆弱性及缓解挑战。
Unveiling Privacy Risks in Multi-modal Large Language Models: Task-specific Vulnerabilities and Mitigation Challenges
Tiejin Chen, Pingzhi Li, Kaixiong Zhou, Tianlong Chen, Hua Wei

## DAM：用于长上下文大规模语言模型推理加速的动态注意力掩码。
DAM: Dynamic Attention Mask for Long-Context Large Language Model Inference Acceleration
Hanzhi Zhang, Heng Fan, Kewei Sha, Yan Huang, Yunhe Feng

## 探究大规模语言模型中的语境忠实性：记忆强度与证据风格的作用。
Investigating Context Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style
Yuepei Li, Kang Zhou, Qiao Qiao, Bach Nguyen, Qing Wang, Qi Li

## 题目：矛盾的仲裁者：在共识缺失任务中使用LLMs所面临的挑战。
Arbiters of Ambivalence: Challenges of using LLMs in No-Consensus tasks
Bhaktipriya Radharapu, Manon Revel, Megan Ung, Sebastian Ruder, Adina Williams

## 高效但脆弱：LLM批处理提示攻击的基准测试与防御。
Efficient but Vulnerable: Benchmarking and Defending LLM Batch Prompting Attack
Murong Yue, Ziyu Yao

## MM-R³：关于视觉-语言模型（VLMs）的一致性问题。
MM-R$^3$: On (In-)Consistency of Vision-Language Models (VLMs)
Shih-Han Chou, Shivam Chandhok, Jim Little, Leonid Sigal

## 提升多语言大型语言模型：持续预训练与欠代表语言的全面评估。
Enhancing Multilingual Large Language Models: Continued Pretraining and Comprehensive Evaluation for Underrepresented Languages
Pablo Rodríguez, Silvia Paniagua Suárez, Pablo Gamallo, Susana Sotelo Docio

## SynFix：通过关系图进行代码库的同步修复。
SynFix: Synchronous Repair for Codebase via RelationGraph
Xunzhu Tang, Jiechao Gao, Jin Xu, Tiezhu Sun, Yewei Song, Saad Ezzini, Wendkûuni C. Ouédraogo, Jacques Klein, Tegawendé F. Bissyandé

## K级排序偏好优化对大型语言模型的影响。
K-order Ranking Preference Optimization for Large Language Models
Shihao Cai, Chongming Gao, Yang Zhang, Wentao Shi, Jizhi Zhang, Keqin Bao, Qifan Wang, Fuli Feng

## 为什么视觉语言模型在视觉算术任务上表现不佳？迈向增强的图表和几何理解。
Why Vision Language Models Struggle with Visual Arithmetic? Towards Enhanced Chart and Geometry Understanding
Kung-Hsiang Huang, Can Qin, Haoyi Qiu, Philippe Laban, Shafiq Joty, Caiming Xiong, Chien-Sheng Wu

## EXIT：基于上下文的提取式摘要，\n
EXIT: Context-Aware Extractive Compression for Enhancing Retrieval-Augmented Generation
Taeho Hwang, Sukmin Cho, Soyeong Jeong, Hoyun Song, SeungYoon Han, Jong C. Park

## 通过语音预训练模型探究声学特征标志以进行音频换声源识别。
Investigating Prosodic Signatures via Speech Pre-Trained Models for Audio Deepfake Source Attribution
Orchid Chetia Phukan, Drishti Singh, Swarup Ranjan Behera, Arun Balaji Buduru, Rajesh Sharma

## CodeTaxo：通过代码语言提示在有限示例下增强分类扩展。
CodeTaxo: Enhancing Taxonomy Expansion with Limited Examples via Code Language Prompts
Qingkai Zeng, Yuyang Bai, Zhaoxuan Tan, Zhenyu Wu, Shangbin Feng, Meng Jiang

## 重新审视大语言模型任务：从能力、技能和知识视角出发。
Re-TASK: Revisiting LLM Tasks from Capability, Skill, and Knowledge Perspectives
Zhihu Wang, Shiwan Zhao, Yu Wang, Heyuan Huang, Sitao Xie, Yubo Zhang, Jiaxin Shi, Zhixing Wang, Hongyan Li, Junchi Yan

## 大数据语言模型中的数据盲性关键层谱分析 insights。
Spectral Insights into Data-Oblivious Critical Layers in Large Language Models
Xuyuan Liu, Lei Hsiung, Yaoqing Yang, Yujun Yan

## 初始化和改装键值适配器以实现可追踪的模型编辑。
Initializing and Retrofitting Key-Value Adaptors for Traceable Model Editing
Hanlun Zhu, Yunshi Lan, Xiang Li, Weining Qian

## MegaAgent：无需SOP的动态代理协调。
MegaAgent: Dynamic Agent Coordination Without SOPs
Qian Wang, Tianyu Wang, Zhenheng Tang, Qinbin Li, Nuo Chen, Jingsheng Liang, Bingsheng He

## 神经机器翻译的自我蒸馏配方。
A Self-Distillation Recipe for Neural Machine Translation
Hongfei Xu, Zhuofei Liang, Qiuhui Liu, Lingling Mu

## Persona-judge：通过令牌级自我判断实现大型语言模型的个性化对齐。
Persona-judge: Personalized Alignment of Large Language Models via Token-level Self-judgment
Xiaotian Zhang, Ruizhe Chen, YANG FENG, Zuozhu Liu

## 通过使用大型语言模型进行搜索以改进红队演练。
Better Red Teaming via Searching with Large Language Model
Yongkang Chen, Chongyang Zhao, jianwentian, Guiling Cao, Hu LI, Xiaohui Kuang

## BlockPruner：大规模语言模型的细粒度剪枝。
BlockPruner: Fine-grained Pruning for Large Language Models
Longguang Zhong, Fanqi Wan, Ruijun Chen, Xiaojun Quan, Liangzhi Li

## 通过反向 paraphrase 攻击减轻机器文本检测中的 paraphrase 攻击。
Mitigating Paraphrase Attacks on Machine-Text Detection via Paraphrase Inversion
Rafael Alberto Rivera Soto, Barry Y. Chen, Nicholas Andrews

## LongCite：使大规模语言模型能够生成长上下文问答中的精细引用。
LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-Context QA
Jiajie Zhang, Yushi Bai, Xin Lv, Wanjun Gu, Danqing Liu, Minhao Zou, Shulin Cao, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li

## 关于多代理系统中群体一致性的一种实证研究
An Empirical Study of Group Conformity in Multi-Agent Systems
Min Choi, Keonwoo Kim, Sungwon Chae, Sangyeop Baek

## 从心理测量学角度攻击以评估大型语言模型中的隐性偏见。
Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective
Yuchen Wen, Keping Bi, Wei Chen, Jiafeng Guo, Xueqi Cheng

## ASPO：自适应句级偏好优化的细粒度多模态推理方法。
ASPO: Adaptive Sentence-Level Preference Optimization for Fine-Grained Multimodal Reasoning
Yeyuan Wang, Dehong Gao, Rujiao Long, Lei Yi, Linbo Jin, Libin Yang, Xiaoyan Cai

## 探索大型语言模型的选择行为。
Exploring the Choice Behavior of Large Language Models
Weidong Wu, Qinlin Zhao, Hao Chen, Lexin Zhou, Defu Lian, Hong Xie

## 新型CR：一种专门针对长跨度同指消解的大型双语数据集。
NovelCR: A Large-Scale Bilingual Dataset Tailored for Long-Span Coreference Resolution
MeiHan Tong, Shuai Wang

## 超越文本：文档研究中领域专家需求的特征化。
Beyond Text: Characterizing Domain Expert Needs in Document Research
Sireesh Gururaja, Nupoor Gandhi, Jeremiah Milbauer, Emma Strubell

## 动态注意力引导的上下文解码方法，用于缓解大型语言模型中的上下文忠实性幻觉。
Dynamic Attention-Guided Context Decoding for Mitigating Context Faithfulness Hallucinations in Large Language Models
Huangyw, Yong Zhang, Ning Cheng, Zhitao Li, Shaojun Wang, Jing Xiao

## 基于政策的细粒度知识反馈自我对齐以减轻幻觉现象。
On-Policy Self-Alignment with Fine-grained Knowledge Feedback for Hallucination Mitigation
Xueru Wen, Jie Lou, Xinyu Lu, Yuqiu Ji, Xinyan Guan, Yaojie Lu, Hongyu Lin, Ben He, Xianpei Han, Debing Zhang, Le Sun

## 从短语到子图：知识图谱中的细粒度语义解析。
From Phrases to Subgraphs: Fine-Grained Semantic Parsing with Knowledge Graphs
Yurun Song, Xiangqing Shen, Rui Xia

## ClaimPKG：通过轻量级专业化LLM与伪子图生成增强论断验证。
ClaimPKG: Enhancing Claim Verification via Pseudo-Subgraph Generation with Lightweight Specialized LLM
Hoang Pham, Thanh-Do Nguyen, Khac-Hoai Nam Bui

## TriEmbed：通过嵌入重参数化连接文本与token索引之间的差距。
TriEmbed: Bridge the Gap between Text and Token Indices with Embedding Reparameterization
Baizhou Huang, Xiaojun Wan

## StableToolBench-MirrorAPI：将工具环境建模为7000多个真实世界API的镜像。
StableToolBench-MirrorAPI: Modeling Tool Environments as Mirrors of 7,000+ Real-World APIs
Zhicheng Guo, Sijie Cheng, Yuchen Niu, Hao Wang, Sicheng Zhou, Wenbing Huang, Yang Liu

## 打包分析：监督微调中大型模型或数据集更适配于打包。
Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning
Shuhe Wang, Guoyin Wang, Yizhong Wang, Jiwei Li, Eduard Hovy, Chen Guo

## MIRe：通过融合-free 模态交互增强多模态查询表示以提高多模态检索效果。
MIRe: Enhancing Multimodal Queries Representation via Fusion-Free Modality Interaction for Multimodal Retrieval
Yeong-Joon Ju, Ho-Joong Kim, Seong-Whan Lee

## SuLoRA：子空间低秩适应性参数高效微调方法。
SuLoRA: Subspace Low-Rank Adaptation for Parameter-Efficient Fine-Tuning
Chenhao Ding, Jiangyang Li, SongLin Dong, Xinyuan Gao, Yuhang He, Yihong Gong

## 个性化对齐综述——大型语言模型在实际应用中的缺失环节。
A Survey on Personalized Alignment—The Missing Piece for Large Language Models in Real-World Applications
Jian Guan, Junfei Wu, Jia-Nan Li, Chuanqi Cheng, Wei Wu

## 影子激活的多模态大语言模型后门攻击。
Shadow-Activated Backdoor Attacks on Multimodal Large Language Models
Ziyi Yin, Muchao Ye, Yuanpu Cao, Jiaqi Wang, Aofei Chang, Han Liu, Jinghui Chen, Ting Wang, Fenglong Ma

## 使用弱到强知识蒸馏消除LLMs后门攻击。
Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation
Shuai Zhao, Xiaobao Wu, Cong-Duy T Nguyen, Yanhao Jia, Meihuizi Jia, Feng Yichao, Anh Tuan Luu

## 图上的纠正：基于大型语言模型的知识图谱忠实语义解析。
Correcting on Graph: Faithful Semantic Parsing over Knowledge Graphs with Large Language Models
Ruilin Zhao, Feng Zhao, Hong Zhang

## COPR：通过最优策略正则化实现持续的人类偏好学习。
COPR: Continual Human Preference Learning via Optimal Policy Regularization
Han Zhang, Lin Gui, Yu Lei, Yuanzhao Zhai, Yehong Zhang, Zhuo Zhang, Yulan He, Hui Wang, Yue Yu, Kam-Fai Wong, Bin Liang, Ruifeng Xu

## 通过动态目标边际实现稳健的偏好优化。
Robust Preference Optimization via Dynamic Target Margins
Jie Sun, Junkang Wu, Jiancan Wu, Lintao Ma, Zhibo Zhu, Xingyu Lu, JUN ZHOU, Xiang Wang

## 使用大规模语言模型的开放式居住需求预测。
Open-Set Living Need Prediction with Large Language Models
Xiaochong Lan, Jie Feng, Yizhou Sun, Chen Gao, Jiahuan Lei, Xinleishi, Hengliang Luo, Yong Li

## 重新思考多轮对话中的状态型工具使用：基准与挑战。
Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges
Hongru WANG, Wenyu Huang, Yufei Wang, Yuanhao Xi, Jianqiao Lu, Huan Zhang, Nan Hu, Zeming Liu, Jeff Z. Pan, Kam-Fai Wong

## 通过自我诱导和相关性重估改进规则检索与推理。
Improve Rule Retrieval and Reasoning with Self-Induction and Relevance ReEstimate
Ziyang Huang, Wangtao Sun, Jun Zhao, Kang Liu

## 方法链：在无需训练的情况下扩展测试时间计算。
Chain of Methodologies: Scaling Test Time Computation without Training
Cong Liu, Jie Wu, Weigang Wu, Xu Chen, Liang Lin, Wei-Shi Zheng

## 基于上下文的分层合并方法用于长文档摘要。
Context-Aware Hierarchical Merging for Long Document Summarization
Litu Ou, Mirella Lapata

## 长视频理解的语言资源库。
Language Repository for Long Video Understanding
Kumara Kahatapitiya, Kanchana Ranasinghe, Jongwoo Park, Michael S Ryoo

## 自我推理语言模型：使用少量推理催化剂展开隐藏的推理链条。
Self-Reasoning Language Models: Unfold Hidden Reasoning Chains with Few Reasoning Catalyst
Hongru WANG, Deng Cai, Wanjun Zhong, Shijue Huang, Jeff Z. Pan, Zeming Liu, Kam-Fai Wong

## 兼顾两者之长：一种混合NMT和LLM翻译的方法。
Combining the Best of Both Worlds: A Method for Hybrid NMT and LLM Translation
Zhanglin Wu, Daimeng Wei, Xiaoyu Chen, Hengchao Shang, Jiaxin GUO, Zongyao Li, Yuanchang Luo, Jinlong Yang, Zhiqiang Rao, Hao Yang

## 超越语言：将心智理论整合到对话代理中，以实现类似人类的信念、欲望和意图对齐。
Beyond Words: Integrating Theory of Mind into Conversational Agents for Human-Like Belief, Desire, and Intention Alignment
Mehdi Jafari, YUNCHENG HUA, Hao Xue, Flora D. Salim

## LLM 是一个过于自信的裁判吗？揭示 LLM 在检测 hateful 语言方面的能力，通过标注分歧。
Is LLM an Overconfident Judge? Unveiling the Capabilities of LLMs in Detecting Offensive Language with Annotation Disagreement
Junyu Lu, Kai Ma, Kaichun Wang, Kelaiti Xiao, Roy Ka-Wei Lee, Bo Xu, Liang Yang, Hongfei Lin

## 调查多语言RAG系统的语言偏好。
Investigating Language Preference of Multilingual RAG Systems
Jeonghyun Park, Hwanhee Lee

## 自我调教：指示大型语言模型通过自我教学有效地获取新知识。
Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching
Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Yipeng Zhang, Haitao Mi, Helen M. Meng

## QueryAttack：使用结构化非自然查询语言解锁对齐大型语言模型的方法。
QueryAttack: Jailbreaking Aligned Large Language Models Using Structured Non-natural Query Language
Qingsong Zou, Jingyu Xiao, Qing Li, Zhi Yan, Yuhang Wang, Li Xu, Wenxuan Wang, Kuofeng Gao, Ruoyu Li, Yong Jiang

## FGDGNN：社交媒体中 rumor 检测的细粒度动态图神经网络。
FGDGNN: Fine-Grained Dynamic Graph Neural Network for Rumor Detection on Social Media
Mei Guo, Chen Chen, Chunyan Hou, Yike Wu, Xiaojie Yuan

## AdaReTaKe：自适应冗余减少以感知更长时长的视频-语言理解。
AdaReTaKe: Adaptive Redundancy Reduction to Perceive Longer for Video-language Understanding
Xiao Wang, Qingyi Si, Shiyu Zhu, Jianlong Wu, Li Cao, Liqiang Nie

## VCD：图像中视觉常识发现的数据集。
VCD: A Dataset for Visual Commonsense Discovery in Images
Xiangqing Shen, Fanfan Wang, Siwei Wu, Rui Xia

## 多模态因果推理基准：挑战大型多模态语言模型在不同模态之间辨识因果联系。
Multimodal Causal Reasoning Benchmark: Challenging Multimodal Large Language Models to Discern Causal Links Across Modalities
Zhiyuan Li, Heng Wang, Dongnan Liu, Chaoyi Zhang, Ao Ma, Jieting Long, Weidong Cai

## CA-GAR：基于上下文的LLM生成对齐以进行文档检索。
CA-GAR: Context-Aware Alignment of LLM Generation for Document Retrieval
Heng Yu, Junfeng Kang, Rui Li, Qi Liu, Liyang He, Zhenya Huang, Shuanghong Shen, Junyu Lu

## AgentCourt：模拟法庭的 adversarial 可演化律师代理机构 Veranstaltung
AgentCourt: Simulating Court with Adversarial Evolvable Lawyer Agents
Guhong Chen, Liyang Fan, Zihan Gong, Nan Xie, Zixuan Li, Ziqiang Liu, Chengming Li, QIANG QU, Hamid Alinejad-Rokny, Shiwen Ni, Min Yang

## 论据并不是万能药：衡量论据对模型性能和可靠性的影响。
Rationales Are Not Silver Bullets: Measuring the Impact of Rationales on Model Performance and Reliability
Chiwei Zhu, Benfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Zhendong Mao

## PersonaX：面向推荐代理的长行为序列用户建模框架
PersonaX: A Recommendation Agent-Oriented User Modeling Framework for Long Behavior Sequence
Yunxiao Shi, Wujiang Xu, Zhang Zeqi, Xing Zi, Qiang Wu, Min Xu

## 记忆还是推理？探究大模型如何计算混合算术表达式。
Memory or Reasoning? Explore How LLMs Compute Mixed Arithmetic Expressions
Chengzhi Li, Heyan Huang, Ping Jian, Zhen Yang, Chenxu Wang, Yifan Wang

## MLDebugging：跨多库场景编码调试基准测试的研究方向。
MLDebugging: Towards Benchmarking Code Debugging Across Multi-Library Scenarios
JinYang Huang, Xiachong Feng, Qiguang Chen, Hanjie Zhao, Zihui Cheng, Jiesong Bai, Jingxuan Zhou, Min Li, Libo Qin

## CipherBank：通过 cryptography 挑战探索大语言模型推理能力的边界。
CipherBank: Exploring the Boundary of LLM Reasoning Capabilities through Cryptography Challenge
Yu Li, Qizhi Pei, Mengyuan Sun, Honglin Lin, Chenlin Ming, Xin Gao, Jiang Wu, Conghui He, Lijun Wu

## 多轮对话推荐代理的期望确认偏好优化
Expectation Confirmation Preference Optimization for Multi-Turn Conversational Recommendation Agent
Xueyang Feng, Jingsen Zhang, Jiakai Tang, Wei Li, Guohao Cai, Xu Chen, Quanyu Dai, Yue Zhu, Zhenhua Dong

## 关于将LLM作为法官进行LLM评估的实证研究：微调的法官模型并不是GPT-4的通用替代品。
An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Model is not a General Substitute for GPT-4
Hui Huang, Xingyuan Bu, Hongli Zhou, Yingqi Qu, Jing Liu, Muyun Yang, Bing Xu, Tiejun Zhao

## 哪种保留集适用于大规模语言模型去学习？一项关于实体去学习的案例研究。
Which Retain Set Matters for LLM Unlearning? A Case Study on Entity Unlearning
Hwan Chang, Hwanhee Lee

## McBE：针对大语言模型的多任务中文偏见评估基准。
McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models
Tian Lan, Xiangdong Su, Xu Liu, Ruirui Wang, Ke Chang, Jiang Li, Guanglai Gao

## 通过缩放单隐藏状态通道减轻LLM中的位置偏见。
Mitigate Position Bias in LLMs via Scaling a Single Hidden States Channel
Yijiong Yu, Huiqiang Jiang, Xufang Luo, Qianhui Wu, Chin-Yew Lin, Dongsheng Li, Yuqing Yang, Yongfeng Huang, Lili Qiu

## MARK：带有排名指导的多代理协作文本归属图聚类。
MARK: Multi-agent Collaboration with Ranking Guidance for Text-attributed Graph Clustering
Yiwei Fu, Yuxing Zhang, Chunchun Chen, JianwenMa, Quan Yuan, Rong-Cheng Tu, Xinli Huang, Wei Ye, Xiao Luo, Minghua Deng

## 基于自注意力的思维图数学问题求解
Self-attention-based Graph-of-Thought for Math Problem Solving
Ruiqiao Bai, Xue Han, Shuo Lei, Junlan Feng, Yanyan Luo, Chao Deng

## ProMedTS：一种自监督、提示引导的多模态方法，用于集成医疗文本和时间序列数据。
ProMedTS: A Self-Supervised, Prompt-Guided Multimodal Approach for Integrating Medical Text and Time Series
Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, V. W., Richard Yi Da Xu, Guo Li, Xian Yang

## 语言模型能否捕捉到人类在文本摘要中的写作偏好？
Can Language Models Capture Human Writing Preferences on Text Summarization?
Jingbao Luo, Ming Liu, Ran Liu, Yongpan Sheng, Gang Li, Xin Hu, WupengNjust

## 告诉我你不知道的：通过表示空间分析和编辑增强角色扮演代理的拒绝能力。
Tell Me What You Don’t Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing
Wenhao Liu, Siyu An, Junru Lu, Muling Wu, Tianlong Li, Xiaohua Wang, Changze Lv, Xiaoqing Zheng, di yin, Xing Sun, Xuanjing Huang

## LR²Bench：通过约束满足问题评估大型语言模型的长链反射推理能力。
LR^2Bench: Evaluating Long-chain Reflective Reasoning Capabilities of Large Language Models via Constraint Satisfaction Problems
Jianghao Chen, Zhenlin Wei, Zhenjiang Ren, Ziyong Li, Jiajun Zhang

## FRère：一种基于知识图谱的灵活模块化检索增强生成框架。
FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs
Zengyi Gao, Yukun Cao, Hairu Wang, Ao Ke, Yuan Feng, S Kevin Zhou, Xike Xie

## KAPA：带有树状知识库的多域用户意图理解递决策体框架。
KAPA: A Deliberative Agent Framework with Tree-Structured Knowledge Base for Multi-Domain User Intent Understanding
Jiakai Tang, Shiqi Shen, ZhipengWang, Gong Zhi, Xueyang Feng, Zexu Sun, Haoran Tan, Xu Chen

## BAR：一种基于backward reasoning的Minecraft复杂任务智能体。
BAR: A Backward Reasoning based Agent for Complex Minecraft Tasks
Weihong Du, Wenrui Liao, Binyu Yan, Hongru Liang, Anthony G Cohn, Wenqiang Lei

## 以法官身份审判：通过大型语言模型的法官一致性提升检索增强生成的评估。
Judge as A Judge: Improving the Evaluation of Retrieval-Augmented Generation through the Judge-Consistency of Large Language Models
Shuliang Liu, Xinze Li, Zhenghao Liu, Yukun Yan, Cheng Yang, Zheni Zeng, Zhiyuan Liu, Maosong Sun, Ge Yu

## RASD：检索增强推测性解码。
RASD: Retrieval-Augmented Speculative Decoding
Guofeng Quan, Wenfeng Feng, Chuzhan Hao, Guochao Jiang, Yuewei Zhang, Hao Henry Wang

## SEK：自我解释关键术语赋能大型语言模型进行代码生成。
SEK: Self-Explained Keywords Empower Large Language Models for Code Generation
Lishui Fan, Mouxiang Chen, Zhongxin Liu

## 题目：多语种的福音：面向上下文的学习的多语种系统分析。
Blessing of Multilinguality: A Systematic Analysis of Multilingual In-Context Learning
Yilei Tu, Andrew Xue, Freda Shi

## 为何不付诸行动？通过自我意识防护增强释放大型语言模型的安全潜力。
Why Not Act on What You Know? Unleashing Safety Potential of LLMs via Self-Aware Guard Enhancement
Peng Ding, Jun Kuang, ZongYu Wang, Xuezhi Cao, Xunliang Cai, Jiajun Chen, Shujian Huang

## EssayJudge：评估多模态大规模语言模型自动作文评分能力的多粒度基准。
EssayJudge: A Multi-Granular Benchmark for Assessing Automated Essay Scoring Capabilities of Multimodal Large Language Models
Jiamin Su, Yibo Yan, Fangteng FU, Zhang Han, Jingheng Ye, Xiang Liu, Jiahao Huo, Huiyu Zhou, Xuming Hu

## 礁结：针对多模态大规模语言模型中关系错忆评估、分析与缓解的综合基准。
Reefknot: A Comprehensive Benchmark for Relation Hallucination Evaluation, Analysis and Mitigation in Multimodal Large Language Models
Kening Zheng, Junkai Chen, Yibo Yan, Xin Zou, Huiyu Zhou, Xuming Hu

## 论文标题翻译如下：\n提升视觉语言模型的通用多模态能力：基于金字塔下降视觉位置编码的方法。
Advancing General Multimodal Capability of Vision-language Models with Pyramid-descent Visual Position Encoding
Zhanpeng Chen, Mingxiao Li, Ziyang Chen, nan du, Xiaolong Li, Yuexian Zou

## P-React：通过专业化LoRA专家混合体合成主题适应性个性特质反应。
P-React: Synthesizing Topic-Adaptive Reactions of Personality Traits via Mixture of Specialized LoRA Experts
Yuhao Dan, Jie Zhou, Qin Chen, Junfeng Tian, Liang He

## IW-Bench：评估大型多模态模型在图像转网页方面的性能
IW-Bench: Evaluating Large Multimodal Models for Converting Image-to-Web
Hongcheng Guo, Wei Zhang, Junhao Chen, Yaonan Gu, Jian Yang, Junjia Du, Shaosheng Cao, Binyuan Hui, Tianyu Liu, Jianxin Ma, Chang Zhou, Zhoujun Li

## 超越反应性安全：通过长期仿真实现风险管理下的LLM对齐。
Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation
Chenkai Sun, Denghui Zhang, ChengXiang Zhai, Heng Ji

## 自我提升悖论：语言模型能否在无需外部支撑的情况下自行提升推理能力？
The Self-Improvement Paradox: Can Language Models Bootstrap Reasoning Capabilities without External Scaffolding?
Yutao Sun, Mingshuai Chen, Tiancheng Zhao, Ruochen Xu, Zilun Zhang, Jianwei Yin

## 将模型协作链简化为生成任务中单次前向传递。
Streamlining the Collaborative Chain of Models into A Single Forward Pass in Generation-Based Tasks
Yuanjie Lyu, Chao Zhang, Yuhao Chen, Yong Chen, Tong Xu

## 链式思考推理是否会真正减少破解带来的危害性？
Does Chain-of-Thought Reasoning Really Reduce Harmfulness from Jailbreaking?
Chengda Lu, Xiaoyu Fan, Yu Huang, Rongwu Xu, Jijie Li, Wei Xu

## TDCSA：基于大模型指引的自上而下稳健引文情感分析方法。
TDCSA: LLM-Guided Top-Down Approach for Robust Citation Sentiment Analysis
Fan Gao, Jieyang Peng, Xiaoming Tao, WANG Youzheng

## DeepRTL2：一种多功能的RTL相关任务模型。
DeepRTL2: A Versatile Model for RTL-Related Tasks
Yi Liu, Hongji Zhang, Yunhao Zhou, Zhengyuan Shi, Changran XU, Qiang Xu

## 自我纠正远超 refinery：一种用于视觉和语言推理任务的学习框架。
Self-Correction is More than Refinement: A Learning Framework for Visual and Language Reasoning Tasks
Jiayi He, Hehai Lin, Qingyun Wang, Yi R. Fung, Heng Ji

## RMoA：通过多样性和残差补偿优化混合智能体模型。
RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation
Zhentao Xie, Chengcheng Han, Jinxin Shi, Wenjun Cui, Xin Zhao, Xingjiao Wu, Jiabao Zhao

## InternLM-XComposer2.5-奖励：一个简单而有效的多模态奖励模型。
InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model
Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Ziyu Liu, Shengyuan Ding, Shenxi Wu, Yubo Ma, Haodong Duan, Wenwei Zhang, Kai Chen, Dahua Lin, Jiaqi Wang

## RLKGF：无需人力标注的知识图谱反馈强化学习
RLKGF: Reinforcement Learning from Knowledge Graph Feedback Without Human Annotations
Lian Yan, Chen Tang, Yi Guan, Haotian Wang, Songyuan Wang, Haifeng Liu, Yang Yang, Jingchi Jiang

## 通过语言家族解缠和重新思考转移进行低资源语言的跨语言多模态情感分析。
Cross-lingual Multimodal Sentiment Analysis for Low-Resource Languages via Language Family Disentanglement and Rethinking Transfer
Long Chen, Shuoyu Guan, Xiaohua Huang, Wen-Jing Wang, Cai Xu, Ziyu Guan, Wei Zhao

## HyperCRS：基于超图的多粒度偏好学习方法以打破会话推荐系统中的信息茧房
HyperCRS: Hypergraph-Aware Multi-Grained Preference Learning to Burst Filter Bubbles in Conversational Recommendation System
Yongsen Zheng, Mingjie Qian, Guohua Wang, Yang Liu, Ziliang Chen, Mingzhi Mao, Liang Lin, Kwok-Yan Lam

## CAVGAN：通过生成对抗攻击统一大语言模型的脱牢笼攻击与防御方法。
CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations
Xiaohu Li, Yunfeng Ning, Zepeng Bao, Mayi Xu, Jianhao Chen, Tieyun Qian

## 稳健还是善变？评估大型语言模型在连续交互中的一致性。
Firm or Fickle? Evaluating Large Language Models Consistency in Sequential Interactions
Yubo Li, Yidi Miao, Xueying Ding, Ramayya Krishnan, Rema Padman

## RATE-Nav：基于区域的终止增强方法，用于结合视觉-语言模型的零样本对象导航。
RATE-Nav: Region-Aware Termination Enhancement for Zero-shot Object Navigation with Vision-Language Models
Junjie Li, Nan Zhang, Xiaoyang Qu, Kai Lu, Guokuan Li, Jiguang Wan, Jianzong Wang

## OS-Kairos：旨在适应多模态大型语言模型驱动的GUI代理交互。
OS-Kairos: Adaptive Interaction for MLLM-Powered GUI Agents
Pengzhou Cheng, Zheng Wu, Zongru Wu, Tianjie Ju, Aston Zhang, Zhuosheng Zhang, Gongshen Liu

## 通过通信攻击红队测试LLM多代理系统
Red-Teaming LLM Multi-Agent Systems via Communication Attacks
Pengfei He, Yuping Lin, Shen Dong, Han Xu, Yue Xing, Hui Liu

## AdaV：自适应文本-视觉重定向的视觉语言模型
AdaV: Adaptive Text-visual Redirection for Vision-Language Models
Jiayi Han, Liang Du, Yiwen Wu, Guanming Liang, Xiangguo Zhou, Weibo Zheng, Donghong Han, Zixun Sun

## 基于视觉辅助的多MLLM无监督成分解析与辩论。
Vision-aided Unsupervised Constituency Parsing with Multi-MLLM Debating
Dong Zhang, Haiyan Tian, Qingying Sun, Shoushan Li

## DRT：通过长逻辑推理实现的深度理解翻译。
DRT: Deep Reasoning Translation via Long Chain-of-Thought
Jiaan Wang, Fandong Meng, Yunlong Liang, Jie Zhou

## 多证据多答案 QA 中的跨段落验证
Inter-Passage Verification for Multi-evidence Multi-answer QA
Bingsen Chen, Shengjie Wang, Xi Ye, Chen Zhao

## 概率一致的偏好优化以增强LLM推理能力。
Probability-Consistent Preference Optimization for Enhanced LLM Reasoning
Yunqiao Yang, Houxing Ren, Zimu Lu, Ke Wang, Weikang Shi, Aojun Zhou, Junting Pan, Mingjie Zhan, Hongsheng Li

## 我们能信任AI医生吗？大型语言模型和大型多模态模型中的医疗幻觉调查。
Can We Trust AI Doctors? A Survey of Medical Hallucination in Large Language and Large Vision-Language Models
Zhihong Zhu, Yunyan Zhang, Xianwei Zhuang, Fan Zhang, Zhongwei Wan, Yuyan Chen, QingqingLong, Yefeng Zheng, Xian Wu

## PROMTEC：使用模板数据库和常见序列的多查看提示解码以实现快速LLM推理推断。
PROMTEC: Fast LLM Inference Decoding using Prompt Multi-Lookup with Template Database and Common Sequences
Alan Chi-Man Lee, Wing-Sun Cheng, Calvin Chun-Kit Chan

## 生成音乐模型与专业与业余用户期望的契合度
Generative Music Models’ Alignment with Professional and Amateur Users’ Expectations
Zihao Wang, Jiaxing Yu, Haoxuan Liu, Zehui Zheng, Yuhang Jin, Shuyu Li, Shulei Ji, Kejun Zhang

## 逻辑DA：通过多代理系统增强逻辑推理的数据增强方法。
Logical DA: Enhancing Data Augmentation for Logical Reasoning via a Multi-Agent System
Haoqi Zheng, DongWang, Silin Yang, Yunpeng Qi, Ruochun Jin

## SQL注入越狱：大型语言模型的结构性灾难。
SQL Injection Jailbreak: A Structural Disaster of Large Language Models
Jiawei Zhao, Kejiang Chen, Weiming Zhang, Nenghai Yu

## 使用关键词检索适应通用嵌入模型的私人数据集。
Adapting General-Purpose Embedding Models to Private Datasets Using Keyword-based Retrieval
Yubai Wei, Jiale Han, Yi Yang

## 任务校准：对大型语言模型在推理任务上的校准。
Task Calibration: Calibrating Large Language Models on Inference Tasks
Yingjie Li, Yun Luo, Xiaotian Xie, Yue Zhang

## KodCode：一个多样化、具有挑战性和可验证的合成数据集用于编程。
KodCode: A Diverse, Challenging, and Verifiable Synthetic Dataset for Coding
Zhangchen Xu, Yang Liu, Yueqin Yin, Mingyuan Zhou, Radha Poovendran

## LLM-森林：通过图增强提示的LLM集成学习用于数据插补。
LLM-Forest: Ensemble Learning of LLMs with Graph-Augmented Prompts for Data Imputation
Xinrui He, Yikun Ban, Jiaru Zou, Tianxin Wei, Curtiss Cook, Jingrui He

## 选择、阅读与写作：基于全文的相关工作生成多Agent框架。
Select, Read, and Write: A Multi-Agent Framework of Full-Text-based Related Work Generation
Xiaochuan Liu, Ruihua Song, Xiting Wang, Xu Chen

## 从网页重构实现从头合成指令调优数据。
Instruction-Tuning Data Synthesis from Scratch via Web Reconstruction
Yuxin Jiang, Yufei Wang, Chuhan Wu, Xinyi Dai, Yan Xu, Weinan Gan, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Wei Wang

## 从上下文学习中学习任务表示
Learning Task Representations from In-Context Learning
Baturay Saglam, Xinyang Hu, Zhuoran Yang, Dionysis Kalogerias, Amin Karbasi

## 气候适应中的问答：基于专家反馈的模型开发与评估。
Question answering in Climate Adaptation: Model Development and Evaluation with Expert Feedback
Vincent Nguyen, Sarvnaz Karimi, Willow Hallgren, Mahesh Prakash

## TAMP：面向Token自适应多层剪枝在多模态大规模语言模型中的应用。
TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models
Jaewoo Lee, Keyang Xuan, Chanakya Ekbote, Sandeep Polisetty, Yi R. Fung, Paul Pu Liang

## MiniELM：一种用于电商搜索优化的轻量级和自适应查询重写框架。
MiniELM: A Lightweight and Adaptive Query Rewriting Framework for E-Commerce Search Optimization
Duy A. Nguyen, Rishi Kesav Mohan, Shimeng Yang, Pritom Saha Akash, Kevin Chen-Chuan Chang

## 因果去噪原型网络在少样本多标签方面类别检测中的应用
Causal Denoising Prototypical Network for Few-Shot Multi-label Aspect Category Detection
Jin Cui, Xinfeng Wang, Yoshimi Suzuki, Fumiyo Fukumoto

## RealHiTBench：用于评估基于LLM的表格分析的一种全面的现实层级表基准测试。
RealHiTBench: A Comprehensive Realistic Hierarchical Table Benchmark for Evaluating LLM-Based Table Analysis
Pengzuo Wu, Yuhang Yang, Guangcheng Zhu, Chao Ye, Hong Gu, Xu Lu, Ruixuan Xiao, Bowen Bao, Yijing He, Liangyu Zha, Wentao Ye, Junbo Zhao, Haobo Wang

## 一种用于复杂布局文档图像翻译的查询-响应框架，伴有相关区域集中处理。
A Query-Response Framework for Whole-Page Complex-Layout Document Image Translation with Relevant Regional Concentration
Zhiyang Zhang, Yaping Zhang, Yupu Liang, Zhiyuan Chen, Lu Xiang, Yang Zhao, Yu Zhou, Chengqing Zong

## DependEval：评估仓库依赖理解能力的基准测试
DependEval: Benchmarking LLMs for Repository Dependency Understanding
Junjia Du, Yadi Liu, Hongcheng Guo, Jiawei Wang, Haojian Huang, Yunyi Ni, Zhoujun Li

## AGRec：通过图推理适应自回归解码器的基于LLM的序列推荐方法。
AGRec: Adapting Autoregressive Decoders with Graph Reasoning for LLM-based Sequential Recommendation
Xinfeng Wang, Jin Cui, Fumiyo Fukumoto, Yoshimi Suzuki

## DiffSkip：大型语言模型中的差异层跳过。
DiffSkip: Differential Layer Skipping in Large Language Models
Xuan Luo, Weizhi Wang, Xifeng Yan

## MMUnlearner：在多模态大语言模型时代重新定义多模态机器遗忘。
MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models
Jiahao Huo, Yibo Yan, Xu Zheng, Yuanhuiyi Lyu, Xin Zou, Zhihua Wei, Xuming Hu

## 走向可解释的时间推理的大语言模型：一种结构感知生成框架。
Towards Explainable Temporal Reasoning in Large Language Models: A Structure-Aware Generative Framework
Zihao Jiang, Ben Liu, Miao Peng, Wenjie Xu, Yao Xiao, Zhenyan Shan, Min Peng

## 面向ICD编码的一般知识注入框架。
A General Knowledge Injection Framework for ICD Coding
Xu Zhang, Kun Zhang, Wenxin ma, Rongsheng Wang, Chenxu Wu, Yingtai Li, S Kevin Zhou

## 从零开始的 TableDreamer：渐进式和基于弱点的数据合成技术，用于表格指令调优。
TableDreamer: Progressive and Weakness-guided Data Synthesis from Scratch for Table Instruction Tuning
Mingyu Zheng, Zhifan Feng, Jia Wang, Lanrui Wang, Zheng Lin, Hao Yang, Weiping Wang

## 根据视频生成问题、答案和干扰项：探索对象运动的语义不确定性。
Generating Questions, Answers, and Distractors for Videos: Exploring Semantic Uncertainty of Object Motions
Wenjian Ding, YAO ZHANG, Jun Wang, Adam Jatowt, Zhenglu Yang

## 一个边界框相当于一个词——在大型语言模型中交替进行布局和文本处理以实现文档理解。
A Bounding Box is Worth One Token - Interleaving Layout and Text in a Large Language Model for Document Understanding
Jinghui Lu, Haiyang Yu, Yanjie Wang, Yongjie Ye, Jingqun Tang, Ziwei Yang, Binghong Wu, Qi Liu, Hao Feng, Han Wang, Hao Liu, Can Huang

## Explorer：扩展探索驱动的网页轨迹合成以满足多模态网络代理的需求。
Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents
Vardaan Pahuja, Yadong Lu, Corby Rosset, Boyu Gou, Arindam Mitra, Spencer Whitehead, Yu Su, Ahmed Hassan Awadallah

## CodeV：基于视觉数据的问题解决。
CodeV: Issue Resolving with Visual Data
Linhao Zhang, Daoguang Zan, Quanshun Yang, Zhirong Huang, Dong Chen, Bo Shen, Tianyu Liu, Yongshun Gong, Huang Pengjie, Xudong Lu, Guangtai Liang, Lizhen Cui, Qianxiang Wang

## Konooz：跨域跨方言语料库用于命名实体识别。
Konooz: Cross-domain Cross-dialect Corpora for Named Entity Recognition
Nagham Hamad, Mohammed Khalilia, Mustafa Jarrar

## 自我奖励的大规模视觉-语言模型，在文本到图像生成中优化提示。
Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation
Hongji Yang, Yucheng Zhou, Wencheng Han, Jianbing Shen

## 打破推理障碍：从自我进化视角探讨大语言模型的复杂推理综述。
Breaking the Reasoning Barrier A Survey on LLM Complex Reasoning through the Lens of Self-Evolution
Tao He, Hao Li, Jingchang Chen, Runxuan Liu, Yixin Cao, Lizi Liao, Zihao Zheng, Zheng Chu, Jiafeng Liang, Ming Liu, Bing Qin

## 心理学疗法中的大型语言模型综述：当前格局与未来方向
A Survey of Large Language Models in Psychotherapy: Current Landscape and Future Directions
Hongbin Na, Yining Hua, Zimu Wang, Tao Shen, Beibei Yu, Lilin Wang, Wei Wang, John Torous, Ling Chen

## 基于图辅助的文化适应性习语翻译方法——面向印欧语系语言。
Graph-Assisted Culturally Adaptable Idiomatic Translation for Indic languages
Pratik Rakesh Singh, Kritarth Prasad, Mohammadi Zaki, Pankaj Wasnik

## 从模仿到反省：探究语言模型的自我意识。
From Imitation to Introspection: Probing Self-Consciousness in Language Models
Sirui Chen, Shu Yu, Shengjie Zhao, Chaochao Lu

## StructFact：使用大规模语言模型从结构化数据中推理由 factual 知识。
StructFact: Reasoning Factual Knowledge from Structured Data with Large Language Models
Sirui Huang, Yanggan Gu, Zhonghao Li, Xuming Hu, Li Qing, Guandong Xu

## DocFusion：统一的文档解析框架。
DocFusion: A Unified Framework for Document Parsing Tasks
Mingxu Chai, Ziyu Shen, Chong Zhang, Yue Zhang, Xiao Wang, Shihan Dou, Jihua Kang, Jiazheng Zhang, Qi Zhang

## 增强组合检索：为构建信息性 环境检索步骤。
Reinforcing Compositional Retrieval: Retrieving Step-by-Step for Composing Informative Contexts
Quanyu Long, Jianda Chen, Zhengyuan Liu, Nancy F. Chen, Wenya Wang, Sinno Jialin Pan

## 分层安全重新对齐：大型视觉-语言模型剪枝后轻量级的安全恢复。
Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models
Yue Li, Xin Yi, Dongsheng Shi, Gerard de Melo, Xiaoling Wang, Linlin Wang

## OpenHuEval：评估匈牙利语特定问题的大语言模型。
OpenHuEval: Evaluating Large Language Model on Hungarian Specifics
Haote Yang, Xingjian Wei, Jiang Wu, Noémi Ligeti-Nagy, Jiaxing Sun, Yingfan Wang, Győző Zijian Yang, Junyuan Gao, Jingchao Wang, Bowen Jiang, Shasha Wang, Nanjun Yu, Zihao Zhang, Shixin Hong, Hongwei Liu, Wei Li, Songyang Zhang, Dahua Lin, Lijun Wu, Gábor Prószéky, Conghui He

## 未经编辑的希腊语的词干提取与形态分析：简单的任务是否需要复杂的解决方案？
Lemmatisation & Morphological Analysis of Unedited Greek: Do Simple Tasks Need Complex Solutions?
Colin Swaelens, Ilse De Vos, Els Lefever

## Towards a 更好的初始策略模型 以实现可扩展的长上下文推理强化学习。
Towards A Better Initial Policy Model For Scalable Long-CoT Reinforcement Learning
Bofei Gao, Yejie Wang, Yibo Miao, Feifan Song, Longhui Yu, Tianyu Liu, Baobao Chang

## LongDPO：通过批判增强的逐步信息提升LLM的长文生成能力
LongDPO: Unlock Better Long-form Generation Abilities for LLMs via Critique-augmented Stepwise Information
Bowen Ping, Jiali Zeng, Fandong Meng, Shuo Wang, Jie Zhou, Shanghang Zhang

## 链式审查：检测大型语言模型中的后门攻击。
Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models
Xi Li, Ruofan Mao, Yusen Zhang, Renze Lou, Chen Wu, Jiaqi Wang

## 探究并增强多模态大型语言模型中的视觉-音频能力。
Investigating and Enhancing Vision-Audio Capability in Omnimodal Large Language Models
Rui Hu, Delai Qiu, Shuyu Wei, Jiaming Zhang, Yining Wang, Shengping Liu, Jitao Sang

## FRAME：反馈改进的代理方法，用于增强医疗研究洞见。
FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights
Chengzhang Yu, Yiming Zhang, Zhixin Liu, Zenghui Ding, Yining Sun, Zhanpeng Jin

## 基于最优传输聚类的短文本主题建模。
Topic Modeling for Short Texts via Optimal Transport-Based Clustering
Tu Vu, Manh Do, Tung Nguyen, Linh Ngo Van, Sang Dinh, Thien Huu Nguyen

## SEE：顺序专家集成的持续微调。
SEE: Continual Fine-tuning with Sequential Ensemble of Experts
Zhilin Wang, Yafu Li, Xiaoye Qu, Yu Cheng

## 神经元激活调节在文本风格转换中的应用：引导大规模语言模型。
Neuron Activation Modulation for Text Style Transfer: Guiding Large Language Models
Chaona Kong, Jianyi Liu, Yifan Tang, Ru Zhang

## MTVQA：多语言文本中心视觉问答基准测试。
MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering
Jingqun Tang, Qi Liu, Yongjie Ye, Jinghui Lu, Shu Wei, An-Lan Wang, Chunhui Lin, Hao Feng, Zhen Zhao, Yanjie Wang, Yuliang Liu, Hao Liu, Xiang Bai, Can Huang

## HICD：通过注意力分散诱导幻觉以对比解码减轻大型语言模型中的幻觉。
HICD: Hallucination-Inducing via Attention Dispersion for Contrastive Decoding to Mitigate Hallucinations in Large Language Models
Xinyan Jiang, Hang Ye, Yongxin Zhu, Xiaoying Zheng, Zikang Chen, Jun Gong

## CTPD：跨模态时间模式发现，以增强多模态电子健康记录分析。
CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis
Fuying Wang, Feng Wu, Yihan Tang, Lequan Yu

## 代码切换课程学习在LLM多语言迁移中的应用。
Code-Switching Curriculum Learning for Multilingual Transfer in LLMs
Haneul Yoo, Cheonbok Park, Sangdoo Yun, Alice Oh, Hwaran Lee

## Tag-Evol：通过标签注入实现高效的指令演化。
Tag-Evol: Achieving Efficient Instruction Evolving via Tag Injection
Yixuan Wang, Shiqi Zhou, Chuanzhe Guo, Qingfu Zhu

## LCHAIM - 探究希伯来语中的长期上下文推理。
LCHAIM - Investigating Long Context Reasoning in Hebrew
Ehud Malul, Oriel Perets, Ziv Mor, Yigal Kassel, Elior Sulem

## LGAR：零样本LLM引导的神经排序方法在系统文献综述中的摘要筛选。
LGAR: Zero-Shot LLM-Guided Neural Ranking for Abstract Screening in Systematic Literature Reviews
Christian Jaumann, Andreas Wiedholz, Annemarie Friedrich

## 题目：可见性即生存：通用化自然语言处理以识别原住民阿拉斯加语言。
Visibility as Survival: Generalizing NLP for Native Alaskan Language Identification
Ivory Yang, Chunhui Zhang, Yuxin Wang, Zhongyu Ouyang, Soroush Vosoughi

## CLeVeR：多模态对比学习在漏洞代码表示中的应用。
CLeVeR: Multi-modal Contrastive Learning for Vulnerability Code Representation
Jiayuan Li, Lei Cui, Sen Zhao, Yun Yang, Lun Li, Hongsong Zhu

## GeNRe：一种使用集体名词的法语中性性别重写系统。
GeNRe: a French Gender-Neutral Rewriting System Using Collective Nouns
Enzo Doyen, Amalia Todirascu

## 通过TMP适配器进行排名列表截断的相关性得分校准。
Relevance Scores Calibration for Ranked List Truncation via TMP Adapter
Pavel Posokhov, Sergei Masliukhin, Skrylnikov Stepan, Danil Tirskikh, Olesia Makhnytkina

## 从特征视角理解大型语言模型中的重复诅咒。
Understanding the Repeat Curse in Large Language Models from a Feature Perspective
Junchi Yao, Shu Yang, Jianhua Xu, Lijie Hu, Mengdi Li, Di Wang

## 大型语言模型在预测分析中的应用：它们的发展程度如何？
Large Language Models for Predictive Analysis: How Far Are They?
Qin Chen, Yuanyi Ren, Xiaojun Ma, Yuyang Shi

## 突破天花板：通过扩展策略空间探索越狱攻击的潜力。
Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space
Yao Huang, Yitong Sun, Shouwei Ruan, Yichi Zhang, Yinpeng Dong, Xingxing Wei

## 一个捕鼠夹：通过迭代混沌链欺骗大型推理模型以实现脱疆。
A Mousetrap: Fooling Large Reasoning Models for Jailbreak with Chain of Iterative Chaos
Yang Yao, Xuan Tong, Ruofan Wang, Yixu Wang, Lujundong Li, Liang Liu, Yan Teng, Yingchun Wang

## MEMIT-Merge：在LLMs同一主题批量编辑中解决MEMIT的关键值冲突。
MEMIT-Merge: Addressing MEMIT’s Key-Value Conflicts in Same-Subject Batch Editing for LLMs
Zilu dong, Xiangqing Shen, Rui Xia

## 文档分割对于检索增强生成很重要。
Document Segmentation Matters for Retrieval-Augmented Generation
Zhitong Wang, Cheng Gao, Yufei Huang, Shuzheng Si, Kangyang Luo, Yuzhuo Bai, Wenhao Li, Tangjian Duan, Chuancheng Lv, Guoshan Lu, Gang Chen, Fanchao Qi, Chaojun Xiao, Maosong Sun

## 思考更多，幻觉更少：通过快速和慢速思考的双重过程减轻幻觉。
Think More, Hallucinate Less: Mitigating Hallucinations via Dual Process of Fast and Slow Thinking
Xiaoxue Cheng, Junyi Li, Xin Zhao, Ji-Rong Wen

## 一种基于语义的层固定方法，用于高效语言模型微调。
A Semantic-Aware Layer-Freezing Approach to Computation-Efficient Fine-Tuning of Language Models
Jian Gu, Aldeida Aleti, Chunyang Chen, Hongyu Zhang

## CNNSum：利用大规模语言模型探索中文小说的长文摘要技术。
CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels
Lingxiao Wei, He Yan, Lu Xiangju, Junmin Zhu, Jun Wang, Wei Zhang

## Towards自适应记忆驱动优化以增强检索增强生成。
Towards Adaptive Memory-Based Optimization for Enhanced Retrieval-Augmented Generation
Qitao Qin, Yucong Luo, Yihang Lu, Zhibo Chu, Xiaoman Liu, Xianwei Meng

## 更聪明，不是更努力：无需训练的自适应计算方法for Transformers。
Smarter, Not Harder: Training-Free Adaptive Computation for Transformers
Romain Storaï, Jaeseong Lee, seung-won hwang

## Flow2Code：评估基于流程图的代码生成能力的大语言模型
Flow2Code: Evaluating Large Language Models for Flowchart-based Code Generation Capability
Mengliang He, Jiayi Zeng, Yankai Jiang, Wei Zhang, Zeming Liu, Xiaoming Shi, Aimin Zhou

## UBench：使用多项选择题评估大型语言模型的不确定性。
UBench: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions
Xunzhi Wang, Zhuowei Zhang, Gaonan Chen, Qiongyu Li, Bitong Luo, Zhixin Han, Haotian Wang, Zhiyu li, Hang Gao, Mengting Hu

## CodePRM：代码生成的执行反馈增强过程奖励模型。
CodePRM: Execution Feedback-enhanced Process Reward Model for Code Generation
Qingyao Li, Xinyi Dai, Xiangyang Li, Weinan Zhang, Yasheng Wang, Ruiming Tang, Yong Yu

## 检索视觉对比解码以减轻大型视觉-语言模型中的对象幻觉。
Retrieval Visual Contrastive Decoding to Mitigate Object Hallucinations in Large Vision-Language Models
Jihoon Lee, Min Song

## 双向思考：教师与学生双向推理增强多项选择题生成及干扰项质量。
Think Both Ways: Teacher-Student Bidirectional Reasoning Enhances MCQ Generation and Distractor Quality
Yimiao Qiu, Yang Deng, Quanming Yao, Zhimeng Zhang, Zhiang Dong, Chang Yao, Jingyuan Chen

## 增强跨Tokenizer知识精简的上下文动态映射。
Enhancing Cross-Tokenizer Knowledge Distillation with Contextual Dynamical Mapping
Yijie Chen, Yijin Liu, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou

## STEM-POM：评估文档解析中语言模型的数学符号推理能力。
STEM-POM: Evaluating Language Models Math-Symbol Reasoning in Document Parsing
Jiaru Zou, Qing Wang, Pratyush Thakur, Nickvash Kani

## 通过蒙特卡罗树搜索提升开放领域问答中的策略和过程奖励模型
Boosting Policy and Process Reward Models with Monte Carlo Tree Search in Open-Domain QA
Chi-Min Chan, Chunpu Xu, Junqi Zhu, Jiaming Ji, Donghai Hong, Pengcheng Wen, Chunyang Jiang, Zhen Ye, Yaodong Yang, Wei Xue, Sirui Han, Yike Guo

## UCS-SQL：综合内容与结构以增强文本到SQL的语义桥梁构建
UCS-SQL: Uniting Content and Structure for Enhanced Semantic Bridging In Text-to-SQL
Zhenhe Wu, Zhongqiu Li, JieZhangChinaTele, Zhongjiang He, Jian Yang, Yu Zhao, Ruiyu Fang, Bing Wang, Hongyan Xie, Shuangyong Song, Zhoujun Li

## REALM：现实世界大型语言模型应用场景数据集。
REALM: A Dataset of Real-World LLM Use Cases
Jingwen Cheng, Kshitish Ghate, Wenyue Hua, William Yang Wang, Hong Shen, Fei Fang

## MECoT：马尔可夫情绪链思考，用于性格一致的角色扮演。
MECoT: Markov Emotional Chain-of-Thought for Personality-Consistent Role-Playing
Yangbo Wei, Zhen huang, Fangzhou Zhao, Qi Feng, WEI W. XING

## Word2Passage：基于单词级别重要性加权的查询扩展方法
Word2Passage : Word-level Importance Re-weighting for Query Expansion
Jeonghwan Choi, Minjeong Ban, Minseok Kim, Hwanjun Song

## 利用大模型进行孟加拉语语法错误修正：错误分类、合成数据和模型评估。
Leveraging LLMs for Bangla Grammar Error Correction: Error Categorization, Synthetic Data, and Model Evaluation
Pramit Bhattacharyya, Arnab Bhattacharya

## mmE5：通过高质量合成数据改进多模态多语言嵌入。
mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data
Haonan Chen, Liang Wang, Nan Yang, Yutao Zhu, Ziliang Zhao, Furu Wei, Zhicheng Dou

## BABELEDITS：一种基准和模块化方法，用于大型语言模型的鲁棒跨语言知识编辑。
BABELEDITS: A Benchmark and a Modular Approach for Robust Cross-lingual Knowledge Editing of Large Language Models
Tommaso Green, Félix Gaschi, Fabian David Schmidt, Simone Paolo Ponzetto, Goran Glavaš

## SQLForge：生成可靠且多样的数据以增强LLMs中文本到SQL推理能力。
SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs
Yu Guo, Dong Jin, Shenghao Ye, Shuangwu chen, jianyang, Xiaobin Tan

## Self-Foveate：通过多级注视增强无监督文本合成指令的多样性和难易程度。
Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation
Mingzhe Li, Xin Lu, Yanyan Zhao

## 任务无关的语音大语言模型预训练的对比学习方法
Contrastive Learning for Task-Independent SpeechLLM-Pretraining
Maike Züfle, Jan Niehues

## BESSTIE：多种英语情感与讽刺分类基准。
BESSTIE: A Benchmark for Sentiment and Sarcasm Classification for Varieties of English
Dipankar Srirag, Aditya Joshi, Jordan Painter, Diptesh Kanojia

## NavRAG：通过检索增强LLM生成用户的导航指令。
NavRAG: Generating User Demand Instructions for Embodied Navigation through Retrieval-Augmented LLM
Zihan Wang, Yaohui Zhu, Gim Hee Lee, Yachun Fan

## 面向LLMs复杂推理的基于问题解决逻辑引导的在情境中学习课程设计。
Problem-Solving Logic Guided Curriculum In-Context Learning for LLMs Complex Reasoning
Xuetao Ma, Wenbin Jiang, Hua Huang

## ALW：自适应分层对比解码在大规模语言模型中增强推理能力。
ALW: Adaptive Layer-Wise contrastive decoding enhancing reasoning ability in Large Language Models
Yuechi Zhou, Chuyue Zhou, Jianxin Zhang, Juntao Li, Min Zhang

## 增强检索过程奖励模型以实现通用数学推理。
Retrieval-Augmented Process Reward Model for Generalizable Mathematical Reasoning
Jiachen Zhu, Congmin Zheng, Jianghao Lin, Kounianhua Du, Ying Wen, Yong Yu, Jun Wang, Weinan Zhang

## NMT模型对语法错误鲁棒性的一种表示层级分析。
A Representation Level Analysis of NMT Model Robustness to Grammatical Errors
Abderrahmane Issam, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis

## VidCapBench：可控文本到视频生成的全面视频字幕基准测试。
VidCapBench: A Comprehensive Benchmark of Video Captioning for Controllable Text-to-Video Generation
Xinlong Chen, Yuanxing Zhang, Chongling Rao, Yushuo Guan, Jiaheng Liu, Fuzheng Zhang, Chengru Song, Qiang Liu, Di ZHANG, Tieniu Tan

## 从特定-MLLMs到全能-MLLMs：多模态对齐的MLLLMs综述。
From Specific-MLLMs to Omni-MLLMs: A Survey on MLLMs Aligned with Multi-modalities
Shixin Jiang, Jiafeng Liang, Jiyuan Wang, Xuan Dong, Heng Chang, Weijiang Yu, Jinhua Du, Ming Liu, Bing Qin

## $T^2DR$：一种两层抗缺陷框架，用于不完整多模态学习。
$T^2DR$: A Two-Tier Deficiency-Resistant Framework for Incomplete Multimodal Learning
Han Lin, Xiu Tang, Huan Li, Wenxue Cao, Sai Wu, Chang Yao, Lidan Shou, Gang Chen

## 混合解码：一种受注意力机制启发的自适应解码策略，用于减轻大型视觉-语言模型中的幻觉现象。
Mixture of Decoding: An Attention-Inspired Adaptive Decoding Strategy to Mitigate Hallucinations in Large Vision-Language Models
Xinlong Chen, Yuanxing Zhang, Qiang Liu, Junfei Wu, Fuzheng Zhang, Tieniu Tan

## CDS：基于认知诊断理论的数据合成方法。
CDS: Data Synthesis Method Guided by Cognitive Diagnosis Theory
Haokun Zhao, Jinyi Han, Jiaqing Liang, Yanghua Xiao, Xiaojun Meng, Jiansheng Wei

## 最新的注意操作是由最新的注意算法生成的。
SOTA Attention Operator is generated by SOTA Attention Algorithm
Qirui Zhou, Shaohui Peng, Weiqiang Xiong, Haixin Chen, Yuanbo Wen, Haochen Li, Ling Li, Qi Guo, Yongwei Zhao, KE GAO, Ruizhi Chen, Yanjun Wu, Zhao Chen, Yunji Chen

## 大型语言模型内的语言连接性。
The Linguistic Connectivities Within Large Language Models
Dan Wang, Boxi Cao, Ning Bian, Xuanang Chen, Yaojie Lu, Hongyu Lin, Jia Zheng, Le Sun, Shanshan Jiang, Bin Dong, Xianpei Han

## 分析语言相似性对跨语言迁移影响：任务和实验设置很重要。
Analyzing the Effect of Linguistic Similarity on Cross-Lingual Transfer: Tasks and Experimental Setups Matter
Verena Blaschke, Masha Fedzechkina, Maartje Ter Hoeve

## 代理通过使用自适应语言策略来泛化到新的抽象层次。
Agents generalize to novel levels of abstraction by using adaptive linguistic strategies
Kristina Kobrock, Xenia Ohmer, Elia Bruni, Nicole Gotzner

## Align\\(^2\\)LLaVA：多层次人类与大型语言模型偏好对齐以实现多模态指令编纂。
Align$^2$LLaVA: Cascaded Human and Large Language Model Preference Alignment for Multi-modal Instruction Curation
Hongzhe Huang, Jiang Liu, Zhewen Yu, Li Cai, Dian Jiao, Wenqiao Zhang, Siliang Tang, Juncheng Li, Hao Jiang, Haoyuan Li, Yueting Zhuang

## 通过零空间约束减轻多语言知识编辑中的负干扰。
Mitigating Negative Interference in Multilingual Knowledge Editing through Null-Space Constraints
Wei Sun, Tingyu Qu, Mingxiao Li, Jesse Davis, Marie-Francine Moens

## 使用后训练量化实现LLM的二值权重和激活。
Achieving binary weight and activation for LLMs using Post-Training Quantization
Siqing Song, Chuang Wang, Rui-Qi Wang, Yi Yang, Xu-Yao Zhang

## 离线强化学习在大模型多步推理中的应用
Offline Reinforcement Learning for LLM Multi-step Reasoning
Huaijie Wang, Shibo Hao, Hanze Dong, Shenao Zhang, Yilin Bao, Ziran Yang, Yi Wu

## AMoPO：无需奖励模型和参考模型的自适应多目标偏好优化。
AMoPO: Adaptive Multi-objective Preference Optimization without Reward Models and Reference Models
Qi Liu, Jingqing Ruan, Hao Li, Haodong Zhao, Desheng Wang, Jiansong Chen, Wan Guanglu, Xunliang Cai, Zhi Zheng, Tong Xu

## AgentStore：大规模集成异构代理的专业通用计算机助手。
AgentStore: Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant
Chengyou Jia, Minnan Luo, Zhuohang Dang, Qiushi Sun, Fangzhi Xu, Junlin Hu, Tianbao Xie, Zhiyong Wu

## 基于抽样法的伪似然会员推断攻击。
Sampling-based Pseudo-Likelihood for Membership Inference Attacks
Masahiro Kaneko, Youmi Ma, Yuki Wata, Naoaki Okazaki

## 通过合成推理数据优化 curriculum 偏好的漏洞检测提升大语言模型安全性。
Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data
Xin-Cheng Wen, Yijun Yang, Cuiyun Gao, Yang Xiao, Qing Liao, Deheng Ye

## 从意识提升到适应性增强：提高科学推理中工具的利用能力。
From Awareness to Adaptability: Enhancing Tool Utilization for Scientific Reasoning
wenjing Xie, Xiaobo Liang, Juntao Li, Wanfu Wang, Kehai Chen, Qiaoming Zhu, Min Zhang

## NeuronMerge：通过功能神经元组融合模型
NeuronMerge: Merging Models via Functional Neuron Groups
Wangyun Gu, Qianghua Gao, Zhang Li-Xin, Xu Shen, Jieping Ye

## HellaSwag-Pro：一个大规模双语基准，用于评估LLMs在常识推理方面鲁棒性的能力。
HellaSwag-Pro: A Large-Scale Bilingual Benchmark for Evaluating the Robustness of LLMs in Commonsense Reasoning
Xiaoyuan Li, Moxin Li, Rui Men, Yichang Zhang, Keqin Bao, Wenjie Wang, Fuli Feng, Dayiheng Liu, Junyang Lin

## $GA-S^3$: 基于群体代理的综合社会网络仿真。
$GA-S^3$: Comprehensive Social Network Simulation with Group Agents
Yunyao Zhang, Zikai Song, Hang Zhou, Wenfeng Ren, Yi-Ping Phoebe Chen, Junqing Yu, Wei Yang

## 自我导向优化：大型语言模型的自主偏好优化。
Self-Steering Optimization: Autonomous Preference Optimization for Large Language Models
Hao Xiang, Bowen Yu, Hongyu Lin, Keming Lu, Yaojie Lu, Xianpei Han, Ben He, Le Sun, Jingren Zhou, Junyang Lin

## M-RangeDetector：通过多范围注意力面具增强机器生成文本检测的一般化能力。
M-RangeDetector: Enhancing Generalization in Machine-Generated Text Detection through Multi-Range Attention Masks
Kaijie Jiao, Quan Wang, Licheng Zhang, Zikang Guo, Zhendong Mao

## 语言模型的代码审查理解评估
The Code Review Comprehension Assessment for Language Models
Hong Yi Lin, Chunhua Liu, Haoyu Gao, Patanamon Thongtanunam, Christoph Treude

## 拥抱大型语言模型在交通流量预测中的应用。
Embracing Large Language Models in Traffic Flow Forecasting
Yusheng Zhao, Xiao Luo, Haomin Wen, Zhiping Xiao, Wei Ju, Ming Zhang

## 辩论、反思与提炼：基于树结构偏好优化的多代理反馈以实现高效语言模型增强。
Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement
Xiaofeng Zhou, Heyan Huang, Lizi Liao

## 政治 discourse 中叙事媒体框架的框架体系。
A Framework of Narrative Media Framing in Political Discourse
Yulia Otmakhova, Lea Frermann

## 语义拓扑：一种新的沟通风格 characterization 视角。
Semantic Topology: a New Perspective for Communication Style Characterization
Barbara Scalvini, Alireza Mashaghi

## MHALO：评估MLLMs作为细粒度幻觉检测器。
MHALO: Evaluating MLLMs as Fine-grained Hallucination Detectors
Yishuo Cai, Renjie Gu, Jiaxu Li, Xuancheng Huang, Junzhe Chen, Xiaotao Gu, Minlie Huang

## 解码大语言模型个性测量：强制选择 vs.李克特量表
Decoding LLM Personality Measurement: Forced-Choice vs. Likert
Xiaoyu Li, Haoran Shi, Zengyi Yu, Yukun Tu, Chanjin Zheng

## 具有文本-图像深入问题的多模态机器翻译。
Multimodal Machine Translation with Text-Image In-depth Questioning
Yue Gao, Jing Zhao, Shiliang Sun, Xiaosong Qiao, Tengfei Song, Hao Yang

## BadWindtunnel：在高噪声模拟训练中通过信心方差保护后门。
BadWindtunnel: Defending Backdoor in High-noise Simulated Training with Confidence Variance
Ruyi Zhang, Songlei Jian, Yusong Tan, Heng Gao, Haifang Zhou, Kai Lu

## MultiMSD：来自在线医疗参考的多语言医疗文本简化语料库。
MultiMSD: A Corpus for Multilingual Medical Text Simplification from Online Medical References
Koki Horiguchi, Tomoyuki Kajiwara, Takashi Ninomiya, Shoko Wakamiya, Eiji Aramaki

## 题目：CMIE：结合外部证据的LLM见解进行可上下文虚假信息检测。
CMIE: Combining MLLM Insights with External Evidence for Explainable Out-of-Context Misinformation Detection
Fanxiao Li, Jiaying Wu, Canyuan He, Wei Zhou

## HTML：层次拓扑多任务学习在知识库问答中的语义解析。
HTML: Hierarchical Topology Multi-task Learning for Semantic Parsing in Knowledge Base Question Answering
Aziguli Wulamu, Lyu Zhengyu, Kaiyuan Gong, Yu Han, Zewen Wang, Zhihong Zhu, Bowen Xing

## StructFlowBench：多轮指令遵循的结构化流基准。
StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction Following
Jinnan Li, Jinzhe Li, Yue Wang, Yi Chang, Yuan Wu

## ReKG-MCTS：通过无训练集蒙特卡洛树搜索强化大型语言模型在知识图谱上的推理能力。
ReKG-MCTS: Reinforcing LLM Reasoning on Knowledge Graphs via Training-Free Monte Carlo Tree Search
Xiaozhuang Song, Shufei Zhang, Tianshu Yu

## 理解大型语言模型中的标签偏见的方向。
Towards Understanding Etiquettical Bias in LLMs
Ashutosh Dwivedi, Siddhant Shivdutt Singh, Ashutosh Modi

## FiDeLiS：大规模语言模型在知识图谱问答中的忠实推理。
FiDeLiS: Faithful Reasoning in Large Language Models for Knowledge Graph Question Answering
Yuan Sui, Yufei He, Nian Liu, Xiaoxin He, Kun Wang, Bryan Hooi

## LIME：少即是多的MLLM评估方法。
LIME: Less Is More for MLLM Evaluation
King Zhu, Qianbo Zang, Shian Jia, Siwei Wu, Feiteng Fang, Yizhi LI, Shuyue Guo, Tianyu Zheng, Jiawei Guo, Bo Li, Haoning Wu, Xingwei Qu, Jian Yang, Ruibo Liu, Xiang Yue, Jiaheng Liu, Chenghua Lin, Hamid Alinejad-Rokny, Min Yang, Shiwen Ni, Wenhao Huang, Ge Zhang

## FinRipple：使大型语言模型与金融市场对事件涟漪效应保持一致。
FinRipple: Aligning Large Language Models with Financial Market for Event Ripple Effect Awareness
Yuanjian Xu, Jianing Hao, Kunsheng Tang, Jingnan Chen, Anxian Liu, Peng LIU, Guang Zhang

## 规模的陷阱：探索大型语言模型中重新定义的逆向任务。
Pitfalls of Scale: Investigating the Inverse Task of Redefinition in Large Language Models
Elena Stringli, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou

## 超越仅解码器：大型语言模型可以成为机器翻译良好的编码器。
Beyond Decoder-only: Large Language Models Can be Good Encoders for Machine Translation
yingfeng luo, Tong Zheng, Yongyu Mu, Bei Li, Qinghong Zhang, Yongqi Gao, Ziqiang Xu, Peinan Feng, Xiaoqian Liu, Tong Xiao, JingBo Zhu

## 学习多面向评估对齐：一个统一且稳健的框架。
Learning to Align Multi-Faceted Evaluation: A Unified and Robust Framework
Kaishuai Xu, Tiezheng YU, Yi Cheng, Wenjun Hou, Liangyou Li, Xin Jiang, Lifeng Shang, Qun Liu, Wenjie Li

## XFinBench：在复杂金融问题解决与推理中的 Large Language Models (LLMs) 基准测试。
XFinBench: Benchmarking LLMs in Complex Financial Problem Solving and Reasoning
Zhihan Zhang, Yixin Cao, Lizi Liao

## 变压器中的隐含推理是通过捷径进行的推理。
Implicit Reasoning in Transformers is Reasoning through Shortcuts
Tianhe Lin, Jian Xie, Siyu Yuan, Deqing Yang

## CortexDebate：多智能体辩论的稀疏平等参与方式。
CortexDebate: Debating Sparsely and Equally for Multi-Agent Debate
Yiliu Sun, Zicheng Zhao, Sheng Wan, Chen Gong

## 监督乐观校正：当大模型确信时保持信心。
Supervised Optimism Correction: Be Confident When LLMs Are Sure
Junjie Zhang, Rushuai Yang, Shunyu Liu, Ting-En Lin, Fei Huang, Yi Chen, Yongbin Li, Dacheng Tao

## 使用大型语言模型进行债务催收谈判：评价系统与多代理优化决策。
Debt Collection Negotiations with Large Language Models: An Evaluation System and Optimizing Decision Making with Multi-Agent
Xiaofeng Wang, Zhixin Zhang, Jin Guang Zheng, Yiming Ai, Rui Wang

## PAP2PAT：基于专利-论文配对的指导性概要长文本专利生成基准测试。
PAP2PAT: Benchmarking Outline-Guided Long-Text Patent Generation with Patent-Paper Pairs
Valentin Knappich, Anna Hätty, Simon Razniewski, Annemarie Friedrich

## 通过全球共进化的推理减轻示范偏见。
Mitigating Demonstration Bias through Global Coevolutionary Reasoning
Chuan Gou, Bangwei Li, Jianhua Dai, Xiaoyang Han, Ming Cai

## 集中优化-DPO：通过对易出错点的集中偏好优化来增强代码生成。
Focused-DPO: Enhancing Code Generation Through Focused Preference Optimization on Error-Prone Points
Kechi Zhang, Ge Li, Jia Li, Yihong Dong, Jia Li, Zhi Jin

## R-VLM：面向区域的视觉语言模型，用于精确的GUI定位。
R-VLM: Region-Aware Vision Language Model for Precise GUI Grounding
Joonhyung Park, Peng Tang, Sagnik Das, srikar appalaraju, Kunwar Yashraj Singh, R. Manmatha, Shabnam Ghadar

## 大型语言模型在解决主观任务中的视角转变。
Perspective Transition of Large Language Models for Solving Subjective Tasks
Xiaolong Wang, Yuanchi Zhang, Ziyue Wang, Yuzhuang Xu, Fuwen Luo, Yile Wang, Peng Li, Yang Liu

## 监督探查和无监督探查中的捷径学习研究：BERT中句法启发式算法的产生与演化案例研究
Supervised and Unsupervised Probing of Shortcut Learning: Case Study on the Emergence and Evolution of Syntactic Heuristics in BERT
Elke Vandermeerschen, Miryam de Lhoneux

## BiasGuard：一种增强推理的大型语言模型偏见检测工具。
BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language Models
Zhiting Fan, Ruizhe Chen, Zuozhu Liu

## MMXU：一种用于疾病进展的多模态和多X光理解数据集。
MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease Progression
Linjie Mu, Zhongzhen Huang, Shengqian Qin, Yakun Zhu, Shaoting Zhang, Xiaofan Zhang

## 你的语音助手会记得吗？分析语音交互模型中的对话上下文回忆与利用。
Does Your Voice Assistant Remember? Analyzing Conversational Context Recall and Utilization in Voice Interaction Models
Heeseung Kim, Che Hyun Lee, Sangkwon Park, Jiheum Yeom, Nohil Park, Sangwon Yu, Sungroh Yoon

## EC-RAFT：通过检索增强微调自动生成临床试验入组标准。
EC-RAFT: Automated Generation of Clinical Trial Eligibility Criteria through Retrieval-Augmented Fine-Tuning
Nopporn Lekuthai, Nattawit Pewngam, Supitcha Sokrai, Titipat Achakulvisut

## Qorǵau：评估哈萨克-俄语双语环境下的安全性。
Qorǵau: Evaluating Safety in Kazakh-Russian Bilingual Contexts
Maiya Goloburda, Nurkhan Laiyk, Diana Turmakhan, Yuxia Wang, Mukhammed Togmanov, Jonibek Mansurov, Askhat Sametov, Nurdaulet Mukhituly, Minghan Wang, Daniil Orel, Zain Muhammad Mujahid, Fajri Koto, Timothy Baldwin, Preslav Nakov

## GIMMICK：全球包容性多模态多任务文化知识基准评估。
GIMMICK: Globally Inclusive Multimodal Multitask Cultural Knowledge Benchmarking
Florian Schneider, Carolin Holtermann, Chris Biemann, Anne Lauscher

## 结构自适应对抗对比学习在多领域虚假新闻检测中的应用
Structure-adaptive Adversarial Contrastive Learning for Multi-Domain Fake News Detection
Lingwei Wei, Dou Hu, Wei Zhou, Philip S. Yu, Songlin Hu

## Chain of Attack：通过多轮询问隐藏意图。
Chain of Attack: Hide Your Intention through Multi-Turn Interrogation
Xikang Yang, biyu zhou, Xuehai Tang, Jizhong Han, Songlin Hu

## Akan 影视情绪数据集（ACE）：一种用于电影对话情绪识别的多模态多说话人数据集。
Akan Cinematic Emotions (ACE): A Multimodal Multi-party Dataset for Emotion Recognition in Movie Dialogues
David Sasu, zehui wu, Ziwei Gong, Run Chen, Pengyuan Shi, Lin Ai, Julia Hirschberg, Natalie Schluter

## Migician：揭示多模态大型语言模型中自由形式多图像定位的魔力。
Migician: Revealing the Magic of Free-Form Multi-Image Grounding in Multimodal Large Language Models
You Li, Heyu Huang, Chi Chen, Kaiyu Huang, Chao Huang, Zonghao Guo, Zhiyuan Liu, Jinan Xu, Yuhua Li, Ruixuan Li, Maosong Sun

## SIKeD：自我引导迭代知识精炼方法在数学推理中的应用。
SIKeD: Self-guided Iterative Knowledge Distillation for Mathematical Reasoning
Shivam Adarsh, Kumar Shridhar, Caglar Gulcehre, Nicholas Monath, Mrinmaya Sachan

## MIG：通过最大化语义空间中的信息增益自动进行指令调优的数据选择方法。
MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space
Yicheng Chen, Yining Li, Kai Hu, Ma Zerun, HaochenYe, Kai Chen

## Tree-of-Code：一种用于复杂任务中端到端代码生成与执行的自生长树框架。
Tree-of-Code: A Self-Growing Tree Framework for End-to-End Code Generation and Execution in Complex Tasks
Ziyi Ni, YIFAN LI, Ning Yang, Dou Shen, Pin Lyu, daxiang dong

## 通过句法检索增强大规模语言模型的自动术语提取。
Enhancing Automatic Term Extraction in Large Language Models via Syntactic Retrieval
Yongchan Chun, Minhyuk Kim, Dongjun Kim, Chanjun Park, Heuiseok Lim

## 细粒度知识增强以增强检索增强生成。
Fine-grained Knowledge Enhancement for Retrieval-Augmented Generation
Jingxuan Han, Zhendong Mao, Yi Liu, Yexuan Che, Zheren Fu, Quan Wang

## EMPEC：评估大型语言模型在多元医疗专业领域中的全面基准。
EMPEC: A Comprehensive Benchmark for Evaluating Large Language Models Across Diverse Healthcare Professions
Zheheng Luo, Chenhan Yuan, Qianqian Xie, Sophia Ananiadou

## 通过LLM进行受控图像编辑的贝叶斯优化。
Bayesian Optimization for Controlled Image Editing via LLMs
Chengkun Cai, Haoliang Liu, Xu Zhao, Zhongyu Jiang, Tianfang Zhang, Zongkai Wu, Jenq-Neng Hwang, Serge Belongie, Lei Li

## 超越数值奖励：具有LLM代理的上下文 Dueling 贝叶斯算法。
Beyond Numeric Rewards: In-Context Dueling Bandits with LLM Agents
Fanzeng Xia, Hao Liu, Yisong Yue, Tongxin Li

## 具有个性化检索增强生成的可解释抑郁诊断在临床访谈中的应用。
Explainable Depression Detection in Clinical Interviews with Personalized Retrieval-Augmented Generation
Linhai Zhang, Ziyang Gao, Deyu Zhou, Yulan He

## 题目：基于双视角关键词引导的多跳疑问句生成。
Multi-Hop Question Generation via Dual-Perspective Keyword Guidance
Maodong Li, Longyin Zhang, Fang Kong

## “好吧，继续思考”：通过自适应注入解码提升LLM推理能力。
“Well, Keep Thinking”: Enhancing LLM Reasoning with Adaptive Injection Decoding
Hyunbin Jin, Je Won Yeom, Seunghyun Bae, Taesup Kim

## SPOT：在属性图上的零样本语义解析。
SPOT: Zero-Shot Semantic Parsing Over Property Graphs
Francesco Cazzaro, Justin Kleindienst, Sofia Márquez Gomez, Ariadna Quattoni

## LoRMA：低秩倍增适应性方法用于大规模语言模型。
LoRMA: Low Rank Multiplicative Adaptation for LLMs
Harsh Bihany, Shubham Patel, Ashutosh Modi

## 语言模型中的推理电路：演绎推理的机理解释。
Reasoning Circuits in Language Models: A Mechanistic Interpretation of Syllogistic Inference
Geonhee Kim, Marco Valentino, Andre Freitas

## MultiHoax：多跳虚假前提问题数据集
MultiHoax: A Dataset of Multi-hop False-premise questions
Mohammadamin Shafiei, Hamidreza Saffari, Nafise Sadat Moosavi

## DI-BENCH：大规模语言模型在依存关系推理方面的基准测试，附带可测试的大型仓库。
DI-BENCH: Benchmarking Large Language Models on Dependency Inference with Testable Repositories at Scale
Linghao Zhang, Junhao Wang, Shilin He, Chaoyun Zhang, Yu Kang, Bowen Li, Jiaheng Wen, Chengxing Xie, Maoquan Wang, Yufan Huang, Elsie Nallipogu, Qingwei Lin, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

## STATE ToxiCN：中文仇恨言论检测中面向目标的跨度级别毒性提取基准。
STATE ToxiCN: A Benchmark for Span-level Target-Aware Toxicity Extraction in Chinese Hate Speech Detection
Zewen Bai, shengdi yin, Junyu Lu, Jingjie Zeng, Haohao Zhu, Yuanyuan Sun, Liang Yang, Hongfei Lin

## RelEdit：通过关系推理评估语言模型中概念知识的编辑。
RelEdit: Evaluating Conceptual Knowledge Editing in Language Models via Relational Reasoning
Yifan Niu, Miao Peng, Nuo Chen, Yatao Bian, Tingyang Xu, Jia Li

## 学习像人类一样玩：一种在交互式虚构游戏中使大规模语言模型适应的框架。
Learning to Play Like Humans: A Framework for LLM Adaptation in Interactive Fiction Games
Jinming Zhang, Yunfei Long

## Context-DPO：提高上下文忠实性的语言模型对齐方法。
Context-DPO: Aligning Language Models for Context-Faithfulness
Baolong Bi, Shaohan Huang, Yiwei Wang, Tianchi Yang, Zihan Zhang, Haizhen Huang, Lingrui Mei, Junfeng Fang, Zehao Li, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang, Shenghua Liu

## 通过学习排序监督实现从弱到强的诚实对齐。
Weak-to-Strong Honesty Alignment via Learning-to-Rank Supervision
YunfanXie, Lixin Zou, Dan Luo, Min Tang, Chenliang Li

## 从逃避到隐秘：为大语言模型实现隐蔽的知识遗忘。
From Evasion to Concealment: Stealthy Knowledge Unlearning for LLMs
Tianle Gu, Kexin Huang, Ruilin Luo, Yuanqi Yao, Xiuying Chen, Yujiu Yang, Yan Teng, Yingchun Wang

## TableLLM：在实际办公使用场景中使大语言模型能够处理表格数据。
TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios
Xiaokang Zhang, Sijia Luo, Bohan Zhang, Zeyao Ma, Jing Zhang, Yang Li, Guanlin Li, Zijun Yao, Kangli Xu, Jinchang Zhou, Daniel Zhang-Li, Jifan Yu, Shu Zhao, Juanzi Li, Jie Tang

## 面向上下文的鲁棒知识编辑用于语言模型
Context Robust Knowledge Editing for Language Models
Haewon Park, Gyubin Choi, Minjun Kim, Yohan Jo

## 通过跨团队编排实现多Agent协作。
Multi-Agent Collaboration via Cross-Team Orchestration
Zhuoyun Du, Chen Qian, Wei Liu, Zihao Xie, YiFei Wang, Rennai Qiu, Yufan Dang, Weize Chen, Cheng Yang, Ye Tian, Xuantang Xiong, Lei Han

## 基于认知写作的约束长文本生成视角。
A Cognitive Writing Perspective for Constrained Long-Form Text Generation
Kaiyang Wan, Honglin Mu, Rui Hao, Haoran Luo, Tianle Gu, Xiuying Chen

## 基于LLM的医疗代理调研。
A Survey of LLM-based Agents in Medicine
Wenxuan Wang, Zizhan Ma, Zheng WANG, Chenghan Wu, Jiaming Ji, Wenting Chen, Xiang Li, Yixuan Yuan

## 利用查询重写解锁语音指令数据的潜力。
Unlocking Speech Instruction Data Potential with Query Rewriting
Yonghua Hei, Yibo Yan, Shuliang Liu, Huiyu Zhou, Linfeng Zhang, Xuming Hu

## 优化的テキスト埋め込みモデルとアンハリック段落検索の基准比较。
Optimized Text Embedding Models and Benchmarks for Amharic Passage Retrieval
Kidist Amde Mekonnen, Yosef Worku Alemneh, Maarten de Rijke

## 使用具有多样外部知识的LLM增强自然语言到信号时序逻辑的转换。
Enhancing Transformation from Natural Language to Signal Temporal Logic Using LLMs with Diverse External Knowledge
Yue Fang, Zhi Jin, Jie An, Hongshen Chen, Xiaohong Chen, Naijun Zhan

## DAGS：一种基于依赖关系的双注意机制与全局语义改进框架用于隐喻识别。
DAGS: A Dependency-Based Dual-Attention and Global Semantic Improvement Framework for Metaphor Recognition
Puli Chen, Cheng Yang, Xingmao Zhang, Qingbao Huang

## ESF：高效的敏感指纹技术，用于大型语言模型的黑盒篡改检测。
ESF: Efficient Sensitive Fingerprinting for Black-Box Tamper Detection of Large Language Models
Xiaofan Bai, Pingyi Hu, Xiaojing Ma, Bin Benjamin Zhu, Linchen Yu, Dongmei Zhang, Qi Zhang

## 朝向用户控制的临床文本生成自适应。
Towards Conditioning Clinical Text Generation for User Control
Osman Alperen Koraş, Rabi Bahnan, Jens Kleesiek, Amin Dada

## Q-Mamba：通过后训练量化实现更高效的Mamba模型。
Q-Mamba: Towards more efficient Mamba models via post-training quantization
Chen Tianqi, Yuanteng Chen, Peisong Wang, Weixiang Xu, Zeyu Zhu, Jian Cheng

## TripTailor：个性行程规划的现实基准。
TripTailor: A Real-World Benchmark for Personalized Travel Planning
Kaimin Wang, Yuanzhe Shen, Changze Lv, Xiaoqing Zheng, Xuanjing Huang

## 通过NLI微调评估多语言数据到文本生成的语义：精确度、召回率和F1分数。
Semantic Evaluation of Multilingual Data-to-Text Generation via NLI Fine-Tuning: Precision, Recall and F1 scores
William Soto Martinez, Yannick Parmentier, Claire Gardent

## CoDet-M4：在多语言、多生成器和多领域设置中检测机器生成代码。
CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings
Daniil Orel, Dilshod Azizov, Preslav Nakov

## SpeechT-RAG：利用语音时序信息的检索增强生成方法在大规模语言模型中实现可靠的抑郁检测。
SpeechT-RAG: Reliable Depression Detection in LLMs with Retrieval-Augmented Generation Using Speech Timing Information
Xiangyu Zhang, Hexin Liu, Qiquan Zhang, Beena Ahmed, Julien Epps

## 基于大规模语言模型排序句子生成的句嵌表示优化内容。
Refining Sentence Embedding Model through Ranking Sentences Generation with Large Language Models
Liyang He, Chenglong Liu, Rui Li, Zhenya Huang, Shulan Ruan, JUN ZHOU, Enhong Chen

## 论文标题翻译：推理并不 necessarily 提高角色扮演能力。 \n\n注：\"necessarily\" 在这句话中显得不太自然，可能是原文中的某个特定含义。若保持原文意义，可以翻译为：\"推理并不一定会提高角色扮演能力。\"
Reasoning Does Not Necessarily Improve Role-Playing Ability
Xiachong Feng, Longxu Dou, Lingpeng Kong

## P²Net：用于复杂布局中关键信息提取的并行指针网络。
P²Net: Parallel Pointer-based Network for Key Information Extraction with Complex Layouts
kaiwen wei, Jie Yao, Jiang Zhong, Yangyang Kang, Jingyuan Zhang, Changlong Sun, Xin Zhang, Fengmao Lv, Li Jin

## taz2024full：分析几十年来德国报纸中的性别偏见与歧视。
taz2024full: Analysing German Newspapers for Gender Bias and Discrimination across Decades
Stefanie Urchs, Veronika Thurner, Matthias Aßenmacher, Christian Heumann, Stephanie Thiemichen

## RQT：多模型压缩的分级残差量化。
RQT: Hierarchical Residual Quantization for Multi-Model Compression
Chen Tianqi, Peisong Wang, Weixiang Xu, Zeyu Zhu, Jian Cheng

## 基于跨度的语义角色标注作为词汇化构词树解析。
Span-based Semantic Role Labeling as Lexicalized Constituency Tree Parsing
Yang Hou, Zhenghua Li

## 通过计算运行时进行自我对弈以提高图表推理能力。
Self-play through Computational Runtimes improves Chart Reasoning
Tautvydas Misiūnas, Hassan Mansoor, Jasper Uijlings, Oriana Riva, Victor Carbune

## LCFO：长上下文和长形式输出的数据集和基准测试。
LCFO: Long Context and Long Form Output Dataset and Benchmarking
Marta R. Costa-jussà, Pierre Andrews, Mariano Coria Meglioli, Joy Chen, Joe Chuang, David Dale, Christophe Ropers, Alexandre Mourachko, Eduardo Sánchez, Holger Schwenk, Tuan A. Tran, Arina Turkatenko, Carleigh Wood

## 学习 biomedical 生omedical 生成实体链接中的负样本。 \n\n注意：标题中的“biomedical”重复出现且“generative”在目标语言中可能需要更流畅的表达，但具体领域术语应保持不变。如果您有特定的领域术语翻译建议，请告知。
Learning from Negative Samples in Biomedical Generative Entity Linking
Chanhwi Kim, Hyunjae Kim, Sihyeon Park, Jiwoo Lee, Mujeen Sung, Jaewoo Kang

## 迈向更优秀的链式思维：关于有效性与忠實性的反思。
Towards Better Chain-of-Thought: A Reflection on Effectiveness and Faithfulness
Jiachun Li, Pengfei Cao, Yubo Chen, Jiexin Xu, Huaijun Li, Xiaojian Jiang, Kang Liu, Jun Zhao

## CoMuMDR：代码混排多模态多领域语料库，用于会话中的 Discourse 解析。
CoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in conversations
Divyaksh Shukla, Ritesh Baviskar, Dwijesh Gohil, Aniket Tiwari, Atul Shree, Ashutosh Modi

## 题目：一个懒人沙发土豆并不等于沙发上的土豆： noun 复合词的提示策略、图像生成和组合预测。
A Couch Potato is not a Potato on a Couch: Prompting Strategies, Image Generation, and Compositionality Prediction for Noun Compounds
Sinan Kurtyigit, Diego Frassinelli, Carina Silberer, Sabine Schulte im Walde

## 动态邪恶分数引导解码：一种高效的红队模型解码框架。
Dynamic Evil Score-Guided Decoding: An Efficient Decoding Framework For Red-Team Model
Cong Gao, Bo Zhang, Linkang Yang, Minghao Hu, Zhunchen Luo, Xiaoying Bai, Guotong Geng, Jun Zhang, Yunhua XUE

## 多词度量：复合名词中语义变化的建模
Multi-word Measures: Modeling Semantic Change in Compound Nouns
Chris Jenkins, Filip Miletić, Sabine Schulte im Walde

## 一种评估评估词汇语义变化维度方法的一般框架，使用LLM生成的合成数据。
A General Framework to Evaluate Methods for Assessing Dimensions of Lexical Semantic Change Using LLM-Generated Synthetic Data
Naomi Baes, Raphael Merx, Nick Haslam, Ekaterina Vylomova, Haim Dubossarsky

## 2M-BELEBELE：大规模多语种语音和美国手语理解数据集 下载PDF
2M-BELEBELE: Highly Multilingual Speech and American Sign Language Comprehension Dataset Download PDF
Marta R. Costa-jussà, Bokai YU, Pierre Andrews, Belen Alastruey, Necati Cihan Camgoz, Joe Chuang, Jean Maillard, Christophe Ropers, Arina Turkatenko, Carleigh Wood

## ProBench：评估多模态基础模型在开放域多领域专家任务中的表现。
ProBench: Judging Multimodal Foundation Models on Open-ended Multi-domain Expert Tasks
Yan Yang, Dongxu Li, Haoning Wu, Bei Chen, Liu Liu, Liyuan Pan, Junnan Li

## 分词对语言变体敏感。
Tokenization is Sensitive to Language Variation
Anna Wegmann, Dong Nguyen, David Jurgens

## 通过逐步编辑进行图像生成模型链式越狱攻击。
Chain-of-Jailbreak Attack for Image Generation Models via Step by Step Editing
Wenxuan Wang, Kuiyi Gao, Youliang Yuan, Jen-tse Huang, Qiuzhi Liu, Shuai Wang, Wenxiang Jiao, Zhaopeng Tu

## WirelessMathBench：无线通信中LLM的数学建模基准。
WirelessMathBench: A Mathematical Modeling Benchmark for LLMs in Wireless Communications
Xin Li, Mengbing Liu, LI WEI, Jiancheng An, Merouane Abdelkader DEBBAH, Chau Yuen

## 桥接编码器：将高资源编程语言的能力转移到低资源编程语言。
Bridge-Coder: Transferring Model Capabilities from High-Resource to Low-Resource Programming Language
Jipeng Zhang, Jianshu Zhang, Yuanzhe LI, Renjie Pi, Rui Pan, Runtao Liu, Zheng Ziqiang, Tong Zhang

## 调查并扩展代码切换在多语言语言模型预训练中的应用。
Investigating and Scaling up Code-Switching for Multilingual Language Model Pre-Training
Zhijun Wang, Jiahuan Li, Hao zhou, Rongxiang Weng, Jingang Wang, Xin Huang, Xue Han, Junlan Feng, Chao Deng, Shujian Huang

## 将用户行为预测作为评估大型语言模型泛化能力的一种通用、稳健、可扩展且低成本的方法。
User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs
Sougata Saha, Monojit Choudhury

## 超越浏览：基于API的网络代理。
Beyond Browsing: API-Based Web Agents
Yueqi Song, Frank F. Xu, Shuyan Zhou, Graham Neubig

## MiLiC-Eval：评估中国少数民族语言的多语言LLM基准。
MiLiC-Eval: Benchmarking Multilingual LLMs for China’s Minority Languages
Chen Zhang, Mingxu Tao, Zhiyuan Liao, Yansong Feng

## 大规模语言模型中集体道德推理的概率聚合与目标嵌入优化。
Probabilistic Aggregation and Targeted Embedding Optimization for Collective Moral Reasoning in Large Language Models
Chenchen Yuan, Zheyu Zhang, Shuo Yang, Bardh Prenkaj, Gjergji Kasneci

## 开发过程奖励模型在数学推理中的教训。
The Lessons of Developing Process Reward Models in Mathematical Reasoning
Zhenru Zhang, Chujie Zheng, Yangzhen Wu, Beichen Zhang, Runji Lin, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin

## ArgInstruct：专门化的指令微调用于计算论证。
ArgInstruct: Specialized Instruction Fine-Tuning for Computational Argumentation
Maja Stahl, Timon Ziegenbein, Joonsuk Park, Henning Wachsmuth

## MEGen：通过模型 编辑生成大型语言模型中的后门。
MEGen: Generative Backdoor into Large Language Models via Model Editing
Jiyang Qiu, Xinbei Ma, Zhuosheng Zhang, hai zhao, Yun Li, Qianren Wang

## 随机拆分对命名实体识别评估产生负面影响：量化和消除命名实体识别性能的高估。
Random Splitting Negatively Impacts NER Evaluation: Quantifying and Eliminating the Overestimation of NER Performance
Florian Babl, Moritz Hennen, Jakob Murauer, Michaela Geierhos

## 社会偏见基准测试：生成与基于问答的评估比较。
Social Bias Benchmark for Generation: A Comparison of Generation and QA-Based Evaluations
Jiho Jin, Woosung Kang, Junho Myung, Alice Oh

## Math2Visual：一个生成教学数学应用题有意义可视化图形的框架。
Math2Visual: A Framework for Generating Pedagogically Meaningful Visuals for Teaching Math Word Problems
Junling Wang, Anna Rutkiewicz, April Wang, Mrinmaya Sachan

## 解锁LLMs的递归思维：通过细化实现对齐。
Unlocking Recursive Thinking of LLMs: Alignment via Refinement
Haoke Zhang, xiaobo liang, Cunxiang Wang, Juntao Li, Min Zhang

## 测量真正重要的内容：通过标签细化在归纳编码中评估集成大规模语言模型。
Measuring What Matters: Evaluating Ensemble LLMs with Label Refinement in Inductive Coding
Angelina Parfenova, Jürgen Pfeffer

## 并非shine一切皆黄金：通过事实为中心的偏好对齐提升稳健的检索增强语言模型。
All That Glitters is Not Gold: Improving Robust Retrieval-Augmented Language Models with Fact-Centric Preference Alignment
Jia Hao, Chunhong Zhang, Jiarun Liu, Haiyu Zhao, Zhiqiang Zhan, Zheng Hu

## FairSteer：基于动态激活导向的LLM推理时 debiasing 方法。
FairSteer: Inference Time Debiasing for LLMs with Dynamic Activation Steering
Yichen Li, Zhiting Fan, Ruizhe Chen, Xiaotang Gai, Luqi Gong, Yan Zhang, Zuozhu Liu

## 观看、回忆并学习感受：用于复合情绪生成的检索增强情绪推理。
Listen, Watch, and Learn to Feel: Retrieval-Augmented Emotion Reasoning for Compound Emotion Generation
Zhuofan Wen, Zheng Lian, Shun Chen, Hailiang Yao, Longjiang Yang, Bin Liu, Jianhua Tao

## 学习选择受大型语言模型偏好为主的内部上下文示例。
Learning to Select In-Context Demonstration Preferred by Large Language Model
Zheng Zhang, Shaocheng Lan, Lei Song, Jiang Bian, Yexin Li, Kan Ren

## InfiniteICL：通过长期短期记忆转换突破上下文窗口大小限制。
InfiniteICL: Breaking the Limit of Context Window Size via Long Short-term Memory Transformation
Bowen Cao, Deng Cai, Wai Lam

## 向帕累托最优自我提升：缓解多目标对齐中的偏好冲突。
Self-Improvement Towards Pareto Optimality: Mitigating Preference Conflicts in Multi-Objective Alignment
Moxin Li, Yuantao Zhang, Wenjie Wang, Wentao Shi, Zhuo Liu, Fuli Feng, Tat-Seng Chua

## M3HG：多模态、多尺度和多类型节点图在对话中情感触发三元组提取中的应用
M3HG: Multimodal, Multi-scale, and Multi-type Node Heterogeneous Graph for Emotion Cause Triplet Extraction in Conversations
Qiao Liang, Ying Shen, Tiantian Chen, Lin Zhang

## 大型语言模型是自然视频流行度预测器。
Large Language Models Are Natural Video Popularity Predictors
Pratik Kayal, Pascal Mettes, Nima Dehmamy, Minsu Park

## 别名也一样：由大规模语言模型生成的解释可以作为人类解释的替代，用于收集自然语言推理中的标签分布。
A Rose by Any Other Name: LLM-Generated Explanations Are Good Proxies for Human Explanations to Collect Label Distributions on NLI
Beiduo Chen, Siyao Peng, Anna Korhonen, Barbara Plank

## DELMAN：动态防御大规模语言模型脱狱攻击的模型编辑方法
DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing
Yi Wang, Fenghua Weng, Sibei Yang, Zhan Qin, Minlie Huang, Wenjie Wang

## 你需要模仿才能成名：通过多代理对话解决会议纪要短缺问题。
You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with a Multi-Agent Conversations
Frederic Kirstein, Muneeb Khan, Jan Philip Wahle, Terry Ruas, Bela Gipp

## 从大型语言模型生成领域特定知识图谱。
Generating Domain-Specific Knowledge Graphs from Large Language Models
Marinela Parović, Ze Li, Jinhua Du

## RASPberry：基于检索增强的蒙特卡洛树自博弈与推理一致性多跳问答方法。
RASPberry: Retrieval-Augmented Monte Carlo Tree Self-Play with Reasoning Consistency for Multi-Hop Question Answering
Baixuan Li, Yunlong Fan, Tianyi Ma, Miao Gao, Chuanqi Shi, Zhiqiang Gao

## CitaLaw：在法律领域增强LLM的引文应用。
CitaLaw: Enhancing LLM with Citations in Legal Domain
Kepu Zhang, Weijie Yu, Sunhao Dai, Jun Xu

## LEMMA：从错误中学习以促进LLMs的数学进步。
LEMMA: Learning from Errors for MatheMatical Advancement in LLMs
Zhuoshi Pan, Yu Li, Honglin Lin, Qizhi Pei, Zinan Tang, Wei Wu, Chenlin Ming, H. Vicky Zhao, Conghui He, Lijun Wu

## 大规模语言模型是欠校准的上下文内学习者。
Large Language Models are Miscalibrated In-Context Learners
Chengzu Li, Han Zhou, Goran Glavaš, Anna Korhonen, Ivan Vulić

## 投票制准等于共识吗？多智能体辩论中的决策制定。
Voting or Consensus? Decision-Making in Multi-Agent Debate
Lars Benedikt Kaesberg, Jonas Becker, Jan Philip Wahle, Terry Ruas, Bela Gipp

## 具有反事实数据增强的修辞设备意识讽刺检测。
Rhetorical Device-Aware Sarcasm Detection with Counterfactual Data Augmentation
Qingqing Hong, Dongyu Zhang, Jiayi Lin, Dapeng Yin, Shuyue Zhu, Junli Wang

## 超越拼写奇迹：探究字符盲语言模型的子字符串意识。
Beyond the Spelling Miracle: Investigating Substring Awareness in Character-Blind Language Models
Cristiano Ciaccio, Marta Sartor, Alessio Miaschi, Felice Dell’Orletta

## MinosEval：通过LLM进行定制化开放型问答评估以区分事实性和非事实性 kukuku kukuko kukukokosukuukkosukosukUCTLULUTTUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUlklokukulkluklkuklkukKIKKKKKKKKKKKKKKKKKKKKKKKKKkkkkkukk君君君君君君� take kukuk kuk kuk kuk 命名评价：通过大语言模型区分事实性和非事实性ukuokusukososkusoskosukosukUKUKUKUKUKUKUKUKUKUKUKUKUKUKUKUKUKUKUKUKUKUKUKUKUKUKukuk kukuk kuk kuk kuk kukuk kuk kuk kuk kuk kuk kuk kuk kuk kuk kuk kuk kuk kukkekkekkokokokkokokokokokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkok kokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkok Kokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkokkkoko
MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs
Yongqi Fan, Yating Wang, Guandong Wang, Zhai Jie, Jingping Liu, Qi Ye, Tong Ruan

## 螃蟹：在黑盒环境中通过自动生成消费资源以对LLM进行DoS攻击。
Crabs: Consuming Resource via Auto-generation for LLM-DoS Attack under Black-box Settings
Yuanhe Zhang, Zhenhong Zhou, Wei Zhang, Xinyue Wang, Xiaojun Jia, Yang Liu, Sen Su

## 通过梯度匹配进行多-shot 在上下文学习的演示选择。
Selecting Demonstrations for Many-Shot In-Context Learning via Gradient Matching
Jianfei Zhang, Bei Li, Jun Bai, Rumei Li, Yanmeng Wang, Chenghua Lin, Wenge Rong

## STeCa：LLM智能体学习中的步级轨迹校准。
STeCa: Step-level Trajectory Calibration for LLM Agent Learning
Hanlin Wang, Jian Wang, Chak Tou Leong, Wenjie Li

## DOVE：一个面向有意义的大规模多维度预测数据集，用于LLM评估。
DOVE: A Large-Scale Multi-Dimensional Predictions Dataset Towards Meaningful LLM Evaluation
Eliya Habba, Ofir Arviv, Itay Itzhak, Yotam Perlitz, Elron Bandel, Leshem Choshen, Michal Shmueli-Scheuer, Gabriel Stanovsky

## DEMO：通过细粒度元素建模重新定义对话交互。
DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling
Minzheng Wang, Xinghua Zhang, Kun Chen, Nan Xu, Haiyang Yu, Fei Huang, Wenji Mao, Yongbin Li

## 论文题目：物理学：基础模型在解决博士资格考试物理问题中的基准测试。
Physics: Benchmarking Foundation Models for PhD-Qualifying Exam Physics Problem Solving
Kaiyue Feng, Yilun Zhao, Yixin Liu, Tianyu Yang, Chen Zhao, John Sous, Arman Cohan

## 快速简洁的文本-图形变换器是有效的链接预测器。
Fast-and-Frugal Text-Graph Transformers are Effective Link Predictors
Andrei Catalin Coman, Christos Theodoropoulos, Marie-Francine Moens, James Henderson

## DeTAM：通过目标注意力修改防御大型语言模型针对逃逸攻击。
DeTAM: Defending LLMs Against Jailbreak Attacks via Targeted Attention Modification
Yu Li, Han Jiang, Zhihua Wei

## ALPS：用于大型语言模型高效适应性的注意力定位与裁剪策略。
ALPS: Attention Localization and Pruning Strategy for Efficient Adaptation of Large Language Models
Hao Chen, Haoze Li, Zhiqing Xiao, Lirong Gao, Qi Zhang, Xiaomeng Hu, NINGTAO WANG, Xing Fu, Junbo Zhao

## NeoQA：基于证据的生成新闻事件问答。
NeoQA: Evidence-based Question Answering with Generated News Events
Max Glockner, Xiang Jiang, Leonardo F. R. Ribeiro, Iryna Gurevych, Markus Dreyer

## ChatMap：通过多agent合作挖掘人类思维过程以构建客户服务聊天机器人。
ChatMap: Mining Human Thought Processes for Customer Service Chatbots via Multi-Agent Collaboration
Xinyi Jiang, Tianyi Hu, Yuheng Qin, Guoming Wang, Zhou Huan, kehan chen, Gang Huang, Rongxing Lu, Siliang Tang

## P3: 提示促进提示。
P3: Prompts Promote Prompting
Xinyu Zhang, Yuanquan Hu, Fangchao Liu, Zhicheng Dou

## 多模态大型语言模型时代数学推理调研：基准、方法与挑战。
A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges
Yibo Yan, Jiamin Su, Jianxiang He, Fangteng FU, Xu Zheng, Yuanhuiyi Lyu, Kun Wang, Shen Wang, Qingsong Wen, Xuming Hu

## 被遗忘的多边形：多模态大型语言模型无视形状。
Forgotten Polygons: Multimodal Large Language Models are Shape-Blind
William Rudman, Michal Golovanevsky, Amir Bar, Vedant Palit, Yann LeCun, Carsten Eickhoff, Ritambhara Singh

## FIHA：使用戴维森场景图在大规模视觉语言模型中自动化细粒度幻觉评估。
FIHA: Automated Fine-grained Hallucinations Evaluations in Large Vision Language Models with Davidson Scene Graphs
Bowen Yan, Zhengsong Zhang, Liqiang Jing, Eftekhar Hossain, Xinya Du

## GeAR：增强图表示的检索增强生成代理。
GeAR: Graph-enhanced Agent for Retrieval-augmented Generation
Zhili Shen, Chenxin Diao, Pavlos Vougiouklis, Pascual Merita, Shriram Piramanayagam, Enting Chen, Damien Graux, Andre Melo, Ruofei Lai, Zeren Jiang, Zhongyang Li, YE QI, Yang Ren, Dandan Tu, Jeff Z. Pan

## MindBridge：通过记忆增强模态实现可扩展的跨模型知识编辑。
MindBridge: Scalable and Cross-Model Knowledge Editing via Memory-Augmented Modality
Shuaike Li, Kai Zhang, Qi Liu, Enhong Chen

## 关于语义原型角色在语义分析中的作用：LLM们对代理性了解多少？
On the Role of Semantic Proto-roles in Semantic Analysis: What do LLMs know about agency?
Elizabeth Spaulding, Shafiuddin Rehan Ahmed, James Martin

## 神经符号查询编译器
Neuro-Symbolic Query Compiler
Yuyao Zhang, Zhicheng Dou, Xiaoxi Li, Jiajie Jin, Yongkang Wu, Zhonghua Li, YE QI, Ji-Rong Wen

## 朝向适应开源大型语言模型以生成专家级临床笔记的方向
Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation
Hanyin Wang, Chufan Gao, Bolun Liu, Qiping Xu, Guleid Hussein, Mohamad El Labban, Kingsley Iheasirim, Hariprasad Reddy Korsapati, Chuck Outcalt, Jimeng Sun

## 揭示并缓解马姆巴的局部模式捷径。
Revealing and Mitigating the Local Pattern Shortcuts of Mamba
WangJie You, Zecheng Tang, Juntao Li, Lili Yao, Min Zhang

## 廉价字符噪声用于OCR鲁棒多语言嵌入。
Cheap Character Noise for OCR-Robust Multilingual Embeddings
Andrianos Michail, Juri Opitz, Yining Wang, Robin Meister, Rico Sennrich, Simon Clematide

## Slamming：在一天内使用单个GPU训练语音语言模型。
Slamming: Training a Speech Language Model on One GPU in a Day
Gallil Maimon, Avishai Elmakies, Yossi Adi

## 通过理据萃取提升大语言模型的翻译技能而不损失通用能力。
Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation
Junhong Wu, Yang Zhao, Yangyifan Xu, Bing Liu, Chengqing Zong

## Optima：针对基于LLM的多智能体系统的有效性与效率优化。
Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System
Weize Chen, Jiarui Yuan, Chen Qian, Cheng Yang, Zhiyuan Liu, Maosong Sun

## WebNLG-IT：通过机器翻译技术构建对齐的RDF-意大利语语料库。
WebNLG-IT: Construction of an aligned RDF-Italian corpus through Machine Translation techniques
Michael Oliverio, Pier Felice Balestrucci, Alessandro Mazzei, Valerio Basile

## 忘记标记和像素：重新思考多模态生成模型中概念忘却的梯度上升方法。
Forget the Token and Pixel: Rethinking Gradient Ascent for Concept Unlearning in Multimodal Generative Models
Jiaqi Li, Chuanyi Zhang, Miaozeng Du, Hui Zhang, Yongrui Chen, Qianshan Wei, Junfeng Fang, Ruipeng Wang, Sheng Bi, Guilin Qi

## 通过增长界矩阵方法实现对词语替换攻击的鲁棒性和泛化能力的桥梁构建。
Bridging Robustness and Generalization Against Word Substitution Attacks in NLP via the Growth Bound Matrix Approach
Mohammed Bouri, Adnane Saoud

## SEA-HELM：东南亚全方位语言模型评估。
SEA-HELM: Southeast Asian Holistic Evaluation of Language Models
Yosephine Susanto, Adithya Venkatadri Hulagadri, Jann Railey Montalan, Jian Gang Ngui, Xianbin Yong, Wei Qi Leong, Hamsawardhini Rengarajan, Peerat Limkonchotiwat, Yifan Mai, William Chandra Tjhi

## 探索逻辑形式的图表示以进行语言建模。
Exploring Graph Representations of Logical Forms for Language Modeling
Michael Sullivan

## TRANS-ZERO：自我对弈激励大规模语言模型进行多语种翻译，无需平行数据。
TRANS-ZERO: Self-Play Incentivizes Large Language Models for Multilingual Translation Without Parallel Data
Wei Zou, Sen Yang, Yu Bao, Shujian Huang, Jiajun Chen, Shanbo Cheng

## WMT24++：将WMT24的语言覆盖范围扩展到55种语言及方言。
WMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects
Daniel Deutsch, Eleftheria Briakou, Isaac Rayburn Caswell, Mara Finkelstein, Rebecca Galor, Juraj Juraska, Geza Kovacs, Alison Lui, Ricardo Rei, Jason Riesa, Shruti Rijhwani, Parker Riley, Elizabeth Salesky, Firas Trabelsi, Stephanie Winkler, Biao Zhang, Markus Freitag

## 一种符合性风险控制框架，用于评估粒度单词和CLIPScore质量估计的不确定性校准。
A Conformal Risk Control Framework for Granular Word Assessment and Uncertainty Calibration of CLIPScore Quality Estimates
Goncalo Emanuel Cavaco Gomes, Bruno Martins, Chrysoula Zerva

## 使用大型语言模型进行价格预测的分位数回归。
Quantile Regression with Large Language Models for Price Prediction
Nikhita Vedula, Dushyanta Dhyani, Laleh Jalali, Boris N. Oreshkin, Mohsen Bayati, Shervin Malmasi

## VAQUUM：模糊量词是否基于视觉数据？
VAQUUM: Are Vague Quantifiers Grounded in Visual Data?
Hugh Mee Wong, Rick Nouwen, Albert Gatt

## 题目：苏格拉底式思维链帮助大型语言模型成为更好的推理器。
Socratic Style Chain-of-Thoughts Help LLMs to be a Better Reasoner
Jiangbo Pei, Peiyu Liu, Xin Zhao, Aidong Men, Yang Liu

## 训练逐步验证器以供对话辅导代理使用：大型语言模型作为你的编程辅导老师之谜
Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors
Jian Wang, Yinpei Dai, Yichi Zhang, Ziqiao Ma, Wenjie Li, Joyce Chai

## 澄清指令文本中未指定的语篇关系。
Clarifying Underspecified Discourse Relations in Instructional Texts
Berfin Aktas, Michael Roth

## 事实一致性评估的故事：来自文档摘要评估的案例研究 nigeria
A Tale of Evaluating Factual Consistency: Case Study on Long Document Summarization Evaluation
Yang Zhong, Diane Litman

## AIGuard：电子商务AIGC风险的基准与轻量级检测方法
AIGuard: A Benchmark and Lightweight Detection for E-commerce AIGC Risks
Wenhua Zhang, Lixin Zou, Xuanrong Rao, Weicheng Li, Xiangyang Luo, Chubin Zhuang, Yongjie Hong, Zhen Qin, Hengyu Chang, Chenliang Li, Bo Zheng

## TransBench：打破障碍，构建适用于动态数字环境的可移植图形用户界面代理。
TransBench: Breaking Barriers for Transferable Graphical User Interface Agents in Dynamic Digital Environments
Yuheng Lu, Qian Yu, Hongru WANG, Zeming Liu, Wei Su, Yanping Liu, Yuhang Guo, Maocheng Liang, Yunhong Wang, Haifeng Wang

## CoVE：压缩词汇扩展打造更好的基于LLM的推荐系统。
CoVE: Compressed Vocabulary Expansion Makes Better LLM-based Recommender Systems
Haochen Zhang, Tianyi Zhang, Junze Yin, Oren Gal, Anshumali Shrivastava, Vladimir Braverman

## 顺序有讲究：探讨多约束指令遵循中的位置偏见。
Order Matters: Investigate the Position Bias in Multi-constraint Instruction Following
Jie Zeng, Qianyu He, Qingyu Ren, Jiaqing Liang, Weikang Zhou, Zeye Sun, Fei Yu, Yanghua Xiao

## A$^2$ATS：通过窗口旋转位置嵌入和查询意识向量量化实现的基于检索的KV缓存减少方法。
A$^2$ATS: Retrieval-Based KV Cache Reduction via Windowed Rotary Position Embedding and Query-Aware Vector Quantization
Junhui He, Junna Xing, Nan Wang, Rui Xu, Shangyu Wu, Peng Zhou, Qiang Liu, Chun Jason Xue, Qingan Li

## 评估预训练因果语言模型在同义词识别中的性能。
Evaluating Pretrained Causal Language Models for Synonymy
Ioana Ivan, Carlos Ramisch, Alexis Nasr

## 题目：CoT-VTM：基于链式思维推理的视觉到音乐生成。
CoT-VTM: Visual-to-Music Generation with Chain-of-Thought Reasoning
Xikang Guan, Zheng Gu, Jing Huo, Tianyu Ding, Yang Gao

## 专家混合最大分数路由
Maximum Score Routing For Mixture-of-Experts
Bowen Dong, Yilong Fan, Yutao Sun, Zhenyu Li, Tengyu Pan, zhou Xun, Jianyong Wang

## 善始者昌：由弱监督到强监督的低资源偏好对齐。
Well Begun is Half Done: Low-resource Preference Alignment by Weak-to-Strong Decoding
Feifan Song, Shaohang Wei, Wen Luo, Yuxuan Fan, Tianyu Liu, Guoyin Wang, Houfeng Wang

## 分离多跨度演变网络在时间知识图谱推理中的应用楽しさ barcelona
Disentangled Multi-span Evolutionary Network against Temporal Knowledge Graph Reasoning
Hao Dong, Ziyue Qiao, Zhiyuan Ning, Qi Hao, Yi Du, Pengyang Wang, Yuanchun Zhou

## 人类-大模型共进化：来自学术写作的证据
Human-LLM Coevolution: Evidence from Academic Writing
Mingmeng Geng, Roberto Trotta

## Time Course MechInterp：分析大型语言模型中组件和知识的演变。
Time Course MechInterp: Analyzing the Evolution of Components and Knowledge in Large Language Models
Ahmad Dawar Hakimi, Ali Modarressi, Philipp Wicke, Hinrich Schuetze

## CtrlA：通过固有控制进行自适应检索增强生成。
CtrlA: Adaptive Retrieval-Augmented Generation via Inherent Control
Liu Huanshuo, Hao Zhang, Zhijiang Guo, Jing Wang, Kuicai Dong, Xiangyang Li, Yi Quan Lee, Cong Zhang, Yong Liu

## GRAF：通过事实增强的图检索用于罗马尼亚法律多选题回答。
GRAF: Graph Retrieval Augmented by Facts for Romanian Legal Multi-Choice Question Answering
Cristian-George Craciun, Răzvan-Alexandru Smădu, Dumitru-Clementin Cercel, Mihaela-Claudia Cercel

## Express 💬 你所看到的 👀：多模态大语言模型能通过直觉符号理解解码视觉密码吗？
Express 💬 What You See 👀: Can Multimodal LLMs Decode Visual Ciphers with Intuitive Semiosis Comprehension?
Jiayi Kuang, Yinghui Li, Chen Wang, Haohao Luo, Ying Shen, Wenhao Jiang

## 理解胜于表达：LLM表示在完成之前包含了思维链成功的信息。
Knowing Before Saying: LLM Representations Encode Information About Chain-of-Thought Success Before Completion
Anum Afzal, Florian Matthes, Gal Chechik, Yftah Ziser

## 双重去偏差化以减轻噪声上下文学习对文本生成的影响。
Dual Debiasing for Noisy In-Context Learning for Text Generation
Siqi Liang, Sumyeong Ahn, Paramveer Dhillon, Jiayu Zhou

## 令人惊叹、定律与不足：当今大规模语言模型研究探析。
Awes, Laws, and Flaws From Today’s LLM Research
Adrian de Wynter

## ConFit v2：利用假设简历嵌入和备选次负样本挖掘改进简历-职位匹配。
ConFit v2: Improving Resume-Job Matching using Hypothetical Resume Embedding and Runner-Up Hard-Negative Mining
Xiao Yu, Ruize Xu, Chengyuan Xue, Jinzhong Zhang, Xu Ma, Zhou Yu

## DRS：深度问题重铸与结构化输出
DRS: Deep Question Reformulation With Structured Output
Zhecheng Li, Yiwei Wang, Bryan Hooi, Yujun Cai, Nanyun Peng, Kai-Wei Chang

## 迈向可解释的仇恨言论检测
A Step Towards Explainable Hate Speech Detection
Happy Khairunnisa Sariyanto, Diclehan Ulucan, Oguzhan Ulucan, Marc Ebner

## PipeSpec：打破层级LLM解码中阶段依赖性。
PipeSpec: Breaking Stage Dependencies in Hierarchical LLM Decoding
Bradley McDanel, Sai Qian Zhang, Yunhai Hu, Zining Liu

## BioHopR：生物医学领域多跳多答案推理基准测试。
BioHopR: A Benchmark for Multi-Hop, Multi-Answer Reasoning in Biomedical Domain
Yunsoo Kim, Yusuf Abdulle, Honghan Wu

## 《秩分与扩展》：基于谱系的分类扩展推理方法。
$\\textit{Rank, Chunk and Expand}$: Lineage-Oriented Reasoning for Taxonomy Expansion
Sahil Mishra, Kumar Arjun, Tanmoy Chakraborty

## LAM 模拟器：通过在线探索和反馈模拟为大规模动作模型训练提供数据生成方法。
LAM SIMULATOR: Advancing Data Generation for Large Action Models Trainings via Online Exploration and Feedback Simulation
Thai Quoc Hoang, Kung-Hsiang Huang, Shirley Kokane, Jianguo Zhang, Zuxin Liu, Ming Zhu, Jake Grigsby, Tian Lan, Michael S Ryoo, Chien-Sheng Wu, Shelby Heinecke, Huan Wang, Silvio Savarese, Caiming Xiong, Juan Carlos Niebles

## GLTW：通过三词语言联合改进的图变压器和大语言模型用于知识图填充。
GLTW: Joint Improved Graph Transformer and LLM via Three-Word Language for Knowledge Graph Completion
Kangyang Luo, Yuzhuo Bai, Cheng Gao, Shuzheng Si, Zhu Liu, Yingli Shen, Zhitong Wang, Cunliang Kong, Wenhao Li, Yufei Huang, Ye Tian, Xuantang Xiong, Lei Han, Maosong Sun

## 区分文字与数学题中的文字和数学内容：大规模语言模型推理的双维结构证据。
Disentangling Text and Math in Word Problems: Evidence for the Bidimensional Structure of Large Language Models’ Reasoning
Pedro Calais, Gabriel Franco, Zilu Tang, Themistoklis Nikas, Wagner Meira Jr., Evimaria Terzi, Mark Crovella

## 大语言模型中提示（PROMPTS）的威胁：从系统和用户提示视角分析。
The Threat of PROMPTS in Large Language Models: A System and User Prompt Perspective
Zixuan Xia, Haifeng Sun, Jingyu Wang, Qi Qi, Huazheng Wang, Xiaoyuan Fu, Jianxin Liao

## 使用注释指南对LLMs进行指令调优以实现事件提取。
Instruction-Tuning LLMs for Event Extraction with Annotation Guidelines
Saurabh Srivastava, Sweta Pati, Ziyu Yao

## RoseRAG：通过边际意识偏好优化实现的小规模LLM增强生成方法。
RoseRAG: Robust Retrieval-augmented Generation with Small-scale LLMs via Margin-aware Preference Optimization
Tianci Liu, Haoxiang Jiang, Tianze Wang, Ran Xu, Yue Yu, Linjun Zhang, Tuo Zhao, Haoyu Wang

## SGDPO：自我引导直接偏好优化的语言模型对齐方法。
SGDPO: Self-Guided Direct Preference Optimization for Language Model Alignment
Wenqiao Zhu, Ji Liu, Lulu Wang, Jun Wu, Yulun Zhang

## mRAKL：面向低资源语言的多语言检索增强知识图构建方法。
mRAKL: Multilingual Retrieval-Augmented Knowledge Graph Construction for Low-Resourced Languages
Hellina Hailu Nigatu, Min Li, Maartje Ter Hoeve, Saloni Potdar, Sarah Chasins

## 大型语言模型中情绪推断的机制可解释性。
Mechanistic Interpretability of Emotion Inference in Large Language Models
Ala N. Tak, Amin Banayeeanzade, Anahita Bolourani, Mina Kian, Robin Jia, Jonathan Gratch

## 代码转换与句法：一项大规模实验。
Code-Switching and Syntax: A Large-Scale Experiment
Igor Sterner, Simone Teufel

## RL-Guider：利用历史决策和反馈进行药物编辑的大语言模型方法。
RL-Guider: Leveraging Historical Decisions and Feedback for Drug Editing with Large Language Models
Xufeng Liu, Yixuan Ding, Jingxiang Qu, Yichi Zhang, Wenhan Gao, Yi Liu

## 我理解你的意思：共言手势在多模态对话中参考解析的应用。
I see what you mean: Co-Speech Gestures for Reference Resolution in Multimodal Dialogue
Esam Ghaleb, Bulat Khaertdinov, asli ozyurek, Raquel Fernández

## ACCESS DENIED INC：首个敏感性意识基准环境。
ACCESS DENIED INC: The First Benchmark Environment for Sensitivity Awareness
Dren Fazlija, Arkadij Orlov, Sandipan Sikdar

## 空间坐标作为细胞语言：一种用于成像质谱流式细胞术分析的多句框架。
Spatial Coordinates as a Cell Language: A Multi-Sentence Framework for Imaging Mass Cytometry Analysis
Chi-Jane Chen, Yuhang Chen, Sukwon Yun, Natalie Stanley, Tianlong Chen

## 计算技能的最佳扩展：知识 vs 原理力。
Compute Optimal Scaling of Skills: Knowledge vs Reasoning
Nicholas Roberts, Niladri S. Chatterji, Sharan Narang, Mike Lewis, Dieuwke Hupkes

## HumanEval Pro 和 MBPP Pro：评估大语言模型在自助调用代码生成任务中的表现。
HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation Task
Zhaojian Yu, Yilun Zhao, Arman Cohan, Xiao-Ping Zhang

## 世界知识解决方面义ambiguity。 \n\n注：这里的“aspectual ambiguity”翻译为“方面义ambiguity”，在语境中似乎特\nuser\n请翻译以下内容：\nAbstract: We propose a new\n:';\nassistant\n摘要：我们提出了一种方法。
World Knowledge Resolves Aspectual Ambiguity
Katarzyna Pruś, Mark Steedman, Adam Lopez

## 多义嵌入语言模型及知识精炼。
Multi-Sense Embeddings for Language Models and Knowledge Distillation
Qitong Wang, Mohammed J Zaki, Georgios Kollias, Vasileios Kalantzis

## 基于图结构外部记忆的终身模型编辑。
Lifelong Model Editing with Graph-Based External Memory
Yash Kumar Atri, Ahmed Alaa, Thomas Hartvigsen

## PECAN：基于注意力引导层次加权图的LLM引导动态进度控制长文档QA系统。
PECAN: LLM-Guided Dynamic Progress Control with Attention-Guided Hierarchical Weighted Graph for Long-Document QA
Xinyu Wang, Yanzheng Xiang, Lin Gui, Yulan He

## 基于单次示范的多模态提示 grounding 任务协助。
Grounding Task Assistance with Multimodal Cues from a Single Demonstration
Gabriel Herbert Sarch, Balasaravanan Thoravi Kumaravel, Sahithya Ravi, Vibhav Vineet, Andy Wilson

## CodeScientist：基于代码实验的端到端半自动化科学研究。
CodeScientist: End-to-End Semi-Automated Scientific Discovery with Code-based Experimentation
Peter Jansen, Oyvind Tafjord, Marissa Radensky, Pao Siangliulue, Tom Hope, Bhavana Dalvi Mishra, Bodhisattwa Prasad Majumder, Daniel S Weld, Peter Clark

## 超越事实准确性：评估长文生成中多样化事实信息的覆盖情况。
Beyond Factual Accuracy: Evaluating Coverage of Diverse Factual Information in Long-form Text Generation
Chris Samarinas, Alexander Krubner, Alireza Salemi, Youngwoo Kim, Hamed Zamani

## 当检测失效时：细调模型生成类似人类的社交媒体文本的能力。
When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text
Hillary Dawkins, Kathleen C. Fraser, Svetlana Kiritchenko

## 持续量化感知预训练：何时从16位切换到1.58位预训练以用于BitNet语言模型？
Continual Quantization-Aware Pre-Training: When to transition from 16-bit to 1.58-bit pre-training for BitNet language models?
Jacob Nielsen, Peter Schneider-Kamp, Lukas Galke

## IDEA：通过归纳、演绎和溯因增强大型语言内容代理的规则学习能力。
IDEA: Enhancing the Rule Learning Ability of Large Language Model Agent through Induction, Deduction, and Abduction
Kaiyu He, Mian Zhang, Shuo Yan, Peilin Wu, Zhiyu Chen

## 不甚像福尔摩斯：预训练语言模型无法可靠地区分不可能事件与不太可能的事件。
Not quite Sherlock Holmes: Pretrained language models cannot reliably differentiate impossible from improbable events
James A. Michaelov, Reeka Estacio, Zhien Zhang, Ben Bergen

## EnigmaToM：通过实体状态神经知识库提高LLMs的理论思维推理能力。
EnigmaToM: Improve LLMs’ Theory-of-Mind Reasoning Capabilities with Neural Knowledge Base of Entity States
Hainiu Xu, Siya Qi, Jiazheng Li, Yuxiang Zhou, Jinhua Du, Caroline Catmur, Yulan He

## 旋转变换位置嵌入可能导致注意力头在长距离检索中产生维度 inefficiency。
The Rotary Position Embedding May Cause Dimension Inefficiency in Attention Heads for Long-Distance Retrieval
Ting-Rui Chiang, Dani Yogatama

## ReasonerRank：无_groundtruth排名框架重塑语言模型评估。
ReasonerRank: Redefining Language Model Evaluation with Ground-Truth-Free Ranking Frameworks
Jiamu Zhang, Jiayi Yuan, Andrew Wen, Hoang Anh Duy Le, Yu-Neng Chuang, Soo-Hyun Choi, Rui Chen, Xia Hu

## 探究形态学模型中的亚音素成分。
Probing Subphonemes in Morphology Models
Gal Astrach, Yuval Pinter

## HyGenar：一种由大语言模型驱动的混合遗传算法，用于少量示例语法生成。
HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation
Weizhi Tang, Yixuan Li, Chris Sypherd, Elizabeth Polgreen, Vaishak Belle

## MMInA：多跳多模互联网代理基准测试。
MMInA: Benchmarking Multihop Multimodal Internet Agents
Shulin Tian, Ziniu Zhang, Liangyu Chen, Ziwei Liu

## 大型语言模型能理解论辩方案吗？
Can Large Language Models Understand Argument Schemes?
Elfia Bezou-Vrakatseli, Oana Cocarascu, Sanjay Modgil

## ThinkGuard：深思熟虑的缓慢思考促成谨慎的界限。
ThinkGuard: Deliberative Slow Thinking Leads to Cautious Guardrails
Xiaofei Wen, Wenxuan Zhou, Wenjie Jacky Mo, Muhao Chen

## 使用蕴含图消除LLM推理中的偏差。
Neutralizing Bias in LLM Reasoning using Entailment Graphs
Liang Cheng, Tianyi Li, Zhaowei Wang, Tianyang Liu, Mark Steedman

## 迷失在翻译之中：评估商业机器翻译模型对学习障碍文本的表现。
Lost in Translation: Benchmarking Commercial Machine Translation Models for Dyslexic-Style Text
Gregory Price, Shaomei Wu

## 利用指令遵循检索器进行恶意信息检索。
Exploiting Instruction-Following Retrievers for Malicious Information Retrieval
Parishad BehnamGhader, Nicholas Meade, Siva Reddy

## Eeyore：通过监督和偏好优化实现的现实抑郁模拟。
Eeyore: Realistic Depression Simulation via Supervised and Preference Optimization
Siyang Liu, Bianca Brie, Wenda Li, Laura Biester, Andrew Lee, James Pennebaker, Rada Mihalcea

## 以任务为导向的框架语义自动事实核查。
Task-Oriented Automatic Fact-Checking with Frame-Semantics
Jacob Devasier, Akshith Reddy Putta, Rishabh Mediratta, Chengkai Li

## LlamaPIE：主动式耳内对话助手。
LlamaPIE: Proactive In-Ear Conversation Assistants
Tuochao Chen, Nicholas Scott Batchelder, Alisa Liu, Noah A. Smith, Shyamnath Gollakota

## 基于 episodic 记忆的动态 steering 大型语言模型。
Dynamic Steering With Episodic Memory For Large Language Models
Van Dai Do, Quan Hung Tran, Svetha Venkatesh, Hung Le

## Craw4LLM：高效的Web抓取用于LLM预训练。
Craw4LLM: Efficient Web Crawling for LLM Pretraining
Shi Yu, Zhiyuan Liu, Chenyan Xiong

## 警惕合并陌生的LLM：一款具备窃取隐私功能的欺诈模型。
Be Cautious When Merging Unfamiliar LLMs: A Phishing Model Capable of Stealing Privacy
GUO Zhenyuan, Yi Shi, Wenlong Meng, Chen GONG, Chengkun Wei, Wenzhi CHEN

## 通过LLM辅助的即时用户体验访谈理解用户对大型语言模型的意见。
Understand User Opinions of Large Language Models via LLM-Powered In-the-Moment User Experience Interviews
Mengqiao Liu, Tevin Wang, Cassandra A. Cohen, Sarah Li, Chenyan Xiong

## FLAG-TRADER：融合基于梯度强化学习的LLM-Agent进行金融交易。
FLAG-TRADER: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading
GUOJUN XIONG, Zhiyang Deng, Keyi Wang, Yupeng Cao, Haohang Li, Yangyang Yu, Xueqing Peng, MINGQUAN LIN, Kaleb E Smith, Xiao-Yang Liu, Jimin Huang, Sophia Ananiadou, Qianqian Xie

## 无声的破坏者： imperceptible 隐蔽对抗性攻击黑盒检索增强生成系统研究
The Silent Saboteur: Imperceptible Adversarial Attacks against Black-Box Retrieval-Augmented Generation Systems
Hongru Song, Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Jianming Lv, Maarten de Rijke, Xueqi Cheng

## 解耦记忆，静默神经元：通往实用的大语言模型机器遗忘技术。
Decoupling Memories, Muting Neurons: Towards Practical Machine Unlearning for Large Language Models
Lishuai Hou, Zixiong Wang, Gaoyang Liu, Chen Wang, Wei Liu, Kai Peng

## CROSSAGENTIE：跨类型和跨任务多智能体语言模型协作的零样本信息提取。
CROSSAGENTIE: Cross-Type and Cross-Task Multi-Agent LLM Collaboration for Zero-Shot Information Extraction
Meng Lu, Yuzhang Xie, Zhenyu Bi, Shuxiang Cao, Xuan Wang

## 同化与顺应：面向Web任务的自适应层次化抽象方法。
Assimilation and Accommodation: Task-Adaptive Hierarchical Abstraction for Solving Web Tasks
Xinyu Pang, Ruixin Hong, Hongming Zhang, Changshui Zhang

## BriefMe：辅助法律备忘录的法律NLP基准。
BriefMe: A Legal NLP Benchmark for Assisting with Legal Briefs
Jesse Woo, Fateme Hashemi Chaleshtori, Ana Marasovic, Kenneth Marino

## 3DM：提炼、动态丢弃和合并以正则化多模态大型语言模型。
3DM: Distill, Dynamic Drop, and Merge for Debiasing Multi-modal Large Language Models
Zhaoxi Zhang, Sanwoo Lee, Zhixiang Wang, Yunfang Wu

## HiCOT：通过最优传输和对比学习改善神经主题模型。
HiCOT: Improving Neural Topic Models via Optimal Transport and Contrastive Learning
Hoang Tran Vuong, Tue Le, Tu Vu, Tung Nguyen, Linh Ngo Van, Sang Dinh, Thien Huu Nguyen

## SafeLawBench：大型语言模型安全对齐的方向。
SafeLawBench: Towards Safe Alignment of Large Language Models
Chuxue Cao, Han Zhu, Jiaming Ji, Qichao Sun, Zhenghao Zhu, WU YINYU, Josef Dai, Yaodong Yang, Sirui Han, Yike Guo

## CapArena：在大语言模型时代评估与分析详细的图像描述任务。
CapArena: Benchmarking and Analyzing Detailed Image Captioning in the LLM Era
Kanzhi Cheng, Wenpo Song, Jiaxin Fan, Zheng Ma, Qiushi Sun, Fangzhi Xu, Chenyang Yan, Nuo Chen, Jianbing Zhang, Jiajun Chen

## 彻夜未眠，甜蜜之日：为真实Coach代理互动创建具有健康状况的合成用户。
Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions
Taedong Yun, Eric Yang, Mustafa Safdari, Jong Ha Lee, Vaishnavi Vinod Kumar, S. Sara Mahdavi, Jonathan Amar, Derek Peyton, Reut Aharony, Andreas Michaelides PhD, Logan Douglas Schneider, Isaac Galatzer-Levy, Yugang jia, John Canny, Arthur Gretton, Maja Mataric

## GLiM：集成图变换器和大语言模型进行具有不完整标签的医学文献级别关系提取。
GLiM: Integrating Graph Transformer and LLM for Document-Level Biomedical Relation Extraction with Incomplete Labeling
Hao Fang, Yuejie Zhang, Rui Feng, Yingwen Wang, Qing Wang, Wen He, Xiaobo Zhang, Tao Zhang, Shang Gao

## LLM赋能的类别不平衡图提示学习在在线毒品交易检测中的应用
LLM-Empowered Class Imbalanced Graph Prompt Learning for Online Drug Trafficking Detection
Tianyi Ma, Yiyue Qian, Zehong Wang, Zheyuan Zhang, Chuxu Zhang, Yanfang Ye

## CoLA：协作低秩适应。
CoLA: Collaborative Low-Rank Adaptation
Yiyun Zhou, Chang Yao, Jingyuan Chen

## AnalyticKWS：旨在实现无需示例的分析类增量学习的小尺寸关键字 spotting 方法。
AnalyticKWS: Towards Exemplar-Free Analytic Class Incremental Learning for Small-footprint Keyword Spotting
Yang Xiao, Peng Tianyi, Rohan Kumar Das, Yuchen Hu, Huiping Zhuang

## SafeEraser：通过多模态机器遗忘增强多模态大型语言模型的安全性。
SafeEraser: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning
Junkai Chen, Zhijie Deng, Kening Zheng, Yibo Yan, Shuliang Liu, PeiJun WU, Peijie Jiang, Jia Liu, Xuming Hu

## TCSinger 2：可定制的多语言零样本歌声合成。
TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis
Yu Zhang, Wenxiang Guo, Changhao Pan, Dongyu Yao, Zhiyuan Zhu, Ziyue Jiang, Yuhan Wang, Tao Jin, Zhou Zhao

## 想象听见：听觉知识生成可以成为语言模型的有效辅助。
Imagine to Hear: Auditory Knowledge Generation can be an Effective Assistant for Language Models
Suho Yoo, Hyunjong Ok, Jaeho Lee

## 根据动态兴趣适应定制基于LLM的推荐中的上下文学习。
Customizing In-context Learning for Dynamic Interest Adaption in LLM-based Recommendation
Keqin Bao, Ming Yan, Yang Zhang, Jizhi Zhang, Wenjie Wang, Fuli Feng, Xiangnan He

## DiSCo：设备-服务器协作基于LLM的文本流服务。
DiSCo: Device-Server Collaborative LLM-based Text Streaming Services
Ting Sun, Penghan Wang, Fan Lai

## 通过注入虚构知识在语言模型中实现稳健的数据水印。
Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge
Xinyue Cui, Johnny Wei, Swabha Swayamdipta, Robin Jia

## FedLEKE：联邦定位 then 编辑知识编辑方法用于多客户端协作。
FedLEKE: Federated Locate-then-Edit Knowledge Editing for Multi-Client Collaboration
Zongkai Zhao, Guozeng Xu, Xiuhua Li, kaiwen wei, Jiang Zhong

## 基于贝叶斯规则推导出的低熵水印检测器。
Low-Entropy Watermark Detection via Bayes’ Rule Derived Detector
Beining Huang, Du Su, Fei Sun, Qi Cao, Huawei Shen, Xueqi Cheng

## LLM增强的查询生成与任务导向对话中的检索保持
LLM-Enhanced Query Generation and Retrieval Preservation for Task-Oriented Dialogue
Jiale Chen, Xuelian Dong, Wenxiu Xie, Ru Peng, Kun Zeng, Tianyong Hao

## 预测增强生成用于自动诊断任务。
Prediction-Augmented Generation for Automatic Diagnosis Tasks
Chan-Yang Ju, Dong-Ho Lee

## 探索有毒中文检测中的多模态挑战：分类学、基准和发现。
Exploring Multimodal Challenges in Toxic Chinese Detection: Taxonomy, Benchmark, and Findings
Shujian Yang, Shiyao Cui, Haicheng Wang, Tianwei Zhang, Minlie Huang, Jialiang LU, Han Qiu

## ClozeMath：通过学习填写方程提高语言模型的数学推理能力。
ClozeMath: Improving Mathematical Reasoning in Language Models by Learning to Fill Equations
Quang Hieu Pham, Thuy-Duong Nguyen, Tung Pham, Anh Tuan Luu, Dat Quoc Nguyen

## DaNet：双模态增强对齐网络，用于多模态方面基于情感分析。
DaNet: Dual-Aware Enhanced Alignment Network for Multimodal Aspect-Based Sentiment Analysis
Aoqiang Zhu, Min Hu, Xiaohua Wang, Jiaoyun Yang, Yiming Tang, Ning An

## 基于排名投票的大语言模型自我一致性。
Ranked Voting based Self-Consistency of Large Language Models
Weiqin Wang, Yile Wang, Hui Huang

## CoD，一种基于诊序解释的医疗智能代理。
CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis
Junying Chen, Chi Gui, Anningzhe Gao, Ke Ji, Xidong Wang, Xiang Wan, Benyou Wang

## MDIT-Bench：评估大型多模态模型中的双重隐含毒性。
MDIT-Bench: Evaluating the Dual-Implicit Toxicity in Large Multimodal Models
Bohan Jin, Shuhan Qi, Kehai Chen, Xinyi Guo, Xuan Wang

## AlignXIE：通过多语言对齐增强跨语言通用信息提取。
AlignXIE: Boosting Cross-Lingual Universal Information Extraction by Multilingual Alignment
Yuxin Zuo, Wenxuan Jiang, Wenxuan Liu, Zixuan Li, Long Bai, Hanbin Wang, Yutao Zeng, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng

## 通过双向奖励信号提高过程监督效果。
Better Process Supervision with Bi-directional Rewarding Signals
Wenxiang Chen, Wei He, Zhiheng Xi, Honglin Guo, Boyang Hong, Jiazheng Zhang, Nijun Li, Tao Gui, Yun Li, Qi Zhang, Xuanjing Huang

## 通过医疗可验证问题实现基于LLMs的医疗复杂推理。
Towards Medical Complex Reasoning with LLMs through Medical Verifiable Problems
Junying Chen, Zhenyang Cai, Ke Ji, Xidong Wang, Wanlong Liu, Rongsheng Wang, Benyou Wang

## 利用大型语言模型进行灾害管理：一项综述。
Harnessing Large Language Models for Disaster Management: A Survey
Zhenyu Lei, Yushun Dong, Weiyu Li, Rong Ding, Qi R. Wang, Jundong Li

## MEIT：多模态心电图指令调优大型语言模型以生成报告。
MEIT: Multi-Modal Electrocardiogram Instruction Tuning on Large Language Models for Report Generation
Zhongwei Wan, Che Liu, Xin Wang, Chaofan Tao, Hui Shen, Jing Xiong, Rossella Arcucci, Huaxiu Yao, Mi Zhang

## MMSciBench：评估语言模型在多模态科学问题上的表现。
MMSciBench: Benchmarking Language Models on Multimodal Scientific Problems
Xinwu Ye, Chengfan Li, Siming Chen, Xiangru Tang, Wei Wei

## 划分-验证-细化：LLM 能够自我与复杂指令对齐吗？
Divide-Verify-Refine: Can LLMs Self-align with Complex Instructions?
Xianren Zhang, Xianfeng Tang, Hui Liu, Zongyu Wu, Qi He, Dongwon Lee, Suhang Wang

## LDIR：基于相对表示的低维度密集可解释文本嵌入。
LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations
Yile Wang, Zhanyu Shen, Hui Huang

## 探索大语言模型标注在数据共享限制下的临床信息提取模型适应性研究。
Exploring LLM Annotation for Adaptation of Clinical Information Extraction Models under Data-sharing Restrictions
Seiji Shimizu, HISADA Shohei, Yutaka Uno, Shuntaro Yada, Shoko Wakamiya, Eiji Aramaki

## 轻量级查询检查点：分类错误用户查询以减轻大型语言模型问答中的幻想现象。
Lightweight Query Checkpoint: Classifying Faulty User Queries to Mitigate Hallucinations in Large Language Model Question Answering
Jonghak Jang, Minjoo Son, Misuk Kim

## EvoBench：面向演化的大型语言模型生成文本检测基准测试的现实世界方案。
EvoBench: Towards Real-world LLM-Generated Text Detection Benchmarking for Evolving Large Language Models
Xiao Yu, Yi Yu, Dongrui Liu, Kejiang Chen, Weiming Zhang, Nenghai Yu, Jing Shao

## 多模态不变情感表示学习
Multimodal Invariant Sentiment Representation Learning
Aoqiang Zhu, Min Hu, Xiaohua Wang, Jiaoyun Yang, Yiming Tang, Ning An

## SemanticCamo：通过语义伪装突破大型语言模型的限制。
SemanticCamo: Jailbreaking Large Language Models through Semantic Camouflage
Jihui Yan, Xiaocui Yang, Daling Wang, Shi Feng, Yifei Zhang, Yinzhi Zhao

## 通过无监督概念发现提升文本解释的可理解性。
Enhancing the Comprehensibility of Text Explanations via Unsupervised Concept Discovery
Yifan Sun, Danding Wang, Qiang Sheng, Juan Cao, Jintao Li

## ChuLo：长文档理解的块级关键信息表示
ChuLo: Chunk-Level Key Information Representation for Long Document Understanding
Yan Li, Caren Han, Yue Dai, Feiqi Cao

## LLM进行观点检测时外部信息有用吗？
Is External Information Useful for Stance Detection with LLMs?
Quang Minh Nguyen, Taegyoon Kim

## REVS：通过词汇空间中的排序编辑去除语言模型中的敏感信息。
REVS: Unlearning Sensitive Information in Language Models via Rank Editing in the Vocabulary Space
Tomer Ashuach, Martin Tutek, Yonatan Belinkov

## 超越表面模式：一种基于本质驱动的防御框架，用于抵御LLMs中的 Jailbreak 攻击。
Beyond Surface-Level Patterns: An Essence-Driven Defense Framework Against Jailbreak Attacks in LLMs
Shiyu Xiang, Ansen zhang, Yanfei Cao, Fan Yang, Ronghao Chen

## 基于查询条件的自然语言推理基准测试。
Benchmarking Query-Conditioned Natural Language Inference
Marc E. Canby, Xinchi Chen, Xing Niu, Jifan Chen, Bonan Min, Sergul Aydore, Vittorio Castelli

## 基于流程图的大型语言模型决策制定。
Flowchart-Based Decision Making with Large Language Models
Yuuki Yamanaka, Hiroshi Takahashi, Tomoya Yamashita

## 通过可扩展的块浮点表示提高大型语言模型的效率。
Improving Efficiency in Large Language Models via Extendable Block Floating Point Representation
Dongyang Li, Zeyang Li, Bosheng Liu, Jigang Wu

## NarGINA：通过叙事图谱实现准确可解释的儿童叙事能力评估。
NarGINA: Towards Accurate and Interpretable Children’s Narrative Ability Assessment via Narrative Graphs
Jun Zhong, Longwei Xu, Li Kong, Xianzhuo Li, Dandan Liang, Junsheng Zhou

## EpiCoDe：通过外推和对比解码提升模型性能。
EpiCoDe: Boosting Model Performance Beyond Training with Extrapolation and Contrastive Decoding
Mingxu Tao, Jie Hu, mingchuan yang, Yunhuai Liu, Dongyan Zhao, Yansong Feng

## 在健忘性探查中通过均值投影提高因果干预的效果。
Improving Causal Interventions in Amnesic Probing with Mean Projection
Alicja Dobrzeniecka, Antske Fokkens, Pia Sommerauer

## NativQA：面向LLMs的多语言文化对齐自然查询。
NativQA: Multilingual Culturally-Aligned Natural Query for LLMs
Md. Arid Hasan, Maram Hasanain, Fatema Ahmad, Sahinur Rahman Laskar, Sunaya Upadhyay, Vrunda N Sukhadia, Mucahid Kutlu, Shammur Absar Chowdhury, Firoj Alam

## VADE：基于视觉注意力的幻觉检测与消除。
VADE: Visual Attention Guided Hallucination Detection and Elimination
Vishnu Prabhakaran, Purav Aggarwal, Vinay Kumar Verma, Gokul Swamy, Anoop Saladi

## RISE：多跳问答中的迭代自我探索以增强推理能力。
RISE: Reasoning Enhancement via Iterative Self-Exploration in Multi-hop Question Answering
Bolei He, Xinran He, Mengke Chen, xianwei xue, Ying Zhu, Zhen-Hua Ling

## 无包装令牌化在临床笔记中的有效性。
The Effectiveness of Uncased Tokeniziaion for Clinical Notes
Cory Paik, Katharina von der Wense

## 题目：DoCIA：一种用于语音翻译的在线文档级上下文整合代理。
DoCIA: An Online Document-Level Context Incorporation Agent for Speech Translation
Xinglin Lyu, Wei Tang, Yuang Li, Xiaofeng Zhao, Ming Zhu, Junhui Li, Yunfei Lu, Min Zhang, Daimeng Wei, Hao Yang, Min zhang

## AMXFP4：使用非对称微缩浮点数处理4位LLM推理中的激活异常值。
AMXFP4: Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference
Janghwan Lee, Jiwoong Park, Jinseok Kim, Yongjik Kim, Jungju Oh, Jinwook Oh, Jungwook Choi

## 名称年龄感知对大规模语言模型中职位推荐的影响。
The Impact of Name Age Perception on Job Recommendations in LLMs
Mahammed Kamruzzaman, Gene Louis Kim

## DAPI：领域适应性毒性探针向量干预，用于精细去毒。
DAPI: Domain Adaptive Toxicity Probe Vector Intervention, for Fine-Grained Detoxification
Cho Hyeonsu, Dooyoung Kim, Youngjoong Ko

## 揭开提炼思维链条推理的关键因素
Unveiling the Key Factors for Distilling Chain-of-Thought Reasoning
Xinghao Chen, Zhijing Sun, Guo Wenjin, Miaoran Zhang, Yanjun Chen, Yirong Sun, Hui Su, Yijie Pan, Dietrich Klakow, Wenjie Li, Xiaoyu Shen

## LLM评论者有助于捕获数学错误：朝着更好的数学验证器自然语言反馈的方向发展。
LLM Critics Help Catch Bugs in Mathematics: Towards a Better Mathematical Verifier with Natural Language Feedback
Bofei Gao, Zefan Cai, Runxin Xu, Peiyi Wang, Ce Zheng, Runji Lin, Keming Lu, Dayiheng Liu, Chang Zhou, Wen Xiao, Tianyu Liu, Baobao Chang

## 通过内插和恢复注入任务知识以增强大型语言模型的泛化能力。
Task Knowledge Injection via Interpolations and Reinstatement for Large Language Model Generalization
Yukun Zhao, Lingyong Yan, Zhenyang Li, Shuaiqiang Wang, Zhumin Chen, Zhaochun Ren, Dawei Yin

## RecordTwin：迈向创建安全的合成临床语料库。
RecordTwin: Towards Creating Safe Synthetic Clinical Corpora
Seiji Shimizu, Ibrahim Baroud, Lisa Raithel, Shuntaro Yada, Shoko Wakamiya, Eiji Aramaki

## STARS：统一的歌唱转录、对齐与风格标注框架。
STARS: A Unified Framework for Singing Transcription, Alignment, and Refined Style Annotation
Wenxiang Guo, Yu Zhang, Changhao Pan, Zhiyuan Zhu, Ruiqi Li, ZheTao Chen, Wenhao Xu, Fei Wu, Zhou Zhao

## 题目：通过因果影响提示增强大语言模型代理的安全性。
Enhancing LLM Agent Safety via Causal Influence Prompting
Dongyoon Hahm, Woogyeol Jin, June Suk Choi, Sungsoo Ahn, Kimin Lee

## 位置论文：MeMo：朝向具有关联记忆机制的语言模型。
Position Paper: MeMo: Towards Language Models with Associative Memory Mechanisms
Fabio Massimo Zanzotto, Elena Sofia Ruzzetti, Giancarlo A. Xompero, Leonardo Ranaldi, Davide Venditti, Federico Ranaldi, Cristina Giannone, Andrea Favalli, Raniero Romagnoli

## DeRAGEC：使用合成解释进行ASR错误修正的命名实体候选去噪。
DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction
Solee Im, Wonjun Lee, JinMyeong AN, Yunsu Kim, Jungseul Ok, Gary Lee

## 超越平均读者：读者嵌入方法。
Beyond the Average Reader: the Reader Embedding Approach
Calogero Jerik Scozzaro, Matteo Delsanto, Daniele Paolo Radicioni

## INT：建立多语言意图检测与槽填充的信息传输。
INT: Establishing Information Transfer for Multilingual Intent Detection and Slot Filling
Di Wu, Liting Jiang, Bohui Mao, Hongyan Xie, Haoxiang Su, Zhongjiang He, Ruiyu Fang, Shuangyong Song, Hao Huang, Xuelong Li

## PredictaBoard：评估语言模型得分可预测性基准。
PredictaBoard: Benchmarking LLM Score Predictability
Lorenzo Pacchiardi, Konstantinos Voudouris, Ben Slater, Fernando Martínez-Plumed, Jose Hernandez-Orallo, Lexin Zhou, Wout Schellaert

## 与用户一起练习：基于大型语言模型的角色扮演个性化意见总结。
Rehearse With User: Personalized Opinion Summarization via Role-Playing based on Large Language Models
Yanyue Zhang, Yulan He, Deyu Zhou

## 拔除杂草，然后收割：双重低秩适应是一种有效的噪声标签检测器，用于抗噪声学习。
Weed Out, Then Harvest: Dual Low-Rank Adaptation is an Effective Noisy Label Detector for Noise-Robust Learning
Bo Yuan, Yulin Chen, Yin Zhang

## “我理解你的观点”：通过沟通行动理论视角探讨大型语言模型的说服力。
“I understand your perspective”: LLM Persuasion through the Lens of Communicative Action Theory
Esra Dönmez, Agnieszka Falenska

## FedDQC：联邦指令调优中大规模语言模型的数据质量控制。
FedDQC: Data Quality Control in Federated Instruction-tuning of Large Language Models
Yaxin Du, Rui Ye, Fengting Yuchi, Wanru Zhao, Jingjing Qu, Yanfeng Wang, Siheng Chen

## AdParaphrase v2.0：使用带有偏 presença注释的重写数据集生成有吸引力的广告文本。
AdParaphrase v2.0: Generating Attractive Ad Texts Using a Preference-Annotated Paraphrase Dataset
Soichiro Murakami, Peinan Zhang, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura

## daDPO：基于分布感知的对话能力精简方法。
daDPO: Distribution-Aware DPO for Distilling Conversational Abilities
Zhengze Zhang, Shiqi Wang, Yiqun Shen, Simin Guo, Dahua Lin, Wang Xiaoliang, Nguyen Cam-Tu, Fei Tan

## 顾问解码：又一协同机制。
Consultant Decoding: Yet Another Synergistic Mechanism
Chuanghao Ding, Jiaping Wang, Ziqing Yang, Wang Xiaoliang, Dahua Lin, Nguyen Cam-Tu, Fei Tan

## PGPO：通过伪代码风格规划引导的偏好优化增强智能体推理能力。
PGPO: Enhancing Agent Reasoning via Pseudocode-style Planning Guided Preference Optimization
zouying cao, Runze Wang, Yifei Yang, Xinbei Ma, Xiaoyong Zhu, Bo Zheng, hai zhao

##  IntelliCockpitBench：一个全面的基础模型评估基准，用于智能座舱。
IntelliCockpitBench: A Comprehensive Benchmark to Evaluate VLMs for Intelligent Cockpit
Liang Lin, Siyuan Chai, Jiahao Wu, Hongbing Hu, Xiaotao Gu, Hao Hu, Fan Zhang, Wei Wang, Dan Zhang

## Nunchi-Bench：基于韩国 superstition 的文化推理基准测试语言模型。
Nunchi-Bench: Benchmarking Language Models on Cultural Reasoning with a Focus on Korean Superstition
KYU HEE KIM, Sangah Lee

## PISCO：简单高效的检索增强生成压缩方法。
PISCO: Pretty Simple Compression for Retrieval-Augmented Generation
Maxime Louis, Hervé Déjean, Stéphane Clinchant

## AnchorCoT：锚点引导多跳推理。
AnchorCoT: Anchors Pave the Way for Multi-hop Reasoning
Tianshi Ming, Xian Wu, Yingying Zhang, Zichuan Fu, Dawei Cheng

## 他们想假装不懂：当前语言模型在解释政治话语中的隐含内容方面的局限。
They want to pretend not to understand: The Limits of Current LLMs in Interpreting Implicit Content of Political Discourse
Walter Paci, Alessandro Panunzi, Sandro Pezzelle

##  federated 数据高效指令调优大语言模型
Federated Data-Efficient Instruction Tuning for Large Language Models
Zhen Qin, Zhaomin Wu, Bingsheng He, Shuiguang Deng

## CausalAbstain：通过因果推理增强多语言LLMs的可靠拒绝能力
CausalAbstain: Enhancing Multilingual LLMs with Causal Reasoning for Trustworthy Abstention
Yuxi SUN, Aoqi Zuo, Wei Gao, Jing Ma

## 通过目标导向的情感分类分析LLM中的政治偏见。
Analyzing Political Bias in LLMs via Target-Oriented Sentiment Classification
Akram Elbouanani, Evan Dufraisse, Adrian Popescu

## 多模态大型语言模型中的标记剪枝：我们是否在解决正确的难题？
Token Pruning in Multimodal Large Language Models: Are We Solving the Right Problem?
Zichen Wen, Yifeng Gao, Weijia Li, Conghui He, Linfeng Zhang

## 链式多模态思维推理时的扩展性研究——\n
Investigating Inference-time Scaling for Chain of Multi-modal Thought: A Preliminary Study
Yujie Lin, Ante Wang, Moye Chen, Jingyao Liu, Hao Liu, Jinsong Su, Xinyan Xiao

## E2I-Synth：通过大规模指令合成促进GUI定位的发展。
E2I-Synth: Advancing GUI Grounding with Large-Scale Instruction Synthesis
Xinyi Liu, Xiaoyi Zhang, Ziyun Zhang, Yan Lu

## ZeroNER：通过实体类型描述驱动的零样本命名实体识别。
ZeroNER: Fueling Zero-Shot Named Entity Recognition via Entity Type Descriptions
Alessio Cocchieri, Marcos Martínez Galindo, Giacomo Frisoni, Gianluca Moro, Claudio Sartori, Giuseppe Tagliavini

## 对大型语言模型时间稳健性的研究
A Study into Investigating Temporal Robustness of LLMs
Jonas Wallat, Abdelrahman Abdallah, Adam Jatowt, Avishek Anand

## ToolExpNet：具有相似性和依赖性感知体验网络的多工具优化选择。
ToolExpNet: Optimizing Multi-Tool Selection in LLMs with Similarity and Dependency-Aware Experience Networks
Zijing Zhang, Zhanpeng Chen, He Zhu, Ziyang Chen, nan du, Xiaolong Li

## 大型语言模型拥有“情感神经元”吗？探究其存在及其作用。
Do Large Language Models Have “Emotion Neurons”? Investigating the Existence and Role
Jaewook Lee, Woojin Lee, Oh-Woog KWON, Harksoo Kim

## 题目：基于语法的代码表示：对于大语言模型（LLMs）来说值得追求吗？
Grammar-Based Code Representation: Is It a Worthy Pursuit for LLMs?
Qingyuan Liang, Zhao Zhang, Zeyu Sun, Zheng Lin, Qi Luo, Xiao Yueyi, Yizhou Chen, Yuqun Zhang, Haotian Zhang, Lu Zhang, chenbin, Yingfei Xiong

## SPILL：基于选择和聚合的大语言模型驱动的零样本意图聚类。
SPILL: Zero-shot Intent Clustering based on Selection and Pooling with Large Language Models
I-Fan Lin, Faegheh Hasibi, Suzan Verberne

## 更好地理解跨语言和多语言环境中程序思维推理\n
Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments
Patomporn Payoungkhamdee, Pume Tuchinda, Jinheon Baek, Samuel Cahyawijaya, Can Udomcharoenchaikit, Potsawee Manakul, Peerat Limkonchotiwat, Ekapol Chuangsuwanich, Sarana Nutanong

## WebUIBench：一个全面的多模态大型语言模型在WebUI到代码评估基准。
WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code
Zhiyu Lin, Zhengda Zhou, Zhiyuan Zhao, Tianrui Wan, Yilun Ma, Junyu Gao, Xuelong Li

## GRI-QA：环境数据表问题回答的综合基准。
GRI-QA: a Comprehensive Benchmark for Table Question Answering over Environmental Data
Michele Luca Contalbo, Sara Pederzoli, Francesco Del Buono, Venturelli Valeria, Francesco Guerra, Matteo Paganelli

## 语言模型能作为类比标注器吗？
Can Language Models Serve as Analogy Annotators?
Xiaojing Zhang, Bochen Lyu

## 通过无缝数据打包提高持续预训练。
Improving Continual Pre-training Through Seamless Data Packing
Ruicheng Yin, Xuan Gao, Changze Lv, Xiaohua Wang, Xiaoqing Zheng, Xuanjing Huang

## RLHF中的奖励泛化：一个拓扑视角。
Reward Generalization in RLHF: A Topological Perspective
Tianyi Qiu, Fanzhi Zeng, Jiaming Ji, Dong Yan, Kaile Wang, Jiayi Zhou, Yang Han, Josef Dai, Xuehai Pan, Yaodong Yang

## 通过中间表示优化多跳文档检索。
Optimizing Multi-Hop Document Retrieval Through Intermediate Representations
Linjiaen, Jingyu Liu

## 通过层次GFlowNet生成的推理结构增强LLM的数据合成。
Enhanced Data Synthesis for LLM through Reasoning Structures Generated by Hierarchical GFlowNet
Tianpeng Bu, Minying Zhang, Hongtao Duan, Shurui Li, lulu hu, Yu Li

## 基于令牌级偏置自动对齐优化的多风格概要可控生成。
Token-level Preference Self-Alignment Optimization for Multi-style Outline Controllable Generation
Zihao Li, Xuekong Xu, Ziyao Chen, Lixin Zou, Ethanhjwu, Qiang Chen, Chenliang Li

## 捕捉细腻的偏好：面向偏好的一贯蒸馏小型语言模型
Capturing Nuanced Preferences: Preference-Aligned Distillation for Small Language Models
Yanggan Gu, Junzhuo Li, Sirui Huang, Xin Zou, Zhenghua Li, Xuming Hu

## 连接政策、平台与研究：推动针对仇恨言论的主动缓解自然语言处理技术发展。
Bridging Policies, Platforms and Research: Advancing NLP for Hate Speech Proactive Mitigation
Naquee Rizwan, Seid Muhie Yimam, Daryna Dementieva, Dr. Florian Skupin, Tim Fischer, Daniil Moskovskiy, Aarushi Ajay Borkar, Robert Geislinger, Punyajoy Saha, Sarthak Roy, Martin Semmann, Alexander Panchenko, Chris Biemann, Animesh Mukherjee

## SeqPO-SiMT：序列策略优化同时机器翻译
SeqPO-SiMT: Sequential Policy Optimization for Simultaneous Machine Translation
Ting Xu, Zhichao Huang, Jiankai Sun, Shanbo Cheng, Wai Lam

## Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem Proving  \n译文：基于验证者在环内的局部前瞻引导的自动定理证明方法
Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem Proving
Sara Rajaee, Kumar Pratik, Gabriele Cesa, Arash Behboodi

## 通用跨语言认知歪曲检测：基于标准化注释和多任务学习的方法。
Generalizable Cross-Lingual Cognitive Distortion Detection with Standardized Annotations and Multi-Task Learning
Hongzhi Qi, Nan Bai, Jianqiang Li, Wei Zhai, Qing Zhao, Qi Gao, Bing Xiang Yang, Guanghui FU

## BOSE：一种针对基础模型优化的系统评估方法。
BOSE: A Systematic Evaluation Method Optimized for Base Models
Hongzhi Luan, Changxin Tian, Zhaoxin Huan, Xiaolu Zhang, Kunlong Chen, Zhiqiang Zhang, JUN ZHOU

## DPGA-TextSyn：差分隐私遗传算法合成文本生成
DPGA-TextSyn: Differentially Private Genetic Algorithm for Synthetic Text Generation
Zhonghao Sun, Zhiliang Tian, YIPING SONG, yuyi Si, Juhua Zhang, Minlie Huang, Kai Lu, Zeyu Xiong, Xinwang Liu, Dongsheng Li

## 大型语言模型了解民间故事吗？关于日本民间故事中“叶山鬼”的案例研究。
Do Large Language Models Know Folktales? A Case Study of Yokai in Japanese Folktales
Ayuto Tsutsumi, Yuu Jinnai

## 增强、解缠和定制：一种稳健的系统2到系统1代码生成流水线。
Boost, Disentangle, and Customize: A Robust System2-to-System1 Pipeline for Code Generation
Kounianhua Du, Hanjing Wang, Jianxing Liu, Jizheng Chen, Xinyi Dai, Yasheng Wang, Ruiming Tang, Yong Yu, Jun Wang, Weinan Zhang

## 声明调优能够使编码器-only模型在跨语言泛化中更高效。
Statement-Tuning Enables Efficient Cross-lingual Generalization in Encoder-only Models
Ahmed Elshabrawy, Thanh-Nhi Nguyen, Yeeun Kang, Lihan Feng, Annant Jain, Faadil Abdullah Shaikh, Jonibek Mansurov, Mohamed Fazli Mohamed Imam, Jesus-German Ortiz-Barajas, Rendi Chevi, Alham Fikri Aji

## 利用预训练语言模型进行跨语言迁移的语义感知线性转移。
Semantic Aware Linear Transfer by Recycling Pre-trained Language Models for Cross-lingual Transfer
Seungyoon Lee, Seongtae Hong, Hyeonseok Moon, Heuiseok Lim

## 关于大规模语言模型中常识一致性的探讨。
On the Consistency of Commonsense in Large Language Models
Guozheng Li, Peng Wang, Wenjun Ke, Zijie Xu, Jiajun Liu, Ziyu Shang

## 通过对话规划训练多模态LLM以应用于人机交互。
Training Multi-Modal LLMs through Dialogue Planning for HRI
Claudiu Daniel Hromei, Federico Borazio, Andrea Sensi, Elisa Passone, Danilo Croce, Roberto Basili

## 一步步自我生成：一种基于渐进学习的大语言模型自动推理方法。
Let’s Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models
Kangyang Luo, Zichen Ding, Zhenmin Weng, Lingfeng Qiao, Meng Zhao, Xiang Li, di yin, Jinlong Shu

## 黑暗的兴起：角色扮演游戏代理的安全-效益权衡。
The Rise of Darkness: Safety-Utility Trade-Offs in Role-Playing Dialogue Agents
Yihong Tang, Kehai Chen, Xuefeng Bai, Zheng-Yu Niu, Bo Wang, Jie Liu, Min Zhang

## 利用层次错误检查表增强大型语言模型中的工具学习。
Enhancing Tool Learning in Large Language Models with Hierarchical Error Checklists
Yue Cui, Liuyi Yao, Shuchang Tao, Weijie Shi, Yaliang Li, Bolin Ding, Xiaofang Zhou

## 用于细粒度阿拉伯语可读性评估的大型平衡语料库。
A Large and Balanced Corpus for Fine-grained Arabic Readability Assessment
Khalid Elmadani, Nizar Habash, Hanada Taha

## 一种全自动的会话话语标注流水线：基于大规模语言模型的树结构生成与标注。
A Fully Automated Pipeline for Conversational Discourse Annotation: Tree Scheme Generation and Labeling with Large Language Models
Kseniia Petukhova, Ekaterina Kochmar

## SynGraph：一种用于稀疏流式用户情感建模的动态图-LLM 综合框架。
SynGraph: A Dynamic Graph-LLM Synthesis Framework for Sparse Streaming User Sentiment Modeling
Xin Zhang, Qiyu Wei, Yingjie Zhu, Linhai Zhang, Deyu Zhou, Sophia Ananiadou

## 题目：仅使用合成数据，医学视觉-语言预训练能否成功？
Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?
Che Liu, Zhongwei Wan, Haozhe Wang, Yinda Chen, Talha Qaiser, Chen Jin, Nikolay Burlutskiy, Fariba Yousefi, Rossella Arcucci

## 资源友好型多跳问答动态增强链
Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering
Binquan Ji, Haibo Luo, YifeiLu, Lei Hei, Jiaqi Wang, Tingjing Liao, Wang Lingyu, Shichao Wang, Feiliang Ren

## 通过总结视角评估大语言模型对混合情境幻觉的评估能力。
Evaluating LLMs’ Assessment of Mixed-Context Hallucination Through the Lens of Summarization
Siya Qi, RUI CAO, Yulan He, Zheng Yuan

## TUBA：通过指令微调在LLMs中跨语言后门攻击的可移植性。
TUBA: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning
Xuanli He, Jun Wang, Qiongkai Xu, Pasquale Minervini, Pontus Stenetorp, Benjamin I. P. Rubinstein, Trevor Cohn

## LLM与我们的数字双身相距多远？基于人设的行为链模拟基准。
How Far are LLMs from Being Our Digital Twins? A Benchmark for Persona-Based Behavior Chain Simulation
Rui Li, Heming Xia, Xinfeng Yuan, Qingxiu Dong, Lei Sha, Wenjie Li, Zhifang Sui

## 展望世界，发现知识：面向大型视觉语言模型的中文事实性评估。
See the World, Discover Knowledge: A Chinese Factuality Evaluation for Large Vision Language Models
Jihao Gu, Yingyao Wang, Pi Bu, Chen Wang, Ziming Wang, Tengtao Song, Donglai Wei, Jiale Yuan, Yingxiu Zhao, Jun Song, Bo Zheng, Yancheng He, Shilong Li, Jiaheng Liu, Meng Cao, Xiaoyong Zhu, Yingshui Tan, Xiang Li, Wenbo Su

## 将独特角色分配给量化矩阵和低秩矩阵以实现最优权重分解。
Assigning Distinct Roles to Quantized and Low-Rank Matrices Toward Optimal Weight Decomposition
Yoonjun Cho, Soeun Kim, Dongjae Jeon, Kyelim Lee, Beomsoo Lee, Albert No

## 多语言语言模型如何记住事实？
How Do Multilingual Language Models Remember Facts?
Constanza Fierro, Negar Foroutan, Desmond Elliott, Anders Søgaard

## 不确定性估计在检索增强生成中的公理分析。
Axiomatic Analysis of Uncertainty Estimation For Retrieval Augmented Generation
Heydar Soudani, Evangelos Kanoulas, Faegheh Hasibi

## 从连续提示的表示中提取文本描述。
Eliciting Textual Descriptions from Representations of Continuous Prompts
Daniela Gottesman, Mor Geva, Dana Ramati

## 通过针对幻觉的直接偏好优化减轻多模态大型语言模型的幻觉。
Mitigating Hallucination in Multimodal Large Language Model via Hallucination-targeted Direct Preference Optimization
Yuhan Fu, Ruobing Xie, Xingwu Sun, Zhanhui Kang, Xirong Li

## LoFTI：本地化与事实性转移至印度地区。
LoFTI: Localization and Factuality Transfer to Indian Locales
Sona Elza Simon, Soumen Kumar Mondal, Abhishek Singhania, Sayambhu Sen, Preethi Jyothi

## 基于证据编辑的层次检索方法在标准财务文件开放域问答中的应用。
Hierarchical Retrieval with Evidence Curation for Open-Domain Financial Question Answering on Standardized Documents
Jaeyoung Choe, Jihoon Kim, Woohwan Jung

## 监测解码：通过评估生成部分响应的事实性来减轻幻觉现象。
Monitoring Decoding: Mitigating Hallucination via Evaluating the Factuality of Partial Response during Generation
Yurui Chang, Bochuan Cao, Lu Lin

## GNN-RAG：基于图神经网络的检索方法，用于知识图上高效的大语言模型推理。
GNN-RAG: Graph Neural Retrieval for Efficient Large Language Model Reasoning on Knowledge Graphs
Costas Mavromatis, George Karypis

## EuroVerdict：针对错误信息的多语言裁决生成数据集
EuroVerdict: A Multilingual Dataset for Verdict Generation Against Misinformation
Daniel Russo, Fariba Sadeghi, Stefano Menini, Marco Guerini

## RAPID：基于写作规划和信息发现的高效长文本生成与检索增强。
RAPID: Efficient Retrieval-Augmented Long Text Generation with Writing Planning and Information Discovery
Hongchao Gu, Dexun Li, Kuicai Dong, Hao Zhang, Hang Lv, Hao Wang, Defu Lian, Yong Liu, Enhong Chen

## ASTRID - 一种自动化且可扩展的 TRIaD，用于评价基于RAG的临床问答系统。
ASTRID - An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems
Yajie Vera He, Mohita Chowdhury, Jared Joselowitz, Aisling Higham, Ernest Lim

## 题目：Debate4MATH：多智能体辩论以实现详细的数学推理。
Debate4MATH: Multi-Agent Debate for Fine-Grained Reasoning in Math
Shaowei Zhang, Deyi Xiong

## 证据的解剖：可解释的ICD编码调查。
The anatomy of evidence: An investigation into explainable ICD coding
Katharina Beckh, Felix Studeny, Sujan Sai Gannamaneni, Dario Antweiler, Stefan Rueping

## 采用任何模态提问：关于多模态检索增强生成的全面综述。
Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation
Mohammad mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari

## 先消歧后解析：在语义解析中的歧义解决生成解释。
Disambiguate First Parse Later: Generating Interpretations for Ambiguity Resolution in Semantic Parsing
Irina Saparina, Mirella Lapata

## 基于LLM的迭代双语理解翻译推理。
LLM-based Translation Inference with Iterative Bilingual Understanding
Andong Chen, Kehai Chen, Yang Xiang, Xuefeng Bai, Muyun Yang, Yang Feng, Tiejun Zhao, Min zhang

## AVG-LLaVA：一种具有自适应视觉粒度的高效多模态大型模型。
AVG-LLaVA: An Efficient Large Multimodal Model with Adaptive Visual Granularity
Zhibin Lan, Liqiang Niu, Fandong Meng, Wenbo Li, Jie Zhou, Jinsong Su

## 基于信心的检查集选择评估大型语言模型。
Evaluating Large Language Models for Confidence-based Check Set Selection
Jane Arleth dela Cruz, Iris Hendrickx, Martha Larson

## 词形很重要：.typogrify（错别字或拼写错误）对LLMs语义重建的影响。
Word Form Matters: LLMs’ Semantic Reconstruction under Typoglycemia
Chenxi Wang, Tianle Gu, zhongyu wei, Lang Gao, Zirui Song, Xiuying Chen

## 文本到图像模型对提示模板窃取的脆弱性：一种差分进化方法
Vulnerability of Text-to-Image Models to Prompt Template Stealing: A Differential Evolution Approach
Yurong Wu, Fangwen Mu, Qiuhong Zhang, Jinjing Zhao, Xinrun Xu, Lingrui Mei, Yang Wu, Lin Shi, Junjie Wang, Zhiming Ding, Yiwei Wang

## MVL-SIB：大规模多语言视觉-语言基准，用于跨模态主题匹配。
MVL-SIB: A Massively Multilingual Vision-Language Benchmark for Cross-Modal Topical Matching
Fabian David Schmidt, Florian Schneider, Chris Biemann, Goran Glavaš

## 通过学习自我生成数据的自我反思来提高小规模语言模型的元 introspection。
Improving Meta Introspection of Small LLMs by Learning Self-Reflection from Self-Generated Data
Jiaqi Li, Xinyi Dong, Yang Liu, Zhizhuo Yang, Quansen Wang, Xiaobo Wang, Song-Chun Zhu, Zixia Jia, Zilong Zheng

## 自动调整大型语言模型层级：优化成本与准确性。
Automatic Transmission for LLM Tiers: Optimizing Cost and Accuracy in Large Language Models
Injae Na, Keonwoong Noh, Woohwan Jung

## 低秩互联层间适应
Low-Rank Interconnected Adaptation across Layers
Yibo Zhong, Jinman Zhao, Yao Zhou

## mStyleDistance：多语言风格嵌入及其评估。
mStyleDistance: Multilingual Style Embeddings and their Evaluation
Justin Qiu, Jiacheng Zhu, Ajay Patel, Marianna Apidianaki, Chris Callison-Burch

## Argus：基准测试与增强视觉-语言模型以生成三维放射学报告
Argus: Benchmarking and Enhancing Vision-Language Models for 3D Radiology Report Generation
Che Liu, Zhongwei Wan, Yuqi Wang, Hui Shen, Haozhe Wang, Kangyu Zheng, Mi Zhang, Rossella Arcucci

## MAGIC-VQA：结合常识知识的多模态 grounded 推理视觉问答。
MAGIC-VQA: Multimodal And Grounded Inference with Commonsense Knowledge for Visual Question Answering
Shuo Yang, Siwen Luo, Caren Han, Eduard Hovy

## SeqMMR：增强批次序列知识编辑的序列模型合并与LLM路由方法。
SeqMMR: Sequential Model Merging and LLM Routing for Enhanced Batched Sequential Knowledge Editing
Shanbao Qiao, Xuebing Liu, Akshat Gupta, Seung-Hoon Na

## RAG-RewardBench：评估检索增强生成中奖励模型的偏好对齐基准。
RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment
Zhuoran Jin, Hongbang Yuan, Tianyi Men, Pengfei Cao, Yubo Chen, Jiexin Xu, Huaijun Li, Xiaojian Jiang, Kang Liu, Jun Zhao

## 基于变化实体引导的异构表示分离方法用于变化描述生成。
Change Entity-guided Heterogeneous Representation Disentangling for Change Captioning
Yi Li, Yunbin Tu, Liang Li, Li Su, Qingming Huang

## GaRAGe：一种用于RAG评估的带有语义 grounding 注释的基准数据集。
GaRAGe: A Benchmark with Grounding Annotations for RAG Evaluation
Ionut Teodor Sorodoc, Leonardo F. R. Ribeiro, Rexhina Blloshmi, Christopher Davis, Adrià de Gispert

## 生成、鉴别、进化：通过精细粒度的句子级自我进化提升上下文忠实度。
Generate, Discriminate, Evolve: Enhancing Context Faithfulness via Fine-Grained Sentence-Level Self-Evolution
Kun LI, Tianhua Zhang, Yunxiang Li, Hongyin Luo, Abdalla Mohamed Salama Sayed Moustafa, Xixin Wu, James R. Glass, Helen M. Meng

## PAM：同义替换中心化的AMR评估指标。
PAM: Paraphrase AMR-Centric Evaluation Metric
Afonso Sousa, Henrique Lopes Cardoso

## VP-MEL：视觉提示引导的多模态实体链接。
VP-MEL: Visual Prompts Guided Multimodal Entity Linking
Hongze Mi, Jinyuan Li, Zhangxuying, Haoran Cheng, Jiahao Wang, Di Sun, Gang Pan

## 在大语言模型时代，词义归纳仍未解决。
In the LLM era, Word Sense Induction remains unsolved
Anna Mosolova, Marie Candito, Carlos Ramisch

## FADE：为何优秀特征会出现糟糕的描述。
FADE: Why Bad Descriptions Happen to Good Features
Bruno Puri, Aakriti Jain, Elena Golimblevskaia, Patrick Kahardipraja, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin

## 谁能够抵抗聊天音频攻击？大型语言模型评估基准。
Who Can Withstand Chat-Audio Attacks? An Evaluation Benchmark for Large Language Models
Wanqi Yang, Yanda Li, Meng Fang, Yunchao Wei, Ling Chen

## 导航政治立场：评估多语言大型语言模型在不同语言和国籍中的表现。
Navigating the Political Compass: Evaluating Multilingual LLMs across Languages and Nationalities
Chadi Helwe, Oana Balalau, Davide Ceolin

## Libra：利用时间序列图像进行生物医学放射分析。
Libra: Leveraging Temporal Images for Biomedical Radiology Analysis
Xi Zhang, Zaiqiao Meng, Jake Lever, Edmond S. L. Ho

## ExpliCa：评估大型语言模型中的显式因果推理能力。
ExpliCa: Evaluating Explicit Causal Reasoning in Large Language Models
Martina Miliani, Serena Auriemma, Alessandro Bondielli, Emmanuele Chersoni, Lucia Passaro, Irene Sucameli, Alessandro Lenci

## 作为增强偏见检测催化剂的刻板印象检测：一种多任务学习方法。
Stereotype Detection as a Catalyst for Enhanced Bias Detection: A Multi-Task Learning Approach
Aditya Tomar, Rudra Murthy, Pushpak Bhattacharyya

## 填补时间空白：使用大语言模型在项目 Gutenberg 集廊中恢复缺失的出版年份。
Filling the Temporal Void: Recovering Missing Publication Years in the Project Gutenberg Corpus Using LLMs
Omar Momen, Manuel Schaaf, Alexander Mehler

## 方言能否更好地充当提示词？以阿拉伯语主观文本分类为例的研究。
Are Dialects Better Prompters? A Case Study on Arabic Subjective Text Classification
Leila MOUDJARI, Farah Benamara

## 语言模型中的实体识别研究
On Entity Identification in Language Models
Masaki Sakata, Sho Yokoi, Benjamin Heinzerling, Takumi Ito, Kentaro Inui

## 核心自然逻辑：演绎树生成的动态奖励。
Natural Logic at the Core: Dynamic Rewards for Entailment Tree Generation
Jihao Shi, Xiao Ding, Kai Xiong, Hengwei Zhao, Bing Qin, Ting Liu

## 嵌套细化形态变化：高效的算法设计中提示和代码的反思性演化。
Nested-Refinement Metamorphosis: Reflective Evolution of Prompts and Code for Efficient Algorithm Design
Shuhan Guo, Nan Yin, James Kwok, Quanming Yao

## 可视化策略-奖励互动以指导大型语言模型的零阶偏好优化。
Visualising Policy-Reward Interplay to Inform Zeroth-Order Preference Optimisation of Large Language Models
Alessio Galatolo, Zhenbang Dai, Meriem Beloucif, Katie Winkle

## Review-Instruct：一种基于评价的多轮对话生成方法用于大规模语言模型。
Review-Instruct: A Review-Driven Multi-Turn Conversations Generation Method for Large Language Models
Jiangxu Wu, Cong Wang, Tianhuang Su, lin haozhi, JunYang, Zhangchao, Binqiang Pan, SongpanYang, Mingpeng, Kai Shi, ZIXIAN LI

## MC-MKE：一种强调模态一致性的细粒度多模态知识编辑基准。
MC-MKE: A Fine-Grained Multimodal Knowledge Editing Benchmark Emphasizing Modality Consistency
Junzhe Zhang, Huixuan Zhang, Xunjian Yin, Baizhou Huang, Xu Zhang, Xinyu Hu, Xiaojun Wan

## 隐喻与大型语言模型：表层特征比深层次理解更为重要。
Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding
Elisa Sanchez-Bayona, Rodrigo Agerri

## AskQE：机器翻译自动评价的问答式方法。
AskQE: Question Answering as Automatic Evaluation for Machine Translation
Dayeon Ki, Kevin Duh, Marine Carpuat

## R.R.: 通过回忆和排序揭露大模型训练隐私。
R.R.: Unveiling LLM Training Privacy through Recollection and Ranking
Wenlong Meng, GUO Zhenyuan, Lenan Wu, Chen GONG, Wenyan Liu, Weixian Li, Chengkun Wei, Wenzhi CHEN

## 你的大规模语言模型具备稳定推理的能力吗？
Are Your LLMs Capable of Stable Reasoning?
Junnan Liu, Hongwei Liu, Linchen Xiao, Ziyi Wang, Kuikun Liu, Songyang Gao, Wenwei Zhang, Songyang Zhang, Kai Chen

## 每张图都是新的语言：图学习与大语言模型。
Each graph is a new language: Graph Learning with LLMs
Huachi Zhou, Jiahe Du, Chuang Zhou, Chang Yang, Yilin Xiao, Yuxuan Xie, Xiao Huang

## 连接直觉联想与刻意回忆：赋能大型语言模型个人助手的图结构长期记忆。
Bridging Intuitive Associations and Deliberate Recall: Empowering LLM Personal Assistant with Graph-Structured Long-term Memory
Yujie Zhang, Weikang Yuan, Zhuoren Jiang

## 100-LongBench：实际上，默认的长上下文基准测试是否在真正评估长上下文能力？
100-LongBench: Are de facto Long-Context Benchmarks Literally Evaluating Long-Context Ability?
Van Yang, Hongye Jin, Shaochen Zhong, Song Jiang, Qifan Wang, Vipin Chaudhary, Xiaotian Han

## FANNO：仅使用开放源代码的大语言模型增强高质量教学数据。
FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs Only
He Zhu, Yifan Ding, Yicheng Tao, Zhiwen Ruan, Yixia Li, Wenjia Zhang, Yun Chen, Guanhua Chen

## Look & Mark：利用放射医师的眼球固定和边界框在多模态大型语言模型中生成胸部X光报告。
Look & Mark: Leveraging Radiologist Eye Fixations and Bounding boxes in Multimodal Large Language Models for Chest X-ray Report Generation
Yunsoo Kim, Jinge Wu, Su Hwan Kim, Pardeep Vasudev, Jiashu Shen, Honghan Wu

##  hatevolution：静态基准无法告诉我们的内容。
Hatevolution: What Static Benchmarks Don’t Tell Us
Chiara Di Bonaventura, Barbara McGillivray, Yulan He, Albert Meroño-Peñuela

## JEBS：细粒度生物医学词汇简化任务。
JEBS: A Fine-grained Biomedical Lexical Simplification Task
William Xia, Ishita Unde, Brian David Ondov, Dina Demner-Fushman

## CHARPEVAL：大型语言模型在知识导向对话中语境推理能力的基准测评。
CHARPEVAL: Benchmarking Large Language Models’ Contextual Reasoning in Knowledge-Grounded Dialogue
Abbas Ghaddar, David Alfonso-Hermelo, Philippe Langlais, Boxing Chen, Prasanna Parthasarathi

## 开放世界作者识别。
Open-World Authorship Attribution
Xinhao Tan, Songhua Liu, Xia Cong, Kunjun Li, Xinchao Wang

## Code-SPA：针对大型语言模型的有效且 robust 的代码调试中的风格偏好对齐。
Code-SPA: Style Preference Alignment to Large Language Models for Effective and Robust Code Debugging
Tengfei Wen, Xuanang Chen, Ben He, Le Sun

## EMRs2CSP：从电子医疗记录中提取临床状态路径。
EMRs2CSP : Mining Clinical Status Pathway from Electronic Medical Records
Yifei Chen, Ruihui Hou, Jingping Liu, Tong Ruan

## BenNumEval：评估孟加拉语数值推理能力的标准基准。
BenNumEval: A Benchmark to Assess LLM’s Numerical Reasoning Capabilities in Bengali
Kawsar Ahmed, Md Osama, Omar Sharif, Eftekhar Hossain, Mohammed Moshiul Hoque

## 用于协调多用户信息收集的LM代理。
LM Agents for Coordinating Multi-User Information Gathering
Harsh Jhamtani, Jacob Andreas, Benjamin Van Durme

## 一种基于树组织结构的法律推理基准，包括事实证明、证据和经验。
A Law Reasoning Benchmark for LLM with Tree-Organized Structures including Factum Probandum, Evidence and Experiences
Jiaxin Shen, Jinan Xu, Huiqi Hu, Luyi Lin, Guoyang Ma, Fei Zheng, Fandong Meng, Jie Zhou, Wenjuan Han

## $\\text{C}^{2}$KD：基于小型语言模型推荐的知识跨层和跨头蒸馏。
$\\text{C}^{2}$KD: Cross-layer and Cross-head Knowledge Distillation for Small Language Model-based Recommendation
Xiao Chen, Changyi Ma, Wenqi Fan, Zhaoxiang Zhang, Li Qing

## 名称背后有什么？通过匿名化减轻文本嵌入中的名称偏见。
What is in a name? Mitigating Name Bias in Text Embedding via Anonymization
Sahil Manchanda, Pannaga Shivaswamy

## 生成框架采样器用于长视频理解。
Generative Frame Sampler for Long Video Understanding
Linli Yao, Haoning Wu, Kun Ouyang, Yuanxing Zhang, Caiming Xiong, Bei Chen, Xu Sun, Junnan Li

## 通过视觉语言任务的后训练学习更好地行动。
Learning to Better Act by Post-training on Vision Language Tasks
Li Muyao, Zihao Wang, Kaichen He, Xiaojian Ma, Yitao Liang

## 通过可信赖引用透明化LLM中的内部和外部知识利用。
Transparentize the Internal and External Knowledge Utilization in LLMs with Trustworthy Citation
Jiajun Shen, Tong Zhou, Yubo Chen, Delai Qiu, Shengping Liu, Kang Liu, Jun Zhao

## Sign2Vis：自动手语数据可视化
Sign2Vis: Automated Data Visualization from Sign Language
Yao Wan, Yang Wu, Zhen Li, Guobiao Zhang, Hongyu Zhang, Zhou Zhao, Hai Jin, April Wang

## 基准中的基准：重现与气候相关的自然语言处理任务。
Benchmarking the Benchmarks: Reproducing Climate-Related NLP Tasks
Tom Calamai, Oana Balalau, Fabian M. Suchanek

## PersonaLens：对话人工智能助手个性化评估基准。
PersonaLens: A Benchmark for Personalization Evaluation in Conversational AI Assistants
Zheng Zhao, Clara Vania, Subhradeep Kayal, Naila Khan, Shay B Cohen, Emine Yilmaz

## 超越效率的尖端：探索小型语言模型中越狱攻击潜藏的威胁。
Beyond the Tip of Efficiency: Uncovering the Submerged Threats of Jailbreak Attacks in Small Language Models
Sibo Yi, Tianshuo Cong, Xinlei He, Qi Li, Jiaxing Song

## 多模态融合与一致性建模在视频主题切分中的应用
Multimodal Fusion and Coherence Modeling for Video Topic Segmentation
Hai Yu, Chong Deng, Qinglin Zhang, Jiaqing Liu, Qian Chen, Wen Wang

## FactLens：细粒度事实验证基准测试。
FactLens: Benchmarking Fine-Grained Fact Verification
Kushan Mitra, Dan Zhang, Sajjadur Rahman, Estevam Hruschka

## 基于过程的自我奖励语言模型
Process-based Self-Rewarding Language Models
Shimao Zhang, Xiao Liu, Xin Zhang, Junxiao Liu, Zheheng Luo, Shujian Huang, Yeyun Gong

## ShieldHead：大规模语言模型的解码时防护措施。
ShieldHead: Decoding-time Safeguard for Large Language Models
Zitao Xuan, Xiaofeng Mao, Da Chen, Xin Zhang, Yuhan Dong, JUN ZHOU

## iAgent：用户与推荐系统之间的防护代理，基于大语言模型。
iAgent: LLM Agent as a Shield between User and Recommender Systems
Wujiang Xu, Yunxiao Shi, Zujie Liang, Xuying Ning, Kai Mei, Kun Wang, Xi Zhu, Min Xu, Yongfeng Zhang

## 细节决定生死：基于翻译的跨语言转移在词分类任务中的应用。
The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks
Benedikt Ebing, Goran Glavaš

## 面向大型语言模型中的 misinformation 的主动防御策略综述。
A Survey on Proactive Defense Strategies Against Misinformation in Large Language Models
Shuliang Liu, Hongyi Liu, Aiwei Liu, Duan Bingchen, Zheng Qi, Yibo Yan, He GENG, Peijie Jiang, Jia Liu, Xuming Hu

## Tag-Instruct：基于结构增益的控制指令复杂性增强。
Tag-Instruct: Controlled Instruction Complexity Enhancement through Structure-based Augmentation
He Zhu, Zhiwen Ruan, Junyou Su, Xingwei He, Wenjia Zhang, Yun Chen, Guanhua Chen

## 通过指数竞争进行的 speculative 解码。
Speculative Decoding via Exponential Races
Szymon Kobus, Deniz Gunduz

## 超越预期：在同时同传中的延迟指标分析。
Going Beyond Your Expectations in Latency Metrics for Simultaneous Speech Translation
Jorge Iranzo-Sánchez, Javier Iranzo-Sánchez, Adrià Giménez, Jorge Civera

## 动用生成模型让死式混合语复生——以俄挪混合语为例。
Smotrom tvoja på ander drogoj verden! Resurrecting Dead Pidgin with Generative Models: Russenorsk Case Study
Ivan P. Yamshchikov, Sergei Shteiner, Anna Bykova, Alexey Tikhonov

## 使用双曲表示增强多跳推理以提高问答系统性能。
Enhancing Multi-Hop Reasoning for Question Answering with Hyperbolic Representations
Simon Welz, Lucie Flek, Akbar Karimi

## 混合结构文本检索在丰富文本图知识库中的应用。
Mixture of Structural-and-Textual Retrieval over Text-rich Graph Knowledge Bases
Yongjia Lei, Haoyu Han, Ryan A. Rossi, Franck Dernoncourt, Nedim Lipka, Mahantesh M Halappanavar, Jiliang Tang, Yu Wang

## PromptCoT：为大型语言模型中的数学推理合成奥林匹克级别问题。
PromptCoT: Synthesizing Olympiad-level Problems for Mathematical Reasoning in Large Language Models
Xueliang Zhao, Wei Wu, Jian Guan, Lingpeng Kong

## 递归问题理解在异构个人数据复杂问答中的应用。
Recursive Question Understanding for Complex Question Answering over Heterogeneous Personal Data
Philipp Christmann, Gerhard Weikum

## ExPerT：高效可解释的个性化长文本生成评估方法。
ExPerT: Effective and Explainable Evaluation of Personalized Long-Form Text Generation
Alireza Salemi, Julian Killingback, Hamed Zamani

## 注解者注解：关于说服技巧检测注解活动的分析、见解与建模。
Annotating the Annotators: Analysis, Insights and Modelling from an Annotation Campaign on Persuasion Techniques Detection
Davide Bassi, Dimitar Iliyanov Dimitrov, Bernardo D’Auria, Firoj Alam, Maram Hasanain, Christian Moro, Luisa Orrù, Gian Piero Turchi, Preslav Nakov, Giovanni Da San Martino

## 基于LLM的多语言机器翻译训练后不对称冲突与协同作用。
Asymmetric Conflict and Synergy in Post-training for LLM-based Multilingual Machine Translation
Tong Zheng, Yan Wen, Huiwen Bao, Junfeng Guo, Heng Huang

## 事实回忆、启发式方法或纯粹猜測？语言模型在事实填充中的精确解读。
Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion
Denitsa Saynova, Lovisa Hagström, Moa Johansson, Richard Johansson, Marco Kuhlmann

## FPE2M2：接近无损且高效的量化方法，使用原生浮点数。
FPE2M2: Approaching Lossless and Efficient Quantization with Native Floating Point
Ke Yi, jianwei zhang, Zhiying Xu, Xinlong Yang, Yang Zhou, Minmin Sun, Zengke Liu, Tong Zhang, Junyang Lin, Jingren Zhou

## 理解并满足在测量由大规模语言模型（LLM）系统引起的表征性伤害时的实践需求。
Understanding and Meeting Practitioner Needs When Measuring Representational Harms Caused by LLM-Based Systems
Emma Harvey, Emily Sheng, Su Lin Blodgett, Alexandra Chouldechova, Jean Garcia-Gathright, Alexandra Olteanu, Hanna Wallach

## 同一公司，相似信号：身份在 earnings 电话会议记录中的作用。
Same Company, Same Signal: The Role of Identity in Earnings Call Transcripts
Ding Yu, Zhuo Liu, Hangfeng He

## 探索关于NLP成果的人类中心语言表达。
Exploring Anthropomorphic Language in the Reporting of NLP Findings
Matthew Shardlow, Ashley Williams, Charlie Roadhouse, Filippos Ventirozos, Piotr Przybyła

## SemCSE：使用LLM生成的摘要构建科学摘要的语义对比句子嵌入。
SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts
Marc Felix Brinner, Sina Zarrieß

## 注意（信念）差距：在大语言模型世界中的群体身份。
Mind the (Belief) Gap: Group Identity in the World of LLMs
Angana Borah, Marwa Houalla, Rada Mihalcea

## 一种增强基于微调的大型语言模型遗忘的一般框架。
A General Framework to Enhance Fine-tuning-based LLM Unlearning
Jie Ren, Zhenwei DAI, Xianfeng Tang, Hui Liu, Jingying Zeng, Zhen Li, Rahul Goutam, Suhang Wang, Yue Xing, Qi He, Hui Liu

## 人类验证对理论思维基准不够充分。
Human Validation Is Not Enough for Theory of Mind Benchmarks
Adil Soubki, Owen Rambow

## MiniKV：通过压缩和系统协同设计在高效长上下文推理中推动2位KV缓存的极限。
MiniKV: Pushing the Limits of 2-Bit KV Cache via Compression and System Co-Design for Efficient Long Context Inference
Akshat Sharma, Hangliang Ding, Jianping Li, Neel Dani, Minjia Zhang

## Sci-LoRA：跨域非专业术语重述的科学LoRA混合模型。
Sci-LoRA: Mixture of Scientific LoRAs for Cross-Domain Lay Paraphrasing
Ming Cheng, Jiaying Gong, Hoda Eldardiry

##  Trick或诚意：对抗模糊性与语言模型评估。
Trick or Neat: Adversarial Ambiguity and Language Model Evaluation
Antonia Karamolegkou, Oliver Eberle, Phillip Rust, Carina Kauf, Anders Søgaard

## 编码器为基础的视觉-语言模型中的偏差会传播：从内在度量到零样本检索结果的系统分析。
Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes
Kshitish Ghate, Tessa Charlesworth, Mona T. Diab, Aylin Caliskan

## 逐步困惑度引导细化以提高大型语言模型连贯推理效率。
Stepwise Perplexity-Guided Refinement for Efficient Chain-of-Thought Reasoning in Large Language Models
Yingqian Cui, Pengfei He, Jingying Zeng, Hui Liu, Xianfeng Tang, Zhenwei DAI, Yan Han, Chen Luo, Jing Huang, Zhen Li, Suhang Wang, Yue Xing, Jiliang Tang, Qi He

## 朝向RPA评估设计指南：基于大型语言模型的角色扮演代理综述。
Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents
Chaoran Chen, Bingsheng Yao, Ruishi Zou, Wenyue Hua, Weimin Lyu, Toby Jia-Jun Li, Dakuo Wang

## MultiChallenge：一个面向前沿大语言模型的挑战性多轮对话评估基准。
MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs
Kaustubh Deshpande, Ved Sirdeshmukh, Johannes Baptist Mols, Lifeng Jin, Ed-Yeremai Hernandez-Cardona, Dean Lee, Jeremy Kritz, Willow E. Primack, Summer Yue, Chen Xing

## 多模态基础模型能够理解示意图吗？一项针对科学论文中信息查询的实证研究。
Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers
Yilun Zhao, Chengye Wang, Chuhan Li, Arman Cohan

## 安全不仅仅关于拒绝：增强推理的微调以实现可解释的大语言模型安全。
Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for Interpretable LLM Safety
Yuyou Zhang, Miao Li, William Han, Yihang Yao, Zhepeng Cen, Ding Zhao

## 在语言模型训练中添加或删除个人信息引起的隐私级联效应。
Privacy Ripple Effects from Adding or Removing Personal Information in Language Model Training
Jaydeep Borkar, Matthew Jagielski, Katherine Lee, Niloofar Mireshghallah, David A. Smith, Christopher A. Choquette-Choo

## MetaSynth：以元提示为导向的能动支架，用于生成多样的合成数据。
MetaSynth: Meta-Prompting-Driven Agentic Scaffolds for Diverse Synthetic Data Generation
Haris Riaz, Sourav Sanjukta Bhabesh, Vinayak Arannil, Miguel Ballesteros, Graham Horwood

## MVTamperBench：评估视觉-语言模型的鲁棒性。
MVTamperBench: Evaluating Robustness of Vision-Language Models
Amit Agarwal, Srikant Panda, Angeline Charles, Hitesh Laxmichand Patel, Bhargava Kumar, Priyaranjan Pattnayak, Taki Hasan Rafi, Tejaswini Kumar, Hansa Meghwani, Karan Gupta, Dong-Kyu Chae

## BEDAA：贝叶斯增强的DeBERTa用于不确定性感知的作者识别。
BEDAA: Bayesian Enhanced DeBERTa for Uncertainty-Aware Authorship Attribution
Iqra Zahid, Youcheng Sun, Riza Batista-Navarro

## 多模态不一致性推理（MMIR）：多模态推理模型的新基准。
Multimodal Inconsistency Reasoning (MMIR): A New Benchmark for Multimodal Reasoning Models
Qianqi Yan, Yue Fan, Hongquan Li, Shan Jiang, Yang Zhao, Xinze Guan, Ching-Chen Kuo, Xin Eric Wang

## 视觉-语言模型在跨模态对齐实体方面存在问题。
Vision-Language Models Struggle to Align Entities across Modalities
Iñigo Alonso, Gorka Azkune, Ander Salaberria, Jeremy Barnes, Oier Lopez de Lacalle

## 一个萌度弗德在你说它可爱时会感觉不那么萌度弗德，但仍然觉得不好：LLM中的情境依赖形式-意义系统性。
A puyfred feels less of a puyfred if you say it’s cute, but it still feels bad: context-dependent form-meaning systematicity in LLMs
Giovanni Cassani, Jaïr A. Waal

## MedCite：语言模型能否生成可验证的医学文本？
MedCite: Can Language Models Generate Verifiable Text for Medicine?
Xiao Wang, Mengjue Tan, Qiao Jin, Guangzhi Xiong, Yu Hu, Aidong Zhang, Zhiyong Lu, Minjia Zhang

## 改进可解释的礼貌检测模型泛化能力的言语行为模式。
Speech Act Patterns for Improving Generalizability of Explainable Politeness Detection Models
Ahmad Aljanaideh

## 面向印尼语 discourse 的多标签数据集：探究毒性、极化和人口统计信息。
A Multi-Labeled Dataset for Indonesian Discourse: Examining Toxicity, Polarization, and Demographics Information
Lucky Susanto, Musa Izzanardi Wijanarko, Prasetia Anugrah Pratama, Zilu Tang, Fariz Akyas, Traci Hong, Ika Karlina Idris, Alham Fikri Aji, Derry Tanti Wijaya

## 变色龙大语言模型：用户角色影响聊天机器人个性转变。
Chameleon LLMs: User Personas Influence Chatbot Personality Shifts
Jane Xing, Tianyi Niu, Shashank Srivastava

## 系统评估Transformer-LM表示以捕捉作者状态和特质。
A Systematic Evaluation of Transformer-LM Representations for Capturing Author States and Traits
Khushboo Singh, Vasudha Varadarajan, Adithya V Ganesan, August Håkan Nilsson, Nikita Soni, Syeda Mahwish, Pranav Chitale, Ryan L. Boyd, Lyle Ungar, Richard N Rosenthal, H. Schwartz

## 《谎言人物述说：利用大型语言模型正常化 adversarial unicode_perturbations》
The Lies Characters Tell: Utilizing Large Language Models to Normalize Adversarial Unicode Perturbations
Portia Cooper, Eduardo Blanco, Mihai Surdeanu

## 让陪审团决定：通过增量贪婪评估实现情境学习中的公平展示选择。
Let The Jury Decide: Fair Demonstration Selection for In-Context Learning through Incremental Greedy Evaluation
Sadaf MD Halim, Chen Zhao, Xintao Wu, Latifur Khan, Christan Grant, Fariha Ishrat Rahman, Feng Chen

## 大型语言模型中的保守偏差：衡量关系预测。
Conservative Bias in Large Language Models: Measuring Relation Predictions
Toyin Aguda, Erik Wilson, Allan Anzagira, Simerjot Kaur, Charese Smiley

## 正确答案，错误得分：揭示LLM在多项选择题回答评价中的不一致性。
Right Answer, Wrong Score: Uncovering the Inconsistencies of LLM Evaluation in Multiple-Choice Question Answering
Francesco Maria Molfese, Luca Moroni, Luca Gioffré, Alessandro Scirè, Simone Conia, Roberto Navigli

## 题目：AfroBench：大型语言模型在非洲语言上的表现如何？
AfroBench: How Good are Large Language Models on African Languages?
Jessica Ojo, Odunayo Ogundepo, Akintunde Oladipo, Kelechi Ogueji, Jimmy Lin, Pontus Stenetorp, David Ifeoluwa Adelani

## 在目标语言中受限数据下训练双语语言模型。
Training Bilingual LMs with Data Constraints in the Targeted Language
Skyler Seto, Maartje Ter Hoeve, Richard He Bai, Natalie Schluter, David Grangier

## V-ALPHASOCIAL：视觉社交常识推理的基准与自省式思维过程生成。
V-ALPHASOCIAL: Benchmark and Self-Reflective Chain-of-Thought Generation for Visual Social Commonsense Reasoning
Zongyu Lin, Zhikun Xu, Xiaohan Song, Yixin Wan, Xingcheng Yao, Tsung-Han Lin, Selina Song, Pranav Subbaraman, Ben Zhou, Kai-Wei Chang, Yizhou Sun

## ChartQAPro：更具多样性和挑战性的图表问答基准。
ChartQAPro: A More Diverse and Challenging Benchmark for Chart Question Answering
Ahmed Masry, Mohammed Saidul Islam, Mahir Ahmed, Aayush Bajaj, Firoz Kabir, Aaryaman Kartha, Md Tahmid Rahman Laskar, Mizanur Rahman, Shadikur Rahman, Mehrad Shahmohammadi, Megh Thakkar, Md Rizwan Parvez, Enamul Hoque, Shafiq Joty

## 不如随机？关于大型多模态模型在医疗VQA中的尴尬简单探测评估。
Worse than Random? An Embarrassingly Simple Probing Evaluation of Large Multimodal Models in Medical VQA
Qianqi Yan, Xuehai He, Xiang Yue, Xin Eric Wang

## TReMu：面向具有记忆功能多会话对话中LLM代理的时间符号神经推理方法。
TReMu: Towards Neuro-Symbolic Temporal Reasoning for LLM-Agents with Memory in Multi-Session Dialogues
Yubin Ge, Salvatore Romeo, Jason Cai, Raphael Shu, MONICA SUNKARA, Yassine Benajiba, Yi Zhang

## 减轻RAG中的偏差：控制嵌入器
Mitigating Bias in RAG: Controlling the Embedder
Taeyoun Kim, Jacob Mitchell Springer, Aditi Raghunathan, Maarten Sap

## 假设文档还是知识泄露？关于基于LLM的查询扩展的重新思考。
Hypothetical Documents or Knowledge Leakage? Rethinking LLM-based Query Expansion
Yejun Yoon, Jaeyoon Jung, Seunghyun Yoon, Kunwoo Park

## 从观察到理解：具有不确定性校准的前门调整方法以增强EGOCentric推理在LVLM中的性能。
From Observation to Understanding: Front-Door Adjustments with Uncertainty Calibration for Enhancing Egocentric Reasoning in LVLMs
Shenshen Li, Wenxin Meng, Lei Wang, Hao Yang, Chong Peng, Peng Yan, Fumin Shen, Jingkuan Song, Heng Tao Shen, Xing Xu

## 作为神经语言主体的大语言模型：形式与意义表现与能力差异研究。
Large Language Models as Neurolinguistic Subjects: Discrepancy in Performance and Competence for Form and Meaning
Linyang He, Ercong Nie, Helmut Schmid, Hinrich Schuetze, Nima Mesgarani

## 解构逻辑：上下文在大型语言模型推理能力中的作用。
Disentangling Logic: The Role of Context in Large Language Model Reasoning Capabilities
Wenyue Hua, Kaijie Zhu, Lingyao Li, Lizhou Fan, Mingyu Jin, Shuhang Lin, Haochen Xue, Zelong Li, Jindong Wang, Yongfeng Zhang

## PreSumm：无需总结即预测总结性能。
PreSumm: Predicting Summarization Performance Without Summarizing
Steven Koniaev, Ori Ernst, Jackie CK Cheung

## Sens-合并：基于灵敏度的参数平衡以合并大型语言模型
Sens-Merging: Sensitivity-Guided Parameter Balancing for Merging Large Language Models
Shuqi LIU, Han Wu, Bowei He, Xiongwei Han, Mingxuan Yuan, Linqi Song

## 利用执行反馈优化文本到SQL的推理。
Optimizing Reasoning for Text-to-SQL with Execution Feedback
Bohan Zhai, Canwen Xu, Zhewei Yao, Yuxiong He

## EgoNormia：物理社交规范理解基准测试。
EgoNormia: Benchmarking Physical Social Norm Understanding
MohammadHossein Rezaei, Yicheng Fu, Phil Cuvin, Caleb Ziems, Yanzhe Zhang, Hao Zhu, Diyi Yang

## 知识蒸馏中的泛化与忠实性悖论探析
On the Generalization vs Fidelity Paradox in Knowledge Distillation
Suhas Kamasetty Ramesh, Ayan Sengupta, Tanmoy Chakraborty

## 树形提示：简化提示流程控制优化。
Tree-of-Prompts: Abstracting Control-Flow for Prompt Optimization
Jihyuk Kim, Shubham Garg, Lahari Poddar, seung-won hwang, Chris Hench

## FaVe：长格式答案的分解与验证搜索理由。
FaVe: Factored and Verified Search Rationale for Long-form Answer
Jihyuk Kim, SUNGJIN LEE, seung-won hwang, Yang Liu

## VISIAR：赋能多模态语言模型进行视觉故事创意生成。
VISIAR: Empower MLLM for Visual Story Ideation
Zhaoyang Xia, Somdeb Sarkhel, Mehrab Tanjim, Stefano Petrangeli, Ishita Dasgupta, Yuxiao Chen, JINXUAN XU, Di Liu, Saayan Mitra, Dimitris N. Metaxas

## 直接行为优化：释放轻量级大语言模型的潜力。
Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs
Hongming Yang, Shi Lin, Jun Shao, Changting Lin, Donghai Zhu, Meng Han, Qinglei Kong

## 题目：带有异常值权重的分层采样用于大规模语言模型微调。
Outlier-weighed Layerwise Sampling for LLM Fine-tuning
Pengxiang Li, Lu Yin, Xiaowei Gao, Shiwei Liu

## KVPR：基于I/O感知的KV缓存部分重计算高效LLM推断方法。
KVPR: Efficient LLM Inference with I/O-Aware KV Cache Partial Recomputation
Chaoyi Jiang, Lei Gao, Hossein Entezari Zarch, Murali Annavaram

## UnrealLLM：由LLM驱动的程序化内容生成，迈向高度可控且可交互的3D场景生成。
UnrealLLM: Towards Highly Controllable and Interactable 3D Scene Generation by LLM-powered Procedural Content Generation
SongTang, Kaiyong Zhao, Lei Wang, Yuliang Li, Xuebo Liu, Junyi Zou, Qiang Wang, Xiaowen Chu

## 通过LLM指导的异常生成进行分布外检测：面向文本标注图的方法
Out-of-Distribution Detection via LLM-Guided Outlier Generation for Text-attributed Graph
Xiangwei Lv, Mengze Li, Jingyuan Chen, Zhiang Dong, Sirui Han, Beishui Liao

## CoRE：基于条件的推理以识别复杂事件中结果的变异。
CoRE: Condition-based Reasoning for Identifying Outcome Variance in Complex Events
Sai P Vallurupalli, Francis Ferraro

## LLM们的偏好如何影响事件论元提取？CAT：应对无监督事件论元提取中的偏好陷阱。
How do LLMs’ Preferences Affect Event Argument Extraction? CAT: Addressing Preference Traps in Unsupervised EAE
Yunhao Wei, Kai Shuang, Zhiyi Li, Chenrui Mao

## 是否知道自己知道：通过无偏差历史上下文学习识别知识边界。
Whether LLMs Know If They Know: Identifying Knowledge Boundaries via Debiased Historical In-Context Learning
Bo Lv, Nayu Liu, Yang Shen, Xin Liu, Ping Luo, Yue Yu

## 文档级关系抽取中的全局关系与实体对推理。
Document-Level Relation Extraction with Global Relations and Entity Pair Reasoning
Fu Zhang, Yi Yan, Jingwei Cheng

## MemBench：朝着LLM基于代理内存更为全面的评估迈进。
MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents
Haoran Tan, Zeyu Zhang, Quanyu Dai, Chen Ma, Xu Chen, Zhenhua Dong

## ZeroDL：借助大型语言模型实现的零样本分布学习文本聚类。
ZeroDL: Zero-shot Distribution Learning for Text Clustering via Large Language Models
Hwiyeol Jo, Hyunwoo Lee, Taiwoo Park

## 朝向存储高效的视觉文档检索：关于减少块级嵌入的实证研究。
Towards Storage-Efficient Visual Document Retrieval: An Empirical Study on Reducing Patch-Level Embeddings
Yubo Ma, Jinsong Li, Yuhang Zang, Xiaobao Wu, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Haodong Duan, Jiaqi Wang, Yixin Cao, Aixin Sun

## LLMTaxo：利用大型语言模型构建社交媒体中事实断言的分类体系。
LLMTaxo: Leveraging Large Language Models for Constructing Taxonomy of Factual Claims from Social Media
Haiqi Zhang, Zhengyuan Zhu, Zeyu Zhang, Chengkai Li

## MMEvol：增强多模态大型语言模型的Evol-Instruct。
MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct
Run Luo, Haonan Zhang, Longze Chen, Ting-En Lin, Xiong Liu, Yuchuan Wu, Min Yang, Yongbin Li, Minzheng Wang, Pengpeng Zeng, Lianli Gao, Heng Tao Shen, Yunshui Li, Hamid Alinejad-Rokny, Xiaobo Xia, Jingkuan Song, Fei Huang

## AnCast++：基于图的意义表示的文档级评估方法。
AnCast++: Document-Level Evaluation of Graph-based Meaning Representations
Haibo Sun, Jayeol Chun, Nianwen Xue

## 模式胜于原则：在噪声观测下LLMs归纳推理的脆弱性。
Patterns Over Principles: The Fragility of Inductive Reasoning in LLMs under Noisy Observations
Chunyang Li, Weiqi Wang, Tianshi Zheng, Yangqiu Song

## SciVerse：揭示多模态科学问题上LMMs的知识理解和视觉推理能力。
SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems
Ziyu Guo, Renrui Zhang, Hao Chen, Jialin Gao, Dongzhi Jiang, Jiaze Wang, Pheng-Ann Heng

## 探索预训练语言模型中英语和中文同形词的层间表示
Exploring Layer-wise Representations of English and Chinese Homonymy in Pre-trained Language Models
Matthew King-Hang Ma, XIE Chenwei, Wenbo Wang, William Shiyuan Wang

## DocMEdit：面向文档级别模型编辑。
DocMEdit: Towards Document-Level Model Editing
Li Zeng, Zeming Liu, Chong Feng, Heyan Huang, Yuhang Guo

## 数据解释器：一个用于数据科学的大型语言模型代理。
Data Interpreter: An LLM Agent for Data Science
Sirui Hong

## 解释后再处理：使用语法提示来增强语法接受性判断。
Explain-then-Process: Using Grammar Prompting to Enhance Grammatical Acceptability Judgments
Russell Scheinberg, Ameeta Agrawal, Amber Shore, So Young Lee

## 评估大型语言模型的长期记忆。
Evaluating the Long-Term Memory of Large Language Models
Zixi Jia, Qinghua Liu, Hexiao Li, Yuyan Chen, Jiqiang Liu

## 自适应解毒：通过毒性意识知识编辑保障LLMs的一般能力。
Adaptive Detoxification: Safeguarding General Capabilities of LLMs through Toxicity-Aware Knowledge Editing
Yifan Lu, Jing Li, Yigeng Zhou, Yihui Zhang, Wenya Wang, Xiucheng Li, Meishan Zhang, Fangming Liu, Jun Yu, Min Zhang

## DReSD：推测性解码的密集检索
DReSD: Dense Retrieval for Speculative Decoding
Milan Gritta, Huiyin Xue, Gerasimos Lampouras

## 使用半监督学习提高词对齐效果。
Improving Word Alignment Using Semi-Supervised Learning
Zhongtao Miao, Qiyu Wu, Masaaki Nagata, Yoshimasa Tsuruoka

## LLM如何获取新知识？从持续预训练的角度看知识电路视角。
How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training
Yixin Ou, Yunzhi Yao, Ningyu Zhang, Hui Jin, Jiacheng Sun, Shumin Deng, Zhenguo Li, Huajun Chen

## 多模态大型语言模型在文本丰富图像理解中的应用：全面综述
Multimodal Large Language Models for Text-rich Image Understanding: A Comprehensive Review
Pei Fu, Tongkun Guan, Zining Wang, Zhentao Guo, Chen Duan, Hao Sun, Boming Chen, Qianyi Jiang, Jiayao Ma, Kai zhou, Junfeng Luo

## 逐步精通：提升大型语言模型的软约束遵循能力。
Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models
Qingyu Ren, Jie Zeng, Qianyu He, Jiaqing Liang, Yanghua Xiao, Weikang Zhou, Zeye Sun, Fei Yu

## Core：增强事实精确性的鲁棒子断言识别。
Core: Robust Factual Precision with Informative Sub-Claim Identification
Zhengping Jiang, Jingyu Zhang, Nathaniel Weir, Seth Ebner, Miriam Wanner, Kate Sanders, Daniel Khashabi, Anqi Liu, Benjamin Van Durme

## 大型语言模型在学术界的影响力：从写作到演讲。
The Impact of Large Language Models in Academia: from Writing to Speaking
Mingmeng Geng, Caixi Chen, Yanru Wu, Yao Wan, Pan Zhou, Dongping Chen

## 重新思考基于主成分分析的多元人类偏好学习。
Rethinking Diverse Human Preference Learning through Principal Component Analysis
Feng Luo, Rui Yang, Hao Sun, Chunyuan Deng, Jiarui Yao, Jingyan Shen, Huan Zhang, Hanjie Chen

## PromptWizard：通过任务感知、反馈驱动自我进化优化提示。
PromptWizard: Optimizing Prompts via Task-Aware, Feedback-Driven Self-Evolution
Eshaan Agarwal, Raghav Magazine, Joykirat Singh, Vivek Dani, Tanuja Ganu, Akshay Nambi

## LongAttn：通过标记级注意力选择长上下文训练数据。
LongAttn: Selecting Long-context Training Data via Token-level Attention
Longyun Wu, Dawei Zhu, Guangxiang Zhao, Zhuocheng Yu, Junfeng Ran, Xiangyu Wong, Lin Sun, Sujian Li

## 基于LLM的符号积分在稳健的时间表推理中的应用
LLM-Symbolic Integration for Robust Temporal Tabular Reasoning
Atharv Kulkarni, Kushagra Dixit, Vivek Srikumar, Dan Roth, Vivek Gupta

## 揭示数值能力差距：评估大型语言模型基本数值能力的标准。
Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical Abilities in Large Language Models
Haoyang LI, Xuejia Chen, Zhanchao Xu, Darian Li, Nicole HU, Fei Teng, Yiming Li, Luyu QIU, Chen Jason Zhang, Li Qing, Lei Chen

## TABGEN-ICL：基于残差的上下文自举示例选择以生成表格数据。
TABGEN-ICL: Residual-Aware In-Context Example Selection for Tabular Data Generation
Liancheng Fang, Aiwei Liu, Hengrui Zhang, Henry Peng Zou, Weizhi Zhang, Philip S. Yu

## PruneVid：高效的视频大型语言模型视觉标记剪枝
PruneVid: Visual Token Pruning for Efficient Video Large Language Models
Xiaohu Huang, Hao Zhou, Kai Han

## Pro mind--- LLM：基于因果推理与传感器数据的主动心理健康护理。
ProMind-LLM: Proactive Mental Health Care via Causal Reasoning with Sensor Data
Xinzhe Zheng, Sijie JI, Jiawei Sun, Renqi Chen, Wei Gao, Mani Srivastava

## 通过保留偏好特征去偏差的在线偏好学习
Debiasing Online Preference Learning via Preference Feature Preservation
Dongyoung Kim, Jinsung Yoon, Jinwoo Shin, Jaehyung Kim

## 无关紧要，正确答案往往不如平行模式所示——人类与大模型在多项选择题答题表现中的差异。
None of the Above, Less of the Right Parallel Patterns in Human and LLM Performance on Multi-Choice Questions Answering
Zhi Rui Tam, Cheng-Kuang Wu, Chieh-Yen Lin, Yun-Nung Chen

## ShortGPT：大型语言模型中的层比你想象的更有冗余性。
ShortGPT: Layers in Large Language Models are More Redundant Than You Expect
Xin Men, Mingyu Xu, Qingyu Zhang, Qianhao Yuan, Bingning Wang, Hongyu Lin, Yaojie Lu, Xianpei Han, Weipeng Chen

## 多国价值对齐基准测试for大规模语言模型
Benchmarking Multi-National Value Alignment for Large Language Models
Chengyi Ju, Weijie Shi, Chengzhong LIU, Jiaming Ji, Jipeng Zhang, Ruiyuan Zhang, Jiajie Xu, Yaodong Yang, Sirui Han, Yike Guo

## 自信提高大模型的自一致性。
Confidence Improves Self-Consistency in LLMs
Amir Taubenfeld, Tom Sheffer, Eran Ofek, Amir Feder, Ariel Goldstein, Zorik Gekhman, Gal Yona

## 题目：FRAME：通过四象四阶段多阶段预训练策略提升大语言模型。
FRAME: Boosting LLMs with A Four-Quadrant Multi-Stage Pretraining Strategy
Xuemiao Zhang, Feiyu Duan, Xu Liangyu, Yongwei Zhou, Sirui Wang, Rongxiang Weng, Jingang Wang, Xunliang Cai

## 当大型语言模型遇到语音：关于整合方法的综述。
When Large Language Models Meet Speech: A Survey on Integration Approaches
Zhengdong Yang, Shuichiro Shimizu, Yahan Yu, Chenhui Chu

## MotiveBench：我们在多大程度上接近了人类动机推理的大语言模型？
MotiveBench: How Far Are We From Human-Like Motivational Reasoning in Large Language Models?
Xixian Yong, Jianxun Lian, Xiaoyuan Yi, Xiao Zhou, Xing Xie

## 自适应LoRA融合与参数剪枝用于低资源生成。
Adaptive LoRA Merge with Parameter Pruning for Low-Resource Generation
Ryota Miyano, Yuki Arase

## 在对话中寻找丢失的拱门：一个多轮对话的依存对话行为语料库。
In Search of the Lost Arch in Dialogue: A Dependency Dialogue Acts Corpus for Multi-Party Dialogues
Jon Cai, Brendan King, Peyton Cameron, Susan Windisch Brown, Miriam Eckert, Dananjay Srinivas, George Arthur Baker, V Kate Everson, Martha Palmer, James Martin, Jeffrey Flanigan

## InImageTrans：基于多模态LLM的文本图像机器翻译。
InImageTrans: Multimodal LLM-based Text Image Machine Translation
Fei Zuo, Kehai Chen, Yu Zhang, Zhengshan Xue, Min Zhang

## 超越完成：一种通用知识图谱推理的基础模型。
Beyond Completion: A Foundation Model for General Knowledge Graph Reasoning
Yin Hua, Zhiqiang Liu, Mingyang Chen, Zheng Fang, Chi Man Wong, Lingxiao Li, Chi Man VONG, Huajun Chen, Wen Zhang

## KE-MHISTO：针对长尾问题的多语言历史知识提取基准研究。
KE-MHISTO: Towards a Multilingual Historical Knowledge Extraction Benchmark for Addressing the Long-Tail Problem
Arianna Graciotti, Leonardo Piano, Nicolas Lazzari, Enrico Daga, Rocco Tripodi, Valentina Presutti, Livio Pompianu

## TailorKV：一种通过定制化键值缓存优化实现长上下文推理的混合框架。
TailorKV: A Hybrid Framework for Long-Context Inference via Tailored KV Cache Optimization
Dingyu Yao, Bowen Shen, Zheng Lin, Wei Liu, Jian Luan, Bin Wang, Weiping Wang

## ProjectEval：基于项目级别的代码生成自动化评估基准
ProjectEval: A Benchmark for Programming Agents Automated Evaluation on Project-Level Code Generation
Kaiyuan Liu, Youcheng Pan, Yang Xiang, Daojing He, Jing Li, Yexing Du, Tianrun Gao

## 生成模型错误修正：面向情感的语音转文本翻译。
Generative Error Correction for Emotion-aware Speech-to-text Translation
Zhengdong Yang, Sheng Li, Chenhui Chu

## DYNTEXT：面向隐私保护的大语言模型推理的语义意识动态文本净化。
DYNTEXT: Semantic-Aware Dynamic Text Sanitization for Privacy-Preserving LLM Inference
Juhua Zhang, Zhiliang Tian, Minghang Zhu, YIPING SONG, Minlie Huang, Siyi Yang, Qiunan Du, Xinwang Liu, Taishu sheng, Dongsheng Li

## V²R-Bench：全面评估LVLM在基本视觉变化面前的鲁棒性。
V²R-Bench: Holistically Evaluating LVLM Robustness to Fundamental Visual Variations
Zhiyuan Fan, Yumeng Wang, Sandeep Polisetty, Yi R. Fung

## LLM们可以在与离线模式相同的效果下实现高质量的同步机器翻译。
LLMs Can Achieve High-quality Simultaneous Machine Translation as Efficiently as Offline
Biao Fu, Minpeng Liao, Kai Fan, Chengxi Li, Liang Zhang, Yidong Chen, Xiaodong Shi

## 房间里的大象：探究中性词在语言模型无群体偏好去偏见中的作用。
The Elephant in the Room: Exploring the Role of Neutral Words in Language Model Group-Agnostic Debiasing
Xinwei Guo, Jiashi Gao, Junlei Zhou, Jiaxin Zhang, Guanhua Chen, Xiangyu Zhao, Quanying Liu, Haiyan Wu, Xin Yao, Xuetao Wei

## TRATES：基于特质的评标量表辅助跨提示作文评分方法。
TRATES: Trait-Specific Rubric-Assisted Cross-Prompt Essay Scoring
Sohaila Eltanbouly, Salam Albatarni, Tamer Elsayed

## SynapticRAG：通过突触机制增强大型语言模型的 temporal 记忆检索。
SynapticRAG: Enhancing Temporal Memory Retrieval in Large Language Models through Synaptic Mechanisms
Yuki Hou, Haruki Tamoto, Qinghua Zhao, HOMEI MIYASHITA

## EMGLLM：基于医学数值数据编码的 electromyogram 诊断生成的数据到文本对齐方法。
EMGLLM: Data-to-Text Alignment for Electromyogram Diagnosis Generation with Medical Numerical Data Encoding
Zefei Long, Zhenbiao Cao, Wei Chen, zhongyu wei

## 一种用于揭示时间知识图谱中历史模式的多专家结构语义混合框架。
A Multi-Expert Structural-Semantic Hybrid Framework for Unveiling Historical Patterns in Temporal Knowledge Graphs
Yimin Deng, Yuxia Wu, Yejing Wang, Guoshuai Zhao, Li Zhu, Qidong Liu, Derong Xu, Zichuan Fu, Xian Wu, Yefeng Zheng, Xiangyu Zhao, Xueming Qian

## LLMVoX：自回归流式文本到语音模型，适用于任何大型语言模型。
LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM
sambal shikhar, Mohammed Irfan Kurpath, Sahal Shaji Mullappilly, Jean Lahoud, Fahad Shahbaz Khan, Rao Muhammad Anwer, Salman Khan, Hisham Cholakkal

## MWPO：通过多权重偏好强度和长度优化提升大语言模型性能。
MWPO: Enhancing LLMs Performance through Multi-Weight Preference Strength and Length Optimization
Shiyue Xu, Fu Zhang, Jingwei Cheng, Linfeng Zhou

## 语言模型缺乏时间泛化能力，更大并不总是更好。
Language Models Lack Temporal Generalisation and Bigger is Not Better
Stella Verkijk, Piek Vossen, Pia Sommerauer

## 评估大语言模型在基于证据的声称验证情境下的推理能力。
Assessing the Reasoning Capabilities of LLMs in the context of Evidence-based Claim Verification
John Dougrez-Lewis, Mahmud Elahi Akhter, Federico Ruggeri, Sebastian Löbbers, Yulan He, Maria Liakata

## Act2P：由LLM驱动的在线对话行为分类以进行功率分析。
Act2P: LLM-Driven Online Dialogue Act Classification for Power Analysis
Zhangwenbo, Wang yuhan

## DiffLM：通过扩散语言模型实现可控的合成数据生成。
DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models
Ying Zhou, Xinyao Wang, Yulei Niu, Yaojie Shen, Lexin Tang, Fan Chen, Ben He, Le Sun, Longyin Wen

## 将大型语言模型与较小的细调模型在低资源马耳他语NLP中的性能进行基准测试。
Benchmarking Large Language Models against Smaller Fine-Tuned Models for Low-Resource Maltese NLP
Kurt Micallef, Claudia Borg

## 复杂指令遵循中的逆向偏好优化。
Reverse Preference Optimization for Complex Instruction Following
Xiang Huang, Ting-En Lin, Feiteng Fang, Yuchuan Wu, Hangyu Li, Yuzhong Qu, Fei Huang, Yongbin Li

## Def-DTS：开放领域对话主题分割的演绎推理方法
Def-DTS: Deductive Reasoning for Open-domain Dialogue Topic Segmentation
Seungmin Lee, Yongsang Yoo, Minhwa Jung, Min Song

## Verbosity-Aware Rationale Reduction：面向冗余性的解释缩减——高效有效的推理句级解释缩减。
Verbosity-Aware Rationale Reduction: Sentence-Level Rationale Reduction for Efficient and Effective Reasoning
Joonwon Jang, Jaehee Kim, WONBIN KWEON, Seonghyeon Lee, Hwanjo Yu

## 不确定性揭开：更多的上下文示例能否减轻大型语言模型的不确定性？
Uncertainty Unveiled: Can Exposure to More In-context Examples Mitigate Uncertainty for Large Language Models?
Yifei Wang, Yu Sheng, Linjing Li, Daniel Dajun Zeng

## MMS-LLaMA：基于最小多模态语音令牌的高效大语言模型导向的视听语音识别。
MMS-LLaMA: Efficient LLM-based Audio-Visual Speech Recognition with Minimal Multimodal Speech Tokens
Jeong Hun Yeo, Hyeongseop Rha, Se Jin Park, Yong Man Ro

## STORYTELLER：一种增强的故事规划框架，用于生成连贯且具有 cohesion 的故事。
STORYTELLER: An Enhanced Plot-Planning Framework for Coherent and Cohesive Story Generation
Jiaming Li, Yukun Chen, Ziqiang Liu, Minghuan Tan, Lei Zhang, Yunshui Li, Run Luo, Longze Chen, Jing Luo, Ahmadreza Argha, Hamid Alinejad-Rokny, Wei Zhou, Min Yang

## SelectLLM：一种面向查询的大型语言模型高效选择算法。
SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language Models
Kaushal Kumar Maurya, KV Aditya Srivatsa, Ekaterina Kochmar

## 通过意图隐藏与转移探索对LLM的越狱攻击
Exploring Jailbreak Attacks on LLMs through Intent Concealment and Diversion
Tiehan Cui, Yanxu Mao, Peipei Liu, Congying Liu, Datao You

## CLEAR：文本和视觉模态中的字符遗忘。
CLEAR: Character Unlearning in Textual and Visual Modalities
Alexey Dontsov, Dmitrii Korzh, Alexey Zhavoronkin, Boris Mikheev, Denis Bobkov, Aibek Alanov, Oleg Rogov, Ivan Oseledets, Elena Tutubalina

## 基于贝塔策略的提示设计策略选择可改善提示优化器。
Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers
Rin Ashizawa, Yoichi Hirose, Nozomu Yoshinari, Kento Uchida, Shinichi Shirakawa

## PM3-KIE：一种概率多任务元模型的文档关键信息提取方法。
PM3-KIE: A Probabilistic Multi-Task Meta-Model for Document Key Information Extraction
Birgit Kirsch, Héctor Allende-Cid, Stefan Rueping

## 题目：探讨心理健康对话代理在培训医疗学生和专业人员中的作用：一项系统文献综述。
Exploring the Role of Mental Health Conversational Agents in Training Medical Students and Professionals: A Systematic Literature Review
Thushari Atapattu, Menasha Thilakaratne, Duc Nhan Do, Mahen Herath, Katrina E. Falkner

## 解开推理令牌与模板令牌对于语言模型微调的谜团。
Disentangling Reasoning Tokens and Boilerplate Tokens For Language Model Fine-tuning
Ziang Ye, Zhenru Zhang, Yang Zhang, jianxing ma, Junyang Lin, Fuli Feng

## Matina：一种文化对齐的波斯语言模型，采用多个LoRA专家。
Matina: A Culturally-Aligned Persian Language Model Using Multiple LoRA Experts
Sara Bourbour Hosseinbeigi, MohammadAli SeifKashani, Javad seraj, Fatemeh Taherinezhad, Ali Nafisi, Fatemeh Nadi, Iman Barati, Hosein Hasani, Mostafa Amiri, Mostafa Masoudi

## APT：通过弱点案例获取与迭代偏好训练提高专科大语言模型性能。
APT: Improving Specialist LLM Performance with Weakness Case Acquisition and Iterative Preference Training
Jun Rao, Zepeng Lin, Xuebo Liu, Xiaopeng Ke, Lian Lian, Dong Jin, shengjun cheng, Jun Yu, Min Zhang

## SkyLLM：低成本查询处理的跨LLM-API联邦架构。
SkyLLM: Cross-LLM-APIs Federation for Cost-effective Query Processing
Heng Zhao, Yifei Zhu

## G2S：一种基于大型语言模型的时间知识图谱通用到具体的预测学习框架。
G2S: A General-to-Specific Learning Framework for Temporal Knowledge Graph Forecasting with Large Language Models
Long Bai, Zixuan Li, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng, Tat-Seng Chua

## RoleMRC：一个细粒度综合基准，用于角色扮演和指令遵循。
RoleMRC: A Fine-Grained Composite Benchmark for Role-Playing and Instruction-Following
Junru Lu, Jiazheng Li, Guodong Shen, Lin Gui, Siyu An, Yulan He, di yin, Xing Sun

## C²RBench：面向大型语言模型的中文复杂推理基准。
C²RBench: A Chinese Complex Reasoning Benchmark for Large Language Models
Junru Wu, Tianhao Shen, Linxi Su, Deyi Xiong

##  TechniqueRAG：在网络安全威胁 intelligence 文本中对抗技术标注的检索增强生成技术。
TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique Annotation in Cyber Threat Intelligence Text
Ahmed Lekssays, Utsav Shukla, Husrev Taha Sencar, Md Rizwan Parvez

## 通过自主学习解锁大语言模型在领域自适应中的自我改进能力。
Unlocking LLMs’ Self-Improvement Capacity with Autonomous Learning for Domain Adaptation
Ke Ji, Junying Chen, Anningzhe Gao, Wenya Xie, Xiang Wan, Benyou Wang

## 使用多语言领域转换的代码混合仇恨言论词级检测。
Word-Level Detection of Code-Mixed Hate Speech with Multilingual Domain Transfer
Karin Niederreiter, Dagmar Gromann

## 性格特质如何塑造大模型的冒险行为。
How Personality Traits Shape LLM Risk-Taking Behaviour
John Hartley, Conor Brian Hamill, Dale Seddon, Devesh Batra, Ramin Okhrati, Raad Khraishi

## 评估生成器启发式检索增强大型语言模型中的归因偏见。
Evaluation of Attribution Bias in Generator-Informed Retrieval-Augmented Large Language Models
Amin Abolghasemi, Leif Azzopardi, Seyyed Hadi Hashemi, Maarten de Rijke, Suzan Verberne

## 自适应多阈值损失及文档级关系提取中协作损失的一般框架
An Adaptive Multi-Threshold Loss and a General Framework for Collaborating Losses in Document-Level Relation Extraction
Huangming Xu, Fu Zhang, Jingwei Cheng

## 编码错误：上下文内多语言语法错误纠正的表示检索方法。
Encode Errors: Representational Retrieval of In-Context Demonstrations for Multilingual Grammatical Error Correction
Guangyue Peng, Wei Li, Wen Luo, Houfeng Wang

## 输入归因能否解读基于上下文学习中的归纳推理过程？
Can Input Attributions Interpret the Inductive Reasoning Process in In-Context Learning?
Mengyu Ye, Tatsuki Kuribayashi, Goro Kobayashi, Jun Suzuki

## 隐式跨语言奖励优化多语言偏好对齐效率。
Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference Alignment
Wen Yang, Junhong Wu, Chen Wang, Chengqing Zong, Jiajun Zhang

## X-WebAgentBench：一种用于评估全球代理系统的多语言交互式网络基准测试。
X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System
Peng Wang, Ruihan Tao, Qiguang Chen, Mengkang Hu, Libo Qin

## DAST：通过动态分配软令牌实现的LLM上下文感知压缩。
DAST: Context-Aware Compression in LLMs via Dynamic Allocation of Soft Tokens
Shaoshen Chen, Yangning Li, Zishan Xu, Yongqin Zeng, Shunlong Wu, Xinshuo Hu, Zifei Shan, Xin Su, Jiwei Tang, Yinghui Li, Hai-Tao Zheng

## 超越简介：从表面事实到深层人格模拟在LLMs中的应用。
Beyond Profile: From Surface-Level Facts to Deep Persona Simulation in LLMs
Zixiao Wang, Duzhen Zhang, Ishita Agarwal, Shen Gao, Le Song, Xiuying Chen

## 通过自环的双线性注意实现模态依赖解析。
Modal Dependency Parsing via Biaffine Attention with Self-Loop
Jayeol Chun, Nianwen Xue

## 视频RAG：基于视频语料库的检索增强生成。
VideoRAG: Retrieval-Augmented Generation over Video Corpus
Soyeong Jeong, Kangsan Kim, Jinheon Baek, Sung Ju Hwang

## ToolSpectrum：迈向大型语言模型个性化工具使用。
ToolSpectrum: Towards Personalized Tool Utilization for Large Language Models
Zihao Cheng, Hongru WANG, Zeming Liu, Yuhang Guo, Yuanfang Guo, Yunhong Wang, Haifeng Wang

## NOVA：一种通过大型语言模型促进科学研究创新的迭代规划框架。
NOVA: An Iterative Planning Framework for Enhancing Scientific Innovation with Large Language Models
xiang hu, Hongyu Fu, Jinge Wang, Yifeng wang, zhikun li, Renjun Xu, Yu Lu, Yaochu Jin, Lili Pan, Zhenzhong Lan

## EasyEA：知识图谱实体对齐只需大型语言模型。
EasyEA: Large Language Model is All You Need in Entity Alignment Between Knowledge Graphs
Jingwei Cheng, Chenglong Lu, Linyan Yang, Guoqing Chen, Fu Zhang

## 衡量使你独一无二的因素：提升大型语言模型个性化程度的差异意识用户建模。
Measuring What Makes You Unique: Difference-Aware User Modeling for Enhancing LLM Personalization
Yilun Qiu, Xiaoyan Zhao, Yang Zhang, Yimeng Bai, Wenjie Wang, Hong Cheng, Fuli Feng, Tat-Seng Chua

## 协同增强：通过小型模型辅助大型语言模型提升跨域零样本槽填充。
Synergistic Augmentation: Enhancing Cross-Domain Zero-Shot Slot Filling with Small Model-Assisted Large Language Models
Weizhen li, Junbao Huang, Peijie Huang, Yuhong Xu, Jiekun Fan

## 偏好课程学习：LLM 应该始终在其偏好数据上进行预训练。
Preference Curriculum: LLMs Should Always Be Pretrained on Their Preferred Data
Xuemiao Zhang, Xu Liangyu, Feiyu Duan, Yongwei Zhou, Sirui Wang, Rongxiang Weng, Jingang Wang, Xunliang Cai

## 大型语言模型中不确定性估计方法综述。
A Survey of Uncertainty Estimation Methods on Large Language Models
Zhiqiu Xia, JINXUAN XU, Yuqian Zhang, Hang Liu

## 基于证据的医学中自然语言处理的支持：一项范围性回顾。
Natural Language Processing in Support of Evidence-based Medicine: A Scoping Review
Zihan Xu, Haotian Ma, Yihao Ding, Gongbo Zhang, Chunhua Weng, Yifan Peng

## Entriever：基于能量的检索系统，用于知识驱动对话系统。
Entriever: Energy-based Retriever for Knowledge-Grounded Dialog Systems
Yucheng Cai, Ke Li, Yi Huang, Junlan Feng, Zhijian Ou

## 超越单一值指标：评估和增强大语言模型去学习的认知诊断方法。
Beyond Single-Value Metrics: Evaluating and Enhancing LLM Unlearning with Cognitive Diagnosis
Yicheng Lang, Kehan Guo, Yue Huang, Yujun Zhou, Haomin Zhuang, Tianyu Yang, Yao Su, Xiangliang Zhang

## MONTROSE：由大型语言模型驱动的蒙特卡洛树搜索自我优化在跨领域谣言检测中的应用。
MONTROSE: LLM-driven Monte Carlo Tree Search Self-Refinement for Cross-Domain Rumor Detection
Shanshan Liu, Menglong Lu, Zhen Huang, Zejiang He, Liu Liu, Zhigang Sun, Dongsheng Li

## 科学自然语言推理中的不匹配基准（A MISMATCHED基准）
A MISMATCHED Benchmark for Scientific Natural Language Inference
Firoz Shaik, Mobashir Sadat, Nikita Gautam, Doina Caragea, Cornelia Caragea

## MPBench：一个全面的多模态推理基准，用于过程错误识别。
MPBench: A Comprehensive Multimodal Reasoning Benchmark for Process Errors Identification
xu Zhao Pan, Pengfei Zhou, Jiaxin Ai, Wangbo Zhao, Kai Wang, Xiaojiang Peng, Wenqi Shao, Hongxun Yao, Kaipeng Zhang

## TagRouter：通过标签学习路径生成开放域文本任务的大型语言模型路由方法。
TagRouter: Learning Route to LLMs through Tags for Open-Domain Text Generation Tasks
Zhou Chen, Zhiqiang wei, Yuqi Bai, Xue Xiong, Jianmin WU

## PEToolLLM：通往大型语言模型中个性化工具学习的路径。
PEToolLLM: Towards Personalized Tool Learning in Large Language Models
Qiancheng Xu, Yongqi Li, Heming Xia, Fan Liu, Min Yang, Wenjie Li

## 论文标题翻译如下：\n标题：语言模型中的推理-记忆交互是由单向性介导的。
The Reasoning-Memorization Interplay in Language Models Is Mediated by a Single Direction
Yihuai Hong, Meng Cao, Dian Zhou, Lei Yu, Zhijing Jin

## 题目：迈向“小说新标准”基准：使用大型语言模型评估文学小说。
Towards A “Novel” Benchmark: Evaluating Literary Fiction with Large Language Models
Wenqing Wang, Mingqi Gao, Xinyu Hu, Xiaojun Wan

## 《圣经希伯来文手稿 witness 中词级变体的分类器》
A Classifier of Word-Level Variants in Witnesses of Biblical Hebrew Manuscripts
Iglika Nikolova-Stoupak, Maxime Amblard, Sophie Robert-Hayek, Davide D’Amico, Frédérique Rey

## CRAB：跨环境智能体基准测试，针对多模态语言模型智能体。
CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents
Tianqi Xu, Linyao Chen, Dai-Jie Wu, Yanjun Chen, Zecheng Zhang, Xiang Yao, Zhiqiang Xie, Yongchao Chen, Shilong Liu, Bochen Qian, Anjie Yang, Zhaoxuan Jin, Jianbo Deng, Philip Torr, Bernard Ghanem, Guohao Li

## CARE-STaR：约束感知自主推理器
CARE-STaR: Constraint-aware Self-taught Reasoner
Zhiliang Li, Bo Tang, Yijun Niu, Beihong Jin, Qiwen Shi, Yuchen Feng, Zhiyu li, Jie Hu, mingchuan yang, Feiyu Xiong

## 使用链式思维对齐的跨语言立场检测强化学习框架
A Reinforcement Learning Framework for Cross-Lingual Stance Detection Using Chain-of-Thought Alignment
Binghui Li, Minghui Zou, Xiaowang Zhang, Shizhan Chen, Zhiyong Feng

## 重新思考表格指令调优。
Rethinking Table Instruction Tuning
Naihao Deng, Rada Mihalcea

## 论推理质量的重要性：通过选择性推理提炼增强精神疾病检测。
Does Rationale Quality Matter? Enhancing Mental Disorder Detection via Selective Reasoning Distillation
Hoyun Song, Huije Lee, Jisu Shin, Sukmin Cho, Changgeon Ko, Jong C. Park

## 这只是语义问题吗？关于LLM中话语粒子理解的案例研究。
Is It JUST Semantics? A Case Study of Discourse Particle Understanding in LLMs
William Berkeley Sheffield, Kanishka Misra, Valentina Pyatkin, Ashwini Deo, Kyle Mahowald, Junyi Jessy Li

## 诊断大型语言模型回答中的故障：将错误归因纳入评估框架。
Diagnosing Failures in Large Language Models’ Answers: Integrating Error Attribution into Evaluation Framework
Zishan Xu, Shuyi Xie, Qingsong Lv, Shupei Xiao, Linlin Song, Sui Wenjuan, Fan Lin

## 显式贝叶斯推断以揭示大型语言模型中的潜在主题。
Explicit Bayesian Inference to Uncover the Latent Themes of Large Language Models
Raymond Li, Chuyuan Li, Gabriel Murray, Giuseppe Carenini

## Transformer嵌入如何表示组合关系？一项功能分析。
How do Transformer Embeddings Represent Compositions? A Functional Analysis
Aishik Nagar, Ishaan Singh Rawal, Mansi Dhanania, Cheston Tan

## 使用LLM精炼训练数据提高多语言瑞士职位发布的职业ISCO分类。
Improving Occupational ISCO Classification of Multilingual Swiss Job Postings with LLM-Refined Training Data
Ann-Sophie Gnehm, Simon Clematide

## 多模态新闻框架分析
Multi-Modal Framing Analysis of News
Arnav Arora, Srishti Yadav, Maria Antoniak, Serge Belongie, Isabelle Augenstein

## 对抗偏好学习以实现鲁棒的大规模语言模型对齐。
Adversarial Preference Learning for Robust LLM Alignment
Yuanfu Wang, Pengyu Wang, Chenyang Xi, Bo Tang, Junyi Zhu, Wenqiang Wei, chen chen, Chao Yang, Jingfeng Zhang, Chaochao Lu, Yijun Niu, Keming Mao, Zhiyu li, Feiyu Xiong, Jie Hu, mingchuan yang

## READoc：统一的现实文档结构提取基准。
READoc: A Unified Benchmark for Realistic Document Structured Extraction
Zichao Li, Aizier Abulaiti, Yaojie Lu, Xuanang Chen, Jia Zheng, Hongyu Lin, Xianpei Han, Shanshan Jiang, Bin Dong, Le Sun

## 简练即可持续的本质：刻画大规模语言模型的回答长度。
Brevity is the soul of sustainability: Characterizing LLM response lengths
Soham Poddar, Paramita Koley, Janardan Misra, Niloy Ganguly, Saptarshi Ghosh

## Fan\n\nFanChuan：一种用于 parody 检测与分析的多语言和图形结构化基准数据集。
FanChuan: A Multilingual and Graph-Structured Benchmark For Parody Detection and Analysis
Yilun Zheng, Sha Li, Fangkun Wu, Yang Ziyi, Lin Hongchao, Zhichao Hu, Cai Xinjun, Ziming Wang, Jinxuan Chen, Sitao Luan, Jiahao Xu, Lihui Chen

## 思想之战：竞争激发大型语言模型更强的推理能力。
War of Thoughts: Competition Stimulates Stronger Reasoning in Large Language Models
Yibin Chen, YAN ZHENG, Yifu Yuan, Jinyi Liu, Jianye HAO

## CliniDial：一种自然 Emerged 多模态对话数据集，用于临床操作期间的团队反思。
CliniDial: A Naturally Emerged Multimodal Dialogue Dataset for Team Reflection During Clinical Operation
Naihao Deng, Kapotaksha Das, Rada Mihalcea, Vitaliy Popov, Mohamed Abouelenien

## Chumor：向着中文幽默理解benchmark迈进。
Chumor: Towards Benchmarking Chinese Humor Understanding
Ruiqi He, Yushu He, Longju Bai, Jiarui Liu, Zhenjie Sun, Zenghao Tang, He Wang, Hanchen Xia, Rada Mihalcea, Naihao Deng

## TicTac：具有时间意识的监督微调方法以实现自动文本年代学识别。
TicTac: Temporal-aware Supervised Fine-tuning for Automatic Text Dating
Minna Peng, Han Ren

## 海豚：通过异构锚点提示的文档图像解析。
Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting
Hao Feng, Shu Wei, Xiang Fei, Wei Shi, Yingdong Han, Lei Liao, Jinghui Lu, Binghong Wu, Qi Liu, Chunhui Lin, Jingqun Tang, Hao Liu, Can Huang

## 小型编码器可以与大型解码器匹敌，用于检测语境相关性。
Small Encoders Can Rival Large Decoders in Detecting Groundedness
Istabrak Abbes, Gabriele Prato, Quentin Fournier, Fernando Rodriguez, Alaa Boukhary, Adam Elwood, Sarath Chandar

## AL-QASIDA：系统分析方言阿拉伯语中大规模语言模型的质量和准确性。
AL-QASIDA: Analyzing LLM Quality and Accuracy Systematically in Dialectal Arabic
Nathaniel Romney Robinson, Shahd Abdelmoneim, Kelly Marchisio, Sebastian Ruder

## LLMs的人类冒犯感知人口统计学对齐的稳健性与混杂因素。
Robustness and Confounders in the Demographic Alignment of LLMs with Human Perceptions of Offensiveness
Shayan Alipour, Indira Sen, Mattia Samory, Tanu Mitra

## KITAB-Bench：一个全面的多领域基准测试套件，用于阿拉伯OCR和文档理解。
KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding
Ahmed Heakl, Muhammad Abdullah Sohail, Mukul Ranjan, Rania Elbadry, Ghazi Shazan Ahmad, Mohamed El-Geish, Omar Maher, Zhiqiang Shen, Fahad Shahbaz Khan, Salman Khan

## 一种基于模式Seeking偏好对齐的全面图框架用于问答系统。
A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment
Quanwei Tang, Sophia Yat Mei Lee, Junshuang Wu, Dong Zhang, Shoushan Li, Erik Cambria, Guodong Zhou

## 在长段落问答中定位和减轻错误的方法。
Localizing and Mitigating Errors in Long-form Question Answering
Rachneet Singh Sachdeva, Yixiao Song, Mohit Iyyer, Iryna Gurevych

## DynaCode：一种面向代码生成评估的大语言模型动态复杂度aware代码基准。
DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation
Wenhao Hu, Jinhao Duan, Chunchen Wei, Li Zhang, Yue Zhang, Kaidi Xu

## 结构安全性泛化问题
The Structural Safety Generalization Problem
Julius Broomfield, Tom Gibbs, George Ingebretsen, Ethan Kosak-Hine, Tia Nasir, Jason Zhang, Reihaneh Iranmanesh, Sara Pieri, Reihaneh Rabbany, Kellin Pelrine

## P-CoT：一种以教学为导向的参与式思维链提示，用于大型语言模型中的音位推理。
P-CoT: A Pedagogically-motivated Participatory Chain-of-Thought Prompting for Phonological Reasoning in LLMs
Dongjun Jang, Youngchae Ahn, Hyopil Shin

## 依赖模型的中介作用：基于LLM的系统在仇恨言论检测中的不一致性。
Model-Dependent Moderation: Inconsistencies in Hate Speech Detection Across LLM-based Systems
Neil Fasching, Yphtach Lelkes

## 无监督形态树Tokenizer。
Unsupervised Morphological Tree Tokenizer
Qingyang Zhu, Xiang Hu, Pengyu Ji, Wei Wu, Kewei Tu

## 基于启发式搜索算法的自动指令导向提示优化：综述。
Heuristic-based Search Algorithm in Automatic Instruction-focused Prompt Optimization: A Survey
Wendi Cui, Jiaxin Zhang, Zhuohang Li, Hao Sun, Damien Lopez, Kamalika Das, Bradley A. Malin, Sricharan Kumar

## CONSENSAGENT：通过减少奉承以实现多智能体LLM交互中的高效且有效的共识。
CONSENSAGENT: Towards Efficient and Effective Consensus in Multi-Agent LLM Interactions Through Sycophancy Mitigation
Priya Pitre, Naren Ramakrishnan, Xuan Wang

## 一种增强LLM代理工具利用效率的联合优化框架。
A Joint Optimization Framework for Enhancing Efficiency of Tool Utilization in LLM Agents
Bin Wu, Edgar Meij, Emine Yilmaz

## 具有标签语义意识的生成方法，用于领域无关的多标签分类。
Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification
Subhendu Khatuya, Shashwat Naidu, Saptarshi Ghosh, Pawan Goyal, Niloy Ganguly

## DPO内核：一种具有语义意识、核增强和差异丰富的直接偏好优化范式。
DPO Kernels: A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich Paradigm for Direct Preference Optimization
Amitava Das, Suranjana Trivedy, Danush Khanna, Yaswanth Narsupalli, Basab Ghosh, Rajarshi Roy, Gurpreet Singh, Vinija Jain, Vasu Sharma, Aishwarya Naresh Reganti, Aman Chadha

## CausalLink：一个交互式因果推理评估框架。
CausalLink: An Interactive Evaluation Framework for Causal Reasoning
Jinyue Feng, Frank Rudzicz

## 不同的问题表述方式是否会影响大型语言模型在推理任务上的表现？
Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?
Seok Hwan Song, Mohna Chakraborty, Qi Li, Wallapak Tavanapong

## Aria-UI：GUI操作说明的视觉定位
Aria-UI: Visual Grounding for GUI Instructions
Yuhao Yang, Yue Wang, Dongxu Li, Ziyang Luo, Bei Chen, Chao Huang, Junnan Li

## 当索赔演变时：评估并增强嵌入模型抵御误导性编辑的稳健性。
When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding Models Against Misinformation Edits
Jabez Magomere, Emanuele La Malfa, Manuel Tonneau, Ashkan Kazemi, Scott A. Hale

## 迈向全球AI包容性：大规模多语言术语数据集（GIST）
Toward Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset (GIST)
Jiarui Liu, Iman Ouzzani, Wenkai Li, Lechen Zhang, Tianyue Ou, Houda Bouamor, Zhijing Jin, Mona T. Diab

## SignMusketeers：一种高效的多流方法，用于大规模手语翻译。
SignMusketeers: An Efficient Multi-Stream Approach for Sign Language Translation at Scale
Shester Gueuwou, Xiaodan Du, Greg Shakhnarovich, Karen Livescu

## gMBA：基于表达语义的混合布尔-算术去混淆方法，使用Transformer架构。
gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures
Youjeong Roh, Joon-Young Paik, Jingun Kwon, Eun-Sun Cho

## 题目：利用自然语言处理揭示跨境内容审核的隐藏机制。
Revealing Hidden Mechanisms of Cross-Country Content Moderation with Natural Language Processing
Neemesh Yadav, Jiarui Liu, Francesco Ortu, Roya Ensafi, Zhijing Jin, Rada Mihalcea

## MEDEC：临床记录中医疗错误检测与修正基准。
MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes
Asma Ben Abacha, Wen-wai Yim, Yujuan Fu, Zhaoyi Sun, Meliha Yetisgen, Fei Xia, Thomas Lin

## 理解合成数据对文本嵌入模型的影响。
Understanding the Influence of Synthetic Data for Text Embedders
Jacob Mitchell Springer, Vaibhav Adlakha, Siva Reddy, Aditi Raghunathan, Marius Mosbach

## 创设中国文化之镜：一种用于理解中文谐音图表的艺术多模态数据集。
Creating a Lens of Chinese Culture: A Multimodal Dataset for Chinese Pun Rebus Art Understanding
Tuo Zhang, Tiantian Feng, Yibin Ni, Mengqin Cao, Ruying Liu, Kiana Avestimehr, Katharine Butler, Yanjun Weng, Mi Zhang, Shrikanth Narayanan, Salman Avestimehr

## 不要展示，要讲述：利用语言模型的抽象重述来建模文学主题。
Tell, Don’t Show: Leveraging Language Models’ Abstractive Retellings to Model Literary Themes
Li Lucy, Camilla Griffiths, Sarah Levine, Jennifer L Eberhardt, Dorottya Demszky, David Bamman

## BottleHumor：基于信息 bottlenecks 原理的自我启发式幽默解释。
BottleHumor: Self-Informed Humor Explanation using the Information Bottleneck Principle
EunJeong Hwang, Peter West, Vered Shwartz

## 基于大型语言模型的证据驱动反驳生成中的动态知识集成。
Dynamic Knowledge Integration for Evidence-Driven Counter-Argument Generation with Large Language Models
Anar Yeginbergen, Maite Oronoz, Rodrigo Agerri

## 分割非连缀语言以实现更好的分词。
Splintering Nonconcatenative Languages for Better Tokenization
Bar Gazit, Shaltiel Shmidman, Avi Shmidman, Yuval Pinter

## Unilogit：针对大规模语言模型的稳健机器遗忘方法，采用均匀目标自我蒸馏。
Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation
Stefan Vasilev, Christian Herold, Baohao Liao, Seyyed Hadi Hashemi, Shahram Khadivi, Christof Monz

## CausalRAG：将因果图整合到检索增强生成中。
CausalRAG: Integrating Causal Graphs into Retrieval-Augmented Generation
Nengbo Wang, Xiaotian Han, JAGDIP SINGH, Jing Ma, Vipin Chaudhary

## 论文标题翻译如下：\n金融语言模型评估（FLaME）
Financial Language Model Evaluation (FLaME)
Glenn Matlin, Mika Okamoto, Huzaifa Pardawala, Yang Yang, Sudheer Chava

## 解释然后排序：使用大型语言模型的自然语言解释进行神经排序器的尺度校准。
Explain then Rank: Scale Calibration of Neural Rankers Using Natural Language Explanations from LLMs
Puxuan Yu, Daniel Cohen, Hemank Lamba, Joel R. Tetreault, Alejandro Jaimes

## MutantPrompt：在预算限制下对中等规模语言模型进行突变优化的提示优化方法
MutantPrompt: Prompt Optimization via Mutation Under a Budget on Modest-sized LMs
Arijit Nag, Animesh Mukherjee, Niloy Ganguly, Soumen Chakrabarti

## FastDraft：如何训练你的草案。
FastDraft: How to Train Your Draft
Ofir Zafrir, Igor Margulis, Dorin Shteyman, Shira Guskin, Guy Boudoukh

## 通过本体导向干预评估LLM在数学和编程能力方面的能力。
Evaluating LLMs’ Mathematical and Coding Competency through Ontology-guided Interventions
Pengfei Hong, Navonil Majumder, Deepanway Ghosal, Somak Aditya, Rada Mihalcea, Soujanya Poria

## 使用大规模语言模型的归纳语言推理。
Inductive Linguistic Reasoning with Large Language Models
Raghav Ramji, Keshav Ramji

## 点击、输入、重复：关于GUI代理的全面调查。
Click, Type, Repeat: A Comprehensive Survey on GUI Agents
Dang Nguyen, Jian Chen, Yu Wang, Gang Wu, Namyong Park, Zhengmian Hu, Hanjia Lyu, Junda Wu, Ryan Aponte, Yu Xia, Xintong Li, Jing Shi, Hongjie Chen, Viet Dac Lai, Zhouhang Xie, Sungchul Kim, Ruiyi Zhang, Tong Yu, Mehrab Tanjim, Nesreen K. Ahmed, Puneet Mathur, Seunghyun Yoon, Lina Yao, Branislav Kveton, Jihyung Kil, Thien Huu Nguyen, Trung Bui, Tianyi Zhou, Ryan A. Rossi, Franck Dernoncourt

## TabXEval：为什么这是一个糟糕的表格？一个全面的表格评估评价标准。
TabXEval: Why this is a Bad Table? An eXhaustive Rubric for Table Evaluation
Vihang Pancholi, Jainit Sushil Bafna, Tejas Anvekar, Manish Shrivastava, Vivek Gupta

## Metagent-P：具备元认知的神经符号规划代理，适用于开放世界。
Metagent-P: A Neuro-Symbolic Planning Agent with Metacognition for Open Worlds
YanfangZhou, Yuntao Liu, Xiaodong Li, Yongqiang Zhao, Xintong Wang, Jinlong Tian, Zhenyu Li, Xinhai Xu

## 用于学习的令牌，用于取消学习的令牌：通过双功能训练在大型语言模型中减轻成员推理攻击。
Tokens for Learning, Tokens for Unlearning: Mitigating Membership Inference Attacks in Large Language Models via Dual-Purpose Training
Toan Tran, Ruixuan Liu, Li Xiong

## 利用音韵和部首级图形表示法以理解古汉语。
Exploiting Phonetics and Glyph Representation at Radical-level for Classical Chinese Understanding
Junyi Xiang, Maofu Liu

## 审慎验证：依赖不完美事实度量指标的风险。
Verify with Caution: The Pitfalls of Relying on Imperfect Factuality Metrics
Ameya Godbole, Robin Jia

## Q-STRUM 辩论：基于查询的对比总结推荐比较。
Q-STRUM Debate: Query-Driven Contrastive Summarization for Recommendation Comparison
George-Kirollos Saad, Scott Sanner

## 从交互多主题协作中预测筛查访谈中的抑郁症状。
Predicting Depression in Screening Interviews from Interactive Multi-Theme Collaboration
Xianbing Zhao, Yiqing Lyu, Di Wang, Buzhou Tang

## LADDER：基于语言指导的切片发现与视觉分类器错误修正。
LADDER: Language-Driven Slice Discovery and Error Rectification in Vision Classifiers
Shantanu Ghosh, Rayan Syed, Chenyu Wang, Vaibhav Choudhary, Binxu Li, Clare B Poynton, Shyam Visweswaran, kayhan Batmanghelich

## 朝向LLM的安全推理：AI代理性的推理以创建嵌入政策的CoT数据。
Towards Safety Reasoning in LLMs: AI-agentic Deliberation for Policy-embedded CoT Data Creation
Tharindu Kumarage, Ninareh Mehrabi, Anil Ramakrishna, Xinyan Zhao, Richard Zemel, Kai-Wei Chang, Aram Galstyan, Rahul Gupta, Charith Peris

## 你的语言模型可能思考得太 entrenched：通过增强对称性训练实现推理一致性。
Your Language Model May Think Too Rigidly: Achieving Reasoning Consistency with Symmetry-Enhanced Training
Yihang Yao, Zhepeng Cen, Miao Li, William Han, Yuyou Zhang, Emerson Liu, Zuxin Liu, Chuang Gan, Ding Zhao

## UniT：一份文档，多次修订，编辑意图分类繁多。
UniT: One Document, Many Revisions, Too Many Edit Intention Taxonomies
Fangping Lan, Abdullah Aljebreen, Eduard Dragut

## 超越指令调节，MoTE：任务专家混合的多任务嵌入模型。
Beyond instruction-conditioning, MoTE: Mixture of Task Experts for Multi-task Embedding Models
Miguel Romero Calvo, Shuoyang Ding, Corey D Barrett, Georgiana Dinu, George Karypis

## Just KIDDIN’：知识注入与蒸馏以检测不雅梗图。
Just KIDDIN’ : Knowledge Infusion and Distillation for Detection of INdecent Memes
Rahul Garg, Trilok Padhi, Hemang Jain, Ugur Kursuncu, Ponnurangam Kumaraguru

## TritonBench：评估大型语言模型生成Triton操作能力的基准测试工具。
TritonBench: Benchmarking Large Language Model Capabilities for Generating Triton Operators
jianling li, ShangZhan Li, Zhenye Gao, Qi Shi, Yuxuan Li, Zefan Wang, Jiacheng Huang, WangHaojie, Jianrong Wang, Xu Han, Zhiyuan Liu, Maosong Sun

## 在医疗文本摘要中LLM评估：高OOV设置中词汇适应的作用。
Evaluation of LLMs in Medical Text Summarization: The Role of Vocabulary Adaptation in High OOV Settings
Gunjan Balde, Soumyadeep Roy, Mainack Mondal, Niloy Ganguly

## 关于ASR指标的稳健近似方法
On the Robust Approximation of ASR Metrics
Abdul Waheed, Hanin atwany, Rita Singh, Bhiksha Raj

## GSQ-Tuning：为LLMs设备端微调进行全面量化训练中的组共享指数整数调整htubloom
GSQ-Tuning: Group-Shared Exponents Integer in Fully Quantized Training for LLMs On-Device Fine-tuning
Sifan Zhou, Shuo Wang, Zhihang Yuan, Mingjia Shi, Yuzhang Shang, Dawei Yang

## AnnaAgent：具备多时会记忆的动态进化智能体系统，真实的寻求者模拟。
AnnaAgent: Dynamic Evolution Agent Systerm with Multi-Session Memory for Realistic Seeker Simulation
Ming Wang, Peidong Wang, Lin Wu, Xiaocui Yang, Daling Wang, Shi Feng, Yuxin Chen, Bixuan Wang, Yifei Zhang

## 迷失于转录，发现于分布偏移：揭开语音基础模型中幻觉的奥秘。
Lost in Transcription, Found in Distribution Shift: Demystifying Hallucination in Speech Foundation Models
Hanin atwany, Abdul Waheed, Rita Singh, Monojit Choudhury, Bhiksha Raj

## LLM代理中的动态人格：囚徒困境中演化建模与行为分析的框架
Dynamic Personality in LLM Agents: A Framework for Evolutionary Modeling and Behavioral Analysis in the Prisoner’s Dilemma
Weiqi Zeng, Bo Wang, Dongming Zhao, Zongfeng Qu, Ruifang He, Yuexian Hou, Qinghua Hu

## M2PA：受认知理论启发的开放世界多记忆规划代理。
M2PA: A Multi-Memory Planning Agent for Open Worlds Inspired by Cognitive Theory
YanfangZhou, Xiaodong Li, Yuntao Liu, Yongqiang Zhao, Xintong Wang, Zhenyu Li, Jinlong Tian, Xinhai Xu

## 运行之前先思考！通过全面探索与优化精炼进行高效代码生成。
Thinking Before Running! Efficient Code Generation with Thorough Exploration and Optimal Refinement
Xiaoqing Zhang, Yuhan Liu, Flood Sung, Xiuying Chen, Shuo Shang, Rui Yan

## 一次编辑，随处更新：一种简单的跨语言知识同步框架在大语言模型中的应用。
Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs
Yuchen Wu, Liang Ding, Li Shen, Dacheng Tao

## SafeChain：具有长链思考推理能力的语言模型的安全性。
SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities
Fengqing Jiang, Zhangchen Xu, Yuetai Li, Luyao Niu, Zhen Xiang, Bo Li, Bill Yuchen Lin, Radha Poovendran

## 大语言模型也能做得很好！通过大语言模型打破语义角色标注的壁垒。
LLMs Can Also Do Well! Breaking Barriers in Semantic Role Labeling via Large Language Models
Xinxin Li, Huiyao Chen, Chengjun Liu, Jing Li, Meishan Zhang, Jun Yu, Min Zhang

## 查询驱动的多模态GraphRAG：在线推理中的动态局部知识图构建。
Query-Driven Multimodal GraphRAG: Dynamic Local Knowledge Graph Construction for Online Reasoning
Chenyang Bu, Guojie Chang, zihao chen, CunYuan Dang, Zhize Wu, Yi He, Xindong Wu

## LegoMT2：选择性异步分片数据并行训练大规模神经机器翻译。
LegoMT2: Selective Asynchronous Sharded Data Parallel Training for Massive Neural Machine Translation
Fei Yuan, Yinquan Lu, Lei Li, Jingjing Xu

## 多样化促进语言模型对未见语义指令的泛化能力。
Diversification Catalyzes Language Models’ Instruction Generalization To Unseen Semantics
Dylan Zhang, Justin Wang, Francois Charton

## 知识压制定律：理解、预测和防止大语言模型幻觉的途径。
The Law of Knowledge Overshadowing: Towards Understanding, Predicting and Preventing LLM Hallucination
Yuji Zhang, Sha Li, Cheng Qian, Jiateng Liu, Pengfei Yu, Chi Han, Yi R. Fung, Kathleen McKeown, ChengXiang Zhai, Manling Li, Heng Ji

## EQS：统一实体-查询-句子对比学习方法用于多模态时间知识图谱完成。
EQS: Unified Entity-Query-Sentence Contrastive Learning for Multimodal Temporal Knowledge Graph Completion
Ying Zhang, Li Zhang, Yu Zhao, Baohang Zhou, Xinying Qian, Xuhui Sui, Kehui Song

## 在数据稀缺情况下，构建一个比GPT-4o优秀的64%的证明导向型程序员。
Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarcity
Dylan Zhang, Justin Wang, Tianran Sun

## 忽视背景信息：评估大型语言模型对索引词元素的理解能力。
Un-considering Contextual Information: Assessing LLMs’ Understanding of Indexical Elements
Metehan Oğuz, Yavuz Faruk Bakman, Duygu Nur Yaldiz

## 行为差距：评估零样本LLM代理在复杂任务导向对话中的表现。
The Behavior Gap: Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs
Avinash Baidya, Kamalika Das, Xiang Gao

## ETRQA：评估大型语言模型事件时间推理能力的综合性基准。
ETRQA: A Comprehensive Benchmark for Evaluating Event Temporal Reasoning Abilities of Large Language Models
Sigang Luo, Yinan Liu, Dongying Lin, Yingying Zhai, Bin Wang, Xiaochun Yang, Junpeng Liu

## 增强文本与图像多模态一致性与连贯性以生成计划。
Enhance Multimodal Consistency and Coherence for Text-Image Plan Generation
Xiaoxin Lu, Ranran Haoran Zhang, Yusen Zhang, Rui Zhang

## 阴陽-对\n在.yang-Align：一个内容基准，用于竞争\n比较不同目标，并介绍引入多\n多目标多重目标偏好文本到\n至图像对\n
YinYang-Align: A new Benchmark for Competing Objectives and Introducing Multi-Objective Preference based Text-to-Image Alignment
Amitava Das, Yaswanth Narsupalli, Gurpreet Singh, Vinija Jain, Vasu Sharma, Suranjana Trivedy, Aman Chadha, Amit Sheth

## 将大语言模型作为有效的流处理处理器：通过组位置编码弥合流式处理与批处理之间的差异。
LLM as Effective Streaming Processor: Bridging Streaming-Batch Mismatches with Group Position Encoding
Junlong Tong, Jinlan Fu, Zixuan Lin, Yingqi Fan, Anhao Zhao, Hui Su, Xiaoyu Shen

## 大型语言模型中的信息显著性行为分析
Behavioral Analysis of Information Salience in Large Language Models
Jan Trienes, Jörg Schlötterer, Junyi Jessy Li, Christin Seifert

## REPRO-Bench：AI代理能评估社会科学论文的可重复性吗？
REPRO-Bench: Can AI Agents Assess the Reproducibility of Social Science Papers?
Chuxuan Hu, Liyun Zhang, Yeji Lim, Aum Wadhwani, Austin Peters, Daniel Kang

## FREE：快速且稳健的视觉语言模型与早期退出。
FREE: Fast and Robust Vision Language Models with Early Exits
Divya Jyoti Bajpai, Manjesh Kumar Hanawal

## DecompileBench：一种全面的基准测试，用于评估实际应用场景中的反汇编器。
DecompileBench: A Comprehensive Benchmark for Evaluating Decompilers in Real-World Scenarios
Zeyu Gao, Yuxin Cui, Hao Wang, Siliang Qin, Yuanda Wang, Zhang Bolun, Chao Zhang

## 揭示并解决大型语言模型中的伪遗忘问题。
Unveiling and Addressing Pseudo Forgetting in Large Language Models
Huashan Sun, Yizhe Yang, Yinghao Li, Jiawei Li, Yang Gao

## HG-InsightLog：用于非自然语言构造日志数据的背景优先级确定与减少方法。
HG-InsightLog: Context Prioritization and Reduction for Question Answering with Non-Natural Language Construct Log Data
Supriya Bajpai, Athira Gopal, Chandrakant Harjpal, Niraj Kumar

## 使用大规模语言模型和形态学规则的方言规范化方法。
Dialect Normalization using Large Language Models and Morphological Rules
Antonios Dimakis, John Pavlopoulos, Antonios Anastasopoulos

## 任务维度学习：一种结构化的提示优化方法。
Task Facet Learning: A Structured Approach To Prompt Optimization
Gurusha Juneja, Gautam Jajoo, Hua Li, Jian Jiao, Nagarajan Natarajan, Amit Sharma

## 将通用大型语言模型精简为定制专家模型
Pruning General Large Language Models into Customized Expert Models
Yiran Zhao, Guizhen Chen, Kenji Kawaguchi, Lidong Bing, Wenxuan Zhang

## 学习插入[PAUSE]标记以提高推理能力。
Learning to Insert [PAUSE] Tokens for Better Reasoning
Eunki Kim, Sangryul Kim, James Thorne

## 论文标题翻译：EventRAG：超图上的事件检索支持，用于未来预测。
EventRAG: Supportive Event Retrieval on Hypergraph for Future Forecasting
Zhengwei Tao, Zhi Jin, pu wu, Xiaoying Bai, Haiyan Zhao, Jia Li, Xiancai Chen, Linyu Li, Chongyang Tao

## 理解涵义：学习进行实用理解的思维。
Understand the Implication: Learning to Think for Pragmatic Understanding
Settaluri Lakshmi Sravanthi, Kishan Maharaj, Sravani Gunnu, Abhijit Mishra, Pushpak Bhattacharyya

## 大型语言模型推理中的知识图谱反思
Reflection on Knowledge Graph for Large Language Models Reasoning
Yigeng Zhou, Wu Li, Yifan Lu, Jing Li, Fangming Liu, Meishan Zhang, Yequan Wang, Daojing He, Honghai LIU, Min Zhang

## 通过同步自我审查其OCR能力以提高MLLM的文档图像机器翻译效果。
Improving MLLM’s Document Image Machine Translation via Synchronously Self-reviewing Its OCR Proficiency
Yupu Liang, Yaping Zhang, Zhiyang Zhang, Zhiyuan Chen, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou

## 重新审视3D LLM基准：我们真的在测试3D能力吗？
Revisiting 3D LLM Benchmarks: Are We Really Testing 3D Capabilities?
Jiahe Jin, Yanheng He, Mingyan Yang

## USDC：一种用户立场与固执在长对话中的数据集。
USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations
Mounika Marreddy, SUBBA REDDY OOTA, Venkata Charan Chinni, Manish Gupta, Lucie Flek

## 基于数量比较意图的密集检索。
Dense Retrieval with Quantity Comparison Intent
Prayas Agrawal, Nandeesh Kumar K M, Muthusamy Chelliah, Surender Kumar, Soumen Chakrabarti

## 大语言模型的价值是否结构上与人类对齐？一个因果视角。
Are the Values of LLMs Structurally Aligned with Humans? A Causal Perspective
Yipeng Kang, Junqi Wang, Yexin Li, Mengmeng Wang, Wenming Tu, Quansen Wang, Hengli Li, Tingjun Wu, Xue Feng, Fangwei Zhong, Zilong Zheng

## 迈向结构化知识推理：基于对比检索的生成体验方法。
Toward Structured Knowledge Reasoning: Contrastive Retrieval-Augmented Generation on Experience
Jiawei Gu, Ziting Xian, Yuanzhen Xie, Ye Liu, Enjie Liu, Ruichao Zhong, Mochi Gao, Yunzhi Tan, Bo Hu, Zang Li

## DIESEL - 动态推理引导通过逃避语义嵌入在大语言模型中的干扰。
DIESEL - Dynamic Inference-Guidance via Evasion of Semantic Embeddings in LLMs
Ben Ganon, Alon Zolfi, Omer Hofman, Inderjeet Singh, Hisashi Kojima, Yuval Elovici, Asaf Shabtai

## iMOVE：实例动作感知视频理解。
iMOVE : Instance-Motion-Aware Video Understanding
Jiaze Li, Yaya Shi, Zongyang Ma, Haoran Xu, cheng.feng, Huihui Xiao, Ruiwen Kang, Fan Yang, Tingting Gao, Di ZHANG

## STORM-BORN：一种通过人类介入多智能体框架精心编纂的具有挑战性的数学推导数据集。
STORM-BORN: A Challenging Mathematical Derivations Dataset Curated via a Human-in-the-Loop Multi-Agent Framework
Wenhao Liu, Zhenyi Lu, Xinyu Hu, Jerry Zhang, Dailin Li, Jiacheng Cen, Huilin Cao, Haiteng Wang, Yuhan Li, XIE KUN, Dandan Li, Pei Zhang, Chengbo Zhang, Yuxiang Ren, Xiaohong Huang, Yan Ma

## JsonTuning：朝向通用、稳健且可控的指令调优。
JsonTuning: Towards Generalizable, Robust, and Controllable Instruction Tuning
Chang Gao, Wenxuan Zhang, Guizhen Chen, Wai Lam

## SceneGram：在场景中概念化和描述七巧板。
SceneGram: Conceptualizing and Describing Tangrams in Scene Context
Simeon Junker, Sina Zarrieß

## MERIT：多-agent 协作的无监督时间序列表示学习。
MERIT: Multi-Agent Collaboration for Unsupervised Time Series Representation Learning
Shu Zhou, Yunyang Xuan, Yuxuan Ao, Xin Wang, Tao Fan, Hao Wang

## RAND：通过冗余意识噪声防御打破对抗同步在变压器中的影响。
RAND: Disrupting Adversarial Synchronization in Transformers via Redundancy-Aware Noise Defense
Lian Duan, Hanzhang Wang, Yuchun Fang

## KaFT：增强大模型领域特定问题回答性能的知识辅助微调
KaFT: Knowledge-aware Fine-tuning for Boosting LLMs’ Domain-specific Question-Answering Performance
Qihuang Zhong, Liang Ding, Xiantao Cai, Juhua Liu, Bo Du, Dacheng Tao

## PodAgent：全方位播客生成框架。
PodAgent: A Comprehensive Framework for Podcast Generation
Yujia Xiao, Lei He, Haohan Guo, Feng-Long Xie, Tan Lee

## 基于记忆增强查询重构的LLM知识图谱推理方法
Memory-augmented Query Reconstruction for LLM-based Knowledge Graph Reasoning
Mufan Xu, Gewen Liang, Kehai Chen, wei wang, Xun Zhou, Muyun Yang, Tiejun Zhao, Min Zhang

## 多模态大型语言模型在简单的参考解析任务中是否具备实用性的倾听能力？
Are Multimodal Large Language Models Pragmatically Competent Listeners in Simple Reference Resolution Tasks?
Simeon Junker, Manar Ali, Larissa Koch, Sina Zarrieß, Hendrik Buschmeier

## 大型语言模型生成数据的来源归因。
Source Attribution for Large Language Model-Generated Data
Xinyang Lu, Jingtan Wang, Zitong Zhao, Zhongxiang Dai, Chuan-Sheng Foo, See-Kiong Ng, Bryan Kian Hsiang Low

## RedundancyLens：揭示并利用视觉令牌处理的冗余性以实现高效的仅解码器大规模语言模型。
RedundancyLens: Revealing and Exploiting Visual Token Processing Redundancy for Efficient Decoder-Only MLLMs
Hongliang Li, Jiaxin Zhang, Wenhui Liao, Dezhi Peng, Kai Ding, Lianwen Jin

## 用于多样化最佳选择优化的结构化剪枝。
Structured Pruning for Diverse Best-of-$N$ Reasoning Optimization
Hieu Trung Nguyen, Bao Nguyen, Viet Anh Nguyen

## 潜在分布解耦以实现不确定感知的多模态多标签情绪识别。
Latent Distribution Decouple for Uncertain-Aware Multimodal Multi-label Emotion Recognition
Jingwang Huang, Jiang Zhong, Qin Lei, gaojinpeng, ymyang, Sirui Wang, PeiguangLi, kaiwen wei

## LLMs是理性投资者吗？关于LLMs中的财务偏向的研究。
Are LLMs Rational Investors? A Study on the Financial Bias in LLMs
Yuhang Zhou, Yuchen Ni, Zhiheng Xi, Zhangyue Yin, Yu He, Gan Yunhui, Xiang Liu, Zhang Jian, Sen Liu, Xipeng Qiu, Yixin Cao, Guangnan Ye, Hongfeng Chai

## 反驳两种常见的关于LLM认知的反通胀立场。
A rebuttal of two common deflationary stances against LLM cognition
Zak Hussain, Rui Mata, Dirk U. Wulff

## 通信高效的张量化 federated 细粒度调优大型语言模型
Communication-Efficient and Tensorized Federated Fine-Tuning of Large Language Models
Sajjad Ghiasvand, Yifan Yang, Zhiyu Xue, Mahnoosh Alizadeh, Zheng Zhang, Ramtin Pedarsani

## 相关还是随机：大型语言模型真的能进行类比推理吗？
Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?
Chengwei Qin, Wenhan Xia, Tan Wang, Fangkai Jiao, Yuchen Hu, Bosheng Ding, Ruirui Chen, Shafiq Joty

## 大型语言模型反映了人们的态度吗？关于大型语言模型人口代表性的一项系统文献综述。
Do Large Language Models Represent the People? A Systematic Literature Review on the Demographic Representativeness of Large Language Models
Indira Sen, Marlene Lutz, Elisa Rogers, David Garcia, Markus Strohmaier

## 时间旅行：一个全面的基准评估LMMs在历史和文化艺术品上的表现。
Time Travel: A Comprehensive Benchmark to Evaluate LMMs on Historical and Cultural Artifacts
Sara Ghaboura, Ketan Pravin More, Ritesh Thawkar, Wafa Al Ghallabi, Omkar Thawakar, Fahad Shahbaz Khan, Hisham Cholakkal, Salman Khan, Rao Muhammad Anwer

## 情绪真的会影响论点的说服力吗？基于LLM的动态检测方法探究。
Do Emotions Really Affect Argument Convincingness? A Dynamic Approach with LLM-based Manipulation Checks
Yanran Chen, Steffen Eger

## LlamaV-o1：重新思考LLMs中的逐步视觉推理。
LlamaV-o1: Rethinking Step-by-step Visual Reasoning in LLMs
Omkar Thawakar, Dinura Dissanayake, Ketan Pravin More, Ritesh Thawkar, Ahmed Heakl, Noor Ahsan, Yuhao Li, Ilmuz Zaman Mohammed Zumri, Jean Lahoud, Rao Muhammad Anwer, Hisham Cholakkal, Ivan Laptev, Mubarak Shah, Fahad Shahbaz Khan, Salman Khan

## 从人类反馈中去除强化学习中的提示模板偏差。
Removing Prompt-template Bias in Reinforcement Learning from Human Feedback
Chaojie Wang, Haonan shi, Long Tian, Bo An, Shuicheng YAN

## MOSAIC：多位观察者识别AI内容
MOSAIC: Multiple Observers Spotting AI Content
Matthieu Dubois, François Yvon, Pablo Piantanida

## 只读勿删：多模态大型语言模型真是捕获了图像序列中的事件顺序吗？
Burn After Reading: Do Multimodal Large Language Models Truly Capture Order of Events in Image Sequences?
Yingjin Song, Yupei Du, Denis Paperno, Albert Gatt

## COVER：面向上下文的过拒绝验证在大语言模型中
COVER: Context-Driven Over-Refusal Verification in LLMs
Giovanni Sullutrone, Riccardo A. Vigliermo, Sonia Bergamaschi, Luca Sala

## 感知语义的提示以实现通告到飞机人员的翻译。
Semantics-aware prompting for translating NOtices To AirMen
Minal Nitin Dani, Aishwarya Maheswaran, Maunendra Sankar Desarkar

## SCOPE：压缩数学推理步骤以实现高效自动过程标注。
SCOPE: Compress Mathematical Reasoning Steps for Efficient Automated Process Annotation
Huimin Xu, Xin Mao, Feng-Lin Li, Xiaobao Wu, WANG CHEN, Wei Zhang, Anh Tuan Luu

## 看见什么很好吃：在十亿参数时代重新审视多模态分布语义学。
Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era
Dan Oneata, Desmond Elliott, Stella Frank

## 全步骤增强偏好优化：具有逐步奖励的自我监督数学推理偏好优化。
Full-Step-DPO: Self-Supervised Preference Optimization with Step-wise Rewards for Mathematical Reasoning
Huimin Xu, Xin Mao, Feng-Lin Li, Xiaobao Wu, WANG CHEN, Wei Zhang, Anh Tuan Luu

## GUIDEX：引导合成数据生成用于零样本信息提取。
GUIDEX: Guided Synthetic Data Generation for Zero-Shot Information Extraction
Neil De La Fuente, Oscar Sainz, Iker García-Ferrero, Eneko Agirre

## 面向二外或外语学习者的组成句义银行英语学习资源。
Compositional Syntactico-SemBanking for English as a Second or Foreign Language
Wenxi Li, Xihao Wang, Weiwei Sun

## 自动生成叙事discourse主要概念用于失语症评估。
Automated main concept generation for narrative discourse assessment in aphasia
Ankita Gupta, Marisa Hudspeth, Jacquie Kurland, Brendan O’Connor

## FINECITE：一种细粒度引用上下文分析的新方法。
FINECITE: A Novel Approach on Fine-Grained Citation Context Analysis
Lasse M. Jantsch, Dong-Jae Koh, Seonghwan Yoon, Jisu Lee, Anne Lauscher, Young-Kyoon Suh

## 解耦推理和知识注入以实现上下文编辑。
Decoupling Reasoning and Knowledge Injection for In-Context Editing
Changyue Wang, Weihang Su, Qingyao Ai, Yujia Zhou, Yiqun LIU

## 检索模型并不懂工具：评估大型语言模型的工具检索能力。
Retrieval Models Aren’t Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models
Zhengliang Shi, Yuhan Wang, Lingyong Yan, Pengjie Ren, Shuaiqiang Wang, Dawei Yin, Zhaochun Ren

## 基于迭代修复的方法在知识库问答中实现少样本迁移，考虑不可回答性。
An Iterative Repair Approach for Few-shot Transfer in KBQA with Unanswerability
Riya Sawhney, Samrat Yadav, Indrajit Bhattacharya, Mausam

## EnSToM：通过熵缩放引导向量提升对话系统的话题维持能力
EnSToM: Enhancing Dialogue Systems with Entropy-Scaled Steering Vectors for Topic Maintenance
Heejae Suh, Yejin Jeon, Deokhyung Kang, Taehee Park, Yejin Min, Gary Lee

## 通过推理时缩放和循环验证的工具学习。
Tool learning via Inference-time Scaling and Cycle Verifier
xiaobo liang, Wenjin Xie, Juntao Li, Wanfu Wang, Yibin Chen, Kehai Chen, Min Zhang

## 刻板印象还是个性化？用户身份偏见对聊天机器人推荐的影响。
Stereotype or Personalization? User Identity Biases Chatbot Recommendations
Anjali Kantharuban, Jeremiah Milbauer, Maarten Sap, Emma Strubell, Graham Neubig

## Entrospect：基于信息论的自我反思促进小型语言模型响应优化。
Entrospect: Information-Theoretic Self-Reflection Elicits Better Response Refinement of Small Language Models
Tianqiang Yan, Ziqiao Lin, Zhenglong Sun, Lin Zhang, Yuan Gao

## MultiTEND：一种多语言NoSQL查询翻译基准。
MultiTEND: A Multilingual Benchmark for Natural Language to NoSQL Query Translation
Zhiqian Qin, Yuanfeng SONG, Jinwei Lu, Yuanwei SONG, Shuaimin Li, Chen Jason Zhang

## VLMs 真的具备视觉和阅读能力吗？关于视觉语言模型中模态崩溃现象的综述。
Can VLMs Actually See and Read? A Survey on Modality Collapse in Vision-Language Models
Mong Yuan Sim, Wei Emma Zhang, Xiang Dai, Biaoyan Fang

## 基于人物混合的语言模型在人口模拟中的应用。
Mixture-of-Personas Language Models for Population Simulation
Ngoc Bui, Hieu Trung Nguyen, Shantanu Kumar, Julian Theodore, Weikang Qiu, Viet Anh Nguyen, Rex Ying

## “你很美丽，体型刻板印象很丑陋！”BIStereo：衡量语言模型中体型刻板印象的标准基准。
“You are Beautiful, Body Image Stereotypes are Ugly!” BIStereo: A Benchmark to Measure Body Image Stereotypes in Language Models
Narjis Asad, Nihar Ranjan Sahoo, Rudra Murthy, Swaprava Nath, Pushpak Bhattacharyya

## 使用GMTP保护RAG管道：一种基于梯度的遮蔽词概率方法用于受污染文档检测。
Safeguarding RAG Pipelines with GMTP: A Gradient-based Masked Token Probability Method for Poisoned Document Detection
San Kim, Jonghwi Kim, Yejin Jeon, Gary Lee

## 基于重新排练的生成方法用于无偏视角总结。
Reranking-based Generation for Unbiased Perspective Summarization
Narutatsu Ri, Nicholas Deas, Kathleen McKeown

## 面向方面的情感摘要分解
Aspect-Aware Decomposition for Opinion Summarization
Miao Li, Jey Han Lau, Eduard Hovy, Mirella Lapata

## KARPA：一种无需训练的方法，将知识图谱作为大型语言模型推理路径聚合的参考。
KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model’s Reasoning Path Aggregation
Siyuan Fang, Kaijing Ma, Tianyu Zheng, Xeron Du, Ningxuan Lu, Ge Zhang, Qingkun Tang

## ClusComp：一种简单的模型压缩和高效微调范式。
ClusComp: A Simple Paradigm for Model Compression and Efficient Finetuning
Baohao Liao, Christian Herold, Seyyed Hadi Hashemi, Stefan Vasilev, Shahram Khadivi, Christof Monz

## 考虑Token预算的LLM推理。
Token-Budget-Aware LLM Reasoning
Tingxu Han, Zhenting Wang, Chunrong Fang, Shiyu Zhao, Shiqing Ma, Zhenyu Chen

## MAGI：多代理引导访谈在精神评估中的应用。
MAGI: Multi-Agent Guided Interview for Psychiatric Assessment
Guanqun Bi, Zhuang Chen, Zhoufu Liu, Hongkai Wang, Xiyao Xiao, Yuqiang Xie, Wen Zhang, Yongkang Huang, Yuxuan Chen, Libiao Peng, Minlie Huang

##  LIST：线性增量SQL翻译器，用于单跳推理、生成和验证。
LIST: Linearly Incremental SQL Translator for Single-Hop Reasoning, Generation and Verification
Kaiyuan Guan, Ruoxin Li, Xudong Guo, Zhenning Huang, Xudong Weng, Hehuan Liu, Zheng Wei, Zang Li

## 当基准说话时：通过互动反馈重新评估代码LLM。
When Benchmarks Talk: Re-Evaluating Code LLMs with Interactive Feedback
Jane Pan, Ryan Shar, Jacob Pfau, Ameet Talwalkar, He He, Valerie Chen

## 在需要时回答，在不需要时遗忘：语言模型通过内在知识遗忘假装遗忘。
Answer When Needed, Forget When Not: Language Models Pretend to Forget via In-Context Knowledge Unlearning
Shota Takashiro, Takeshi Kojima, Andrew Gambardella, Qi Cao, Yusuke Iwasawa, Yutaka Matsuo

## WikiMixQA：一个基于表格和图表的多模态问答基准数据集。
WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts
Negar Foroutan, Angelika Romanou, Matin Ansaripour, Julian Martin Eisenschlos, Karl Aberer, Rémi Lebret

## 利用元毒知识图谱增强基于LLM的仇恨和毒性检测。
Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph
Yibo Zhao, Jiapeng Zhu, Can Xu, Yao Liu, Xiang Li

## HATA：可训练且硬件高效的数据感知Top-$k$ 注意力，用于可扩展的大模型推理。
HATA: Trainable and Hardware-Efficient Hash-Aware Top-$k$ Attention for Scalable Large Model Inference
Ping Gong, Jiawei Yi, Shengnan Wang, Juncheng Zhang, Zewen Jin, Ouxiang Zhou, Ruibo Liu, Guanbin Xu, Youhui Bai, Bowen Ye, Kun Yuan, Tong Yang, Gong Zhang, Renhai Chen, Feng Wu, Cheng Li

## LegalCore：一个用于法律文件事件共指解析的数据集。
LegalCore: A Dataset for Event Coreference Resolution in Legal Documents
Kangda Wei, Xi Shi, Jonathan Tong, Sai Ramana Reddy, Anandhavelu Natarajan, Rajiv Jain, Aparna Garimella, Ruihong Huang

## TituLLMs：一套全面基准测试的孟加拉语大型语言模型系列。
TituLLMs: A Family of Bangla LLMs with Comprehensive Benchmarking
Shahriar Kabir Nahin, Rabindra Nath Nandi, Sagor Sarker, Quazi Sarwar Muhtaseem, Md Kowsher, Apu Chandraw Shill, Md Ibrahim, Mehadi Hasan Menon, Tareq Al Muntasir, Firoj Alam

## 让我们一步步融合：代际融合解码算法与大语言模型结合以提高语音识别和文本图像识别。
Let’s Fuse Step by Step: Generative Fusion Decoding Algorithm with LLMs to Enhance Speech Recognition and Text Image Recognition
Chan-Jan Hsu, Yi-Chang Chen, FengTing Liao, Pei-Chen Ho, Yu-Hsiang Wang, Po-Chun Hsu, Da-shan Shiu

## HPSS：面向大模型评估者的启发式提示策略搜索。
HPSS: Heuristic Prompting Strategy Search for LLM Evaluators
Bosi Wen, Pei Ke, Yufei Sun, Cunxiang Wang, Xiaotao Gu, Jinfeng Zhou, Jie Tang, Hongning Wang, Minlie Huang

## 通过反学习矫正信念空间以充分发挥LLMs的推理能力。
Rectifying Belief Space via Unlearning to Harness LLMs’ Reasoning
Ayana Niwa, Masahiro Kaneko, Kentaro Inui

## 题目：从动态分布对齐视角 revisiting 自我一致性在聚合中的应用-vespective
Revisiting Self-Consistency from Dynamic Distributional Alignment Perspective on Answer Aggregation
Yiwei Li, Ji Zhang, Shaoxiong Feng, Peiwen Yuan, Xinglin Wang, Jiayi Shi, Yueqi Zhang, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li

## 从对话到自动化：利用大语言模型进行问题解决疗法分析。
From Conversation to Automation: Leveraging LLMs for Problem-Solving Therapy Analysis
Elham Aghakhani, Lu Wang, Karla T. Washington, George Demiris, Jina Huh-Yoo, Rezvaneh Rezapour

## MemeDetoxNet：平衡毒性降低与语境保留。
MemeDetoxNet: Balancing Toxicity Reduction and Context Preservation
Gitanjali Kumari, Jitendra solanki, Asif Ekbal

## 多矩阵因子注意机制
Multi-matrix Factorization Attention
Jingcheng Hu, Houyi Li, Yinmin Zhang, Zili Wang, Shuigeng Zhou, Xiangyu Zhang, Heung-Yeung Shum

## 自我训练促使大型语言模型进行简洁推理。
Self-Training Elicits Concise Reasoning in Large Language Models
Tergel Munkhbat, Namgyu Ho, Seo Hyun Kim, Yongjin Yang, Yujin Kim, Se-Young Yun

## 不要说不：通过抑制拒绝来破解大语言模型。
Don’t Say No: Jailbreaking LLM by Suppressing Refusal
Yukai Zhou, Jian Lou, Zhijie Huang, Zhan Qin, Sibei Yang, Wenjie Wang

## 一种全生成动机访谈咨询聊天机器人，帮助吸烟者迈向戒烟决定。
A Fully Generative Motivational Interviewing Counsellor Chatbot for Moving Smokers Towards the Decision to Quit
Zafarullah Mahmood, Soliman Ali, Jiading Zhu, Mohamed Abdelwahab, Michelle Yu Collins, Sihan Chen, Yi Cheng Zhao, Jodi Wolff, Osnat C. Melamed, Nadia Minian, Marta Maslej, Carolynne Cooper, Matt Ratto, Peter Selby, Jonathan Rose

## 从感知到推理：增强针对移动UI理解的视觉语言模型。
From Perception to Reasoning: Enhancing Vision-Language Models for Mobile UI Understanding
Settaluri Lakshmi Sravanthi, Ankit Mishra, Debjyoti Mondal, Subhadarshi Panda, Rituraj Singh, Pushpak Bhattacharyya

## MAM：模块化多代理框架，通过角色专业化协作进行多模态医疗诊断。
MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration
Yucheng Zhou, Lingran Song, Jianbing Shen

## 题目：应该相信你吗？基于反事实RL的谈判中的欺骗检测。
Should I Trust You? Detecting Deception in Negotiations using Counterfactual RL
Wichayaporn Wongkamjan, Yanze Wang, Feng Gu, Denis Peskoff, Jonathan K. Kummerfeld, Jonathan May, Jordan Lee Boyd-Graber

## TagGen：基于标签控制的语法结构约束。
TagGen: Enforcing Syntactic Structures with Tag-Based Control
Vicky Xefteri, Afra Amini, Tim Vieira, Ryan Cotterell

## ATLAS：通过学习关键步骤进行智能体调优。
ATLAS: Agent Tuning via Learning Critical Steps
Zhixun Chen, Ming Li, Yuxuan Huang, Yali Du, Meng Fang, Tianyi Zhou

## Mosaic-IT：无成本组成数据合成用于指令调优。
Mosaic-IT: Cost-Free Compositional Data Synthesis for Instruction Tuning
Ming Li, Pei Chen, Chenguang Wang, Hongyu Zhao, Yijun Liang, YuPeng Hou, Fuxiao Liu, Tianyi Zhou

## 引申意义重要，但非那种重要方式：基于词素的形态学_inflection_泛化的预测因素。
Lemmas Matter, But Not Like That: Predictors of Lemma-Based Generalization in Morphological Inflection
Sarah Ruth Brogden Payne, Jordan Kodner

## 几乎人工智能，几乎人性：检测AI润色写作的挑战。
Almost AI, Almost Human: The Challenge of Detecting AI-Polished Writing
Shoumik Saha, Soheil Feizi

## REUBEN：基于重抽样的不确定性界评估自然语言处理任务。
REUBEN: REsampling-based Uncertainty Bounds for Evaluating NLP
Jonne Sälevä, Duygu Ataman, Constantine Lignos

## 小型模型难以从强大推理者中学习。
Small Models Struggle to Learn from Strong Reasoners
Yuetai Li, Xiang Yue, Zhangchen Xu, Fengqing Jiang, Luyao Niu, Bill Yuchen Lin, Bhaskar Ramasubramanian, Radha Poovendran

## CogSteer：受认知启发的选择性层干预方法，用于高效引导大型语言模型。
CogSteer: Cognition-Inspired Selective Layer Intervention for Efficiently Steering Large Language Models
Xintong Wang, Jingheng Pan, Liang Ding, Longyue Wang, Longqin Jiang, Xingshan Li, Chris Biemann

## 超越生成：利用大语言模型的创造力来克服分类中的标签偏差。
Beyond Generation: Leveraging LLM Creativity to Overcome Label Bias in Classification
Xiaoyue Wang, Xin Liu

## ELI-Why：评估大语言模型解释的教育应用价值。
ELI-Why: Evaluating the Pedagogical Utility of LLM Explanations
Brihi Joshi, Keyu He, Sahana Ramnath, Sadra Sabouri, Kaitlyn Zhou, Souti Chattopadhyay, Swabha Swayamdipta, Xiang Ren

## 基于LLMs增强的通用信息抽取事实不一致性总结检测。
Summary Factual Inconsistency Detection Based on LLMs Enhanced by Universal Information Extraction
Anguo Li, Lei Yu

## COSMIC：LLM激活中泛化的拒绝识别。
COSMIC: Generalized Refusal Identification in LLM Activations
Vincent Siu, Nicholas Crispino, Zihao Yu, Sam Pan, Zhun Wang, Yang Liu, Dawn Song, Chenguang Wang

## 幻觉修正能否提高视频与语言的对齐度？
Can Hallucination Correction Improve Video-Language Alignment?
Lingjun Zhao, Mingyang Xie, Paola Cascante-Bonilla, Hal Daumé III, Kwonjoon Lee

## 红皇后：揭露大型语言模型中的潜在多轮风险。
Red Queen: Exposing Latent Multi-Turn Risks in Large Language Models
Yifan Jiang, Kriti Aggarwal, Tanmay Laud, Kashif Munir, Jay Pujara, Subhabrata Mukherjee

## 预见未来：逆向思维链增强LLM推理。
Reason from Future: Reverse Thought Chain Enhances LLM Reasoning
Yinlong Xu, Yanzhao Zheng, Shuoshuo Sun, Shuaihan Huang, Baohua Dong, Zhu Hangcheng, Ruohui Huang, Gang Yu, Hongxia Xu, Jian Wu

## MDBench：一种基于知识指导的合成多文档推理基准。
MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance
Joseph J Peper, Wenzhao Qiu, Ali Payani, Lu Wang

## LLM作为规划模型构建者：利用大型语言模型构建自动化规划模型的综述。
LLMs as Planning Modelers: A Survey for Leveraging Large Language Models to Construct Automated Planning Models
Marcus Tantakoun, Christian Muise, Xiaodan Zhu

## IMPARA-GED：语法错误检测促进无参考语法错误质量估计器。
IMPARA-GED: Grammatical Error Detection is Boosting Reference-free Grammatical Error Quality Estimator
Yusuke Sakai, Takumi Goto, Taro Watanabe

## 为什么多兴趣公平性很重要：超图对比多兴趣学习在公平对话推荐系统中的应用。
Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System
Yongsen Zheng, Zongxuan Xie, Guohua Wang, Ziyao Liu, Liang Lin, Kwok-Yan Lam

## DiaLLM：增强医疗记录的临床对话系统，用于临床检测推荐和诊断预测。
DiaLLM: EHR-Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction
Weijieying Ren, Tianxiang Zhao, Lei Wang, Tianchun Wang, Vasant G Honavar

## 利用图进行推理：结构化隐形知识以增强ELM的推理能力。
Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning
Haoyu Han, Yaochen Xie, Hui Liu, Xianfeng Tang, Sreyashi Nag, William Headden, Yang Li, Chen Luo, Shuiwang Ji, Qi He, Jiliang Tang

## 低资源语法规则错误纠正：基于往返机器翻译的选择性数据扩增。
Low-Resource Grammatical Error Correction: Selective Data Augmentation with Round-Trip Machine Translation
Frank Palma Gomez, Alla Rozovskaya

## 通过知识精炼和动态提示调整增强医疗对话生成。
Enhancing Medical Dialogue Generation through Knowledge Refinement and Dynamic Prompt Adjustment
Hongda Sun, Jiaren Peng, Wenzhong Yang, Liang He, Bo Du, Rui Yan

## 谨慎的下一个词预测
Cautious Next Token Prediction
Yizhou Wang, Lingzhi Zhang, Yue Bai, Mang Tik Chiu, Zhengmian Hu, Mingyuan Zhang, Qihua Dong, Yu Yin, Sohrab Amirghodsi, Yun Fu

## 语言模型是否反映了人类的信心？探索心理洞察以解决大规模语言模型中的过度自信问题。
Do Language Models Mirror Human Confidence? Exploring Psychological Insights to Address Overconfidence in LLMs
Chenjun Xu, Bingbing Wen, Bin HAN, Robert Wolfe, Lucy Lu Wang, Bill Howe

## 稀疏奖励可以自我训练对话代理。
Sparse Rewards Can Self-Train Dialogue Agents
Barrett Martin Lattimer, Varun Prashant Gangal, Ryan McDonald, Yi Yang

## 基准测试与持续预训练中新知识获取的提升
Benchmarking and Improving New Knowledge Acquisition during Continued Pre-training
Aochong Oliver Li, Tanya Goyal

## 论文标题的翻译为：基于稀疏自动编码器的 artificial 文本检测的特征级洞察。
Feature-Level Insights into Artificial Text Detection with Sparse Autoencoders
Kristian Kuznetsov, Laida Kushnareva, Anton Razzhigaev, Polina Druzhinina, Anastasia Voznyuk, Irina Piontkovskaya, Evgeny Burnaev, Serguei Barannikov

## 利用Whisper进行语调重音分析。
Harnessing Whisper for Prosodic Stress Analysis
Samuel S. Sohn, Sten Knutsen, Karin Stromswold

## 多语言定义建模
Multilingual Definition Modeling
Edison Marrese-Taylor, Erica K. Shimomoto, A. Solano, Enrique Reid

## 人类在面对AI时的偏见：人类判断在AI生成文本评估中的作用。
Human Bias in the Face of AI: The Role of Human Judgement in AI Generated Text Evaluation
Tiffany Zhu, Iain Weissburg, Kexun Zhang, William Yang Wang

## CourtEval：基于法庭的多代理评估框架
CourtEval: A Courtroom-Based Multi-Agent Evaluation Framework
Sandeep Kumar, Abhijit A Nargund, Vivek Sridhar

## GradNormIR：我们在不断演变的 CORPORA 中何时应该更新密集检索器？
GradNormIR: When Should We Update the Dense Retriever in Evolving Corpora?
Dayoon Ko, Jinyoung Kim, Sohyeon Kim, Jinhyuk Kim, Jaehoon Lee, Seonghak Song, Minyoung Lee, Gunhee Kim

## 对“智能”及大型语言模型研究社区视角的研究
Research Community Perspectives on “Intelligence” and Large Language Models
Bertram Højer, Terne Sasha Thorn Jakobsen, Anna Rogers, Stefan Heinrich

## 词典来帮忙：使用双语词典为低资源语言进行跨语言词汇迁移。
Dictionaries to the Rescue: Cross-Lingual Vocabulary Transfer for Low-Resource Languages Using Bilingual Dictionaries
Haruki Sakajo, Yusuke Ide, Justin Vasselli, Yusuke Sakai, Yingtao Tian, Hidetaka Kamigaito, Taro Watanabe

## 仅仅将人类置于循环中？探究LLM辅助标注在主观任务中的应用。
Just Put a Human in the Loop? Investigating LLM-Assisted Annotation for Subjective Tasks
Hope Schroeder, Deb Roy, Jad Kabbara

## 你能分享你的故事吗？建模客户的心智活动和开放性以供大语言模型 therapists 评估。
Can You Share Your Story? Modeling Clients’ Metacognition and Openness for LLM Therapist Evaluation
Minju Kim, Dongje Yoo, Yeonjun Hwang, Minseok Kang, Namyoung Kim, Minju Gwak, Beong-woo Kwak, Hyungjoo Chae, Harim Kim, Yunjoong Lee, Min Hee Kim, Dayi jung, Kyong-Mee Chung, Jinyoung Yeo

## ACLED-DS：一个大规模多语言专家标注事件数据集，适用于现实世界。
ACLED-DS: A Large Multilingual Expert-Annotated Event Dataset for the Real World
Sina Semnani, Pingyue Zhang, Wanyue Zhai, Haozhuo Li, Ryan Beauchamp, Trey Billing, Katayoun Kishi, Manling Li, Monica Lam

## 闪耀的输入，闪耀的输出？揭开多模态LLMs中的光环效应。
Shiny Inputs, Shiny Outputs? Unveiling the Halo Effect in MultiModal LLMs
Kyusik Kim, Jeongwoo Ryu, Hyeonseok Jeon, Bongwon Suh

## 大型语言模型在长文本中仍然表现出偏见。
Large Language Models Still Exhibit Bias in Long Text
Wonje Jeung, Dongjae Jeon, Ashkan Yousefpour, Jonghyun Choi

## 当AI像人类一样写作：通过内在文本指标捕捉文学判断中的 emergent 模式。
When AI Writes Like Humans: Capturing the Emergent Patterns of Literary Judgment via Intrinsic Textual Metrics
Guillermo Marco, Julio Gonzalo, Víctor Fresno, Juan-Luis Suárez

## PASTEL：使用LLM作为法官的极性感知情感三元组提取。
PASTEL : Polarity-Aware Sentiment Triplet Extraction with LLM-as-a-Judge
Aaditya Bodke, Avinoor Singh Kohli, Hemant Subhash Pardeshi, Prathamesh Bhosale

## Text2World：评估大型语言模型符号世界模型生成能力的基准测试。
Text2World: Benchmarking Large Language Models for Symbolic World Model Generation
Mengkang Hu, Tianxing Chen, Yude Zou, Yuheng Lei, Qiguang Chen, Ming Li, Yao Mu, Hongyuan Zhang, Wenqi Shao, Ping Luo

## ADO：自动数据优化用于LLM提示中的输入。
ADO: Automatic Data Optimization for Inputs in LLM Prompts
Sam Lin, Wenyue Hua, Lingyao Li, Zhenting Wang, Yongfeng Zhang

## 基于提示的文本嵌入的冗余性、各向同性与固有维数。
Redundancy, Isotropy, and Intrinsic Dimensionality of Prompt-based Text Embeddings
Hayato Tsukagoshi, Ryohei Sasano

## 百万作者语料库：一个跨语言和跨领域的维基百科作者身份验证数据集。
The Million Authors Corpus: A Cross-Lingual and Cross-Domain Wikipedia Dataset for Authorship Verification
Abraham Israeli, Shuai Liu, Jonathan May, David Jurgens

## 视觉-语言模型内部是否具备世界模型？向着原子级评估的方向努力。
Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation
Qiyue Gao, Xinyu Pi, Kevin Liu, Junrong Chen, Ruolan Yang, Xinqi Huang, Xinyu Fang, Lu Sun, Gautham Kishore, Bo Ai, Stone Tao, Mengyang Liu, Jiaxi Yang, Chao-Jung Lai, Chuanyang Jin, Jiannan Xiang, Benhao Huang, Zeming Chen, David Danks, Hao Su, Tianmin Shu, Ziqiao Ma, Lianhui Qin, Zhiting Hu

## 模糊推测解码以实现可调的准确率-运行时tradeoff。
Fuzzy Speculative Decoding for a Tunable Accuracy-Runtime Tradeoff
Maximilian Holsman, Yukun Huang, Bhuwan Dhingra

## 利用 Persona 意识对比学习增强 LLMs 角色扮演的一致性。
Enhancing Persona Consistency for LLMs’ Role-Playing using Persona-Aware Contrastive Learning
Ke Ji, Yixin Lian, Linxu Li, Jingsheng Gao, Weiyuan Li, Bin Dai

## CoT-UQ：通过思维链在大规模语言模型中改进响应级不确定性量化。
CoT-UQ: Improving Response-wise Uncertainty Quantification in LLMs with Chain-of-Thought
Boxuan Zhang, Ruqi Zhang

## 识别人设脱节行为：开放生成中人设 fidelity 的原子级评估。
Spotting Out-of-Character Behavior: Atomic-Level Evaluation of Persona Fidelity in Open-Ended Generation
Jisu Shin, Juhyun Oh, Eunsu Kim, Hoyun Song, Alice Oh

## BridG MT：通过句子桥梁和渐进式机器翻译提升大型语言模型的机器翻译能力
BridG MT: Enhancing LLMs’ Machine Translation Capabilities with Sentence Bridging and Gradual MT
Seungwoo Choi, Gahyun Yoo, Jay-Yoon Lee

## M\\(^2\\)-TabFact：利用表格数据的视觉和文本表示进行多文档多模态事实验证。
M$^{2}$-TabFact: Multi-Document Multi-Modal Fact Verification with Visual and Textual Representations of Tabular Data
Mingyang Zhou, Lingyu Zhang, Sophia Horng, Maximillian Chen, Kung-Hsiang Huang, Shih-Fu Chang

## 保护用户免受自身影响：在与对话代理交互中保护上下文隐私。
Protecting Users From Themselves: Safeguarding Contextual Privacy in Interactions with Conversational Agents
Ivoline C. Ngong, Swanand Ravindra Kadhe, Hao Wang, Keerthiram Murugesan, Justin D. Weisz, Amit Dhurandhar, Karthikeyan Natesan Ramamurthy

## $T^5Score$：一种自动评估大语言模型生成的多文档主题集质量的方法。
$T^5Score$: A Methodology for Automatically Assessing the Quality of LLM Generated Multi-Document Topic Sets
Itamar Trainin, Omri Abend

## 朝清华进七步，但清华需十点？评估具代理性的多语言大型语言模型中的偏见。
7 Points to Tsinghua but 10 Points to 清华? Assessing Large Language Models in Agentic Multilingual National Bias
Qianying Liu, Katrina Qiyao Wang, Fei Cheng, Sadao Kurohashi

## 朝向大型语言模型在教学中的引导性使用：基于建模生成性失败的案例研究。
Towards the Pedagogical Steering of Large Language Models for Tutoring: A Case Study with Modeling Productive Failure
Romain Puech, Jakub Macina, Julia Chatain, Mrinmaya Sachan, Manu Kapur

## 将LLM作为面试官：超越静态测试，通过动态LLM评估。
LLM-as-an-Interviewer: Beyond Static Testing Through Dynamic LLM Evaluation
Eunsu Kim, Juyoung Suk, Seungone Kim, Niklas Muennighoff, Dongkwan Kim, Alice Oh

## 论文标题翻译为：非英语中心化大型语言模型思考的是哪种语言？
What Language Do Non-English-Centric Large Language Models Think in?
Chengzhi Zhong, Qianying Liu, Fei Cheng, Junfeng Jiang, Zhen Wan, Chenhui Chu, Yugo Murawaki, Sadao Kurohashi

## IntentionESC：一种以意图为中心的框架，用于增强对话系统中的情感支持。
IntentionESC: An Intention-Centered Framework for Enhancing Emotional Support in Dialogue Systems
Xinjie Zhang, Wenxuan Wang, Qin Jin

## 重新审视大规模语言模型基于提示的去偏见方法。
Rethinking Prompt-based Debiasing in Large Language Model
Xinyi Yang, Runzhe Zhan, Shu Yang, Junchao Wu, Lidia S. Chao, Derek F. Wong

## 基于上下文搜索多跳问答：通过动态键值检索与蒙特卡洛树搜索高效处理长上下文。
Search-in-Context: Efficient Multi-Hop QA over Long Contexts via Monte Carlo Tree Search with Dynamic KV Retrieval
Jiabei Chen, Guang Liu, Shizhu He, Kun Luo, Yao Xu, Jun Zhao, Kang Liu

## PLAY2PROMPT：通过工具玩耍实现LLM代理零样本工具指令优化。
PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play
Wei Fang, Yang Zhang, Kaizhi Qian, James R. Glass, Yada Zhu

## RomanLens：潜藏罗马化在大规模语言模型多语言性中的作用。
RomanLens: The Role Of Latent Romanization In Multilinguality In LLMs
Alan Saji, Jaavid Aktar Husain, Thanmay Jayakumar, Raj Dabre, Anoop Kunchukuttan, Ratish Puduppully

## GEMS：基于生成的事件论元提取方法，利用多角度提示和本体导向。
GEMS: Generation-Based Event Argument Extraction via Multi-perspective Prompts and Ontology Steering
Run Lin, Yao Liu, Yanglei Gan, Yuxiang Cai, Tian Lan, Qiao Liu

## V-HATE：基于投票的隐性仇恨言论检测
V-HATE: Voting-based Implicit Hate Speech Detection
Yejin Lee, Hyeseon Ahn, Yo-Sub Han

## 探索基于上下文的示例生成在机器翻译中的应用。
Exploring In-context Example Generation for Machine Translation
Dohyun Lee, Seungil Chad Lee, Chanwoo Yang, Yujin Baek, Jaegul Choo

## NBDESCRIB：用于生成Jupyter Notebook中表格和代码文本描述的数据集及其指南。
NBDESCRIB: A Dataset for Text Description Generation from Tables and Code in Jupyter Notebooks with Guidelines
Xuye Liu, Tengfei Ma, Yimu Wang, Fengjie Wang, Jian Zhao

## 知识增强的文字到SQL转换的知识库构建
Knowledge Base Construction for Knowledge-Augmented Text-to-SQL
Jinheon Baek, Horst Samulowitz, Oktie Hassanzadeh, Dharmashankar Subramanian, Sola Shirai, Alfio Gliozzo, Debarun Bhattacharjya

## 大规模语言模型是有偏见的评估者但不是检索增强生成的有偏见者。
LLMs are Biased Evaluators But Not Biased for Retrieval Augmented Generation
Yen-Shan Chen, Jin Jing, Peng-Ting Kuo, Chao-Wei Huang, Yun-Nung Chen

## CSTRL：基于上下文的序列迁移学习方法，用于放射学报告的抽象总结。
CSTRL: Context-Driven Sequential Transfer Learning for Abstractive Radiology Report Summarization
Mst. Fahmida Sultana Naznin, Adnan Ibney Faruq, Mostafa Rifat Tazwar, Md Jobayer, Md. Mehedi Hasan Shawon, Md Rakibul Hasan

## 从复杂性到清晰性：AI/NLP在合规监管中的作用。
From Complexity to Clarity: AI/NLP’s Role in Regulatory Compliance
Jivitesh Jain, Nivedhitha Dhanasekaran, Mona T. Diab

## 留意你的理论：心理学理论比推理更为深入。 \n\n注：此处\"theory of mind\"通常被译为\"心理学理论\"或\"心理理论\"。为了更贴近原文含义，选择\"心理学理论\"。
Mind Your Theory: Theory of Mind Goes Deeper Than Reasoning
Eitan Wagner, Nitay Alon, Joseph M Barnby, Omri Abend

## 超越背景进入认知评估：情感推理作为大型语言模型的理论思维基准。
Beyond Context to Cognitive Appraisal: Emotion Reasoning as a Theory of Mind Benchmark for Large Language Models
Gerard Christopher Yeo, Kokil Jaidka

## skLEP：斯洛伐克通用语言理解基准。
skLEP: A Slovak General Language Understanding Benchmark
Marek Suppa, Andrej Ridzik, Daniel Hládek, Tomáš Javůrek, Viktória Ondrejová, Kristína Sásiková, Martin Tamajka, Marian Simko

## 源自当前NLP评估的标准质量标准，用于引导评估设计并确立可比性和AI合规性评估的基础。
Standard Quality Criteria Derived from Current NLP Evaluations for Guiding Evaluation Design and Grounding Comparability and AI Compliance Assessments
Anya Belz, Simon Mille, Craig Thomson

## EXPERT：一种带有结构化解释的可解释图像描述评价指标。
EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations
Hyunjong Kim, Sangyeop Kim, Jongheon Jeong, Yeongjae Cho, Sungzoon Cho

## ECoRAG：基于证据性指导的长上下文检索增强生成压缩方法。
ECoRAG: Evidentiality-guided Compression for Long Context RAG
Yeonseok Jeong, Jinsu Kim, Dohyeon Lee, seung-won hwang

## 视觉语言模型能理解象形画吗？
Can Vision Language Models Understand Mimes?
Hyundong Justin Cho, Spencer Lin, Tejas Srinivasan, Michael Saxon, Deuksin Kwon, Natali T. Chavez, Jonathan May

## DICE-BENCH：评估大型语言模型在多轮多党对话中使用工具的能力。
DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues
Kyochul Jang, Donghyeon Lee, Kyusik Kim, Dongseok Heo, Taewhoo Lee, Woojeong Kim, Bongwon Suh

## HASH-RAG：桥梁融合深度哈希与检索器以实现高效、精密检索及增强生成。
HASH-RAG: Bridging Deep Hashing with Retriever for Efficient, Fine Retrieval and Augmented Generation
Jinyu Guo, Xunlei Chen, Qiyang Xia, Zhaokun Wang, Jie Ou, Libo Qin, Shunyu Yao, Wenhong Tian

## 动态任务向量分组以实现高效的多任务提示调优。
Dynamic Task Vector Grouping for Efficient Multi-Task Prompt Tuning
Peiyi Zhang, Richong Zhang, Zhijie Nie, Ziqiao Wang

## 重新审视长上下文语言模型中的内部上下文学习。
Revisiting In-Context Learning with Long Context Language Models
Jinheon Baek, Sun Jae Lee, Prakhar Gupta, Geunseob Oh, Siddharth Dalmia, Prateek Kolhar

## MMRefine：揭示多模态大型语言模型稳健精炼的障碍ительн\n
MMRefine: Unveiling the Obstacles to Robust Refinement in Multimodal Large Language Models
Gio Paik, Geewook Kim, Jinbae Im

## 基于迭代规划和搜索的约束文本修订代理。
A Constrained Text Revision Agent via Iterative Planning and Searching
Hannan Cao, Hwee Tou Ng

## 自动细粒度专家混合量化
Automated Fine-Grained Mixture-of-Experts Quantization
Zhanhao Xie, Yuexiao Ma, Xiawu Zheng, Fei Chao, Wanchen Sui, Shen Li, Yong Li, Rongrong Ji

## 训练语言模型进行批评以实现更好的精炼。
Training Language Model to Critique for Better Refinement
Tianshu Yu, Chao Xiang, mingchuan yang, Pei Ke, Bosi Wen, Cunxiang Wang, Jiale Cheng, Li Zhang, Xinyu Mu, Chuxiong Sun, Minlie Huang

## 编程概念与神经元在代码语言模型中的共通性。
How Programming Concepts and Neurons Are Shared in Code Language Models
Amir Hossein Kargaran, Yihong Liu, François Yvon, Hinrich Schuetze

## 通过指令驱动的检索重迭表示缩减加速自适应检索增强生成。
Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps
Jie Ou, Jinyu Guo, Shuaihong Jiang, Zhaokun Wang, Libo Qin, Shunyu Yao, Wenhong Tian

## ProcrustesGPT：使用结构化矩阵和正交变换压缩大型语言模型。
ProcrustesGPT: Compressing LLMs with Structured Matrices and Orthogonal Transformations
Ekaterina Grishina, Mikhail Gorbunov, Maxim Rakhuba

## MEXA：通过跨语言对齐评估以英语为中心的多语言LLM。
MEXA: Multilingual Evaluation of English-Centric LLMs via Cross-Lingual Alignment
Amir Hossein Kargaran, Ali Modarressi, Nafiseh Nikeghbal, Jana Diesner, François Yvon, Hinrich Schuetze

## 通过查询图近似增强知识图谱问答中的复杂推理能力。
Enhancing Complex Reasoning in Knowledge Graph Question Answering Through Query Graph Approximation
Hongjun Jeong, Minji Kim, Heesoo Jung, Ko Keun Kim, Hogun Park

## DynaQuest：反映现实世界知识更新的动态问答数据集。
DynaQuest: A Dynamic Question Answering Dataset Reflecting Real-World Knowledge Updates
Qian Lin, Junyi Li, Hwee Tou Ng

## 合理化与对齐：通过自我训练利用理由增强写作辅助以提高对齐效果。
Rationalize and Align: Enhancing Writing Assistance with Rationale via Self-Training for Improved Alignment
Hannan Cao, Hai Ye, Hwee Tou Ng

## 具备不确定性意识的对比解码。
Uncertainty Aware Contrastive Decoding
Hakyung Lee, Subeen Park, JOOWANG KIM, Sungjun Lim, Kyungwoo Song

