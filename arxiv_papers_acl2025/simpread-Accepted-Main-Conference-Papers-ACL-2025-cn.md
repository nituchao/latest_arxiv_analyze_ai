## 语言模型中的偏差：超越技巧测试，迈向全面评估。
Bias in Language Models: Beyond Trick Tests and Towards RUTEd Evaluation
Kristian Lum, Jacy Reese Anthis, Kevin Robinson, Chirag Nagpal, Alexander Nicholas D’Amour

## 公平的LLM不可能性。
The Impossibility of Fair LLMs
Jacy Reese Anthis, Kristian Lum, Michael Ekstrand, Avi Feller, Chenhao Tan

## EL\nuser\nEL\n\nEL human-LLM联手编程竞赛的全面基准研究。
ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming
Xinwei Yang, Zhaofeng Liu, Chen Huang, Jiashuai Zhang, Tong Zhang, Yifan Zhang, Wenqiang Lei

## TAGExplainer：为文本关联图学习模型叙述图解释的方法。
TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models
Bo Pan, Zhen Xiong, Guanchen Wu, Zheng Zhang, Yifei Zhang, Yuntong Hu, Liang Zhao

## 滑动窗口并非终点：探索大规模语言模型的全面排名与长期上下文。
Sliding Windows Are Not the End: Exploring Full Ranking with Long-Context Large Language Models
Wenhan Liu, Xinyu Ma, Yutao Zhu, Ziliang Zhao, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou

## 直观微调：朝着将对齐简化为单一步骤的目标迈进。
Intuitive Fine-Tuning: Towards Simplifying Alignment into a Single Process
Ermo Hua, Biqing Qi, Kaiyan Zhang, Kai Tian, Xingtai Lv, Ning Ding, Bowen Zhou

## CLEME2.0：通过分解编辑以实现可解释的语法错误纠正评价。
CLEME2.0: Towards Interpretable Evaluation by Disentangling Edits for Grammatical Error Correction
Jingheng Ye, Zishan Xu, Yinghui Li, Linlin Song, Qingyu Zhou, Hai-Tao Zheng, Ying Shen, Wenhao Jiang, Hong-Gee Kim, Ruitong Liu, Xin Su, Zifei Shan

## GAPO：通过生成对抗策略优化学习偏好提示。
GAPO: Learning Preferential Prompt through Generative Adversarial Policy Optimization
Zhouhong Gu, Xingzhou Chen, Xiaoran Shi, Tao Wang, Suhang Zheng, Tianyu Li, Hongwei Feng, Yanghua Xiao

## 文献遇见数据：一种假设生成的协同方法。
Literature Meets Data: A Synergistic Approach to Hypothesis Generation
Haokun Liu, Yangqiaoyu Zhou, Mingxuan Li, Chenfei Yuan, Chenhao Tan

## M-RewardBench：多语言环境中的奖励模型评估。
M-RewardBench: Evaluating Reward Models in Multilingual Settings
Srishti Gureja, Lester James Validad Miranda, Shayekh Bin Islam, Rishabh Maheshwary, Drishti Sharma, Gusti Triandi Winata, Nathan Lambert, Sebastian Ruder, Sara Hooker, Marzieh Fadaee

## StrucText-Eval：评估大型语言模型在结构丰富文本文本中的推理能力。
StrucText-Eval: Evaluating Large Language Model’s Reasoning Ability in Structure-Rich Text
Zhouhong Gu, Haoning Ye, Xingzhou Chen, Zeyang Zhou, Hongwei Feng, Yanghua Xiao

## 迈向基于大规模语言模型的留意听众：一种通过数量自我修复的实用方法。
Towards LLM-powered Attentive Listener: A Pragmatic Approach through Quantity Self-Repair
Junlin Li, Bo Peng, Yu-Yin Hsu

## 动态标签名称细化在少样本对话意图分类中的应用。
Dynamic Label Name Refinement for Few-Shot Dialogue Intent Classification
Gyutae Park, Ingeol Baek, Byeongjeong Kim, Joongbo Shin, Hwanhee Lee

## 任务包含估计中的统计缺陷。
Statistical Deficiency for Task Inclusion Estimation
Loïc Fosse, Frederic Bechet, Benoit Favre, Géraldine Damnati, Gwénolé Lecorvé, Maxime DARRIN, Philippe Formont, Pablo Piantanida

## 探究多语言伦理偏见：使用统计假设检验的MSQAD和大型语言模型。
Delving into Multilingual Ethical Bias: The MSQAD with Statistical Hypothesis Tests for Large Language Models
Seunguk Yu, Juhwan Choi, YoungBin Kim

## MIRAGE：探索大型语言模型在复杂社交互动环境中的表现。
MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments
Yin Cai, Zhouhong Gu, Zhaohan Du, Zheyu Ye, Shaosheng Cao, Yiqian xu, Hongwei Feng, Ping Chen

## 辅助患者数据对自动化胸片报告生成的影响及 Incorporate 方法探究。
The Impact of Auxiliary Patient Data on Automated Chest X-Ray Report Generation and How to Incorporate It
Aaron Nicolson, Shengyao Zhuang, Jason Dowling, Bevan Koopman

## 捕捉关键推理以增强CoT提取泛化能力。
Capture the Key in Reasoning to Enhance CoT Distillation Generalization
Chengwei Dai, Kun Li, Wei Zhou, Songlin Hu

## 如何实现人类与自然语言处理模型的有效协作：原则、形式化方法及相关研究综述。
How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond
Chen Huang, Yang Deng, Wenqiang Lei, Jiancheng Lv, Tat-Seng Chua, Jimmy Huang

## 进化之树：面向大型语言模型的树结构指令进化代码生成。
Tree-of-Evolution: Tree-Structured Instruction Evolution for Code Generation in Large Language Models
Ziyang Luo, Kaixin Li, Hongzhan Lin, Yuchen Tian, Mohan Kankanhalli, Jing Ma

## LLM驱动的测试用例生成，用于检测可信程序中的错误。
LLM-Powered Test Case Generation for Detecting Bugs in Plausible Programs
Kaibo Liu, Zhenpeng Chen, Yiyang Liu, Jie Zhang, Mark Harman, Yudong Han, Yun Ma, Yihong Dong, Ge Li, Gang Huang

## UniICL：统一压缩、选择和生成的高效ICL框架。
UniICL: An Efficient ICL Framework Unifying Compression, Selection, and Generation
Jun Gao, Qi Lv, Zili Wang, Tianxiang Wu, Ziqiang Cao, Wenjie Li

## BelarusianGLUE：白俄罗斯自然语言理解基准测试的方向。
BelarusianGLUE: Towards a Natural Language Understanding Benchmark for Belarusian
Maksim Aparovich, Volha Harytskaya, Vladislav Poritski, Oksana Volchek, Pavel Smrz

## ReSCORE：带有相关性一致性监督的多跳问答无标签迭代检索训练方法。
ReSCORE: Label-free Iterative Retriever Training for Multi-hop Question Answering with Relevance-Consistency Supervision
Dosung Lee, Wonjun Oh, Boyoung Kim, Minyoung Kim, Joonsuk Park, Paul Hongsuck Seo

## 关于单细胞生物基础语言模型的综述。
A Survey on Foundation Language Models for Single-cell Biology
Fan Zhang, Hao Chen, Zhihong Zhu, Ziheng Zhang, Zhenxi Lin, Ziyue Qiao, Yefeng Zheng, Xian Wu

## 使用自适应门控进行高效语言模型问题求解的语义探索。
Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models
Sungjae Lee, Hyejin Park, Jaechang Kim, Jungseul Ok

## HotelMatch-LLM：小型和大型语言模型的联合多任务训练，用于高效的多模态酒店检索。
HotelMatch-LLM: Joint Multi-Task Training of Small and Large Language Models for Efficient Multimodal Hotel Retrieval
Arian Askari, Emmanouil Stergiadis, Ilya Gusev, Moran Beladev

## EcomScriptBench：一种基于逐步意图驱动产品关联的电子商务脚本规划多任务基准。
EcomScriptBench: A Multi-task Benchmark for E-commerce Script Planning via Step-wise Intention-Driven Product Association
Weiqi Wang, Limeng Cui, Xin Liu, Sreyashi Nag, Wenju Xu, Chen Luo, Sheikh Muhammad Sarwar, Yang Li, Hansu Gu, Hui Liu, Changlong Yu, Jiaxin Bai, Yifan Gao, Haiyang Zhang, Qi He, Shuiwang Ji, Yangqiu Song

## TrimLLM：领域专用大语言模型的逐层丢弃策略。
TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs
Lanxiang Hu, Tajana Rosing, Hao Zhang

## Multi社会：多语种机器生成文本检测的社会媒体文本基准测试。
MultiSocial: Multilingual Benchmark of Machine-Generated Text Detection of Social-Media Texts
Dominik Macko, Jakub Kopál, Robert Moro, Ivan Srba

## JuStRank：评估系统排名的人工智能法官基准测试。
JuStRank: Benchmarking LLM Judges for System Ranking
Ariel Gera, Odellia Boni, Yotam Perlitz, Roy Bar-Haim, Lilach Eden, Asaf Yehudai

## 高效且准确的提示优化：典范引导反思中的记忆优势。
Efficient and Accurate Prompt Optimization: the Benefit of Memory in Exemplar-Guided Reflection
Cilin Yan, Jingyun Wang, Lin Zhang, Ruihui Zhao, Xiaopu Wu, Kai Xiong, Qingsong Liu, Guoliang Kang, Yangyang Kang

## 使用大型语言模型生成关系提取的多样化训练样本。
Generating Diverse Training Samples for Relation Extraction with Large Language Models
Zexuan Li, Hongliang Dai, Piji Li

## EscapeBench：迈向提升语言模型代理的创意思想。
EscapeBench: Towards Advancing Creative Intelligence of Language Model Agents
Cheng Qian, Peixuan Han, Qinyu Luo, Bingxiang He, Xiusi Chen, Yuji Zhang, Hongyi Du, Jiarui Yao, Xiaocheng Yang, Denghui Zhang, Yunzhu Li, Heng Ji

## 朝向具有异质客户端的健壮高效联邦低秩适应。
Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients
Jabin Koo, Minwoo Jang, Jungseul Ok

## 评估大型语言模型在生成个性化虚假信息方面的滥用风险。
Evaluation of LLM Vulnerabilities to Being Misused for Personalized Disinformation Generation
Aneta Zugecova, Dominik Macko, Ivan Srba, Robert Moro, Jakub Kopál, Katarína Marcinčinová, Matúš Mesarčík

## LACA：通过LLM数据增强改进跨语言方面级\nAssistant 感情分析 salarié：LACA：通过LLM数据增强改进跨语言方面基于情感分析。
LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation
Jakub Šmíd, Pavel Priban, Pavel Kral

## FACT-AUDIT：一种适应性多agent框架，用于大型语言模型事实核查评估的动态评价。
FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models
Hongzhan Lin, Yang Deng, Yuxuan Gu, Wenxuan Zhang, Jing Ma, See-Kiong Ng, Tat-Seng Chua

## 多模态大语言模型能理解空间关系吗？
Can Multimodal Large Language Models Understand Spatial Relations?
Jingping Liu, Ziyan Liu, Zhedong Cen, Yan Zhou, Yinan Zou, Weiyan Zhang, Haiyun Jiang, Tong Ruan

## 利用双向动态交互和情感知识增强比喻和夸张修辞的检测能力。
Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge
Li Zheng, Sihang Wang, Hao Fei, Zuquan Peng, Fei Li, Jianming Fu, Chong Teng, Donghong Ji

## 使用大规模语言模型重新排名以减轻社交媒体平台上有害内容的暴露风险。
Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms
Rajvardhan Oak, Muhammad Haroon, Claire Wonjeong jo, Magdalena Wojcieszak, Anshuman Chhabra

## MIND：一种针对零样本有害 meme 检测的多\n傥多剂检测的多代理框架。”
MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection
Ziyan Liu, Chunxiao Fan, Haoran Lou, Yuexin Wu, Kaiwei Deng

## HybGRAG：基于文本和关系知识库的混合检索增强生成。
HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases
Meng-Chieh Lee, Qi Zhu, Costas Mavromatis, Zhen Han, Soji Adeshina, Vassilis N. Ioannidis, Huzefa Rangwala, Christos Faloutsos

## 融合高度专业化语言模型以实现全方位专业知识。
Fusing Highly Specialized Language Models for Comprehensive Expertise
Ning Ding, Yulin Chen, Ganqu Cui, Xingtai Lv, Weilin Zhao, Kaiyan Zhang, Ruobing Xie, Bowen Zhou, Zhiyuan Liu, Maosong Sun

## RuleArena：基于规则引导推理的LLM基准测试，在现实场景中的应用。
RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios
Ruiwen Zhou, Wenyue Hua, Liangming Pan, Sitao Cheng, Xiaobao Wu, En Yu, William Yang Wang

## EvoWiki：评估大型语言模型在不断演进的知识上的表现。
EvoWiki: Evaluating LLMs on Evolving Knowledge
Wei Tang, Yixin Cao, Yang Deng, Jiahao Ying, Bo Wang, Yizhe Yang, Yuyue Zhao, Qi Zhang, Xuanjing Huang, Yu-Gang Jiang, Yong Liao

## ProcessBench：识别数学推理中的过程错误。
ProcessBench: Identifying Process Errors in Mathematical Reasoning
Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin

## 将人工智能研究与临床编码工作流程需求对齐：基于美国数据解析与critical review的八条建议。
Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review
Yidong Gan, Maciej Rybinski, Ben Hachey, Jonathan K. Kummerfeld

## 通过自适应分组位置编码扩展LLM上下文窗口：一种无需训练的方法。
Extending LLM Context Window with Adaptive Grouped Positional Encoding: A Training-Free Method
Xinhao Xu, Jiaxin Li, Hui Chen, Zijia Lin, Jungong Han, Guiguang Ding

## 重新思考代码生成中LLMs的重复问题。
Rethinking Repetition Problems of LLMs in Code Generation
Yihong Dong, Yuchen Liu, Xue Jiang, Zhi Jin, Ge Li

## $S^3$ - 语义信号分离。
$S^3$ - Semantic Signal Separation
Márton Kardos, Jan Kostkan, Kenneth Enevoldsen, Arnault-Quentin Vermillet, Kristoffer Nielbo, Roberta Rocca

## PunchBench：多模态讽刺结尾理解中MLLMs的基准测试
PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension
Kun Ouyang, Yuanxin Liu, Shicheng Li, Yi Liu, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun

## MPVStance：多视角验证在立场检测中减轻幻觉的方法。
MPVStance: Mitigating Hallucinations in Stance Detection with Multi-Perspective Verification
ZhaoDan Zhang, Zhao Zhang, Jin Zhang, Hui Xu, Xueqi Cheng

## 使用大规模语言模型的人格引导代码生成。
Personality-Guided Code Generation Using Large Language Models
Yaoqi Guo, Zhenpeng Chen, Jie Zhang, Yang Liu, Yun Ma

## 基于阅读时 reading 过程中眼球运动的自动检测阅读障碍方法（俄语）
Automatic detection of dyslexia based on eye movements during reading in Russian
Anna Laurinavichyute, Anastasiya Lopukhina, David Robert Reich

## 重新思考KenLM：高效过滤大型网络语料库中文本质量的优质和不良模型组合。
Rethinking KenLM: Good and Bad Model Ensembles for Efficient Text Quality Filtering in Large Web Corpora
Yungi Kim, Hyunsoo Ha, Sukyung Lee, Jihoo Kim, Seonghoon Yang, Chanjun Park

## 模型外推加速对齐。
Model Extrapolation Expedites Alignment
Chujie Zheng, Ziqi Wang, Heng Ji, Minlie Huang, Nanyun Peng

## BIPro：基于块逆向提示生成约束框架的零样本中文诗歌生成。
BIPro: Zero-shot Chinese Poem Generation via Block Inverse Prompting Constrained Generation Framework
Xu Zou

## ATLANTIS：基于重要性采样的弱监督到强监督学习。
ATLANTIS: Weak-to-Strong Learning via Importance Sampling
Yi Liu, Guoyin Wang, Shicheng Li, Feifan Song, Xu Sun

## PsyDT：使用大型语言模型构建具有个性化咨询风格的心理辅导员数字孪生体用于心理咨询。
PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling
Haojie Xie, Yirong Chen, Xiaofen Xing, Jingkai Lin, Xiangmin Xu

## CECT数据集：克服情境意识电子商务机器翻译中的数据稀缺性。
CECT dataset: Overcoming Data Scarcity in Context-Aware E-Commerce MT
Mikołaj Pokrywka, Wojciech Kusa, Mieszko Rutkowski, Mikołaj Koszowski

## 基于遗传学习的无嵌套选择性合理化。
Interlocking-free Selective Rationalization Through Genetic-based Learning
Federico Ruggeri, Gaetano Signorelli

## LongDocURL：一个综合性的多模态长文档基准，集成理解、推理和定位功能。
LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating
CHAO DENG, Jiale Yuan, Pi Bu, Peijie Wang, Zhong-Zhi Li, Jian Xu, Xiao-Hui Li, Yuan Gao, Jun Song, Bo Zheng, Cheng-Lin Liu

## 使用自回归填充重新识别去标识化文档。
Re-identification of De-identified Documents with Autoregressive Infilling
Lucas Georges Gabriel Charpentier, Pierre Lison

## 文档互动：多页面异构文档问答。
Doc-React: Multi-page Heterogeneous Document Question-answering
Junda Wu, Yu Xia, Tong Yu, Xiang Chen, Sai Sree Harsha, Akash V Maharaj, Ruiyi Zhang, Victor Bursztyn, Sungchul Kim, Ryan A. Rossi, Julian McAuley, Yunyao Li, Ritwik Sinha

## ObfusLM：针对嵌入反转攻击的隐私保护语言模型服务。
ObfusLM: Privacy-preserving Language Model Service against Embedding Inversion Attacks
Yu Lin, Ruining Yang, Yunlong Mao, Qizhi Zhang, Jue Hong, Quanwei Cai, Ye Wu, Huiqi Liu, zhiyu chen, Bing Duan, Sheng Zhong

## APPL：一种程序与大型语言模型提示和谐集成的提示编程语言。
APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts
Honghua Dong, Qidong Su, Yubo Gao, Zhaoyu Li, Yangjun Ruan, Gennady Pekhimenko, Chris J. Maddison, Xujie Si

## 论文标题：评估神经语言模型的词汇熟练程度。
Evaluating Lexical Proficiency in Neural Language Models
Cristiano Ciaccio, Alessio Miaschi, Felice Dell’Orletta

## 自动化指标的系统依赖性度量。
A Measure of the System Dependence of Automated Metrics
Pius von Däniken, Jan Milan Deriu, Mark Cieliebak

## 无需向量量化的时间递归语音合成。
Autoregressive Speech Synthesis without Vector Quantization
Lingwei Meng, Long Zhou, Shujie LIU, Sanyuan Chen, Bing Han, Shujie HU, Yanqing Liu, Jinyu Li, sheng zhao, Xixin Wu, Helen M. Meng, Furu Wei

## 在社交媒体语言中捕捉作者自我信念。
Capturing Author Self Beliefs in Social Media Language
Siddharth Mangalik, Adithya V Ganesan, Abigail B. Wheeler, Nicholas Kerry, Jeremy D. W. Clifton, H. Schwartz, Ryan L. Boyd

## FedEx-LoRA： federated与高效大型语言模型细调的确切聚合方法。
FedEx-LoRA: Exact Aggregation for Federated and Efficient Fine-Tuning of Large Language Models
Raghav Singhal, Kaustubh Ponkshe, Praneeth Vepakomma

## Cuckoo：一种从大规模语言模型巢穴中孵化出来的，利用资源而不劳作的信息抽取寄生虫。
Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM’s Nest
Letian Peng, Zilong Wang, Feng Yao, Jingbo Shang

## 通过预测质量代理衡量masked语言模型中的社会偏见。
Measuring Social Biases in Masked Language Models by Proxy of Prediction Quality
Rahul Zalkikar, Kanchan Chandra

## 使用大型语言模型循环的神经主题建模。
Neural Topic Modeling with Large Language Models in the Loop
Xiaohao Yang, He Zhao, Weijie Xu, YUANYUAN QI, Jueqing Lu, Dinh Phung, Lan Du

## HALoGEN：令人惊叹的大型语言模型幻觉及其发现之道。
HALoGEN: Fantastic LLM Hallucinations and Where to Find Them
Abhilasha Ravichander, Shrusti Ghela, David Wadden, Yejin Choi

## “是的，我的LoRD。”使用局部强化蒸馏引导语言模型提取。
“Yes, My LoRD.” Guiding Language Model Extraction with Locality Reinforced Distillation
Zi Liang, Qingqing Ye, Yanyun Wang, Sen Zhang, Yaxin Xiao, RongHua Li, Jianliang Xu, Haibo Hu

## 通过多模态链接破解大型视觉-语言模型。
Jailbreak Large Vision-Language Models Through Multi-Modal Linkage
Yu Wang, Xiaofei Zhou, Yichen Wang, Geyuan Zhang, Tianxing He

## 等等，那不是一个选项：LLM在错误的多项选择题中的稳健性。
Wait, that’s not an option: LLMs Robustness with Incorrect Multiple-Choice Options
Gracjan Góral, Emilia Wiśnios, Piotr Sankowski, Paweł Budzianowski

## 结合全球标签传播的大型语言模型在多模态假新闻检测中的协同作用。
Synergizing LLMs with Global Label Propagation for Multimodal Fake News Detection
Shuguo Hu, Jun Hu, Huaiwen Zhang

## KV-Latent：基于频率意识旋转型位置嵌入的维度级KV缓存减少方法。
KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding
Shi Luohe, Zuchao Li, Lefei Zhang, Baoyuan Qi, Liu Guoming, hai zhao

## 来自 adversarial 反馈的实时假新闻。
Real-time Fake News from Adversarial Feedback
Sanxing Chen, Yukun Huang, Bhuwan Dhingra

## 提高视觉语言模型的链式思考推理能力
Improve Vision Language Model Chain-of-thought Reasoning
Ruohong Zhang, Bowen Zhang, Yanghao Li, Haotian Zhang, Zhiqing Sun, Zhe Gan, Yinfei Yang, Ruoming Pang, Yiming Yang

## MARS：使用多任务评估数据集衡量语言模型的形而上学推理能力。
MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset
Weiqi Wang, Yangqiu Song

## LEANCODER：了解预训练大型语言模型代码简化模型的原理。
LEANCODE: Understanding Models Better for Code Simplification of Pre-trained Large Language Models
YAN WANG, Ling Ding, Tien N Nguyen, Shaohua Wang, Yanan Zheng

## 拆解大型语言模型中的记忆能力和推理能力。
Disentangling Memory and Reasoning Ability in Large Language Models
Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang

## 解开束缚：一种高效的数据增强策略，用于语言模型中的长序上下文预训练。
Untie the Knots: An Efficient Data Augmentation Strategy for Long-Context Pre-Training in Language Models
Junfeng Tian, Da Zheng, Yang Chen, Rui Wang, colin zhang, Debing Zhang

## LangSAMP：语言-脚本 aware多语言预训练。
LangSAMP: Language-Script Aware Multilingual Pretraining
Yihong Liu, Haotian Ye, Chunlan Ma, Mingyang Wang, Hinrich Schuetze

## 利用多模态自我校正指令调优进行电子商务产品开放世界属性挖掘。
Open-World Attribute Mining for E-Commerce Products with Multimodal Self-Correction Instruction Tuning
Jiaqi Li, Yanming Li, Xiaoli Shen, Chuanyi Zhang, Guilin Qi, Sheng Bi

## 归一化AOPC：修正特征归因解释性中的误导性指标。
Normalized AOPC: Fixing Misleading Faithfulness Metrics for Feature Attributions Explainability
Joakim Edin, Andreas Geert Motzfeldt, Casper L. Christensen, Tuukka Ruotsalo, Lars Maaløe, Maria Maistro

## 曼巴模型中的隐藏注意机制。
The Hidden Attention of Mamba Models
Ameen Ali Ali, Itamar Zimerman, Lior Wolf

## BPP-Search：增强树状思维推理以解决数学建模问题。
BPP-Search: Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving
Teng Wang, Wing Yin YU, Zhenqi He, Zehua Liu, HaileiGong, Han Wu, Xiongwei Han, Wei Shi, Ruifeng She, Fangzhou Zhu, Tao Zhong

## 通过概率嵌入建模组合图像检索中的不确定性。
Modeling Uncertainty in Composed Image Retrieval via Probabilistic Embedding
Haomiao Tang, Jinpeng Wang, Yuang Peng, GuangHao Meng, Ruisheng Luo, Bin Chen, Long Chen, Yaowei Wang, Shu-Tao Xia

## RelationalCoder：复杂表格的关系表示及其在程序处理与推理中的应用。
RelationalCoder: Relational Representation of Complex Tables for Program-Based Processing and Reasoning
Haoyu Dong, Yue Hu, Huailiang Peng, Yanan Cao

## 大型语言模型在生成合成德国公众意见方面的算法忠实性：一项案例研究。
Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study
Bolei Ma, Berk Yoztyurk, Anna-Carolina Haensch, Xinpeng Wang, Markus Herklotz, Frauke Kreuter, Barbara Plank, Matthias Aßenmacher

## 从信息到洞察：利用大语言模型进行开放方面导向的教育摘要总结。
From Information to Insight: Leveraging LLMs for Open Aspect-Based Educational Summarization
Yang Zhong, Diane Litman

## 在检测前提问：识别并缓解由大模型驱动的数学文字题解决方案检测器中的 conformity 偏差。
Ask-Before-Detection: Identifying and Mitigating Conformity Bias in LLM-Powered Error Detector for Math Word Problem Solutions
Hang Li, Tianlong Xu, Kaiqi Yang, Yucheng Chu, Yanling Chen, Yichi Song, Qingsong Wen, Hui Liu

## UnSeenTimeQA：超越LLM记忆能力的时间敏感问答。
UnSeenTimeQA: Time-Sensitive Question-Answering Beyond LLMs’ Memorization
Md Nayem Uddin, Amir Saeidi, Divij Handa, Agastya Seth, Tran Cao Son, Eduardo Blanco, Steven Corman, Chitta Baral

## 基于灵活文本引导定位的野外声音空间化。
In-the-wild Audio Spatialization with Flexible Text-guided Localization
Tianrui Pan, Jie Liu, Zewen Huang, Jie Tang, Gangshan Wu

## 自我指导生成的衍生提示与上下文内学习的结合：解锁黑盒大语言模型的新潜力。
Self-Instructed Derived Prompt Generation Meets In-Context Learning: Unlocking New Potential of Black-Box LLMs
Zhuo Li, Yuhao Du, Jinpeng Hu, Xiang Wan, Anningzhe Gao

## 根防御策略：确保Large Language Model在解码层面的安全性。
Root Defense Strategies: Ensuring Safety of LLM at the Decoding Level
Xinyi Zeng, Yuying Shang, Jiawei Chen, Jingyuan Zhang, Yu Tian

## AfriMed-QA：一项覆盖非洲、多专科的医学问答基准数据集。
AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question-Answering Benchmark Dataset
Charles Nimo, Tobi Olatunji, Abraham Toluwase Owodunni, Tassallah Abdullahi, Emmanuel Ayodele, Mardhiyah Sanni, Ezinwanne C. Aka, Folafunmi Omofoye, Foutse Yuehgoh, Timothy Faniran, Bonaventure F. P. Dossou, Moshood O. Yekini, Jonas Kemp, Katherine A Heller, Jude Chidubem Omeke, Chidi Asuzu MD, Naome A Etori, Aïmérou Ndiaye, Ifeoma Okoh, Evans Doe Ocansey, Wendy Kinara, Michael Best, Irfan Essa, Stephen Edward Moore, Chris Fourie, Mercy Nyamewaa Asiedu

## L4Q：针对大规模语言模型的参数高效量化感知微调。
L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models
Hyesung Jeon, Yulhwa Kim, Jae-Joon Kim

## 超越人口统计学： fine-tune大规模语言模型以预测个体对文本情感的主观偏好。
Beyond Demographics: Fine-tuning Large Language Models to Predict Individuals’ Subjective Text Perceptions
Matthias Orlikowski, Jiaxin Pei, Paul Röttger, Philipp Cimiano, David Jurgens, Dirk Hovy

## 性别和职业在大语言模型表示中的相互影响。
On the Mutual Influence of Gender and Occupation in LLM Representations
Haozhe An, Connor Baumler, Abhilasha Sancheti, Rachel Rudinger

## 探索大型语言模型预训练中的遗忘现象。
Exploring Forgetting in Large Language Model Pre-Training
Chonghua Liao, Ruobing Xie, Xingwu Sun, Haowen Sun, Zhanhui Kang

## ECERC：基于证据-因果注意力网络的多模态对话情感识别。
ECERC: Evidence-Cause Attention Network for Multi-Modal Emotion Recognition in Conversation
Tao Zhang, Zhenhua Tan

## 通过渐进词汇扩展学习第二语言（阿拉伯语）的大型语言模型。
Second Language (Arabic) Acquisition of LLMs via Progressive Vocabulary Expansion
Jianqing Zhu, Huang Huang, Zhihang Lin, Juhao Liang, Zhengyang Tang, Khalid Almubarak, Mosen Alharthi, Bang An, Juncai He, Xiangbo Wu, Fei Yu, Junying Chen, MA Zhuoheng, Yuhao Du, He Zhang, Saied Alshahrani, Emad A. Alghamdi, Lian Zhang, Ruoyu Sun, Haizhou Li, Benyou Wang, Jinchao Xu

## CompileAgent：具有工具集成LLM基础代理系统的自动实时仓库级编译。
CompileAgent: Automated Real-World Repo-Level Compilation with Tool-Integrated LLM-based Agent System
Li Hu, Guoqiang Chen, Xiuwei Shang, Shaoyin Cheng, Benlong Wu, LiGangyang, Xu Zhu, Weiming Zhang, Nenghai Yu

## 多示例攻击中真正重要的因素是什么？LLMs中长上下文漏洞的实证研究。
What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs
Sangyeop Kim, Yohan Lee, Yongwoo Song, Kimin Lee

## 论文标题翻译：呼吁提高报告教学调整数据质量的严谨性。
Call for Rigor in Reporting Quality of Instruction Tuning Data
Hyeonseok Moon, Jaehyung Seo, Heuiseok Lim

## AndroidLab：在可重现环境中开发和评估Android代理。
AndroidLab: Developing and Evaluating Android Agents in A Reproducible Environment
Yifan Xu, Xiao Liu, Xueqiao Sun, Siyi Cheng, Hao Yu, Hanyu Lai, Shudan Zhang, Dan Zhang, Jie Tang, Yuxiao Dong

## TUNA：密集动态视频中全面细粒度时间理解评估
TUNA: Comprehensive Fine-grained Temporal Understanding Evaluation on Dense Dynamic Videos
Fanheng Kong, Jingyuan Zhang, Hongzhi Zhang, Shi Feng, Daling Wang, Linhao Yu, Xingguang Ji, Yu Tian, V. W., Fuzheng Zhang

## 偏见在镜中：大规模语言模型的观点对其自身的对抗攻击是否稳健？
Bias in the Mirror : Are LLMs opinions robust to their own adversarial attacks
Virgile Rennard, Christos Xypolopoulos, Michalis Vazirgiannis

## Takin-VC：通过适应性混合内容编码和增强的音色建模实现富有表现力的零样本语音转换。
Takin-VC: Expressive Zero-Shot Voice Conversion via Adaptive Hybrid Content Encoding and Enhanced Timbre Modeling
Yang Yuguang, Yu Pan, Jixun Yao, xiang zhang, Jianhao Ye, Hongbin Zhou, Lei Xie, Lei Ma, Jianjun Zhao

## 多模态变压器是按模态分层的异质图。
Multimodal Transformers are Hierarchical Modal-wise Heterogeneous Graphs
Yijie Jin, Junjie Peng, Xuanchao Lin, Haochen Yuan, Lan Wang, Cangzhi Zheng

## 模块化句编码器：分离语言专一性与跨语言对齐。
Modular Sentence Encoders: Separating Language Specialization from Cross-Lingual Alignment
Yongxin Huang, Kexin Wang, Goran Glavaš, Iryna Gurevych

## LegalAgentBench：评估法律领域的LLM代理性能。
LegalAgentBench: Evaluating LLM Agents in Legal Domain
Haitao Li, Junjie Chen, Jingli Yang, Qingyao Ai, Wei Jia, Youfeng Liu, Kai Lin, Yueyue WU, Guozhi Yuan, Yiran HU, Wuyue Wang, Yiqun LIU, Minlie Huang

## LLäMmlein 🐑：透明、紧凑且具有竞争力的全德语文本模型。
LLäMmlein 🐑: Transparent, Compact and Competitive German-Only Language Models from Scratch
Jan Pfister, Julia Wunderle, Andreas Hotho

## 我们设计的结构化知识提示具有泛化能力吗？系统评估与反思。
Have We Designed Generalizable Structural Knowledge Promptings? Systematic Evaluation and Rethinking
Yichi Zhang, Zhuo Chen, Lingbing Guo, yajing Xu, Shaokai Chen, Mengshu Sun, Binbin Hu, Zhiqiang Zhang, Lei Liang, Wen Zhang, Huajun Chen

## 大型语言模型对齐的二元分类器优化。
Binary Classifier Optimization for Large Language Model Alignment
Seungjae Jung

## 超越语言的言语表达：面向视频 Grounded 对话的非言语线索学习的大规模多模态数据集
Speaking Beyond Language: A Large-Scale Multimodal Dataset for Learning Nonverbal Cues from Video-Grounded Dialogues
Youngmin Kim, Jiwan Chung, Jisoo Kim, sunghyun lee, Sangkyu Lee, Junhyeok Kim, Cheoljong Yang, Youngjae Yu

## 关于词语意义，预训练语言模型知道多少？
How Much Do Pretrained Language Models Know About Word Senses?
Simone Teglia, Simone Tedeschi, Roberto Navigli

## 推理计算优化的视频vislang模型。
Inference Compute-Optimal Video Vision Language Models
Peiqi Wang, ShengYun Peng, Xuewen Zhang, Hanchao Yu, Yibo Yang, Lifu Huang, Fujun Liu, Qifan Wang

## 当后门开口说话：通过模型生成的解释理解大模型后门攻击。
When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations
Huaizhi Ge, Yiming Li, Qifan Wang, Yongfeng Zhang, Ruixiang Tang

## 转向新的嵌入空间：分析由多语言语言模型中介干预引起的跨语言对齐。
Steering into New Embedding Spaces: Analyzing Cross-Lingual Alignment Induced by Model Interventions in Multilingual Language Models
Anirudh Sundar, Sinead Williamson, Katherine Metcalf, Barry-John Theobald, Skyler Seto, Masha Fedzechkina

## 有人注意到翻译模型变得更 robust 吗？
Did Translation Models Get More Robust Without Anyone Even Noticing?
Ben Peters, Andre Martins

## INVESTORBENCH：基于LLM的代理进行金融决策任务的基准。
INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent
Haohang Li, Yupeng Cao, Yangyang Yu, Shashidhar Reddy Javaji, Zhiyang Deng, Yueru He, Yuechen Jiang, Zining Zhu, K.P. Subbalakshmi, Jimin Huang, Lingfei Qian, Xueqing Peng, Jordan W. Suchow, Qianqian Xie

## 更聪明、更出色、更快速、更持久：一种现代双方向编码器，用于快速、内存高效且支持长上下文微调和推理。
Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference
Benjamin Warner, Antoine Chaffin, Benjamin Clavié, Orion Weller, Oskar Hallström, Said Taghadouini, Alexis Gallagher, Raja Biswas, Faisal Ladhak, Tom Aarsen, Griffin Thomas Adams, Jeremy Howard, Iacopo Poli

## 隐匿于词语之后：创建并探究 forePLay 注解数据集以研究波兰语色情语用。
Behind Closed Words: Creating and Investigating the forePLay Annotated Dataset for Polish Erotic Discourse
Anna Kołos, Katarzyna Lorenc, Emilia Wiśnios, Agnieszka Karlińska

## 通过多语言套娃嵌入实现分层级逐层新闻文章聚类。
Hierarchical Level-Wise News Article Clustering via Multilingual Matryoshka Embeddings
Hans William Alexander Hanley, Zakir Durumeric

## HateDay：推特上一天代表性仇恨言论数据集的见解。
HateDay: Insights from a Global Hate Speech Dataset Representative of a Day on Twitter
Manuel Tonneau, Diyi Liu, Niyati Malhotra, Scott A. Hale, Samuel Fraiberger, Victor Orozco-Olvera, Paul Röttger

## 将Common Crawl转换为精细的长 horizon 预训练数据集。
Transforming Common Crawl into a Refined Long-Horizon Pretraining Dataset
Dan SU, Kezhi Kong, Ying Lin, Joseph Jennings, Brandon Norick, Markus Kliegl, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro

## 性别包容性公平指数（GIFI）：评估大型语言模型中性别多样性的一种多层次框架。
Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models
Zhengyang Shan, Emily Diana, Jiawei Zhou

## MAIN-RAG：多智能体过滤检索增强生成。
MAIN-RAG: Multi-Agent Filtering Retrieval-Augmented Generation
Chia-Yuan Chang, Zhimeng Jiang, Vineeth Rakesh, Menghai Pan, Chin-Chia Michael Yeh, Guanchu Wang, Mingzhi Hu, Zhichao Xu, Yan Zheng, Mahashweta Das, Na Zou

## oteMedSum：一种统一的医疗摘要生成框架。
uMedSum: A Unified Framework for Advancing Medical Abstractive Summarization
Aishik Nagar, Yutong Liu, Andy T. Liu, Viktor Schlegel, Vijay Prakash Dwivedi, Arun-Kumar Kaliya-Perumal, GUNA PRATHEEP KALANCHIAM, Yili Tang, Robby T. Tan

## 直接使用连续表示进行提示优化。
Direct Prompt Optimization with Continuous Representations
Yangkun Wang, Zihan Wang, Jingbo Shang

## 基于对比iveplexity 的可控生成：在净化大规模语言模型中的应用。 \n\n注：这里的 \"ContrastiveVieplexity\" 看似是一个错误或者拼写错误，在正常情况下应为 \"ContrastitiveVleplexity\"，但更可能是 \"ContrastiveVleplex\"， 应为 \"ContrastiveV\"plex\" + 这个术语意\"对比 perplexplexity，，如果它更像是一个特定领域的术语或可能要是\"对比 perplexplex\";， �。信假 \"ContrativeVpleex\"应 是一个特定研究中的术语，。 如果 是特 是一个特定领域的专有名词，那 � 这个术语就 应该 � � �stan 按原文保留。ContrativeVpleex\"。。 为 了 保持 原文 的 准 � 当然 不 是特定术语 専术语 则 建议 为 \"对比plex\" \"以 寄 意最 一些 � 例如 \"对比ielex\"。 作为 一个 较 通 用 的 下 译。
Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models
Tassilo Klein, Moin Nabi

## 论文标题：解析基于学习的演示选择机制在上下文学习中的作用。
Unraveling the Mechanics of Learning-Based Demonstration Selection for In-Context Learning
Hui Liu, Wenya Wang, Hao Sun, Chris XING TIAN, Chenqi Kong, Xin Dong, Haoliang Li

## AndroidGen：在数据稀缺条件下构建Android语言代理。
AndroidGen: Building an Android Language Agent under Data Scarcity
Hanyu Lai, Junjie Gao, Xiao Liu, Yifan Xu, Shudan Zhang, Yuxiao Dong, Jie Tang

## 基于LLM的多视角角色扮演代理的上下文感知情感预测。
Context-Aware Sentiment Forecasting via LLM-based Multi-Perspective Role-Playing Agents
Fanhang Man, Huandong Wang, Jianjie Fang, Zhaoyi Deng, Baining Zhao, Xinlei Chen, Yong Li

## TARGA：针对结构化数据实践推理的目标合成数据生成方法。
TARGA: Targeted Synthetic Data Generation for Practical Reasoning over Structured Data
Xiang Huang, Jiayu Shen, Shanshan Huang, Sitao Cheng, Xiaxia Wang, Yuzhong Qu

## 位置感知自动电路发现
Position-aware Automatic Circuit Discovery
Tal Haklay, Hadas Orgad, David Bau, Aaron Mueller, Yonatan Belinkov

## 在跨模态转移中，任意到任意模型是否比专业模型更一致？
Are Any-to-Any Models More Consistent Across Modality Transfers Than Specialists?
Jiwan Chung, Janghan Yoon, Junhyeong Park, Sangeyl Lee, Joowon Yang, Sooyeon Park, Youngjae Yu

## GigaSpeech 2：一种用于低资源语言的不断演化、大规模多领域ASR语料库，配有自动化爬取、转录和精炼功能。
GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for Low-Resource Languages with Automated Crawling, Transcription and Refinement
Yifan Yang, Zheshu Song, Jianheng Zhuo, Mingyu Cui, Jinpeng Li, Bo Yang, Yexing Du, Ziyang Ma, Xunying Liu, Ziyuan Wang, Ke Li, Shuai Fan, Kai Yu, Wei-Qiang Zhang, Guoguo Chen, Xie Chen

## 大型语言模型训练后缩放综述。
A Survey of Post-Training Scaling in Large Language Models
Hanyu Lai, Xiao Liu, Junjie Gao, Jiale Cheng, Zehan Qi, Yifan Xu, Shuntian Yao, Dan Zhang, Jinhua Du, Zhenyu Hou, Xin Lv, Minlie Huang, Yuxiao Dong, Jie Tang

## BQA：用于视频大型语言模型的体语问答数据集。
BQA: Body Language Question Answering Dataset for Video Large Language Models
Shintaro Ozaki, Kazuki Hayashi, Miyu Oba, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe

## HyperFM：基于事实的超关系知识图谱链接预测的多模态融合方法。
HyperFM: Fact-Centric Multimodal Fusion for Link Prediction over Hyper-Relational Knowledge Graphs
Yuhuan Lu, Weijian Yu, Xin Jing, Dingqi Yang

## Centurio：探讨大型视觉-语言模型的多语言能力驱动因素。
Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model
Gregor Geigle, Florian Schneider, Carolin Holtermann, Chris Biemann, Radu Timofte, Anne Lauscher, Goran Glavaš

## 提示候选人，然后精练：一种由大规模语言模型驱动的数据标注教师-学生框架。
Prompt Candidates, then Distill: A Teacher-Student Framework for LLM-driven Data Annotation
Mingxuan Xia, Haobo Wang, Yixuan Li, Zewei Yu, Jindong Wang, Junbo Zhao, Runze Wu

## 大型语言模型的集成水印。
Ensemble Watermarks for Large Language Models
Georg Niess, Roman Kern

## DioR：适应性认知检测与上下文检索优化的动态检索增强生成。
DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation
Hanghui Guo, Jia Zhu, Shimin Di, Weijie Shi, Zhangze Chen, Jiajie Xu

## TRACT：回归意识微调结合链式思考推理以实现LLM作为法官。
TRACT: Regression-Aware Fine-tuning Meets Chain-of-Thought Reasoning for LLM-as-a-Judge
Cheng-Han Chiang, Hung-yi Lee, Michal Lukasik

## Mixture of Insightful Experts (MoTE)：推理链与专家混合在自我对齐中的协同作用。
Mixture of insighTful Experts (MoTE): The Synergy of Reasoning Chains and Expert Mixtures in Self-Alignment
Zhili Liu, Yunhao GOU, Kai Chen, Lanqing HONG, Jiahui Gao, Fei Mi, Yu Zhang, Zhenguo Li, Xin Jiang, Qun Liu, James Kwok

## $\\mathsf{Con Instruction}$：通过非文本模态对多模态大型语言模型进行通用破解。
$\\mathsf{Con Instruction}$: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities
Jiahui Geng, Thy Thy Tran, Preslav Nakov, Iryna Gurevych

## 少而精：增强反馈对齐混合语言模型在分子描述生成和细粒度自然语言推理评估中的应用。
Less for More: Enhanced Feedback-aligned Mixed LLMs for Molecule Caption Generation and Fine-Grained NLI Evaluation
Dimitris Gkoumas, Maria Liakata

## MAPS：基于动机意识的个性化搜索通过LLM驱动的咨询对齐。
MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation Alignment
Weicong Qin, Yi Xu, Weijie Yu, Chenglei Shen, Ming He, Jianping Fan, Xiao Zhang, Jun Xu

## 亚里士多德：一种逻辑完备分解搜索解决框架下的逻辑推理掌握。
Aristotle: Mastering Logical Reasoning with A Logic-Complete Decompose-Search-Resolve Framework
Jundong Xu, Hao Fei, Meng Luo, Qian Liu, Liangming Pan, William Yang Wang, Preslav Nakov, Mong-Li Lee, Wynne Hsu

## LADM：基于注意力依赖测度的长上下文训练数据选择方法用于LLM。
LADM: Long-context Training Data Selection with Attention-based Dependency Measurement for LLMs
Jianghao Chen, Junhong Wu, Yangyifan Xu, Jiajun Zhang

## A-TASC：基于亚洲TED的数据自动字幕 corpus。
A-TASC: Asian TED-Based Automatic Subtitling Corpus
Yuhan Zhou, Naoki Yoshinaga

## 铁磨铁：通过对抗训练在机器生成文本检测中抵御攻击。
Iron Sharpens Iron: Defending Against Attacks in Machine-Generated Text Detection with Adversarial Training
Yuanfan Li, Zhaohan Zhang, Chengzhengxu Li, Chao Shen, Xiaoming Liu

## Token预添加：一种无需训练的从大规模语言模型中引出更好句子嵌入的方法。
Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs
Yuchen Fu, Zifeng Cheng, Zhiwei Jiang, Zhonghui Wang, Yafeng Yin, Zhengliang Li, Qing Gu

## 基于文化学习的语言模型文化适应。
Cultural Learning-Based Culture Adaptation of Language Models
Chen Cecilia Liu, Anna Korhonen, Iryna Gurevych

## 没有愚蠢的问题，只有表述不佳的问题：理解表述不佳的信息寻求问题。
No Questions are Stupid, but some are Poorly Posed: Understanding Poorly-Posed Information-Seeking Questions
Neha Srikanth, Rachel Rudinger, Jordan Lee Boyd-Graber

## 从资源配置的角度看RLHF中的奖励公平性。
Towards Reward Fairness in RLHF: From a Resource Allocation Perspective
Sheng Ouyang, Yulan Hu, Ge Chen, Qingyang Li, Fuzheng Zhang, Yong Liu

## 感觉不安全时随时拒绝：通过解耦拒絕训练提高LLM的安全性。
Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training
Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Jiahao Xu, Tian Liang, Pinjia He, Zhaopeng Tu

## LazyReview——一个发现NLP同行评审中懒惰思维的数据集。
LazyReview A Dataset for Uncovering Lazy Thinking in NLP Peer Reviews
Sukannya Purkayastha, Zhuang Li, Anne Lauscher, Lizhen Qu, Iryna Gurevych

## 解决盲目猜测：通过视频语言模型在多项选择题回答中校准选择偏差。
Addressing Blind Guessing: Calibration of Selection Bias in Multiple-Choice Question Answering by Video Language Models
Olga Loginova, Oleksandr Bezrukov, Ravi Shekhar, Alexey Kravets

## 用梯度分组来驯服大规模语言模型。
Taming LLMs with Gradient Grouping
Siyuan Li, Juanxi Tian, Zedong Wang, Xin Jin, Zicheng Liu, Wentao Zhang, Dan Xu

## 理解目标导向对话中共同ground错位：基于Ubuntu聊天日志的案例研究。
Understanding Common Ground Misalignment in Goal-Oriented Dialog: A Case-Study with Ubuntu Chat Logs
Rupak Sarkar, Neha Srikanth, Taylor Hudson, Rachel Rudinger, Claire Bonial, Philip Resnik

## 基于事实还是善于猜测？一个按问题平衡的数据集，用于区分基于事实和基于环境的体模问答模型。
Grounded, or a Good Guesser? A Per-Question Balanced Dataset to Separate Blind from Grounded Models for Embodied Question Answering
Miles Shelton, Nate Wingerd, Kritim K Rijal, Ayush Garg, Adelina Gutic, Brett Barnes, Catherine Finegan-Dollak

## 重新审视NLP中关于阿拉伯方言的常见假设。
Revisiting Common Assumptions about Arabic Dialects in NLP
Amr Keleg, Sharon Goldwater, Walid Magdy

## 检索以解释：基于证据的可解释药物靶标识别预测。
Retrieve to Explain: Evidence-driven Predictions for Explainable Drug Target Identification
Ravi Patel, Angus Brayne, Rogier Hintzen, Daniel Jaroslawicz, Georgiana Neculae, Dane S. Corneil

## 以下哪一项最能描述使用大规模语言模型进行的多项选择评估？A) 被迫的 B) 有缺陷的 C) 可修复的 D) 以上全部。
Which of These Best Describes Multiple Choice Evaluation with LLMs? A) Forced B) Flawed C) Fixable D) All of the Above
Nishant Balepur, Rachel Rudinger, Jordan Lee Boyd-Graber

## 谁的船在浮航？通过推断用户人像来改善偏好调整中的个性化。
Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas
Nishant Balepur, Vishakh Padmakumar, Fumeng Yang, Shi Feng, Rachel Rudinger, Jordan Lee Boyd-Graber

##  Urdu 中的人工制造假新闻和机器编造假新闻的检测。
Detection of Human and Machine-Authored Fake News in Urdu
Muhammad Zain Ali, Yuxia Wang, Bernhard Pfahringer, Tony C Smith

## 一种高效的面向任务对话策略：注入精英个体的进化强化学习。
An Efficient Task-Oriented Dialogue Policy: Evolutionary Reinforcement Learning Injected by Elite Individuals.
Yangyang Zhao, Ben Niu, Libo Qin, Shihan Wang

## 学习稀疏性以实现有效的高效音乐表演问答。
Learning Sparsity for Effective and Efficient Music Performance Question Answering
Xingjian Diao, Tianzhen Yang, Chunhui Zhang, Weiyi Wu, Ming Cheng, Jiang Gui

## 数字守门人：谷歌在策划 hashtags 和 subreddits 方面的作用。
Digital Gatekeepers: Google’s Role in Curating Hashtags and Subreddits
Amrit Poudel, Yifan Ding, Tim Weninger, Jürgen Pfeffer

## 使用心理测量量表评估和操控预训练语言模型中的潜在构念。
Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales
Maor Reuben, Ortal Slobodin, Idan-Chaim Cohen, Aviad Elyashar, Orna Braun-Lewensohn, Odeya Cohen, Rami Puzis

## 驯服语言模型进行文本属性图学习的解耦聚合方法。
Taming Language Models for Text-attributed Graph Learning with Decoupled Aggregation
Chuang Zhou, Zhu Wang, Shengyuan Chen, Jiahe Du, Qiyuan Zheng, Zhaozhuo Xu, Xiao Huang

## 利用视觉感知头部发散破解LVLMs幻觉之码。
Cracking the Code of Hallucination in LVLMs with Vision-aware Head Divergence
Jinghan He, Kuan Zhu, Haiyun Guo, Junfeng Fang, Zhenglin Hua, Yuheng Jia, Ming Tang, Tat-Seng Chua, Jinqiao Wang

## 对比提示可以在推理时引导大型语言模型的句子嵌入，从而增强句子嵌入。
Contrastive Prompting Enhances Sentence Embeddings in LLMs through Inference-Time Steering
Zifeng Cheng, Zhonghui Wang, Yuchen Fu, Zhiwei Jiang, Yafeng Yin, Cong Wang, Qing Gu

## D.Va：在使用前先验证你的演示。
D.Va: Validate Your Demonstration First Before You Use It
Qi Zhang, Zhiqing Xiao, Ruixuan Xiao, Lirong Gao, Junbo Zhao

## 大规模语言模型的预训练蒸馏：设计空间探索。
Pre-training Distillation for Large Language Models: A Design Space Exploration
Hao Peng, Xin Lv, Yushi Bai, Zijun Yao, Jiajie Zhang, Lei Hou, Juanzi Li

## 分层文档精炼以实现长上下文检索增强生成。
Hierarchical Document Refinement for Long-context Retrieval-augmented Generation
Jiajie Jin, Xiaoxi Li, Guanting Dong, Yuyao Zhang, Yutao Zhu, Yongkang Wu, Zhonghua Li, YE QI, Zhicheng Dou

## 渐进式多模态推理通过主动检索
Progressive Multimodal Reasoning via Active Retrieval
Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen

## 使用词汇联想比较西方英语国家与LLMs之间的道德价值观。
Comparing Moral Values in Western English-speaking societies and LLMs with Word Associations
Chaoyi Xiang, Chunhua Liu, Simon De Deyne, Lea Frermann

## 教学视觉-语言模型提问：解决视觉问题中的歧义。
Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions
Pu Jian, Donglei Yu, Jiajun Zhang, Shuo Ren, Wen Yang

## FoldMoE：通过注意力-MoE 管道化高效训练长序列 MoE 模型
FoldMoE: Efficient Long Sequence MoE Training via Attention-MoE Pipelining
Guichao Zhu, Lintian Lei, Yuhao QING, Yichao Fu, Fanxin Li, Dong HUANG, Zekai Sun, Heming Cui

## ToolHop：一个基于查询的基准测试，用于评估多跳工具使用的大语言模型。
ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use
Junjie Ye, Zhengyin Du, Xuesong Yao, Weijian Lin, Yufei Xu, Zehui Chen, Zaiyuan Wang, Sining Zhu, Zhiheng Xi, Siyu Yuan, Tao Gui, Qi Zhang, Xuanjing Huang, Jiecao Chen

## RAG-批评者：利用自动批评引导的代理工作流增强检索生成。
RAG-Critic: Leveraging Automated Critic-Guided Agentic Workflow for Retrieval Augmented Generation
Guanting Dong, Jiajie Jin, Xiaoxi Li, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen

## TEACH：一种用于古中文理解的对比知识自适应精炼框架。
TEACH: A Contrastive Knowledge Adaptive Distillation Framework for Ancient Chinese Understanding
Yuting Wei, Qi Meng, Yuanxing Xu, Bin Wu

## 揭示源语言的力量：基于源语言的最小贝叶斯风险解码在神经机器翻译中的应用。
Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding for Neural Machine Translation
Boxuan Lyu, Hidetaka Kamigaito, Kotaro Funakoshi, Manabu Okumura

## 语言模型校准的影响因素：响应一致性、损失函数和提示风格的研究
Influences on LLM Calibration: A Study of Response Agreement, Loss Functions, and Prompt Styles
Yuxi Xia, Pedro Henrique Luz de Araujo, Klim Zaporojets, Benjamin Roth

## 大型语言模型在概念的柏拉图表示上的模型间转移能力。
Cross-model Transferability among Large Language Models on the Platonic Representations of Concepts
Youcheng Huang, Chen Huang, Duanyu Feng, Wenqiang Lei, Jiancheng Lv

## 朝向更好评估生成的专利索赔方向。
Towards Better Evaluation for Generated Patent Claims
Lekang Jiang, Pascal A. Scherz, Stefan Goetz

## LongReward：通过AI反馈提升长上下文大型语言模型。
LongReward: Improving Long-context Large Language Models with AI Feedback
Jiajie Zhang, Zhongni Hou, Xin Lv, Shulin Cao, Zhenyu Hou, Yilin Niu, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li

## LongBench v2：朝着对真实长上下文多任务有更深入理解与推理的方向发展。
LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks
Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li

## 大规模语言模型是否带有英语口音？评估与改进多语言LLM的自然度。
Do Large Language Models have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs
Yanzhu Guo, Simone Conia, Zelin Zhou, Min Li, Saloni Potdar, Henry Xiao

## UTBoost：对SWE-Bench编码代理进行严格的评估。
UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench
Boxi Yu, Yuxuan Zhu, Pinjia He, Daniel Kang

## 通过快捷神经元分析建立可信赖的大语言模型评估。
Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis
Kejian Zhu, Shangqing Tu, Zhuoran Jin, Lei Hou, Juanzi Li, Jun Zhao

## 通过词元内部结构学习增强LLM中的字符级理解。
Enhancing Character-Level Understanding in LLMs through Token Internal Structure Learning
Zhu Xu, Zhiqiang Zhao, Zihan Zhang, Yuchi Liu, Quanwei Shen, Fei Liu, Yu Kuang, Jian He, Conglin Liu

## 对抗强硬抵抗者：针对不可协作对话的战略规划博弈论策略。
Battling against Tough Resister: Strategy Planning with Adversarial Game for Non-collaborative Dialogues
Haiyang Wang, Zhiliang Tian, Yuchen Pan, Xin Song, Xin Niu, Minlie Huang, Bin Zhou

## 在多样推理链上微调促进大语言模型内的推理过程中解释能力的精炼。
Fine-Tuning on Diverse Reasoning Chains Drives Within-Inference CoT Refinement in LLMs
Haritz Puerto, Tilek Chubakov, Xiaodan Zhu, Harish Tayyar Madabushi, Iryna Gurevych

## 大型语言模型中的 conformity（一致性）
Conformity in Large Language Models
Xiaochen Zhu, Caiqi Zhang, Tom Stafford, Nigel Collier, Andreas Vlachos

## 位置过载：基于集编码的位置偏差消除及上下文窗口扩展 for 大型语言模型
Positional Overload: Positional Debiasing and Context Window Extension for Large Language Models using Set Encoding
Lukas Kinder, Lukas Edman, Alexander Fraser, Tobias Käfer

## 过去遇现在：使用大规模语言模型创建历史类比。
Past Meets Present: Creating Historical Analogy with Large Language Models
Nianqi Li, Siyu Yuan, Jiangjie Chen, Jiaqing Liang, Feng Wei, Zujie Liang, Deqing Yang, Yanghua Xiao

## FR-Spec：通过频率排序推测采样加速大型词汇量语言模型。
FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling
Weilin Zhao, Tengyu Pan, Xu Han, Yudi Zhang, Sun Ao, Yuxiang Huang, Kaihuo Zhang, Weilun Zhao, Yuxuan Li, Jie Zhou, Hao Zhou, Jianyong Wang, Maosong Sun, Zhiyuan Liu

## 跨语言文化知识转移：一种不对称现象。
Cross-Lingual Transfer of Cultural Knowledge: An Asymmetric Phenomenon
Chen Zhang, Zhiyuan Liao, Yansong Feng

## 通过输入-标签映射的视角解释和改善增量学习。
Interpret and Improve In-Context Learning via the Lens of Input-Label Mappings
Chenghao Sun, Zhen Huang, Yonggang Zhang, Le Lu, Houqiang Li, Xinmei Tian, Xu Shen, Jieping Ye

## 使用大语言模型自动化法律概念解释：检索、生成与评估。
Automating Legal Concept Interpretation with LLMs: Retrieval, Generation, and Evaluation
Kangcheng Luo, Quzhe Huang, Cong Jiang, Yansong Feng

## 元反思：一种无需反馈的反射学习框架。
Meta-Reflection: A Feedback-Free Reflection Learning Framework
Yaoke Wang, Yun Zhu, XintongBao, Wenqiao Zhang, Suyang Dai, kehan chen, Wenqiang Li, Gang Huang, Siliang Tang, Yueting Zhuang

## 自信与批判：LLMs 自我修正能力的分解分析。
Confidence v.s. Critique: A Decomposition of Self-Correction Capability for LLMs
Zhe Yang, Yichang Zhang, Yudong Wang, Ziyao Xu, Junyang Lin, Zhifang Sui

## TokAlign：高效的词汇适配通过词元对齐。
TokAlign: Efficient Vocabulary Adaptation via Token Alignment
Chong Li, Jiajun Zhang, Chengqing Zong

## 两步阅读：使用代码增强语法书翻译极度低资源语言。
Read it in Two Steps: Translating Extremely Low-Resource Languages with Code-Augmented Grammar Books
Chen Zhang, Jiuheng Lin, Xiao Liu, Zekai Zhang, Yansong Feng

## 视觉证据提示缓解了大型视觉-语言模型中的幻觉问题。
Visual Evidence Prompting Mitigates Hallucinations in Large Vision-Language Models
Wei Li, Zhen Huang, Houqiang Li, Le Lu, Yang Lu, Xinmei Tian, Xu Shen, Jieping Ye

## 段落级别扩散：一种可控长文本生成的扩散语言模型框架。
Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models
Xiaochen Zhu, Georgi Karadzhov, Chenxi Whitehouse, Andreas Vlachos

## VReST：通过树搜索和自我奖励机制增强大型视觉-语言模型的推理能力。
VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism
Congzhi Zhang, Jiawei Peng, Zhenglin Wang, Yilong Lai, Haowen Sun, Heng Chang, Fei Ma, Weijiang Yu

## 利用双过程理论在语言代理框架中实现实时人机协同翻译。
Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration
Shao Zhang, Xihuai Wang, Wenhao Zhang, Chaoran Li, Junru Song, Tingyu Li, Lin Qiu, Xuezhi Cao, Xunliang Cai, Wen Yao, Weinan Zhang, Xinbing Wang, Ying Wen

## 动态且可泛化的过程奖励建模。
Dynamic and Generalizable Process Reward Modeling
Zhangyue Yin, Qiushi Sun, Zhiyuan Zeng, Qinyuan Cheng, Xipeng Qiu, Xuanjing Huang

## BELLE：一种用于多跳问答的多层次多代理推理框架。
BELLE: A Bi-Level Multi-Agent Reasoning Framework for Multi-Hop Question Answering
Taolin Zhang, Dongyang Li, Qizhou Chen, Chengyu Wang, Xiaofeng He

## AceEdit：促进大型语言模型连续知识编辑的发展。
AceEdit: Advancing Continuous Knowledge Editing For Large Language Models
Qi Li, Xiaowen Chu

## 不同粒度トークン对语言模型 surprisal 预测能力的影响
The Impact of Token Granularity on the Predictive Power of Language Model Surprisal
Byung-Doh Oh, William Schuler

## 迈向文本与图像交织检索。
Towards Text-Image Interleaved Retrieval
Xin Zhang, Ziqi Dai, Yongqi Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Jun Yu, Wenjie Li, Min Zhang

## 大型边际表示学习以实现鲁棒跨语言命名实体识别。
Large Margin Representation Learning for Robust Cross-lingual Named Entity Recognition
Guangcheng Zhu, Ruixuan Xiao, Zhen Zhu, Gengyu Lyu, Junbo Zhao, Haobo Wang

## 论文标题：以人类-大语言模型互动为基础的游戏开发。
Game Development as Human-LLM Interaction
Jiale Hong, Hongqiu Wu, hai zhao

## 一种用于数学推理的工艺监督奖励模型高效精准训练数据构建框架。
An Efficient and Precise Training Data Construction Framework for Process-supervised Reward Model in Mathematical Reasoning
Wei Sun, Qianlong Du, Fuwei Cui, Jiajun Zhang

## QAEncoder：朝着问题解答系统中对齐表示学习的研究。
QAEncoder: Towards Aligned Representation Learning in Question Answering Systems
Zhengren Wang, Qinhan Yu, Shida Wei, Zhiyu li, Feiyu Xiong, Xiaoxing Wang, Simin Niu, Hao Liang, Wentao Zhang

## DeepSolution：通过基于树的探索和双点思考提升复杂工程技术解决方案设计。
DeepSolution: Boosting Complex Engineering Solution Design via Tree-based Exploration and Bi-point Thinking
Zhuoqun Li, Haiyang Yu, Xuanang Chen, Hongyu Lin, Yaojie Lu, Fei Huang, Xianpei Han, Yongbin Li, Le Sun

## 大型语言模型能否模拟第二语言英语对话？一种基于信息论的母语依赖偏差分析。
Can LLMs Simulate L2-English Dialogue? An Information-Theoretic Analysis of L1-Dependent Biases
Rena Wei Gao, Xuetong Wu, Tatsuki Kuribayashi, Mingrui Ye, Siya Qi, Carsten Roever, Yuanxing Liu, Zheng Yuan, Jey Han Lau

## 细粒度视频配音时长对齐与段监督偏好优化
Fine-grained Video Dubbing Duration Alignment with Segment Supervised Preference Optimization
Chaoqun Cui, Liangbin Huang, Shijing Wang, Zhe Tong, Zhaolong Huang, Xiao Zeng, Xiaofeng Liu

## 论文题目翻译：人类和大语言模型组织概念知识的方式：探讨意大利语中的次级类别。
How Humans and LLMs Organize Conceptual Knowledge: Exploring Subordinate Categories in Italian
Andrea Pedrotti, Giulia Rambelli, Caterina Villani, Marianna Bolognesi

## 利用人类生产和解释不对称性测试大型语言模型的认知合理性。
Leveraging Human Production-Interpretation Asymmetries to Test LLM Cognitive Plausibility
Suet-Ying Lam, Qingcheng Zeng, Jingyi Wu, Rob Voigt

## PTQ1.61：极低比特后训练量化方法在大规模语言模型中的极限推动研究
PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training Quantization Methods for Large Language Models
Jiaqi Zhao, Miao Zhang, Ming Wang, Yuzhang Shang, Kaihao Zhang, Weili Guan, Yaowei Wang, Min Zhang

## 稀疏潜在变量引导检索增强生成。
Sparse Latents Steer Retrieval-Augmented Generation
Chunlei Xin, Shuheng Zhou, Huijia Zhu, Weiqiang Wang, Xuanang Chen, Xinyan Guan, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun

## ProtoLens：推进原型学习以实现文本分类中的精细粒度可解释性。
ProtoLens: Advancing Prototype Learning for Fine-Grained Interpretability in Text Classification
Bowen Wei, Ziwei Zhu

## SafeRAG：大型语言模型检索增强生成的安全性基准测试。
SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model
Xun Liang, Simin Niu, Zhiyu li, Sensen Zhang, Hanyu Wang, Feiyu Xiong, Zhaoxin Fan, Bo Tang, Jihao Zhao, Jiawei Yang, Shichao Song, Mengwei Wang

## SR-LLM：重思大型语言模型中的结构化表示。
SR-LLM: Rethinking the Structured Representation in Large Language Model
Jiahuan Zhang, Tianheng Wang, Ziyi Huang, Yulong Wu, HANQING WU, DongbaiChen, Linfeng Song, Yue Zhang, guozheng rao, Kaicheng Yu

## SurveyPilot：一种自动化的社交媒体个人意见收集代理框架。
SurveyPilot: an Agentic Framework for Automated Human Opinion Collection from Social Media
Viet Thanh Pham, Lizhen Qu, Zhuang Li, Suraj Sharma, Gholamreza Haffari

## 文本即一切：增强增量社会事件检测的大型语言模型。
Text is All You Need: LLM-enhanced Incremental Social Event Detection
Zitai Qiu, Congbo Ma, Jia Wu, Jian Yang

## 通过稀疏自编码器揭示大规模语言模型中的语言特异性特征。
Unveiling Language-Specific Features in Large Language Models via Sparse Autoencoders
Boyi Deng, Yu Wan, Baosong Yang, Yidan Zhang, Fuli Feng

## 利用输出分布的特性改进文本生成中置信分数的校准。
Improving the Calibration of Confidence Scores in Text Generation Using the Output Distribution’s Characteristics
Lorenzo Jaime Yu Flores, Ori Ernst, Jackie CK Cheung

## AnRe：时间知识图谱预测中的类比回放。
AnRe: Analogical Replay for Temporal Knowledge Graph Forecasting
Guo Tang, Zheng Chu, Wenxiang Zheng, Junjia Xiang, Yizhuo Li, Weihao Zhang, Ming Liu, Bing Qin

## 生成Transformer模型在算术推理任务中泛化能力的原理性理解。
Principled Understanding of Generalization for Generative Transformer Models in Arithmetic Reasoning Tasks
Xingcheng Xu, Zibo Zhao, Haipeng Zhang, Yanqing Yang

## 重新审视o1-like模型的测试时缩放能力：它们真的具有测试时缩放能力吗？
Revisiting the Test-Time Scaling of o1-like Models: Do they Truly Possess Test-Time Scaling Capabilities?
Zhiyuan Zeng, Qinyuan Cheng, Zhangyue Yin, Yunhua Zhou, Xipeng Qiu

## 基于话语关系的神经连贯性建模
Discourse Relation-Enhanced Neural Coherence Modeling
Wei Liu, Michael Strube

## 多模态语用劫持文本到图像模型
Multimodal Pragmatic Jailbreak on Text-to-image Models
Tong Liu, Zhixin Lai, Jiawen Wang, Gengyuan Zhang, Shuo Chen, Philip Torr, Vera Demberg, Volker Tresp, Jindong Gu

## 从良性转化成有毒：通过对抗隐喻突破语言模型。
from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors
Yu Yan, Sheng Sun, Zenghao Duan, Teli Liu, Min Liu, Zhiyi yin, Qi Li, LeiJingyu

## 评估开放式音频对话理解能力——针对大规模音频-语言模型。
Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models
Kuofeng Gao, Shu-Tao Xia, Ke Xu, Philip Torr, Jindong Gu

## ShifCon：基于变换对比框架提升非主导语言能力。
ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework
Hengyuan Zhang, Chenming Shang, Sizhe Wang, Dongdong Zhang, Feng Yao, Renliang Sun, Yiyao Yu, Yujiu Yang, Furu Wei

## 作为规划形式化的语言模型的极限。
On the Limit of Language Models as Planning Formalizers
Cassie Huang, Li Zhang

## 使用模式强化学习生成结构化输出。
Learning to Generate Structured Output with Schema Reinforcement Learning
Yaxi Lu, Haolun Li, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Zhiyuan Liu, Fangming Liu, Maosong Sun

## MorphMark：用于大型语言模型的灵活自适应水印方法。
MorphMark: Flexible Adaptive Watermarking for Large Language Models
Zongqi Wang, Tianle Gu, Baoyuan Wu, Yujiu Yang

## 当知识 discrepancy 存在时，RAG 系统在教育问答中的鲁棒性研究。
On the Robustness of RAG Systems in Educational Question Answering under Knowledge Discrepancies
Tianshi Zheng, Weihan Li, Jiaxin Bai, Weiqi Wang, Yangqiu Song

## WarriorCoder：学习专家对决以增强代码大型语言模型。
WarriorCoder: Learning from Expert Battles to Augment Code Large Language Models
Huawen Feng, Pu Zhao, Qingfeng Sun, Can Xu, Fangkai Yang, Lu Wang, Qianli Ma, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

## 大型语言模型蒸馏的量化研究
Quantification of Large Language Model Distillation
Sunbowen Lee, Junting Zhou, Chang Ao, Kaige Li, Xeron Du, Sirui He, Haihong Wu, Tianci Liu, Jiaheng Liu, Hamid Alinejad-Rokny, Min Yang, Yitao Liang, Zhoufutu Wen, Shiwen Ni

## 潘多拉的盒子与阿拉丁的油灯：全面分析揭示RAG噪音在大型语言模型中的作用。
Pandora’s Box or Aladdin’s Lamp: A Comprehensive Analysis Revealing the Role of RAG Noise in Large Language Models
Jinyang Wu, Shuai Zhang, Feihu Che, Mingkuan Feng, Pengpeng Shao, Jianhua Tao

## 通过关键安全向量定位提高大型语言模型的安全培训。
Improve Safety Training of Large Language Models with Safety-Critical Singular Vectors Localization
Peijian Gu, Quan Wang, Zhendong Mao

## 全注意的灵丹妙药还是妥协方案？关于核心词基于的上下文压缩的全面研究。
A Silver Bullet or a Compromise for Full Attention? A Comprehensive Study of Gist Token-based Context Compression
Chenlong Deng, Zhisong Zhang, Kelong Mao, Shuaiyi Li, Xinting Huang, Dong Yu, Zhicheng Dou

## 带有聚类引导对比学习的细粒度情绪分类三视角框架
A Triple-View Framework for Fine-Grained Emotion Classification with Clustering-Guided Contrastive Learning
Junqing Gong, Binhan Yang, Wei Shen

## LLM的逐步推理破坏攻击。
Stepwise Reasoning Disruption Attack of LLMs
Jingyu Peng, Maolin Wang, Xiangyu Zhao, Kai Zhang, Wanyu Wang, Pengyue Jia, Qidong Liu, Ruocheng Guo, Qi Liu

## 通过知识驱动的数据增强和高斯衰减对比学习增强无监督句嵌入。
Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning
Peichao Lai, Zhengfeng Zhang, Wentao Zhang, Fangcheng Fu, Bin CUI

## 大型语言模型的知识边界：一项综述。
Knowledge Boundary of Large Language Models: A Survey
Moxin Li, Yong Zhao, Wenxuan Zhang, Shuaiyi Li, Wenya Xie, See-Kiong Ng, Tat-Seng Chua, Yang Deng

## 迷失在多语态之中：解析变换器语言模型中的跨语言事实不一致现象。
Lost in Multilinguality: Dissecting Cross-lingual Factual Inconsistency in Transformer Language Models
Mingyang Wang, Heike Adel, Lukas Lange, Yihong Liu, Ercong Nie, Jannik Strötgen, Hinrich Schuetze

## 优化分解以实现最优索赔验证。
Optimizing Decomposition for Optimal Claim Verification
Yining Lu, Noah Ziems, Hy Dang, Meng Jiang

## 细节中的恶魔：关于实现负载均衡损失以训练专业化混合专家模型的研究。
Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models
Zihan Qiu, Zeyu Huang, Bo Zheng, Kaiyue Wen, Zekun Wang, Rui Men, Ivan Titov, Dayiheng Liu, Jingren Zhou, Junyang Lin

## GradOT：无需训练的梯度保存远程调优方法，适用于大型语言模型。
GradOT: Training-free Gradient-persevering Offsite-tuning for Large Language Models
Kai Yao, Zhaorui Tan, Penglei Gao, Lichun Li, Kaixin Wu, Yinggui Wang, Yuan Zhao, Yixin Ji, Jianke Zhu, Wei Wang

## MoC：用于检索增强生成系统的文本片段组合学习器。
MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented Generation System
Jihao Zhao, Zhiyuan Ji, Zhaoxin Fan, Hanyu Wang, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu li

## 通过随带视觉调节减轻视觉遗忘，用于多模态长链推理。
Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning
Hai-Long Sun, Zhun Sun, Houwen Peng, Han-Jia Ye

## 通过节点修剪和辅助选项减轻选择偏差。
Mitigating Selection Bias with Node Pruning and Auxiliary Options
Hyeong Kyu Choi, Weijie Xu, Chi Xue, Stephanie Eckman, Chandan K. Reddy

## 在测试时从反馈中学习推理。
Learning to Reason from Feedback at Test-Time
Yanyang Li, Michael Lyu, Liwei Wang

## RPO：稳健检索增强生成中的检索偏好优化
RPO: Retrieval Preference Optimization for Robust Retrieval-Augmented Generation
Shi-Qi Yan, Quan Liu, Zhen-Hua Ling

## 使用大型语言模型的双重自我提升反事实数据增强。
Dually Self-Improved Counterfactual Data Augmentation Using Large Language Model
Luhao Zhang, Xinyu Zhang, Linmei Hu, Dandan Song, Liqiang Nie

## 改进低资源和濒危语言的并行句子挖掘。
Improving Parallel Sentence Mining for Low-Resource and Endangered Languages
Shu Okabe, Katharina Hämmerl, Alexander Fraser

## 语言模型生命周期中组成性的几何特征。
Geometric Signatures of Compositionality Across a Language Model’s Lifetime
Jin Hwa Lee, Thomas Jiralerspong, Lei Yu, Yoshua Bengio, Emily Cheng

## AdamMeme：适配性探究多模态大型语言模型在有害性判断上的推理能力
AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness
Zixin Chen, Hongzhan Lin, Kaixin Li, Ziyang Luo, Zhen Ye, Guang Chen, Zhiyong Huang, Jing Ma

## $SECRET$: 半监督临床试验文件相似性搜索。
$SECRET$: Semi-supervised Clinical Trial Document Similarity Search
Trisha Das, Afrah Shafquat, Mandis Beigi, Jacob Aptekar, Jimeng Sun

## $\\textit{L-CiteEval}$：评估长上下文模型忠实度的一站式工具。
$\\textit{L-CiteEval}$: A Suite for Evaluating Fidelity of Long-context Models
Zecheng Tang, Keyan Zhou, Juntao Li, Baibei Ji, jianye hou, Min Zhang

## 重新审视知识标记在不确定性估计中的作用：标记能否准确反映大型语言模型的不确定性？
Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models’ Uncertainty?
Jiayu Liu, Qing Zong, Weiqi Wang, Yangqiu Song

## 更精确、更快意味着更好：迈向更高效的小时级长视频视觉-语言模型。
Sharper and Faster mean Better: Towards More Efficient Vision-Language Model for Hour-scale Long Video Understanding
Daoze Zhang, Yuze Zhao, Jintao Huang, Yingda Chen

## YuLan-Mini：开放数据高效语言模型的极限挑战。
YuLan-Mini: Pushing the Limits of Open Data-efficient Language Model
Hu Yiwen, Song Huatong, Jie Chen, Jia Deng, jiapeng wang, Kun Zhou, Yutao Zhu, Jinhao Jiang, zican Dong, YANG LU, Xu Miao, Xin Zhao, Ji-Rong Wen

## 频繁使用ChatGPT进行写作任务的人能准确且稳健地识别AI生成的文本。
People who frequently use ChatGPT for writing tasks are accurate and robust detectors of AI-generated text
Jenna Russell, Marzena Karpinska, Mohit Iyyer

## Auto-Arena：通过代理同行battle和委员会讨论自动进行LLM评估。
Auto-Arena: Automating LLM Evaluations with Agent Peer Battles and Committee Discussions
Ruochen Zhao, Wenxuan Zhang, Yew Ken Chia, Weiwen Xu, Deli Zhao, Lidong Bing

## 增强Transformer以实现可迁移的一阶逻辑蕴含。
Enhancing Transformers for Generalizable First-Order Logical Entailment
Tianshi Zheng, Jiazheng Wang, Zihao Wang, Jiaxin Bai, Hang Yin, Zheye Deng, Yangqiu Song, Jianxin Li

## 你的模型过于自信，以及其他我们告诉自己的谎言。
Your Model is Overconfident, and Other Lies We Tell Ourselves
Timothee Mickus, Aman Sinha, Raúl Vázquez

## 在推理时进行跨语言干预以弥合大型语言模型之间的语言差距。
Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention
Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch

## 自我学习能动性长上下文理解
Self-Taught Agentic Long Context Understanding
Yufan Zhuang, Xiaodong Yu, Jialian Wu, Ximeng Sun, Ze Wang, Jiang Liu, Yusheng Su, Jingbo Shang, Zicheng Liu, Emad Barsoum

## ATRI：通过减少数据分布错误来缓解多语言音频文本检索不一致性。
ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors
Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou

## OS-Genesis：通过逆向任务合成自动化GUI代理轨迹构建。
OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis
Qiushi Sun, Kanzhi Cheng, Zichen Ding, Chuanyang Jin, Yian Wang, Fangzhi Xu, Zhenyu Wu, Chengyou Jia, Liheng Chen, Zhoumianze Liu, Ben Kao, Guohao Li, Junxian He, Yu Qiao, Zhiyong Wu

## ConSim：使用自动仿真性衡量基于概念的解释有效性。
ConSim: Measuring Concept-Based Explanations’ Effectiveness with Automated Simulatability
Antonin Poché, Alon Jacovi, Agustin Martin Picard, Victor Boutin, Fanny Jourdan

## 从眼动追踪解码阅读目标。
Decoding Reading Goals from Eye Movements
Omer Shubi, Cfir Avraham Hadar, Yevgeni Berzak

## CORAL：学习跨多步训练的一致表示——使用更轻量级的推测性 Draftsman。
CORAL: Learning Consistent Representations across Multi-step Training with Lighter Speculative Drafter
Yepeng Weng, Dianwen Mei, Huishi Qiu, Xujie Chen, Li Liu, Jiang Tian, Zhongchao Shi

## 从文本嵌入空间的分布结构中揭示视觉语义心理语言学特性。
Uncovering Visual-Semantic Psycholinguistic Properties from the Distributional Structure of Text Embedding Space
Si Wu, Sebastian Bruch

## P$^2$定律：模型剪枝后训练的缩放定律。
P$^2$ Law: Scaling Law for Post-Training After Model Pruning
Xiaodong Chen, Yuxuan Hu, Xiaokang Zhang, Yanling Wang, Cuiping Li, Hong Chen, Jing Zhang

## 人群对比推理：解锁LLM作为法官的全面评估。
Crowd Comparative Reasoning: Unlocking Comprehensive Evaluations for LLM-as-a-Judge
Qiyuan Zhang, Yufei Wang, Yuxin Jiang, Liangyou Li, Chuhan Wu, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Fuyuan Lyu, Chen Ma

## GUI-explorer：自主探索和挖掘具有过渡意识的知识的GUI代理。
GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent
Bin Xie, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Jie Liu, Min Zhang, Liqiang Nie

## 迷失在语境中：偏好建模中语境关注不足且分散。
Lost in the Context: Insufficient and Distracted Attention to Contexts in Preference Modeling
Shihan Dou, Jiayi Chen, Chenhao Huang, Feng Chen, Wei Chengzhi, Huiyuan Zheng, Shichun Liu, Yan Liu, Chenxiao Liu, Chao Xin, Lin Yan, Zongzhang Zhang, Tao Gui, Qi Zhang, Xuanjing Huang

## 保蕴含的一阶逻辑表示在自然语言蕴含中的应用。
Entailment-Preserving First-order Logic Representations in Natural Language Entailment
Jinu Lee, Qi Liu, Runzhi Ma, Vincent Han, Ziqi Wang, Heng Ji, Julia Hockenmaier

## 迈向大型语言模型有效且高效的持续预训练。
Towards Effective and Efficient Continual Pre-training of Large Language Models
Jie Chen, Zhipeng Chen, jiapeng wang, Kun Zhou, Yutao Zhu, Jinhao Jiang, Yingqian Min, Xin Zhao, Zhicheng Dou, Jiaxin Mao, Yankai Lin, Ruihua Song, Jun Xu, Xu Chen, Rui Yan, Zhewei Wei, Di Hu, Wenbing Huang, Ji-Rong Wen

## 通过输出中心特征描述增强自动化可解释性。
Enhancing Automated Interpretability with Output-Centric Feature Descriptions
Yoav Gur-Arieh, Roy Mayan, Chen Agassy, Atticus Geiger, Mor Geva

## 以语义引导的提示组织实现高效的通用目标劫持。
Efficient Universal Goal Hijacking with Semantics-guided Prompt Organization
Yihao Huang, Chong Wang, Xiaojun Jia, Qing Guo, Felix Juefei-Xu, Jian Zhang, Yang Liu, Geguang Pu

## 模式识别还是医学知识？医学选择题存在的问题。
Pattern Recognition or Medical Knowledge? The Problem with Multiple-Choice Questions in Medicine
Maxime Griot, Jean Vanderdonckt, Demet YUKSEL, Coralie Hemptinne

## 什么是好的自然语言提示？
What Makes a Good Natural Language Prompt?
Do Xuan Long, Duy Dinh, Ngoc-Hai Nguyen, Kenji Kawaguchi, Nancy F. Chen, Shafiq Joty, Min-Yen Kan

## mPLUG-DocOwl2：无OCR高分辨率压缩多页文档理解。
mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding
Anwen Hu, Haiyang Xu, Liang Zhang, Jiabo Ye, Ming Yan, Ji Zhang, Qin Jin, Fei Huang, Jingren Zhou

## 有限资源适配器是正则化器，而非语言学家。
Limited-Resource Adapters Are Regularizers, Not Linguists
Marcell Fekete, Nathaniel Romney Robinson, Ernests Lavrinovics, Djeride Jean-Baptise, Raj Dabre, Johannes Bjerva, Heather Lent

## 模态感知神经元剪枝以在多模态大语言模型中实现遗忘。
Modality-Aware Neuron Pruning for Unlearning in Multimodal Large Language Models
Zheyuan Liu, Guangyao Dou, Xiangchi Yuan, Chunhui Zhang, Zhaoxuan Tan, Meng Jiang

## 插件 fine-tuning：从小型语言模型到大型语言模型的差距桥梁。
Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models
Kyeonghyun Kim, Jinhee Jang, Juhwan Choi, Yoonji Lee, Kyohoon Jin, YoungBin Kim

## 规则是来被打破的吗？基于UniMoral理解多语言道德推理的计算流水线
Are Rules Meant to be Broken? Understanding Multilingual Moral Reasoning as a Computational Pipeline with UniMoral
Shivani Kumar, David Jurgens

## NGQA：面向个性化健康感知营养推理的营养图问答基准。
NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning
Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye

## ReLearn：通过学习实现大型语言模型的遗忘机制。
ReLearn: Unlearning via Learning for Large Language Models
Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo, Huajun Chen, Ningyu Zhang

## 是什么造成了 stigma？一个基于理论、专家标注的访谈语料库，旨在揭开心理健康 stigma 的面纱。
What is Stigma Attributed to? A Theory-Grounded, Expert-Annotated Interview Corpus for Demystifying Mental-Health Stigma
Han Meng, Yancan Chen, Yunan Li, YITIAN YANG, Jungup Lee, Renwen Zhang, Yi-Chieh Lee

## 幻觉解毒：大型语言模型训练中的敏感性降采样(SenD)。
Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training
Shahrad Mohammadzadeh, Juan David Guerra, Marco Bonizzato, Reihaneh Rabbany, Golnoosh Farnadi

## 理解低资源主题建模中的跨域适应。
Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling
Pritom Saha Akash, Kevin Chen-Chuan Chang

## UAlign：利用不确定性估计实现大规模语言模型的事实对齐。
UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models
Boyang XUE, Fei Mi, Qi Zhu, Hongru WANG, Rui Wang, Sheng Wang, Erxin Yu, Xuming Hu, Kam-Fai Wong

## LLM代理中的不确定性传播。
Uncertainty Propagation on LLM Agent
Qiwei Zhao, Dong Li, Yanchi Liu, Wei Cheng, Yiyou Sun, Mika Oishi, Takao Osaki, Katsushi Matsuda, Huaxiu Yao, Chen Zhao, Haifeng Chen, Xujiang Zhao

## CoT-Valve：长度可压缩的思维链调优。
CoT-Valve: Length-Compressible Chain-of-Thought Tuning
Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, Xinchao Wang

## 通过机器卸学拆分大型语言模型中带偏见的知识与推理。
Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning
Zheyuan Liu, Suraj Maharjan, Fanyou Wu, Rahil Parikh, Belhassen Bayar, Srinivasan H. Sengamedu, Meng Jiang

## 隐藏状态在隐藏什么？测试LLMs事实编码能力的极限。
Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs
Giovanni Servedio, Alessandro De Bellis, Dario Di Palma, Vito Walter Anelli, Tommaso Di Noia

## HoH：一个动态基准，用于评估过时信息对检索增强生成影响的评估。
HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation
Jie Ouyang, Tingyue Pan, Mingyue Cheng, Ruiran Yan, Yucong Luo, Jiaying Lin, Qi Liu

## CxGGEC：基于构建的语法错误修正。
CxGGEC: Construction-Guided Grammatical Error Correction
Yayu Cao, Tianxiang Wang, Lvxiaowei Xu, Zhenyao Wang, Ming Cai

## 增强多模态持续指令调优的BranchLoRA。
Enhancing Multimodal Continual Instruction Tuning with BranchLoRA
Duzhen Zhang, Yong Ren, Zhong-Zhi Li, Yahan Yu, Jiahua Dong, Chenxing Li, Zhilong Ji, Jinfeng Bai

## 这是在谈论什么？一种科学汇报的视频到文本摘要数据集。
What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations
Dongqi Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu QIU, Mirella Lapata, Vera Demberg

## 超越序列：编码和依赖关系表示的二维表示与依赖编码在代码生成中的应用
Beyond Sequences: Two-dimensional Representation and Dependency Encoding for Code Generation
Xiangyu Zhang, Yu Zhou, Guang Yang, Wei Cheng, Taolue Chen

## LLaMAs同样有所感受：通过探测揭示LLaMA模型中的情感和情绪表示。
LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing
Dario Di Palma, Alessandro De Bellis, Giovanni Servedio, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia

## ProvBench：合同自动审查中的法律条款推荐基准测试。
ProvBench: A Benchmark of Legal Provision Recommendation for Contract Auto-Reviewing
Xiuxuan Shen, Zhongyuan Jiang, Junsan Zhang, Junxiao Han, Yao Wan, Chengjie Guo, Bingcheng Liu, Jie Wu, Renxiang Li, Philip S. Yu

## 让FETCH! 发生：通过共通环境发现潜在的狗哨声。
Making FETCH! Happen: Finding Emergent Dog Whistles Through Common Habitats
Kuleen Sasse, Carlos Alejandro Aguirre, Isabel Cachola, Sharon Levy, Mark Dredze

## HD-NDEs：用于大语言模型 hallucination 检测的神经微分方程。
HD-NDEs: Neural Differential Equations for Hallucination Detection in LLMs
Qing Li, Jiahui Geng, Zongxiong Chen, Derui Zhu, Yuxia Wang, Congbo Ma, Chenyang Lyu, Fakhri Karray

## 有效地识别混合来源文本中的水印段落。
Efficiently Identifying Watermarked Segments in Mixed-Source Texts
Xuandong Zhao, Chenwen Liao, Yu-Xiang Wang, Lei Li

## FocalPO：通过聚焦正确偏好排名来提升偏好优化。
FocalPO: Enhancing Preference Optimizing by Focusing on Correct Preference Rankings
Tong Liu, Xiao Yu, Wenxuan Zhou, Jindong Gu, Volker Tresp

## 基于CoT的合成器：通过答案合成提升LLM性能。
CoT-based Synthesizer: Enhancing LLM Performance through Answer Synthesis
Bohan Zhang, Xiaokang Zhang, Jing Zhang, Jifan Yu, Sijia Luo, Jie Tang

## NeuSym-RAG：基于多视图结构化检索的神经符号融合检索方法用于PDF问答。
NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring for PDF Question Answering
Ruisheng Cao, Hanchong Zhang, Tiancheng Huang, Zhangyi Kang, Yuxin Zhang, Liangtai Sun, Hanqi Li, Yuxun Miao, Shuai Fan, Lu Chen, Kai Yu

## AutoMedEval：利用语言模型进行自动医疗能力评估。
AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation
Xiechi Zhang, Zetian Ouyang, Linlin Wang, Gerard de Melo, Zhu Cao, Xiaoling Wang, Ya Zhang, Yanfeng Wang, Liang He

## F5-TTS：一种通过流匹配生成流畅且忠实语音的童话故事合成器。
F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching
Yushen CHEN, Zhikang Niu, Ziyang Ma, Keqi Deng, Chunhui Wang, JianZhao, Kai Yu, Xie Chen

## 无需自我认知的自适应检索？让不确定性回归。
Adaptive Retrieval Without Self-Knowledge? Bringing Uncertainty Back Home
Viktor Moskvoretskii, Maria Marina, Mikhail Salnikov, Nikolay Ivanov, Sergey Pletenev, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Irina Nikishina, Alexander Panchenko

## 迈向更通用的开放关系提取方法。
Towards a More Generalized Approach in Open Relation Extraction
Qing Wang, Yuepei Li, Qiao Qiao, Kang Zhou, Qi Li

## 用大型语言模型替代人类法官？跨20项自然语言处理评估任务的大规模实证研究。
LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks
Anna Bavaresco, Raffaella Bernardi, Leonardo Bertolazzi, Desmond Elliott, Raquel Fernández, Albert Gatt, Esam Ghaleb, Mario Giulianelli, Michael Hanna, Alexander Koller, Andre Martins, Philipp Mondorf, Vera Neplenbroek, Sandro Pezzelle, Barbara Plank, David Schlangen, Alessandro Suglia, Aditya K Surikuchi, Ece Takmaz, Alberto Testoni

## 评价语言模型作为合成数据生成器的能力。
Evaluating Language Models as Synthetic Data Generators
Seungone Kim, Juyoung Suk, Xiang Yue, Vijay Viswanathan, Seongyun Lee, Yizhong Wang, Kiril Gashteovski, Carolin Lawrence, Sean Welleck, Graham Neubig

## X-TURING：面向长对话代理的增强高效图灵测试。
X-TURING: Towards an Enhanced and Efficient Turing Test for Long-Term Dialogue Agents
Weiqi Wu, Hongqiu Wu, hai zhao

## 图描述顺序能否影响使用大语言模型解决图问题？
Can Graph Descriptive Order Affect Solving Graph Problems with LLMs?
Yuyao Ge, Shenghua Liu, Baolong Bi, Yiwei Wang, Lingrui Mei, Wenjie Feng, Lizhe Chen, Xueqi Cheng

## 评估大型语言模型在推理任务中口音公平性和稳健性。
Assessing Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks
Fangru Lin, Shaoguang Mao, Emanuele La Malfa, Valentin Hofmann, Adrian de Wynter, Xun Wang, Si-Qing Chen, Michael J. Wooldridge, Janet B. Pierrehumbert, Furu Wei

## 通过蒙特卡洛树搜索评估多模态大型语言模型在视频字幕生成中的性能。
Evaluating Multimodal Large Language Models on Video Captioning via Monte Carlo Tree Search
Linhao Yu, Xingguang Ji, Yahui Liu, Fanheng Kong, Chenxi Sun, Jingyuan Zhang, Hongzhi Zhang, V. W., Fuzheng Zhang, Deyi Xiong

## GIFT-SW：高斯噪声注入精细调整显著权重以适用于大语言模型
GIFT-SW: Gaussian noise Injected Fine-Tuning of Salient Weights for LLMs
Maxim Zhelnin, Viktor Moskvoretskii, Egor Shvetsov, Maria Krylova, Venediktov Egor, Zuev Aleksandr, Evgeny Burnaev

## 不可解问题检测：大规模多模态模型的稳健理解评估。
Unsolvable Problem Detection: Robust Understanding Evaluation for Large Multimodal Models
Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Qing Yu, Go Irie, Yixuan Li, Hai Helen Li, Ziwei Liu, Kiyoharu Aizawa

## AlignMMBench：评估大型视觉-语言模型中的中文多模态对齐能力
AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models
Yuhang Wu, Wenmeng Yu, Yean Cheng, Yan Wang, Xiaohan Zhang, Jiazheng Xu, Ming Ding, Yuxiao Dong

## Quaff：基于离群空间稳定性假设的量化参数高效微调方法。
Quaff: Quantized Parameter-Efficient Fine-Tuning under Outlier Spatial Stability Hypothesis
Hong Huang, Dapeng Wu

## 这个是不可接受的：取消文化的道德基础。
That is Unacceptable: the Moral Foundations of Canceling
Soda Marem Lo, Oscar Araque, Rajesh Sharma, Marco Antonio Stranisci

## FloorPlan-LLaMa：对齐建筑师反馈与建筑楼层平面设计领域知识。
FloorPlan-LLaMa: Aligning Architects’ Feedback and Domain Knowledge in Architectural Floor Plan Generation
Jun Yin, Pengyu Zeng, Haoyuan Sun, Yuqin Dai, Han Zheng, Miao Zhang, Yachao Zhang, Shuai Lu

## LexTempus：通过动态专家混合增强法律语言模型的时间通用性。
LexTempus: Enhancing Temporal Generalizability of Legal Language Models Through Dynamic Mixture of Experts
Santosh T.Y.S.S, Tuan-Quang Vuong

## 超越位置：变压器中波let-like性质的涌现。
Beyond Position: the emergence of wavelet-like properties in Transformers
Valeria Ruscio, Umberto Nanni, Fabrizio Silvestri

## FineReason：通过反思型谜题解决评估和提升LLMs的审慎推理能力。
FineReason: Evaluating and Improving LLMs’ Deliberate Reasoning through Reflective Puzzle Solving
Guizhen Chen, Weiwen Xu, Hao Zhang, Hou Pong Chan, Chaoqun Liu, Lidong Bing, Deli Zhao, Anh Tuan Luu, Yu Rong

## 用于斯拉夫语形态素分割的 BERT 类模型。
BERT-like Models for Slavic Morpheme Segmentation
Dmitry Morozov, Lizaveta Astapenka, Anna Glazkova, Timur Garipov, Olga Lyashevskaya

## 语言模型能够推理个体主义的人类价值观和偏好吗？
Can Language Models Reason about Individualistic Human Values and Preferences?
Liwei Jiang, Taylor Sorensen, Sydney Levine, Yejin Choi

## 论文题目：识别科学文本修订的可靠评估指标。
Identifying Reliable Evaluation Metrics for Scientific Text Revision
Leane Jourdan, Nicolas Hernandez, Florian Boudin, Richard Dufour

## 论文标题：TheoremExplainAgent：基于视频的多模态解释用于LLM定理理解。
TheoremExplainAgent: Towards Video-based Multimodal Explanations for LLM Theorem Understanding
Max Ku, Thomas Chong, Jonathan Leung, Krish Shah, Alvin Yu, Wenhu Chen

## 通过表示工程解锁大规模语言模型的通用长链推理能力。
Unlocking General Long Chain-of-Thought Reasoning Capabilities of Large Language Models via Representation Engineering
Xinyu Tang, Xiaolei Wang, Zhihao Lv, Yingqian Min, Xin Zhao, Binbin Hu, Ziqi Liu, Zhiqiang Zhang

## 冰山一角：揭示一类隐藏的基于提示的对抗攻击任务类别。
The TIP of the Iceberg: Revealing a Hidden Class of Task-in-Prompt Adversarial Attacks on LLMs
Sergey Berezin, Reza Farahbakhsh, Noel Crespi

## Drift：通过双奖赏概率推理增强LLM在生成推理过程中的忠诚度。
Drift: Enhancing LLM Faithfulness in Rationale Generation via Dual-Reward Probabilistic Inference
Jiazheng Li, Hanqi Yan, Yulan He

## 通过差异意识实现公平：测量LLMs中的期望组别歧视。
Fairness through Difference Awareness: Measuring $\\textit{Desired}$ Group Discrimination in LLMs
Angelina Wang, Michelle Phan, Daniel E. Ho, Sanmi Koyejo

## 论文标题：代码奖励建模中单元测试的动力学缩放。
Dynamic Scaling of Unit Tests for Code Reward Modeling
Zeyao Ma, Xiaokang Zhang, Jing Zhang, Jifan Yu, Sijia Luo, Jie Tang

## MergePrint：具有鲁棒黑盒大型语言模型所有权验证的合并抵抗指纹技术。
MergePrint: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models
Shojiro Yamabe, Futa Kai Waseda, Tsubasa Takahashi, Koki Wataoka

## 追踪生命起起落落：从社交媒体帖子中挖掘生活事件以分析心理健康。
Tracking Life’s Ups and Downs: Mining Life Events from Social Media Posts for Mental Health Analysis
Minghao Lv, Siyuan Chen, Haoan Jin, Minghao Yuan, Qianqian Ju, Yujia Peng, Kenny Q. Zhu, Mengyue Wu

## UniConv：统一对话中检索与响应生成的大语言模型方法。
UniConv: Unifying Retrieval and Response Generation for Large Language Model in Conversation
Fengran Mo, Yifan Gao, Chuan Meng, Xin Liu, Zhuofeng Wu, Kelong Mao, Zhengyang Wang, Pei Chen, Zheng Li, Xian Li, Bing Yin, Meng Jiang

## 对组合句法变压器语言模型的系统性研究。
A Systematic Study of Compositional Syntactic Transformer Language Models
Yida Zhao, Hao Xve, Xiang Hu, Kewei Tu

## SongComposer：用于歌曲创作的歌词和旋律生成大规模语言模型。
SongComposer: A Large Language Model for Lyric and Melody Generation in Song Composition
Shuangrui Ding, Zihan Liu, Xiaoyi Dong, Pan Zhang, Rui Qian, Junhao Huang, Conghui He, Dahua Lin, Jiaqi Wang

## 超越事实：评估大型语言模型中的意图幻觉。
Beyond Facts: Evaluating Intent Hallucination in Large Language Models
Yijie Hao, Haofei Yu, Jiaxuan You

## 朝向同时独立实现零样本说话人克隆和零样本语言风格控制。
Towards Simultaneous and Independent Zero-shot Speaker Cloning and Zero-shot Language Style Control
Shengpeng Ji, Qian Chen, Wen Wang, Jialong Zuo, Minghui Fang, Ziyue Jiang, Hai Huang, Zehan Wang, Xize Cheng, Siqi Zheng, Zhou Zhao

## M-MAD：多维度多agents辩论评估高级机器翻译效果。
M-MAD: Multidimensional Multi-Agent Debate for Advanced Machine Translation Evaluation
Zhaopeng Feng, Jiayuan Su, Jiamei Zheng, Jiahan Ren, Yan Zhang, Jian Wu, Hongwei Wang, Zuozhu Liu

## PIC：通过位置ID压缩解锁大规模语言模型长文本生成能力。
PIC: Unlocking Long-Form Text Generation Capabilities of Large Language Models via Position ID Compression
Haoran Que, Wenge Rong

## 学习重写：通用LLM生成文本检测。
Learning to Rewrite: Generalized LLM-Generated Text Detection
Wei Hao, Ran Li, Weiliang Zhao, Junfeng Yang, Chengzhi Mao

## 朝向有效提取和评估事实性论断的研究
Towards Effective Extraction and Evaluation of Factual Claims
Dasha Metropolitansky, Jonathan Larson

## 混合偏好：学习如何路由实例以获取人类与AI的反馈。
Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback
Lester James Validad Miranda, Yizhong Wang, Yanai Elazar, Sachin Kumar, Valentina Pyatkin, Faeze Brahman, Noah A. Smith, Hannaneh Hajishirzi, Pradeep Dasigi

## 个性化文本生成与对比激活导向。
Personalized Text Generation with Contrastive Activation Steering
Jinghao Zhang, Yuting Liu, Wenjie Wang, Qiang Liu, Shu Wu, Liang Wang, Tat-Seng Chua

## SEOE：一种面向开放域事件检测的可扩展且可靠的语义评估框架。
SEOE: A Scalable and Reliable Semantic Evaluation Framework for Open Domain Event Detection
Yi-Fan Lu, Xian-Ling Mao, Tian Lan, Tong Zhang, Yu-Shi Zhu, Heyan Huang

## 格伯尔重新排序：可微端到端重新排序优化。
Gumbel Reranking: Differentiable End-to-End Reranker Optimization
Siyuan Huang, Zhiyuan Ma, Jintao Du, Changhua Meng, Weiqiang Wang, Jingwen Leng, Minyi Guo, Zhouhan Lin

## 义务论关键词偏差：模态动词对语言模型规范判断的影响。
Deontological Keyword Bias: The Impact of Modal Verbs on Normative Judgments of Language Models
Bumjin Park, Leejinsil, Jaesik Choi

## DRAG：从大规模语言模型精炼RAG以转移知识并基于证据和图精练减轻幻觉效应。
DRAG: Distilling RAG for SLMs from LLMs to Transfer Knowledge and Mitigate Hallucination via Evidence and Graph-based Distillation
Jennifer Chen, Aidar Myrzakhan, Yaxin Luo, Hassaan Muhammad Khan, Sondos Mahmoud Bsharat, Zhiqiang Shen

## UD-新闻抓取语料库：大规模Tagalog语法标注项目的反思与挑战。
The UD-NewsCrawl Treebank: Reflections and Challenges from a Large-scale Tagalog Syntactic Annotation Project
Angelina Aspra Aquino, Lester James Validad Miranda, Elsie Marie T. Or

## G-Safeguard：面向LLM基于多智能体系统的拓扑导向安全透镜与治疗方法。
G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems
Shilong Wang, Guibin Zhang, Miao Yu, Guancheng Wan, Fanci Meng, chongye guo, Kun Wang, Yang Wang

## Rolling the DICE on Idiomatic on: How LLMsials Fail to ongr Context.\n\n译文：\n标题：利用语义上的滚DICE：关于预训练语言模型未能理解背景内容。\n\n注释：“这里ICE在此处应为Dice的的缩写，ICE，但\"DICE\"在中文中并没有直接对应的含义，因此在翻译时时词语时时采取意译方式D并将原考虑到其名称来源是Dice（所以我们保留Dice词汇D在此加上语义上的D以以强调其在语义理解上的问题。
Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context
Maggie Mi, Aline Villavicencio, Nafise Sadat Moosavi

## 有偏见的语言模型可能影响政治决策。
Biased LLMs can Influence Political Decision-Making
Jillian Fisher, Shangbin Feng, Robert Aron, Thomas Richardson, Yejin Choi, Daniel W Fisher, Jennifer Pan, Yulia Tsvetkov, Katharina Reinecke

## LegalReasoner：逐步验证修正的法律判决推理。
LegalReasoner: Step-wised Verification-Correction for Legal Judgment Reasoning
Weijie Shi, Han Zhu, Jiaming Ji, Mengze Li, Jipeng Zhang, Ruiyuan Zhang, Jia Zhu, Jiajie Xu, Sirui Han, Yike Guo

## ChartCoder：促进图表到代码生成的多模态大型语言模型。
ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code Generation
Xuanle Zhao, Xianzhen Luo, Qi Shi, Chi Chen, Shuo Wang, Zhiyuan Liu, Maosong Sun

## 跨语言中动画性在语法结构中的作用。
The Cross-linguistic Role of Animacy in Grammar Structures
Nina Gregorio, Matteo Gay, Sharon Goldwater, Edoardo Ponti

## 在自然语言对话中挖掘论辩推理的复杂模式。
Mining Complex Patterns of Argumentative Reasoning in Natural Language Dialogue
Ramon Ruiz-Dolz, Zlata Kikteva, John Lawrence

## 如何有效地训练长上下文语言模型。
How to Train Long-Context Language Models (Effectively)
Tianyu Gao, Alexander Wettig, Howard Yen, Danqi Chen

## LexGen：基于领域知识的多语言词典生成。
LexGen: Domain-aware Multilingual Lexicon Generation
Ayush Maheshwari, Atul Kumar Singh, N J Karthika, Krishnakant Bhatt, Preethi Jyothi, Ganesh Ramakrishnan

## 统一语义表示能否帮助GPT 4 翻译原住民语言？
Can Uniform Meaning Representation Help GPT-4 Translate from Indigenous Languages?
Shira Wein

## OS代理：基于MLLM的计算机、手机和浏览器用代理综述。
OS Agents: A Survey on MLLM-based Agents for Computer, Phone and Browser Use
Xueyu Hu, Tao Xiong, Biao Yi, Ruixuan Xiao, Zishu Wei, Yurun Chen, Jiasheng Ye, Meiling Tao, Xiangxin Zhou, Ziyu Zhao, Yuhuai Li, Shengze Xu, Shenzhi Wang, Xinchen Xu, Shuofei Qiao, Zhaokai Wang, Kun Kuang, Tieyong Zeng, Liang Wang, Jiwei Li, Yuchen Eleanor Jiang, Wangchunshu Zhou, Guoyin Wang, Keting Yin, Zhou Zhao, Hongxia Yang, Fan Wu, Shengyu Zhang, Fei Wu

## 论文题目翻译如下：\n多语言语音数据集中数据质量的问题：社会语言学意识和前瞻性语言规划的必要性。
Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning
Mingfei Lau, Qian Chen, Yeming Fang, Tingting Xu, Tongzhou Chen, Pavel Golik

## LLM 作为一种Broken Telephone：迭代生成扭曲信息。
LLM as a Broken Telephone: Iterative Generation Distorts Information
Amr Mohamed, Mingmeng Geng, Michalis Vazirgiannis, Guokan Shang

## MathFusion：通过指令融合提升LLM的数学问题解决能力。
MathFusion: Enhancing Mathematical Problem-solving of LLM through Instruction Fusion
Qizhi Pei, Lijun Wu, Zhuoshi Pan, Yu Li, Honglin Lin, Chenlin Ming, Xin Gao, Conghui He, Rui Yan

## 变废为宝：通过_token回收_加速大规模语言模型推理。
Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling
Xianzhen Luo, Yixuan Wang, Qingfu Zhu, Zhiming Zhang, Xuanyu Zhang, Qing Yang, Dongliang Xu

## 缓解合成数据中的分布偏移以提高机器翻译质量估计。
Alleviating Distribution Shift in Synthetic Data for Machine Translation Quality Estimation
Xiang Geng, Zhejian Lai, Jiajun Chen, Hao Yang, Shujian Huang

## VLM2-Bench：更深入探究VLM如何隐式链接显式视觉匹配线索。
VLM2-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues
Jianshu Zhang, Dongyu Yao, Renjie Pi, Paul Pu Liang, Yi R. Fung

## 超越结果：透明评估大语言模型在游戏中的推理能力。
Beyond Outcomes: Transparent Assessment of LLM Reasoning in Games
Wenye Lin, Jonathan Roberts, Yunhan Yang, Samuel Albanie, Zongqing Lu, Kai Han

## 结合领域向量和对齐向量能在大语言模型中提供更好的知识安全性权衡。
Combining Domain and Alignment Vectors Provides Better Knowledge-Safety Trade-offs in LLMs
Megh Thakkar, Quentin Fournier, Matthew Riemer, Pin-Yu Chen, Amal Zouaq, Payel Das, Sarath Chandar

## 翻译和融合改进跨语言信息提取。
Translation and Fusion Improves Cross-lingual Information Extraction
Yang Chen, Vedaant Shah, Alan Ritter

## ActiView：评估多模态大型语言模型的主动感知能力。
ActiView: Evaluating Active Perception Ability for Multimodal Large Language Models
Ziyue Wang, Chi Chen, Fuwen Luo, Yurui Dong, Yuanchi Zhang, Yuzhuang Xu, Xiaolong Wang, Peng Li, Yang Liu

## 足够的 coin 掷可以令大模型行为呈现贝叶斯特性。
Enough Coin Flips Can Make LLMs Act Bayesian
Ritwik Gupta, Rodolfo Corona, Jiaxin Ge, Eric Wang, Dan Klein, Trevor Darrell, David M. Chan

## 阿拉伯文化中的常识推理。
Commonsense Reasoning in Arab Culture
Abdelrahman Sadallah, Junior Cedric Tonga, Khalid Almubarak, Saeed Almheiri, Farah Atif, Chatrine Qwaider, Karima Kadaoui, Sara Shatnawi, Yaser Alesh, Fajri Koto

## 一段文本相当于多个标记：从大规模语言模型中获得的文本嵌入secretly与关键标记高度对齐。
A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns Well with The Key Tokens
Zhijie Nie, Richong Zhang, Zhanyu Wu

## AXIS：以API优先的LLM基础代理实现高效的人机互动。
AXIS: Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents
Junting Lu, Zhiyang Zhang, Fangkai Yang, Jue Zhang, Lu Wang, Chao Du, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

## 在没有人类帮助的情况下，大型语言模型难以描述 haystack：一种受社会科学启发的主题模型评估。
LLMs Struggle to Describe the Haystack without Human Help: A Social Science-Inspired Evaluation of Topic Models
Zongxia Li, Lorena Calvo-Bartolomé, Alexander Miserlis Hoyle, Paiheng Xu, Daniel Kofi Stephens, Juan Francisco Fung, Alden Dima, Jordan Lee Boyd-Graber

## 通过几何嵌入实现的条件二分量化。
Conditional Dichotomy Quantification via Geometric Embedding
Shaobo Cui, Wenqing Liu, Yiyang Feng, Jiawei Zhou, Boi Faltings

## 通过指令训练数据提炼端到端语音助手。
Distilling an End-to-End Voice Assistant Without Instruction Training Data
William Barr Held, Yanzhe Zhang, Weiyan Shi, Minzhi Li, Michael J Ryan, Diyi Yang

## CoMet：基于隐喻的多智能体语言游戏隐蔽通信方法。
CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games
Shuhang Xu, Fangwei Zhong

## VQAGuider：引导多模态大型语言模型回答复杂视频问题。
VQAGuider: Guiding Multimodal Large Language Models to Answer Complex Video Questions
Yuyan Chen, Jiyuan Jia, Jiaxin Lu, Siyue Li, Yu Guan, Ming Yang, Qingpei Guo

## 大型语言模型是优秀的关系学习者。
Large Language Models are Good Relational Learners
Fang Wu, Vijay Prakash Dwivedi, Jure Leskovec

## 根据用户生成内容中的隐含偏好对大型语言模型进行对齐。
Aligning Large Language Models with Implicit Preferences from User-Generated Content
Zhaoxuan Tan, Zheng Li, Tianyi Liu, Haodong Wang, Hyokun Yun, Ming Zeng, Pei Chen, Zhihan Zhang, Yifan Gao, Ruijie Wang, Priyanka Nigam, Bing Yin, Meng Jiang

## CER：增强置信度的 reasoning 在大语言模型中的应用。
CER: Confidence Enhanced Reasoning in LLMs
Ali Razghandi, Seyed Mohammad Hadi Hosseini, Mahdieh Soleymani Baghshah

## LLM正位器：通过相关子更新校正LLM预测。
LLM Braces: Straightening Out LLM Predictions with Relevant Sub-Updates
Ying Shen, Lifu Huang

## 关于特定领域生成检索的合成数据策略。
On Synthetic Data Strategies for Domain-Specific Generative Retrieval
Haoyang Wen, Jiang Guo, Yi Zhang, Jiarong Jiang, Zhiguo Wang

## 大型语言模型中的水印技术：一种无偏见且低风险的方法。
Watermarking Large Language Models: An Unbiased and Low-risk Method
Minjia Mao, Dongjun Wei, Zeyu Chen, Xiao Fang, Michael Chau

## 评估不确定心灵理论：从对话线索预测他人的不确定信念。
Evaluating Theory of (an uncertain) Mind: Predicting the Uncertain Beliefs of Others from Conversational Cues
Anthony Sicilia, Malihe Alikhani

## CONFETTI：通过回合级交互进行对话功能调用评估。
CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions
Tamer Alkhouli, Katerina Margatina, James Gung, Raphael Shu, Claudia Zaghi, MONICA SUNKARA, Yi Zhang

## AGrail：一种有效的自适应安全检测终身代理护栏。
AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection
Weidi Luo, Shenghong Dai, Xiaogeng Liu, Suman Banerjee, Huan Sun, Muhao Chen, Chaowei Xiao

## 因果关系中的不确定性：一个新的前沿。
Uncertainty in Causality: A New Frontier
Shaobo Cui, Luca Mouchel, Boi Faltings

## SynthesizeMe！诱导基于人设的提示以在大语言模型中构建个性化奖励模型。
SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward Models in LLMs
Michael J Ryan, Omar Shaikh, Aditri Bhagirath, Daniel Frees, William Barr Held, Diyi Yang

## 构建带有多类标签的长文本隐私政策语料库。
Building a Long Text Privacy Policy Corpus with Multi-Class Labels
David Stein, Florencia Marotta-Wurgler

## 当人类成了洪流：使用大型语言模型分析移民 discourse 中的人性化贬低隐喻。
When People are Floods: Analyzing Dehumanizing Metaphors in Immigration Discourse with Large Language Models
Julia Mendelsohn, Ceren Budak

## x-SAL：通过跨语言符号辅助语言模型引领符号推理 Across Languages。
x-SAL: Leading Symbolic Reasoning across Languages via Cross-lingual Symbolic-Aided Language Model
Leonardo Ranaldi, Giulia Pucci

## 跨语言陷阱：多语言大型语言模型的自动探查跨语言薄弱环节。
Cross-Lingual Pitfalls: Automatic Probing Cross-Lingual Weakness of Multilingual Large Language Models
Zixiang Xu, Yanbo Wang, Yue Huang, Xiuying Chen, Jieyu Zhao, Meng Jiang, Xiangliang Zhang

## 通过细粒度评判基础评估器提高模型事实性。
Improving Model Factuality with Fine-grained Critique-based Evaluator
Yiqing Xie, Wenxuan Zhou, Pradyot Prakash, Di Jin, Yuning Mao, Quintin Fettes, Arya Talebzadeh, Sinong Wang, Han Fang, Carolyn Rose, Daniel Fried, Hejia Zhang

## 阴谋论及其在TikTok上的传播途径。
Conspiracy Theories and Where to Find Them on TikTok
Francesco Corso, Francesco Pierri, Gianmarco De Francisci Morales

## 数据清洗：通过知识蒸馏人工提升基准结果。
Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation
Jonibek Mansurov, Akhmed Sakip, Alham Fikri Aji

## VLSBench：揭示多模态安全中的视觉泄漏。
VLSBench: Unveiling Visual Leakage in Multimodal Safety
Xuhao Hu, Dongrui Liu, Hao Li, Xuanjing Huang, Jing Shao

## 探索遗失的未形成回忆：舌尖现象搜索与推理的基准。
Browsing Lost Unformed Recollections: A Benchmark for Tip-of-the-Tongue Search and Reasoning
Sky CH-Wang, Darshan Girish Deshpande, Smaranda Muresan, Anand Kannappan, Rebecca Qian

## 当语言模型误解了人类的笑声：分析人类与语言模型的 garden path 效应。
When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models
Samuel Joseph Amouyal, Aya Meltzer-Asscher, Jonathan Berant

## 通过弹窗攻击视觉语言计算机代理。
Attacking Vision-Language Computer Agents via Pop-ups
Yanzhe Zhang, Tao Yu, Diyi Yang

## 过去与未来的视角：长期内存管理以实现个性化对话代理的反思性\nOMPI
In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents
Zhen Tan, Jun Yan, I-Hung Hsu, Rujun Han, Zifeng Wang, Long Le, Yiwen Song, Yanfei Chen, Hamid Palangi, George Lee, Anand Rajan Iyer, Tianlong Chen, huan liu, Chen-Yu Lee, Tomas Pfister

## 通过经验成长：在语言模型中扩展事件接地。
Growing Through Experience: Scaling Episodic Grounding in Language Models
Chunhui Zhang, Sirui Wang, Zhongyu Ouyang, Xiangchi Yuan, Soroush Vosoughi

## 将LLM用作生物医学实体消歧系统的实体链接工具。
LLM as Entity Disambiguator for Biomedical Entity-Linking
Christophe Ye, Cassie S. Mitchell

## 评估代理：视觉生成模型的高效可调用评估框架。
Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models
Fan Zhang, Shulin Tian, Ziqi Huang, Yu Qiao, Ziwei Liu

## 朝向地理文化基础的大语言模型生成。
Towards Geo-Culturally Grounded LLM Generations
Piyawat Lertvittayakumjorn, David Kinney, Vinodkumar Prabhakaran, Donald Martin Jr., Sunipa Dev

## 论文标题：检索增强生成中的不可回答性评估。
Unanswerability Evaluation for Retrieval Augmented Generation
XIANGYU PENG, Prafulla Kumar Choubey, Caiming Xiong, Chien-Sheng Wu

## 挖掘阴影：通过大型语言模型中低排名令牌揭露隐私泄漏。
Exploiting the Shadows: Unveiling Privacy Leaks through Lower-Ranked Tokens in Large Language Models
Yuan Zhou, ZHUO ZHANG, Xiangyu Zhang

## 自我错误指导：从错误中泛化以提高LLM的数学推理能力。
Self-Error-Instruct: Generalizing from Errors for LLMs Mathematical Reasoning
Erxin Yu, Jing Li, Ming Liao, Qi Zhu, Boyang XUE, Minghui Xu, Baojun Wang, Lanqing HONG, Fei Mi, Lifeng Shang

## 显式和隐式数据增强在社会事件检测中的应用。
Explicit and Implicit Data Augmentation for Social Event Detection
Congbo Ma, Yuxia Wang, Jia Wu, Jian Yang, Jing Du, Zitai Qiu, Qing Li, Hu Wang, Preslav Nakov

## 论文标题：专利分析概览：从自然语言处理到多模态AI。
A Survey on Patent Analysis: From NLP to Multimodal AI
Homaira Huda Shomee, Zhu Wang, Sathya N. Ravi, Sourav Medya

## 借助古代文献信息 revisiting 经典中文事件抽取。
Revisiting Classical Chinese Event Extraction with Ancient Literature Information
Xiaoyi Bao, Zhongqing Wang, Jinghang Gu, Chu-Ren Huang

## RAGEval：基于场景的RAG评估数据集生成框架
RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework
Kunlun Zhu, Yifan Luo, Dingling Xu, Yukun Yan, Zhenghao Liu, Shi Yu, Ruobing Wang, Shuo Wang, Yishan Li, Nan Zhang, Xu Han, Zhiyuan Liu, Maosong Sun

## MultiAgentBench：评估LLM代理之间的协作与竞争。
MultiAgentBench : Evaluating the Collaboration and Competition of LLM agents
Kunlun Zhu, Hongyi Du, Zhaochen Hong, Xiaocheng Yang, Shuyi Guo, Zhe Wang, Zhenhailong Wang, Cheng Qian, Xiangru Tang, Heng Ji, Jiaxuan You

## SpaRE：通过合成数据增强视觉-语言模型的空间推理能力。
SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data
Michael Ogezi, Freda Shi

## SCALE：朝着大规模语言模型代理与人类干预相结合的社会科学合作内容分析迈进。
SCALE: Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention
Chengshuai Zhao, Zhen Tan, Chau-Wai Wong, Xinyan Zhao, Tianlong Chen, huan liu

## 僧伽罗语编码器-only 语言模型及评估
Sinhala Encoder-only Language Models and Evaluation
Tharindu Ranasinghe, Hansi Hettiarachchi, Nadeesha Chathurangi Naradde Vidana Pathirana, Damith Premasiri, Lasitha Uyangodage, Isuri Nanomi Arachchige, Alistair Plum, Paul Rayson, Ruslan Mitkov

## SEUF：混合专家大型语言模型中卸载一个专家足够吗？
SEUF: Is Unlearning One Expert Enough for Mixture-of-Experts LLMs?
Haomin Zhuang, Yihua Zhang, Kehan Guo, Jinghan Jia, Gaowen Liu, Sijia Liu, Xiangliang Zhang

## SciVer：评估基础模型在多模态科学主张验证中的性能。
SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification
Chengye Wang, Yifei Shen, Zexi Kuang, Arman Cohan, Yilun Zhao

## 理解针对低资源语言的上下文内机器翻译：满语案例研究
Understanding In-context Machine Translation for Low-Resource Languages: A Case Study on Manchu
Renhao Pei, Yihong Liu, Peiqin Lin, François Yvon, Hinrich Schuetze

## 大型语言模型可以在多维度上执行分析写作评估：关于二语研究生学术英语写作的案例研究。
LLMs can Perform Multi-Dimensional Analytic Writing Assessments: A Case Study of L2 Graduate-Level Academic English Writing
Zhengxiang Wang, Veronika Makarova, Zhi Li, Jordan Kodner, Owen Rambow

## 注意差距：静态与互动评估大规模音频模型
Mind the Gap: Static and Interactive Evaluations of Large Audio Models
Minzhi Li, William Barr Held, Michael J Ryan, Kunat Pipatanakul, Potsawee Manakul, Hao Zhu, Diyi Yang

## 在大型语言模型时代的话语理论：关于数据集、评估、机遇与挑战的综述。
Pragmatics in the Era of Large Language Models: A Survey on Datasets, Evaluation, Opportunities and Challenges
Bolei Ma, Yuting Li, Wei Zhou, Ziwei Gong, Yang Janet Liu, Katja Jasinskaja, Annemarie Friedrich, Julia Hirschberg, Frauke Kreuter, Barbara Plank

## MUSTS：多语言语义文本相似度基准。
MUSTS: MUltilingual Semantic Textual Similarity Benchmark
Tharindu Ranasinghe, Hansi Hettiarachchi, Constantin Orasan, Ruslan Mitkov

## LocAgent：图引导的大语言模型代理代码定位。
LocAgent: Graph-Guided LLM Agents for Code Localization
Zhaoling Chen, Xiangru Tang, Gangda Deng, Fang Wu, Jialong Wu, Zhiwei Jiang, Viktor Prasanna, Arman Cohan, Xingyao Wang

## 大型语言模型能否准确生成健康相关问题的答案键？
Can Large Language Models Accurately Generate Answer Keys for Health-related Questions?
Davis Bartels, Deepak Gupta, Dina Demner-Fushman

## TripleFact：防御LLM驱动的假新闻检测评估中的数据污染
TripleFact: Defending Data Contamination in the Evaluation of LLM-driven Fake News Detection
Cheng Xu, Nan Yan

## 基于大规模语言和推理模型的系统关系推理基准测试。
Benchmarking Systematic Relational Reasoning with Large Language and Reasoning Models
Irtaza Khalid, Amir Masoud Nourollah, Steven Schockaert

## CKnowEdit：一种用于纠正LLM中汉语语言、事实和逻辑错误的新知识编辑数据集。
CKnowEdit: A New Chinese Knowledge Editing Dataset for Linguistics, Facts, and Logic Error Correction in LLMs
Jizhan Fang, Tianhe Lu, Yunzhi Yao, Ziyan Jiang, Xin Xu, Huajun Chen, Ningyu Zhang

## 超越真值条件的意义：通过消解指承性评估话语层级理解。
Meaning Beyond Truth Conditions: Evaluating Discourse Level Understanding via Anaphora Accessibility
Xiaomeng Zhu, Zhenghao Zhou, Simon Charlow, Robert Frank

## BRIGHTER\n\n: BR Bridging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 2 2 8 Languages.
BRIGHTER: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages
Shamsuddeen Hassan Muhammad, Nedjma Ousidhoum, Idris Abdulmumin, Jan Philip Wahle, Terry Ruas, Meriem Beloucif, Christine de Kock, Nirmal Surange, Daniela Teodorescu, Ibrahim Said Ahmad, David Ifeoluwa Adelani, Alham Fikri Aji, Felermino D. M. A. Ali, Ilseyar Alimova, Vladimir Araujo, Nikolay Babakov, Naomi Baes, Ana-Maria Bucur, Andiswa Bukula, Guanqun Cao, Rodrigo Tufiño, Rendi Chevi, Chiamaka Ijeoma Chukwuneke, Alexandra Ciobotaru, Daryna Dementieva, Murja Sani Gadanya, Robert Geislinger, Bela Gipp, Oumaima Hourrane, Oana Ignat, Falalu Ibrahim Lawan, Rooweither Mabuya, Rahmad Mahendra, Vukosi Marivate, Alexander Panchenko, Andrew Piper, Charles Henrique Porto Ferreira, Vitaly Protasov, Samuel Rutunda, Manish Shrivastava, Aura Cristina Udrea, Lilian Diana Awuor Wanzare, Sophie Wu, Florian Valentin Wunderlich, Hanif Muhammad Zhafran, Tianhui Zhang, Yi Zhou, Saif M. Mohammad

## 预热生成：一种面向任务的无监督初始状态生成方法，用于引导序列到序列的学习。
Warmup Generations: A Task-Agnostic Approach for Guiding Sequence-to-Sequence Learning with Unsupervised Initial State Generation
Senyu Li, Zipeng Sun, Jiayi Wang, Xue Liu, Pontus Stenetorp, Siva Reddy, David Ifeoluwa Adelani

## 大型语言模型在心理评估方面是否有效？借助自适应RAG实现可解释的心理健康筛查。
Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice
Federico Ravenda, Seyed Ali Bahrainian, Andrea Raballo, Antonietta Mira, Noriko Kando

## SkillVerse：评估与提升语言模型的树评价方法。
SkillVerse : Assessing and Enhancing LLMs with Tree Evaluation
Yufei Tian, Jiao Sun, Nanyun Peng, Zizhao Zhang

## INTERACT：使大型语言模型能够进行交互式、以问题驱动的学习。
INTERACT: Enabling Interactive, Question-Driven Learning in Large Language Models
Aum Kendapadi, Kerem Zaman, Rakesh R Menon, Shashank Srivastava

## 论文标题翻译：多元视角下的共情预测。
Empathy Prediction from Diverse Perspectives
Francine Chen, Scott Carter, Tatiana Lau, Nayeli Suseth Bravo, Sumanta Bhattacharyya, Kate Sieck, Charlene C. Wu

## 构建更优资源：在数据稀缺时避免开发语言资源的 pitfalls。 \n\n注：此处“pitfalls”在上下文中意为“陷阱”或“误区”，直译为“陷井”不够自然，故翻译为“误区”。
Building Better: Avoiding Pitfalls in Developing Language Resources when Data is Scarce
Nedjma Ousidhoum, Meriem Beloucif, Saif M. Mohammad

## 电路稳定性表征语言模型的泛化能力。
Circuit Stability Characterizes Language Model Generalization
Alan Sun

## CypherBench：在大规模现代知识图谱中迈向LLM时代精确检索的新方法。
CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era
Yanlin Feng, Simone Papicchio, Sajjadur Rahman

## 使用正式的句法学理论比较生成式大模型和人类撰写的新闻文本。
Comparing LLM-generated and human-authored news text using formal syntactic theory
Olga Zamaraeva, Dan Flickinger, Francis Bond, Carlos Gómez-Rodríguez

## 通过分类探针识别潜在知识以提高LLMs的偏好提取。
Improving Preference Extraction In LLMs By Identifying Latent Knowledge Through Classifying Probes
Sharan Maiya, Yinhong Liu, Ramit Debnath, Anna Korhonen

## 密集检索的崩溃：短语、early（可能为文章中的错误，应为“early” 或“长”）和文字偏向超越事实依据。
Collapse of Dense Retrievers: Short, Early, and Literal Biases Outranking Factual Evidence
Mohsen Fayyaz, Ali Modarressi, Hinrich Schuetze, Nanyun Peng

## SelfElicit：你的语言模型悄悄知道哪些是相关证据。
SelfElicit: Your Language Model Secretly Knows Where is the Relevant Evidence
Zhining Liu, Rana Ali Amjad, Ravinarayana Adkathimar, Tianxin Wei, Hanghang Tong

## 少量的人类数据效果显著。
A Little Human Data Goes A Long Way
Dhananjay Ashok, Jonathan May

## 男CEO与女助理：双人主体的文字-to-图像生成中性别偏见的评估与缓解。
The Male CEO and the Female Assistant: Evaluation and Mitigation of Gender Biases in Text-To-Image Generation of Dual Subjects
Yixin Wan, Kai-Wei Chang

## 通过插值学习减轻捷径学习。
Mitigating Shortcut Learning with InterpoLated Learning
Michalis Korakakis, Andreas Vlachos, Adrian Weller

## 论文标题：白人男性领导，黑人女性相助？LLM中语言代理社会偏见的基准测试与缓解。
White Men Lead, Black Women Help? Benchmarking and Mitigating Language Agency Social Biases in LLMs
Yixin Wan, Kai-Wei Chang

## AIMSCheck：利用大语言模型进行跨司法辖区的现代奴隶制声明的人工智能辅助审查。
AIMSCheck: Leveraging LLMs for AI-Assisted Review of Modern Slavery Statements Across Jurisdictions
Adriana Eufrosina Bora, Akshatha Arodi, Duoyi Zhang, Jordan Bannister, Mirko Bronzi, Arsene Fansi Tchango, Md Abul Bashar, Richi Nayak, Kerrie Mengersen

## DiffuseDef：通过迭代去噪提高对抗攻击的鲁棒性\n
DiffuseDef: Improved Robustness to Adversarial Attacks via Iterative Denoising
Zhenhao Li, Huichi Zhou, Marek Rei, Lucia Specia

## 在空间转录组学中识别细胞龛：大型语言模型能力探究。
Identifying Cellular Niches in Spatial Transcriptomics: An Investigation into the Capabilities of Large Language Models
Huanhuan Wei, Xiao Luo, Hongyi Yu, Jinping Liang, Luning Yang, Lixing Lin, Alexandra Popa, Xiting Yan

## 朝自动发现犬吠字母表的目标迈进。
Toward Automatic Discovery of a Canine Phonetic Alphabet
Theron S. Wang, Xingyuan Li, Hridayesh Lekhak, Tuan Minh Dang, Mengyue Wu, Kenny Q. Zhu

## 字节潜 transformer：patches 比 tokens 更具扩展性。
Byte Latent Transformer: Patches Scale Better Than Tokens
Artidoro Pagnoni, Ramakanth Pasunuru, Pedro Rodriguez, John Nguyen, Benjamin Muller, Margaret Li, Chunting Zhou, LILI YU, Jason E Weston, Luke Zettlemoyer, Gargi Ghosh, Mike Lewis, Ari Holtzman, Srini Iyer

## Bitnet.cpp：高效的三值LLMs边iffinference算法。 \n\n注意 kuk邻隔，，，字“edge inference”在不同专具业专术语，这这hol一很般般般般般般般般般般般般贯通广泛的理解为“边erinference”或“边缘推理”，在机器学习领域中的具体含义可能需要根据上下文进一步确认 kuk邻隔.ne
Bitnet.cpp: Efficient Edge Inference for Ternary LLMs
Jinheng Wang, Hansong Zhou, Ting Song, Shijie Cao, Yan Xia, Ting Cao, Jianyu Wei, Shuming Ma, Hongyu Wang, Furu Wei

## COSMMIC：考虑评论的多模态多语言印度语语料库，用于总结和标题生成
COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation
Raghvendra Kumar, Mohammed Salman S A, Aryan Sahu, Tridib Nandi, Pragathi Y P, Sriparna Saha, Jose G Moreno

## 文化因素在 Persian 有毒语言检测中的重要性。
Culture Matters in Toxic Language Detection in Persian
Zahra Bokaei, Walid Magdy, Bonnie Webber

## 发展合理的工件记忆形成了语言习得的关键期。
Developmentally-plausible Working Memory Shapes a Critical Period for Language Acquisition
Masato Mita, Ryo Yoshida, Yohei Oseki

## 通过长上下文语言模型进行文学证据检索。
Literary Evidence Retrieval via Long-Context Language Models
Katherine Thai, Mohit Iyyer

## LLM + 个性插件 = 个性化LLM。
LLMs + Persona-Plug = Personalized LLMs
Jiongnan Liu, Yutao Zhu, Shuting Wang, Xiaochi Wei, Erxue Min, Yu Lu, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou

## 受实例选择启发的欠采样策略：减少二元文本分类中小型和大型语言模型的偏差。
Instance-Selection-Inspired Undersampling Strategies for Bias Reduction in Small and Large Language Models for Binary Text Classification
Guilherme Fonseca, Washington Cunha, Gabriel Prenassi, Marcos André Gonçalves, Leonardo Chaves Dutra da Rocha

## 正向预测高效的反向路径：基于重要性指导的大语言模型记忆高效微调。
Forward Knows Efficient Backward Path: Saliency-Guided Memory-Efficient Fine-tuning of Large Language Models
Yeachan Kim, SangKeun Lee

## 通过查询引导激活补充以增强长上下文信息查询。
Boosting Long-Context Information Seeking via Query-Guided Activation Refilling
Hongjin Qian, Zheng Liu, Peitian Zhang, Zhicheng Dou, Defu Lian

## AdaDHP：通过双哈达玛乘积和自适应参数选择的精细微调。
AdaDHP: Fine-Grained Fine-Tuning via Dual Hadamard Product and Adaptive Parameter Selection
Han Liu, Changya Li, Xiaotong Zhang, Feng Zhang, Fenglong Ma, Wei Wang, Hong Yu

## KG-Agent：一种高效的复杂知识图推理自主代理框架
KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph
Jinhao Jiang, Kun Zhou, Xin Zhao, Yang Song, Chen Zhu, Hengshu Zhu, Ji-Rong Wen

## INJONGO：一种针对16种非洲语言的多文化意图检测和槽填充数据集。
INJONGO: A Multicultural Intent Detection and Slot-filling Dataset for 16 African Languages
Hao Yu, Jesujoba Oluwadara Alabi, Andiswa Bukula, Jian Yun Zhuang, En-Shiun Annie Lee, Tadesse Kebede Guge, Israel Abebe Azime, Happy Buzaaba, Blessing Kudzaishe Sibanda, Godson Koffi KALIPE, Jonathan Mukiibi, Salomon KABONGO KABENAMUALU, Mmasibidi Setaka, Lolwethu Ndolela, Nkiruka Odu, Rooweither Mabuya, Shamsuddeen Hassan Muhammad, Salomey Osei, Sokhar Samb, Dietrich Klakow, David Ifeoluwa Adelani

## 通过多行动者协作进行语言模型预训练数据选择的高效方法。
Efficient Pretraining Data Selection for Language Models via Multi-Actor Collaboration
Tianyi Bai, Ling Yang, Zhen Hao Wong, Fupeng Sun, Xinlin Zhuang, Jiahui Peng, Chi Zhang, Lijun Wu, Qiu Jiantao, Wentao Zhang, Binhang Yuan, Conghui He

## 大型语言模型在因果发现中的可靠性研究。
On the Reliability of Large Language Models for Causal Discovery
Tao Feng, Lizhen Qu, Niket Tandon, Zhuang Li, Xiaoxi Kang, Gholamreza Haffari

## 关注关键信息：通过自动注意对齐调优提升医疗视觉语言模型。
Focus on What Matters: Enhancing Medical Vision-Language Models with Automatic Attention Alignment Tuning
Aofei Chang, Le Huang, Alex James Boyd, Parminder Bhatia, Taha Kass-Hout, Cao Xiao, Fenglong Ma

## 背景重要吗？一种名为ContextualJudgeBench的方法，用于评估基于LLM的法官在背景下的表现。
Does Context Matter? ContextualJudgeBench for Evaluating LLM-based Judges in Contextual Settings
Austin Xu, Srijan Bansal, Yifei Ming, Semih Yavuz, Shafiq Joty

## 将领域知识融入材料标记化。
Incorporating Domain Knowledge into Materials Tokenization
Yerim Oh, Jun-Hyung Park, Junho Kim, SungHo Kim, SangKeun Lee

## TeRDy：通过频域分解分析时间关系动态的知识图谱时间完成方法。
TeRDy: Temporal Relation Dynamics through Frequency Decomposition for Temporal Knowledge Graph Completion
Ziyang Liu, Chaokun Wang

## 困守之AI：以优化提示攻击破解实用多智能体LLM系统
Agents Under Siege: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks
Rana Shahroz, Zhen Tan, Sukwon Yun, Charles Fleming, Tianlong Chen

## 价值光谱：通过社会媒体情境中的价值分解量化视觉语言模型的偏好。
Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts
Jingxuan Li, Yuning Yang, Shengqi Yang, Linfan Zhang, Ying Nian Wu

## Semantic-Eval：一种无需训练的大语言模型语义理解评估框架。
Semantic-Eval : A Semantic Comprehension Evaluation Framework for Large Language Models Generation without Training
Shusheng Li, Jiale Li, Yifei Qu, Xinwei Shi, Yanliang Guo, Ziyi He, Yubo Wang, Wenjun Tan

## DavIR：基于隐式奖励的数据选择用于大型语言模型。
DavIR: Data Selection via Implicit Reward for Large Language Models
Haotian Zhou, Tingkai Liu, Qianli Ma, Yufeng Zhang, Jianbo Yuan, Pengfei Liu, Yang You, Hongxia Yang

## 一种用于大型语言模型即时推测解码适应的即插即用解决方案。
A Drop-In Solution for On-the-Fly Adaptation of Speculative Decoding in Large Language Models
Jiesong Liu, Brian Park, Xipeng Shen

## 介于电路与乔姆斯基之间：预先学习形式语言可灌输语言偏见。
Between Circuits and Chomsky: Pre-pretraining on Formal Languages Imparts Linguistic Biases
Michael Y. Hu, Jackson Petty, Chuan Shi, William Merrill, Tal Linzen

## 关于在大语言模型时代恶意社交文本检测中证据污染风险的研究。
On the Risk of Evidence Pollution for Malicious Social Text Detection in the Era of LLMs
Herun Wan, Minnan Luo, Zhixiong Su, Guang Dai, Xiang Zhao

## 注意力熵是关键因素：全全注意力基预训练语言模型的并行上下文编码分析。
Attention Entropy is a Key Factor: An Analysis of Parallel Context Encoding with Full-attention-based Pre-trained Language Models
Zhisong Zhang, Yan Wang, Xinting Huang, Tianqing Fang, Hongming Zhang, Chenlong Deng, Shuaiyi Li, Dong Yu

## 该说何时说，该沉默何时沉默：对比解码与沉默策略。
When to Speak, When to Abstain: Contrastive Decoding with Abstention
Hyuhng Joon Kim, Youna Kim, Sang-goo Lee, Taeuk Kim

## 使用基于大型语言模型的代理探究并拓展霍曼斯的社会交换理论。
Investigating and Extending Homans’ Social Exchange Theory with Large Language Model based Agents
Lei Wang, Zheqing Zhang, Xu Chen

## 使大型语言模型助理与个性化情境认知相一致。
Aligning VLM Assistants with Personalized Situated Cognition
Yongqi Li, Shen Zhou, Xiaohu Li, Xin Miao, Jintao Wen, Mayi Xu, Jianhao Chen, Birong Pan, Hankun Kang, Yuanyuan Zhu, Ming Zhong, Tieyun Qian

## 如果注意力作为一种认知模型来模拟人类记忆检索，那么合理的记忆表示是什么？
If Attention Serves as a Cognitive Model of Human Memory Retrieval, What is the Plausible Memory Representation?
Ryo Yoshida, Shinnosuke Isono, Kohei Kajikawa, Taiga Someya, Yushi Sugimoto, Yohei Oseki

## 通过精简候选树的有效草稿解码器实现更快的推测解码。
Faster Speculative Decoding via Effective Draft Decoder with Pruned Candidate Tree
Huanran Zheng, Xiaoling Wang

## 选择与合并：面向大型语言模型的可适应可扩展命名实体识别。
Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models
Zhuojun Ding, Wei Wei, Chenghao Fan

## IRIS：在缺乏表格数据情况下可验证因果发现的迭代综合框架。
IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery in the Absence of Tabular Data
Tao Feng, Lizhen Qu, Niket Tandon, Gholamreza Haffari

## 拥抱不完美：使用基于LLM的代理模拟具有不同认知水平的学生。
Embracing Imperfection: Simulating Students with Diverse Cognitive Levels Using LLM-based Agents
Tao Wu, Jingyuan Chen, Wang Lin, Mengze Li, Yumeng Zhu, Ang Li, Kun Kuang, Fei Wu

## CADReview：自动审查CAD程序并进行错误检测与修复。
CADReview: Automatically Reviewing CAD Programs with Error Detection and Correction
Jiali Chen, Xusen Hei, HongFei Liu, Yuancheng Wei, Zikun Deng, Jiayuan Xie, Yi Cai, Li Qing

## PIG：通过基于梯度的迭代上下文内优化进行的大语言模型隐私破解攻击。
PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization
Yidan Wang, Yanan Cao, Yubing Ren, Fang Fang, Zheng Lin, Binxing Fang

## Think&Cite：通过自我引导的树搜索和进步奖励建模改进标注文本生成。
Think&Cite: Improving Attributed Text Generation with Self-Guided Tree Search and Progress Reward Modeling
Junyi Li, Hwee Tou Ng

## 多级相关文档标识学习生成检索
Multi-level Relevance Document Identifier Learning for Generative Retrieval
Fuwei Zhang, Xiaoyu Liu, Xinyu Jia, Yingfei Zhang, Shuai Zhang, Xiang Li, Fuzhen Zhuang, Wei Lin, Zhao Zhang

## 课程去偏见：朝向在数据集偏见下更 robust 的参数高效微调。
Curriculum Debiasing: Toward Robust Parameter-Efficient Fine-Tuning Against Dataset Biases
Mingyu Lee, Yeachan Kim, Wing-Lam Mok, SangKeun Lee

## 优化每一个 facets 的 GEM：在 Korean 语言中测试 LLMs 和人类的语言能力。
Polishing Every Facet of the GEM: Testing Linguistic Competence of LLMs and Humans in Korean
SungHo Kim, Nayeon Kim, Taehee Jeon, SangKeun Lee

## 探索生成型MLLM如何使用相同的视觉编码器比CLIP感知更多内容。
Exploring How Generative MLLMs Perceive More Than CLIP with the Same Vision Encoder
Siting Li, Pang Wei Koh, Simon Shaolei Du

## 通过目标语言数据增强神经机器翻译：基于$k$NN-LM的方法在领域适应中的应用。
Enhancing Neural Machine Translation Through Target Language Data: A $k$NN-LM Approach for Domain Adaptation
Abudurexiti Reheman, Hongyu Liu, Junhao Ruan, Abudukeyumu Abudula, yingfeng luo, Tong Xiao, JingBo Zhu

## SpeechFake：一个集成了先进生成方法的大规模多语言语音换脸数据集。
SpeechFake: A Large-Scale Multilingual Speech Deepfake Dataset Incorporating Cutting-Edge Generation Methods
Wen Huang, Yanmei Gu, Zhiming Wang, Huijia Zhu, Yanmin Qian

## NexusSum：用于长文本叙述总结的层次化LLM代理。
NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization
Hyuntak Kim, Byung-Hak Kim

## InvestAlign：克服 herd 行为下投资者决策过程与大型语言模型对齐中数据稀缺性的问题。
InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes Under Herd Behavior
Huisheng Wang, Zhuoshi Pan, Hangjing Zhang, Mingxiao Liu, Hanqing Gao, H. Vicky Zhao

## Uni-Retrieval：面向STEM教育的多风格检索框架。
Uni-Retrieval: A Multi-Style Retrieval Framework for STEM’s Education
Yanhao Jia, Xinyi Wu, Li Hao, QinglinZhang, Yuxiao Hu, Shuai Zhao, Wenqi Fan

## 探索大型语言模型作为个性化助手的潜力：数据集、评估与分析。
Exploring the Potential of LLMs as Personalized Assistants: Dataset, Evaluation, and Analysis
Jisoo Mok, Ik-hwan Kim, Sangkwon Park, Sungroh Yoon

## EfficientQAT：面向大规模语言模型的高效量化感知训练。
EfficientQAT: Efficient Quantization-Aware Training for Large Language Models
Mengzhao Chen, Wenqi Shao, Peng Xu, Jiahao Wang, Peng Gao, Kaipeng Zhang, Ping Luo

## DenseLoRA：大型语言模型的密集低秩适应。
DenseLoRA: Dense Low-Rank Adaptation of Large Language Models
Lin Mu, Xiaoyu Wang, Li Ni, Yang Li, Zhize Wu, Peiquan Jin, Yiwen Zhang

## 关于下一词预测的支持样本研究。
On Support Samples of Next Word Prediction
Yuqian Li, Yupei Du, Yufang Liu, Feifei Feng, Mou Xiao Feng, Yuanbin Wu

## HAIC：通过更好的多模态标注提高人类动作理解和生成——借助大型语言模型。
HAIC: Improving Human Action Understanding and Generation with Better Captions for Multi-modal Large Language Models
Xiao Wang, Jingyun Hua, Weihong Lin, Yuanxing Zhang, Fuzheng Zhang, Jianlong Wu, Di ZHANG, Liqiang Nie

## WebWalker：评估LLM在网页导航中的表现。
WebWalker: Benchmarking LLMs in Web Traversal
Jialong Wu, Wenbiao Yin, Yong Jiang, Zhenglin Wang, Zekun Xi, Runnan Fang, Linhai Zhang, Yulan He, Deyu Zhou, Pengjun Xie, Fei Huang

## 破解事实性\nuser\n请翻译以下内容 kukai会议记录：KUKAI在日本推进AI伦理标准，，相关的主题发言嘉宾包括AI伦理专家、律师和政策制定者。这次会议的重点讨论了AI伦理标准在不同行业的应用。\n\n会议还强调，未来的AI应用除了满足现有的技术标准外，还还需遵守道德和伦理准则。此外，，一致性、透明度以及对多样性和包容性的支持也是关键考量因素。\n\n会议中还讨论了具体的标准和实践案例，以及未来可能的发展方向。这些问题讨论对推动AI伦理标准的国际化进程以及全球范围内AI的健康发展具有重要意义。\n\n总结，KUKAI在日本致力于制定和实施AI伦理标准，从而为全球范围内的AI应用提供更好的指导和规范。\n\n会议进一步指出，实现这些高标准的还需国际合作，包括立法、实施监督和公众参与。不仅是技术供应商还需行业合作伙伴和政策制定者共同努力。通过共同努力，KUKAI致力于在人类和AI共存的的未来中建立可信和可扩展的AI解决方案。
Cracking Factual Knowledge: A Comprehensive Analysis of Degenerate Knowledge Neurons in Large Language Models
Yuheng Chen, Pengfei Cao, Yubo Chen, Yining Wang, Shengping Liu, Kang Liu, Jun Zhao

## 从权衡到协同：一种适用于大型语言模型的多功能共生水印框架。
From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models
Yidan Wang, Yubing Ren, Yanan Cao, Binxing Fang

## 探究大型语言模型的合理证明：一种针对无监督跨域关键词生成的领域泛化方法。
Seeking Rational Demonstrations for Large Language Models: A Domain Generalization Approach to Unsupervised Cross-Domain Keyphrase Generation
Guangzhen Zhao, Yu Yao, Dechang Kong, Zhenjiang Dong

## ReflectionCoder：通过反射序列学习以增强一次性代码生成。
ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation
Houxing Ren, Mingjie Zhan, Zhongyuan Wu, Aojun Zhou, Junting Pan, Hongsheng Li

## 迈向上下文鲁棒的大型语言模型：一种门控表示微调方法。
Towards Context-Robust LLMs: A Gated Representation Fine-tuning Approach
Shenglai Zeng, Pengfei He, Kai Guo, Tianqi Zheng, Hanqing Lu, Yue Xing, Hui Liu

## LexKeyPlan：基于关键词和检索增强的法律文本生成规划：欧洲人权法院案件研究案例。
LexKeyPlan: Planning with Keyphrases and Retrieval Augmentation for Legal Text Generation: A Case Study on European Court of Human Rights Cases
Santosh T.Y.S.S, Elvin Quero Hernandez

## 通过参数高效微调将图上下文引入语言模型以进行词汇关系挖掘。
Introducing Graph Context into Language Models through Parameter-Efficient Fine-Tuning for Lexical Relation Mining
Jingwen Sun, Zhiyi Tian, Yu He, Jingwei Sun, Guangzhong Sun

## 不善思考的律师：一致性和公平性是可靠AI的关键。
The Lawyer That Never Thinks: Consistency and Fairness as Keys to Reliable AI
Dana R Alsagheer, Abdulrahman Kamal, Mohammad Kamal, Cosmo Yang Wu, Weidong Shi

## 从功能单元视角揭开大规模语言模型服务的环境影响。
Unveiling Environmental Impacts of Large Language Model Serving: A Functional Unit View
Yanran Wu, Inez Hua, Yi Ding

## PrivaCI-Bench：基于情境完整性和法律合规性的隐私评估。
PrivaCI-Bench: Evaluating Privacy with Contextual Integrity and Legal Compliance
Haoran Li, Wenbin Hu, Huihao JING, Yulin Chen, Qi Hu, Sirui Han, Tianshu Chu, Peizhao Hu, Yangqiu Song

## S-RAG：一种新型审计框架，用于检测RAG系统中个人数据的未经授权使用。
S-RAG: A Novel Audit Framework for Detecting Unauthorized Use of Personal Data in RAG Systems
Zhirui Zeng, Jiamou Liu, Meng-Fen Chiang, Jialing He, Zijian Zhang

## 从真实到合成：合成数百万条多样化且复杂的用户指令及其属性约束。
From Real to Synthetic: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding
Chiwei Zhu, Benfeng Xu, Xiaorui Wang, Zhendong Mao

## MuSC：通过多粒度自我对比训练提高复杂指令跟随能力。
MuSC: Improving Complex Instruction Following with Multi-granularity Self-Contrastive Training
Hui Huang, Jiaheng Liu, Yancheng He, Shilong Li, Bing Xu, Conghui Zhu, Muyun Yang, Tiejun Zhao

## ExpeTrans：LLMs是经验迁移学习者。
ExpeTrans: LLMs Are Experiential Transfer Learners
Jinglong Gao, Xiao Ding, Lingxiao Zou, Bibo Cai, Bing Qin, Ting Liu

## MCS-Bench：中文古典学多模态大语言模型综合测评基准。
MCS-Bench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in Chinese Classical Studies
Yang Liu, Jiahuan Cao, Hiuyi Cheng, Yongxin Shi, Kai Ding, Lianwen Jin

## 普雷托：一种细粒度生成型大型语言模型评估器，支持实例级别的自定义评估标准。
Praetor: A Fine-Grained Generative LLM Evaluator with Instance-Level Customizable Evaluation Criteria
Yongqi Leng, Renren Jin, Yue chen, Zhuowen Han, Ling Shi, Jianxiang Peng, Lei Yang, Juesi Xiao, Deyi Xiong

## 通过权重屏蔽减轻痴呆检测中言语语言中的性别混淆偏差。
Mitigating Gender Confounding Bias from Spoken Language in Dementia Detection via Weight Masking
Zhecheng Sheng, Xiruo Ding, Brian Hur, Changye Li, Trevor Cohen, Serguei V. S. Pakhomov

## PPT：一种通过跨语言偏好模式转移的次要语言新闻推荐模型。
PPT: A Minor Language News Recommendation Model via Cross-Lingual Preference Pattern Transfer
Yiyang Zhang, Nan Chen

## Cool-Fusion：融合大型语言模型无需训练
Cool-Fusion: Fuse Large Language Models without Training
Cong Liu, Xiaojun Quan, Yan Pan, Weigang Wu, Xu Chen, Liang Lin

## DAPE V2：将过程注意力得分作为特征图进行长度外推。
DAPE V2: Process Attention Score as Feature Map for Length Extrapolation
Chuanyang Zheng, Yihang Gao, Han Shi, Jing Xiong, Jiankai Sun, Jingyao Li, Minbin Huang, Xiaozhe Ren, Michael Ng, Xin Jiang, Zhenguo Li, Yu Li

## APB：通过跨GPU传递压缩的上下文块来加速分布式长上下文推理。
APB: Accelerating Distributed Long-Context Inference by Passing Compressed Context Blocks across GPUs
Yuxiang Huang, Mingye Li, Xu Han, Chaojun Xiao, Weilin Zhao, Sun Ao, Hao Zhou, Jie Zhou, Zhiyuan Liu, Maosong Sun

## Top-$n\\sigma$: 在逻辑空间中消除噪音以提高大型语言模型令牌采样的 robust 性。
Top-$n\\sigma$: Eliminating Noise in Logit Space for Robust Token Sampling of LLM
Chenxia Tang, Jianchun Liu, Hongli Xu, Liusheng Huang

## LongReD：通过恢复精炼消除长上下文大语言模型中的短文本退化。
LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation
Zican Dong, Junyi Li, Jinhao Jiang, Mingyu Xu, Xin Zhao, Bingning Wang, Weipeng Chen

## 缓解Few-Shot continual Relation Extraction中非代表性原型和表示偏差的问题。
Mitigating Non-Representative Prototypes and Representation Bias in Few-Shot Continual Relation Extraction
Thanh Duc Pham, Nam Le Hai, Linh Ngo Van, Nguyen Thi Ngoc Diep, Sang Dinh, Thien Huu Nguyen

## GainRAG：通过Gain信号合成实现检索增强生成中的偏好对齐。
GainRAG: Preference Alignment in Retrieval-Augmented Generation through Gain Signal Synthesis
Yi Jiang, Sendong Zhao, Jianbo Li, Haochun Wang, Bing Qin

## GuessArena：猜猜我是谁？一种自适应评估框架，用于领域特定知识和推理的大型语言模型。
GuessArena: Guess Who I Am? A Self-Adaptive Framework for Evaluating LLMs in Domain-Specific Knowledge and Reasoning
Qingchen Yu, Zifan Zheng, Ding Chen, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu li

## MoQAE：用于长上下文LLM推理的混合精度量化混合专家方法。
MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts
Wei Tao, Haocheng Lu, Xiaoyang Qu, Bin Zhang, Kai Lu, Jiguang Wan, Jianzong Wang

## Meta-rater：一种用于预训练语言模型的数据选择多维方法。
Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models
Xinlin Zhuang, Jiahui Peng, Ren Ma, Yinfan Wang, Tianyi Bai, Xingjian Wei, Qiu Jiantao, Chi Zhang, Ying Qian, Conghui He

## AutoGUI：通过来自大语言模型的自动功能注释扩展GUI接地。
AutoGUI: Scaling GUI Grounding with Automatic Functionality Annotations from LLMs
Hongxin Li, Jingfan CHEN, Jingran Su, Yuntao Chen, Li Qing, Zhaoxiang Zhang

## ARise：朝向基于风险适配性寻-find 的知识增强型推理。
ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search
Yize Zhang, Tianshu Wang, Sirui Chen, Kun Wang, Xingyu Zeng, Hongyu Lin, Xianpei Han, Le Sun, Chaochao Lu

## SCOPE：优化长上下文生成中键值缓存压缩。
SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation
Jialong Wu, Zhenglin Wang, Linhai Zhang, Yilong Lai, Yulan He, Deyu Zhou

## PrivacyRestore：通过隐私移除与恢复在大型语言模型中实现的隐私保护推断。
PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration
Ziqian Zeng, Jianwei Wang, Junyao Yang, ZhengdongLu, Haoran Li, Huiping Zhuang, Cen Chen

## DTCRS：递归总结中的动态树构建。
DTCRS: Dynamic Tree Construction for Recursive Summarization
Guanran Luo

## 摩擦代理对齐框架：慢慢来，别打破一切。
Frictional Agent Alignment Framework: Slow Down and Don’t Break Things
Abhijnan Nath, Carine Graff, Andrei Bachinin, Nikhil Krishnaswamy

## 一种用于时间知识图推理的生成自适应回放连续学习模型。
A Generative Adaptive Replay Continual Learning Model for Temporal Knowledge Graph Reasoning
Zhiyu Zhang, Wei Chen, Youfang Lin, Huaiyu Wan

## 小心你的 Po! 评定与减轻在大语言模型角色扮演微调中的人工智能安全风险。
Beware of Your Po! Measuring and Mitigating AI Safety Risks in Role-Play Fine-Tuning of LLMs
Weixiang Zhao, Yulin Hu, Yang Deng, Jiahe Guo, Xingyu Sui, Xinyang Han, An Zhang, Yanyan Zhao, Bing Qin, Tat-Seng Chua, Ting Liu

## TWIST：文本编码权重编辑，用于在文本到图像模型中植入秘密木马 nigeria. \n\n注：此处“nigeria”应为“trojans”，可能是打字错误。正确的翻译如下：\n\n题目：TWIST：文本编码权重编辑，用于在文本到图像模型中植入秘密木马。
TWIST: Text-encoder Weight-editing for Inserting Secret Trojans in Text-to-Image Models
Xindi Li, Zhe Liu, Tong Zhang, Jiahao Chen, Qingming Li, Jinbao Li, Shouling Ji

## PKAG-DDI：基于成对知识增强的语言模型用于药物-药物相互作用事件文本生成。
PKAG-DDI: Pairwise Knowledge-Augmented Language Model for Drug-Drug Interaction Event Text Generation
Ziyan Wang, Zhankun Xiong, Feng Huang, Wen Zhang

## Powerformer：高效且高精度的同态加密隐私保护语言模型
Powerformer: Efficient and High-Accuracy Privacy-Preserving Language Model with Homomorphic Encryption
Dongjin Park, Eunsang Lee, Joon-Woo Lee

## 知识显微镜：特征作为比神经元更好的分析透镜。
The Knowledge Microscope: Features as Better Analytical Lenses than Neurons
Yuheng Chen, Pengfei Cao, Kang Liu, Jun Zhao

## 图神经网络能在极其弱的文字监督下学习语言吗？
Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?
Zihao Li, Lecheng Zheng, Bowen Jin, Dongqi Fu, Baoyu Jing, Yikun Ban, Jingrui He, Jiawei Han

## 朝向基于大语言模型的交互戏剧中增强沉浸感和主动性的研究。
Towards Enhanced Immersion and Agency for LLM-based Interactive Drama
Hongqiu Wu, Weiqi Wu, Tianyang Xu, Jiameng Zhang, hai zhao

## 提高事实准确性与显性工作记忆的关系。
Improving Factuality with Explicit Working Memory
Mingda Chen, Yang Li, Karthik Padthe, Rulin Shao, Alicia Yi Sun, Luke Zettlemoyer, Gargi Ghosh, Wen-tau Yih

## 通过联合建模文本和多模态语义结构来消除视觉接地对话中的指称歧义。
Disambiguating Reference in Visually Grounded Dialogues through Joint Modeling of Textual and Multimodal Semantic Structures
Shun Inadumi, Nobuhiro Ueda, Koichiro Yoshino

## GenderAlign：降低大型语言模型性别偏见的数据对齐数据集 kukuk
GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models
Tao Zhang, Ziqian Zeng, YuxiangXiao, Huiping Zhuang, Cen Chen, James R. Foulds, Shimei Pan

## SHARE：一种基于SLM的分层动作修正辅助器用于文本到SQL转换。
SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL
Ge Qu, Jinyang Li, Bowen Qin, Xiaolong Li, Nan Huo, Chenhao Ma, Reynold Cheng

## 梯度自适应策略优化：朝着大型语言模型多目标对齐的目标努力。
Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models
Chengao Li, Hanyu Zhang, Yunkun Xu, Hongyan Xue, Xiang Ao, Qing He

## 样本高效的大型语言模型人类评估方法：最大差异竞争。
Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition
Kehua Feng, Keyan Ding, tan hongzhi, Kede Ma, Zhihua Wang, Shuangquan Guo, Cheng yuzhou, Ge Sun, Guozhou Zheng, Qiang Zhang, Huajun Chen

## Pre$^3$：启用确定性上下文自动机以更快地生成结构化大语言模型。
Pre$^3$: Enabling Deterministic Pushdown Automata for Faster Structured LLM Generation
Junyi Chen, Shihao Bai, Zaijun Wang, Siyu Wu, Chuheng Du, Hailong Yang, Ruihao Gong, Shengzhong Liu, Fan Wu, Guihai Chen

## 大规模语言模型下的一对多总结实证研究
An Empirical Study of Many-to-Many Summarization with Large Language Models
Jiaan Wang, Fandong Meng, Zengkui Sun, Yunlong Liang, Yuxuan Cao, Jiarong Xu, HAOXIANG SHI, Jie Zhou

## 大型语言与蛋白质助手在蛋白质-蛋白质相互作用预测中的应用
Large Language and Protein Assistant for Protein-Protein Interactions Prediction
Peng Zhou, Pengsen Ma, Jianmin Wang, Xibao Cai, Haitao Huang, Wei Liu, Longyue Wang, Lai Hou Tim, xiangxiang Zeng

## SynWorld：代理行动知识精炼的虚拟场景合成。
SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement
Runnan Fang, Xiaobin Wang, Yuan Liang, Shuofei Qiao, Jialong Wu, Zekun Xi, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen

## GuideBench：面向领域导向指南遵循的基准测试。
GuideBench: Benchmarking Domain-Oriented Guideline Following for LLM Agents
Lingxiao Diao, Xinyue Xu, Wanxuan Sun, Cheng Yang, Zhuosheng Zhang

## SoRFT：以子任务为导向的强化微调解决 ISSUE。
SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning
Zexiong Ma, Chao Peng, Pengfei Gao, Xiangxin Meng, Yanzhen Zou, Bing Xie

## 分工再对齐：基于RAG知识边界的真实对齐
Divide-Then-Align: Honest Alignment based on the Knowledge Boundary of RAG
Xin Sun, Jianan Xie, Zhongqi Chen, Qiang Liu, Shu Wu, Yuehe Chen, Bowen Song, Zilei Wang, Weiqiang Wang, Liang Wang

## TC–RAG：医疗大语言系统中图灵完备RAG的案例研究
TC–RAG: Turing–Complete RAG’s Case study on Medical LLM Systems
Xinke Jiang, Yue Fang, Rihong Qiu, Haoyu Zhang, Yongxin Xu, Hao Chen, WentaoZhang, Ruizhe Zhang, Yuchen Fang, Xinyu Ma, Xu Chu, Junfeng Zhao, Yasha Wang

## MiniLongBench：低成本长上下文理解基准测试套件（用于大型语言模型）。
MiniLongBench: The Low-cost Long Context Understanding Benchmark for Large Language Models
Zhongzhan Huang, Guoming Ling, Shanshan Zhong, Hefeng Wu, Liang Lin

## PwnGPT：基于大型语言模型的自动漏洞利用生成。
PwnGPT: Automatic Exploit Generation Based on Large Language Models
Wanzong Peng, Lin Ye, Xuetao Du, Hongli Zhang, Dongyang Zhan, Yunting Zhang, Yicheng Guo, Chen Zhang

## 用非同时扩散过程统一连续文本扩散和离散文本扩散。
Unifying Continuous and Discrete Text Diffusion with Non-simultaneous Diffusion Processes
Bocheng Li, Zhujin Gao, Linli Xu

## VMLU 基准测试工具包：一套全面的越南语言大模型基准工具。
VMLU Benchmarks: A comprehensive benchmark toolkit for Vietnamese LLMs
Cuc Thi Bui, Nguyen Truong Son, Truong van trang, Lam Viet Phung, Pham Nhut Huy, Hoang Anh Le, Quoc Huu Van, Phong Nguyen-Thuan Do, Van Le Tran Truc, Duc Thanh Chau, Le-Minh Nguyen

## 一种战略协调框架，小型语言模型在数据合成方面可匹配大型语言模型。
A Strategic Coordination Framework of Small LMs Matches Large LMs in Data Synthesis
Xin Gao, Qizhi Pei, Zinan Tang, Yu Li, Honglin Lin, Jiang Wu, Lijun Wu, Conghui He

## 在长上下文场景中基于状态大小的RNN大规模语言模型扩展规律。
Scaling Laws for RNN LLM in Long-Context Scenarios with State Size
Kai Liu, Jianfei Gao, Kai Chen

## 通过推理时逻辑推理增强检索系统。
Enhancing Retrieval Systems with Inference-Time Logical Reasoning
Felix Faltings, Wei Wei, Yujia Bao

## 从心理测量学视角定义和评估视觉语言模型的基本空间能力。
Defining and Evaluating Visual Language Models’ Basic Spatial Abilities: A Perspective from Psychometrics
Wenrui Xu, Dalin Lyu, Weihang Wang, Jie Feng, Chen Gao, Yong Li

## 越狱？一步即可！
Jailbreaking? One Step Is Enough!
Weixiong Zheng, Peijian Zeng, YiWei Li, Hongyan Wu, Nankai Lin, Junhao Chen, Aimin Yang, Yongmei Zhou

## 用户端模型一致性监控用于开源大型语言模型推理服务。
User-side Model Consistency Monitoring for Open Source Large Language Models Inference Services
Qijun Miao, Zhixuan Fang

## SPHERE：通过层次评估揭示视觉-语言模型的空间盲点。
SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation
Wenyu Zhang, Wei En Ng, Lixin Ma, Yuwen Wang, Junqi Zhao, Allison Koenecke, Boyang Li, WANGLU

## 利用潜文本增强生成性IDRR。
Using Subtext to Enhance Generative IDRR
Zhipang Wang, Yu Hong, Weihao Sun, Guodong Zhou

## EpMAN：用于长上下文泛化的 episodic 记忆注意机制。
EpMAN: Episodic Memory AttentioN for Generalizing to Longer Contexts
Subhajit Chaudhury, Payel Das, Sarathkrishna Swaminathan, Georgios Kollias, Elliot Nelson, Khushbu Pahwa, Tejaswini Pedapati, Igor Melnyk, Matthew Riemer

## 育儿：通过参数解耦和定制调优来优化检索增强语言模型的知识选择。
Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning
Yongxin Xu, Ruizhe Zhang, Xinke Jiang, Yujie Feng, Yuzhen Xiao, Xinyu Ma, Runchuan Zhu, Xu Chu, Junfeng Zhao, Yasha Wang

## 不够成熟更为适应于句子级别的语言建模。
Less Mature is More Adaptable for Sentence-level Language Modeling
Abhilasha Sancheti, David Dale, Artyom Kozhevnikov, Maha Elbayad

## TROVE：一种通过源句跟踪和关系分类实现细致粒度文本来源挑战的研究。
TROVE: A Challenge for Fine-Grained Text Provenance via Source Sentence Tracing and Relationship Classification
Junnan Zhu, Min Xiao, Yining Wang, Feifei Zhai, Yu Zhou, Chengqing Zong

## UORA：在大型模型参数高效微调中的均匀正交重新初始化适应。
UORA: Uniform Orthogonal Reinitialization Adaptation in Parameter Efficient Fine-Tuning of Large Models
Xueyan Zhang, Jinman Zhao, Zhifei Yang, Yibo Zhong, Shuhao Guan, Linbo Cao, Yining Wang

## 知识增强的多模态临床推理生成以小语言模型进行疾病诊断。
Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models
Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, Richard Yi Da Xu, Yunya Song, Xian Yang

## CaLMQA：探索跨23种语言的具有文化特性的长文问答。
CaLMQA: Exploring culturally specific long-form question answering across 23 languages
Shane Arora, Marzena Karpinska, Hung-Ting Chen, Ipsita Bhattacharjee, Mohit Iyyer, Eunsol Choi

## BeamLoRA：带束约束的低秩适配。
BeamLoRA: Beam-Constraint Low-Rank Adaptation
Naibin Gu, Zhenyu Zhang, Xiyu Liu, Peng Fu, Zheng Lin, Shuohuan Wang, Yu Sun, Hua Wu, Weiping Wang, Haifeng Wang

## HyKGE：一种假设知识图谱增强的RAG框架，用于提高医疗大模型响应的准确性和可靠性。
HyKGE: A Hypothesis Knowledge Graph Enhanced RAG Framework for Accurate and Reliable Medical LLMs Responses
Xinke Jiang, Ruizhe Zhang, Yongxin Xu, Rihong Qiu, Yue Fang, Zhiyuan Wang, Jinyi Tang, Hongxin Ding, Xu Chu, Junfeng Zhao, Yasha Wang

## Agri-CM$^3$：面向农业理解与推理的中文大规模多模式多层次基准。
Agri-CM$^3$: A Chinese Massive Multi-modal, Multi-level Benchmark for Agricultural Understanding and Reasoning
Haotian Wang, Yi Guan, Fanshu Meng, Chao Zhao, Lian Yan, Yang Yang, Jingchi Jiang

## UniLR：统一法律检索器在多项法律任务中释放大语言模型的power。
UniLR: Unleashing the Power of LLMs on Multiple Legal Tasks with a Unified Legal Retriever
Ang Li, Yiquan Wu, Yifei Liu, Ming Cai, Lizhi Qing, Shihang Wang, Yangyang Kang, Chengyuan Liu, Fei Wu, Kun Kuang

## PaSa：一种全面学术论文搜索的大型语言模型代理。
PaSa: An LLM Agent for Comprehensive Academic Paper Search
Yichen He, Guanhua Huang, Peiyuan Feng, Yuan Lin, Yuchen Zhang, Hang Li, Weinan E

## LongRecipe：高效长上下文泛化的大型语言模型配方
LongRecipe: Recipe for Efficient Long Context Generalization in Large Language Models
Zhiyuan Hu, Yuliang Liu, Jinman Zhao, Suyuchen Wang, WangYan, Wei Shen, Qing Gu, Anh Tuan Luu, See-Kiong Ng, Zhiwei Jiang, Bryan Hooi

## 动态并行树搜索以实现高效的LLM推理。
Dynamic Parallel Tree Search for Efficient LLM Reasoning
Yifu Ding, Wentao Jiang, Shunyu Liu, Yongcheng Jing, Jinyang Guo, Yingjie Wang, Jing Zhang, Zengmao Wang, Ziwei Liu, Bo Du, Xianglong Liu, Dacheng Tao

## GODBench：视频评论艺术中多模态大型语言模型的基准测试。
GODBench: A Benchmark for Multimodal Large Language Models in Video Comment Art
Chenkai Zhang, Yiming Lei, Zeming Liu, Haitao Leng, ShaoGuo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang

## 生成心理词汇方法在大型语言模型中构建价值体系。
Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models
Haoran Ye, TianZe Zhang, Yuhang Xie, Liyuan Zhang, Yuanyi Ren, Xin Zhang, Guojie Song

## 量化语言模型中的语义涌现。
Quantifying Semantic Emergence in Language Models
Hang Chen, Xinyu Yang, Jiaying Zhu, Wenya Wang

## 超越对话：一种面向通用角色扮演语言模型的个人资料-对话对齐框架。
Beyond Dialogue: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model
Yeyong Yu, Runsheng Yu, Haojie Wei, Zhanqiu Zhang, Quan QIAN

## ACECODER：通过自动化测试案例合成提升编码器RL性能。
ACECODER: Acing Coder RL via Automated Test-Case Synthesis
Huaye Zeng, Dongfu Jiang, Haozhe Wang, Ping Nie, Xiaotong Chen, Wenhu Chen

## 可裁剪的知识图嵌入。
Croppable Knowledge Graph Embedding
Yushan Zhu, Wen Zhang, Zhiqiang Liu, Mingyang Chen, Lei Liang, Huajun Chen

## 定位并聚焦：增强语言模型中术语翻译。
Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models
Suhang Wu, Jialong Tang, Chengyi Yang, Pei Zhang, Baosong Yang, Junhui Li, Min Zhang, Jinsong Su

## 多 persona 框架用于论据质量评估。
A Multi-persona Framework for Argument Quality Assessment
Bojun Jin, Jianzhu Bao, Yufang Hou, Yang Sun, Yice Zhang, Huajie Wang, Bin Liang, Ruifeng Xu

## DebateCoder：通过测试案例驱动的LLM辩论来实现代码生成的集体智能。
DebateCoder: Towards Collective Intelligence of LLMs via Test Case Driven LLM Debate for Code Generation
Jizheng Chen, Kounianhua Du, Xinyi Dai, Weiming Zhang, Xihuai Wang, Yasheng Wang, Ruiming Tang, Weinan Zhang, Yong Yu

## GraphInsight：解锁大型语言模型中图结构理解的洞察。
GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding
Yukun Cao, Shuo Han, Zengyi Gao, Zezhong Ding, Xike Xie, S Kevin Zhou

## 权衡之战：在大型语言模型中缓解公平性与隐私性的冲突。
The Tug of War Within: Mitigating the Fairness-Privacy Conflicts in Large Language Models
Chen Qian, Dongrui Liu, Jie Zhang, Yong Liu, Jing Shao

## SAM 解码：基于后缀自动机的 speculative 解码。
SAM Decoding: Speculative Decoding via Suffix Automaton
Yuxuan Hu, Ke Wang, Xiaokang Zhang, Fanjin Zhang, Cuiping Li, Hong Chen, Jing Zhang

## Safe：通过回顾性步骤感知形式验证提升大型语言模型的数学推理能力。
Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification
Chengwu Liu, Ye Yuan, Yichun Yin, Yan Xu, Xin Xu, Zaoyu Chen, Lifeng Shang, Qun Liu, Ming Zhang

## 通过偏好对齐提升零样本文本到语音的可懂度，跨越多样领域。
Advancing Zero-shot Text-to-Speech Intelligibility across Diverse Domains via Preference Alignment
Xueyao Zhang, Yuancheng Wang, Chaoren Wang, Ziniu Li, Zhuo Chen, Zhizheng Wu

## TreeRL：基于树搜索的LLM强化学习方法。
TreeRL: LLM Reinforcement Learning with On-Policy Tree Search
Zhenyu Hou, Ziniu Hu, Yujiang Li, Rui Lu, Jie Tang, Yuxiao Dong

## 通过LLM代理和条件概念瓶颈模型增强可解释的图像分类。
Enhancing Interpretable Image Classification Through LLM Agents and Conditional Concept Bottleneck Models
Yiwen Jiang, Deval Mehta, Wei Feng, Zongyuan Ge

## PsyAdvisor：一种在心理对话中具备主动提问功能的即插即用策略建议规划器。
PsyAdvisor: A Plug-and-Play Strategy Advice Planner with Proactive Questioning in Psychological Conversations
Yuxin Hu, Danni Liu, Bo Liu, Yida Chen, Jiuxin Cao, Yan Liu

## Phonotomizer：一种紧凑的、无监督的、在线训练的实时多语言音素分割方法。
Phonotomizer: A Compact, Unsupervised, Online Training Approach to Real-Time, Multilingual Phonetic Segmentation
Michael S. Yantosca, Albert M. K. Cheng

## RSCF：实体嵌入关系语义一致过滤器
RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph
Junsik Kim, Jinwook Park, Kangil Kim

## 可靠地界定了假阳性：一种基于多尺度齐性预测的零样本机器生成文本检测框架。
Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction
Xiaowei Zhu, Yubing Ren, Yanan Cao, Xixun Lin, Fang Fang, Yangxi Li

## RolePlot：评估和增强角色扮演代理故事情节进展能力的系统框架。
RolePlot: A Systematic Framework for Evaluating and Enhancing the Plot-Progression Capabilities of Role-Playing Agents
Pinyi Zhang, Siyu An, Lingfeng Qiao, Yifei Yu, Jingyang Chen, Jie Wang, di yin, Xing Sun, Kai Zhang

## 单模型能够兼主多轮对话与工具使用吗？CALM：统一对话代理语言模型。
Can a Single Model Master Both Multi-turn Conversations and Tool Use? CALM: A Unified Conversational Agentic Language Model
Emre Can Acikgoz, Jeremiah Greer, Akul Datta, Ze Yang, William Zeng, Oussama Elachqar, Emmanouil Koukoumidis, Dilek Hakkani-Tür, Gokhan Tur

## SDPO：社会智能体的段落级直接偏好优化。
SDPO: Segment-Level Direct Preference Optimization for Social Agents
Aobo Kong, Wentao Ma, Shiwan Zhao, Yongbin Li, Yuchuan Wu, Ke Wang, Xiaoqian Liu, Qicheng Li, Yong Qin, Fei Huang

## GiFT：基于吉布斯采样的代码生成细调方法。
GiFT: Gibbs Fine-Tuning for Code Generation
Haochen Li, Wanjin Feng, Xin Zhou, Zhiqi Shen

## 使用多模态大语言模型进行单模态到多模态对齐的文档图像机器翻译。
Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation
Yupu Liang, Yaping Zhang, Zhiyang Zhang, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou

## WavRAG：结合音频的检索增强生成模型用于语音对话系统。
WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models
Yifu Chen, Shengpeng Ji, Haoxiao Wang, Ziqing Wang, Siyu Chen, Jinzheng He, Jin Xu, Zhou Zhao

## 通过分级学习提高大模型在多对多语音转文本翻译中的表现。
Making LLMs Better Many-to-Many Speech-to-Text Translators with Curriculum Learning
Yexing Du, Youcheng Pan, Ziyang Ma, Bo Yang, Yifan Yang, Keqi Deng, Xie Chen, Yang Xiang, Ming Liu, Bing Qin

## MLLMs基准中的冗余原则。
Redundancy Principles for MLLMs Benchmarks
Zicheng Zhang, Xiangyu Zhao, Xinyu Fang, Chunyi Li, Xiaohong Liu, Xiongkuo Min, Haodong Duan, Kai Chen, Guangtao Zhai

## AbGen：评估大型语言模型的消融研究设计与评价方法在科学研究中的应用。
AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research
Yilun Zhao, Weiyuan Chen, Zhijian Xu, Yixin Liu, Chengye Wang, Manasi Patwardhan, Lovekesh Vig, Arman Cohan

## SURVEYFORGE：关于大纲启发式方法、基于内存生成以及多维度评估的自动问卷写作。
SURVEYFORGE : On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing
Xiangchao Yan, Shiyang Feng, Jiakang Yuan, Renqiu Xia, Bin Wang, LEI BAI, Bo Zhang

## 赋权知识型自我意识。
Agentic Knowledgeable Self-awareness
Shuofei Qiao, Zhisong Qiu, Baochang Ren, Xiaobin Wang, Xiangyuan Ru, Ningyu Zhang, Xiang Chen, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen

## 标题: $HomeBench$: 在单设备和多设备环境中，使用有效和无效指令评估智能家中大型语言模型的表现。
$HomeBench$: Evaluating LLMs in Smart Homes with Valid and Invalid Instructions Across Single and Multiple Devices
Silin Li, Yuhang Guo, Jiashu Yao, Zeming Liu, Haifeng Wang

## 针对鲁棒的大型语言模型4位量化的一种基于异常值防护的预训练方法。
Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models
Jungwoo Park, Chanwoong Yoon, Hyeon Hwang, Taewhoo Lee, Jaewoo Kang

## 统一的代理框架：评估条件图像生成
A Unified Agentic Framework for Evaluating Conditional Image Generation
Jifang Wang, Yangxue, Longyue Wang, Zhenran Xu, Yiyu Wang, Yaowei Wang, Weihua Luo, Kaifu Zhang, Baotian Hu, Min zhang

## KokoroChat：由训练有素的咨询师通过角色扮演收集的日语心理咨询服务对话数据集。
KokoroChat: A Japanese Psychological Counseling Dialogue Dataset Collected via Role-Playing by Trained Counselors
Zhiyang Qi, Takumasa Kaneko, Keiko Takamizo, Mariko Ukiyo, Michimasa Inaba

## 规划驱动的编程：一种大型语言模型编程工作流。
Planning-Driven Programming: A Large Language Model Programming Workflow
Chao Lei, Yanchuan Chang, Nir Lipovetzky, Krista A. Ehinger

## SINCon：减轻LLM生成的恶意消息注入攻击以检测谣言。
SINCon: Mitigate LLM-Generated Malicious Message Injection Attack for Rumor Detection
Mingqing Zhang, Qiang Liu, Xiang Tao, Shu Wu, Liang Wang

## 轻推：通过引导解码在推理时对LLM进行对齐。
Nudging: Inference-time Alignment of LLMs via Guided Decoding
Yu Fei, Yasaman Razeghi, Sameer Singh

## 知识图谱能让大型语言模型更值得信赖吗？一项关于开放式问题回答的实证研究
Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study Over Open-ended Question Answering
Yuan Sui, Yufei He, Zifeng Ding, Bryan Hooi

## ChildMandarin：适用于3-5岁幼儿的综合 Mandarin 语音数据集。
ChildMandarin: A Comprehensive Mandarin Speech Dataset for Young Children Aged 3-5
Jiaming Zhou, shiyao wang, Shiwan Zhao, Jiabei He, Haoqin Sun, Hui Wang, Cheng Liu, Aobo Kong, Yujie Guo, Xi Yang, Yequan Wang, Yonghua Lin, Yong Qin

## 揭示大型语言模型中的吸引子循环：从动力系统视角看逐步 paraphrasing 成功机制。
Unveiling Attractor Cycles in Large Language Models: A Dynamical Systems View of Successive Paraphrasing
Zhilin Wang, Yafu Li, Jianhao Yan, Yu Cheng, Yue Zhang

## 论文标题：自然语言处理论文的内外部影响。
Internal and External Impacts of Natural Language Processing Papers
Yu Zhang

## SCAR：一种通过样式一致性感知响应排名的数据选择方法，用于大型语言模型的高效指令调优。
SCAR: Data Selection via Style Consistency-Aware Response Ranking for Efficient Instruction-Tuning of Large Language Models
Zhuang Li, YUNCHENG HUA, Thuy-Trang Vu, Haolan Zhan, Lizhen Qu, Gholamreza Haffari

## HFT：大型语言模型的半微调方法。
HFT: Half Fine-Tuning for Large Language Models
Tingfeng Hui, Zhenyu Zhang, Shuohuan Wang, Weiran Xu, Yu Sun, Hua Wu

## 超越表面简单性：揭示隐藏的推理属性以实现精确常识诊断。
Beyond Surface Simplicity: Revealing Hidden Reasoning Attributes for Precise Commonsense Diagnosis
Huijun Lian, Zekai Sun, Keqi Chen, Yingming Gao, Ya Li

## 从目标到问题：一种基于规划的教育数学问题生成框架。
From Objectives to Questions: A Planning-based Framework for Educational Mathematical Question Generation
Cheng Cheng, Zhenya Huang, GuanHao Zhao, Yuxiang Guo, Xin Lin, Jinze Wu, Xin Li, Shijin Wang

## 基于状态的参数高效微调：状态空间模型的state-offset调谐。
State-offset Tuning: State-based Parameter-Efficient Fine-Tuning for State Space Models
Wonjun Kang, Kevin Galim, Yuchen Zeng, Minjae Lee, Hyung Il Koo, Nam Ik Cho

## RankCoT：通过排名链式思考精炼知识以增强检索生成。
RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts
Mingyan Wu, Zhenghao Liu, Yukun Yan, Xinze Li, Shi Yu, Zheni Zeng, Yu Gu, Ge Yu

## 大型语言模型能否通过用户生成内容理解网络热词？
Can Large Language Models Understand Internet Buzzwords Through User-Generated Content
Chen Huang, Junkai Luo, Xinzuo Wang, Wenqiang Lei, Jiancheng Lv

## 有效的异构知识课程学习在序列标注中的应用
An Effective Incorporating Heterogeneous Knowledge Curriculum Learning for Sequence Labeling
Xuemei Tang, Jun Wang, Qi Su, Chu-Ren Huang, Jinghang Gu

## EAC-MoE：一种考虑专家选择的混合专家大型语言模型压缩器。
EAC-MoE: Expert-Selection Aware Compressor for Mixture-of-Experts Large Language Models
Yuanteng Chen, Yuantian Shao, Peisong Wang, Jian Cheng

## 带有离群 token 跟踪的精确 KV 缓存量化。
Accurate KV Cache Quantization with Outlier Tokens Tracing
Yi Su, Yuechi Zhou, Quantong Qiu, Juntao Li, Qingrong Xia, Ping Li, Xinyu Duan, Zhefeng Wang, Min Zhang

## 交互演化：一种用于大型语言模型的神经符号自训练框架。
Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models
Fangzhi Xu, Qiushi Sun, Kanzhi Cheng, Jun Liu, Yu Qiao, Zhiyong Wu

## 激活引导解码：通过双向隐藏状态干预减轻大型视觉-语言模型的虚构响应。
Activation Steering Decoding: Mitigating Hallucination in Large Vision-Language Models through Bidirectional Hidden State Intervention
Jingran Su, Jingfan CHEN, Hongxin Li, Yuntao Chen, Li Qing, Zhaoxiang Zhang

## 从密集模型到混合专家的循环利用指令调优：基于参数合并的方法。
Upcycling Instruction Tuning from Dense to Mixture-of-Experts via Parameter Merging
Tingfeng Hui, Zhenyu Zhang, Shuohuan Wang, Yu Sun, Hua Wu, Sen Su

## 利用异常感知反馈提升医疗大型视图语言模型。
Improving Medical Large Vision-Language Models with Abnormal-Aware Feedback
Yucheng Zhou, Lingran Song, Jianbing Shen

## 多代理协作多语言代码指令调整
Multi-Agent Collaboration for Multilingual Code Instruction Tuning
Jian Yang, Wei Zhang, Yibo Miao, Shanghaoran Quan, Zhenhe Wu, Qiyao Peng, Liqun Yang, Tianyu Liu, Zeyu Cui, Binyuan Hui, Junyang Lin

## MapNav：基于标注语义地图的新颖记忆表示方法及其在VLM驱动的视觉-语言导航中的应用。
MapNav: A Novel Memory Representation via Annotated Semantic Maps for VLM-based Vision-and-Language Navigation
Lingfeng Zhang, Xiaoshuai Hao, Qinwen Xu, Qiang Zhang, Xinyao Zhang, Pengwei Wang, Jing Zhang, Zhongyuan Wang, Shanghang Zhang, Renjing Xu

## CLAIM：通过跨语言注意力干预减轻大型视觉语言模型的多语言对象错觉。
CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention
Zekai Ye, Qiming Li, Xiaocheng Feng, Libo Qin, Yichong Huang, Baohang Li, Kui Jiang, Yang Xiang, Zhirui Zhang, Yunfei Lu, Duyu Tang, Dandan Tu, Bing Qin

## 培养自己的 Gaming 感知：让大模型成为 Gaming 专家。
Cultivating Gaming Sense for Yourself: Making VLMs Gaming Experts
wenxuan lu, Jiangyang He, Zhanqiu Zhang, Tianning Zang, Steven Y. Guo

## 通过知识偏好优化提升安全可控的蛋白质生成。
Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization
Yuhao Wang, Keyan Ding, Kehua Feng, Zeyuan Wang, Ming Qin, Xiaotong Li, Qiang Zhang, Huajun Chen

## 迷失在字面意义中：监督训练如何塑造LLM中的翻译风格。
Lost in Literalism: How Supervised Training Shapes Translationese in LLMs
Yafu Li, Ronghao Zhang, Zhilin Wang, Huajian Zhang, Leyang Cui, Yongjing Yin, Tong Xiao, Yue Zhang

## 通过正交投影实现的知识解耦及其在大型语言模型终身编辑中的应用
Knowledge Decoupling via Orthogonal Projection for Lifelong Editing of Large Language Models
Haoyu Xu, Pengxiang Lan, Enneng Yang, Guibing Guo, Jianzhe Zhao, Linying Jiang, Xingwei Wang

## 通过L0正则化混合专家模型加速密集大语言模型
Accelerating Dense LLMs via L0-regularized Mixture-of-Experts
Zhenyu Zhang, JiuDong Yang, taozhaowen, Meng Chen

## 购物巫师：基于决策树分支的目标导向电子商务对话生成。
Wizard of Shopping: Target-Oriented E-commerce Dialogue Generation with Decision Tree Branching
Xiangci Li, Zhiyu Chen, Jason Ingyu Choi, Nikhita Vedula, Besnik Fetahu, Oleg Rokhlenko, Shervin Malmasi

## 天才：一个普遍适用且完全无监督的自我训练框架，用于高级推理。
Genius: A Generalizable and Purely Unsupervised Self-Training Framework For Advanced Reasoning
Fangzhi Xu, Hang Yan, Chang Ma, Haiteng Zhao, Qiushi Sun, Kanzhi Cheng, Junxian He, Jun Liu, Zhiyong Wu

## 从奖励过优化的角度重新思考奖励模型评估。
Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization
Sunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Dongha Lee, Jinyoung Yeo

## 高效运放适应缩放注意力以突出金色上下文。
Efficient OpAmp Adaptation for Zoom Attention to Golden Contexts
Haoyuan Wu, Rui Ming, Haisheng Zheng, Zhuolun He, Bei Yu

## 连接离散编码器表示与语音语言模型。
Bridging Discrete Codec Representations and Speech Language Models
Shengpeng Ji, Minghui Fang, Jialong Zuo, Ziyue Jiang, Dingdong WANG, Hanting Wang, Hai Huang, Zhou Zhao

## 扩展不确定性知识图上的复杂逻辑查询。
Extending Complex Logical Queries on Uncertain Knowledge Graphs
Weizhi Fei, Zihao Wang, Hang Yin, Yang Duan, Yangqiu Song

## 大模型水印能否可靠地防止未经授权的知识精炼？
Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?
Leyi Pan, Aiwei Liu, Shiyu Huang, Yijian LU, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu

## 具有元认知触发的大语言模型中的自适应工具使用。
Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger
Wenjun Li, Dexun Li, Kuicai Dong, Cong Zhang, Hao Zhang, Weiwen Liu, Yasheng Wang, Ruiming Tang, Yong Liu

## LISTN：基于社会时间维度的词典诱导。
LISTN: Lexicon induction with socio-temporal nuance
Christine de Kock

## LLaSE-G1：基于LLaMA的语音增强中 geralization 能力激励机制。
LLaSE-G1: Incentivizing Generalization Capability for LLaMA-based Speech Enhancement
Boyi Kang, Xinfa Zhu, Zihan Zhang, Zhen Ye, Mingshuai Liu, Ziqian Wang, Yike Zhu, Guobin Ma, Jun Chen, Longshuai Xiao, CHAO WENG, Wei Xue, Lei Xie

## 通过对齐规模化问题合成激发大规模语言模型的推理能力。
Unleashing LLM Reasoning Capability via Scalable Question Synthesis from Scratch
Yuyang Ding, Xinyu Shi, Xiaobo Liang, Juntao Li, Zhaopeng Tu, Qiaoming Zhu, Min Zhang

## $\\phi$-解码：自适应预见采样以实现平衡的推理时探索与利用。
$\\phi$-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation
Fangzhi Xu, Hang Yan, Chang Ma, Haiteng Zhao, Jun Liu, Qika Lin, Zhiyong Wu

## MadaKV：自适应多模态感知KV缓存淘汰方案，实现高效的长上下文多模态推理。
MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference
Kunxi Li, Zhonghua Jiang, Zhouzhou Shen, ZhaodeWang, chengfei lv, Shengyu Zhang, Fan Wu, Fei Wu

## MMLU-CF：无污染多任务语言理解基准。
MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark
Qihao Zhao, Yangyu Huang, Tengchao Lv, Lei Cui, Qinzheng Sun, Shaoguang Mao, Xin Zhang, Ying Xin, Qiufeng Yin, Scarlett Li, Furu Wei

## 多\n助手\n多模态大型语言模型真能理解我们所\nparalleled\n所指的事物吗？探讨指示性、象形和象征手势的理解能力。
Do Multimodal Large Language Models Truly See What We Point At? Investigating Indexical, Iconic, and Symbolic Gesture Comprehension
Noriki Nishida, Koji Inoue, Hideki Nakayama, Mayumi Bono, Katsuya Takanashi

## 代码切换红队测试：评估大规模语言模型的安全性和多语言理解能力。
Code-Switching Red-Teaming: LLM Evaluation for Safety and Multilingual Understanding
Haneul Yoo, Yongjin Yang, Hwaran Lee

## PQR：通过潜在查询建模改进密集检索。
PQR: Improving Dense Retrieval via Potential Query Modeling
Junfeng Kang, Rui Li, Qi Liu, Yanjiang Chen, Zheng Zhang, Junzhe Jiang, Heng Yu, Yu Su

## SDBench：基于调查的领域特定大语言模型基准测试与优化框架。
SDBench: A Survey-based Domain-specific LLM Benchmarking and Optimization Framework
Cheng Guo, Hu Kai, Shuxian Liang, Yiyang Jiang, Yi Gao, Xian-Sheng Hua, Wei Dong

## 自我监督量化表示：无缝集成知识图谱与大规模语言模型
Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models
Qika Lin, Tianzhe Zhao, Kai He, Zhen Peng, Fangzhi Xu, Ling Huang, Jingying Ma, Mengling Feng

## ReflecTool：迈向具备反思意识的工具增强临床代理。
ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents
Yusheng Liao, Shuyang Jiang, Yanfeng Wang, Yu Wang

## 词汇回忆还是逻辑推理：探究大型语言模型的推理能力极限。
Lexical Recall or Logical Reasoning: Probing the Limits of Reasoning Abilities in Large Language Models
Henrike Beyer, Chris Reed

## TeamLoRA：通过专家合作与竞争提升低秩适应性
TeamLoRA: Boosting Low-Rank Adaptation with Expert Collaboration and Competition
Tianwei Lin, Jiang Liu, Wenqiao Zhang, Yang Dai, Haoyuan Li, Zhelun Yu, Wanggui He, Juncheng Li, Jiannan Guo, Hao Jiang, Siliang Tang, Yueting Zhuang

## DREsS：基于评分 rubric 的英语作为外语写作 essays 评分数据集。
DREsS: Dataset for Rubric-based Essay Scoring on EFL Writing
Haneul Yoo, Jieun Han, So-Yeon Ahn, Alice Oh

## HiDe-LLaVA：多模态大型语言模型连续指令调优的分层解耦方法。
HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model
Haiyang Guo, Fanhu Zeng, Ziwei Xiang, Fei Zhu, Da-Han Wang, Xu-Yao Zhang, Cheng-Lin Liu

## ChainEdit：基于逻辑规则引导的链式更新传播影响。
ChainEdit: Propagating Ripple Effects through Logical Rule-Guided Chain Updates
Zilu dong, Xiangqing Shen, Zinong Yang, Rui Xia

## 跨语言泛化与压缩：从特定语言到共享神经元。
Cross-lingual Generalization and Compression: From Language-Specific to Shared Neurons
Frederick Riemenschneider, Anette Frank

## 错误信息如何影响大型语言模型的行为和偏好？
How does Misinformation Affect Large Language Model Behaviors and Preferences?
Miao Peng, Nuo Chen, Jianheng Tang, Jia Li

## GALLa：图对齐大型语言模型，以提高源代码理解能力。
GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding
Ziyin Zhang, Hang Yu, Sage Lee, Peng Di, Jianguo Li, Rui Wang

## MEDDxAgent：一个统一的模块化代理框架，用于可解释的自动鉴别诊断。
MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis
Daniel Philip Rose, Chia-Chien Hung, Marco Lepri, Israa Alqassem, Kiril Gashteovski, Carolin Lawrence

## 具有链式思考的有限状态自动机内嵌Transformer：一种关于状态追踪的机制性研究。
Finite State Automata Inside Transformers with Chain-of-Thought: A Mechanistic Study on State Tracking
Yifan Zhang, Wenyu Du, Dongming Jin, Jie Fu, Zhi Jin

## CRiskEval：面向大规模语言模型的多层次风险评估基准数据集（中文多层级风险评估基准数据集）
CRiskEval: A Chinese Multi-Level Risk Evaluation Benchmark Dataset for Large Language Models
Ling Shi, Deyi Xiong

## STUN：基于结构化然后去结构化剪枝的可扩展摩尔架构剪枝方法。
STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning
Jaeseong Lee, seung-won hwang, Aurick Qiao, Daniel F Campos, Zhewei Yao, Yuxiong He

## FlashAudio：快速高保真文本转音频的修正流方法。
FlashAudio: Rectified Flow for Fast and High-Fidelity Text-to-Audio Generation
Huadai Liu, Jialei Wang, Rongjie Huang, Yang Liu, Heng Lu, Wei Xue, Zhou Zhao

## YESciEval： robust 的大规模语言模型法官用于科学研究解答。
YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering
Jennifer D’Souza, Hamed Babaei Giglou, Quentin Münch

## 模仿熟悉的：在大语言模型工具学习系统中进行信息窃取攻击的动态命令生成。
Mimicking the Familiar: Dynamic Command Generation for Information Theft Attacks in LLM Tool-Learning System
Ziyou Jiang, Mingyang Li, Guowei Yang, Junjie Wang, Yuekai Huang, Zhiyuan Chang, Qing Wang

## HCSR：分层次自我对比奖励以对齐医疗视觉语言模型。
HSCR: Hierarchical Self-Contrastive Rewarding for Aligning Medical Vision Language Models
Songtao Jiang, Yan Zhang, Yeying Jin, Zhihang Tang, Yangyang Wu, YANG FENG, Jian Wu, Zuozhu Liu

## 论文标题：语音语言模型的近期进展：一项综述。
Recent Advances in Speech Language Models: A Survey
Wenqian Cui, Dianzhi Yu, Xiaoqi Jiao, Ziqiao Meng, Guangyan Zhang, Qichao Wang, Steven Y. Guo, Irwin King

## MAammoTH-VL：大规模指令调优激发多模态推理。
MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale
Jiawei Guo, Tianyu Zheng, Yizhi LI, Yuelin Bai, Bo Li, Yubo Wang, King Zhu, Graham Neubig, Wenhu Chen, Xiang Yue

## 探索多模态大语言模型在医学成像中的组合泛化能力
Exploring Compositional Generalization of Multimodal LLMs for Medical Imaging
Zhenyang Cai, Junying Chen, Rongsheng Wang, Weihong Wang, Yonglin Deng, Dingjie Song, Yize Chen, Zixu Zhang, Benyou Wang

## 针对少次查询黑盒模型的多任务对抗攻击。
Multi-task Adversarial Attacks against Black-box Model with Few-shot Queries
Wenqiang Wang, Yan XIAO, Hao Lin, Yangshijie Zhang, Xiaochun Cao

## LexCLiPR：跨语言段落检索来自法律判决文书。
LexCLiPR: Cross-Lingual Paragraph Retrieval from Legal Judgments
Rohit Upadhya, Santosh T.Y.S.S

## SIFT-50M：用于语音指令微调的大规模多语言数据集。
SIFT-50M: A Large-Scale Multilingual Dataset for Speech Instruction Fine-Tuning
Prabhat Pandey, Rupak Vignesh Swaminathan, K V Vijay Girish, Arunasish Sen, Jian. Xie, Grant Strimel, Andreas Schwarz

## SPECTRA：通过优化内部和外部猜测加速大型语言模型推理。
SPECTRA: Faster Large Language Model Inference with Optimized Internal and External Speculation
Nguyen-Khang Le, Truong Dinh Do, Le-Minh Nguyen

## 从旅行记录中提取图形结构轨迹。
Graph-Structured Trajectory Extraction from Travelogues
Aitaro Yamamoto, Hiroyuki Otomo, Hiroki Ouchi, Shohei Higashiyama, Hiroki Teranishi, Hiroyuki Shindo, Taro Watanabe

## 协作还是竞争？从博弈论视角理解注意力头之间的交互。
Cooperative or Competitive? Understanding the Interaction between Attention Heads From A Game Theory Perspective
Xiaoye Qu, Zengqi Yu, Dongrui Liu, Wei Wei, Daizong Liu, Jianfeng Dong, Yu Cheng

## 多级关联 refinement 网络对话话方面情感四元组分析
Multi-level Association Refinement Network for Dialogue Aspect-based Sentiment Quadruple Analysis
Zeliang Tong, Wei Wei, Xiaoye Qu, Rikui Huang, Zhixin Chen, Xingyu Yan

## 无需训练的基于大规模语言模型的通用中文字符错误纠正方法
A Training-free LLM-based Approach to General Chinese Character Error Correction
Houquan Zhou, Bo Zhang, Zhenghua Li, Ming Yan, Min Zhang

## UniRAG：统一查询理解方法用于检索增强生成。
UniRAG: Unified Query Understanding Method for Retrieval Augmented Generation
Rui Li, Liyang He, Qi Liu, Zheng Zhang, Heng Yu, Yuyang Ye, Linbo Zhu, Yu Su

## 学习一阶逻辑规则进行论据挖掘。
Learning First-Order Logic Rules for Argumentation Mining
Yang Sun, Guanrong Chen, Hamid Alinejad-Rokny, Jianzhu Bao, Yuqi Huang, Bin Liang, Kam-Fai Wong, Min Yang, Ruifeng Xu

## MM-Verify：增强多模态推理的链式思考验证方法。
MM-Verify: Enhancing Multimodal Reasoning with Chain-of-Thought Verification
Linzhuang Sun, Hao Liang, Jingxuan Wei, Bihui Yu, Tianpeng Li, Fan Yang, Zenan Zhou, Wentao Zhang

## 探究并增强大型多模态模型的 temporal 不一致性 robustness。
Investigating and Enhancing the Robustness of Large Multimodal Models Against Temporal Inconsistency
Jiafeng Liang, Shixin Jiang, Xuan Dong, Ning Wang, Zheng Chu, Hui Su, Jinlan Fu, Ming Liu, See-Kiong Ng, Bing Qin

## Emma-X：一个具备基于语境推理和前瞻空间推理的多模态动作模型。
Emma-X: An Embodied Multimodal Action Model with Grounded Chain of Thought and Look-ahead Spatial Reasoning
Qi Sun, Pengfei Hong, Tej Deep Pala, Vernon Toh, U-Xuan Tan, Deepanway Ghosal, Soujanya Poria

## 数学推理中测试时缩放的语言通用性性
Linguistic Generalizability of Test-Time Scaling in Mathematical Reasoning
Guijin Son, Jiwoo Hong, Hyunwoo Ko, James Thorne

## 教育中的全面论据分析：数据集、任务与方法
Towards Comprehensive Argument Analysis in Education: Dataset, Tasks, and Method
Yupei Ren, Xinyi Zhou, Ning Zhang, Shangqing Zhao, Man Lan, Xiaopeng Bai

## 基于上下文体验回放的语言代理连续学习方法。
Contextual Experience Replay for Continual Learning of Language Agents
Yitao Liu, Chenglei Si, Karthik R Narasimhan, Shunyu Yao

## MLLMs能够理解中国图像背后的深层含义吗？
Can MLLMs Understand the Deep Implication Behind Chinese Images?
Chenhao Zhang, Xi Feng, Yuelin Bai, Xeron Du, Jinchang Hou, Kaixin Deng, Guangzeng Han, Qinrui Li, Bingli Wang, Jiaheng Liu, Xingwei Qu, Yifei Zhang, Qixuan Zhao, Yiming Liang, Ziqiang Liu, Feiteng Fang, Min Yang, Wenhao Huang, Chenghua Lin, Ge Zhang, Shiwen Ni

## 快还是慢？结合快速直觉与深思熟虑以提升视觉问答。
Fast or Slow? Integrating Fast Intuition and Deliberate Thinking for Enhancing Visual Question Answering
Songtao Jiang, Chenyi Zhou, Yan Zhang, Yeying Jin, Zuozhu Liu

## MaXIFE：多语言跨语言指令跟随评估。
MaXIFE: Multilingual and Cross-lingual Instruction Following Evaluation
Yile Liu, Ziwei Ma, Xiu Jiang, Jinglu HU, ChangJing, Liang Li

## ClusterAttn：基于内在注意力聚类的KV缓存压缩。
ClusterAttn: KV Cache Compression under Intrinsic Attention Clustering
Minwei Zhang, Haifeng Sun, Jingyu Wang, Shaolong Li, Wanyi Ning, Qi Qi, Zirui Zhuang, Jianxin Liao

## SHARE：基于电影剧本构建的共享内存意识开放领域长期对话数据集
SHARE: Shared Memory-Aware Open-Domain Long-Term Dialogue Dataset Constructed from Movie Script
Eunwon Kim, Chanho Park, Buru Chang

## 像人类一样浏览：一种具有经验性快慢思考模式的多模式网络代理。
Browsing Like Human: A Multimodal Web Agent with Experiential Fast-and-Slow Thinking
Haohao Luo, Jiayi Kuang, Wei Liu, Ying Shen, Jian Luan, Yang Deng

## 跨领域多维度评估大规模语言模型摘要能力
Towards Multi-dimensional Evaluation of LLM Summarization across Domains and Languages
Hyangsuk Min, Yuho Lee, Minjeong Ban, Jiaqi Deng, Nicole Hee-Yeon Kim, Taewon Yun, Hang Su, Jason Cai, Hwanjun Song

## 通过激活反转攻击从去中心化训练的大语言模型中窃取训练数据。
Stealing Training Data from Large Language Models in Decentralized Training through Activation Inversion Attack
Chenxi Dai, Lin Lu, Pan Zhou

## DoMIX：一种在微调过程中利用领域知识的有效框架。
DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning
Dohoon Kim, Donghun Kang, Taesup Moon

## 针对公共资源和文化数据的指令调优：以哈萨克语为例的研究案例。
Instruction Tuning on Public Government and Cultural Data for Low-Resource Language: a Case Study in Kazakh
Nurkhan Laiyk, Daniil Orel, Rituraj Joshi, Maiya Goloburda, Yuxia Wang, Preslav Nakov, Fajri Koto

## KazMMLU：评估哈萨克语、俄语及 Kazakhstan 地方知识的语言模型性能。
KazMMLU: Evaluating Language Models on Kazakh, Russian, and Regional Knowledge of Kazakhstan
Mukhammed Togmanov, Nurdaulet Mukhituly, Diana Turmakhan, Jonibek Mansurov, Maiya Goloburda, Akhmed Sakip, Zhuohan Xie, Yuxia Wang, Bekassyl Syzdykov, Nurkhan Laiyk, Alham Fikri Aji, Ekaterina Kochmar, Preslav Nakov, Fajri Koto

## 知情矛盾的多模态讽刺检测场网络
Incongruity-aware Tension Field Network for Multi-modal Sarcasm Detection
Jiecheng Zhang, C.L.Philip Chen, Shuzhen Li, Tong Zhang

## EAGLE：专家指导下的自我增强方法以实现病理领域的偏好对齐大规模视觉-语言模型
EAGLE: Expert-Guided Self-Enhancement for Preference Alignment in Pathology Large Vision-Language Model
Meidan Ding, Jipeng Zhang, Wenxuan Wang, Haiqin Zhong, Xiaoqin Wang, XINHENG LYU, Wenting Chen, Linlin Shen

## Flexora：灵活低秩适应的大语言模型。
Flexora: Flexible Low-Rank Adaptation for Large Language Models
Chenxing Wei, Yao Shu, Ying Tiffany He, Fei Yu

## 利用跨样本异常分析的创新图像欺诈检测：大型语言模型的力量。
Innovative Image Fraud Detection with Cross-Sample Anomaly Analysis: The Power of LLMs
QiWen Wang, Zhenghao Lin, Chen Lin, Junqi Yang, Zhenzhe Ying, Weiqiang Wang

## OmniFlatten：端到端的GPT模型，实现无缝语音对话。
OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation
Qinglin Zhang, Luyao Cheng, Chong Deng, Qian Chen, Wen Wang, Siqi Zheng, Jiaqing Liu, Hai Yu, Chao-Hong Tan, Zhihao Du, ShiLiang Zhang

## CoT-ICL 实验室：一种研究基于上下文示例的链式思考学习的实验平台。
CoT-ICL Lab: A Petri Dish for Studying Chain-of-Thought Learning from In-Context Demonstrations
Vignesh Kothapalli, Hamed Firooz, Maziar Sanjabi

## QAEval：用于问答任务评估的多种评估者混合模型。
QAEval: Mixture of Evaluators for Question-Answering Task Evaluation
Tan Yue, Rui Mao, xuzhao Shi, SHUO ZHAN, Zuhao Yang, Dongyan Zhao

## 从选择到生成：基于LLM的主动学习综述。
From Selection to Generation: A Survey of LLM-based Active Learning
Yu Xia, Subhojyoti Mukherjee, Zhouhang Xie, Junda Wu, Xintong Li, Ryan Aponte, Hanjia Lyu, Joe Barrow, Hongjie Chen, Franck Dernoncourt, Branislav Kveton, Tong Yu, Ruiyi Zhang, Jiuxiang Gu, Nesreen K. Ahmed, Yu Wang, Xiang Chen, Hanieh Deilamsalehy, Sungchul Kim, Zhengmian Hu, Yue Zhao, Nedim Lipka, Seunghyun Yoon, Ting-Hao Kenneth Huang, Zichao Wang, Puneet Mathur, Soumyabrata Pal, Koyel Mukherjee, Zhehao Zhang, Namyong Park, Thien Huu Nguyen, Jiebo Luo, Ryan A. Rossi, Julian McAuley

## QDTSynth：面向质量的形式定理合成，以增强LLMs的证明性能。
QDTSynth: Quality-Driven Formal Theorem Synthesis for Enhancing Proving Performance of LLMs
Lei Wang, Ruobing Zuo, Gaolei He, Jianlin Wang, Zhengfeng Yang

## RSVP：基于视觉提示与多模态链式思考的推理分割。
RSVP: Reasoning Segmentation via Visual Prompting and Multi-modal Chain-of-Thought
Yi Lu, Jiawang Cao, Yongliang Wu, Bozheng Li, Licheng Tang, Yangguang Ji, Chong Wu, Jay Wu, Wenbo Zhu

## 揭开边缘部署小型语言模型的神秘面纱。
Demystifying Small Language Models for Edge Deployment
Zhenyan Lu, Xiang Li, Dongqi Cai, Rongjie Yi, Fangming Liu, Wei Liu, Jian Luan, Xiwen Zhang, Nicholas D. Lane, Mengwei Xu

## 视觉-语言模型能评估手写数学问题吗？
Can Vision-Language Models Evaluate Handwritten Math?
Oikantik Nath, Hanani Bathina, Mohammed Safi Ur Rahman Khan, Mitesh M Khapra

## 适应一次，随更新而 thriving：演进基础模型上的可迁移参数高效微调。
Adapt Once, Thrive with Updates: Transferable Parameter-Efficient Fine-Tuning on Evolving Base Models
Naibin Gu, Peng Fu, Xiyu Liu, Ke Ma, Zheng Lin, Weiping Wang

## 在偏见意识PEFT下实现LLMs中细粒度分类任务的去偏见化。
Debiasing the Fine-Grained Classification Task in LLMs with Bias-Aware PEFT
Daiying Zhao, Xinyu Yang, Hang Chen

## HiddenDetect：通过监控隐藏状态检测针对多模态大语言模型的越狱攻击
HiddenDetect: Detecting Jailbreak Attacks against Multimodal Large Language Models via Monitoring Hidden States
Yilei Jiang, Xinyan Gao, Tianshuo Peng, Yingshui Tan, Xiaoyong Zhu, Bo Zheng, Xiangyu Yue

## 社区笔记能否取代专业事实核查员？
Can Community Notes Replace Professional Fact-Checkers?
Nadav Borenstein, Greta Warren, Desmond Elliott, Isabelle Augenstein

## 朝向客观微调：大规模语言模型先验知识如何导致潜在的校准不足？
Towards Objective Fine-tuning: How LLMs’ Prior Knowledge Causes Potential Poor Calibration?
Ziming Wang, Zeyu Shi, Haoyi Zhou, Shiqi Gao, Qingyun Sun, Jianxin Li

## GraphCheck：利用提取知识图谱进行事实核查，打破长期文本障碍。
GraphCheck: Breaking Long-Term Text Barriers with Extracted Knowledge Graph-Powered Fact-Checking
Yingjian Chen, Haoran Liu, Yinhong Liu, Jinxiang Xie, Rui Yang, Han Yuan, Yanran Fu, Peng Yuan Zhou, Qingyu Chen, James Caverlee, Irene Li

## 朝着抵御绿色washing风险的 robust ESG分析：基于跨类别泛化的方面-行动分析。
Towards Robust ESG Analysis Against Greenwashing Risks: Aspect-Action Analysis with Cross-Category Generalization
Keane Ong, Rui Mao, Deeksha varshney, Erik Cambria, Gianmarco Mengaldo

## SwiLTra-Bench：瑞士法律翻译基准。
SwiLTra-Bench: The Swiss Legal Translation Benchmark
Joel Niklaus, Jakob Merane, Luka Nenadic, Sina Ahmadi, Yingqiang Gao, Cyrill A. H. Chevalley, Claude Humbel, Christophe Gösken, Lorenzo Tanzi, Thomas Lüthi, Stefan Palombo, Spencer Poff, Boling Yang, Nan Wu, Matthew Guillod, Robin Mamié, Daniel Brunner, Julio Pereyra, Niko Grupen

## 电路Compose结构：探索基于变换器的语言模型中的模块化结构。
Circuit Compositions: Exploring Modular Structures in Transformer-Based Language Models
Philipp Mondorf, Sondre Wold, Barbara Plank

## SCULPT：系统化调谐长提示词。
SCULPT: Systematic Tuning of Long Prompts
Shanu Kumar, Akhila Yesantarao Venkata, Shubhanshu Khandelwal, Bishal Santra, Parag Agrawal, Manish Gupta

## 两个中间翻译胜过一个：针对文档级别翻译 refinement 的 LLM 微调。
Two Intermediate Translations Are Better Than One: Fine-tuning LLMs for Document-level Translation Refinement
Yichen Dong, Xinglin Lyu, Junhui Li, Daimeng Wei, Min Zhang, Shimin Tao, Hao Yang

## 当它们（不知情时）能否立足：关于直接和隐含政治问题的研究。
Can LLMs Ground when they (Don’t) Know: A Study on Direct and Loaded Political Questions
Clara Lachenmaier, Judith Sieker, Sina Zarrieß

## TRIDENT：通过三维度多样化红队合成数据提高大型语言模型安全性。
TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis
Xiaorui Wu, Xiaofeng Mao, Fei Li, Xin Zhang, Donghong Ji, Chong Teng, Xuanhong Li, Zhuang Li

## 跨语言优化在大型语言模型中的语言转移。
Cross-Lingual Optimization for Language Transfer in Large Language Models
Jungseob Lee, Seongtae Hong, Hyeonseok Moon, Heuiseok Lim

## 中文安全QA：面向大型语言模型的安全简短事实性基准。
Chinese SafetyQA: A Safety Short-form Factuality Benchmark for Large Language Models
Yingshui Tan, Boren Zheng, Baihui Zheng, Kerui Cao, Huiyun Jing, Jincheng Wei, Jiaheng Liu, Yancheng He, Wenbo Su, Xiaoyong Zhu, Bo Zheng, Kaifu Zhang

## ACE：一种基于粗细粒度语义建模的生成跨模态检索框架。
ACE: A Generative Cross-Modal Retrieval Framework With Coarse-To-Fine Semantic Modeling
Minghui Fang, Shengpeng Ji, Jialong Zuo, Hai Huang, Yan Xia, Jieming Zhu, Xize Cheng, Xiaoda Yang, Wenrui Liu, Gang Wang, Zhenhua Dong, Zhou Zhao

## 为什么受保护的船只会搁浅？对齐的大语言模型的安全机制倾向于扎根于模板区域。
Why Safeguarded Ships Run Aground? Aligned Large Language Models’ Safety Mechanisms Tend to Be Anchored in The Template Region
Chak Tou Leong, Qingyu Yin, Jian Wang, Wenjie Li

## 蟹Plan：一种新型可配置角色扮演大语言模型及其评估基准。
Crab: A Novel Configurable Role-Playing LLM with Assessing Benchmark
Kai He, Yucheng Huang, Wenqing Wang, Delong Ran, Dongming Sheng, Junxuan Huang, Qika Lin, Jiaxing Xu, Wenqiang Liu, Mengling Feng

## Cheems：从零构建和评估中文奖励模型的实用指南。
Cheems: A Practical Guidance for Building and Evaluating Chinese Reward Models from Scratch
Xueru Wen, Jie Lou, Zichao Li, Yaojie Lu, XingYu, Yuqiu Ji, Guohai Xu, Hongyu Lin, Ben He, Xianpei Han, Le Sun, Debing Zhang

## MMMU-Pro：更 robust 的多学科多模态理解基准。
MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark
Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Botao Yu, Ge Zhang, Huan Sun, Yu Su, Wenhu Chen, Graham Neubig

## 朝向全方位RAG：医学应用中大型语言模型的全面检索增强生成。
Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large Language Models in Medical Applications
Zhe Chen, Yusheng Liao, Shuyang Jiang, Pingjie Wang, YiQiu Guo, Yanfeng Wang, Yu Wang

## LAQuer：基于内容的生成中局部归因查询。
LAQuer: Localized Attribution Queries in Content-grounded Generation
Eran Hirsch, Aviv Slobodkin, David Wan, Elias Stengel-Eskin, Mohit Bansal, Ido Dagan

## 使用压缩的高效长上下文语言模型检索。
Efficient Long Context Language Model Retrieval with Compression
Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang

## 通过上下文多样性重新论述zipf的意义-频率定律
A New Formulation of Zipf’s Meaning-Frequency Law through Contextual Diversity
Ryo Nagata, Kumiko Tanaka-Ishii

## 模型编辑的幻想：重访现实中的评估。
The Mirage of Model Editing: Revisiting Evaluation in the Wild
Wanli Yang, Fei Sun, Jiajun Tan, Xinyu Ma, Qi Cao, Dawei Yin, Huawei Shen, Xueqi Cheng

## 基于本体引导的逆向思考使大型语言模型在知识图谱问答中更为强大。
Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering
Runxuan Liu, luobei, Jiaqi Li, Baoxin Wang, Ming Liu, Dayong Wu, Shijin Wang, Bing Qin

## LLaVA 导航：通过模态线性表示-导航进行视觉指令调优，参数量减少500倍。
LLaVA Steering: Visual Instruction Tuning with 500x Fewer Parameters through Modality Linear Representation-Steering
Jinhe Bi, Yujun Wang, Haokun Chen, Xun Xiao, Artur Hecker, Volker Tresp, Yunpu Ma

## 使用语言、音声和视觉信号预测人机对话中的轮换和反馈。
Predicting Turn-Taking and Backchannel in Human-Machine Conversations Using Linguistic, Acoustic, and Visual Signals
Yuxin Lin, Yinglin Zheng, Ming Zeng, Wangzheng Shi

## EPO：通过强化学习进行明确策略优化以在LLM中实现战略推理。
EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning
Xiaoqian Liu, Ke Wang, Yongbin Li, Yuchuan Wu, Wentao Ma, Aobo Kong, Fei Huang, Jianbin Jiao, Junge Zhang

## 共同学习以表现更好：通过偏好调优教会小型语言模型协作。
Learning Together to Perform Better: Teaching Small-Scale LLMs to Collaborate via Preferential Rationale Tuning
Sohan Patnaik, Milan Aggarwal, Sumit Bhatia, Balaji Krishnamurthy

## 持续梯度低秩投影微调用于大型语言模型。
Continual Gradient Low-Rank Projection Fine-Tuning for LLMs
Chenxu Wang, Yilin Lyu, Zicheng Sun, Liping Jing

## MISP-Meeting：一种包含多模态提示的大规模实际会议转录和总结数据集。
MISP-Meeting: A Real-World Dataset with Multimodal Cues for Long-form Meeting Transcription and Summarization
HangChen, Chao-Han Huck Yang, Jia-Chen Gu, Hongxu Yin, Sabato Marco Siniscalchi, Jun Du

## 多语言无词典手语翻译：朝构建手语基础模型迈进。
Multilingual Gloss-free Sign Language Translation: Towards Building a Sign Language Foundation Model
Sihan Tan, Taro Miyazaki, Kazuhiro Nakadai

## DCG-SQL：增强文本到SQL转换的深度上下文模式链接图内的语境学习。
DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph
Jihyung Lee, Jin-Seop Lee, Jaehoon Lee, YunSeok Choi, Jee-Hyong Lee

## RecLM：推荐指令调优。
RecLM: Recommendation Instruction Tuning
Yangqin Jiang, Yuhao Yang, Lianghao Xia, Da Luo, Kangyi Lin, Chao Huang

## PreP-OCR：一种完整的文档图像修复pipeline及增强OCR准确性的方法。
PreP-OCR: A Complete Pipeline for Document Image Restoration and Enhanced OCR Accuracy
Shuhao Guan, Moule Lin, Cheng Xu, Xinyi Liu, Jinman Zhao, Jiexin Fan, Qi Xu, Derek Greene

## MolRAG：解锁大规模语言模型在分子性质预测中的潜力。
MolRAG: Unlocking the Power of Large Language Models for Molecular Property Prediction
Ziting Xian, Jiawei Gu, Lingbo Li, Eran Segal, Shangsong Liang

## 消化知识：大型语言模型赋能的消息传递在知识图谱问答中的应用。
Digest the Knowledge: Large Language Models empowered Message Passing for Knowledge Graph Question Answering
Junhong Wan, Tao Yu, Kunyu Jiang, Yao Fu, Weihao Jiang, Jiang Zhu

## iQUEST：一种迭代问题导向的知识库问答框架。
iQUEST: An Iterative Question-Guided Framework for Knowledge Base Question Answering
Shuai Wang, Yinan Yu

## SkillAggregation：无需参考的LLM依赖聚合。
SkillAggregation: Reference-free LLM-Dependent Aggregation
Guangzhi Sun, Anmol Kagrecha, Potsawee Manakul, Phil Woodland, Mark Gales

## DS$^2$-ABSA：面向少量样本方面基于情感分析的数据双流合成与标签精炼。
DS$^2$-ABSA: Dual-Stream Data Synthesis with Label Refinement for Few-Shot Aspect-Based Sentiment Analysis
Hongling Xu, Yice Zhang, Qianlong Wang, Ruifeng Xu

## 超越一刀切：针对高效评估的定制基准。
Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation
Peiwen Yuan, Yueqi Zhang, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Jiayi Shi, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li

## 超越单一标签：通过LLM驱动的数据增强改进对话推荐。
Beyond Single Labels: Improving Conversational Recommendation through LLM-Powered Data Augmentation
Haozhe Xu, Xiaohua Wang, Changze Lv, Xiaoqing Zheng

## MasRouter：学习为多Agent系统路由LLMs。
MasRouter: Learning to Route LLMs for Multi-Agent Systems
Yanwei Yue, Guibin Zhang, Boyang Liu, Guancheng Wan, Kun Wang, Dawei Cheng, Yiyan Qi

## MLAS-LoRA：语言感知参数检测与基于LoRA的知识迁移在多语言机器翻译中的应用。
MLAS-LoRA: Language-Aware Parameters Detection and LoRA-Based Knowledge Transfer for Multilingual Machine Translation
Tianyu Dong, Bo Li, Jinsong Liu, shaolin Zhu, Deyi Xiong

## 论文标题：在自回归模型中推进序列数值预测。
Advancing Sequential Numerical Prediction in Autoregressive Models
Xiang Fei, Jinghui Lu, Qi Sun, Hao Feng, Yanjie Wang, Wei Shi, An-Lan Wang, Jingqun Tang, Can Huang

## 如何正确比较事物？基于论点总结的比较问题回答研究
How to Compare Things Properly? A Study on Answering Comparative Questions using Argument Summarization
Irina Nikishina, Saba Anwar, Nikolay Dolgov, Maria Manina, Daria Ignatenko, Artem Shelmanov, Chris Biemann

## IRT-Router：基于项目反应理论的有效可解释多语言模型路由方法。
IRT-Router: Effective and Interpretable Multi-LLM Routing via Item Response Theory
Wei Song, Zhenya Huang, Cheng Cheng, Weibo Gao, Bihan Xu, GuanHao Zhao, Fei Wang, Runze Wu

## 使用语言模型实现可控的风格算术。
Controllable Style Arithmetic with Language Models
Weiqi Wang, Wengang Zhou, Zongmeng Zhang, Jie Zhao, Houqiang Li

## M2RC-EVAL：大规模多语言仓库级代码补全评估。
M2RC-EVAL: Massively Multilingual Repository-level Code Completion Evaluation
Jiaheng Liu, Ken Deng, Congnan Liu, Jian Yang, Shukai Liu, He Zhu, Peng Zhao, Linzheng Chai, Yanan Wu, Ge Zhang, Yingshui Tan, Zekun Moore Wang, JinKe, Zhaoxiang Zhang, Bangyu Xiang, Guoan Zhang, Wenbo Su, Bo Zheng

## 金融推理：让金融数值推理更加可靠、全面和具有挑战性。
FinanceReasoning: Make Financial Numerical Reasoning More Credible, Comprehensive, and Challenging
Zichen Tang, Haihong E, Ziyan Ma, Haoyang He, Jiacheng Liu, Zhongjun Yang, Zihua Rong, Rongjin Li, Kun Ji, Huang Qing, Xinyang Hu, Yang Liu, Qianhe Zheng

## XLogoOnline环境下的视觉编程合成基准测试。
Program Synthesis Benchmark for Visual Programming in XLogoOnline Environment
Chao Wen, Jacqueline Staub, Adish Singla

## 掩码可以被学习作为一种替代专家的方法。
Masks Can be Learned As An Alternative of Experts
Peiyu Liu, Tianwen Wei, Bo Zhu, Xin Zhao, Shuicheng YAN

## 通过不平衡最优传输量化词汇语义转移。
Quantifying Lexical Semantic Shift via Unbalanced Optimal Transport
Ryo Kishino, Hiroaki Yamagiwa, Ryo Nagata, Sho Yokoi, Hidetoshi Shimodaira

## 书界世界：从小说到互动智能社会的故事创作。
BOOKWORLD: From Novels to Interactive Agent Societies for Story Creation
Yiting Ran, Xintao Wang, Tian Qiu, Jiaqing Liang, Yanghua Xiao, Deqing Yang

## CodeDPO：将代码模型与自动生成和验证的源代码对齐。
CodeDPO: Aligning Code Models with Self Generated and Verified Source Code
Kechi Zhang, Ge Li, Yihong Dong, Jingjing Xu, Jun Zhang, Jing Su, Yongfei Liu, Zhi Jin

## 中间层表示对齐在微调的LLM跨语言迁移中的应用。
Middle-Layer Representation Alignment for Cross-Lingual Transfer in Fine-Tuned LLMs
Danni Liu, Jan Niehues

## ProxAnn：基于应用场景的topic模型和文档聚类评估方法。
ProxAnn: Use-Oriented Evaluations of Topic Models and Document Clustering
Alexander Miserlis Hoyle, Lorena Calvo-Bartolomé, Jordan Lee Boyd-Graber, Philip Resnik

## SAKE：引导激活以编辑知识。
SAKE: Steering Activations for Knowledge Editing
Marco Scialanga, Thibault Laugel, Vincent Grari, Marcin Detyniecki

## 自适应且稳健的自然语言到多模型查询语言的转换。
Adaptive and Robust Translation from Natural Language to Multi-model Query Languages
Gengyuan Shi, Chaokun Wang, Liu Yabin, Jiawei Ren

## 代理奖励建模：将人类偏好与可验证的正确性信号集成以构建可靠的奖励系统。
Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems
Hao Peng, Yunjia Qi, Xiaozhi Wang, Zijun Yao, Bin Xu, Lei Hou, Juanzi Li

## CrisisTS：结合社交媒体文本数据和气象时间序列的紧急性分类。
CrisisTS: Coupling Social Media Textual Data and Meteorological Time Series for Urgency Classification
Romain Meunier, Farah Benamara, Véronique Moriceau, Savitha Ramasamy, Zhongzheng Qiao

## VLMInferSlow：评估大型视觉-语言模型作为服务的效率稳健性。
VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service
Xiasi Wang, Tianliang Yao, Simin Chen, Runqi Wang, Lei YE, Kuofeng Gao, Yi Huang, Yuan Yao

## 如何在弱到强泛化中缓解过拟合？
How to Mitigate Overfitting in Weak-to-strong Generalization?
Junhao Shi, Qinyuan Cheng, Zhaoye Fei, Yining Zheng, Qipeng Guo, Xipeng Qiu

## LLM作为法官的替代标注员测试：如何通过统计方法证明用LLM替换人类标注员的合理性。
The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs
Nitay Calderon, Roi Reichart, Rotem Dror

## 评估基于双编码器实体消歧的设计决策。
Evaluating Design Decisions for Dual Encoder-based Entity Disambiguation
Susanna Rücker, Alan Akbik

## 动态头部选择用于神经词法化 Constituency 解析。
Dynamic Head Selection for Neural Lexicalized Constituency Parsing
Yang Hou, Zhenghua Li

## Com$^2$：一种基于因果指导的大规模语言模型中探索复杂常识推理的标准基准。
Com$^2$ : A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models
Kai Xiong, Xiao Ding, Yixin Cao, Yuxiong Yan, Li Du, Yufei Zhang, Jinglong Gao, Jiaqian Liu, Bing Qin, Ting Liu

## 我的话语蕴含你的观点：基于读者代理的传播增强以实现个性化隐含情感分析。
My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis
Jian Liao, Yu Feng, Yujin Zheng, Jun Zhao, Suge Wang, JianXing Zheng

## 消除幻觉中的幻觉：辩论增强的RAG。
Removal of Hallucination on Hallucination: Debate-Augmented RAG
Wentao Hu, Wengyu Zhang, Yiyang Jiang, Chen Jason Zhang, Xiaoyong Wei, Li Qing

## 通过广泛实现启用大语言模型知识分析。
Enabling LLM Knowledge Analysis via Extensive Materialization
Yujia Hu, Tuan-Phong Nguyen, Shrestha Ghosh, Simon Razniewski

## EvolveBench：用于评估大型语言模型在处理演变知识时时间意识的全面基准。
EvolveBench: A Comprehensive Benchmark for Assessing Temporal Awareness in LLMs on Evolving Knowledge
Zhiyuan Zhu, Yusheng Liao, Zhe Chen, Yuhao Wang, Yunfeng Guan, Yanfeng Wang, Yu Wang

## 通过捷径流匹配实现可调控节奏和高效零-shot 语音转换。
Rhythm Controllable and Efficient Zero-Shot Voice Conversion via Shortcut Flow Matching
Jialong Zuo, Shengpeng Ji, Minghui Fang, Mingze Li, Ziyue Jiang, Xize Cheng, Xiaoda Yang, Chen Feiyang, Xinyu Duan, Zhou Zhao

## CritiQ：从人类偏好中挖掘数据质量标准。
CritiQ: Mining Data Quality Criteria from Human Preferences
Honglin Guo, Kai Lv, Qipeng Guo, Tianyi Liang, Zhiheng Xi, Demin Song, Qiuyinzhe Zhang, Yu Sun, Kai Chen, Xipeng Qiu, Tao Gui

## 羊驼看，羊驼学：关于LLM contextual entrainment和distraction的机制视角。
Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs
Jingcheng Niu, Xingdi Yuan, Tong Wang, Hamidreza Saghir, Amir H. Abdi

## 最小贝叶斯风险解码的理论保证。
Theoretical Guarantees for Minimum Bayes Risk Decoding
Yuki Ichihara, Yuu Jinnai, Kaito Ariu, Tetsuro Morimura, Eiji Uchibe

## 揭示风格敏感性：大规模语言模型偏差评估不稳定性的一种因果分析。
Unmasking Style Sensitivity: A Causal Analysis of Bias Evaluation Instability in Large Language Models
Jiaxu Zhao, Meng Fang, Kun Zhang, Mykola Pechenizkiy

## 基于霍夫曼编码的可 反向转换方法：低资源语言的跨语言元数据增强。 \n\n注意：您提供的原文“Enhancing Cross-Lingual Transfer through Reversible Transliteration: A Huffman-Based Approach for Low-Resource Languages”中“Cross-Lingual Transfer”并未找到直接对应的中文术语，因此保留了“跨语言元数据”的直译形式，\n如果您有更具体的上下文，“Cross-Lingual”可以解释为“跨语言”的”，“那么可以进一步调整翻译以更加贴合原文意思。“
Enhancing Cross-Lingual Transfer through Reversible Transliteration: A Huffman-Based Approach for Low-Resource Languages
Wenhao Zhuang, Yuan Sun, Xiaobing Zhao

## 互教共适应策略与奖励模型。
Mutual-Taught for Co-adapting Policy and Reward Models
Tianyuan Shi, Canbin Huang, Fanqi Wan, Longguang Zhong, Ziyi Yang, Weizhou Shen, Xiaojun Quan, Ming Yan

## 通过数据细化和本地化洞察增强基于事件的新闻聚类摘要。
Enhancing Event-centric News Cluster Summarization via Data Sharpening and Localization Insights
Longyin Zhang, Bowei Zou, AiTi Aw

## MockConf：学生解读数据集：分析、词级和短语级对齐及baseline。
MockConf: A Student Interpretation Dataset: Analysis, Word- and Span-level Alignment and Baselines
Dávid Javorský, Ondřej Bojar, François Yvon

## 一改全更新：一次编辑在多个模型间参数化知识同步。
One for All: Update Parameterized Knowledge Across Multiple Models with Once Edit
Weitao Ma, Xiyuan Du, Xiaocheng Feng, Lei Huang, Yichong Huang, Huiyi Zhang, Xiaoliang Yang, Baohang Li, Xiachong Feng, Ting Liu, Bing Qin

## 在评估长篇故事时应注意什么？一项关于长篇故事评估的系统研究。
What Matters in Evaluating Book-Length Stories? A Systematic Study of Long Story Evaluation
Dingyi Yang, Qin Jin

## BMIKE-53：研究跨语言知识编辑的上下文学习方法。
BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context Learning
Ercong Nie, Bo Shao, Mingyang Wang, Zifeng Ding, Helmut Schmid, Hinrich Schuetze

## PROPER：一种渐进学习框架，用于具有组级适应的个性化大型语言模型。
PROPER: A Progressive Learning Framework for Personalized Large Language Models with Group-Level Adaptation
Linhai Zhang, Jialong Wu, Deyu Zhou, Yulan He

## 外部验证工具能否提高LLM作为法官时的标注质量？
Can external validation tools improve annotation quality for LLM-as-a-Judge?
Arduin Findeis, Floris Weers, Guoli Yin, Ke Ye, Ruoming Pang, Tom Gunter

## MMBoundary：通过推理步骤 certainty 校准提升 ML 大模型知识边界意识。
MMBoundary: Advancing MLLM Knowledge Boundary Awareness through Reasoning Step Confidence Calibration
Zhitao He, Sandeep Polisetty, Zhiyuan Fan, Shujin Wu, Yuchen Huang, Yi R. Fung

## 通过有效数据过滤使大型语言模型遵循指令并减少虚构内容。
Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering
Shuzheng Si, Haozhe Zhao, Gang Chen, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Kaikai An, Kangyang Luo, Chen Qian, Fanchao Qi, Baobao Chang, Maosong Sun

## 面向任务的信息分解方法在端到端密集视频字幕生成中的应用。
Task-Specific Information Decomposition for End-to-End Dense Video Captioning
Zhiyue Liu, Xinru Zhang, Jinyuan Liu

## RAEmoLLM：基于情感信息的语境学习增强检索模型在跨域 misinformation 检测中的应用。
RAEmoLLM: Retrieval Augmented LLMs for Cross-Domain Misinformation Detection Using In-Context Learning Based on Emotional Information
Zhiwei Liu, Kailai Yang, Qianqian Xie, Christine de Kock, Sophia Ananiadou, Eduard Hovy

## PhysReason：基于物理推理的综合基准。
PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning
Xinyu Zhang, Yuxuan Dong, Yanrui Wu, Jiaxing Huang, Chengyou Jia, Basura Fernando, Mike Zheng Shou, Lingling Zhang, Jun Liu

## 私有记忆编辑：将记忆转变为一种防御手段以强化大型语言模型的数据隐私。
Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models
Elena Sofia Ruzzetti, Giancarlo A. Xompero, Davide Venditti, Fabio Massimo Zanzotto

## 一次足够：将多轮攻击 Consolidating 整合为高效的单轮提示以供 LLM 使用。
One-Shot is Enough: Consolidating Multi-Turn Attacks into Efficient Single-Turn Prompts for LLMs
Junwoo Ha, Hyunjun Kim, Sangyoon Yu, Haon Park, Ashkan Yousefpour, Yuna Park, Suhyun Kim

## LIFBench：评估大型语言模型在长上下文场景中指令跟随性能和稳定性的基准。
LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios
Xiaodong Wu, Minhao Wang, Yichen Liu, Xiaoming Shi, He Yan, Lu Xiangju, Junmin Zhu, Wei Zhang

## FEAT：一种低成本自动生成与标注框架下的偏好反馈数据集，用于英语人工智能辅导。
FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring
Hyein Seo, Taewook Hwang, Yohan Lee, Sangkeun Jung

## 时间有其位置吗？时间头部：语言模型回忆时间特定信息。
Does Time Have Its Place? Temporal Heads: Where Language Models Recall Time-specific Information
Yein Park, Chanwoong Yoon, Jungwoo Park, Minbyul Jeong, Jaewoo Kang

## 解析问题：利用定义和语义扩展进行性别歧视检测。
Explaining Matters: Leveraging Definitions and Semantic Expansion for Sexism Detection
Sahrish Khan, Gabriele Pergola, Arshad Jhumka

## 羊皮狼的行为：大规模语言模型准备好面对隐含的比喻性仇恨言论了吗？
Sheep’s Skin, Wolf’s Deeds: Are LLMs Ready for Metaphorical Implicit Hate Speech?
Jingjie Zeng, Yuanyuan Sun, zekun wang, Liang Yang, Hongfei Lin

## CalibraEval：调整预测分布以减轻LLM作为裁判时的选择偏差。
CalibraEval: Calibrating Prediction Distribution to Mitigate Selection Bias in LLMs-as-Judges
Haitao Li, Junjie Chen, Qingyao Ai, Zhumin Chu, Yujia Zhou, Qian Dong, Yiqun LIU

## 通过稀疏插值专家混合实现大模型升级中的自动专家发现。
Automatic Expert Discovery in LLM Upcycling via Sparse Interpolated Mixture-of-Experts
Shengzhuang Chen, Ying Wei, Jonathan Richard Schwarz

## RetroLLM：赋能大型语言模型在生成过程中检索细粒度证据。
RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation
Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yongkang Wu, Zhonghua Li, YE QI, Zhicheng Dou

## Velocitune：一种基于速度的动力域重权重方法用于持续预训练。
Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training
Zheheng Luo, Xin Zhang, Xiao Liu, Haoling Li, Yeyun Gong, Qi Chen, Peng CHENG

## VoxEval：评估端到端语音语言模型的知识理解能力。
VoxEval: Benchmarking the Knowledge Understanding Capabilities of End-to-End Spoken Language Models
Wenqian Cui, Xiaoqi Jiao, Ziqiao Meng, Irwin King

## FRACTAL：从聚合文本标签中获取精细粒度评分。
FRACTAL: Fine-Grained Scoring from Aggregate Text Labels
Yukti Makhija, Priyanka Agrawal, Rishi Saket, Aravindan Raghuveer

## SimulS2S-LLM：解锁语音LLM的即时语音转语音翻译推理。
SimulS2S-LLM: Unlocking Simultaneous Inference of Speech LLMs for Speech-to-Speech Translation
Keqi Deng, Wenxi Chen, Xie Chen, Phil Woodland

## ChronoSense：探索大型语言模型中的事件时间间隔时间理解。
ChronoSense: Exploring Temporal Understanding in Large Language Models with Time Intervals of Events
Duygu Sezen Islakoglu, Jan-Christoph Kalo

## 论文标题：关于合成数据以进行问题回答中的上下文归因的研究。
On Synthesizing Data for Context Attribution in Question Answering
Gorjan Radevski, Kiril Gashteovski, Shahbaz Syed, Christopher Malon, Sebastien Nicolas, Chia-Chien Hung, Timo Sztyler, Verena Heußer, Wiem Ben Rim, Masafumi Enomoto, Kunihiro Takeoka, Masafumi Oyamada, Goran Glavaš, Carolin Lawrence

## 通过检索头引导优化提升大规模语言模型的上下文忠实性。
Improving Contextual Faithfulness of Large Language Models via Retrieval Heads-Induced Optimization
Lei Huang, Xiaocheng Feng, Weitao Ma, Yuchun Fan, Xiachong Feng, Yangfan Ye, Weihong Zhong, Yuxuan Gu, Baoxin Wang, Dayong Wu, Guoping Hu, Bing Qin

## ACT：知识丰富的代理以设计和执行复杂任务。
ACT: Knowledgeable Agents to Design and Perform Complex Tasks
Makoto Nakatsuji, Shuhei Tateishi, Yasuhiro Fujiwara, Ayaka Matsumoto, Narichika Nomoto, Yoshihide Sato

## 逻辑形式补充概率理解语言模型（及人类）的表现。
Logical forms complement probability in understanding language model (and human) performance
Yixuan Wang, Freda Shi

## 全球视角：在拓展教学过程中打破“固有思维模式”。
Global Eye: Breaking the “Fixed Thinking Pattern” during the Instruction Expansion Process
wenxuan lu, Wei Liu, Jian Luan, Bin Wang, Songhao Jiang, Tianning Zang

## 解开表示与选择在数据精简中作用的谜题。
Disentangling the Roles of Representation and Selection in Data Pruning
Yupei Du, Yingjin Song, Hugh Mee Wong, Daniil Ignatev, Albert Gatt, Dong Nguyen

## TST：基于模式的自上而下并动态感知的文本到表格任务智能体。
TST: A Schema-Based Top-Down and Dynamic-Aware Agent of Text-to-Table Tasks
Peiwen Jiang, Haitong Jiang, Ruhui Ma, Yvonne Jie Chen, Jinhua Cheng

## 受控长度生成用于黑盒大语言模型。
Length Controlled Generation for Black-box LLMs
Yuxuan Gu, Wenjie Wang, Xiaocheng Feng, Weihong Zhong, kun Zhu, Lei Huang, Ting Liu, Bing Qin, Tat-Seng Chua

## Mis-prompt：大型语言模型主动错误处理能力基准测试。
Mis-prompt: Benchmarking Large Language Models for Proactive Error Handling
Jiayi Zeng, Yizhe Feng, Mengliang He, Wenhui Lei, Wei Zhang, Zeming Liu, Xiaoming Shi, Aimin Zhou

## EventRAG：通过事件知识图谱增强LLM生成能力。
EventRAG: Enhancing LLM Generation with Event Knowledge Graphs
Zairun Yang, Yilin Wang, Zhengyan Shi, Yuan Yao, Lei Liang, Keyan Ding, Emine Yilmaz, Huajun Chen, Qiang Zhang

## 大型语言模型的神经元级序列编辑。
Neuron-Level Sequential Editing for Large Language Models
Houcheng Jiang, Junfeng Fang, Tianyu Zhang, Baolong Bi, An Zhang, Ruipeng Wang, Tao Liang, Xiang Wang

## 不能本末倒置：多模态安全意识 benchmarks 多模态 LLCs。
Can’t See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs
Wenxuan Wang, Xiaoyuan Liu, Kuiyi Gao, Jen-tse Huang, Youliang Yuan, Pinjia He, Shuai Wang, Zhaopeng Tu

## TripCraft：时空精细旅游规划基准。
TripCraft: A Benchmark for Spatio-Temporally Fine Grained Travel Planning
Soumyabrata Chaudhuri, Pranav Purkar, Ritwik Raghav, Shubhojit Mallick, Manish Gupta, Abhik Jana, Shreya Ghosh

## 监督微调通过交替的注意力头激活模式实现快速任务适应。
Supervised Fine-Tuning Achieve Rapid Task Adaption Via Alternating Attention Head Activation Patterns
Yang Zhao, Li Du, Xiao Ding, Kai Xiong, Ting Liu, Bing Qin

## 大型语言模型在问答中评估复杂数字归属吗？基于知识图谱的自动基准测试。
Can LLMs Evaluate Complex Attribution in QA? Automatic Benchmarking using Knowledge Graphs
Nan Hu, Jiaoyan Chen, Yike Wu, Guilin Qi, Hongru WANG, Sheng Bi, Yongrui Chen, Tongtong Wu, Jeff Z. Pan

## DualGuard：一种用于基于分割的大型语言模型微调双向防御的参数空间转换方法。
DualGuard: A Parameter Space Transformation Approach for Bidirectional Defense in Split-Based LLM Fine-Tuning
Zihan Liu, Yizhen Wang, Rui Wang, Sai Wu

## Movie101v2：改进的电影叙事基准。
Movie101v2: Improved Movie Narration Benchmark
Zihao Yue, Yepeng Zhang, Ziheng Wang, Qin Jin

## 价值观画像：通过人类对齐基准理解大型语言模型的价值观。
Value Portrait: Understanding Values of LLMs with Human-aligned Benchmark
Jongwook Han, Dongmin Choi, Woojung Song, Eun-Ju Lee, Yohan Jo

## 积极参与！识别并解决不确定性。
Do not Abstain! Identify and Solve the Uncertainty
Jingyu Liu, JingquanPeng, xiaopeng Wu, Xubin Li, Tiezheng Ge, Bo Zheng, Yong Liu

## FEA-Bench：用于评估特征实现级别代码生成的基准测试。
FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation for Feature Implementation
Wei Li, Xin Zhang, Zhongxin Guo, Shaoguang Mao, Wen Luo, Guangyue Peng, Yangyu Huang, Houfeng Wang, Scarlett Li

## 使用基于LLM的文档组织方法从视觉丰富的文件中提取信息。
Information Extraction from Visually Rich Documents using LLM-based Organization of Documents into Independent Textual Segments
Aniket Bhattacharyya, Anurag Tripathi, Ujjal Das, Archan Karmakar, Amit Pathak, Maneesh Gupta

## LLM可以通过代理共进化模拟标准化病人。
LLMs Can Simulate Standardized Patients via Agent Coevolution
Zhuoyun Du, LujieZheng, Renjun Hu, Yuyang Xu, Xiawei Li, Ying Sun, Wei Chen, Jian Wu, Haolei Cai, Haochao Ying

## 通过对比知识解码：增强大型语言模型对编辑后事实的信心。
Decoding by Contrasting Knowledge: Enhancing Large Language Model Confidence on Edited Facts
Baolong Bi, Shenghua Liu, Lingrui Mei, Yiwei Wang, Junfeng Fang, Pengliang Ji, Xueqi Cheng

## 捐赠还是创造？比较情感标记的多模态社交媒体帖子的数据收集策略。
Donate or Create? Comparing Data Collection Strategies for Emotion-labeled Multimodal Social Media Posts
Christopher Bagdon, Aidan Combs, Carina Silberer, Roman Klinger

## 通过准符号抽象提高链式思考推理能力。
Improving Chain-of-Thought Reasoning via Quasi-Symbolic Abstractions
Leonardo Ranaldi, Marco Valentino, Andre Freitas

## SCOP：从认知视角评估大型语言模型的理解过程。
SCOP: Evaluating the Comprehension Process of Large Language Models from a Cognitive View
Yongjie Xiao, Hongru Liang, Peixin Qin, YAO ZHANG, Wenqiang Lei

## Table-Critic：一种用于表格推理中协作批评与改进的多智能体框架。
Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning
Peiying Yu, Guoxin Chen, Jingjing Wang

## 演绎与归纳推理在大规模语言模型中的作用。
The Role of Deductive and Inductive Reasoning in Large Language Models
Chengkun Cai, Xu Zhao, Haoliang Liu, Zhongyu Jiang, Tianfang Zhang, Zongkai Wu, Jenq-Neng Hwang, Serge Belongie, Lei Li

## ImpliHateVid：一个视频中隐含仇恨言论检测的标准数据集及两阶段对比学习框架。
ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos
Mohammad Zia Ur Rehman, Anukriti Bhatnagar, Omkar Kabde, Shubhi Bansal, Dr. Nagendra Kumar

## AGD：针对大型语言模型越狱攻击的对抗游戏防御方法。
AGD: Adversarial Game Defense Against Jailbreak Attacks in Large Language Models
Shilong Pan, Zhiliang Tian, Zhen Huang, Wanlong Yu, Zhihua Wen, Xinwang Liu, Kai Lu, Minlie Huang, Dongsheng Li

## 分层注意力生成更好的证明。
Hierarchical Attention Generates Better Proofs
Jianlong Chen, Chao Li, Yang Yuan, Andrew C Yao

## 从亚能力诊断到与人类对齐的生成：通过MarkerGen弥合文本长度控制的差距。
From Sub-Ability Diagnosis to Human-Aligned Generation: Bridging the Gap for Text Length Control via MarkerGen
Peiwen Yuan, Chuyi Tan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Yueqi Zhang, Jiayi Shi, Boyuan Pan, Yao Hu, Kan Li

## 通过代码引导的合成多模态数据生成实现文本丰富的图像理解扩展。
Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data Generation
Yue Yang, Ajay Patel, Matt Deitke, Tanmay Gupta, Luca Weihs, Andrew Head, Mark Yatskar, Chris Callison-Burch, Ranjay Krishna, Aniruddha Kembhavi, Christopher Clark

## 你真的可以信任代码 Copilot 吗？从代码安全角度评估大型语言模型。
Can You Really Trust Code Copilot? Evaluating Large Language Models from a Code Security Perspective
Yutao Mou, Xiao Deng, Yuxiao Luo, Shikun Zhang, Wei Ye

## 扩展的大量多语言数据集用于高性能语言技术。
An Expanded Massive Multilingual Dataset for High-Performance Language Technologies
Laurie Burchell, Ona De Gibert Bonet, Nikolay Arefyev, Mikko Aulamo, Marta Bañón, Pinzhen Chen, Mariia Fedorova, Liane Guillou, Barry Haddow, Jan Hajič, Jindřich Helcl, Erik Henriksson, Mateusz Klimaszewski, Ville Komulainen, Andrey Kutuzov, Joona Kytöniemi, Veronika Laippala, Petter Mæhlum, Bhavitvya Malik, Farrokh Mehryary, Vladislav Mikhailov, Nikita Moghe, Amanda Myntti, Dayyán O’Brien, Stephan Oepen, Proyag Pal, Jousia Piha, Sampo Pyysalo, Gema Ramírez-Sánchez, David Samuel, Pavel Stepachev, Jörg Tiedemann, Dušan Variš, Tereza Vojtěchová, Jaume Zaragoza-Bernabeu

## 元学习神经机制而非贝叶斯先验。
Meta-Learning Neural Mechanisms rather than Bayesian Priors
Michael Eric Goodale, Salvador Mascarenhas, Yair Lakretz

## 一个具有传染性越狱的捣蛋鬼在诚实小镇制造混乱。
A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns
Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao

## 从排序转变为集合选择以增强检索生成。
Shifting from Ranking to Set Selection for Retrieval Augmented Generation
Dahyun Lee, Yongrae Jo, Haeju Park, Moontae Lee

## 理解大型语言模型对社会偏见攻击的脆弱性。
Understanding Large Language Model Vulnerabilities to Social Bias Attacks
Jiaxu Zhao, Meng Fang, Fanghua Ye, Ke Xu, Qin Zhang, Joey Tianyi Zhou, Mykola Pechenizkiy

## LLM在标注过程中默认使用哪些人口统计学特征？
Which Demographics do LLMs Default to During Annotation?
Johannes Schäfer, Aidan Combs, Christopher Bagdon, Jiahui Li, Nadine Probol, Lynn Greschner, Sean Papay, Yarik Menchaca Resendiz, Aswathy Velutharambath, Amelie Wuehrl, Sabine Weber, Roman Klinger

## Agent-RewardBench：向着跨感知、规划和安全的现实世界多模态代理奖励建模统一基准迈进。
Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents
Tianyi Men, Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao

## 如果有证据支持就不算自夸：大语言模型能理解自吹自擂吗？
It’s Not Bragging If You Can Back It Up: Can LLMs Understand Braggings?
Jingjie Zeng, Huayang Li, Yuanyuan Sun, Liang Yang, Hongfei Lin

## 揭示知识编辑的欺骗性：浅层编辑的机理分析。
Revealing the Deceptiveness of Knowledge Editing: A Mechanistic Analysis of Superficial Editing
Jiakuan Xie, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao

## 优化问题语义空间以实现动态检索增强多跳问答。
Optimizing Question Semantic Space for Dynamic Retrieval-Augmented Multi-hop Question Answering
LINHAO YE, Qin Chen, Jie Zhou, Lang Yu, Zhikai Lei, Liang He

## ChatSOP：一种由SOP引导的MCTS规划框架，用于可控的LLM对话代理。
ChatSOP: An SOP-Guided MCTS Planning Framework for Controllable LLM Dialogue Agents
Zhigen Li, Jianxiang Peng, Yanmeng Wang, Yong Cao, Tianhao Shen, Minghui Zhang, Linxi Su, Shang Wu, Yihang Wu, YuQian Wang, Ye Wang, Wei Hu, Jianfeng Li, Shaojun Wang, Jing Xiao, Deyi Xiong

## 通过在线自博弈训练修复LLM分布偏移的自我批判。
Fixing Distribution Shifts of LLM Self-Critique via On-Policy Self-Play Training
Rong Bao, Donglei Yu, Kai Fan, Minpeng Liao

## 多跳问答中的掩码：语言模型在上下文排列变化时表现分析。
Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context Permutation
Wenyu Huang, Pavlos Vougiouklis, Mirella Lapata, Jeff Z. Pan

## 论文标题：忠实且稳健的基于LLM的定理证明用于NLI解释。
Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations
Xin Quan, Marco Valentino, Louise A. Dennis, Andre Freitas

## 从人类阅读到NLM理解：评估eye-tracking数据在编码器模型中的作用。
From Human Reading to NLM Understanding: Evaluating the Role of Eye-Tracking Data in Encoder-Based Models
Luca Dini, Lucia Domenichelli, Dominique Brunato, Felice Dell’Orletta

## 通过集成来自GitHub的自主工具来增强大型语言模型在开放领域的能力。
Enhancing Large Language Model’s Capabilities in Open Domains via Autonomous Tool Integration from GitHub
Bohan Lyu, Xin Cong, Heyang Yu, Pan Yang, Cheng Qian, Zihe Wang, Yujia Qin, Yining Ye, Yaxi Lu, Chen Qian, Zhong Zhang, Yukun Yan, Yankai Lin, Zhiyuan Liu, Maosong Sun

## 从参数推断注意力头的功能。
Inferring Functionality of Attention Heads from their Parameters
Amit Elhelo, Mor Geva

## 从孤立语言到语言家族：使用神经网络进行自动语言归类。
From Isolates to Families: Using Neural Networks for Automated Language Affiliation
Frederic Blum, Steffen Herbold, Johann-Mattis List

## 增强文本编辑以纠正语法错误：以阿拉伯语为例的研究。
Enhancing Text Editing for Grammatical Error Correction: Arabic as a Case Study
Bashar Alhafni, Nizar Habash

## 洞察超越视野：探索多模态LLM中的视觉知识冲突。
Insight Over Sight: Exploring the Vision-Knowledge Conflicts in Multimodal LLMs
Xiaoyuan Liu, Wenxuan Wang, Youliang Yuan, Jen-tse Huang, Qiuzhi Liu, Pinjia He, Zhaopeng Tu

## SceneGenAgent：基于编码代理的精确工业场景生成。
SceneGenAgent: Precise Industrial Scene Generation with Coding Agent
Xiao Xia, Dan Zhang, Zibo Liao, Zhenyu Hou, Tianrui Sun, Jing Li, Ling Fu, Yuxiao Dong

## ToolCoder：一种系统化的代码赋能工具学习框架，用于大型语言模型。
ToolCoder: A Systematic Code-Empowered Tool Learning Framework for Large Language Models
Hanxing Ding, Shuchang Tao, Liang Pang, Zihao Wei, Jinyang Gao, Bolin Ding, Huawei Shen, Xueqi Cheng

## 人类一致化：我们对大语言模型有多大的适应性？
Human Alignment: How Much Do We Adapt to LLMs?
Cazalets Tanguy, Ruben Janssens, Tony Belpaeme, Joni Dambre

## 探索大规模语言模型在文本操作中自发和条件性修改道德表达的能力。
Exploring LLMs’ Ability to Spontaneously and Conditionally Modify Moral Expressions through Text Manipulation
Candida Maria Greco, Lucio La Cava, Lorenzo Zangari, Andrea Tagarelli

## 当哈里遇到超人：对话生成中对话者的角色。
When Harry Meets Superman: The Role of The Interlocutor in Persona-Based Dialogue Generation
Daniela Occhipinti, Marco Guerini, Malvina Nissim

## 少而精：通过分层专家混合实现高效多语言扩展的大模型。
Less, but Better: Efficient Multilingual Expansion for LLMs via Layer-wise Mixture-of-Experts
Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou

## 重新审视基于自生成测试的自调试代码生成技术。
Revisit Self-Debugging with Self-Generated Tests for Code Generation
Xiancai Chen, Zhengwei Tao, Kechi Zhang, Changzhi Zhou, Xinyu Zhang, Wanli Gu, Yuanpeng He, Mengdi Zhang, Xunliang Cai, Haiyan Zhao, Zhi Jin

## 混合有序评分专家用于跨提示作文特质评分。
Mixture of Ordered Scoring Experts for Cross-prompt Essay Trait Scoring
Po-Kai Chen, Bo-Wei Tsai, Shao Kuan Wei, Chien-Yao Wang, Jia-Ching Wang, Yi-Ting Huang

## InSerter：未监督交错预训练条件生成语音指令跟随。
InSerter: Speech Instruction Following with Unsupervised Interleaved Pre-training
Dingdong WANG, Jin Xu, Ruihang Chu, Zhifang Guo, Xiong Wang, Jincenzi Wu, Dongchao Yang, Shengpeng Ji, Junyang Lin

## 使用手势提示增强语言模型中的口语 discourse 模型。
Enhancing Spoken Discourse Modeling in Language Models Using Gestural Cues
Varsha Suresh, M. Hamza Mughal, Christian Theobalt, Vera Demberg

## 样本离线线节省时间：在大语言模型时代进行知识蒸馏。  \n\n注释：这里的“离离”可能是输入错误或特殊术语，“离线”通常是指分开或远离的意思，需要根据具体上下文进行调整。如果是英文“offline”的意思，offline“则应翻译为“离线”。请根据具体语境确认具体翻译。
A Sample Offline Saves Time: Knowledge Distillation in the LLM Era
Anshumann, Mohd Abbas Zaidi, Akhil Kedia, Jinwoo Ahn, Taehwak Kwon, Kangwook Lee, Haejun Lee, Joohyung Lee

## 先分割还是先理解？探索大规模语言模型在无监督词分割中的极限。
Segment First or Comprehend First? Explore the Limit of Unsupervised Word Segmentation with Large Language Models
Zihong Zhang, Liqi He, Zuchao Li, Lefei Zhang, hai zhao, Bo Du

## 识别语言识别中的开放挑战。
Identifying Open Challenges in Language Identification
Rob van der Goot

## 间接提示注入攻击能否被检测和移除？
Can Indirect Prompt Injection Attacks Be Detected and Removed?
Yulin Chen, Haoran Li, Yuan Sui, Yufei He, Yue Liu, Yangqiu Song, Bryan Hooi

## 基于多轮对话的像素级推理分割。
Pixel-Level Reasoning Segmentation via Multi-turn Conversations
Dexian Cai, Xiaocui Yang, YongKang Liu, Daling Wang, Shi Feng, Yifei Zhang, Soujanya Poria

## 干扰效应：理解RAG中的无关段落。
The Distracting Effect: Understanding Irrelevant Passages in RAG
Chen Amiraz, Florin Cuconasu, Simone Filice, Zohar Karnin

## ExploraCoder：通过规划与链式探索促进对多种未见API的代码生成。
ExploraCoder: Advancing Code Generation for Multiple Unseen APIs via Planning and Chained Exploration
Yunkun Wang, Yue Zhang, Zhen Qin, Chen Zhi, Binhua Li, Fei Huang, Yongbin Li, Shuiguang Deng

## RUBY：一种有效的多约束多跳问题生成框架。
RUBY: An Effective Framework for Multi-Constraint Multi-Hop Question Generation
Wenzhuo Zhao, Shuangyin Li

## 利用攻击技术防御提示注入攻击
Defense Against Prompt Injection Attack by Leveraging Attack Techniques
Yulin Chen, Haoran Li, Zihao Zheng, Dekai Wu, Yangqiu Song, Bryan Hooi

## 图形表达：借助对话洞察揭露社交媒体中的 abuse。
Graphically Speaking: Unmasking Abuse in Social Media with Conversation Insights
Célia Nouri, Chloé Clavel, Jean-Philippe Cointet

## DNCASR：端到端训练的说话人归 attributive ASR。
DNCASR: End-to-End Training for Speaker-Attributed ASR
Xianrui Zheng, Chao Zhang, Phil Woodland

## CodeTool：通过过程监督提升LLM程序化工具调用能力。
CodeTool: Enhancing Programmatic Tool Invocation of LLMs via Process Supervision
YifeiLu, Fanghua Ye, Jian Li, Qiang Gao, Cheng Liu, Haibo Luo, nan du, Xiaolong Li, Feiliang Ren

## 探索个性化对话生成中的角色情感灵敏度。
Exploring Persona Sentiment Sensitivity in Personalized Dialogue Generation
Yonghyun Jun, Hwanhee Lee

## RARE：检索增强的推理增强技术用于大型语言模型
RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models
Hieu Tran, Zonghai Yao, Zhichao Yang, Junda Wang, Yifan Zhang, Feiyun Ouyang, Shuo Han, hong yu

## 大型语言模型中新型知识的获取与应用。
Acquisition and Application of Novel Knowledge in Large Language Models
Ziyu Shang, Jianghan Liu, Zhizhao Luo, Peng Wang, Wenjun Ke, Jiajun Liu, Zijie Xu, Guozheng Li

## 由大型语言模型引导的语义意识聚类主题建模
LLM-Guided Semantic-Aware Clustering for Topic Modeling
Jianghan Liu, Ziyu Shang, Wenjun Ke, Peng Wang, Zhizhao Luo, Jiajun Liu, Guozheng Li, Yining Li

## 层次括号编码在依赖解析中的标签化应用
Hierarchical Bracketing Encodings for Dependency Parsing as Tagging
Ana Ezquerro, David Vilares, Anssi Yli-Jyrä, Carlos Gómez-Rodríguez

## AntiLeakBench：通过自动构建包含更新真实世界知识的基准来防止数据污染。
AntiLeakBench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge
Xiaobao Wu, Liangming Pan, Yuxi Xie, Ruiwen Zhou, Shuai Zhao, Yubo Ma, Mingzhe Du, Rui Mao, Anh Tuan Luu, William Yang Wang

## 大型语言模型能否检测长链式推理中的错误？
Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?
Yancheng He, Shilong Li, Jiaheng Liu, Weixun Wang, Xingyuan Bu, Ge Zhang, Z.Y. Peng, Zhaoxiang Zhang, Zhicheng Zheng, Wenbo Su, Bo Zheng

## 动态订单模板预测在生成式方面基于情感分析中的应用。
Dynamic Order Template Prediction for Generative Aspect-Based Sentiment Analysis
Yonghyun Jun, Hwanhee Lee

## 基于最小对对码切换评估的评价方法。
Minimal Pair-Based Evaluation of Code-Switching
Igor Sterner, Simone Teufel

## 测量数据多样性以进行指令调优：系统分析与可靠指标。
Measuring Data Diversity for Instruction Tuning: A Systematic Analysis and A Reliable Metric
Yuming Yang, Yang Nan, Junjie Ye, Shihan Dou, Xiao Wang, Shuo Li, Huijie Lv, Tao Gui, Qi Zhang, Xuanjing Huang

## OmniAlign-V：朝向增强的人类偏好人本对齐的多模态大语言模型研究。
OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference
Xiangyu Zhao, Shengyuan Ding, Zicheng Zhang, Haian Huang, Maosongcao, Jiaqi Wang, Weiyun Wang, Xinyu Fang, Wenhai Wang, Guangtao Zhai, Hua Yang, Haodong Duan, Kai Chen

## 大型语言模型在aspect-based情感分析中的误差比较优化
Error Comparison Optimization for Large Language Models on Aspect-Based Sentiment Analysis
Qianlong Wang, Keyang Ding, Hengxin Gao, Hui Wang, Ruifeng Xu

## Micro-Act：通过可操作的自我推理缓解问答中的知识冲突。
Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning
Nan Huo, Jinyang Li, Bowen Qin, Ge Qu, Xiaolong Li, Xiaodong Li, Chenhao Ma, Reynold Cheng

## LLaMA-Omni 2：基于LLM的实时语音聊天机器人，带有自回归流式语音合成。
LLaMA-Omni 2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis
Qingkai Fang, Yan Zhou, Shoutao Guo, Shaolei Zhang, Yang Feng

## DNASpeech：一个包含对话、叙述和动作的情境化文本到语音数据集。
DNASpeech: A Contextualized and Situated Text-to-Speech Dataset with Dialogues, Narratives and Actions
Chuanqi Cheng, Hongda Sun, Bo Du, Shuo Shang, Xinrong Hu, Rui Yan

## 众包、爬虫抓取还是生成？创建SEA-VL——一个面向东南亚的多文化视觉-语言数据集。
Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia
Samuel Cahyawijaya, Holy Lovenia, Joel Ruben Antony Moniz, Tack Hwa Wong, Mohammad Rifqi Farhansyah, Thant Thiri Maung, Frederikus Hudi, David Anugraha, Muhammad Ravi Shulthan Habibi, Muhammad Reza Qorib, Amit Agarwal, Joseph Marvin Imperial, Hitesh Laxmichand Patel, Vicky Feliren, Bahrul Ilmi Nasution, Manuel Antonio Rufino, Genta Indra Winata, Rian Adam Rajagede, Carlos Rafael Catalan, Mohamed Fazli Mohamed Imam, Priyaranjan Pattnayak, Salsabila Zahirah Pranida, Kevin Pratama, Yeshil Bangera, Adisai Na-Thalang, Patricia Nicole Monderin, Yueqi Song, christian simon, Lynnette Hui Xian Ng, Richardy Lobo Sapan, Taki Hasan Rafi, Bin Wang, Supryadi, Kanyakorn Veerakanjana, Piyalitt Ittichaiwong, Matthew Theodore Roque, Karissa Vincentio, Takdanai Kreangphet, Phakphum Artkaew, Kadek Hendrawan Palgunadi, Yanzhi Yu, Rochana Prih Hastuti, William Nixon, Mithil Bangera, Adrian Xuan Wei Lim, Aye Hninn Khine, Hanif Muhammad Zhafran, Teddy Ferdinan, Audra Aurora Izzani, Ayushman Singh, Evan, Jauza Akbar Krito, Michael Anugraha, Fenal Ashokbhai Ilasariya, Haochen Li, John Amadeo Daniswara, Filbert Aurelian Tjiaranata, Eryawan Presma Yulianrifat, Can Udomcharoenchaikit, Fadil Risdian Ansori, Mahardika Krisna Ihsani, Giang Nguyen, Anab Maulana Barik, Dan John Velasco, Rifo Ahmad Genadi, Saptarshi Saha, Chengwei Wei, Isaiah Edri W. Flores, Kenneth Chen Ko Han, Anjela Gail D. Santos, Wan Shen Lim, Kaung Si Phyo, Tim Santos, Meisyarah Dwiastuti, Jiayun Luo, Jan Christian Blaise Cruz, Ming Shan Hee, Ikhlasul Akmal Hanif, M.Alif Al Hakim, Muhammad Rizky Sya’ban, Kun Kerdthaisong, Lester James Validad Miranda, Fajri Koto, Tirana Noor Fatyanosa, Alham Fikri Aji, Jostin Jerico Rosal, Jun Kevin, Robert Wijaya, Onno P. Kampman, Ruochen Zhang, Börje F. Karlsson, Peerat Limkonchotiwat

## Soundwave：少即是多——对于LLMs中的语音-文本对齐而言
Soundwave: Less is More for Speech-Text Alignment in LLMs
Yuhao Zhang, Zhiheng Liu, Fan Bu, Ruiyu Zhang, Benyou Wang, Haizhou Li

## ICR 探测器：追踪隐藏状态动态以实现可靠的幻觉检测在大语言模型中。
ICR Probe: Tracking Hidden State Dynamics for Reliable Hallucination Detection in LLMs
Zhenliang Zhang, Xinyu Hu, Huixuan Zhang, Junzhe Zhang, Xiaojun Wan

## 人工智能差距：社会经济地位如何影响语言技术交互。
The AI Gap: How Socioeconomic Status Affects Language Technology Interactions
Elisa Bassignana, Amanda Cercas Curry, Dirk Hovy

## OASIS：排序增强策略，以改善代码搜索。
OASIS: Order-Augmented Strategy for Improved Code Search
GAO Zuchen, Zizheng Zhan, Xianming LI, Erxin Yu, Haotian Zhang, chenbin, Yuqun Zhang, Jing Li

## 通过统一标签集探究大规模语言模型在多语言论辩归纳中的应用。
Probing LLMs for Multilingual Discourse Generalization Through a Unified Label Set
Florian Eichin, Yang Janet Liu, Barbara Plank, Michael A. Hedderich

## RoToR：针对不变序输入更可靠的响应方法。
RoToR: Towards More Reliable Responses for Order-Invariant Inputs
Soyoung Yoon, Dongha Ahn, Youngwon Lee, Minkyu Jung, HyungJoo Jang, seung-won hwang

## title: 通过具有语篇意识的语句澄清提高对话语篇解析能力。
Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification
Yaxin Fan, Peifeng Li, Qiaoming Zhu

## Tree-KG：知识密集型领域可扩展的知識圖譜構建框架。
Tree-KG: An Expandable KG Construction Framework for Knowledge-intensive Domains
Songjie Niu, Kaisen Yang, Rui Zhao, Yichao Liu, Zonglin Li, Hongning Wang, Wenguang Chen

## HAF-RM：一种奖励模型训练的混合对齐框架。
HAF-RM: A Hybrid Alignment Framework for Reward Model Training
Shujun Liu, Xiaoyu Shen, Yuhang Lai, Siyuan Wang, ShengbinYue, Zengfeng Huang, Xuanjing Huang, zhongyu wei

## ImPart：基于重要性差异稀疏化的模型压缩和合并改进方法在LLM中的应用。
ImPart: Importance-Aware Delta-Sparsification for Improved Model Compression and Merging in LLMs
Yan Yang, Yixia Li, Hongru WANG, Xuetao Wei, James Jianqiao Yu, Yun Chen, Guanhua Chen

## 温暖的话语：超过26000个英文单词的信任与社交规范。
Words of Warmth: Trust and Sociability Norms for over 26k English Words
Saif M. Mohammad

## MemeQA：全面评估 meme 理解能力。
MemeQA: Holistic Evaluation of Meme Understanding
Khoi P. N. Nguyen, Terrence Li, Derek Lou Zhou, Gabriel Xiong, Pranav Balu, Nandhan Alahari, Alan Huang, Tanush Chauhan, Harshavardhan Bala, Emre Guzelordu, Affan Kashfi, Aaron Xu, Suyesh Shrestha, Megan Vu, Jerry Wang, Vincent Ng

## DiffPO：扩散风格的偏好优化，用于大型语言模型推理时间对齐。
DiffPO: Diffusion-styled Preference Optimization for Inference Time Alignment of Large Language Models
Ruizhe Chen, Wenhao Chai, Zhifei Yang, Xiaotian Zhang, Ziyang Wang, Tony Quek, Joey Tianyi Zhou, Soujanya Poria, Zuozhu Liu

## 全球MMLU：理解并解决多语言评估中的文化与语言偏见。
Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation
Shivalika Singh, Angelika Romanou, Clémentine Fourrier, Jian Gang Ngui, David Ifeoluwa Adelani, Daniel Vila-Suero, Peerat Limkonchotiwat, Kelly Marchisio, Wei Qi Leong, Yosephine Susanto, Raymond Ng, Shayne Longpre, Sebastian Ruder, Wei-Yin Ko, Antoine Bosselut, Alice Oh, Andre Martins, Daphne Ippolito, Enzo Ferrante, Leshem Choshen, Marzieh Fadaee, Beyza Ermis, Sara Hooker

## BehaviorBox：自动化语言模型行为比较工具。
BehaviorBox: Automated Behavioral Comparison of Language Models
Lindia Tjuatja, Graham Neubig

## LoGU：带有不确定性表达的长文本生成。
LoGU: Long-form Generation with Uncertainty Expressions
Ruihan Yang, Caiqi Zhang, Zhisong Zhang, Xinting Huang, Sen Yang, Nigel Collier, Dong Yu, Deqing Yang

## ELBA-Bench：一种高效的大语言模型后门攻击基准测试。
ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models
Xuxu Liu, Siyuan Liang, Mengya Han, Yong Luo, Aishan Liu, Xiantao Cai, Zheng He, Dacheng Tao

## CC-Tuning：一种改进联合多语言监督微调的跨语言连接机制。
CC-Tuning: A Cross-Lingual Connection Mechanism for Improving Joint Multilingual Supervised Fine-Tuning
Yangfan Ye, Xiaocheng Feng, Zekun Yuan, Xiachong Feng, Libo Qin, Lei Huang, Weitao Ma, Yichong Huang, Zhirui Zhang, Yunfei Lu, Xiaohui Yan, Duyu Tang, Dandan Tu, Bing Qin

## 利用大型语言模型增强基于词典的文本嵌入。
Enhancing Lexicon-Based Text Embeddings with Large Language Models
Yibin Lei, Tao Shen, Yu Cao, Andrew Yates

## UniCodec：统一音频编码器，采用单域适配码本。
UniCodec: Unified Audio Codec with Single Domain-Adaptive Codebook
Yidi Jiang, Qian Chen, Shengpeng Ji, Yu Xi, Wen Wang, Chong Zhang, Xianghu Yue, ShiLiang Zhang, Haizhou Li

## MegaPairs：大规模数据合成以实现通用多模态检索。
MegaPairs: Massive Data Synthesis for Universal Multimodal Retrieval
Junjie Zhou, yongping xiong, Zheng Liu, Ze Liu, Shitao Xiao, Yueze Wang, Bo Zhao, Chen Jason Zhang, Defu Lian

## CoCoLex：基于置信度的复制解码方法在 grounded 法律文本生成中的应用。
CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation
Santosh T.Y.S.S, Youssef Tarek Elkhayat, Oana Ichim, Pranav Shetty, Dongsheng Wang, Zhiqiang Ma, Armineh Nourbakhsh, Xiaomo Liu

## 超越N-克gram：多语言抽象总结评价指标和策略的重新思考。
Beyond N-Grams: Rethinking Evaluation Metrics and Strategies for Multilingual Abstractive Summarization
Itai Mondshine, Tzuf Paz-Argaman, Reut Tsarfaty

## 当GPT泄露秘辛：全面评估GPT知识文件泄漏情况。
When GPT Spills the Tea: Comprehensive Assessment of Knowledge File Leakage in GPTs
Xinyue Shen, Yun Shen, Michael Backes, Yang Zhang

## SConU：大型语言模型中的选择性 conformal 不确定性。
SConU: Selective Conformal Uncertainty in Large Language Models
Zhiyuan Wang, Qingni Wang, Yue Zhang, Tianlong Chen, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu

## 中文简答QA：大型语言模型的事实性评估。
Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models
Yancheng He, Shilong Li, Jiaheng Liu, Yingshui Tan, Weixun Wang, Hui Huang, Xingyuan Bu, Hangyu Guo, Chengwei Hu, Boren Zheng, Zhuoran Lin, Dekai Sun, Zhicheng Zheng, Wenbo Su, Bo Zheng

## KERL：利用大型语言模型的知识增强个性化菜谱推荐。
KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models
Fnu Mohbat, Mohammed J Zaki

## 任何信息都只需一次截屏：统一搜索与可视化信息检索。
Any Information Is Just Worth One Single Screenshot: Unifying Search With Visualized Information Retrieval
Zheng Liu, Ze Liu, Zhengyang Liang, Junjie Zhou, Shitao Xiao, Chao Gao, Chen Jason Zhang, Defu Lian

## PVP：带有说服力评分、说服策略和观众特征的个性化视觉说服图像数据集
PVP: An Image Dataset for Personalized Visual Persuasion with Persuasiveness Ratings, Persuasion Strategies, and Viewer Characteristic
Junseo Kim, Jongwook Han, Dongmin Choi, Jongwook Yoon, Eun-Ju Lee, Yohan Jo

## 多语言仲裁：优化数据池以加速多语言进展。
Multilingual Arbitration: Optimizing Data Pools to Accelerate Multilingual Progress
Ayomide Odumakinde, Daniel D’souza, Pat Verga, Beyza Ermis, Sara Hooker

## 基于段落的注意力蒙蔽forPTs
Segment-Based Attention Masking for GPTs
Shahar Katz, Liran Ringel, Yaniv Romano, Lior Wolf

## 受控低秩适应与子空间正则化在大型语言模型持续训练中的应用。
Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models
Yuheng Lu, Bingshuo Qian, Caixia Yuan, Huixing Jiang, Xiaojie Wang

## 可调节的大语言模型驱动的主动推荐代理。
Tunable LLM-based Proactive Recommendation Agent
Mingze Wang, Chongming Gao, Wenjie Wang, Yangyang Li, Fuli Feng

## CULEMO：文化视角下的情感理解 - 跨文化情感理解基准测试。
CULEMO: Cultural Lenses on Emotion - Benchmarking LLMs for Cross-Cultural Emotion Understanding
Tadesse Destaw Belay, Ahmed Haj Ahmed, Alvin C Grissom II, Iqra Ameer, Grigori Sidorov, Olga Kolesnikova, Seid Muhie Yimam

## 将1568个标记压缩到一个向量中然后再返回：探索嵌入空间容量的极限。
Cramming 1568 Tokens into a Single Vector and Back Again: Exploring the Limits of Embedding Space Capacity
Yuri Kuratov, Mikhail Arkhipov, Aydar Bulatov, Mikhail Burtsev

## 多语言编码器的功能超乎你想象：适用于极度低资源语言的共享权重预训练。
Multilingual Encoder Knows more than You Realize: Shared Weights Pretraining for Extremely Low-Resource Languages
Zeli Su, Ziyin Zhang, Guixian Xu, Jianing Liu, Xu Han, Ting Zhang, Yushuang Dong

## AgentRM：通过奖励建模提升智能体泛化能力。
AgentRM: Enhancing Agent Generalization with Reward Modeling
Yu Xia, Jingru Fan, Weize Chen, Siyu Yan, Xin Cong, Zhong Zhang, Yaxi Lu, Yankai Lin, Zhiyuan Liu, Maosong Sun

## KiRAG：知识驱动的迭代检索器，用于增强检索增强生成。
KiRAG: Knowledge-Driven Iterative Retriever for Enhancing Retrieval-Augmented Generation
Jinyuan Fang, Zaiqiao Meng, Craig MacDonald

## 得分一致性与偏好对齐：部分奖励建模的双重一致性。
Score Consistency Meets Preference Alignment: Dual-Consistency for Partial Reward Modeling
Bin Xie, Bingbing Xu, Yige Yuan, Shengmao Zhu, Huawei Shen

## LLM位置泛化的计算机制。
Computation Mechanism Behind LLM Position Generalization
Chi Han, Heng Ji

## LLM容易受到指令性干扰的迷惑。
LLMs can be easily Confused by Instructional Distractions
Yerin Hwang, Yongil Kim, Jahyun Koo, Taegwan Kang, Hyunkyung Bae, Kyomin Jung

## DAC：一种动态注意力导向的无任务偏见提示压缩方法。
DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression
Yi Zhao, Zuchao Li, hai zhao, Baoyuan Qi, Liu Guoming

## IPO：你的语言模型秘密地充当了偏好分类器。
IPO: Your Language Model is Secretly a Preference Classifier
Shivank Garg, Ayush Singh, Shweta Singh, Paras Chopra

## 反转思维：通过偏好引导的逆向推理预热增强大规模语言模型。
Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up
Jiahao Yuan, Dehui du, Hao Zhang, Zixiang Di, Usman Naseem

## 深入MoE：从密集模型到专家混合的大语言模型多样化增强重构。
DIVE into MoE: Diversity-Enhanced Reconstruction of Large Language Models from Dense into Mixture-of-Experts
Yuchen Feng, Bowen Shen, Naibin Gu, Jiaxuan Zhao, Peng Fu, Zheng Lin, Weiping Wang

## nvAgent：基于协作代理工作流的自然语言自动数据可视化。
nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow
Geliang Ouyang, Jingyao Chen, Zhihe Nie, Yi Gui, Yao Wan, Hongyu Zhang, Dongping Chen

## PlanGenLLMs：LLM规划能力的现代综述。
PlanGenLLMs: A Modern Survey of LLM Planning Capabilities
Hui Wei, Zihao Zhang, Shenghua He, Tian Xia, Shijia Pan, Fei Liu

## IAM：通过不同尺度大语言模型间注意力映射实现高效推理。
IAM: Efficient Inference through Attention Mapping between Different-scale LLMs
Yi Zhao, Zuchao Li, hai zhao

## ZIPA：一类高效的多语言电话识别模型。
ZIPA: A family of efficient models for multilingual phone recognition
Jian Zhu, Farhan Samir, Eleanor Chodroff, David R. Mortensen

## 这是你的最终答案吗？测试时缩放改进了选择性问题回答。
Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering
William Jurayj, Jeffrey Cheng, Benjamin Van Durme

## GRACE：用于评估模型校准与人类校准之间差异的粒度基准。
GRACE: A Granular Benchmark for Evaluating Model Calibration against Human Calibration
Yoo Yeon Sung, Eve Fleisig, Yu Hou, Ishan Upadhyay, Jordan Lee Boyd-Graber

## 从工具到队友：在多轮编码互动中评估语言模型。
From Tools to Teammates: Evaluating LLMs in Multi-Session Coding Interactions
Nathanaël Carraz Rakotonirina, Mohammed Hamdy, Jon Ander Campos, Lucas Weber, Alberto Testoni, Marzieh Fadaee, Sandro Pezzelle, Marco Del Tredici

## 动态评估结合认知推理以确保大型语言模型多轮安全性的方法。
Dynamic Evaluation with Cognitive Reasoning for Multi-turn Safety of Large Language Models
Lanxue Zhang, Yanan Cao, Yuqiang Xie, Fang Fang, Yangxi Li

## CU-MAM：共现驱动的统一宏观结构用于论据挖掘。
CU-MAM: Coherence-Driven Unified Macro-Structures for Argument Mining
Debela Gemechu, Chris Reed

## 多语言文本到图像生成放大了性别刻板印象。
Multilingual Text-to-Image Generation Magnifies Gender Stereotypes
Felix Friedrich, Katharina Hämmerl, Patrick Schramowski, Manuel Brack, Jindřich Libovický, Alexander Fraser, Kristian Kersting

## 关于检索增强生成中语境利用情况的一次现实核查。
A Reality Check on Context Utilisation for Retrieval-Augmented Generation
Lovisa Hagström, Sara Vera Marjanovic, Haeun Yu, Arnav Arora, Christina Lioma, Maria Maistro, Pepa Atanasova, Isabelle Augenstein

## 这个听起来不对：评估田野语言学语料库中的语音转录质量。
That doesn’t sound right: Evaluating speech transcription quality in field linguistics corpora
Eric Le Ferrand, Bo Jiang, Emily Prud’hommeaux, Joshua Hartshorne

## 一种基于合成数据、预指令调优、模型合并和临床任务对齐的模块化临床SLMs方法。
A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment
Jean-Philippe Corbeil, Amin Dada, Jean-Michel Attendu, Asma Ben Abacha, Alessandro Sordoni, Lucas Caccia, Francois Beaulieu, Thomas Lin, Jens Kleesiek, Paul Vozila

## 引导而非强制：通过移除不必要的约束来增强对大型语言模型（LLMs）实施越狱攻击的可移植性。
Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints
Junxiao Yang, Zhexin Zhang, Shiyao Cui, Hongning Wang, Minlie Huang

## AlignDistil：基于自适应策略蒸馏的标记级语言模型对齐。
AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation
Songming Zhang, Xue Zhang, Tong Zhang, Bojie Hu, Yufeng Chen, Jinan Xu

## 使用联合多物种嵌入进行白脸卷尾猴声纹个体识别。
Acoustic Individual Identification of White-Faced Capuchin Monkeys Using Joint Multi-Species Embeddings
Álvaro Vega-Hidalgo, Artem Abzaliev, Thore Bergman, Rada Mihalcea

## Text-to-ES Bench：全面的自然语言到Elasticsearch查询转换基准测试。
Text-to-ES Bench: A Comprehensive Benchmark for Converting Natural Language to Elasticsearch Query
DonggeXue, Zhili Pu, Zhentao Xia, Hongli Sun, Ruihui Hou, Guangya Yu, Yupian Lin, Yongqi Fan, Jingping Liu, Tong Ruan

## DARS：动态动作重采样以通过自适应树遍历提升编码代理性能。
DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by Adaptive Tree Traversal
Vaibhav Aggarwal, Ojasv Kamal, Abhinav Japesh, Zhijing Jin, Bernhard Schölkopf

## Advversarial 对齐与锚点拖动漂移 ($A^3D^2$): 部分模态偏移的多模态领域适应。
Adversarial Alignment with Anchor Dragging Drift ($A^3D^2$): Multimodal Domain Adaptation with Partially Shifted Modalities
Jun Sun, Xinxin Zhang, Simin Hong, Jian Zhu, Lingfang Zeng

## 偏离航向：导航语言模型的可靠性挑战。
Steering off Course: Reliability Challenges in Steering Language Models
Patrick Queiroz Da Silva, Hari Sethuraman, Dheeraj Rajagopal, Hannaneh Hajishirzi, Sachin Kumar

## 论文标题：公平多任务表示学习通过方差不变概率解码。
Impartial Multi-task Representation Learning via Variance-invariant Probabilistic Decoding
Dou Hu, Lingwei Wei, Wei Zhou, Songlin Hu

## 广义注意力流：Transformer模型的特征归因 via 最大流Advertisement
Generalized Attention Flow: Feature Attribution for Transformer Models via Maximum Flow
Behrooz Azarkhalili, Maxwell W. Libbrecht

## LLM对垂直对齐文本操纵的脆弱性。
Vulnerability of LLMs to Vertically Aligned Text Manipulations
Zhecheng Li, Yiwei Wang, Bryan Hooi, Yujun Cai, Zhen Xiong, Nanyun Peng, Kai-Wei Chang

## AutoMixer：检查点残留作为自动数据混合器。
AutoMixer: Checkpoint Artifacts as Automatic Data Mixers
Ernie Chang, Yang Li, Patrick Huber, Vish Vogeti, David Kant, Yangyang Shi, Vikas Chandra

## 如果埃莉诺·里格比遇到ChatGPT：后LLM世界中的孤独研究。
If Eleanor Rigby Had Met ChatGPT: A Study on Loneliness in a Post-LLM World
Adrian de Wynter

## 结合音频、视觉和语义信息以增强多模态演讲者辨识在多方对话中的效果。
Integrating Audio, Visual, and Semantic Information for Enhanced Multimodal Speaker Diarization on Multi-party Conversation
Luyao Cheng, Hui Wang, Chong Deng, Siqi Zheng, Yafeng Chen, Rongjie Huang, Qinglin Zhang, Qian Chen, Xihao Li, Wen Wang

## 超越提示：一种高效的知识嵌入框架用于开放域问答。
Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering
Zhanghao Hu, Hanqi Yan, Qinglin Zhu, Zhenyi Shen, Yulan He, Lin Gui

## WE-MATH：你的大型多模态模型能达到人类水平的数学推理能力吗？
WE-MATH: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?
Runqi Qiao, Qiuna Tan, Guanting Dong, MinhuiWu, Chong Sun, Xiaoshuai Song, Jiapeng Wang, Zhuoma GongQue, Shanglin Lei, YiFan Zhang, Zhe Wei, Miaoxuan Zhang, Runfeng Qiao, Xiao Zong, Yida Xu, Peiqing Yang, Zhimin Bao, Muxi Diao, Chen Li, Honggang Zhang

## 基于协作信息的双调控顺序推荐的可控大语言模型方法。
Bi-Tuning with Collaborative Information for Controllable LLM-based Sequential Recommendation
Xinyu Zhang, Linmei Hu, Luhao Zhang, Wentao Cheng, Yashen Wang, Ge Shi, Chong Feng, Liqiang Nie

## 使用特征丰富的历时组成性预测模型模拟英语名词复合词的演变。
Modeling the Evolution of English Noun Compounds with Feature-Rich Diachronic Compositionality Prediction
Filip Miletić, Sabine Schulte im Walde

## 更安全还是更幸运？LLM作为安全性评估者并不稳健，容易受到数据偏差的影响。
Safer or Luckier? LLMs as Safety Evaluators Are Not Robust to Artifacts
Hongyu Chen, Seraphina Goldfarb-Tarrant

## V-Oracle：为您和我解码龟甲兽骨的 progressive 理解方法。
V-Oracle: Making Progressive Reasoning in Deciphering Oracle Bones for You and Me
Runqi Qiao, Qiuna Tan, Guanting Dong, MinhuiWu, Jiapeng Wang, YiFan Zhang, Zhuoma GongQue, Chong Sun, Yida Xu, Yadong Xue, Ye Tian, Zhimin Bao, LAN YANG, Chen Li, Honggang Zhang

## 通过字符级别建模提升语言和模态转换翻译性能。
Improving Language and Modality Transfer in Translation by Character-level Modeling
Ioannis Tsiamas, David Dale, Marta R. Costa-jussà

## AIR-Bench：自动化异构信息检索基准。
AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark
Jianlyu Chen, Nan Wang, Chaofan Li, Bo Wang, Shitao Xiao, Han Xiao, Hao Liao, Defu Lian, Zheng Liu

## 揭示文化盲点：分析mLLMs在程序性文本理解中的局限性。
Unveiling Cultural Blind Spots: Analyzing the Limitations of mLLMs in Procedural Text Comprehension
Amir Hossein Yari, Fajri Koto

## 一种用于缓解关系提取中实体偏见的变分方法。
A Variational Approach for Mitigating Entity Bias in Relation Extraction
Samuel Mensah, Elena Kochkina, Jabez Magomere, Joy Prakash Sain, Simerjot Kaur, Charese Smiley

## 有何不同？通过token模式支持用户识别提示和模型变化的影响。
What’s the Difference? Supporting Users in Identifying the Effects of Prompt and Model Changes Through Token Patterns
Michael A. Hedderich, Anyi Wang, Raoyuan Zhao, Florian Eichin, Jonas Fischer, Barbara Plank

## AutoMixAlign：LLM中多任务偏好优化的自适应数据混合方法
AutoMixAlign: Adaptive Data Mixing for Multi-Task Preference Optimization in LLMs
Nicholas E. Corrado, Julian Katz-Samuels, Adithya M Devraj, Hyokun Yun, Chao Zhang, Yi Xu, Yi Pan, Bing Yin, Trishul Chilimbi

## 拨号连接！通过适应模型来建模语言连续体并将方言适应模型。
DialUp! Modeling the Language Continuum by Adapting Models to Dialects and Dialects to Models
Niyati Bafna, Emily Chang, Nathaniel Romney Robinson, David R. Mortensen, Kenton Murray, David Yarowsky, Hale Sirin

## 基于误差的数据高效大型多模态模型调优。
Error-driven Data-efficient Large Multimodal Model Tuning
Barry Menglong Yao, Qifan Wang, Lifu Huang

## 使用扩散模型进行目标导向对话系统的规划。
Planning with Diffusion Models for Target-Oriented Dialogue Systems
Hanwen Du, Bo Peng, Xia Ning

## BIG5-CHAT：通过训练人类接地数据来塑造LLM的性格。
BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data
Wenkai Li, Jiarui Liu, Andy Liu, Xuhui Zhou, Mona T. Diab, Maarten Sap

## Align-SLM：基于人工智能反馈的强化学习无文本语音语言模型。
Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback
Guan-Ting Lin, Prashanth Gurunath Shivakumar, Aditya Gourav, Yile Gu, Ankur Gandhe, Hung-yi Lee, Ivan Bulyko

## 协同偏好对齐下的强弱合作
Synergistic Weak-Strong Collaboration by Aligning Preferences
Yizhu Jiao, Xuchao Zhang, Zhaoyang Wang, Yubo Ma, Zhun Deng, Rujia Wang, Chetan Bansal, Saravan Rajmohan, Jiawei Han, Huaxiu Yao

## 使用对比 fine-tuned 关系编码器建模复杂语义关系。
Modelling Complex Semantics Relation with Contrastively Fine-Tuned Relational Encoders
Naïm Es-sebbani, Esteban Marquer, Zied Bouraoui

## 论文标题翻译如下：\n《大型语言模型能否帮助揭示关于大型语言模型的见解？对前沿大型语言模型的大型规模、不断演化的文献分析。》
Can LLMs Help Uncover Insights about LLMs? A Large-Scale, Evolving Literature Analysis of Frontier LLMs
Jungsoo Park, Junmo Kang, Gabriel Stanovsky, Alan Ritter

## 通过比较判断增强机器翻译的人类评估。
Enhancing Human Evaluation in Machine Translation with Comparative Judgement
Yixiao Song, Parker Riley, Daniel Deutsch, Markus Freitag

## 放大跨性别和非二元性别群体的声音：面向LLMs的社区中心化危害分类体系。
Amplifying Trans and Nonbinary Voices: A Community-Centred Harm Taxonomy for LLMs
Eddie L. Ungless, Sunipa Dev, Cynthia L. Bennett, Rebecca Gulotta, Jasmijn Bastings, Remi Denton

## 交互式和表现性强的代码增强规划方法与大规模语言模型。
Interactive and Expressive Code-Augmented Planning with Large Language Models
Anthony Zhe Liu, Xinhe Wang, Jacob Sansom, Yao Fu, Jongwook Choi, Sungryull Sohn, Jaekyeom Kim, Honglak Lee

## 视频语言模型中的深度时间推理：通过完美时间评估动作时长与完成的跨语言研究。
Deep Temporal Reasoning in Video Language Models: A Cross-Linguistic Evaluation of Action Duration and Completion through Perfect Times
Olga Loginova, Sofía Ortega Loguinova

## 通过定向干预多调控语言模型的多属性方向。
Multi-Attribute Steering of Language Models via Targeted Intervention
Duy Nguyen, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal

## Infogen：从文档中生成复杂的统计图表。
Infogen: Generating Complex Statistical Infographics from Documents
Akash Ghosh, Aparna Garimella, Pritika Ramu, Sambaran Bandyopadhyay, Sriparna Saha

## 部分共存射提高了概念嵌入。
Partial Colexifications Improve Concept Embeddings
Arne Rubehn, Johann-Mattis List

## 改进的无偏水印大语言模型
Improved Unbiased Watermark for Large Language Models
Ruibo Chen, Yihan Wu, Junfeng Guo, Heng Huang

## 曾见于此？从 eye 运动解码重复阅读。
Déjà Vu? Decoding Repeated Reading from Eye Movements
Yoav Meiri, Omer Shubi, Cfir Avraham Hadar, Ariel Kreisberg Nitzav, Yevgeni Berzak

##  bilingual语言模型中共享语法表示的获得研究。
On the Acquisition of Shared Grammatical Representations in Bilingual Language Models
Catherine Arnett, Tyler A. Chang, James A. Michaelov, Ben Bergen

## 论文标题：大型语言模型能否识别科学研究中的关键局限性？对AI研究论文的系统评估。
Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers
Zhijian Xu, Yilun Zhao, Manasi Patwardhan, Lovekesh Vig, Arman Cohan

## 使用Shapley互作用理解模型如何利用结构。
Using Shapley interactions to understand how models use structure
Diganta Misra, Divyansh Singhvi, Andrej Erkelens, Raghav Jain, Isabel Papadimitriou, Naomi Saphra

## GenKnowSub：通过通用知识移除提高大语言模型的模块性和可重用性。
GenKnowSub: Improving Modularity and Reusability of LLMs through General Knowledge Subtraction
Mohammadtaha Bagherifard, Sahar Rajabi, Ali Edalat, Yadollah Yaghoobzadeh

## 使用大型语言模型分类不可靠叙述者。
Classifying Unreliable Narrators with Large Language Models
Anneliese Brei, Katharine Henry, Abhisheik Sharma, Shashank Srivastava, Snigdha Chaturvedi

## AdaptAgent：通过少量示例学习从人类示范中适应多模态网络代理
AdaptAgent: Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations
Gaurav Verma, Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Tucker Balch, Manuela Veloso

## ConceptCarve：动态呈现证据。
ConceptCarve: Dynamic Realization of Evidence
Eylon Caplan, Dan Goldwasser

## 对抗性标记化
Adversarial Tokenization
Renato Geh, Zilei Shao, Guy Van den Broeck

## 论文标题：通过提升回归和基于LLM推断的功能进行开放世界规划的实体代理。
Open-World Planning via Lifted Regression with LLM-Inferred Affordances for Embodied Agents
Xiaotian Liu, Ali Pesaranghader, HANZE LI, Punyaphat Sukcharoenchaikul, Jaehong Kim, Tanmana Sadhu, Hyejeong Jeon, Scott Sanner

## QQSUM：一种基于评价的产品问答中的量化查询聚焦摘要的新任务和模型
QQSUM: A Novel Task and Model of Quantitative Query-Focused Summarization for Review-based Product Question Answering
An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh, Zhuang Li

## SELF-PERCEPT：内省有助于检测对话中多人心理操控的大语言模型。
SELF-PERCEPT: Introspection Improves Large Language Models’ Detection of Multi-Person Mental Manipulation in Conversations
Danush Khanna, Pratinav Seth, Sidhaarth Sredharan Murali, Aditya Kumar Guru, Siddharth Shukla, Tanuj Tyagi, SANDEEP CHAURASIA, Kripabandhu Ghosh

## 穿越人类-大模型对接中的裂隙：研究与基准测试
Navigating Rifts in Human-LLM Grounding: Study and Benchmark
Omar Shaikh, Hussein Mozannar, Gagan Bansal, Adam Fourney, Eric Horvitz

## SYNTHIA：基于功能组合的新颖概念设计。
SYNTHIA: Novel Concept Design with Affordance Composition
Hyeonjeong Ha, Xiaomeng Jin, Jeonghwan Kim, Jiateng Liu, Zhenhailong Wang, Khanh Duy Nguyen, Ansel Blume, Nanyun Peng, Kai-Wei Chang, Heng Ji

## 基于动机访谈的咨询中一致的客户模拟。
Consistent Client Simulation for Motivational Interviewing-based Counseling
Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, Nicholas Gabriel Lim, Cameron Tan Shi Ern, Phey Ling KIT, Jenny Giam Xiuhui, John Pinto, Ee-Peng Lim

## (RSA)²：一种考虑修辞策略的合理言语行为框架，用于隐喻语言理解。
(RSA)2: A Rhetorical-Strategy-Aware Rational Speech Act Framework for Figurative Language Understanding
Cesare Spinoso-Di Piano, David Eric Austin, Pablo Piantanida, Jackie CK Cheung

## 结构推理提升大模型对分子的理解。
Structural Reasoning Improves Molecular Understanding of LLM
Yunhui Jang, Jaehyung Kim, Sungsoo Ahn

## CAMI：一种通过状态推断和支持主题探索的心理咨询代理，以促进动机访谈。
CAMI: A Counselor Agent Supporting Motivational Interviewing through State Inference and Topic Exploration
Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, Phey Ling KIT, Nicholas Gabriel Lim, Cameron Tan Shi Ern, Ee-Peng Lim

## 重实质轻形式：评估主动对话辅导代理。
Substance over Style: Evaluating Proactive Conversational Coaching Agents
Vidya Srinivas, Xuhai Xu, Xin Liu, Kumar Ayush, Isaac Galatzer-Levy, Shwetak Patel, Daniel McDuff, Tim Althoff

## 面向语法错误修正的目标句法评估。
Targeted Syntactic Evaluation for Grammatical Error Correction
Aomi Koyama, Masato Mita, Su-Youn Yoon, Yasufumi Takama, Mamoru Komachi

## 先了解你，再成为更好的你：通过隐含特征建模人类like的用户模拟器
Know You First and Be You Better: Modeling Human-Like User Simulators via Implicit Profiles
Kuang Wang, Xianfei Li, Shenghao Yang, Li Zhou, Feng Jiang, Haizhou Li

## AUTALIC：反自闭症主义语言数据集（ contexts 中的反自闭症主义语言 ）
AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context
Naba Rizvi, Harper Strickland, Daniel Gitelman, Tristan Cooper, Alexis Morales Flores, Aekta Kallepalli, Akshat Alurkar, Haaset Owens, Saleha Ahmedi, Isha Khirwadkar, Imani N. S. Munyaka, Nedjma Ousidhoum

## 通过语言特征分析检测大模型生成的韩文文本。
Detecting LLM-Generated Korean Text through Linguistic Feature Analysis
Shinwoo Park, Shubin Kim, Do-Kyung Kim, Yo-Sub Han

## VQ-Eval：评估生成AIGC视频反馈的多模态LLM
VQ-Eval: Evaluating Multimodal LLMs for Generating Feedback on AIGC Videos
Tingyu Song, Guo Gan, Tongyan Hu, Yilun Zhao

## SAD-LM：大规模通用扩散语言模型
SAD-LM: A Large-Scale Generalist Diffusion Language Model
Jaesung Tae, Hamish Ivison, Sachin Kumar, Arman Cohan

## 基于扩展调查数据的语言模型微调用于预测公众意见分布。
Language Model Fine-Tuning on Scaled Survey Data for Predicting Distributions of Public Opinions
Joseph Suh, Erfan Jahanparast, Suhong Moon, Minwoo Kang, Serina Chang

## 基于最优传输的token加权方案以增强偏好优化
Optimal Transport-Based Token Weighting scheme for Enhanced Preference Optimization
Meng Li, Guangda Huzhang, Haibo Zhang, Xiting Wang, Anxiang Zeng

## CORDIAL：多模态大型语言模型能否有效地理解连贯关系？
CORDIAL: Can Multimodal Large Language Models Effectively Understand Coherence Relationships?
Aashish Anantha Ramakrishnan, Aadarsh Anantha Ramakrishnan, Dongwon Lee

## 论文标题翻译如下：\n《揭示链式思维推理对直接偏好优化的影响：从文本到SQL的启示》
Uncovering the Impact of Chain-of-Thought Reasoning for Direct Preference Optimization: Lessons from Text-to-SQL
Hanbing Liu, Haoyang Li, Xiaokang Zhang, Ruotong Chen, Haiyong Xu, Tian Tian, Qi Qi, Jing Zhang

## 关于跨测量系统的一般化：LLMs在代表性不足的文化中需要更多的测试时计算量。
On Generalization across Measurement Systems: LLMs Entail More Test-Time Compute for Underrepresented Cultures
Minh Duc Bui, Kyung eun Park, Goran Glavaš, Fabian David Schmidt, Katharina von der Wense

## 真实性偏差及其超越：发现LLMs在问题解决推理中的隐藏信念。
Veracity Bias and Beyond: Uncovering LLMs’ Hidden Beliefs in Problem-Solving Reasoning
Yue Zhou, Barbara Di Eugenio

## 语言模型遇上了场景图：大型语言模型能理解和生成场景图吗？基准测试与实证研究
LLM Meets Scene Graph: Can Large Language Models Understand and Generate Scene Graphs? A Benchmark and Empirical Study
Dongil Yang, Minjin Kim, Sunghwan Kim, Beong-woo Kwak, Minjun Park, Jinseok Hong, Woontack Woo, Jinyoung Yeo

## 超越框架：拆解多智能体系统中的合作策略。
Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems
Haochun Wang, Sendong Zhao, Jingbo Wang, Zewen Qiang, Bing Qin, Ting Liu

## 无形之手：揭开大型语言模型在代码生成中提供者的偏见。
The Invisible Hand: Unveiling Provider Bias in Large Language Models for Code Generation
Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Qingshuang Bao, Weipeng Jiang, Qian Wang, Chao Shen, Yang Liu

## THOR-MoE：基于任务引导和语境响应的层级路由神经机器翻译。
THOR-MoE: Hierarchical Task-Guided and Context-Responsive Routing for Neural Machine Translation
Yunlong Liang, Fandong Meng, Jie Zhou

## 第三方能读懂我们的情绪吗？
Can third-parties read our emotions?
Jiayi Li, Yingfan Zhou, Pranav Narayanan Venkit, Halima Binte Islam, Sneha Arya, Shomir Wilson, Sarah Rajtmajer

## OZSpeech：具有学习先验条件流量匹配的一步零样本语音合成。
OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching
Nghia Huynh Nguyen Hieu, Ngoc Son Nguyen, Huynh Nguyen Dang, Thieu Vo, Truong-Son Hy, Van Nguyen

## 抽象表示和观察\nuser\n请翻译以下论文的内容：\nIntroduction: Abstract representationsments and observed preferences play a crucial role in the ordering of binomials in large language models meilleurs modèles de langagee。 These models are trained to generate human-like responses to input tasks Forexample, determining the relative preference of two options presented to the model。 Abstract representationsments allow the models to understand and generate nuances in languagely preferring one option over another。 Similarly， observed preferences allow the models to rank orders presented options seo根据相对重要性。 在大规模语言模型中， 抽象表示和观察到的偏好在排列二\n谎言节：抽象表示法和观察到的偏好在大规模语言模型中对二项排列中起着至关重要的的作用。这些模型被训练来生成类似于人类对给定任务的响应，例如，确定两个选项之间的相对偏好。抽象表示使模型能够理解并生成语言中的细微差别，从而更倾向于其中一个选项。同样，观察到的偏好让模型能够对两个给定的选项进行排序，根据它们的相对重要性。
The Role of Abstract Representations and Observed Preferences in the Ordering of Binomials in Large Language Models
Zachary Nicholas Houghton, Kenji Sagae, Emily Morgan

## K/DA：自动数据生成流水线，用于净化隐含 Offensive 语言的韩语内容。
K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean
Minkyeong Jeon, Hyemin Jeong, Yerang Kim, Jiyoung Kim, Jae Hyeon Cho, Byung-Jun Lee

## 神经元经验梯度：发现并量化神经元的全局线性可控性。
Neuron Empirical Gradient: Discovering and Quantifying Neurons’ Global Linear Controllability
Xin Zhao, Zehui Jiang, Naoki Yoshinaga

## JailbreakRadar：对LLM的 jailbreak 攻击的全面评估。
JailbreakRadar: Comprehensive Assessment of Jailbreak Attacks Against LLMs
Junjie Chu, Yugeng Liu, Ziqing Yang, Xinyue Shen, Michael Backes, Yang Zhang

## PsyDial：一个大规模长时间对话数据集，用于心理健康支持。
PsyDial: A Large-scale Long-term Conversational Dataset for Mental Health Support
Huachuan Qiu, Zhenzhong Lan

## 通过逐步纠正提升LLM的数学推理能力。
Enhancing Mathematical Reasoning in LLMs by Stepwise Correction
Zhenyu Wu, Qingkai Zeng, Zhihan Zhang, Zhaoxuan Tan, Chao Shen, Meng Jiang

## 世界建模使规划者更加出色：基于双偏好优化的体态任务规划。
World Modeling Makes a Better Planner: Dual Preference Optimization for Embodied Task Planning
Siyin Wang, Zhaoye Fei, Qinyuan Cheng, Shiduo Zhang, Panpan Cai, Jinlan Fu, Xipeng Qiu

## CogniBench：一个受法律启发的框架和数据集，用于评估大规模语言模型的认知忠实性。
CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models
Xiaqiang Tang, Jian Li, Keyu Hu, nan du, Xiaolong Li, Xi Zhang, Weigao Sun, Sihong Xie

## 通过基于变换器的大型语言模型从文本描述自动生成CAD建模序列。
Automated CAD Modeling Sequence Generation from Text Descriptions via Transformer-Based Large Language Models
JianXing Liao, Junyan Xu, Yatao Sun, Maowen Tang, Sicheng He, Jingxian Liao, Shui Yu, Yun Li, Xiaohong Guan

## 排除思维负担：在大型语言模型中减轻认知负荷以增强多项选择任务中的推理能力。
Exclusion of Thought: Mitigating Cognitive Load in Large Language Models for Enhanced Reasoning in Multiple-Choice Tasks
Qihang Fu, Yongbin Qin, Ruizhang Huang, Yanping Chen, Yulin Zhou, Lintao Long

## 理解大规模语言模型训练中的静默数据损坏。
Understanding Silent Data Corruption in LLM Training
Jeffrey Jian Ma, Hengzhi Pei, Leonard Lausen, George Karypis

## 通过一致性反思与修正增强目标导向的主动对话系统。
Enhancing Goal-oriented Proactive Dialogue Systems via Consistency Reflection and Correction
Didi Zhang, Yaxin Fan, Peifeng Li, Qiaoming Zhu

## 多语种神经机器翻译中源语言词元的目标语言空间注册。
Registering Source Tokens to Target Language Spaces in Multilingual Neural Machine Translation
Zhi Qu, Yiran Wang, Jiannan Mao, Chenchen Ding, Hideki Tanaka, Masao Utiyama, Taro Watanabe

## 神经不兼容性：大规模语言模型跨尺度参数知识转移的不可逾越鸿沟。
Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models
Yuqiao Tan, Shizhu He, Kang Liu, Jun Zhao

## Dolphin：通过思考、实践和反馈迈向闭环自动研究。
Dolphin: Moving Towards Closed-loop Auto-research through Thinking, Practice, and Feedback
Jiakang Yuan, Xiangchao Yan, Bo Zhang, Tao Chen, Botian Shi, Wanli Ouyang, Yu Qiao, LEI BAI, Bowen Zhou

## VisuoThink：借助多模态树搜索增强低层视觉语言模型的推理能力。
VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search
Yikun Wang, Siyin Wang, Qinyuan Cheng, Zhaoye Fei, Liang Ding, Qipeng Guo, Dacheng Tao, Xipeng Qiu

## PerSphere：一个综合框架，用于多维度视角检索和摘要。
PerSphere: A Comprehensive Framework for Multi-Faceted Perspective Retrieval and Summarization
Yun Luo, Yingjie Li, Xiangkun Hu, Qinglin Qi, Fang Guo, Qipeng Guo, Zheng Zhang, Yue Zhang

## 面向提示的内部状态用于大型语言模型的幻觉检测。
Prompt-Guided Internal States for Hallucination Detection of Large Language Models
Fujie Zhang, Peiqi Yu, Biao Yi, Baolei Zhang, Tong Li, Zheli Liu

## 类型学引导的适应性方法用于非洲自然语言处理。
Typology-Guided Adaptation for African NLP
Ndapa Nakashole

## 不要删除，而是解释！检测并语境化文化遗产收藏中的有害语言。
Don’t Erase, Inform! Detecting and Contextualizing Harmful Language in Cultural Heritage Collections
Orfeas Menis Mastromichalakis, Jason Liartis, Kristina Rose, Antoine Isaac, Giorgos Stamou

## ECLM：实体级语言模型在链式意图理解中的应用
ECLM: Entity Level Language Model for Spoken Language Understanding with Chain of Intent
Shangjian Yin, Peijie Huang, JiaTian Chen, Haojing Huang, Yuhong Xu

## 视觉与文化解释的评估：人类-VLM 协作的 K-Viscuit 基准。
Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration
ChaeHun Park, Yujin Baek, Jaeseok Kim, Yu-Jung Heo, Du-Seong Chang, Jaegul Choo

## FaithfulRAG：基于事实级别的冲突建模以实现上下文忠实的检索增强生成。
FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation
Qinggang Zhang, Zhishang Xiang, Yilin Xiao, Le Wang, Junhui Li, Jinsong Su, Xinrun Wang

## LED-合并：在位置-选举-不交集中处理模型合并中的安全-效益冲突。
LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint
Qianli Ma, Dongrui Liu, Qian Chen, Linfeng Zhang, Jing Shao

## 最大化大型 BERT 模型压缩效果的有效性。
Maximizing the Effectiveness of Larger BERT Models for Compression
Wen-Shu Fan, Su Lu, Shangyu Xing, Xin-Chun Li, De-Chuan Zhan

## MaCP：通过分层余弦投影实现的简洁而强大的适应方法。
MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection
Yixian Shen, Qi Bi, JIA-HONG HUANG, Hongyi Zhu, Andy D. Pimentel, Anuj Pathania

## 知识图谱重要：利用多图大语言模型提升基于知识的视觉推理。
Knowledge Image Matters: Improving Knowledge-Based Visual Reasoning with Multi-Image Large Language Models
Guanghui Ye, Huan Zhao, Zhixue Zhao, Xupeng Zha, Yang Liu, Zhihua Jiang

## IndicSynth：面向低资源印度语言的大规模多语言合成语音数据集。
IndicSynth: A Large-Scale Multilingual Synthetic Speech Dataset for Low-Resource Indian Languages
Divya V Sharma, Vijval Ekbote, Anubha Gupta

## 通过互补信息提取和对齐增强多模态检索。
Enhancing Multimodal Retrieval via Complementary Information Extraction and Alignment
Delong Zeng, Yuexiang Xie, Yaliang Li, Ying Shen

## 强化IR：一种领域自适应信息检索的双强化框架。
Reinforced IR: A Dual Reinforcement Framework For Domain-Adapted Information Retrieval
Chaofan Li, Jianlyu Chen, Yingxia Shao, Chaozhuo Li, Quanqing Xu, Defu Lian, Zheng Liu

## GUICourse：从通用视觉语言模型到多功能GUI代理。
GUICourse: From General Vision Language Model to Versatile GUI Agent
Wentong Chen, Junbo Cui, Jinyi Hu, Yujia Qin, Junjie Fang, Yue Zhao, Chongyi Wang, Jun Liu, Guirong Chen, Yupeng Huo, Yuan Yao, Yankai Lin, Zhiyuan Liu, Maosong Sun

## LLM能够推理程序语义吗？对LLM进行形式规格推断的全面评估。
Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference
Thanh Le-Cong, Bach Le, Toby Murray

## HACo-Det：人类与人工智能协作者环境下细粒度机器生成文本检测研究
HACo-Det: A Study Towards Fine-Grained Machine-Generated Text Detection under Human-AI Coauthoring
Zhixiong Su, Yichen Wang, Herun Wan, Zhaohan Zhang, Minnan Luo

## CoIR：代码信息检索模型的全面基准测试。
CoIR: A Comprehensive Benchmark for Code Information Retrieval Models
Xiangyang Li, Kuicai Dong, Yi Quan Lee, Wei Xia, Hao Zhang, Xinyi Dai, Yasheng Wang, Ruiming Tang

## 代理驱动的鲁棒多模态情感分析（基于 incomplete 数据）。
Proxy-Driven Robust Multimodal Sentiment Analysis with Incomplete Data
Aoqiang Zhu, Min Hu, Xiaohua Wang, Jiaoyun Yang, Yiming Tang, Ning An

## 知识图嵌入中的互信息视角。
A Mutual Information Perspective on Knowledge Graph Embedding
Jiang Li, Xiangdong Su, Zehua Duo, Tian Lan, Xiaotao Guo, Guanglai Gao

## JoPA：通过联合提示归因解释大型语言模型的生成。
JoPA: Explaining Large Language Model’s Generation via Joint Prompt Attribution
Yurui Chang, Bochuan Cao, Yujia Wang, Jinghui Chen, Lu Lin

## 并非所有术语都重要：面向召回的自适应学习在开放域问答中基于PLM的查询扩展。
Not All Terms Matter: Recall-Oriented Adaptive Learning for PLM-aided Query Expansion in Open-Domain Question Answering
Xinran Chen, Ben He, Xuanang Chen, Le Sun

## 使用元学习检测维基百科中的sockpuppet行为。
Detecting Sockpuppetry on Wikipedia Using Meta-Learning
Christine de Kock, Luc Raszewski

## 从文化背景角度分离语言媒介，评估多语言大型语言模型。
Disentangling Language Medium and Culture Context for Evaluating Multilingual Large Language Models
Jiahao Ying, Wei Tang, Yiran Zhao, Yixin Cao, Yu Rong, Wenxuan Zhang

## 使用大规模语言模型进行多样性导向的数据增强。
Diversity-oriented Data Augmentation with Large Language Models
Zaitian Wang, Jinghan Zhang, Xinhao Zhang, Kunpeng Liu, pengfei wang, Yuanchun Zhou

## IOPO：通过输入-输出偏好优化增强LLM的复杂指令跟随能力
IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization
Xinghua Zhang, Haiyang Yu, ChengFu, Fei Huang, Yongbin Li

## 对齐但盲目：对齐会通过降低对种族意识来增加隐性偏见。
Aligned but Blind: Alignment Increases Implicit Bias by Reducing Awareness of Race
Lihao Sun, Chengzhi Mao, Valentin Hofmann, Xuechunzi Bai

## 翻转知识蒸馏：利用小模型的专业知识提升文本匹配的大型语言模型。
Flipping Knowledge Distillation: Leveraging Small Models’ Expertise to Enhance LLMs in Text Matching
Mingzhe Li, Jing Xiang, Qishen Zhang, Kaiyang Wan, Xiuying Chen

## ProMALex：渐进式模块化适配器的多司法辖区法律语言模型。
ProMALex: Progressive Modular Adapters for Multi-Jurisdictional Legal Language Modeling
Santosh T.Y.S.S, Mohamed Hesham Elganayni

## 提示环保：大型语言模型代理易受环境干扰。
Caution for the Environment: LLM Agents are Susceptible to Environmental Distractions
Xinbei Ma, Yiting Wang, Yao Yao, Tongxin Yuan, Aston Zhang, Zhuosheng Zhang, hai zhao

## LLM能理解无声语音吗？探索通过LLM实现EMG到文本的转换。
Can LLMs Understand Unvoiced Speech? Exploring EMG-to-Text Conversion with LLMs
Payal Mohapatra, Akash Pandey, Xiaoyuan Zhang, Qi Zhu

## CoreEval：利用现实世界知识自动构建抗污染数据集以实现可靠的LLM评估。
CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation
Jingqian Zhao, Bingbing Wang, Geng Tu, Yice Zhang, Qianlong Wang, Bin Liang, Jing Li, Ruifeng Xu

## RiOT：基于残差优化树的有效提示细化。
RiOT: Efficient Prompt Refinement with Residual Optimization Tree
Chenyi Zhou, Zhengyan Shi, Yuan Yao, Lei Liang, Huajun Chen, Qiang Zhang

## 缓解检索增强多跳问答中的检索丢失问题。
Mitigating Lost-in-Retrieval Problems in Retrieval Augmented Multi-Hop Question Answering
Rongzhi Zhu, Xiangyu Liu, Zequn Sun, Yiwei Wang, Wei Hu

## 解码器仅模型LLM可以是掩码自编码器。
Decoder-Only LLMs can be Masked Auto-Encoders
Dan Qiao, Yuan Gao, Zheming Yang, Di Yang, Ziheng Wu, Pengcheng Lu, Minghui Qiu, Juntao Li, Min Zhang

## Condor：通过知识驱动的数据合成与精炼提升大型语言模型的一致性。
Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement
Maosongcao, Taolin Zhang, Mo Li, Chuyu Zhang, Yunxin Liu, Conghui He, Haodong Duan, Songyang Zhang, Kai Chen

## TableLoRA：大型语言模型中表格结构理解的低秩适应方法。
TableLoRA: Low-rank Adaptation on Table Structure Understanding for Large Language Models
Xinyi He, Yihao Liu, Mengyu Zhou, Yeye He, Haoyu Dong, Shi Han, Zejian Yuan, Dongmei Zhang

## 自动评估文本到图像生成任务：任务分解框架、精简训练与元评估基准。
Automatic Evaluation for Text-to-image Generation: Task-decomposed Framework, Distilled Training, and Meta-evaluation Benchmark
Rong-Cheng Tu, Zi-Ao Ma, Tian Lan, Yuehao Zhao, Heyan Huang, Xian-Ling Mao

## CulFiT：通过多语言批评数据合成的文化意识细粒度训练范式。
CulFiT: A Fine-grained Cultural-aware LLM Training Paradigm via Multilingual Critique Data Synthesis
Ruixiang Feng, Shen Gao, Xiuying Chen, Lisi Chen, Shuo Shang

## ChartLens：图表中的细粒度视觉归因。
ChartLens: Fine-grained Visual Attribution in Charts
Manan Suri, Puneet Mathur, Nedim Lipka, Franck Dernoncourt, Ryan A. Rossi, Dinesh Manocha

## LESA：可学习的LLM层扩展方法
LESA: Learnable LLM Layer Scaling-Up
Yifei Yang, zouying cao, Xinbei Ma, Yao Yao, Zhi Chen, Libo Qin, hai zhao

## 解码混合专家模型中的知识归因：基础-精炼协作与效率分析框架
Decoding Knowledge Attribution in Mixture-of-Experts: A Framework of Basic-Refinement Collaboration and Efficiency Analysis
Junzhuo Li, Bo Wang, Xiuze Zhou, Peijie Jiang, Jia Liu, Xuming Hu

## 朝向语言模型蒸馏能力差距定律的研究。
Towards the Law of Capacity Gap in Distilling Language Models
Chen Zhang, Qiuchi Li, Dawei Song, Zheyu Ye, Yan Gao, Yao Hu

## MMRC：大规模多模态大型语言模型在现实对话中理解能力的基准。
MMRC: A Large-Scale Benchmark for Understanding Multimodal Large Language Model in Real-World Conversation
Haochen Xue, Feilong Tang, Ming Hu, Yexin Liu, Qidong Huang, Yulong Li, Chengzhi Liu, Zhongxing Xu, Chong Zhang, Chun-Mei Feng, Yutong Xie, Imran Razzak, Zongyuan Ge, Jionglong Su, Junjun He, Yu Qiao

## 稳健编辑的关键：从理论洞察到实际进步。
Keys to Robust Edits: From Theoretical Insights to Practical Advances
Jianhao Yan, Futing Wang, Yun Luo, Yafu Li, Yue Zhang

## MEMERAG：一种多语言端到端元评估基准，用于检索增强生成。
MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation
María Andrea Cruz Blandón, Jayasimha Talur, Bruno Charron, Dong Liu, Saab Mansour, Marcello Federico

## WhiSPA：语义和心理对齐的悄声提示，结合自监督对比学习和学生-教师学习。
WhiSPA: Semantically and Psychologically Aligned Whisper with Self-Supervised Contrastive and Student-Teacher Learning
Rajath Rao, Adithya V Ganesan, Oscar Kjell, Jonah Luby, Akshay Raghavan, Scott M. Feltman, Whitney Ringwald, Ryan L. Boyd, Benjamin J. Luft, Camilo J. Ruggero, Neville Ryant, ROMAN KOTOV, H. Schwartz

## 通过多Agent强化学习实现的角色差异化推动协作辩论的进步。
Advancing Collaborative Debates with Role Differentiation through Multi-Agent Reinforcement Learning
Haoran Li, Ziyi Su, Yun Xue, Zhiliang Tian, YIPING SONG, Minlie Huang

## 利用知识增强树搜索推理提升大语言模型的分子结构解析。
Boosting LLM’s Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning
Xiang Zhuang, Bin Wu, Jiyu Cui, Kehua Feng, Xiaotong Li, Huabin Xing, Keyan Ding, Qiang Zhang, Huajun Chen

## S$^2$R：通过强化学习教会LLMs自我验证和自我修正。
S$^2$R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning
Ruotian Ma, Peisong Wang, Cheng Liu, Xingyan Liu, Jiaqi Chen, Bang Zhang, Xin Zhou, nan du, Jia Li

## 理论思维中情境理解的本质：关于故事情节角色问答的研究。
The Essence of Contextual Understanding in Theory of Mind: A Study on Question Answering with Story Characters
Chulun Zhou, Qiujing Wang, Mo Yu, Xiaoqian Yue, Rui Lu, Jiangnan Li, Yifan Zhou, Shunchi Zhang, Jie Zhou, Wai Lam

## 带偏好优化的检索增强微调用于视觉程序生成
Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation
Deokhyung Kang, Jeonghun Cho, Yejin Jeon, Sunbin Jang, Minsub Lee, JAWOON CHO, Gary Lee

## EdiText：基于扩散语言模型的可控粗细粒度文本编辑。
EdiText: Controllable Coarse-to-Fine Text Editing with Diffusion Language Models
Che Hyun Lee, Heeseung Kim, Jiheum Yeom, Sungroh Yoon

## XDAC：以解释性人工智能为导向的检测与 Attribution 分析韩语生成新闻评论的方法
XDAC: XAI-Driven Detection and Attribution of LLM-Generated News Comments in Korean
Wooyoung Go, Hyoungshick Kim, Alice Oh, Yongdae Kim

## STRICTA：结构化推理在同行评审及更广泛领域中的批判性文本评估。
STRICTA: Structured Reasoning in Critical Text Assessment for Peer Review and Beyond
Nils Dycke, Matej Zečević, Ilia Kuznetsov, Beatrix Suess, Kristian Kersting, Iryna Gurevych

## 压制赋权，纵容偏见：审核 Twitch 上仇恨言论的管理机制。
Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch
Prarabdh Shukla, Wei Yin Chong, Yash Patel, Brennan Schaffner, Danish Pruthi, Arjun Bhagoji

## 通过位置对比解码减轻长上下文语言模型后验显著性衰减。
Mitigating Posterior Salience Attenuation in Long-Context LLMs with Positional Contrastive Decoding
Zikai Xiao, Ziyang Wang, Wen MA, Yan Zhang, Wei Shen, WangYan, Luqi Gong, Zuozhu Liu

## CENTAUR：在隐私保护的变压器推理中实现隐私、效率与性能的不可能三角的桥梁。
CENTAUR: Bridging the Impossible Trinity of Privacy, Efficiency, and Performance in Privacy-Preserving Transformer Inference
Jinglong Luo, Guanzhong Chen, Yehong Zhang, SHIYU LIU, Hui Wang, Yue Yu, Xun Zhou, Yuan Qi, Zenglin Xu

## 对大型语言模型中成员推断攻击的统计与多视角 revisit 研究。
A Statistical and Multi-Perspective Revisiting of the Membership Inference Attack in Large Language Models
Bowen Chen, Namgi Han, Yusuke Miyao

## TUMLU：一个统一且原生的 Turkic 语言理解基准测试。
TUMLU: A Unified and Native Language Understanding Benchmark for Turkic Languages
Jafar Isbarov, Arofat Akhundjanova, Mammad Hajili, Kavsar Huseynova, Dmitry Gaynullin, Anar Rzayev, Osman Tursun, Aizirek Turdubaeva, Ilshat Saetov, Rinat Kharisov, Saule Belginova, Ariana Kenbayeva, Amina Alisheva, Abdullatif Köksal, SAMIR RUSTAMOV, Duygu Ataman

## 论文标题：挖掘人类和模型在道德基础和人类价值观注解中的不确定性模式。
Mining the uncertainty patterns of humans and models in the annotation of moral foundations and human values
Neele Falk, Gabriella Lapesa

## 在24小时内环游世界：探究大语言模型对时间与地点的理解。
Around the World in 24 Hours: Probing LLM Knowledge of Time and Place
Carolin Holtermann, Paul Röttger, Anne Lauscher

## 左右兼顾且无需池化：将LLM转换为文本编码器而无需训练。
Look Both Ways and No Sink: Converting LLMs into Text Encoders without Training
Ziyong Lin, Haoyi Wu, Shu Wang, Kewei Tu, Zilong Zheng, Zixia Jia

## 朝向大型语言模型一致性的不确定性估计。
Towards Harmonized Uncertainty Estimation for Large Language Models
Rui Li, Jing Long, Muge Qi, Heming Xia, Lei Sha, Peiyi Wang, Zhifang Sui

## 论文标题：“当你被告知一条狗是毋庸置疑的真理时，你叫它什么？——‘教条’：通过幽默测试LLM的泛化能力。”
“What do you call a dog that is incontrovertibly true? Dogma’’: Testing LLM Generalization through Humor
Alessio Cocchieri, Luca Ragazzi, Paolo Italiani, Giuseppe Tagliavini, Gianluca Moro

## 超越逻辑函数：对齐特征动态以实现有效的知识蒸馏。
Beyond Logits: Aligning Feature Dynamics for Effective Knowledge Distillation
Guoqiang Gong, Jiaxing Wang, Jin Xu, Deping Xiang, Zicheng Zhang, Leqi Shen, Yifeng Zhang, JunhuaShu, ZhaolongXing, Zhen Chen, Pengzhang Liu, Ke Zhang

## 我们是否已经进入由AI生成文本的世界？量化和监控社交媒体上的AIGT。
Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media
Zhen Sun, Zongmin Zhang, Xinyue Shen, Ziyi Zhang, Yule Liu, Michael Backes, Yang Zhang, Xinlei He

## VITAL：用于医疗领域多元一致性基准测试的新数据集。
VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare
Anudeex Shetty, Amin Beheshti, Mark Dras, Usman Naseem

## WET：通过线性变换水印克服嵌入服务中同义替换漏洞。
WET: Overcoming Paraphrasing Vulnerabilities in Embeddings-as-a-Service with Linear Transformation Watermarks
Anudeex Shetty, Qiongkai Xu, Jey Han Lau

## HoPE：一种新型无长周期衰减的位置编码，以增强上下文意识和外推能力。
HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation
Yuhan Chen, Ang Lv, Jian Luan, Bin Wang, Wei Liu

## One QuantLLM for ALL：为高效部署一次性微调量化大语言模型。
One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient Deployments
Ke Yi, Yuhui Xu, Heng Chang, Yuan Meng, Tong Zhang, Jia Li

## 通过批判性表示微调增强链条推理能力。
Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning
Chenxi Huang, Shaotian Yan, Liang Xie, Binbin Lin, Sinan Fan, Yue Xin, Deng Cai, Chen Shen, Jieping Ye

## MT-RAIG：多表检索增强洞察生成的新型基准和评估框架。
MT-RAIG: Novel Benchmark and Evaluation Framework for Retrieval-Augmented Insight Generation over Multiple Tables
Kwangwook Seo, Donguk Kwon, Dongha Lee

## 原生稀疏注意：硬件对齐且原生可训练的稀疏注意atti textDecoration不适用于文章内容，建议直接使用“标题ağ进行展示。准确的翻译如下：\n\n标题：原生稀疏注意力：硬件对齐且原生训练的稀疏注意力。
Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention
Jingyang Yuan, Huazuo Gao, Damai Dai, Junyu Luo, Liang Zhao, Zhengyan Zhang, Zhenda Xie, Yuxing Wei, Lean Wang, Zhiping Xiao, Yuqing Wang, Chong Ruan, Ming Zhang, Wenfeng Liang, Wangding Zeng

## DRAE：用于机器人终身学习和任务适应的动态检索增强专家网络。
DRAE: Dynamic Retrieval-Augmented Expert Networks for Lifelong Learning and Task Adaptation in Robotics
Yayu Long, Kewei Chen, Long Jin, Mingsheng Shang

## 在高压环境和不同 demographics 属性下，LVLMs 的情感理解能力是否会有所不同？
Does the Emotional Understanding of LVLMs Vary Under High-Stress Environments and Across Different Demographic Attributes?
Jaewook Lee, Yeajin Jang, Oh-Woog KWON, Harksoo Kim

## S2WTM：用于主题建模的球面 sliced-Wasserstein 自动编码器。
S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling
Suman Adhya, Debarshi Kumar Sanyal

## 利用论元连贯性增强来改善跨文档事件和实体共指解析。
Employing Discourse Coherence Enhancement to Improve Cross-Document Event and Entity Coreference Resolution
Xinyu Chen, Peifeng Li, Qiaoming Zhu

## 学习从另一个角度观察：启用双向注意力LLMs中单词语义的探针研究。
Learning to Look at the Other Side: A Probing Study of Word Semantics in LLMs with Enabled Bidirectional Attention
Zhaoxin Feng, MA Jianfei, Xiaoyi Bao, Xiaojing Zhao, Emmanuele Chersoni

## FCMR：金融跨模式多跳推理的稳健评估
FCMR: Robust Evaluation of Financial Cross-Modal Multi-Hop Reasoning
Seunghee Kim, Changhyeon Kim, Taeuk Kim

## SoftCoT：高效的链式思维方法，用于LLM推理。
SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs
Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao

## 超越提示工程：通过引导目标原子在大语言模型中实现稳健的行为控制。
Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering Target Atoms
Mengru Wang, Ziwen Xu, Shengyu Mao, Shumin Deng, Zhaopeng Tu, Huajun Chen, Ningyu Zhang

## 论文标题：Data Whisperer：通过少量示例上下文学习进行任务特定的大语言模型微调的高效数据选择。
Data Whisperer: Efficient Data Selection for Task-Specific LLM Fine-Tuning via Few-Shot In-Context Learning
Shaobo Wang, Xiangqi Jin, Ziming Wang, Jize Wang, Jiajun Zhang, Kaixin Li, Zichen Wen, Zhong Li, Conghui He, Xuming Hu, Linfeng Zhang

## 语言模型抵制对齐：来自数据压缩的证据。
Language Models Resist Alignment: Evidence From Data Compression
Jiaming Ji, Kaile Wang, Tianyi Qiu, Boyuan Chen, Jiayi Zhou, Changye Li, Hantao Lou, Josef Dai, Yunhuai Liu, Yaodong Yang

## 超越答案：通过细腻图推理与评估推动多跳QA的发展。
Beyond the Answer: Advancing Multi-Hop QA with Fine-Grained Graph Reasoning and Evaluation
Qichuan Liu, Chentao Zhang, Chenfeng Zheng, Guosheng Hu, Xiaodong Li, Zhihong Zhang

## 追踪与剖析大语言模型（LLMs）如何回忆事实性知识以回答现实世界问题 kukoukukkuukLLukkuukukkufffuk卢克克克fffuk卢克克悯悯fffuk卢克克oruslysfffuk卢克克fffuk卢克克fffuk卢克克fffukfffuk卢克克fffuk卢克克fffuk卢克克fffuk卢克克fffuk卢克克fffuk卢克克 Lu克克 Lu克克kke 据说我们已经找到了准确的答案。
Tracing and Dissecting How LLMs Recall Factual Knowledge for Real World Questions
Yiqun Wang, Chaoqun Wan, Sile Hu, Yonggang Zhang, Xiang Tian, Yaowu Chen, Xu Shen, Jieping Ye

## 解开事实信息流动的Mamba突变体
Mamba Knockout for Unraveling Factual Information Flow
Nir Endy, Idan Daniel Grosbard, Yuval Ran-Milo, Yonatan Slutzky, Itay Tshuva, Raja Giryes

## 从个性化和主动性视角评估个性化工具增强的大型语言模型。
Evaluating Personalized Tool-Augmented LLMs from the Perspectives of Personalization and Proactivity
Yupu Hao, Pengfei Cao, Zhuoran Jin, Huanxuan Liao, Yubo Chen, Kang Liu, Jun Zhao

## 小变化，大影响：操纵少数神经元如何大幅改变大型语言模型的攻击性。
Small Changes, Big Impact: How Manipulating a Few Neurons Can Drastically Alter LLM Aggression
Jaewook Lee, Junseo Jang, Oh-Woog KWON, Harksoo Kim

## MobiLoRA：通过上下文感知的键值缓存优化加速移动设备上的LoRA基于LLM推断。
MobiLoRA: Accelerating LoRA-based LLM Inference on Mobile Devices via Context-aware KV Cache Optimization
Borui Li, Yitao Wang, Haoran Ma, Ligeng Chen, Jun Xiao, Shuai Wang

## 基于好奇心驱动的强化学习及人类反馈。
Curiosity-Driven Reinforcement Learning from Human Feedback
Haoran Sun, Yekun Chai, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang

## 扩宽推理模型蒸馏瓶颈的方法探究
Towards Widening The Distillation Bottleneck for Reasoning Models
Huifeng Yin, Yu Zhao, Minghao Wu, Xuanfan Ni, Bo Zeng, huaiyu.wh, Tianqi Shi, Liangying Shao, Chenyang Lyu, Longyue Wang, Weihua Luo, Kaifu Zhang

## MPO：通过奖励差距优化实现多语言安全性对齐。
MPO: Multilingual Safety Alignment via Reward Gap Optimization
Weixiang Zhao, Yulin Hu, Yang Deng, Tongtong Wu, Wenxuan Zhang, Jiahe Guo, An Zhang, Yanyan Zhao, Bing Qin, Tat-Seng Chua, Ting Liu

## CoE：一种情绪识别框架，用于对话中的情绪线索。
CoE: A Clue of Emotion Framework for Emotion Recognition in Conversations
Zhiyu Shen, Yunhe Pang, Yanghui Rao, Jianxing Yu

## 别半听半解：在持续指令调优中捕获关键信息。
Don’t Half-listen: Capturing Key-part Information in Continual Instruction Tuning
Yongquan He, Wenyuan Zhang, Xuancheng Huang, peng zhang, Lingxun Meng, Xiang Zhou, Ke Zeng, Xunliang Cai

## 关于感知增强嵌入中微调、拓扑性质与任务性能之间的关系研究。
On the Relation Between Fine-Tuning, Topological Properties, and Task Performance in Sense-Enhanced Embeddings
Deniz Ekin Yavas, Timothée Bernard, Benoit Crabbé, Laura Kallmeyer

## QualiSpeech：一个包含自然语言推理和描述的语音质量评估数据集。
QualiSpeech: A Speech Quality Assessment Dataset with Natural Language Reasoning and Descriptions
Siyin Wang, Wenyi Yu, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Lu Lu, Yu Tsao, Junichi Yamagishi, Yuxuan Wang, Chao Zhang

## 探索解释可以提高基于上下文学习的鲁棒性。
Exploring Explanations Improves the Robustness of In-Context Learning
Ukyo Honda, Tatsushi Oka

## 预测枢纽是LLM中的上下文导向频繁令牌。
Prediction Hubs are Context-Informed Frequent Tokens in LLMs
Beatrix Miranda Ginn Nielsen, Iuri Macocco, Marco Baroni

## 通过学生选择预测生成合理的单项选择题干扰项。
Generating Plausible Distractors for Multiple-Choice Questions via Student Choice Prediction
Yooseop Lee, Suin Kim, Yohan Jo

## CRUXEVAL-X：多语言代码推理、理解和执行基准。
CRUXEVAL-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution
Ruiyang Xu, Jialun Cao, Yaojie Lu, Ming Wen, Hongyu Lin, Xianpei Han, Ben He, Shing-Chi Cheung, Le Sun

## 能力显性向量：细粒度损失与能力对齐以适应下游任务扩展规律。
Capability Salience Vector: Fine-grained Alignment of Loss and Capabilities for Downstream Task Scaling Law
Qiming Ge, Shuhao Xing, Songyang Gao, Yunhua Zhou, Yicheng Zou, Songyang Zhang, Zhi Chen, Hang Yan, Qi Zhang, Qipeng Guo, Kai Chen

## 具有战略性和表达性的谈判代理双重思维框架
A Dual-Mind Framework for Strategic and Expressive Negotiation Agent
Yutong Liu, Lida Shi, Rui Song, Hao Xu

## 记录图：通过图增强检索辅助生成，用于长上下文摘要。
Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs
Haozhen Zhang, Tao Feng, Jiaxuan You

## 鲁布里克的立方体：在CUBE数据集中测试一种新的评价解释标准。
Rubrik’s Cube: Testing a New Rubric for Evaluating Explanations on the CUBE dataset
Diana Galvan-Sosa, Gabrielle Gaudeau, Pride Kavumba, Yunmeng Li, Hongyi gu, Zheng Yuan, Keisuke Sakaguchi, Paula Buttery

## 从英语到第二语言精通：通过跨语言持续指令调优提升LLMs。
From English to Second Language Mastery: Enhancing LLMs with Cross-Lingual Continued Instruction Tuning
Linjuan Wu, Hao-Ran Wei, Baosong Yang, Weiming Lu

## argument mining中有限的泛化能力：当前最佳模型学习的是数据集，而非论证。
Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments
Marc Feger, Katarina Boland, Stefan Dietze

## 回顾语言模型的标度定律：数据质量和训练策略的作用。
Revisiting Scaling Laws for Language Models: The Role of Data Quality and Training Strategies
Zhengyu Chen, Siqi Wang, Teng Xiao, Yudong Wang, Shiqi Chen, Xunliang Cai, Junxian He, Jingang Wang

## 利用自我监督的偏好数据增强机器翻译。
Enhancing Machine Translation with Self-Supervised Preference Data
Haoxiang Sun, Ruize Gao, Pei Zhang, Baosong Yang, Rui Wang

## 不要在细节中迷失：通过克服树搜索探索难题来简化大语言模型推理。
Don’t Get Lost in the Trees: Streamlining LLM Reasoning by Overcoming Tree Search Exploration Pitfalls
Ante Wang, Linfeng Song, Ye Tian, Dian Yu, Haitao Mi, Xiangyu Duan, Zhaopeng Tu, Jinsong Su, Dong Yu

## MEXMA： token级别目标提升句子表示效果。
MEXMA: Token-level objectives improve sentence representations
João Maria Janeiro, Benjamin Piwowarski, Patrick Gallinari, Loic Barrault

## Unveil：统一的视觉-文本整合与精简在多模态文档检索中的应用
Unveil: Unified Visual-Textual Integration and Distillation for Multi-modal Document Retrieval
Hao Sun, Yingyan Hou, Jiayan Guo, Bo Wang, Chunyu Yang, Jinsong Ni, Yan Zhang

## Awareness of 不确定性 的迭代偏好优化以增强大语言模型推理。
Uncertainty-Aware Iterative Preference Optimization for Enhanced LLM Reasoning
Lei Li, Hehuan Liu, Yaxin Zhou, ZhaoYang Gui, Xudong Weng, Yi YUAN, Zheng Wei, Zang Li

## AgentDropout：动态代理删除以实现高效且高性能的基于LLM的多代理协作。
AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration
Zhexuan Wang, Yutong Wang, Xuebo Liu, Liang Ding, Miao Zhang, Jie Liu, Min Zhang

## 迈向动态心智理论：评估大语言模型对人类状态时间演变的适应性。
Towards Dynamic Theory of Mind: Evaluating LLM Adaptation to Temporal Evolution of Human States
Yang Xiao, Jiashuo WANG, Qiancheng Xu, Changhe Song, Chunpu Xu, Yi Cheng, Wenjie Li, Pengfei Liu

## T2A-反馈：通过精细粒度的AI反馈提高文本到语音生成的基本能力。
T2A-Feedback: Improving Basic Capabilities of Text-to-Audio Generation via Fine-grained AI Feedback
Zehan Wang, Ke Lei, Chen Zhu, Jiawei Huang, Sashuai zhou, Luping Liu, Xize Cheng, Shengpeng Ji, Zhenhui Ye, Tao Jin, Zhou Zhao

## M-IFEval：大型语言模型多语言指令遵循能力评估。
M-IFEval: On Multilingual Instruction-Following Capability of Large Language Models
Bo Zeng, Chenyang Lyu, Sinuo Liu, Mingyan Zeng, Minghao Wu, Xuanfan Ni, Tianqi Shi, Yu Zhao, Yefeng Liu, Chenyu Zhu, Ruizhe Li, Jiahui Geng, Qing Li, Yu Tong, Longyue Wang, Weihua Luo, Kaifu Zhang

## 通过内部表征的视角分析大型语言模型对跨语言知识边界认知的理解。
Analyzing LLMs’ Cognition of Knowledge Boundary Across Languages Through the Lens of Internal Representation
Chenghao Xiao, Hou Pong Chan, Hao Zhang, Mahani Aljunied, Lidong Bing, Noura Al Moubayed, Yu Rong

## 视觉模态在多模态数学推理中的作用：挑战与见解。
The Role of Visual Modality in Multimodal Mathematical Reasoning: Challenges and Insights
Yufang Liu, Yao Du, Tao Ji, Jianing Wang, Yang Liu, Yuanbin Wu, Aimin Zhou, Mengdi Zhang, Xunliang Cai

## 用于大型语言模型安全性的表示弯曲。
Representation Bending for Large Language Model Safety
Ashkan Yousefpour, Taeheon Kim, Ryan Sungmo Kwon, Seungbeen Lee, Wonje Jeung, Seungju Han, Alvin Wan, Harrison Ngan, Youngjae Yu, Jonghyun Choi

## HalluLens：LLM幻觉基准。
HalluLens: LLM Hallucination Benchmark
Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

## 阿斯克莱庇俄斯：医疗多模态大型语言模型的谱系评估基准。
Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large Language Models
Jie Liu, Wenxuan Wang, SU Yihang, Jingyuan Huang, Yudi Zhang, Cheng-Yi Li, Wenting Chen, Xiaohan Xing, Kao-Jung Chang, Linlin Shen, Michael R. Lyu

## InstructPart：基于指令推理的任务导向部件分割。
InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning
Zifu Wan, Yaqi Xie, Ce Zhang, Zhiqiu Lin, Zihan Wang, Simon Stepputtis, Deva Ramanan, Katia P. Sycara

## 更深入地了解您的用户：面向persona定向细化的动态persona建模。
DEEPER Insight into Your User: Directed Persona Refinement for Dynamic Persona Modeling
Aili Chen, Chengyu Du, Jiangjie Chen, Jinghan Xu, Yikai Zhang, Siyu Yuan, Zulong Chen, Liangyue Li, Yanghua Xiao

## 通过证据树搜索增强检索增强生成。
Enhancing Retrieval-Augmented Generation via Evidence Tree Search
Hao Sun, Hengyi Cai, Yuchen Li, Xuanbo Fan, Xiaochi Wei, Shuaiqiang Wang, Yan Zhang, Dawei Yin

## Ref-Long：评估长上下文语言模型的长引用能力。
Ref-Long: Benchmarking the Long-context Referencing Capability of Long-context Language Models
Junjie Wu, Gefei Gu, Yanan Zheng, Dit-Yan Yeung, Arman Cohan

## 论文标题：评估常识生成中的多元化评价。
Evaluating the Evaluation of Diversity in Commonsense Generation
Tianhui Zhang, Bei Peng, Danushka Bollegala

## ChemActor：通过LLM生成的数据增强化学合成动作的自动化提取。
ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data
Yu Zhang, Ruijie Yu, Jidong Tian, Feng Zhu, Jiapeng Liu, Xiaokang Yang, Yaohui Jin, Yanyan Xu

## GRaMPa：通过使用高效路径计数马尔可夫模型偏斜均匀分割分布进行子词正则化。
GRaMPa: Subword Regularisation by Skewing Uniform Segmentation Distributions with an Efficient Path-counting Markov Model
Thomas Bauwens, David Kaczér, Miryam de Lhoneux

## 充分利用大型语言模型内部状态以增强知识边界感知。
Towards Fully Exploiting LLM Internal States to Enhance Knowledge Boundary Perception
Shiyu Ni, Keping Bi, Jiafeng Guo, Lulu Yu, Baolong Bi, Xueqi Cheng

## 稀疏到密集：LLM中视频理解的无成本加速免费午餐。
Sparse-to-Dense: A Free Lunch for Lossless Acceleration of Video Understanding in LLMs
Xuan Zhang, Cunxiao Du, Sicheng Yu, Jiawei Wu, Fengzhuo Zhang, Wei Gao, Qian Liu

## STaR-SQL：自我教学推理器，用于文本到SQL转换。
STaR-SQL: Self-Taught Reasoner for Text-to-SQL
Mingqian He, Yongliang Shen, Wenqi Zhang, Qiuying Peng, Jun Wang, Weiming Lu

## FastMCTS：一种简单的数据合成采样策略。
FastMCTS: A Simple Sampling Strategy for Data Synthesis
Peiji Li, Kai Lv, Yunfan Shao, Yichuan Ma, Linyang Li, Xiaoqing Zheng, Xipeng Qiu, Qipeng Guo

## ALGEN：基于对齐与生成的少样本文本嵌入反转攻击。
ALGEN: Few-shot Inversion Attacks on Textual Embeddings using Alignment and Generation
Yiyi Chen, Qiongkai Xu, Johannes Bjerva

## 通过多代理模拟为大语言模型合成后训练数据。
Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation
Shuo Tang, Xianghe Pang, Zexi Liu, Bohan Tang, Rui Ye, Tian Jin, Xiaowen Dong, Yanfeng Wang, Siheng Chen

## 论文标题翻译如下：\n公平性超越性能：探究法律NLP领域各组之间可靠性的差异。
Fairness Beyond Performance: Investigating Reliability Disparities Across Groups in Legal NLP
Santosh T.Y.S.S, Irtiza Chowdhury

## Dialogue-RAG：通过节点链接对话句重写增强大语言模型的检索能力。
Dialogue-RAG: Enhancing Retrieval for LLMs via Node-Linking Utterance Rewriting
Qiwei Li, Teng Xiao, Zuchao Li, Ping Wang, Mengjia Shen, hai zhao

## 使用信息论来表征语调类型学：以声调、音高重音和音节重音为例。
Using Information Theory to Characterize Prosodic Typology: The Case of Tone, Pitch-Accent and Stress-Accent
Ethan Wilcox, Cui Ding, Giovanni Acampa, Tiago Pimentel, Alex Warstadt, Tamar I Regev

## LaTIM：测量Mamba模型中潜在的令牌间交互作用。
LaTIM: Measuring Latent Token-to-Token Interactions in Mamba Models
Hugo Pitorro, Marcos Vinicius Treviso

## 序列级知识蒸馏中记忆遗传机制的研究
Memorization Inheritance in Sequence-Level Knowledge Distillation for Neural Machine Translation
Verna Dankers, Vikas Raunak

## 利用 linguistic Insights 评估 Portuguese 句子简化 LLMs。
Evaluating LLMs for Portuguese Sentence Simplification with Linguistic Insights
ARTHUR MARIANO ROCHA DE AZEVEDO SCALERCIO, Elvis A. de Souza, Maria José Bocorny Finatto, Aline Paes

## 不必重造轮子：基于引导空间变换的有效指令遵循文本嵌入。
Don’t Reinvent the Wheel: Efficient Instruction-Following Text Embedding based on Guided Space Transformation
Yingchaojie Feng, Yiqun Sun, Yandong Sun, Minfeng Zhu, Qiang Huang, Anthony Kum Hoe Tung, Wei Chen

## OMGM： Orchestrating 多粒度和模态以实现高效多模态检索
OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval
Wei Yang, Jingjing Fu, Rui Wang, Jinyu Wang, Lei Song, Jiang Bian

## 通过自我监督目标改进低资源形态学屈折化。
Improving Low-Resource Morphological Inflection via Self-Supervised Objectives
Adam Wiemerslage, Katharina von der Wense

## 通过选择性 性拒绝学习减轻大型语言模型中知识错位引起的幻觉。
Alleviating Hallucinations from Knowledge Misalignment in Large Language Models via Selective Abstention Learning
Lei Huang, Xiaocheng Feng, Weitao Ma, Yuchun Fan, Xiachong Feng, Yuxuan Gu, Yangfan Ye, Liang Zhao, Weihong Zhong, Baoxin Wang, Dayong Wu, Guoping Hu, Lingpeng Kong, Tong Xiao, Ting Liu, Bing Qin

## 基于交互的回顾学习。
Retrospective Learning from Interactions
Zizhao Chen, Mustafa Omer Gul, Yiwei Chen, Gloria Geng, Anne Wu, Yoav Artzi

## 在大规模模型时代的人工个性化生成：一项综述。
Personalized Generation In Large Model Era: A Survey
Yiyan Xu, Jinghao Zhang, Alireza Salemi, Xinting Hu, Wenjie Wang, Fuli Feng, Hamed Zamani, Xiangnan He, Tat-Seng Chua

## 重新审视语言模型中的不确定性量化评估：虚假交互与响应长度偏差结果。
Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results
Andrea Santilli, Adam Golinski, Michael Kirchhof, Federico Danieli, Arno Blaas, Miao Xiong, Luca Zappella, Sinead Williamson

## SOTOPIA-Ω：社会代理的动态策略注入学习与社会指导评估。
SOTOPIA-Ω: Dynamic Strategy Injection Learning and Social Instruction Following Evaluation for Social Agents
Wenyuan Zhang, Tianyun Liu, Mengxiao Song, Xiaodong Li, Tingwen Liu

## 图辅导员：通过多智能体协同提高大语言模型推理能力的自适应图探索。
Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning
Junqi Gao, Xiang Zou, Ying Ai, Dong Li, Yichen Niu, Biqing Qi, Jianxing Liu

## 利用上下文学习进行大规模语言模型政治偏见检测。
Leveraging In-Context Learning for Political Bias Testing of LLMs
Patrick Haller, Jannis Vamvas, Rico Sennrich, Lena Ann Jäger

## 语言模型能否取代程序员？REPOCOD 说“尚未能做到”。
Can Language Models Replace Programmers? REPOCOD Says ‘Not Yet’
Shanchao Liang, Nan Jiang, Yiran Hu, Lin Tan

## CoRet：改进的代码编辑检索器
CoRet: Improved Retriever for Code Editing
Fabio James Fehr, Prabhu Teja S, Luca Franceschi, Giovanni Zappella

## WAFFLE： fine-tuning 多模态模型以实现自动化前端开发。
WAFFLE: Fine-tuning Multi-Modal Model for Automated Front-End Development
Shanchao Liang, Nan Jiang, Shangshu Qian, Lin Tan

## ACORD：专家标注的法律合同起草检索数据集。
ACORD: An Expert-Annotated Retrieval Dataset for Legal Contract Drafting
Steven H Wang, Maksim Zubkov, Kexin Fan, Sarah Harrell, Yuyang Sun, Wei Chen, Andreas Plesner, Roger Wattenhofer

## 数学神经外科：仅使用前向传递隔离语言模型的数学推理能力。
Math Neurosurgery: Isolating Language Models’ Math Reasoning Abilities Using Only Forward Passes
Bryan R Christ, Zachary Gottesman, Jonathan Kropko, Thomas Hartvigsen

## 多个大规模语言模型代理进行公平文化对齐辩论。
Multiple LLM Agents Debate for Equitable Cultural Alignment
Dayeon Ki, Rachel Rudinger, Tianyi Zhou, Marine Carpuat

## 大型语言模型知道自己的漏洞：通过自然分布偏移发现安全性缺口。
LLMs know their vulnerabilities: Uncover Safety Gaps through Natural Distribution Shifts
Qibing Ren, Hao Li, Dongrui Liu, Zhanxu Xie, Xiaoya Lu, Yu Qiao, Lei Sha, Junchi Yan, Lizhuang Ma, Jing Shao

## 先生成再抽样：增强虚假新闻检测的LLM辅助强化抽样方法。
Generate First, Then Sample: Enhancing Fake News Detection with LLM-Augmented Reinforced Sampling
Zhao Tong, Yimeng Gu, Huidong Liu, Qiang Liu, Shu Wu, Haichao Shi, Xiao-Yu Zhang

## SEA：通过合成嵌入实现多模态大规模语言模型的低资源安全对齐。
SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings
Weikai Lu, Hao Peng, Huiping Zhuang, Cen Chen, Ziqian Zeng

## 在图像中寻找针头：多模态LLM能定位细etails吗？（注：将“details”翻译为“细节”更符合中文表达习惯）
Finding Needles in Images: Can Multi-modal LLMs Locate Fine Details?
Parth Thakkar, Ankush Agarwal, Prasad Kasu, Pulkit Bansal, Chaitanya Devaguptapu

## RefreshKV：在长文本生成期间更新小型KV缓存。
RefreshKV: Updating Small KV Cache During Long-form Generation
Fangyuan Xu, Tanya Goyal, Eunsol Choi

## 语言模型在相变之后变得不再像人类。
Language Models Grow Less Humanlike beyond Phase Transition
Tatsuya Aoyama, Ethan Wilcox

## iNews：用于建模对新闻个性化情感响应的多模态数据集。
iNews: A Multimodal Dataset for Modeling Personalized Affective Responses to News
Tiancheng Hu, Nigel Collier

## 机器翻译评估是否达到了人类水平？参考人类标准与进步的局限性。
Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress
Lorenzo Proietti, Stefano Perrella, Roberto Navigli

## 协调混沌：语言协调方法学的结构化回顾。
Coordinating Chaos: A Structured Review of Linguistic Coordination Methodologies
Benjamin Roger Litterer, David Jurgens, Dallas Card

## 超越相似性：基于梯度的图方法用于指令调优数据选择。
Beyond Similarity: A Gradient-based Graph Method for Instruction Tuning Data Selection
Yang Zhao, Li Du, Xiao Ding, Yangou Ouyang, Hepeng Wang, Kai Xiong, Jinglong Gao, Zhouhao Sun, Dongliang Xu, Qing Yang, Dongchen Li, Bing Qin, Ting Liu

## 链式推理：通过多范式视角统一大型语言模型中的数学推理。
Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective
Yiyao Yu, Yuxiang Zhang, Dongdong Zhang, Xiao Liang, Hengyuan Zhang, Xingxing Zhang, MAHMOUD KHADEMI, Hany Hassan Awadalla, Junjie Wang, Yujiu Yang, Furu Wei

## PCoT：增强论证链方法用于检测假新闻和社会媒体虚假信息。
PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation
Arkadiusz Modzelewski, Witold Sosnowski, Tiziano Labruna, Adam Wierzbicki, Giovanni Da San Martino

## 注意手势：评估AI对具有文化冒犯性的非言语手势的敏感性。
Mind the Gesture: Evaluating AI Sensitivity to Culturally Offensive Non-Verbal Gestures
Akhila Yerukola, Saadia Gabriel, Nanyun Peng, Maarten Sap

## 估计语言模型中增强背景知识的隐私泄露程度。
Estimating Privacy Leakage of Augmented Contextual Knowledge in Language Models
James Flemings, Bo Jiang, Wanrong Zhang, Zafar Takhirov, Murali Annavaram

## 500xCompressor：大型语言模型的一般化提示压缩方法。
500xCompressor: Generalized Prompt Compression for Large Language Models
Zongqian Li, Yixuan Su, Nigel Collier

## 探究逻辑：探究 Transformer 在数值满足问题中的通用性性\n#advice您可以提供更多的内容吗？这样我可以为您进行更完整的翻译和解释größe\n
Unravelling the Logic: Investigating the Generalisation of Transformers in Numerical Satisfiability Problems
Tharindu Madusanka, Marco Valentino, Iqra Zahid, Ian Pratt-Hartmann, Riza Batista-Navarro

## 扩散导向无序变换器用于非自回归机器翻译。
Diffusion Directed Acyclic Transformer for Non-Autoregressive Machine Translation
Quan Nguyen-Tri, Cong Dao Tran, Hoang Thanh-Tung

## 使用结构化播客研究语料库映射播客生态系统。
Mapping the Podcast Ecosystem with the Structured Podcast Research Corpus
Benjamin Roger Litterer, David Jurgens, Dallas Card

## 自然语言处理的本质：分析NLP论文的贡献。
The Nature of NLP: Analyzing Contributions in NLP Papers
Aniket Pramanick, Yufang Hou, Saif M. Mohammad, Iryna Gurevych

## 揭露大规模语言模型代理记忆中的隐私风险。
Unveiling Privacy Risks in LLM Agent Memory
Bo Wang, Weiyi He, Shenglai Zeng, Zhen Xiang, Yue Xing, Jiliang Tang, Pengfei He

## 面向挑战性角色类型的文档级事件-论元数据扩增。
Document-Level Event-Argument Data Augmentation for Challenging Role Types
Joseph Gatto, Omar Sharif, Parker Seegmiller, Sarah Masud Preum

## 增强患者与医生对话的后续问题生成。
Follow-up Question Generation For Enhanced Patient-Provider Conversations
Joseph Gatto, Parker Seegmiller, Timothy E. Burdick, Inas S. Khayal, Sarah DeLozier, Sarah Masud Preum

## PRMBench：一种面向过程级奖励模型的精细粒度挑战基准。
PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models
Mingyang Song, Zhaochen Su, Xiaoye Qu, Jiawei Zhou, Yu Cheng

## 语言约束的多模态超适配器用于多对多多模态摘要。
Language Constrained Multimodal Hyper Adapter For Many-to-Many Multimodal Summarization
Nayu Liu, Fanglong Yao, Haoran Luo, Yong Yang, Chen Tang, Bo Lv

## 论文标题：语言模型中的图书馆式行为通过自参考因果循环得到了增强。
Library-Like Behavior In Language Models is Enhanced by Self-Referencing Causal Cycles
Munachiso S Nwadike, Zangir Iklassov, Toluwani Aremu, Tatsuya Hiraoka, Benjamin Heinzerling, Velibor Bojkovic, Hilal AlQuabeh, Martin Takáč, Kentaro Inui

## 书规模核心ference解析: BOOKCOREF
BOOKCOREF: Coreference Resolution at Book Scale
Giuliano Martinelli, Tommaso Bonomo, Pere-Lluís Huguet Cabot, Roberto Navigli

## 塑造安全边界：理解并抵御大型语言模型的越狱攻击。
Shaping the Safety Boundaries: Understanding and Defending Against Jailbreaks in Large Language Models
Lang Gao, Jiahui Geng, Xiangliang Zhang, Preslav Nakov, Xiuying Chen

## 监督那些监督者：揭示机器翻译质量评估中的性别差异。
Watching the Watchers: Exposing Gender Disparities in Machine Translation Quality Estimation
Emmanouil Zaranis, Giuseppe Attanasio, Sweta Agrawal, Andre Martins

## 高效集成体系：多数据集微调语言模型
Efficient Ensemble for Fine-tuning Language Models on Multiple Datasets
Dongyue Li, Ziniu Zhang, Lu Wang, Hongyang R. Zhang

## 嵌入-转换器：一种统一的跨模型嵌入转换框架。
Embedding-Converter: A Unified Framework for Cross-Model Embedding Transformation
Jinsung Yoon, Sercan O Arik

## 论文标题：通过最小预计算实现高效的知识编辑。
Efficient Knowledge Editing via Minimal Precomputation
Akshat Gupta, Maochuan Lu, Thomas Hartvigsen, Gopala Anumanchipalli

## ASPERA：一个用于评估复杂行动执行计划的模拟环境。
ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution
Alexandru Coca, Mark Gaynor, Zhenxing Zhang, Jianpeng Cheng, Bo-Hsiang Tseng, Peter Boothroyd, Hector Martinez Alonso, Diarmuid O Seaghdha, Anders Johannsen

## SARA：面向提取性总结的大语言模型突出显示感知增强自适应解码。
SARA: Salience-Aware Reinforced Adaptive Decoding for Large Language Models in Abstractive Summarization
Nayu Liu, Junnan Zhu, Yiming Ma, Zhicong Lu, Wenlei Xu, Yong Yang, Jiang Zhong, kaiwen wei

## 捂住眼睛的回应：基本视觉语言模型能力中的意外观察。
Response Wide Shut:Surprising Observations in Basic Vision Language Model Capabilities
Shivam Chandhok, Wan-Cyuan Fan, Vered Shwartz, Vineeth N. Balasubramanian, Leonid Sigal

## ReflectDiffu：通过RL-扩散框架实现情绪-意图传染与模仿之间的反映，以生成同理心响应。
ReflectDiffu: Reflect between Emotion-intent Contagion and Mimicry for Empathetic Response Generation via a RL-Diffusion Framework
Jiahao Yuan, Zixiang Di, Zhiqing Cui, Guisong Yang, Usman Naseem

## 多token预测的语言模型预训练课程。
Pre-Training Curriculum for Multi-Token Prediction in Language Models
Ansar Aynetdinov, Alan Akbik

## 我们能否进一步激发LLMs的推理能力？基于批评引导的检索增强计划方法解决具有挑战性的任务。
Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks
Xingxuan Li, Weiwen Xu, Ruochen Zhao, Fangkai Jiao, Shafiq Joty, Lidong Bing

## 关于长上下文评价中多轮上下文学习的研究
On Many-Shot In-Context Learning for Long-Context Evaluation
Kaijian Zou, Muhammad Khalifa, Lu Wang

##  founding era 美国英语中的意义变异与语料库质量。
Meaning Variation and Data Quality in the Corpus of Founding Era American English
Dallas Card

## EffiVLM-Bench：一个全面的基准测试，用于评估大型视觉语言模型中的无训练加速效果。
EffiVLM-Bench: A Comprehensive Benchmark for Evaluating Training-Free Acceleration in Large Visual-Languge Models
Zekun Wang, MingHua Ma, Zexin Wang, Rongchuan Mu, hongtao liu, liping shan, Ming Liu, Bing Qin

## 专用于反馈和编辑的模型赋能开放-ended通用领域任务的推理时扩充。
Dedicated Feedback and Edit Models Empower Inference-Time Scaling for Open-Ended General-Domain Tasks
Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Daniel Egert, Ellie Evans, Hoo-Chang Shin, Felipe Soares, Yi Dong, Oleksii Kuchaiev

## 并非一切闪光的都是新事物：AI生成研究中的抄袭问题。
All That Glitters is Not Novel: Plagiarism in AI Generated Research
Tarun Gupta, Danish Pruthi

## CulturalBench：一种通过人机红队演练衡量模型文化知识的稳健、多样且具挑战性的基准。
CulturalBench: A Robust, Diverse and Challenging Benchmark for Measuring LMs’ Cultural Knowledge Through Human-AI Red-Teaming
Yu Ying Chiu, Liwei Jiang, Bill Yuchen Lin, Chan Young Park, Shuyue Stella Li, Sahithya Ravi, Mehar Bhatia, Maria Antoniak, Yulia Tsvetkov, Vered Shwartz, Yejin Choi

## 平衡预算：理解监督微调与基于偏好微调之间的权衡。
Balancing the Budget: Understanding Trade-offs Between Supervised and Preference-Based Finetuning
Mohit Raghavendra, Junmo Kang, Alan Ritter

## 通过受约束的知识遗忘实现安全性对齐。
Safety Alignment via Constrained Knowledge Unlearning
Zesheng Shi, Yucheng Zhou, Jing Li, Yuxin Jin, YU LI, Daojing He, Fangming Liu, Saleh Alharbi, Jun Yu, Min Zhang

## 向顶尖作家学习写作：基于范例的说明文生成。
Writing Like the Best: Exemplar-Based Expository Text Generation
Yuxiang Liu, Kevin Chen-Chuan Chang

## 寻找声音：探索非洲裔美国人方言和声音生成在聊天机器人中的潜在应用。
Finding A Voice: Exploring the Potential of African American Dialect and Voice Generation for Chatbots
Sarah E. Finch, Ellie S. Paek, Ikseon Choi, Jinho D. Choi

## 图上的解码：通过生成规范链在知识图上进行忠实且可靠的推理。
Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains
Kun LI, Tianhua Zhang, Xixin Wu, Hongyin Luo, James R. Glass, Helen M. Meng

## 语言融合以实现参数高效的跨语言迁移学习。
Language Fusion for Parameter-Efficient Cross-lingual Transfer
Philipp Borchert, Ivan Vulić, Marie-Francine Moens, Jochen De Weerdt

## AAD-LLM：神经注意力驱动的声景理解。
AAD-LLM: Neural Attention-Driven Auditory Scene Understanding
Xilin Jiang, Sukru Samet Dindar, Vishal Choudhari, Stephan Bickel, Ashesh Mehta, Guy M McKhann, Daniel Friedman, Adeen Flinker, Nima Mesgarani

## 帮我写故事：评估大型语言模型生成写作反馈的能力。
Help Me Write a Story: Evaluating LLMs’ Ability to Generate Writing Feedback
Hannah Rashkin, Elizabeth Clark, Fantine Huot, Mirella Lapata

## 文化不仅仅是琐事：社会文化理论在文化自然语言处理中的应用
Culture is Not Trivia: Sociocultural Theory for Cultural NLP
Naitian Zhou, David Bamman, Isaac L. Bleaman

## Delta-KNN：在阿尔茨海默病检测的上下文学习中改进示范选择的方法。
Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer’s Disease Detection
Chuyuan Li, Raymond Li, Thalia S. Field, Giuseppe Carenini

## 去人性化机器：减轻文本生成系统中的拟人化行为。
Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems
Myra Cheng, Su Lin Blodgett, Alicia DeVrio, Lisa Egede, Alexandra Olteanu

## MindRef：以细粒度地理位置意识模仿人类记忆的层次化引用检索方法。
MindRef: Mimicking Human Memory for Hierarchical Reference Retrieval with Fine-Grained Location Awareness
Ye Wang, Xinrun Xu, Zhiming Ding

## 语言模型有语义吗？关于五个标准观点。
Do Language Models Have Semantics? On the Five Standard Positions
Anders Søgaard

## 标题: $\\mathtt{GeLLM^3O}$：通用大型语言模型多性质分子优化。
$\\mathtt{GeLLM^3O}$: Generalizing Large Language Models for Multi-property Molecule Optimization
Vishal Dey, Xiao Hu, Xia Ning

## 评估多模态语言模型作为视觉辅助助理，用于视觉受损用户。
Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users
Antonia Karamolegkou, Malvina Nikandrou, Georgios Pantazopoulos, Danae Sanchez Villegas, Phillip Rust, Ruchira Dhar, Daniel Hershcovich, Anders Søgaard

## HumT DumT：测量和控制LLM中的类人类语言。
HumT DumT: Measuring and controlling human-like language in LLMs
Myra Cheng, Sunny Yu, Dan Jurafsky

## LLM在对话中其语言使用会句法上适应其对话伙伴。
LLMs syntactically adapt their language use to their conversational partner
Florian Kandra, Vera Demberg, Alexander Koller

## ChatBench：从静态基准到人机评价。
ChatBench: From Static Benchmarks to Human-AI Evaluation
Serina Chang, Ashton Anderson, Jake M. Hofman

## 通过自适应推理结合视觉上下文和外部常识知识回答复杂地理问题。
Answering Complex Geographic Questions by Adaptive Reasoning with Visual Context and External Commonsense Knowledge
Fan Li, Jianxing Yu, Jielong Tang, Wenqing Chen, Hanjiang Lai, Yanghui Rao, Jian Yin

## LLM代理创建代理工具
LLM Agents Making Agent Tools
Georg Wölflein, Dyke Ferber, Daniel Truhn, Ognjen Arandjelovic, Jakob Nikolas Kather

## 排名解析：面向AI对战的大型语言模型排名 recipe
Ranking Unraveled: Recipes for LLM Rankings in Head-to-Head AI Combat
Roland Daynauth, Christopher Clarke, Krisztian Flautner, Lingjia Tang, Jason Mars

## 训练老的语言模型进行安全编码：基于提炼偏好下的局部偏好优化。
Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences
Mohammad Saqib Hasan, Saikat Chakraborty, Santu Karmaker, Niranjan Balasubramanian

## CrafText基准测试：在复杂多模态开放环境中推进语言定位。
CrafText Benchmark: Advancing Language Grounding in Complex Multimodal Open-Ended World
Zoya Volovikova, Gregory Gorbov, Petr Kuderov, Aleksandr Panov, Alexey Skrynnik

## 探索边缘地带：跨研究文化分析科学写作。
Research Borderlands: Analysing Scientific Writing Across Research Cultures
Shaily Bhatt, Tal August, Maria Antoniak

## 一切皆有可能？跨语言研究中（不）可能的语言学习在LM中的表现。
Anything Goes? A Crosslinguistic Study of (Im)possible Language Learning in LMs
Xiulin Yang, Tatsuya Aoyama, Yuekun Yao, Ethan Wilcox

## QG-SMS：通过学生建模与模拟增强测试项目分析
QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation
Bang Nguyen, Tingting Du, Mengxia Yu, Lawrence Angrave, Meng Jiang

## LogicPro：通过程序导向学习提升复杂逻辑推理能力。
LogicPro: Improving Complex Logical Reasoning via Program-Guided Learning
Jin Jiang, Yuchen Yan, Yang Liu, Jianing Wang, Shuai Peng, Xunliang Cai, Yixin Cao, Mengdi Zhang, Liangcai Gao

## 通过使用大语言模型作为评判者，改进生物医学关系提取中大语言模型的自动评估
Improving Automatic Evaluation of Large Language Models (LLMs) in Biomedical Relation Extraction via LLMs-as-the-Judge
Md Tahmid Rahman Laskar, Israt Jahan, Elham Dolatabadi, Chun Peng, Enamul Hoque, Jimmy Huang

## 基于因果图的事件推理方法：利用语义关系专家。
Causal Graph based Event Reasoning using Semantic Relation Experts
Mahnaz Koupaee, Xueying Bai, Mudan Chen, Greg Durrett, Nathanael Chambers, Niranjan Balasubramanian

## LLM们理解对话吗？一种对话行为的案例研究。
Do LLMs Understand Dialogues? A Case Study on Dialogue Acts
Ayesha Qamar, Jonathan Tong, Ruihong Huang

## DeAL：大型语言模型解码时对齐框架。
DeAL: Decoding-time Alignment Framework for Large Language Models
James Y. Huang, Sailik Sengupta, Daniele Bonadiman, Yi-An Lai, Arshit Gupta, Nikolaos Pappas, Saab Mansour, Katrin Kirchhoff, Dan Roth

## CEAES：双向强化学习优化以实现一致性和可解释性作文评估。
CEAES: Bidirectional Reinforcement Learning Optimization for Consistent and Explainable Essay Assessment
Xia Li, Wenjing Pan

## 文化偏见很重要：一个多文化基准数据集及情感增强模型，用于理解多模态隐喻。
Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors
Senqi Yang, Dongyu Zhang, Jing Ren, Ziqi Xu, Xiuzhen Zhang, Yiliao Song, Hongfei Lin, Feng Xia

## 全方位字符：朝着无缝言语个性互动的沉浸式角色扮演代理发展。
OmniCharacter: Towards Immersive Role-Playing Agents with Seamless Speech-Language Personality Interaction
Haonan Zhang, Run Luo, Xiong Liu, Yuchuan Wu, Ting-En Lin, Pengpeng Zeng, QIANG QU, Feiteng Fang, Min Yang, Lianli Gao, Jingkuan Song, Fei Huang, Yongbin Li

## MTSA：通过多轮红队攻击实现LLMs多轮安全对齐的 METHOD
MTSA: Multi-turn Safety Alignment for LLMs through Multi-round Red-teaming
Weiyang Guo, Jing Li, Wenya Wang, YU LI, Daojing He, Jun Yu, Min Zhang

## RADAR：通过补充知识注入增强放射学报告生成。
RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection
Wenjun Hou, Yi Cheng, Kaishuai Xu, Heng Li, Yan Hu, Wenjie Li, Jiang Liu

## LLM能欺骗CLIP吗？通过文本更新对预训练多模态表示进行对抗合成性基准测试。
Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates
Jaewoo Ahn, Heeseung Yun, Dayoon Ko, Gunhee Kim

## 混合上下文学习者
Mixtures of In-Context Learners
Giwon Hong, Emile van Krieken, Edoardo Ponti, Nikolay Malkin, Pasquale Minervini

## 探究LoRA干扰：稳健模型合并的正交子空间。
Unraveling LoRA Interference: Orthogonal Subspaces for Robust Model Merging
Haobo Zhang, Jiayu Zhou

## 注意力能够体现大量信息：定位并缓解语言模型中的偏见。
Attention Speaks Volumes: Localizing and Mitigating Bias in Language Models
Rishabh Adiga, Besmira Nushi, Varun Chandrasekaran

## 临床文本中的时间关系提取：基于区间的图形变换器方法。
Temporal Relation Extraction in Clinical Texts: A Span-based Graph Transformer Approach
Rochana Chaturvedi, Peyman Baghershahi, Sourav Medya, Barbara Di Eugenio

## BIG-Bench 额外困难的测试题集
BIG-Bench Extra Hard
Mehran Kazemi, Bahare Fatemi, Hritik Bansal, John Palowitch, Chrysovalantis Anastasiou, Sanket Vaibhav Mehta, Lalit K Jain, Virginia Aglietti, Disha Jindal, Peter Chen, Nishanth Dikkala, Gladys Tyen, Xin Liu, Uri Shalit, Silvia Chiappa, Kate Olszewska, Yi Tay, Vinh Q. Tran, Quoc V Le, Orhan Firat

## 标题翻译：效率与准确性的权衡：使用多头早期退出优化增强的RAG推荐系统。
The Efficiency vs. Accuracy Trade-off: Optimizing RAG-Enhanced LLM Recommender Systems Using Multi-Head Early Exit
Huixue Zhou, Hengrui Gu, Zaifu Zhan, Xi Liu, Kaixiong Zhou, Yongkang Xiao, Mingfu Liang, Srinivas Prasad Govindan, Piyush Chawla, Jiyan Yang, Xiangfei Meng, Huayu Li, Buyun Zhang, Liang Luo, Wen-Yen Chen, Yiping Han, Bo Long, Rui Zhang, Tianlong Chen

## RATIONALYST：增强推理能力的预训练过程监督
RATIONALYST: Pre-training Process-Supervision for Improving Reasoning
Dongwei Jiang, Guoxuan Wang, Yining Lu, Andrew Wang, Jingyu Zhang, Chuyu Liu, Benjamin Van Durme, Daniel Khashabi

## CSTree-SRI：基于反省的认知语义树在超长上下文多轮问答中的应用。
CSTree-SRI: Introspection-Driven Cognitive Semantic Tree for Multi-Turn Question Answering over Extra-Long Contexts
Zhaowen Wang, Xiang Wei, Kangshao Du, Yiting Zhang, Libo Qin, Yingjie Xia, Li Kuang

## TigerLLM - 一系列孟加拉语大型语言模型。
TigerLLM - A Family of Bangla Large Language Models
Nishat Raihan, Marcos Zampieri

## 通过LLM中的多文档事件推理减少媒体偏见。
Mitigating Media Bias through Multi-document Events Reasoning in LLMs
Yuanyuan Lei, Ruihong Huang

## InductionBench：大语言模型在最简单的复杂性类中失败。
InductionBench: LLMs Fail in the Simplest Complexity Class
Wenyue Hua, Tyler Wong, Fei Sun, Liangming Pan, Adam Jardine, William Yang Wang

## 探讨指令调优对大语言模型误信风险的影响 manh
Exploring the Impact of Instruction-Tuning on LLM’s Susceptibility to Misinformation
Kyubeen Han, Junseo Jang, Hongjin Kim, Geunyeong Jeong, Harksoo Kim

## 谁撰写了什么：揭示作者角色对AI生成文本检测的影响。
Who Writes What: Unveiling the Impact of Author Roles on AI-generated Text Detection
Jiatao Li, Xiaojun Wan

## RoCoFT：高效的大型语言模型行列更新微调方法。
RoCoFT: Efficient Finetuning of Large Language Models with Row-Column Updates
Md Kowsher, Tara Esmaeilbeig, Chun-Nam Yu, Chen Chen, Mojtaba Soltanalian, Niloofar Yousefi

##  ternary 语言模型的标度定律与高效推理。
Scaling Laws and Efficient Inference for Ternary Language Models
Tejas Vaidhya, Ayush Kaushal, Vineet Jain, Francis Couture-Harpin, Prashant Shishodia, Majid Behbahani, Irina Rish, Yuriy Nevmyvaka

## 让想象更清晰！基于稳定扩散的多模态机器翻译视觉想象。
Make Imagination Clearer! Stable Diffusion-based Visual Imagination for Multimodal Machine Translation
Andong Chen, Yuchen Song, Kehai Chen, Xuefeng Bai, Muyun Yang, Liqiang Nie, Jie Liu, Tiejun Zhao, Min zhang

## 生成式奖励建模通过合成标准偏好学习。
Generative Reward Modeling via Synthetic Criteria Preference Learning
xiaobo liang, Haoke Zhang, Juntao Li, Kehai Chen, Qiaoming Zhu, Min Zhang

## 推进基于SMoE的连续领域适应MLLMs：自适应路由器与领域专用损失函数。
Advancing SMoE for Continuous Domain Adaptation of MLLMs: Adaptive Router and Domain-Specific Loss
Liang Zhang, Ziyao Lu, Fandong Meng, Hui Li, Jie Zhou, Jinsong Su

## Java语中的敬语系统，语言模型理解了吗？
Do Language Models Understand Honorific Systems in Javanese?
Mohammad Rifqi Farhansyah, Iwan Darmawan, Adryan Kusumawardhana, Genta Indra Winata, Alham Fikri Aji, Derry Tanti Wijaya

## LPOI：用于视觉语言模型的列表优选优化。
LPOI: Listwise Preference Optimization for Vision Language Models
Fatemeh Pesaran zadeh, Yoojin Oh, Gunhee Kim

## 通过生成进行预测：为什么生成方法更胜一筹。
Predicting Through Generation: Why Generation Is Better for Prediction
Md Kowsher, Nusrat Jahan Prottasha, Prakash Bhat, Chun-Nam Yu, Mojtaba Soltanalian, Ivan Garibay, Ozlem Garibay, Chen Chen, Niloofar Yousefi

## 一种稳健的少量样本关系提取自去噪模型
A Self-Denoising Model for Robust Few-Shot Relation Extraction
Liang Zhang, yang zhang, Ziyao Lu, Fandong Meng, Jie Zhou, Jinsong Su

## 使用多任务学习探索层级表格数据的多模态关系抽取。
Exploring Multimodal Relation Extraction of Hierarchical Tabular Data with Multi-task Learning
Xinyu Zhang, Aibo Song, Jingyi Qiu, Jiahui Jin, Tianbo zhang, Xiaolin Fang

## “要BF16还是要命”？大语言模型量化中的准确性和性能权衡。
“Give Me BF16 or Give Me Death”? Accuracy-Performance Trade-Offs in LLM Quantization
Eldar Kurtic, Alexandre Noll Marques, Shubhra Pandit, Mark Kurtz, Dan Alistarh

## 语言驱动的数据增强值得吗？
Is linguistically-motivated data augmentation worth it?
Ray Groshan, Michael Ginn, Alexis Palmer

## 从引用到关键性：预测多语言瑞士司法判例的影响。
From Citations to Criticality: Predicting Legal Decision Influence in the Multilingual Swiss Jurisprudence
Ronja Stern, Ken Kawamura, Matthias Stürmer, Ilias Chalkidis, Joel Niklaus

## StitchLLM：一次一块地提供LLM服务。
StitchLLM: Serving LLMs, One Block at a Time
Bodun Hu, Shuozhe Li, Saurabh Agarwal, Myungjin Lee, Akshay Jajoo, Jiamin Li, Le Xu, Geon-Woo Kim, Donghyun Kim, Hong Xu, Amy Zhang, Aditya Akella

## 一步之内换位思考：基于顶部视角变换的人本视觉定位。
Walk in Others’ Shoes with a Single Glance: Human-Centric Visual Grounding with Top-View Perspective Transformation
Yuqi Bu, Xin Wu, Zirui Zhao, Yi Cai, David Hsu, Qiong Liu

## 从列表到表情符号：格式偏见如何影响模型对齐。
From Lists to Emojis: How Format Bias Affects Model Alignment
Xuanchang Zhang, Wei Xiong, Lichang Chen, Tianyi Zhou, Heng Huang, Tong Zhang

## 具有细粒度可解释控制的新加坡英语口语风格转换。
Colloquial Singaporean English Style Transfer with Fine-Grained Explainable Control
Jinggui Liang, Dung Vo, Yap Hong Xian, Hai Leong Chieu, Kian Ming A. Chai, Jing Jiang, Lizi Liao

## CoAM：所有类型多词表达式语料库。
CoAM: Corpus of All-Type Multiword Expressions
Yusuke Ide, Joshua Tanner, Adam Nohejl, Jacob Hoffman, Justin Vasselli, Hidetaka Kamigaito, Taro Watanabe

## 平衡LLM采样中的多样性和风险：如何选择你的方法和参数进行开放式文本生成。
Balancing Diversity and Risk in LLM Sampling: How to Select Your Method and Parameter for Open-Ended Text Generation
Yuxuan Zhou, Margret Keuper, Mario Fritz

## 从非正式到正式—— Incorporating 和 Evaluating LLMs 对自然语言需求的验证式正式证明的影响。
From Informal to Formal – Incorporating and Evaluating LLMs on Natural Language Requirements to Verifiable Formal Proofs
Jialun Cao, Yaojie Lu, Meiziniu Li, Haoyang Ma, Haokun Li, Mengda He, Cheng Wen, Le Sun, Hongyu Zhang, Shengchao Qin, Shing-Chi Cheung, Cong Tian

## 揭示阿基里斯之踵：评估大型语言模型在数学推理中处理错误的能力。
Exposing the Achilles’ Heel: Evaluating LLMs Ability to Handle Mistakes in Mathematical Reasoning
Joykirat Singh, Akshay Nambi, Vibhav Vineet

##  revisiting LLMs作为零样本时间序列预测器：微小的噪声可以击垮大型模型。
Revisiting LLMs as Zero-Shot Time Series Forecasters: Small Noise Can Break Large Models
Junwoo Park, Hyuck Lee, Dohyun Lee, Daehoon Gwak, Jaegul Choo

## SeaKR：自我 Awareness 知识检索以实现适应性检索增强生成。
SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation
Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Liu Weichuan, Lei Hou, Juanzi Li

## 自动结构化放射学报告生成
Automated Structured Radiology Report Generation
Jean-Benoit Delbrouck, Justin Xu, Johannes Moll, Alois Thomas, Zhihong Chen, Maya Varma, Asfandyar Azhar, Sophie Ostmeier, Andrew Johnston, Eduardo Pontes Reis, Christian Bluethgen, Mohamed S Muneer, Kelvin Zhenghao Li, Curtis Langlotz

## ProgCo：编程助手帮助大规模语言模型自我修正。
ProgCo: Program Helps Self-Correction of Large Language Models
Xiaoshuai Song, Yanan Wu, Weixun Wang, Jiaheng Liu, Wenbo Su, Bo Zheng

## VideoVista2：360°全景视角——跨越文化、语言和领域界限的视频理解。
VideoVista2: 360° Horizons-Bridging Cultures, Languages, and Domains in Video Comprehension
Xinyu Chen, yunxin li, Haoyuan Shi, Baotian Hu, Wenhan Luo, Yaowei Wang, Min Zhang

## SudoLM：参数化知识的授权对齐学习访问控制。
SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment
Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen

## 利用自我注意力进行输入依赖的软提示在大规模语言模型中的应用。
Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs
Ananth Muppidi, Abhilash Nandy, Sambaran Bandyopadhyay

## 奥德赛 navigating 希拉尼亚的歌声：动态焦点解码在事实性和多样化开放生成中的应用。
Odysseus Navigates the Sirens’ Song: Dynamic Focus Decoding for Factual and Diverse Open-Ended Text Generation
Wen Luo, Feifan Song, Wei Li, Guangyue Peng, Shaohang Wei, Houfeng Wang

## 更好的嵌入表示——基于耦合Adam的方法。
Better Embeddings with Coupled Adam
Felix Stollenwerk, Tobias Stollenwerk

## 具有声明性GenieWorksheets的可控且可靠的知识密集型任务代理。
Controllable and Reliable Knowledge-Intensive Task Agents with Declarative GenieWorksheets
Harshit Joshi, Shicheng Liu, James Chen, Larsen Weigle, Monica Lam

## I0T：Towards Zero Modality Gap 的标准化嵌入方法。
I0T: Embedding Standardization Method Towards Zero Modality Gap
Na Min An, Eunki Kim, James Thorne, Hyunjung Shim

## 骨头汤：一种求解与熬汤模型融合的方法，用于可控多目标生成。
Bone Soups: A Seek-and-Soup Model Merging Approach for Controllable Multi-Objective Generation
Guofu Xie, Xiao Zhang, Ting Yao, Yunsheng Shi

## 在长代码理解任务上基准测试长语境语言模型。
Benchmarking Long-Context Language Models on Long Code Understanding
Jia Li, Xuyuan Guo, Lei Li, Kechi Zhang, Ge Li, Jia Li, Zhengwei Tao, Fang Liu, Chongyang Tao, Yuqi Zhu, Zhi Jin

## MAGNET：增强生成解码器的表示学习和填补能力。
MAGNET: Augmenting Generative Decoders with Representation Learning and Infilling Capabilities
Savya Khosla, Aditi Tiwari, Kushal Kafle, Simon Jenni, Handong Zhao, John Collomosse, Jing Shi

## 一种具有自动基准和更好可解释性的双视角NLG元评估框架。
A Dual-Perspective NLG Meta-Evaluation Framework with Automatic Benchmark and Better Interpretability
Xinyu Hu, Mingqi Gao, Li Lin, Zhenghan Yu, Xiaojun Wan

## 基于数据约束的去标识化训练数据合成。
Data-Constrained Synthesis of Training Data for De-Identification
Thomas Vakili, Aron Henriksson, Hercules Dalianis

## 循环知识定位与融合在语言模型持续学习中的应用
Recurrent Knowledge Localization and Fusion for Language Model Continual Learning
Yujie Feng, Xujia Wang, ZEXIN LU, FuShenghong, Guangyuan SHI, Yongxin Xu, Yasha Wang, Philip S. Yu, Xu Chu, Xiao-Ming Wu

## MMDEND：受树突启发的多分支多区域并行脉冲神经元用于序列建模。
MMDEND: Dendrite-Inspired Multi-Branch Multi-Compartment Parallel Spiking Neuron for Sequence Modeling
Kexin Wang, Yuhong Chou, Di Shang, Shijie Mei, Jiahong Zhang, Yanbin Huang, Man Yao, Bo XU, Guoqi Li

## 不一致的分词导致语言模型对日语语法感到困惑。
Inconsistent Tokenizations Cause Language Models to be Perplexed by Japanese Grammar
Andrew Gambardella, Takeshi Kojima, Yusuke Iwasawa, Yutaka Matsuo

## 只是轻轻一擦：通过意图区分和表情符号解读提升大语言模型自我伤害检测能力。
Just a Scratch: Enhancing LLM Capabilities for Self-harm Detection through Intent Differentiation and Emoji Interpretation
Soumitra Ghosh, gopendra Vikram singh, Shambhavi, Sabarna Choudhury, Asif Ekbal

## 基于对比学习的大型语言模型后生成树库跨领域成分解析研究
Contrastive Learning on LLM Back Generation Treebank for Cross-domain Constituency Parsing
Peiming Guo, Meishan Zhang, jianling li, Min Zhang, Yue Zhang

## QuASAR：一种基于问题的结构意识生成方法，用于表格到文本的生成。
QuASAR: A Question-Driven Structure-Aware Approach for Table-to-Text Generation
WeiJie Liu, Yibin Zheng, Fang Kong

## 通过影响函数理解人类反馈的作用。
Understanding Impact of Human Feedback via Influence Functions
Taywon Min, Haeone Lee, Yongchan Kwon, Kimin Lee

## InspireDebate：基于多维度主观与客观评价引导的辩论推理与优化。
InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating
Fuyu Wang, Jiangtong Li, Kun Zhu, Changjun Jiang

## T2I-FactualBench：基于知识密集型概念评估文本到图像模型事实性的基准测试。
T2I-FactualBench: Benchmarking the Factuality of Text-to-Image Models with Knowledge-Intensive Concepts
Ziwei Huang, Wanggui He, Quanyu Long, Yandi Wang, Haoyuan Li, Zhelun Yu, Fangxun Shu, Weilong Dai, Hao Jiang, Leilei Gan, Fei Wu

## WAVE：通过迭代的实际世界探索、反馈和优化构建多模态网络代理
WAVE: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization
Hongliang He, Wenlin Yao, Kaixin Ma, Wenhao Yu, Hongming Zhang, Tianqing Fang, Zhenzhong Lan, Dong Yu

## 理解大型语言模型内在自我修正的阴暗面。
Understanding the Dark Side of LLMs’ Intrinsic Self-Correction
Qingjie Zhang, Di Wang, Haoting Qian, Yiming Li, Tianwei Zhang, Minlie Huang, Han Qiu

## FOCUS：评估预训练的跨模态模型在歧义推理上的表现。
FOCUS: Evaluating Pre-trained Vision-Language Models on Underspecification Reasoning
Kankan Zhou, Eason Lai, Kyriakos Mouratidis, Jing Jiang

## 反击言论：最终的防护手段！通过属性前缀学习实现多条件反击生成。
Counterspeech the ultimate shield! Multi-Conditioned Counterspeech Generation through Attributed Prefix Learning
Aswini Kumar Padhi, Anil Bandhakavi, Tanmoy Chakraborty

## 基于视障用户反馈构建符合BLV数据集的图表描述：重视视障用户的体验。
Sightation Counts: Leveraging Sighted User Feedback in Building a BLV-aligned Dataset of Diagram Descriptions
Wan Ju Kang, Eunki Kim, Na Min An, Sangryul Kim, Haemin Choi, Ki Hoon Kwak, James Thorne

## CheXalign：在不依赖人类反馈的情况下，针对胸部X光解释模型的偏好微调。
CheXalign: Preference fine-tuning in chest X-ray interpretation models without human feedback
Dennis Hein, Zhihong Chen, Sophie Ostmeier, Justin Xu, Maya Varma, Eduardo Pontes Reis, Arne Edward Michalson MD, Christian Bluethgen, Hyun Joo Shin, Curtis Langlotz, Akshay S Chaudhari

## 个人旅行解决者：一个基于偏好的LLM-解决系统，用于旅行规划。
Personal Travel Solver: A Preference-Driven LLM-Solver System for Travel Planning
Zijian Shao, Jiancan Wu, Weijian Chen, Xiang Wang

## 结合学生问题的编程教育知识追踪。
Knowledge Tracing in Programming Education Integrating Students’ Questions
Doyoun Kim, Suin Kim, Yohan Jo

## 论文标题翻译如下：\n什么是构建有效长上下文多跳指令数据集的关键要素？见解与最佳实践。
What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices
Zhi Chen, Qiguang Chen, Libo Qin, Qipeng Guo, haijun Lv, Yicheng Zou, Hang Yan, Kai Chen, Dahua Lin

## 基于知识图谱检索增强的生成推荐模型。
Knowledge Graph Retrieval-Augmented Generation for LLM-based Recommendation
Shijie Wang, Wenqi Fan, Yue Feng, LIN SHANRU, Xinyu Ma, Shuaiqiang Wang, Dawei Yin

## 通过模型合并将文本偏好转移到视觉-语言理解。
Transferring Textual Preferences to Vision-Language Understanding through Model Merging
Chen-An Li, Tzu-Han Lin, Yun-Nung Chen, Hung-yi Lee

## 中文惯性GAN在手写信号生成与识别中的应用
Chinese Inertial GAN for Handwriting Signal Generation and Recognition
Yifeng Wang, Yi Zhao

## 在线迭代自我对齐以生成放射学报告。
Online Iterative Self-Alignment for Radiology Report Generation
Ting Xiao, Lei Shi, Yang Zhang, HaoFeng Yang, Zhe Wang, Chenjia Bai

## PRISM：一种生成具有政治意识交叉编码器的可解释政治偏见嵌入的框架。
PRISM: A Framework for Producing Interpretable Political Bias Embeddings with Political-Aware Cross-Encoder
Yiqun Sun, Qiang Huang, Anthony Kum Hoe Tung, Jun Yu

## LLM×MapReduce：使用大规模语言模型简化长序列处理。
LLM$\\times$MapReduce: Simplified Long-Sequence Processing using Large Language Models
Zihan Zhou, Chong Li, 陈昕怡, Shuo Wang, Yu Chao, Zhili Li, Haoyu Wang, Qi Shi, Zhixing Tan, Xu Han, Xiaodong Shi, Zhiyuan Liu, Maosong Sun

## LLMs 同甘共苦：恶意软件请求与脱缰挑战。
LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges
Haoyang Li, Huan Gao, Zhiyuan Zhao, Zhiyu Lin, Junyu Gao, Xuelong Li

## GRAT：通过过程奖励树搜索引导检索增强推理。
GRAT: Guiding Retrieval-Augmented Reasoning through Process Rewards Tree Search
Xianshu Peng, Wei Wei

## 基于信息理论的序列标注评估。
Evaluating Sequence Labeling on the basis of Information Theory
Enrique Amigo, Elena Álvarez-Mellado, Julio Gonzalo, Jorge Carrillo-de-Albornoz

## T-REG：基于令牌级奖励正则化的偏好优化。
T-REG: Preference Optimization with Token-Level Reward Regularization
Wenxuan Zhou, Shujian Zhang, Lingxiao Zhao, Tao Meng

## 在图像间编织语境：通过聚焦为中心的视觉链提升视觉语言模型。
Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains
Juntian Zhang, Chuanqi Cheng, Yuhan Liu, Wei Liu, Jian Luan, Rui Yan

## 哥德尔代理：一种用于递归自我改进的自指代理框架。
Gödel Agent: A Self-Referential Agent Framework for Recursively Self-Improvement
Xunjian Yin, Xinyi Wang, Liangming Pan, Li Lin, Xiaojun Wan, William Yang Wang

## 通过对比解码增强输入标签映射在上下文学习中的效果。
Enhancing Input-Label Mapping in In-Context Learning with Contrastive Decoding
Keqin Peng, Liang Ding, Yuanxin Ouyang, Meng Fang, Yancheng Yuan, Dacheng Tao

## 重新思考提示策略在大规模语言模型测试时扩展中的角色：从概率论视角出发。
Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory
Yexiang Liu, Zekun Li, Zhi Fang, Nan Xu, Ran He, Tieniu Tan

## 基于查询的生物医学研究中文档级科学研究证据提取。
Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies
Massimiliano Pronesti, Joao H Bettencourt-Silva, Paul Flanagan, Alessandra Pascale, Oisín Redmond, Anya Belz, Yufang Hou

## AgentGym：评估和训练基于大型语言模型的智能体跨多种环境。
AgentGym: Evaluating and Training Large Language Model-based Agents across Diverse Environments
Zhiheng Xi, Yiwen Ding, Wenxiang Chen, Boyang Hong, Honglin Guo, Junzhe Wang, Xin Guo, Dingwen Yang, Chenyang Liao, Wei He, Songyang Gao, Lu Chen, Rui Zheng, Yicheng Zou, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, Yu-Gang Jiang

## 走向稳健的通用信息抽取：数据集、评估与解决方案。
Towards Robust Universal Information Extraction: Dataset, Evaluation, and Solution
Jizhao Zhu, Akang Shi, Zixuan Li, Long Bai, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng

## 在信息论连续谱上的可学习性：神经语言模型中信息局部性的归纳偏置。
Learnability on the Information-Theoretic Continuum: Inductive Bias for Information Locality in Neural Language Models
Taiga Someya, Anej Svete, Brian DuSell, Timothy J. O’Donnell, Mario Giulianelli, Ryan Cotterell

## 社交媒体中的时间线总结的时间推理。
Temporal reasoning for timeline summarisation in social media
Jiayu Song, Mahmud Elahi Akhter, Dana Atzil-Slonim, Maria Liakata

## 学会随时间进行推理：时间线自我反思以提高语言模型的时序推理能力。
Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models
Adrián Bazaga, Rexhina Blloshmi, Bill Byrne, Adrià de Gispert

## 超越负面刻板印象——身份群体及其语义变体的非负面虐待言论。
Beyond Negative Stereotypes – Non-Negative Abusive Utterances about Identity Groups and Their Semantic Variants
Tina Lommel, Elisabeth Eder, Josef Ruppenhofer, Michael Wiegand

## 多视角对齐以提高神经机器翻译的自然度。
Multi-perspective Alignment for Increasing Naturalness in Neural Machine Translation
Huiyuan Lai, Esther Ploeger, Rik van Noord, Antonio Toral

## 分词问题是NP完全问题。
Tokenisation is NP-Complete
Philip Whittington, Gregor Bachmann, Tiago Pimentel

## 基于 lexical 多样性 的相关性评估以增强检索生成。
Lexical Diversity-aware Relevance Assessment for Retrieval-Augmented Generation
Zhange Zhang, Yuqing Ma, Yulong Wang, Shan He, Tianbo Wang, Siqi He, Jiakai Wang, Xianglong Liu

## 持久同调主题网络预测读者好奇心。
Persistent Homology of Topic Networks for the Prediction of Reader Curiosity
Manuel D.S. Hopp, Vincent Labatut, Arthur Amalvy, Richard Dufour, Hannah Stone, Hayley K Jach, Kou Murayama

## 论文标题翻译：通过控制价值向量激活实现大型语言模型内部价值对齐。
Internal Value Alignment in Large Language Models through Controlled Value Vector Activation
Haoran Jin, Meng Li, Xiting Wang, Zhihao Xu, Minlie Huang, Yantao Jia, Defu Lian

## 论文标题翻译如下：\n《大型语言模型中事实、虚构和预测的表示：知识态度与观点》
Representations of Fact, Fiction and Forecast in Large Language Models: Epistemics and Attitudes
Meng Li, Michael Vrazitulis, David Schlangen

## 参数意识对比知识编辑：基于关键传输路径的追踪与修正。
Parameter-Aware Contrastive Knowledge Editing: Tracing and Rectifying based on Critical Transmission Paths
Songlin Zhai, Yuan Meng, Yuxin Zhang, Guilin Qi

## 内在思考变压器：利用动态深度缩放促进适应性内在思考。
Inner Thinking Transformer: Leveraging Dynamic Depth Scaling to Foster Adaptive Internal Thinking
Yilong Chen, Junyuan Shang, Zhenyu Zhang, Yanxi Xie, Jiawei Sheng, Tingwen Liu, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang

## 通过损失减速和零和学习理解语言模型的扩展规律在训练动态中的表现。
Understanding Language Model Scaling Laws in Terms of Training Dynamics via Loss Deceleration and Zero-Sum Learning
Andrei Mircea, Supriyo Chakraborty, Nima Chitsazan, Irina Rish, Ekaterina Lobacheva

## 混合小模型与大模型的中文拼写检查方法
Mixture of Small and Large Models for Chinese Spelling Check
Ziheng Qiao, Houquan Zhou, Zhenghua Li

## 多个大脑胜过一个：基于LLM的多代理系统在科学理念生成中的改进表现。
Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System
Haoyang Su, Renqi Chen, SHIXIANG TANG, Zhenfei Yin, Xinzhe Zheng, Jinzhe Li, Biqing Qi, Qi Wu, Hui Li, Wanli Ouyang, Philip Torr, Bowen Zhou, Nanqing Dong

## Opt-Out：通过最优传输研究实体级别取消学习以应用于大规模语言模型。
Opt-Out: Investigating Entity-Level Unlearning for Large Language Models via Optimal Transport
Minseok Choi, Daniel Rim, Dohyun Lee, Jaegul Choo

## 使用最优运输的最小贝叶斯风险解码文档级文本生成。
Document-Level Text Generation with Minimum Bayes Risk Decoding using Optimal Transport
Yuu Jinnai

## 自底向上的分词器中合并操作的因果影响。
The Causal Effect of Merge Operations in Bottom-up Tokenisers
Pietro Lesci, Clara Meister, Thomas Hofmann, Andreas Vlachos, Tiago Pimentel

## 价值残差学习
Value Residual Learning
Zhanchao Zhou, Tianyi Wu, Zhiyun Jiang, Fares Obeid, Zhenzhong Lan

## DISC：基于字符相似性的插件式解码干预中文拼写检查方法。
DISC: Plug-and-Play Decoding Intervention with Similarity of Characters for Chinese Spelling Check
Ziheng Qiao, Houquan Zhou, Yumeng Liu, Zhenghua Li, Min Zhang, Bo Zhang, Chen Li, Ji Zhang, Fei Huang

## NusaAksara： preserving Indonesian Indigenous Scripts 的跨模态多语言基准。
NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts
Muhammad Farid Adilazuarda, Musa Izzanardi Wijanarko, Lucky Susanto, Khumaisa Nur’aini, Derry Tanti Wijaya, Alham Fikri Aji

## 医疗图RAG：基于图检索增强生成的证据医学大规模语言模型。
Medical Graph RAG: Evidence-based Medical Large Language Model via Graph Retrieval-Augmented Generation
Junde Wu, Jiayuan Zhu, Yunli Qi, Jingkun Chen, Min Xu, Filippo Menolascina, Yueming Jin, Vicente Grau

## 探究多模态实体对齐中的相对交互和动态校准。
Probing Relative Interaction and Dynamic Calibration in Multi-modal Entity Alignment
Chenxiao Li, Jingwei Cheng, Qiang Tong, Fu Zhang, Cairui Wang

## 面向分层任务的多模态增量LoRA专家混合模型在体化持续学习中的应用
Hierarchical-Task-Aware Multi-modal Mixture of Incremental LoRA Experts for Embodied Continual Learning
Ziqi Jia, Anmin Wang, Xiaoyang Qu, Xiaowen Yang, Jianzong Wang

## 统一均匀量化和二进制编码量化以准确压缩大型语言模型
Unifying Uniform and Binary-coding Quantization for Accurate Compression of Large Language Models
Seungcheol Park, Jeongin Bae, Beomseok Kwon, Minjun Kim, Byeongwook Kim, Se Jung Kwon, U Kang, Dongsoo Lee

## SpindleKV：一种兼顾浅层和深层的新型KV缓存减少方法。
SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers
Zicong Tang, Shi Luohe, Zuchao Li, Baoyuan Qi, Liu Guoming, Lefei Zhang, Ping Wang

## 论文标题：基于LLM的 rumor 检测方法：通过影响力引导的样本选择和基于博弈的观点分析。
LLM-based Rumor Detection via Influence Guided Sample Selection and Game-based Perspective Analysis
Zhiliang Tian, jingyuan huang, Zejiang He, Zhen Huang, Menglong Lu, Linbo Qiao, Songzhu Mei, Yijie Wang, Dongsheng Li

## SGIC：一种自指导迭代校准框架for RAG（注：RAG可能指的是Retrieval-Augmented Generation，这里保持原文缩写）
SGIC: A Self-Guided Iterative Calibration Framework for RAG
Guanhua Chen, Yutong Yao, Lidia S. Chao, Xuebo Liu, Derek F. Wong

## 多方面融合用于方面查询-示例检索。
Multi-Facet Blending for Faceted Query-by-Example Retrieval
Heejin Do, Sangwon Ryu, Jonghwi Kim, Gary Lee

## 加速您的代码：通过双向树编辑实现渐进代码加速。
Speed Up Your Code: Progressive Code Acceleration Through Bidirectional Tree Editing
Longhui Zhang, Jiahao Wang, Meishan Zhang, GaoXiong Cao, Ensheng Shi, mayuchi, Jun Yu, Honghai LIU, Jing Li, Min Zhang

## 从出院总结中提取不良事件：一个新的数据集、标注方案和初步发现。
Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings
Imane Guellil, Salomé Andres, Atul Anand, Bruce Guthrie, Huayu Zhang, Abul Hasan, Honghan Wu, Beatrice Alex

## 坚守均值：检测文本嵌入模型中的黏性词汇。
Sticking to the Mean: Detecting Sticky Tokens in Text Embedding Models
Kexin Chen, Dongxia Wang, Yi Liu, Haonan Zhang, Wenhai Wang

## MIR：科学研究所启发性方法的检索方法。
MIR: Methodology Inspiration Retrieval for Scientific Research Problems
Aniketh Garikaparthi, Manasi Patwardhan, Aditya Sanjiv Kanade, Aman Hassan, Lovekesh Vig, Arman Cohan

## 学会记忆：基于邻居混合的记忆诱导在半参数语言模型中的可扩展连续学习。
Learn to Memorize: Scalable Continual Learning in Semiparametric Language Models with Mixture-of-Neighbors Induction Memory
Guangyue Peng, Tao Ge, Wen Luo, Wei Li, Houfeng Wang

## 论文标题：不同的语音翻译模型在编码和翻译说话人性别方面存在差异。
Different Speech Translation Models Encode and Translate Speaker Gender Differently
Dennis Fucci, Marco Gaido, Matteo Negri, Luisa Bentivogli, Andre Martins, Giuseppe Attanasio

## 独特难注意力：二元故事。
Unique Hard Attention: A Tale of Two Sides
Selim Jerad, Anej Svete, Jiaoda Li, Ryan Cotterell

## 记忆不足：通过推理进行深层次知识注入。
Memorizing is Not Enough: Deep Knowledge Injection Through Reasoning
Ruoxi Xu, Yunjie Ji, Boxi Cao, Yaojie Lu, Hongyu Lin, Xianpei Han, Ben He, Yingfei Sun, Xiangang Li, Le Sun

## 通过组合搜索提高对话状态跟踪——针对上下文示例。
Improving Dialogue State Tracking through Combinatorial Search for In-Context Examples
Haesung Pyun, Yoonah Park, Yohan Jo

## PIPER：通过去偏见-蒸馏增强调优，评估和提示大型语言模型事件推理能力的基准测试。
PIPER: Benchmarking and Prompting Event Reasoning Boundary of LLMs via Debiasing-Distillation Enhanced Tuning
Zhicong Lu, Changyuan Tian, PeiguangLi, Li Jin, Sirui Wang, Wei Jia, Ying Shen, Guangluan Xu

## SHuBERT：通过多流聚类预测进行的自监督手语表示学习。
SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction
Shester Gueuwou, Xiaodan Du, Greg Shakhnarovich, Karen Livescu, Alexander H. Liu

## 通过价值强化的情感支持对话系统
Dialogue Systems for Emotional Support via Value Reinforcement
Juhee Kim, Chunghu Mok, Jisun LEE, Hyang Sook Kim, Yohan Jo

## ERU-KG：高效对齐参考的无监督短语生成。
ERU-KG: Efficient Reference-aligned Unsupervised Keyphrase Generation
Lam Thanh Do, Aaditya Bodke, Pritom Saha Akash, Kevin Chen-Chuan Chang

## 预训练上下文压缩器：基于嵌入的记忆大型语言模型。
Pretraining Context Compressor for Large Language Models with Embedding-Based Memory
Yuhong Dai, Jianxun Lian, Yitian Huang, Wei Zhang, Mingyang Zhou, Mingqi Wu, Xing Xie, Hao Liao

## 基于PLM的模型中由长度引起的嵌入崩溃。
Length-Induced Embedding Collapse in PLM-based Models
Yuqi Zhou, Sunhao Dai, Zhanshuo Cao, Xiao Zhang, Jun Xu

## SEAL：扩展以突出注意力的长上下文检索。
SEAL: Scaling to Emphasize Attention for Long-Context Retrieval
Changhun Lee, Minsang Seok, Jun-gyu Jin, YoungHyun Cho, Eunhyeok Park

## LLM更信任人类，这是一个问题！揭示并缓解检索增强生成中的权威偏差。
LLMs Trust Humans More, That’s a Problem! Unveiling and Mitigating the Authority Bias in Retrieval-Augmented Generation
Yuxuan LI, Xinwei Guo, Jiashi Gao, Guanhua Chen, Xiangyu Zhao, Jiaxin Zhang, Quanying Liu, Haiyan Wu, Xin Yao, Xuetao Wei

## 基于大型语言模型的稳健性保留隐私文本匿名化方法。
Robust Utility-Preserving Text Anonymization Based on Large Language Models
Tianyu Yang, Xiaodan Zhu, Iryna Gurevych

## 了解你的错误：通过责任建模减少对以任务为导向的对话AI过度依赖的努力。
Know Your Mistakes: Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling
Suvodip Dey, Yi-Jyun Sun, Gokhan Tur, Dilek Hakkani-Tür

## PopAlign：多样化对比模式以实现更全面的对齐。
PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment
Zekun Moore Wang, Shenzhi Wang, King Zhu, Jiaheng Liu, Ke Xu, Jie Fu, Wangchunshu Zhou, Wenhao Huang

##  revitalizing 文化遗产：一种全面历史文书恢复的新型方法。
Reviving Cultural Heritage: A Novel Approach for Comprehensive Historical Document Restoration
Yuyi Zhang, Peirong Zhang, Zhenhua Yang, Pengyu Yan, Yongxin Shi, Pengwei Liu, Fengjun Guo, Lianwen Jin

## 分割-then-聚合：一种高效的并行工具调用学习方法。
Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation
Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, Dawei Yin

## $\\mathcal{A}^3$：自动对齐框架，用于带有属性的文本生成。
$\\mathcal{A}^3$: Automatic Alignment Framework for Attributed Text Generation
Yue Wang, Haoke Zhang, Juntao Li, Jinxiong Chang, Min Zhang

## 重新思考大规模语言模型的语义解析：通过语义提示增强LLM性能。
Rethinking Semantic Parsing for Large Language Models: Enhancing LLM Performance with Semantic Hints
Kaikai An, Shuzheng Si, Helan Hu, Haozhe Zhao, Yuchi Wang, Qingyan Guo, Baobao Chang

## 朝着大型语言模型对齐更好的价值原则：系统评估与增强。
Towards Better Value Principles for Large Language Model Alignment: A Systematic Evaluation and Enhancement
Bingbing Xu, Jing Yao, Xiaoyuan Yi, Aishan Maoliniyazi, Xing Xie, Xiaofeng Meng

## 从神经元到语义：通过神经元对齐评估大型语言模型的跨语言对齐能力。
From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment
Chongxuan Huang, Yongshi Ye, Biao Fu, Qifeng Su, Xiaodong Shi

## 通过偏差和多样性分解全面分析最小贝叶斯风险解码。
Comprehensive Analysis of Minimum Bayes Risk Decoding through Bias and Diversity Decomposition
Hidetaka Kamigaito, Hiroyuki Deguchi, Yusuke Sakai, Katsuhiko Hayashi, Taro Watanabe

## SDD：自我降级防御 against 恶意微调。
SDD: Self-Degraded Defense against Malicious Fine-tuning
ZiXuan Chen, Weikai Lu, Xin Lin, Ziqian Zeng

## CoachMe：基于参考的运动元素解码与教练指令生成模型。
CoachMe: Decoding Sport Elements with a Reference-Based Coaching Instruction Generation Model
Wei-Hsin Yeh, Yu-An Su, Chih-Ning Chen, Yi-Hsueh Lin, Calvin Ku, WENHSIN CHIU, Min-Chun Hu, Lun-Wei Ku

## 语言模型、图搜索和监督篡改：何时更多的监督反而不好，以及如何使其变得更好。
Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More
Arvid Frydenlund

## 论文标题翻译：跨模态视觉语言模型中实体知识提取的性能差距。
Performance Gap in Entity Knowledge Extraction Across Modalities in Vision Language Models
Ido Cohen, Daniela Gottesman, Mor Geva, Raja Giryes

## 论文标题：语言模型的概率在数值上下文中并不校准。
Language Model Probabilities are $Not$ Calibrated in Numeric Contexts
Charles Lovering, Michael Krumdick, Viet Dac Lai, Varshini Reddy, Seth Ebner, Nilesh Kumar, Rik Koncel-Kedziorski, Chris Tanner

## DeepDeepReview：通过类人的深度思考过程 提升基于LLM的论文评审。 \n\n注：这里的 \"DeepDeep\" 和 \"process\" 我保留了原文形式，
DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process
Minjun Zhu, Yixuan Weng, Linyi Yang, Yue Zhang

## 错归因问题：量化作者归属中的不公平现象。
Misattribution Matters: Quantifying Unfairness in Authorship Attribution
Pegah Alipoormolabashi, Ajay Patel, Niranjan Balasubramanian

## MDCure：一个可扩展的多文档指令遵循流水线。
MDCure: A Scalable Pipeline for Multi-Document Instruction-Following
Gabrielle Kaili-May Liu, Bowen Shi, Avi Caciularu, Idan Szpektor, Arman Cohan

## 跨语言自动评估以评估多语言LLM模型。
Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs
Sumanth Doddapaneni, Mohammed Safi Ur Rahman Khan, Dilip Venkatesh, Raj Dabre, Anoop Kunchukuttan, Mitesh M Khapra

## 如何理解LLM在叙事中对时间结构的把握：一种认知评价LLM的案例研究。
How LLMs Comprehend Temporal Structure in Narratives: A Case Study in Cognitive Evaluation of LLMs
Karin De Langis, Jong Inn Park, Andreas Schramm, Bin Hu, Khanh Chi Le, Dongyeop Kang

##  bypass 反向传播：基于优化的策略梯度大规模语言模型结构剪枝。
Bypass Back-propagation: Optimization-based Structural Pruning for Large Language Models via Policy Gradient
Yuan Gao, Zujing Liu, WEIZHONG ZHANG, Bo Du, Gui-Song Xia

## 树状辩论：多角色辩论树促进科学比较分析的批判性思维。
Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis
Priyanka Kargupta, Ishika Agarwal, Tal August, Jiawei Han

## DRPruning：通过分布鲁棒优化进行高效的大语言模型剪枝。
DRPruning: Efficient Large Language Model Pruning through Distributionally Robust Optimization
Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Jing Li, Min Zhang, Zhaopeng Tu

## 零-shot 文本转语音（针对越南语）
Zero-Shot Text-to-Speech for Vietnamese
Thi Vu, Linh The Nguyen, Dat Quoc Nguyen

## 结构意识领域的知识注入大型语言模型中。
Structure-aware Domain Knowledge Injection for Large Language Models
Kai Liu, Ze Chen, Zhihang Fu, Wei Zhang, Rongxin Jiang, Fan Zhou, Yaowu Chen, Yue Wu, Jieping Ye

## FinMME：一个金融多模态评估数据集。
FinMME: A Financial Multi-Modal Evaluation Dataset
Junyu Luo, Zhizhuo KOU, Liming Yang, Xiao Luo, Jinsheng Huang, Zhiping Xiao, Jingshu Peng, Chengzhong LIU, Jiaming Ji, Xuanzhe Liu, Sirui Han, Ming Zhang, Yike Guo

## EditInspector：文本引导图像编辑评估基准。
EditInspector: A Benchmark for Evaluation of Text-Guided Image Edits
Ron Yosef, Yonatan Bitton, Dani Lischinski, Moran Yanuka

## Wikipedia生成的分层记忆组织。
Hierarchical Memory Organization for Wikipedia Generation
Eugene J. Yu, Dawei Zhu, Yifan Song, Xiangyu Wong, Jiebin Zhang, Wenxuan Shi, Xiaoguang Li, Qun Liu, Sujian Li

## 使用马氏距离对比的类别蒸馏：一种用于实际语言理解任务的有效训练范式。
Class Distillation with Mahalanobis Contrast: An Efficient Training Paradigm for Pragmatic Language Understanding Tasks
Chenlu Wang, Weimin Lyu, Ritwik Banerjee

## Bregman 条件随机场：具有并行可处理推理算法的序列标注。
Bregman Conditional Random Fields: Sequence Labeling with Parallelizable Inference Algorithms
Caio Corro, Mathieu Lacroix, Joseph Le Roux

## 最优算法依然最优吗？在基于LLM的成对排序中重新思考批量处理和缓存下的排序。
Are Optimal Algorithms Still Optimal? Rethinking Sorting in LLM-Based Pairwise Ranking with Batching and Caching
Juan Wisznia, Cecilia Bolaños, Juan Tollo, Giovanni Franco Gabriel Marraffini, Agustín Andrés Gianolini, Noe Fabian Hsueh, Luciano Del Corro

## SEE：战略探索与利用以实现协同的上下文内提示优化。
SEE: Strategic Exploration and Exploitation for Cohesive In-Context Prompt Optimization
Wendi Cui, Jiaxin Zhang, Zhuohang Li, Hao Sun, Damien Lopez, Kamalika Das, Bradley A. Malin, Sricharan Kumar

## 重新审视真实环境中的大规模语言模型不确定性估计方法。
Reconsidering LLM Uncertainty Estimation Methods in the Wild
Duygu Nur Yaldiz, Yavuz Faruk Bakman, Sungmin Kang, Tuo Zhang, Baturalp Buyukates, Sai Praneeth Karimireddy, Salman Avestimehr

## LLM能否生成高质量的算法问题测试案例？TestCase-Eval：一种系统性评估故障覆盖率和暴露程度的体系。
Can LLMs Generate High-Quality Test Cases for Algorithm Problems? TestCase-Eval: A Systematic Evaluation of Fault Coverage and Exposure
Zheyuan Yang, Zexi Kuang, Yilun Zhao

## 编程举例结合历史语言学：基于大型语言模型的声音规律归纳方法。
Programming by Example meets Historical Linguistics: A Large Language Model Based Approach to Sound Law Induction
Atharva Naik, Darsh Agrawal, Hong Sng, Clayton Marr, Kexun Zhang, Nathaniel Romney Robinson, Kalvin Chang, Rebecca Byrnes, Aravind Mysore, Carolyn Rose, David R Mortensen

## 风雨中的沙堡：重新审视强水印的（不）可能性。
Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking
Fabrice Y Harel-Canada, Boran Erol, Connor Choi, Jason Liu, Gary Jiarui Song, Nanyun Peng, Amit Sahai

## 超越真或假：增强检索下的层级细致断言分析
Beyond True or False: Retrieval-Augmented Hierarchical Analysis of Nuanced Claims
Priyanka Kargupta, Runchu Tian, Jiawei Han

## 从感知到决策：基于行为理论导向的大语言模型的森林火灾疏散决策预测。
From Perceptions to Decisions: Wildfire Evacuation Decision Prediction with Behavioral Theory-informed LLMs
Ruxiao Chen, Chenguang Wang, Yuran Sun, Xilei Zhao, Susu Xu

## 任务防护罩：强制任务对齐以防御间接提示注入攻击的LLM代理。
The Task Shield: Enforcing Task Alignment to Defend Against Indirect Prompt Injection in LLM Agents
Feiran Jia, Tong Wu, Xin Qin, Anna Squicciarini

## Time-MQA：带有背景增强的时间序列多任务问答。
Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement
Yaxuan Kong, Yiyuan Yang, Yoontae Hwang, Wenjie Du, Stefan Zohren, Zhangyang Wang, Ming Jin, Qingsong Wen

## 题名：阿拉伯语语音识别中的方言覆盖率与泛化能力。
Dialectal Coverage And Generalization in Arabic Speech Recognition
Amirbek Djanibekov, Hawau Olamide Toyin, Raghad Alshalan, Abdullah Alatir, Hanan Aldarmaki

## GETReason：通过分层多智能体推理增强图像上下文提取。
GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning
Shikhhar Siingh, Abhinav Rawat, Chitta Baral, Vivek Gupta

## 悬而未决：危机咨询对话中的关键时刻。
Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations
Vivian Nguyen, Lillian Lee, Cristian Danescu-Niculescu-Mizil

## 揭示BERT家族的潜力：构建可扩展、通用且竞争力强的大语言模型的新方法。
Unveiling the Potential of BERT-family: A New Recipe for Building Scalable, General and Competitive Large Language Models
Yisheng Xiao, Juntao Li, Wenpeng Hu, Min Zhang

## 使用动态分词重塑大型语言模型。
Retrofitting Large Language Models with Dynamic Tokenization
Darius Feher, Ivan Vulić, Benjamin Minixhofer

## 双语零样本立场检测
Bilingual Zero-Shot Stance Detection
Chenye Zhao, Cornelia Caragea

## 论文标题：关于非自回归翻译迭代 refinement 的实证研究。
An Empirical Study of Iterative Refinements for Non-autoregressive Translation
Yisheng Xiao, Pei Guo, Zechen Sun, Juntao Li, Kai Song, Min Zhang

## 定理证明器作为合成数据生成的裁判
Theorem Prover as a Judge for Synthetic Data Generation
Joshua Ong Jun Leang, Giwon Hong, Wenda Li, Shay B Cohen

## 测量转录噪声对 下游语言理解任务的影响。
Measuring the Effect of Transcription Noise on Downstream Language Understanding Tasks
Ori Shapira, Shlomo Chazan, Amir David Nissan Cohen

## 基于原则的内容选择生成多样且个性化的多文档摘要。
Principled Content Selection to Generate Diverse and Personalized Multi-Document Summaries
Vishakh Padmakumar, Zichao Wang, David Arbour, Jennifer Healey

## TaxoAdapt：将基于LLM的多维分类构建与 evolving 研究语料库的发展对齐。
TaxoAdapt: Aligning LLM-Based Multidimensional Taxonomy Construction to Evolving Research Corpora
Priyanka Kargupta, Nan Zhang, Yunyi Zhang, Rui Zhang, Prasenjit Mitra, Jiawei Han

## GrammaMT：基于语法引导的上下文学习以提升机器翻译。
GrammaMT: Improving Machine Translation with Grammar-Informed In-Context Learning
Rita Ramos, Everlyn Asiko Chimoto, Maartje Ter Hoeve, Natalie Schluter

## LLM抽样理论：描述性与规范性并存。
A Theory of LLM Sampling: Part Descriptive and Part Prescriptive
Sarath Sivaprasad, Pramod Kaushik, Sahar Abdelnabi, Mario Fritz

## PARME：面向中东低资源语言的并行语料库。
PARME: Parallel Corpora for Low-Resourced Middle Eastern Languages
Sina Ahmadi, Rico Sennrich, Erfan Karami, Ako Marani, Parviz Fekrazad, Gholamreza Akbarzadeh Baghban, Hanah Hadi, Semko Heidari, Mahîr Dogan, Pedram Asadi, Dashne Bashir, Mohammad Amin Ghodrati, Kourosh Amini, Zeynab Ashourinezhad, Mana Baladi, Farshid Ezzati, Alireza Ghasemifar, Daryoush Hosseinpour, Behrooz Abbaszadeh, Amin Hassanpour, Bahaddin jalal hamaamin, Saya Kamal Hama, Ardeshir Mousavi, Sarko Nazir Hussein, Isar Nejadgholi, Mehmet Ölmez, Horam Osmanpour, Rashid Roshan Ramezani, Aryan Sediq Aziz, Ali Salehi, Mohammadreza Yadegari, Kewyar Yadegari, Sedighe Zamani Roodsari

## 论文标题：你能信任大语言模型对有偏结论简单推理有效性的判断吗？——不能！
Can You Trust LLMs’ Judgements of the Validity of Simple Inferences With Partisan Conclusions? – No!
Reto Gubelmann, Ghassen Karray

## MEraser：一种有效的大型语言模型指纹擦除方法。
MEraser: An Effective Fingerprint Erasure Approach for Large Language Models
Jingxuan Zhang, Zhenhua Xu, Rui Hu, Wenpeng Xing, Xuhong Zhang, Meng Han

## ConLoan：用于评估借词的对比多语言数据集。
ConLoan: A Contrastive Multilingual Dataset for Evaluating Loanwords
Sina Ahmadi, Micha David Hess, Elena Álvarez-Mellado, Alessia Battisti, Cui Ding, Anne Göhring, Yingqiang Gao, Zifan Jiang, Andrianos Michail, Peshmerge Morad, Joel Niklaus, Maria Christina Panagiotopoulou, Stefano Perrella, Juri Opitz, Anastassia Shaitarova, Rico Sennrich

## METAL：一种用于图表生成的多agent框架，支持测试时扩展。
METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling
Bingxuan Li, Yiwei Wang, Jiuxiang Gu, Kai-Wei Chang, Nanyun Peng

## TreeCut：用于评估LLM幻觉的合成不可回答的数学文字题数据集。
TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation
Jialin Ouyang

## MAPoRL：多智能体后联合训练用于强化学习协作大型语言模型。
MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning
Chanwoo Park, Seungju Han, Xingzhi Guo, Asuman E. Ozdaglar, Kaiqing Zhang, Joo-Kyung Kim

## DRAMA：从大型语言模型向更小且泛化能力强的密集检索器多样化增强的方法。
DRAMA: Diverse Augmentation from Large Language Models Towards Smaller Generalizable Dense Retrievers
Xueguang Ma, Xi Victoria Lin, Barlas Oguz, Jimmy Lin, Wen-tau Yih, Xilun Chen

##  stochastic chameleons：无关背景幻觉揭示了LLM基于类别的（误）概括。
Stochastic Chameleons: Irrelevant Context Hallucinations Reveal Class-Based (Mis)Generalization in LLMs
Ziling Cheng, Meng Cao, Marc-Antoine Rondeau, Jackie CK Cheung

## Map&Make：基于模式引导的文本到表格生成。
Map&Make: Schema Guided Text to Table Generation
Naman Ahuja, Fenil Bardoliya, Chitta Baral, Vivek Gupta

## WinSpot：面向多模态大型语言模型的GUI标注基准。
WinSpot: GUI Grounding Benchmark with Multimodal Large Language Models
Zheng Hui, Yinheng Li, Dan Zhao, Colby Banbury, Tianyi Chen, Kazuhito Koishida

## 对称视觉对比优化：通过最小对比图像对视觉--language 模型进行对齐。
Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images
Shengguang Wu, Fan-Yun Sun, Kaiyue Wen, Nick Haber

## CHEER-Ekman：细粒度具身情感分类。
CHEER-Ekman: Fine-grained Embodied Emotion Classification
Phan Anh Duong, Cat Luong, Divyesh Bommana, Tianyu Jiang

## IRIS：可解释的检索增强分类模型，用于长交错文档序列。
IRIS: Interpretable Retrieval-Augmented Classification for Long Interspersed Document Sequences
Fengnan Li, Elliot D. Hill, JIANG SHU, Jiaxin Gao, Matthew M. Engelhard

## 利用条件变分自动编码器结合多个数据集增强命名实体识别。
Enhancing NER by Harnessing Multiple Datasets with Conditional Variational Autoencoders
Taku Oi, Makoto Miwa

## R2D2：具备反思代理记忆的回忆、回放与动态决策。
R2D2: Remembering, Replaying and Dynamic Decision Making with a Reflective Agentic Memory
Tenghao Huang, Kinjal Basu, Ibrahim Abdelaziz, Pavan Kapanipathi, Jonathan May, Muhao Chen

## ScanEZ：将认知模型与自我监督学习集成以预测空间时间凝视路径。
ScanEZ: Integrating Cognitive Models with Self-Supervised Learning for Spatiotemporal Scanpath Prediction
Ekta Sood, Prajit Dhar, Enrica Troiano, Rosy Southwell, Sidney K. DMello

## 公平的故事：以偏见和刻板印象为重点，分析印度文化背景下的公平性评价。
FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes
Janki Atul Nawale, Mohammed Safi Ur Rahman Khan, Janani D, Danish Pruthi, Mitesh M Khapra

## 自主推理：一种精简框架，用于通过自主工具增强LLM推理。
Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools
Junde Wu, Jiayuan Zhu, Yuyuan Liu, Min Xu, Yueming Jin

## SpeechIQ：大型语言模型在语音理解中的认知层次上的语音智能商𪟝
SpeechIQ: Speech-Agentic Intelligence Quotient Across Cognitive Levels in Voice Understanding by Large Language Models
Zhen Wan, Chao-Han Huck Yang, Yahan Yu, Jinchuan Tian, Sheng Li, Ke Hu, Zhehuai Chen, Shinji Watanabe, Fei Cheng, Chenhui Chu, Yu-Chiang Frank Wang, Sadao Kurohashi

## 虚假相关性及其超越：理解并缓解大型语言模型在社会经济地位提取中的捷径学习。
Spurious Correlations and Beyond: Understanding and Mitigating Shortcut Learning in SDOH Extraction with Large Language Models
Fardin Ahsan Sakib, Ziwei Zhu, Karen Trister Grace, Meliha Yetisgen, Ozlem Uzuner

## 预测程序视频指令中的隐含论元。
Predicting Implicit Arguments in Procedural Video Instructions
Anil Batra, Laura Sevilla-Lara, Marcus Rohrbach, Frank Keller

## ViGiL3D：一个语言多样性的三维视觉定位数据集。
ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding
Austin Wang, ZeMing Gong, Angel X Chang

## InjecGuard：评价与缓解提示注入防护模型中的过度防御。
InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models
Hao Li, Xiaogeng Liu, Ning Zhang, Chaowei Xiao

## CLIPErase：在CLIP中高效删除视觉-文本关联。
CLIPErase: Efficient Unlearning of Visual-Textual Associations in CLIP
Tianyu Yang, Lisen Dai, Xiangqi Wang, Minhao Cheng, Yapeng Tian, Xiangliang Zhang

## 改进多文档总结中大型语言模型的公平性。
Improving Fairness of Large Language Models in Multi-document Summarization
Haoyuan Li, Rui Zhang, Snigdha Chaturvedi

## 韵律与语言上下文冗余的时间尺度。
The time scale of redundancy between prosody and linguistic context
Tamar I Regev, Chiebuka Ohams, Shaylee Xie, Lukas Wolf, Evelina Fedorenko, Alex Warstadt, Ethan Wilcox, Tiago Pimentel

## 基础阅读提练
Basic Reading Distillation
Zhi Zhou, Sirui Miao, Xiangyu Duan, Hao Yang, Min Zhang

## SubLIME：基于秩相关预测的子集选择方法，用于高效的数据驱动大语言模型评估。
SubLIME: Subset Selection via Rank Correlation Prediction for Data-Efficient LLM Evaluation
Gayathri Saranathan, Cong Xu, Mahammad Parwez Alam, Tarun Kumar, Martin Foltin, Soon Yee Wong, Suparna Bhattacharya

## 量化了仍然可以校准：一个统一框架用于量化大型语言模型的校准。
Quantized Can Still Be Calibrated: A Unified Framework to Calibration in Quantized Large Language Models
Mingyu Zhong, Guanchu Wang, Yu-Neng Chuang, Na Zou

## $\\text{M}^3\\text{GQA}$：一种多实体多跳多场景图问答基准。
$\\text{M}^3\\text{GQA}$: A Multi-Entity Multi-Hop Multi-Setting Graph Question Answering Benchmark
Boci Peng, Yongchao Liu, Xiaohe Bo, Jiaxin Guo, Yun Zhu, Xuanbo Fan, Chuntao Hong, Yan Zhang

## 更多不一定更好？通过差异化和加权目标提升少量样本的上下文学习。
More is not always better? Enhancing Many-Shot In-Context Learning with Differentiated and Reweighting Objectives
Xiaoqing Zhang, Ang Lv, Yuhan Liu, Flood Sung, Wei Liu, Jian Luan, Shuo Shang, Xiuying Chen, Rui Yan

## 数据 caricature：关于预训练语料中对非洲美国语言的表示。
Data Caricatures: On the Representation of African American Language in Pretraining Corpora
Nicholas Deas, Blake Vente, Amith Ananthram, Jessica A Grieser, Desmond U. Patton, Shana Kleiner, James R. Shepard III, Kathleen McKeown

## 机智的RAG：克服检索增强和知识冲突的缺陷以提升大型语言模型性能。
Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge Conflicts for Large Language Models
Fei Wang, Xingchen Wan, Ruoxi Sun, Jiefeng Chen, Sercan O Arik

## LSSF：通过低秩安全性子空间融合的大规模语言模型安全性对齐。
LSSF: Safety Alignment for Large Language Models through Low-Rank Safety Subspace Fusion
Guanghao Zhou, Panjia Qiu, Cen Chen, Hongyu Li, Jason Chu, Xin Zhang, JUN ZHOU

## ETF：代码摘要中文幻检测的实体追踪框架
ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries
Kishan Maharaj, Vitobha Munigala, Srikanth G. Tamilselvam, Prince Kumar, Sayandeep Sen, Palani Kodeswaran, Abhijit Mishra, Pushpak Bhattacharyya

## 精细时空阅读行为建模
Fine-Grained Spatio-Temporal Modeling of Reading Behavior
Francesco Ignazio Re, Andreas Opedal, Glib Manaiev, Mario Giulianelli, Ryan Cotterell

## 基准测试与改进大规模视觉-语言模型以实现基本的视觉图理解与推理
Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning
Yingjie Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Jun Yu, Min Zhang

## 元工具：释放通用大型语言模型在开放世界函数调用能力。
Meta-Tool: Unleash Open-World Function Calling Capabilities of General-Purpose Large Language Models
Shengqian Qin, Yakun Zhu, Linjie Mu, Shaoting Zhang, Xiaofan Zhang

## 我Should I Believe in What Medical AI Says? 医疗AI说的话我应该相信吗？—基于知识和推理的中文医疗基准。
Should I Believe in What Medical AI Says? A Chinese Benchmark for Medication Based on Knowledge and Reasoning
Yue Wu, Yangmin Huang, Qianyun Du, Lixian Lai, Zhiyang He, Jiaxue Hu, Xiaodong Tao

## CCHall：一种新的大语言模型跨语言和跨模态幻觉检测基准。
CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal Hallucinations Detection in Large Language Models
Yongheng Zhang, Xu Liu, Ruoxi Zhou, Qiguang Chen, Hao Fei, Wenpeng Lu, Libo Qin

## TestNUC：通过邻近未标注数据一致性提高测试时计算方法。
TestNUC: Enhancing Test-Time Computing Approaches through Neighboring Unlabeled Data Consistency
Henry Peng Zou, Zhengyao Gu, Yue Zhou, Yankai Chen, Weizhi Zhang, Liancheng Fang, Yibo Wang, Yangning Li, Kay Liu, Philip S. Yu

## 在大模型中激活分布式视觉区域以实现高效的视图-语言训练和推理。
Activating Distributed Visual Region within LLMs for Efficient and Effective Vision-Language Training and Inference
Siyuan Wang, Dianyi Wang, Chengxing Zhou, Zejun Li, Zhihao Fan, Xuanjing Huang, zhongyu wei

## ISR：自我完善的指代表达式用于实体定位。
ISR: Self-Refining Referring Expressions for Entity Grounding
Zhuocheng Yu, Bingchan Zhao, Yifan Song, Sujian Li, ZHONGHUI HE

## Esethu框架：重塑低资源语言可持续数据集治理与编目。
The Esethu Framework: Reimagining Sustainable Dataset Governance and Curation for Low-Resource Languages
Jenalea Rajab, Anuoluwapo Aremu, Everlyn Asiko Chimoto, Graham Morrissey, Fadel Thior, Jessica Ojo, Atnafu Lambebo Tonja, Wilhelmina Nekoto, Pelonomi Moiloa, Jade Abbott, Vukosi Marivate, Benjamin Rosman

## 无需位置编码的变换器在分层语言识别与生成中的理论分析
Theoretical Analysis of Hierarchical Language Recognition and Generation by Transformers without Positional Encoding
Daichi Hayakawa, Issei Sato

## 简约胜繁杂：基于临床实体的可解释且高效的ICD码预测。
Less is More: Explainable and Efficient ICD Code Prediction with Clinical Entities
James Douglas, Yidong Gan, Ben Hachey, Jonathan K. Kummerfeld

## 通过参数合并与解耦实现大语言模型的多模态扩展与留存。
Multi-Modality Expansion and Retention for LLMs through Parameter Merging and Decoupling
Junlin Li, Guodong DU, Jing Li, Sim Kuan Goh, Wenya Wang, Yequan Wang, Fangming Liu, Ho-Kin Tang, Saleh Alharbi, Daojing He, Min Zhang

## 论文标题：序列终生编辑通过知识专家混合模型。
Serial Lifelong Editing via Mixture of Knowledge Experts
YuJu Cheng, Yu-Chu Yu, Kai-Po Chang, Yu-Chiang Frank Wang

## IMOL：Incomplete andIm startPosIality-Tolerant Learning for Multi-Domain Fake News Video Detection
IMOL: Incomplete-Modality-Tolerant Learning for Multi-Domain Fake News Video Detection
Zhi Zeng, Jiaying Wu, Minnan Luo, Herun Wan, Xiangzheng Kong, Zihan Ma, Guang Dai, Qinghua Zheng

## 结合大语言模型进行大规模新闻事件无监督事件检测的研究
Synergizing Unsupervised Episode Detection with LLMs for Large-Scale News Events
Priyanka Kargupta, Yunyi Zhang, Yizhu Jiao, Siru Ouyang, Jiawei Han

## 基准测试LLM和基于LLM的代理在代码仓库实用漏洞检测中的表现。
Benchmarking LLMs and LLM-based Agents in Practical Vulnerability Detection for Code Repositories
Alperen Yildiz, Sin G Teo, Yiling Lou, Yebo Feng, Chong Wang, Dinil Mon Divakaran

## SocialEval：评估大型语言模型的社会智能。
SocialEval: Evaluating Social Intelligence of Large Language Models
Jinfeng Zhou, Yuxuan Chen, Yihan Shi, Xuanming Zhang, Leqi Lei, Yi Feng, Zexuan Xiong, Miao Yan, Xunzhi Wang, Yaru Cao, Jianing Yin, Shuai Wang, Quanyu Dai, Zhenhua Dong, Hongning Wang, Minlie Huang

## DDxTutor：基于鉴别诊断结构化推理的临床推理辅导系统。
DDxTutor: Clinical Reasoning Tutoring System with Differential Diagnosis-Based Structured Reasoning
Qian Wu, Zheyao Gao, Longfei Gou, Qi Dou

## PlanningArena：一个模块化基准，用于多维度评估规划与工具学习。
PlanningArena: A Modular Benchmark for Multidimensional Evaluation of Planning and Tool Learning
Zihan Zheng, Tianle Cui, Chuwen Xie, Jiahui Pan, Qianglong Chen, Lewei He

## 从全局视角看扩散模型：它们是否具有文化包容性？
Diffusion Models Through a Global Lens: Are They Culturally Inclusive?
Zahra Bayramli, Ayhan Suleymanzade, Na Min An, Huzama Ahmad, Eunsu Kim, Junyeong Park, James Thorne, Alice Oh

## 分析并缓解离散语音标记的一致性问题以优化神经编解码语言模型。
Analyzing and Mitigating Inconsistency in Discrete Speech Tokens for Neural Codec Language Models
Wenrui Liu, Zhifang Guo, Jin Xu, Yuanjun Lv, Yunfei Chu, Zemin Liu, Junyang Lin

## 一次获取所有内容可行吗？ARM：一种基于LLM的对齐导向检索方法。
Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method
Peter Baile Chen, Yi Zhang, Mike Cafarella, Dan Roth

## 隐匿于plain sight之中：在多模态设置下LLMs欺骗检测能力的评估。
Hidden in Plain Sight: Evaluation of the Deception Detection Capabilities of LLMs in Multimodal Settings
Md Messal Monem Miah, Adrita Anika, Xi Shi, Ruihong Huang

## 向高效的大语言模型后训练迈进：以数据为中心的视角。
Towards Efficient LLM Post Training: A Data-centric Perspective
Junyu Luo, Bohan Wu, Xiao Luo, Zhiping Xiao, Yiqiao Jin, Rong-Cheng Tu, Nan Yin, Yifan Wang, Jingyang Yuan, Wei Ju, Ming Zhang

## 负面事项：多粒度硬负样本合成及锚定词意识聚合以增强文本嵌入。
Negative Matters: Multi-Granularity Hard-Negative Synthesis and Anchor-Token-Aware Pooling for Enhanced Text Embeddings
Tengyu Pan, Zhichao Duan, Zhenyu Li, Bowen Dong, Ning Liu, Xiuxing Li, Jianyong Wang

## GPT-4作为家庭作业导师可以提高学生参与度和学习成果。
GPT-4 as a Homework Tutor Can Improve Student Engagement and Learning Outcomes
Alessandro Vanzo, Sankalan Pal Chowdhury, Mrinmaya Sachan

## 基于表示的奖励建模：实现大型语言模型高效安全对齐的方法。
Representation-based Reward Modeling for Efficient Safety Alignment of Large Language Model
Deng Qiyuan, Xuefeng Bai, Kehai Chen, Yaowei Wang, Liqiang Nie, Min Zhang

## 真理无国界：超越内容评估真实性。
Truth Knows No Language: Evaluating Truthfulness Beyond English
Blanca Calvo Figueras, Eneko Sagarzazu, Julen Etxaniz, Jeremy Barnes, Pablo Gamallo, Iria de-Dios-Flores, Rodrigo Agerri

## Batayan：一种用于评估大型语言模型的菲律宾语自然语言处理基准。
Batayan: A Filipino NLP benchmark for evaluating Large Language Models
Jann Railey Montalan, Jimson Paulo Layacan, David Demitri Africa, Richell Isaiah S. Flores, Michael T. Lopez II, Theresa Denise Magsajo, Anjanette Cayabyab, William Chandra Tjhi

## 基于英语的声学模型在两种基于英语的环岛语强制对齐中表现良好。
English-based acoustic models perform well in the forced-alignment of two English-Based Pacific Creoles
Sam Passmore, Lila San Roque, Saurabh Nath, Keira Mullan, Kira Davey, Rosey Billington, Nick Thieberger, Danielle Barth

## 推理中的细微错误：错误注入自我修正的偏好学习。
Subtle Errors in Reasoning: Preference Learning via Error-injected Self-editing
Kaishuai Xu, Tiezheng YU, Wenjun Hou, Yi Cheng, Chak Tou Leong, Liangyou Li, Xin Jiang, Lifeng Shang, Qun Liu, Wenjie Li

## 重新审视大语言模型的组成泛化能力，考虑到指令遵循能力。
Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability
Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe

## HintsOfTruth：一个包含真实和合成声明的多模态可信度检测数据集。
HintsOfTruth: A Multimodal Checkworthiness Detection Dataset with Real and Synthetic Claims
Michiel van der Meer, Pavel Korshunov, Sébastien Marcel, Lonneke van der Plas

## 重新思考语法错误纠正的评价指标：为什么使用不同于人类的过程？
Rethinking Evaluation Metrics for Grammatical Error Correction: Why Use a Different Evaluation Process than Human?
Takumi Goto, Yusuke Sakai, Taro Watanabe

## 𝛿-态度：一个大规模真实世界的法律论证观点数据集。
𝛿-Stance: A Large-Scale Real World Dataset of Stances in Legal Argumentation
Ankita Gupta, Douglas Rice, Brendan O’Connor

## 个性动力学：揭示个性特质对文本基于游戏agents的影响。
Persona Dynamics: Unveiling the Impact of Persona Traits on Agents in Text-Based Games
Seungwon Lim, Seungbeen Lee, Dongjun Min, Youngjae Yu

## 这不是一场轻松的散步！语音转文本系统中习语翻译的挑战。
It’s Not a Walk in the Park! Challenges of Idiom Translation in Speech-to-text Systems
Iuliia Zaitova, Badr M. Abdullah, Wei Xue, Dietrich Klakow, Bernd Möbius, Tania Avgustinova

## CityNavAgent：具有层次语义规划和全局记忆的 aerial 视觉-语言导航。
CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory
Weichen Zhang, Chen Gao, Shiquan Yu, Ruiying Peng, Baining Zhao, Qian Zhang, Jinqiang Cui, Xinlei Chen, Yong Li

## SeedBench：一种用于评估大型语言模型在种子科学中的多任务基准。
SeedBench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science
Jie Ying, Zihong Chen, Zhefan Wang, Wanli Jiang, Chenyang Wang, Zhonghang Yuan, Haoyang Su, Huanjun Kong, Fan Yang, Nanqing Dong

## PolyNarrative：一个用于从新闻文章中提取叙事的新多语言、多标签、跨领域数据集。
PolyNarrative: A Multilingual, Multilabel, Multi-domain Dataset for Narrative Extraction from News Articles
Nikolaos Nikolaidis, Nicolas Stefanovitch, Purificação Silvano, Dimitar Iliyanov Dimitrov, Roman Yangarber, Nuno Guimarães, Elisa Sartori, Ion Androutsopoulos, Preslav Nakov, Giovanni Da San Martino, Jakub Piskorski

## 面向中文社交媒体对话的多模态同指消解：数据集与基准方法。
Multimodal Coreference Resolution for Chinese Social Media Dialogues: Dataset and Benchmark Approach
Xingyu Li, Chen Gong, Guohong Fu

## Re$^{3}$Syn：一种基于依赖关系的数据合成框架，适用于长上下文的后训练。
Re$^{3}$Syn: A Dependency-Based Data Synthesis Framework for Long-Context Post-training
Zhiyang Zhang, Ziqiang Liu, Huiming Wang, Renke Shan, Li Kuang, Lu Wang

## 学习辅助任务可以改善开放域长文生成中的参照无引导幻觉检测。
Learning Auxiliary Tasks Improves Reference-Free Hallucination Detection in Open-Domain Long-Form Generation
Chengwei Qin, Wenxuan Zhou, Karthik Abinav Sankararaman, Nanshu Wang, Tengyu Xu, Alexander Radovic, Eryk Helenowski, Arya Talebzadeh, Aditya Tayade, Sinong Wang, Shafiq Joty, Han Fang, Hao Ma

## 赋予聊天机器人眼神和耳朵的能力：一种用于动态交互的沉浸式多模态对话系统。
Enabling Chatbots with Eyes and Ears: An Immersive Multimodal Conversation System for Dynamic Interactions
Jihyoung Jang, Minwook Bae, Minji Kim, Dilek Hakkani-Tür, Hyounghun Kim

## 大型语言模型中的理论思维能力综述。
A Review of Theory of Mind Capabilities in Large Language Models
Ruirui Chen, Weifeng Jiang, Chengwei Qin, Cheston Tan

## 论文标题翻译为：信息轮廓的谐波结构。
The Harmonic Structure of Information Contours
Eleftheria Tsipidi, Samuel Kiegeland, Franz Nowak, Tianyang Xu, Ethan Wilcox, Alex Warstadt, Ryan Cotterell, Mario Giulianelli

## 利用交互式人工智能代理在小时而不是月完成系统评价。
Completing A Systematic Review in Hours instead of Months with Interactive AI Agents
Rui Qiu, Shijie Chen, Yu Su, Po-Yin Yen, Han Wei Shen

## VISA：带有视觉来源归因的检索增强生成。
VISA: Retrieval Augmented Generation with Visual Source Attribution
Xueguang Ma, Shengyao Zhuang, Bevan Koopman, Guido Zuccon, Wenhu Chen, Jimmy Lin

## TACLR：一种可扩展且高效的基于检索的方法，用于工业产品属性值识别。
TACLR: A Scalable and Efficient Retrieval-based Method for Industrial Product Attribute Value Identification
Yindu Su, Huike Zou, Lin Sun, Ting Zhang, Haiyang Yang, Chen Li Yu, David Lo, qingheng zhang, Shuguang Han, jufeng chen

## CLaSp：上下文引导层跳过以实现自我推测解码。
CLaSp: In-Context Layer Skip for Self-Speculative Decoding
Longze Chen, Renke Shan, Huiming Wang, Lu Wang, Ziqiang Liu, Run Luo, Jiawei Wang, Hamid Alinejad-Rokny, Min Yang

## CMHKF：跨模态异构知识融合在弱监督视频异常检测中的应用。
CMHKF: Cross-Modality Heterogeneous Knowledge Fusion for Weakly Supervised Video Anomaly Detection
Shengping Song, Yongsen Zheng, Wuchun He, Guohua Wang

## REAL-MM-RAG：一种现实世界多模态检索基准。
REAL-MM-RAG: A Real-World Multi-Modal Retrieval Benchmark
navve wasserman, roi pony, Oshri Naparstek, Adi Raz Goldfarb, Eli Schwartz, Udi Barzelay, Leonid Karlinsky

## LongSafety：评估大型语言模型长上下文安全性。
LongSafety: Evaluating Long-Context Safety of Large Language Models
Yida Lu, Jiale Cheng, Zhexin Zhang, Shiyao Cui, Cunxiang Wang, Xiaotao Gu, Yuxiao Dong, Jie Tang, Hongning Wang, Minlie Huang

## 价值对齐的大语言模型的意外危害：心理学和实证洞见。
Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights
Sooyung Choi, Jaehyeok Lee, Xiaoyuan Yi, Jing Yao, Xing Xie, JinYeong Bak

## 略偏左：一种基于理论的政治偏见度量方法在大型语言模型中的应用。
Only a Little to the Left: A Theory-grounded Measure of Political Bias in Large Language Models
Mats Faulborn, Indira Sen, Max Pellert, Andreas Spitz, David Garcia

## 教文本代理从失败中学习序列决策-making。 \n\n注：为了使翻译更符合中文表达习惯，可以稍微调整为：\n标题：教文本代理从失败中学习序列决策。
Teaching Text Agents to Learn Sequential Decision Making from Failure
Canasai Kruengkrai, Koichiro Yoshino

##  maximal 匹配最重要：防止表示崩塌以实现稳健的跨模态检索。 \n\n修正后：\n标题：最大匹配至关重要：防止表示崩塌以实现稳健的跨模态检索。
Maximal Matching Matters: Preventing Representation Collapse for Robust Cross-Modal Retrieval
Hani Alomari, Anushka Sivakumar, Andrew Zhang, Chris Thomas

## 从来源到引用的噪音路径：衡量学者与过往研究的互动方式。
The Noisy Path from Source to Citation: Measuring How Scholars Engage with Past Research
Hong Chen, Misha Teplitskiy, David Jurgens

## 通过基于 $\\mathcal{V}$ 可用信息的层增强，利用 LLMs 中的上下文知识。
Exploiting Contextual Knowledge in LLMs through $\\mathcal{V}$-usable Information based Layer Enhancement
Xiaowei Yuan, Zhao Yang, Ziyang Huang, Yequan Wang, Siqi Fan, Yiming Ju, Jun Zhao, Kang Liu

## MAPLE：通过可解释推荐中的多方面提示学习增强审查生成。
MAPLE: Enhancing Review Generation with Multi-Aspect Prompt LEarning in Explainable Recommendation
Ching-Wen Yang, Zhi-Quan Feng, Ying-Jia Lin, Che Wei Chen, Kun-da Wu, Hao Xu, Yao Jui-Feng, Hung-Yu Kao

## FocusLLM：通过动态浓缩实现对长上下文的精确理解。
FocusLLM: Precise Understanding of Long Context by Dynamic Condensing
Zhenyu Li, Yike Zhang, Tengyu Pan, Yutao Sun, Zhichao Duan, Junjie Fang, Rong Han, Zixuan Wang, Jianyong Wang

## 动态拆分与选择在大型语言模型中处理超长上下文的阅读理解。
Dynamic Chunking and Selection for Reading Comprehension of Ultra-Long Context in Large Language Models
Boheng Sheng, Jiacheng Yao, Meicong Zhang, Guoxiu He

## 细化基于显著性稀疏微调策略的语言模型。
Refining Salience-Aware Sparse Fine-Tuning Strategies for Language Models
Xinxin Liu, Aaron Thomas, Cheng Zhang, Jianyi Cheng, Yiren Zhao, Xitong Gao

## DualRAG：一种结合推理和检索的双过程多跳问答方法。
DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering
Rong Cheng, Jinyi Liu, YAN ZHENG, Fei Ni, Jiazhen Du, Hangyu Mao, Fuzheng Zhang, Bo Wang, Jianye HAO

## ScaleBiO：面向大规模语言模型数据重权的可-level 嵌套优化方法。
ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting
Rui Pan, Dylan Zhang, Hanning Zhang, Xingyuan Pan, Minrui Xu, Jipeng Zhang, Renjie Pi, Xiaoyu Wang, Tong Zhang

## 超越文本压缩：跨规模评估分词器。
Beyond Text Compression: Evaluating Tokenizers Across Scales
Jonas F. Lotz, António V. Lopes, Stephan Peitz, Hendra Setiawan, Leonardo Emili

## 高效的多-shot 在上下文学习与动态块稀疏注意力。
Efficient Many-Shot In-Context Learning with Dynamic Block-Sparse Attention
Emily Xiao, Chin-Jou Li, Yilin Zhang, Graham Neubig, Amanda Bertsch

## 行为系统性与表征系统性在端到端模型中的对比：一个富有偏见的回顾。
Behavioural vs. Representational Systematicity in End-to-End Models: An Opinionated Survey
Ivan Vegner, Sydelle de Souza, Valentin Forch, Martha Lewis, Leonidas A. A. Doumas

## 当LLM分别被训练用于快速思考和慢速思考时，各层发生了什么：从梯度视角看。
What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective
Ming Li, Yanhong Li, Tianyi Zhou

## 在语言适应持续预训练下大型语言模型新兴能力。
Emergent Abilities of Large Language Models under Continued Pre-training for Language Adaptation
Ahmed Elhady, Eneko Agirre, Mikel Artetxe

##  deliberate reasoning for language models as structure-aware planning with accurate world model 可译为：\n标题：语言模型中的深思熟虑推理：基于结构感知的规划与精确的世界模型。
Deliberate Reasoning for Language Models as Structure-aware Planning with Accurate World Model
Siheng Xiong, Ali Payani, Yuan Yang, Faramarz Fekri

## TiC-LM：面向时间连续预训练的Web规模基准。
TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining
Jeffrey Li, Mohammadreza Armandpour, Seyed Iman Mirzadeh, Sachin Mehta, Vaishaal Shankar, Raviteja Vemulapalli, Samy Bengio, Oncel Tuzel, Mehrdad Farajtabar, Hadi Pouransari, Fartash Faghri

## 藏在字里行间的含义：将隐含含义纳入自然语言推理。
Entailed Between the Lines: Incorporating Implication into NLI
Shreya Havaldar, Hamidreza Alvari, John Palowitch, Mohammad Javad Hosseini, Senaka Buthpitiya, Alex Fabrikant

## R-公平性：评估主观数据排序的公平性。
R-Fairness: Assessing Fairness of Ranking in Subjective Data
Lorenzo Balzotti, Donatella Firmani, Jerin George Mathew, Riccardo Torlone, Sihem Amer-Yahia

## 朝着跨文化翻译中的风格对齐努力。
Towards Style Alignment in Cross-Cultural Translation
Shreya Havaldar, Adam Stein, Eric Wong, Lyle Ungar

## 生成语言模型的多层解释。
Multi-Level Explanations for Generative Language Models
Lucas Monteiro Paes, Dennis Wei, Hyo Jin Do, Hendrik Strobelt, Ronny Luss, Amit Dhurandhar, Manish Nagireddy, Karthikeyan Natesan Ramamurthy, Prasanna Sattigeri, Werner Geyer, Soumya Ghosh

## RePanda：由Pandas驱动的表格验证与推理。
RePanda: Pandas-powered Tabular Verification and Reasoning
Atoosa Chegini, Keivan Rezaei, Hamid Eghbalzadeh, Soheil Feizi

## WiCkED：一种使多项选择基准测试更具挑战性的方法。
WiCkeD: A Simple Method to Make Multiple Choice Benchmarks More Challenging
Ahmed Elhady, Eneko Agirre, Mikel Artetxe

## LETS-C：利用文本嵌入进行时间序列分类。
LETS-C: Leveraging Text Embedding for Time Series Classification
Rachneet Kaur, Zhen Zeng, Tucker Balch, Manuela Veloso

## 低位量化有利于未充分训练的大型语言模型：量化大型语言模型的标度定律（含100T训练令牌）。
Low-Bit Quantization Favors Undertrained LLMs: Scaling Laws for Quantized LLMs with 100T Training Tokens
Xu Ouyang, Tao Ge, Thomas Hartvigsen, Zhisong Zhang, Haitao Mi, Dong Yu

## 一种减轻隐私政策问答系统方言偏见的多代理框架。
A Multi-Agent Framework for Mitigating Dialect Biases in Privacy Policy Question-Answering Systems
Đorđe Klisura, Astrid R Bernaga Torres, Anna Karen Gárate-Escamilla, Rajesh Roshan Biswal, Ke Yang, Hilal Pataci, Anthony Rios

##  Benchmarking 视频-语言模型在城市开放空间中的体态认知表现。
Benchmarking Video-Language Models for Embodied Motion Cognition in Urban Open-Ended Spaces
Baining Zhao, Jianjie Fang, Zichao Dai, Ziyou Wang, Jirong Zha, Weichen Zhang, Chen Gao, Yue Wang, Jinqiang Cui, Xinlei Chen, Yong Li

## 增强基于布局感知的用户控制文本转图像生成。
Enhancing User-Controlled Text-to-Image Generation with Layout-Aware Personalization
Hongliang Luo, Wei Xi

## ONEBench：全面测试的各项能力基于样本级别的基准测试。
ONEBench to Test Them All: Sample-Level Benchmarking Over Open-Ended Capabilities
Adhiraj Ghosh, Sebastian Dziadzio, Ameya Prabhu, Vishaal Udandarao, Samuel Albanie, Matthias Bethge

## La Leaderboard：西班牙语变体及拉丁美洲语言的大规模语言模型排行榜
La Leaderboard: A Large Language Model Leaderboard for Spanish Varieties and Languages of Spain and Latin America
María Grandury, Javier Aula-Blasco, Júlia Falcão, Clémentine Fourrier, Miguel González Saiz, Gonzalo Martínez, Gonzalo Santamaria Gomez, Rodrigo Agerri, Nuria Aldama García, Luis Chiruzzo, Javier Conde, Helena Gomez Adorno, Marta Guerrero Nieto, Guido Ivetta, Natàlia López Fuertes, Flor Miriam Plaza-del-Arco, María-Teresa Martín-Valdivia, Helena Montoro Zamorano, Carmen Muñoz Sanz, Pedro Reviriego, Leire Rosado Plaza, Alejandro Vaca Serrano, Estrella Vallecillo-Rodríguez, Jorge Vallego, Irune Zubiaga

## 使用数据专家模型混合优化预训练数据混合。
Optimizing Pre-Training Data Mixtures with Mixtures of Data Expert Models
Lior Belenki, Alekh Agarwal, Tianze Shi, Kristina Toutanova

## BFS-Prover：基于树搜索的可扩展自动定理证明方法。
BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving
Ran Xin, Chenguang Xi, Jie Yang, Feng Chen, Hang Wu, Xia Xiao, Yifan Sun, Shen Zheng, Ming Ding

## 探索提示空间：当推理误导时，监督在CoT中很重要。
Navigating the Prompt Space: Supervision Matters in CoT When Reasoning Misleads
Xiang Zhang, Juntai Cao, Chenyu You, Dujian Ding

## 大型语言模型推理的能量考虑与效率优化。
Energy Considerations of Large Language Model Inference and Efficiency Optimizations
Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell

## 逻辑正则化的验证器诱发大规模语言模型进行推理。
Logic-Regularized Verifier Elicits Reasoning from LLMs
Xinyu Wang, Changzhi Sun, Lian Cheng, Yuanbin Wu, Dell Zhang, Xuelong Li, Xiaoling Wang

## Magnet：通过图翻译实现的多轮工具使用数据合成与提炼。
Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation
Fan Yin, Zifeng Wang, I-Hung Hsu, Jun Yan, Ke Jiang, Yanfei Chen, Jindong Gu, Long Le, Kai-Wei Chang, Chen-Yu Lee, Hamid Palangi, Tomas Pfister

## 通过对比图像-标题调优实现跨语言表示对齐。
Cross-Lingual Representation Alignment Through Contrastive Image-Caption Tuning
Nathaniel Krasner, Nicholas Lanuzo, Antonios Anastasopoulos

## 挤压注意力：快速固定上下文处理长上下文大语言模型的应用 kukuiuuiuuiuk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n
Squeezed Attention: Fast Fixed Context Processing for Long Context Length LLM Applications
Coleman Richard Charles Hooper, Sehoon Kim, Hiva Mohammadzadeh, Monishwaran Maheswaran, Sebastian Zhao, June Paik, Michael W. Mahoney, Kurt Keutzer, Amir Gholami

## 我们在哪里？评估大型语言模型在非洲语言上的表现。
Where Are We? Evaluating LLM Performance on African Languages
Ife Adebara, Hawau Olamide Toyin, Nahom Tesfu Ghebremichael, AbdelRahim A. Elmadany, Muhammad Abdul-Mageed

## 合并劫持：大型语言模型合并中的后门攻击。
Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models
Zenghui Yuan, Yangming Xu, Jiawen Shi, Pan Zhou, Lichao Sun

## LangMark：多语言自动后编辑数据集。
LangMark: A Multilingual Dataset for Automatic Post-Editing
Diego Velazquez, Mikaela Grace, Konstantinos Karageorgos, Lawrence Carin, Aaron Schliem, Dimitrios Zaikis, Roger Wechsler

## LAMB：一种通过注意引导的标记过滤方法来增强SSMs长上下文理解的无需训练方法。
LAMB: A Training-Free Method to Enhance the Long-Context Understanding of SSMs via Attention-Guided Token Filtering
Zhifan Ye, Zheng Wang, Kejing Xia, Jihoon Hong, Leshu Li, Lexington Whalen, Cheng Wan, Yonggan Fu, Yingyan Celine Lin, Souvik Kundu

## HELIOS：融合早期融合、晚期融合和LLM推理的多粒度表格-文本检索。
HELIOS: Harmonizing Early Fusion, Late Fusion, and LLM Reasoning for Multi-Granular Table-Text Retrieval
Sungho Park, Joohyung Yun, Jongwuk Lee, Wook-Shin Han

## CiteEval：基于原则的引文评估方法用于源归因。
CiteEval: Principle-Driven Citation Evaluation for Source Attribution
Yumo Xu, Peng Qi, Jifan Chen, Kunlun Liu, Rujun Han, Lan Liu, Bonan Min, Vittorio Castelli, Arshit Gupta, Zhiguo Wang

## 用于大规模语言模型中相对时间理解的反事实一致性提示。
Counterfactual-Consistency Prompting for Relative Temporal Understanding in Large Language Models
Jongho Kim, seung-won hwang

## 论文标题：基于神经网络的参数搜索以获得更瘦的微调模型和更好的迁移学习。
Neural Parameter Search for Slimmer Fine-Tuned Models and Better Transfer
Guodong DU, Jing Li, Zitao Fang, Junlin Li, Runhua Jiang, Shuyang Yu, Yifei Guo, Yangneng Chen, Sim Kuan Goh, Ho-Kin Tang, Daojing He, Honghai LIU, Min Zhang

## 通过缓解稳定性差距实现高效的领域连续预训练。
Efficient Domain Continual pretraining by Mitigating the Stability Gap
Yiduo Guo, Jie Fu, Huishuai Zhang, Dongyan Zhao

## HiAgent：层次化工作记忆管理，用于解决长 horizon 代理任务的大型语言模型。
HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agentic Tasks with Large Language Models
Mengkang Hu, Tianxing Chen, Qiguang Chen, Yao Mu, Wenqi Shao, Ping Luo

## KRISTEVA：一种新的基准测试解释推理任务——细致阅读。
KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning
Peiqi Sui, Juan Diego Rodriguez, Philippe Laban, J. Dean Murphy, Joseph P. Dexter, Richard Jean So, Samuel Baker, Pramit Chaudhuri

## 超越输出匹配：增强上下文学习的双向对齐。
Beyond Output Matching: Bidirectional Alignment for Enhanced In-Context Learning
Chengwei Qin, Wenhan Xia, Fangkai Jiao, Chen Chen, Yuchen Hu, Bosheng Ding, Ruirui Chen, Shafiq Joty

## EducationQ：通过多代理对话框架评估大规模语言模型的教学能力。
EducationQ: Evaluating LLMs’ Teaching Capabilities Through Multi-Agent Dialogue Framework
Yao Shi, Rongkeng Liang, Yong Xu

## CFBench：一个全面遵守约束的标准测试平台用于LLM。
CFBench: A Comprehensive Constraints-Following Benchmark for LLMs
Tao Zhang, ChengLIn Zhu, Yanjun Shen, Wenjing Luo, Yan Zhang, Hao Liang, Tao Zhang, Fan Yang, Mingan Lin, Yujing Qiao, Weipeng Chen, Bin CUI, Wentao Zhang, Zenan Zhou

## Palm：为阿拉伯语预训练语言模型提供文化包容性和语言多样性的数据集。
Palm: A Culturally Inclusive and Linguistically Diverse Dataset for Arabic LLMs
Fakhraddin Alwajih, Abdellah EL MEKKI, Samar Mohamed Magdy, AbdelRahim A. Elmadany, OMER NACAR, El Moatez Billah Nagoudi, Reem Abdel-Salam, Hanin atwany, Youssef Nafea, Abdulfattah Mohammed Yahya, Rahaf Alhamouri, Hamzah A. Alsayadi, Hiba Zayed, Sara Shatnawi, Serry Sibaee, Yasir ECH-CHAMMAKHY, Walid Al-Dhabyani, Marwa Mohamed Ali, Imen JARRAYA, Ahmed Oumar El-Shangiti, Aisha Alraeesi, Mohammed Anwar AL-Ghrawi, Abdulrahman S. Al-Batati, Elgizouli Mohamed, Noha Taha Elgindi, Muhammed Saeed, Houdaifa Atou, Issam AIT YAHIA, Abdelhak Bouayad, Mohammed Machrouh, AMAL MAKOUAR, Dania Alkawi, Mukhtar Mohamed, Safaa Taher Abdelfadil, Amine Ziad Ounnoughene, Anfel ROUABHIA, Rwaa Assi, Ahmed Sorkatti, Mohamedou cheikh tourad, Anis Koubaa, Ismail Berrada, Mustafa Jarrar, Shady Shehata, Muhammad Abdul-Mageed

## CoRe-MMRAG：跨源知识 reconciliation 用于多模态RAL。
CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG
yang tian, Fan Liu, Jingyuan Zhang, V. W., Yupeng Hu, Liqiang Nie

## NewsInterview：用于通过信息访谈评估大型语言模型接地差距的数据集和实验平台。
NewsInterview: a Dataset and a Playground to Evaluate LLMs’ Grounding Gap via Informational Interviews
Alexander Spangher, Michael Lu, Sriya Kalyan, Hyundong Justin Cho, Tenghao Huang, Weiyan Shi, Jonathan May

## 无需训练的大型语言模型合并以实现多任务学习
Training-free LLM Merging for Multi-task Learning
Zichuan Fu, Xian Wu, Yejing Wang, Wanyu Wang, Shanshan Ye, Hongzhi Yin, Yi Chang, Yefeng Zheng, Xiangyu Zhao

## 面向13种印度语言的大规模语料库构建与自动语音翻译系统研究
Towards Building Large Scale Datasets and State-of-the-Art Automatic Speech Translation Systems for 13 Indian Languages
Ashwin Sankar, Sparsh Jain, Nikhil Narasimhan, Devilal Choudhary, Dhairya Suman, Mohammed Safi Ur Rahman Khan, Anoop Kunchukuttan, Mitesh M Khapra, Raj Dabre

## 稳健估计重复测量自然语言处理实验设计中的总体效应。
Robust Estimation of Population-Level Effects in Repeated-Measures NLP Experimental Designs
Alejandro Benito-Santos, Adrian Ghajari, Víctor Fresno

## 通过逻辑似然向量映射1,000多个语言模型。
Mapping 1,000+ Language Models via the Log-Likelihood Vector
Momose Oyama, Hiroaki Yamagiwa, Yusuke Takase, Hidetoshi Shimodaira

## ConsistencyChecker：基于树结构的大型语言模型泛化能力评估方法。
ConsistencyChecker: Tree-based Evaluation of LLM Generalization Capabilities
Zhaochen Hong, Haofei Yu, Jiaxuan You

## 基于比较的主动偏好学习在多维度个性化中的应用。
Comparison-based Active Preference Learning for Multi-dimensional Personalization
Minhyeon Oh, Seungjoon Lee, Jungseul Ok

## OpenCoder：顶级代码大规模语言模型的开源 cook 书。
OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models
Siming Huang, Tianhao Cheng, Jason Klein Liu, Weidi Xu, JIARAN HAO, Liuyihan Song, Yang Xu, Jian Yang, Jiaheng Liu, Chenchen Zhang, Linzheng Chai, Ruifeng Yuan, Xianzhen Luo, Qiufeng Wang, YuanTao Fan, Qingfu Zhu, Zhaoxiang Zhang, Yang Gao, Jie Fu, Qian Liu, Houyi Li, Ge Zhang, Yuan Qi, Xu Yinghui, Wei Chu, Zili Wang

## 从logits推断：探索无需解码的生成候选选择的最佳实践。
Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection
Mingyu Derek Ma, Yanna Ding, Zijie Huang, Jianxi Gao, Yizhou Sun, Wei Wang

## FactBench：一种用于真实世界语言模型事实性评估的动态基准。
FactBench: A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation
Farima Fatahi Bayat, Lechen Zhang, Sheza Munir, Lu Wang

## SocialDuolingo：评估语言代理文化 competence 的互动方法。
SocialDuolingo: Interactive Evaluation for Cultural Competence in Language Agents
Jincenzi Wu, Jianxun Lian, Dingdong WANG, Helen M. Meng

## AmbiK：厨房环境中的模糊任务数据集。
AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment
Anastasia Ivanova, Zoya Volovikova, Bakaeva Eva, Alexey Kovalev, Aleksandr Panov

## 通往经济高效的推理：使任何基于Transformer的大语言模型能够实现DeepSeek的多头潜在注意机制。
Towards Economical Inference: Enabling DeepSeek’s Multi-Head Latent Attention in Any Transformer-based LLMs
Tao Ji, Bin Guo, Yuanbin Wu, Qipeng Guo, shenlixing, chenzhan, Xipeng Qiu, Qi Zhang, Tao Gui

## 通过高质量数据整理实现可扩展的视觉语言模型训练。
Scalable Vision Language Model Training via High Quality Data Curation
Hongyuan Dong, Zijian Kang, Weijie Yin, LiangXiao, ChaoFeng, Ran Jiao

## 引入基于集一致能网络的集一致性验证任务。
Introducing Verification Task of Set Consistency with Set-Consistency Energy Networks
Mooho Song, Hye Ryung Son, Jay-Yoon Lee

## GRAM：基于语义aware多粒度晚期融合的生成性推荐。
GRAM: Generative Recommendation via Semantic-aware Multi-granular Late Fusion
Sunkyung Lee, Minjin Choi, Eunseong Choi, Hye-young Kim, Jongwuk Lee

## 欺骗之上的微妙误导：用于立法战略性表述的大型语言模型。
A subtle deception beyond lying: LLMs for strategic phrasing in legislation
Atharvan Dogra, Krishna Pillutla, Ameet Deshpande, Ananya B. Sai, John J Nay, Tanmay Rajpurohit, Ashwin Kalyan, Balaraman Ravindran

## 一种高效细粒度的视觉语言模型Prompt学习方法。
A Parameter-Efficient and Fine-Grained Prompt Learning for Vision-Language Models
Yongbin Guo, Shuzhen Li, zhulin liu, Tong Zhang, C.L.Philip Chen

## TETRIS：批推测解码的最优草稿标记选择。
TETRIS: Optimal Draft Token Selection for Batch Speculative Decoding
Zhaoxuan Wu, Zijian Zhou, Arun Verma, Alok Prakash, Daniela Rus, Bryan Kian Hsiang Low

## 就这样并行化：提高大型语言模型的多语言能力。
Just Go Parallel: Improving the Multilingual Capabilities of Large Language Models
Muhammad Reza Qorib, Junyi Li, Hwee Tou Ng

## AfroCS-xs：创建一种紧凑、高质量、经人类验证的代码转换数据集以供非洲语言使用。
AfroCS-xs: Creating a Compact, High-Quality, Human-Validated Code-Switched Dataset for African Languages
Kayode Olaleye, Arturo Oncevay, Mathieu Sibue, Nombuyiselo Zondi, Michelle Terblanche, Sibongile Mapikitla, Richard Lastrucci, Charese Smiley, Vukosi Marivate

## 设计选择以扩展视觉语言模型的上下文长度。
Design Choices for Extending the Context Length of Visual Language Models
Mukai Li, Lei Li, Shansan Gong, Qi Liu

## LlamaDuo：从服务端大型语言模型无缝迁移至小型本地语言模型的LLMOps管道。
LlamaDuo: LLMOps Pipeline for Seamless Migration from Service LLMs to Small-Scale Local LLMs
Chansung Park, Juyong Jiang, Fan Wang, Sayak Paul, Jing Tang

## 分离舌头与思维：激活补丁揭示Transformer中的语言无关概念表示。
Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers
Clément Dumas, Chris Wendler, Veniamin Veselovsky, Giovanni Monea, Robert West

## BeaverTails v2：针对具有人类偏好导向的LLM多层级安全对齐的尝试。
BeaverTails v2: Towards Multi-Level Safety Alignment for LLMs with Human Preference
Jiaming Ji, Donghai Hong, Borong Zhang, Boyuan Chen, Josef Dai, Boren Zheng, Tianyi Qiu, Jiayi Zhou, Kaile Wang, Boxun Li, Sirui Han, Yike Guo, Yaodong Yang

## 寻找甜蜜点：构建偏好数据以扩展偏好优化。
Finding the Sweet Spot: Preference Data Construction for Scaling Preference Optimization
Yao Xiao, Hai Ye, Linyao Chen, Hwee Tou Ng, Lidong Bing, Xiaoli Li, Roy Ka-Wei Lee

